
1. PLoS One. 2017 Jan 31;12(1):e0171046. doi: 10.1371/journal.pone.0171046.
eCollection 2017.

Metabox: A Toolbox for Metabolomic Data Analysis, Interpretation and Integrative 
Exploration.

Wanichthanarak K(1), Fan S(1), Grapov D(1), Barupal DK(1), Fiehn O(1,)(2).

Author information: 
(1)West Coast Metabolomics Center, Genome Center, University of California Davis,
Davis, California, United States of America. (2)Biochemistry Department, King
Abdulaziz University, Jeddah, Saudi Arabia.

Similar to genomic and proteomic platforms, metabolomic data acquisition and
analysis is becoming a routine approach for investigating biological systems.
However, computational approaches for metabolomic data analysis and integration
are still maturing. Metabox is a bioinformatics toolbox for deep phenotyping
analytics that combines data processing, statistical analysis, functional
analysis and integrative exploration of metabolomic data within proteomic and
transcriptomic contexts. With the number of options provided in each analysis
module, it also supports data analysis of other 'omic' families. The toolbox is
an R-based web application, and it is freely available at
http://kwanjeeraw.github.io/metabox/ under the GPL-3 license.

DOI: 10.1371/journal.pone.0171046 
PMID: 28141874  [PubMed - in process]


2. Bioinformatics. 2017 Jan 30. pii: btx028. doi: 10.1093/bioinformatics/btx028.
[Epub ahead of print]

HIPred: an integrative approach to predicting haploinsufficient genes.

Shihab HA(1), Rogers MF(2), Campbell C(2), Gaunt TR(1).

Author information: 
(1)MRC Integrative Epidemiology Unit (IEU), University of Bristol, Bristol BS8
2BN, UK H.Shihab@bristol.ac.uk. (2)Intelligent Systems Laboratory, University of 
Bristol, Bristol BS8 1UB, UK.

MOTIVATION: A major cause of autosomal dominant disease is haploinsufficiency,
whereby a single copy of a gene is not sufficient to maintain the normal function
of the gene. A large proportion of existing methods for predicting
haploinsufficiency incorporate biological networks, e.g. protein-protein
interaction networks, that have recently been shown to introduce study bias. As a
result, these methods tend to perform best on well studied genes, but
underperform on less studied genes. The advent of large genome sequencing
consortia, such as the 1,000 genomes project, NHLBI Exome Sequencing Project
(ESP) and the Exome Aggregation Consortium (ExAC) creates an urgent need for
unbiased haploinsufficiency prediction methods.
RESULTS: Here, we describe a machine learning approach, called HIPred, that
integrates genomic and evolutionary information from ENSEMBL, with functional
annotations from the Encyclopaedia of DNA Elements (ENCODE) consortium and the
NIH Roadmap Epigenomics Project to predict haploinsufficiency, without the study 
bias described above. We benchmark HIPred using several datasets and show that
our unbiased method performs as well as, and in most cases, outperforms existing 
biased algorithms.
AVAILABILITY: HIPred scores for all gene identifiers are available at:
https://github.com/HAShihab/HIPred CONTACT: Tom.Gaunt@bris.ac.uk SUPPLEMENTARY
INFORMATION: Supplementary data are available at Bioinformatics online.

© The Author(s) 2017. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btx028 
PMID: 28137713  [PubMed - as supplied by publisher]


3. J Theor Biol. 2017 Jan 27. pii: S0022-5193(17)30049-8. doi:
10.1016/j.jtbi.2017.01.040. [Epub ahead of print]

Sequence-based Discrimination of Protein-RNA Interacting Residues using a
Probabilistic Approach.

Pai PP(1), Dash T(2), Mondal S(3).

Author information: 
(1)Annotate Biomolecules Computationally (ABC) Group, Department of Biological
Sciences, Birla Institute of Technology and Science Pilani, K.K. Birla Goa
Campus, Goa 403 726, India. (2)Data Science Research Group, Department of
Computer Science and Information Systems, Birla Institute of Technology and
Science Pilani, K.K. Birla Goa Campus, Goa 403 726, India. Electronic address:
tirtharaj@goa.bits-pilani.ac.in. (3)Annotate Biomolecules Computationally (ABC)
Group, Department of Biological Sciences, Birla Institute of Technology and
Science Pilani, K.K. Birla Goa Campus, Goa 403 726, India. Electronic address:
suku@goa.bits-pilani.ac.in.

Protein interactions with ribonucleic acids (RNA) are well-known to be crucial
for a wide range of cellular processes such as transcriptional regulation,
protein synthesis or translation, and post-translational modifications.
Identification of the RNA-interacting residues can provide insights into these
processes and aid in relevant biotechnological manipulations. Owing to their
eventual potential in combating diseases and industrial production, several
computational attempts have been made over years using sequence- and
structure-based information. Recent comparative studies suggest that despite
these developments, many problems are faced with respect to the usability,
prerequisites, and accessibility of various tools, thereby calling for an
alternative approach and perspective supplementation in the prediction scenario. 
With this motivation, in this paper, we propose the use of a simple-yet-efficient
conditional probabilistic approach based on the application of local occurrence
of amino acids in the interacting region in a non-numeric sequence feature space,
for discriminating between RNA interacting and non-interacting residues. The
proposed method has been meticulously tested for robustness using a
cross-estimation method showing MCC of 0.341 and F- measure of 66.84%. Upon
exploring large scale applications using benchmark datasets available to date,
this approach showed an encouraging performance comparable with the state-of-art.
The software is available at https://github.com/ABCgrp/DORAEMON.

Copyright © 2017 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.jtbi.2017.01.040 
PMID: 28137600  [PubMed - as supplied by publisher]


4. Genome Biol. 2017 Jan 30;18(1):21. doi: 10.1186/s13059-016-1146-2.

Chrom3D: three-dimensional genome modeling from Hi-C and nuclear lamin-genome
contacts.

Paulsen J(1), Sekelja M(1), Oldenburg AR(1), Barateau A(2), Briand N(1), Delbarre
E(1), Shah A(1), Sørensen AL(1), Vigouroux C(3,)(4,)(5,)(6), Buendia B(2), Collas
P(7,)(8).

Author information: 
(1)Department of Molecular Medicine, Institute of Basic Medical Sciences, Faculty
of Medicine, University of Oslo, Oslo, Norway. (2)Institut BFA, Université Paris 
7-CNRS, Paris, France. (3)INSERM, UMR S938, Centre de Recherches Saint-Antoine,
Paris, France. (4)UPMC Université Paris 6 UMR S938, Paris, France. (5)ICAN,
Paris, France. (6)AP-HP Hôpital Tenon, Paris, France. (7)Department of Molecular 
Medicine, Institute of Basic Medical Sciences, Faculty of Medicine, University of
Oslo, Oslo, Norway. philc@medisin.uio.no. (8)Norwegian Center for Stem Cell
Research, Oslo University Hospital, Oslo, Norway. philc@medisin.uio.no.

Current three-dimensional (3D) genome modeling platforms are limited by their
inability to account for radial placement of loci in the nucleus. We present
Chrom3D, a user-friendly whole-genome 3D computational modeling framework that
simulates positions of topologically-associated domains (TADs) relative to each
other and to the nuclear periphery. Chrom3D integrates chromosome conformation
capture (Hi-C) and lamin-associated domain (LAD) datasets to generate structure
ensembles that recapitulate radial distributions of TADs detected in single
cells. Chrom3D reveals unexpected spatial features of LAD regulation in cells
from patients with a laminopathy-causing lamin mutation. Chrom3D is freely
available on github.

DOI: 10.1186/s13059-016-1146-2 
PMID: 28137286  [PubMed - in process]


5. BMC Bioinformatics. 2017 Jan 31;18(1):72. doi: 10.1186/s12859-017-1490-6.

Multiple network algorithm for epigenetic modules via the integration of
genome-wide DNA methylation and gene expression data.

Ma X(1,)(2), Liu Z(3), Zhang Z(4), Huang X(1), Tang W(5).

Author information: 
(1)School of Computer Science and Technology, Xidian University, No.2 South
TaiBai Road, Xi'an, People's Republic of China. (2)Xidian-Ningbo Information
Technology Institute, Xidian University, No. 777 Zhongguanxi Road, Ningbo,
People's Republic of China. (3)Department of Radiology, Guangdong General
Hospital, Guangdong Academy of Medical Sciences, Zhongshan Road, Guangzhou,
People's Republic of China. (4)School of Statistics and Mathematics, Central
University of Finance and Economics, 39 South College Road, Haidian District,
Beijing, People's Republic of China. (5)Department of Nephrology, West China
Hospital, Sichuan University, Wuhou District, Chengdu, People's Republic of
China. tangwx@scu.edu.cn.

BACKGROUND: With the increase in the amount of DNA methylation and gene
expression data, the epigenetic mechanisms of cancers can be extensively
investigate. Available methods integrate the DNA methylation and gene expression 
data into a network by specifying the anti-correlation between them. However, the
correlation between methylation and expression is usually unknown and difficult
to determine.
RESULTS: To address this issue, we present a novel multiple network framework for
epigenetic modules, namely, Epigenetic Module based on Differential Networks
(EMDN) algorithm, by simultaneously analyzing DNA methylation and gene expression
data. The EMDN algorithm prevents the specification of the correlation between
methylation and expression. The accuracy of EMDN algorithm is more efficient than
that of modern approaches. On the basis of The Cancer Genome Atlas (TCGA) breast 
cancer data, we observe that the EMDN algorithm can recognize positively and
negatively correlated modules and these modules are significantly more enriched
in the known pathways than those obtained by other algorithms. These modules can 
serve as bio-markers to predict breast cancer subtypes by using methylation
profiles, where positively and negatively correlated modules are of equal
importance in the classification of cancer subtypes. Epigenetic modules also
estimate the survival time of patients, and this factor is critical for cancer
therapy.
CONCLUSIONS: The proposed model and algorithm provide an effective method for the
integrative analysis of DNA methylation and gene expression. The algorithm is
freely available as an R-package at https://github.com/william0701/EMDN .

DOI: 10.1186/s12859-017-1490-6 
PMID: 28137264  [PubMed - in process]


6. PeerJ. 2017 Jan 19;5:e2888. doi: 10.7717/peerj.2888. eCollection 2017.

Detecting heterogeneity in single-cell RNA-Seq data by non-negative matrix
factorization.

Zhu X(1), Ching T(1), Pan X(2), Weissman SM(2), Garmire L(3).

Author information: 
(1)Epidemiology Program, University of Hawaii Cancer Center, Honolulu, HI, United
States; Molecular Biosciences and Bioengineering Graduate Program, University of 
Hawaii at Manoa, Honolulu, United States. (2)Department of Genetics, Yale
University , New Haven , CT , United States. (3)Epidemiology Program, University 
of Hawaii Cancer Center , Honolulu , HI , United States.

Single-cell RNA-Sequencing (scRNA-Seq) is a fast-evolving technology that enables
the understanding of biological processes at an unprecedentedly high resolution. 
However, well-suited bioinformatics tools to analyze the data generated from this
new technology are still lacking. Here we investigate the performance of
non-negative matrix factorization (NMF) method to analyze a wide variety of
scRNA-Seq datasets, ranging from mouse hematopoietic stem cells to human
glioblastoma data. In comparison to other unsupervised clustering methods
including K-means and hierarchical clustering, NMF has higher accuracy in
separating similar groups in various datasets. We ranked genes by their
importance scores (D-scores) in separating these groups, and discovered that NMF 
uniquely identifies genes expressed at intermediate levels as top-ranked genes.
Finally, we show that in conjugation with the modularity detection method FEM,
NMF reveals meaningful protein-protein interaction modules. In summary, we
propose that NMF is a desirable method to analyze heterogeneous single-cell
RNA-Seq data. The NMF based subpopulation detection package is available at:
https://github.com/lanagarmire/NMFEM.

DOI: 10.7717/peerj.2888 
PMCID: PMC5251935
PMID: 28133571  [PubMed - in process]


7. Bioinformatics. 2017 Jan 27. pii: btx032. doi: 10.1093/bioinformatics/btx032.
[Epub ahead of print]

A comprehensive quality control workflow for paired tumor-normal NGS experiments.

Schroeder CM(1), Hilke FJ(2), Löffler MW(3,)(4), Bitzer M(5), Lenz F(2), Sturm
M(2).

Author information: 
(1)Institute of Medical Genetics and Applied Genomics, University of Tübingen,
Calwerstr. 7, 72076 Tübingen christopher.schroeder@med.uni-tuebingen.de
christopher-schroeder@gmx.de. (2)Institute of Medical Genetics and Applied
Genomics, University of Tübingen, Calwerstr. 7, 72076 Tübingen. (3)University
Hospital Tübingen, Department of General, Visceral and Transplant Surgery,
Hoppe-Seyler-Str. 3, 72076 Tübingen, Germany. (4)Interfaculty Institute for Cell 
Biology, Department of Immunology, University of Tübingen, Auf der Morgenstelle
15, 72076 Tübingen, Germany. (5)Department of Internal Medicine I, Medical
University Hospital, Tübingen, Germany.

Quality control (QC) is an important part of all NGS data analysis stages. Many
available tools calculate QC metrics from different analysis steps of single
sample experiments (raw reads, mapped reads and variant lists). Multi-sample
experiments, as sequencing of tumor-normal pairs, require additional QC metrics
to ensure validity of results. These multi-sample QC metrics still lack
standardization. We therefore suggest a new workflow for QC of DNA sequencing of 
tumor-normal pairs. With this workflow well-known single-sample QC metrics and
additionally metrics specific for tumor-normal pairs can be calculated. The
segmentation into different tools offers a high flexibility and allows reuse for 
other purposes. All tools produce qcML, a generic XML format for QC of -omics
experiments. qcML uses quality metrics defined in an ontology, which was adapted 
for NGS.AVAILABILITY AND IMPLEMENTATION: All QC tools are implemented in C ++ and
run both under Linux and Windows. Plotting requires python 2.7 and matplotlib.
The software is available under the 'GNU General Public License version 2' as
part of the ngs-bits project: https://github.com/imgag/ngs-bits CONTACT:
christopher.schroeder@med.uni-tuebingen.de SUPPLEMENTARY INFORMATION:
Supplementary data are available at Bioinformatics online.

© The Author (2017). Published by Oxford University Press. All rights reserved.
For Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btx032 
PMID: 28130233  [PubMed - as supplied by publisher]


8. Bioinformatics. 2017 Jan 27. pii: btx038. doi: 10.1093/bioinformatics/btx038.
[Epub ahead of print]

ANAQUIN: a software toolkit for the analysis of spike-in controls for next
generation sequencing.

Wong T(1), Deveson IW(1,)(2), Hardwick SA(1,)(3), Mercer TR(4,)(3).

Author information: 
(1)Genomics and Epigenetics Division, Garvan Institute of Medical Research, NSW, 
Australia. (2)School of Biotechnology and Biomolecular Sciences, Faculty of
Science, UNSW Australia, NSW, Australia. (3)St Vincents Clinical School, Faculty 
of Medicine, UNSW Australia, NSW, Australia. (4)Genomics and Epigenetics
Division, Garvan Institute of Medical Research, NSW, Australia
t.mercer@garvan.org.au.

Spike-in controls are synthetic nucleic-acid sequences that are added to a user's
sample and constitute internal standards for subsequent steps in the next
generation sequencing workflow.The Anaquin software toolkit can be used to
analyze the performance of spike-in controls at multiple steps during RNA
sequencing or genome sequencing analysis, providing useful diagnostic statistics,
data visualization and sample normalization.AVAILABILITY: The software is
implemented in C ++/R and is freely available under BSD license. The source code 
is available from github.com/student-t/Anaquin, binaries and user manual from
www.sequin.xyz/software and R package from
bioconductor.org/packages/AnaquinContact: anaquin@garvan.org.au and further
details at http://www.sequin.xyz/softwareSupplementary information: Supplementary
data (User Guide and ERCC workflow) available at Bioinformatics online.

© The Author (2017). Published by Oxford University Press. All rights reserved.
For Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btx038 
PMID: 28130232  [PubMed - as supplied by publisher]


9. J Chem Inf Model. 2017 Jan 26. doi: 10.1021/acs.jcim.6b00686. [Epub ahead of
print]

3D-e-Chem-VM: Structural cheminformatics research infrastructure in a freely
available Virtual Machine.

McGuire R, Verhoeven S, Vass M, Vriend G, De Esch IJ, Lusher SJ, Leurs R, Ridder 
L, Kooistra AJ, Ritschel T, de Graaf C.

3D-e-Chem-VM is an open source, freely available Virtual Machine
(http://3d-e-chem.github.io/3D-e-Chem-VM/) that integrates cheminformatics and
bioinformatics tools for the analysis of protein-ligand interaction data.
3D-e-Chem-VM consists of software libraries, and database and workflow tools that
can analyze and combine small molecule and protein structural information in a
graphical programming environment. New chemical and biological data analytics
tools and workflows have been developed for the efficient exploitation of
structural and pharmacological protein-ligand interaction data from proteome-wide
databases (e.g. ChEMBLdb and PDB), as well as customized information systems
focused on e.g. G Protein-Coupled Receptors (GPCRdb) and protein kinases (KLIFS).
The integrated structural cheminformatics research infrastructure compiled in the
3D-e-Chem-VM enables the design of new approaches in virtual ligand screening
(Chemdb4VS), ligand-based metabolism prediction (SyGMa), and structure-based
protein binding site comparison and bioisosteric replacement for ligand design
(KRIPOdb).

DOI: 10.1021/acs.jcim.6b00686 
PMID: 28125221  [PubMed - as supplied by publisher]


10. G3 (Bethesda). 2017 Jan 25. pii: g3.116.038877. doi: 10.1534/g3.116.038877. [Epub
ahead of print]

Reproducing and In-Depth Evaluation of Genome-Wide Association Studies and
Genome-Wide Meta-Analyses Using Summary Statistics.

Niu YF(1), Ye C(2), He J(3), Han F(4), Guo LB(1), Zheng HF(2), Chen GB(5).

Author information: 
(1)China National Rice Research Institute. (2)Hangzhou Normal University.
(3)Peking University Third Hospital. (4)Peking University People's Hospital.
(5)Evergreen Landscape and Architecture Studio chen.guobo@foxmail.com.

In line with open-source genetics, we report a novel linear regression technique 
for genome-wide association studies (GWAS), called O: pen GW A: S algori TH: m
(OATH). When individual-level data are not available, OATH can not only
completely reproduce reported results from an experimental model but also recover
underreported results from other alternative models with a different combination 
of nuisance parameters using naïve summary statistics (NSS). OATH can also
reliably evaluate all reported results in-depth (e.g., p-value variance
analysis), as demonstrated for 42 Arabidopsis phenotypes under 3 magnesium
conditions. In addition, OATH can be used for consortium-driven genome-wide
association meta-analyses (GWAMA), and greatly improve the flexibility of GWAMA. 
A prototype of OATH is available in the Genetic Analysis Repository
(https://github.com/gc5k/GEAR).

Copyright © 2017 Author et al.

DOI: 10.1534/g3.116.038877 
PMID: 28122950  [PubMed - as supplied by publisher]


11. Bioinformatics. 2017 Jan 25. pii: btw813. doi: 10.1093/bioinformatics/btw813.
[Epub ahead of print]

BioPAXViz: a cytoscape application for the visual exploration of metabolic
pathway evolution.

Psomopoulos FE(1), Vitsios DM(1,)(2), Baichoo S(3), Ouzounis CA(1,)(4).

Author information: 
(1)Computational Genomics Unit, Institute of Applied Biosciences, Center for
Research & Technology Hellas (CERTH), GR-57001 Thessalonica, Greece. (2)The
European Bioinformatics Institute, EMBL Cambridge Outstation, Wellcome Trust
Genome Campus, Hinxton, Cambridge CB10 1SD, UK. (3)Department of Computer Science
& Engineering, Faculty of Engineering, University of Mauritius, Reduit 80837,
Mauritius. (4)Donnelly Centre for Cellular & Biomolecular Research, University of
Toronto, Toronto, Ontario M5S 3E1, Canada.

BioPAXViz is a Cytoscape (version 3) application, providing a comprehensive
framework for metabolic pathway visualization. Beyond the basic parsing, viewing 
and browsing roles, the main novel function that BioPAXViz provides is a visual
comparative analysis of metabolic pathway topologies across pre-computed pathway 
phylogenomic profiles given a species phylogeny. Furthermore, BioPAXViz supports 
the display of hierarchical trees that allow efficient navigation through sets of
variants of a single reference pathway. Thus, BioPAXViz can significantly
facilitate, and contribute to, the study of metabolic pathway evolution and
engineering.AVAILABILITY AND IMPLEMENTATION: BioPAXViz has been developed as a
Cytoscape app and is available at: https://github.com/CGU-CERTH/BioPAX.Viz The
software is distributed under the MIT License and is accompanied by example files
and data. Additional documentation is available at the aforementioned GitHub
repository.
CONTACT: ouzounis@certh.gr.

© The Author 2017. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw813 
PMID: 28122780  [PubMed - as supplied by publisher]


12. Bioinformatics. 2017 Jan 25. pii: btw820. doi: 10.1093/bioinformatics/btw820.
[Epub ahead of print]

Introducing COCOS: codon consequence scanner for annotating reading frame changes
induced by stop-lost and frame shift variants.

Butkiewicz M(1), Haines JL(1), Bush WS(1).

Author information: 
(1)Department of Epidemiology and Biostatistics, Institute for Computational
Biology, Case Western Reserve University, Cleveland, OH, USA.

: Reading frame altering genomic variants can impact gene expression levels and
the structure of protein products, thus potentially inducing disease phenotypes. 
Current annotation approaches report the impact of such variants in the context
of altered DNA sequence only; attributes of the resulting transcript, reading
frame and translated protein product are not reported. To remedy this
shortcoming, we present a new genetic annotation approach termed Codon
Consequence Scanner (COCOS). Implemented as an Ensembl variant effect predictor
(VEP) plugin, COCOS captures amino acid sequence alterations stemming from
variants that produce an altered reading frame, such as stop-lost variants and
small insertions and deletions (InDels). To highlight its significance, COCOS was
applied to data from the 1000 Genomes Project. Transcripts affected by stop-lost 
variants introduce a median of 15 amino acids, while InDels have a more extensive
impact with a median of 66 amino acids being incorporated. Captured sequence
alterations are written out in FASTA format and can be further analyzed for
impact on the underlying protein structure.AVAILABILITY AND IMPLEMENTATION: COCOS
is available to all users on github: https://github.com/butkiem/COCOS CONTACT:
mariusz.butkiewicz@case.edu.

© The Author 2017. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw820 
PMID: 28122779  [PubMed - as supplied by publisher]


13. BMC Syst Biol. 2017 Jan 25;11(1):10. doi: 10.1186/s12918-016-0380-2.

JuPOETs: a constrained multiobjective optimization approach to estimate
biochemical model ensembles in the Julia programming language.

Bassen DM(1), Vilkhovoy M(2), Minot M(2), Butcher JT(1), Varner JD(3).

Author information: 
(1)Department of Biomedical Engineering, Cornell University, Ithaca, 14853, NY,
USA. (2)Department of Chemical and Biomolecular Engineering, Cornell University, 
Ithaca, 14853, NY, USA. (3)Department of Chemical and Biomolecular Engineering,
Cornell University, Ithaca, 14853, NY, USA. jdv27@cornell.edu.

BACKGROUND: Ensemble modeling is a promising approach for obtaining robust
predictions and coarse grained population behavior in deterministic mathematical 
models. Ensemble approaches address model uncertainty by using parameter or model
families instead of single best-fit parameters or fixed model structures.
Parameter ensembles can be selected based upon simulation error, along with other
criteria such as diversity or steady-state performance. Simulations using
parameter ensembles can estimate confidence intervals on model variables, and
robustly constrain model predictions, despite having many poorly constrained
parameters.
RESULTS: In this software note, we present a multiobjective based technique to
estimate parameter or models ensembles, the Pareto Optimal Ensemble Technique in 
the Julia programming language (JuPOETs). JuPOETs integrates simulated annealing 
with Pareto optimality to estimate ensembles on or near the optimal tradeoff
surface between competing training objectives. We demonstrate JuPOETs on a suite 
of multiobjective problems, including test functions with parameter bounds and
system constraints as well as for the identification of a proof-of-concept
biochemical model with four conflicting training objectives. JuPOETs identified
optimal or near optimal solutions approximately six-fold faster than a
corresponding implementation in Octave for the suite of test functions. For the
proof-of-concept biochemical model, JuPOETs produced an ensemble of parameters
that gave both the mean of the training data for conflicting data sets, while
simultaneously estimating parameter sets that performed well on each of the
individual objective functions.
CONCLUSIONS: JuPOETs is a promising approach for the estimation of parameter and 
model ensembles using multiobjective optimization. JuPOETs can be adapted to
solve many problem types, including mixed binary and continuous variable types,
bilevel optimization problems and constrained problems without altering the base 
algorithm. JuPOETs is open source, available under an MIT license, and can be
installed using the Julia package manager from the JuPOETs GitHub repository.

DOI: 10.1186/s12918-016-0380-2 
PMCID: PMC5264316
PMID: 28122561  [PubMed - in process]


14. Front Genet. 2017 Jan 10;7:225. doi: 10.3389/fgene.2016.00225. eCollection 2016.

Extending the R Library PROPER to Enable Power Calculations for Isoform-Level
Analysis with EBSeq.

Gaye A(1).

Author information: 
(1)Metabolic, Cardiovascular and Inflammatory Disease Genomics Branch, National
Human Genome Research Institute Bethesda, MD, USA.

RNA-Sequencing (RNA-Seq) has become a routine technology for investigating gene
expression differences in comparative transcriptomic studies. Differential
expression (DE) analysis of the isoforms of genes is just emerging now that
expression (read counts) can be estimated with higher accuracy at the isoform
level. Estimating the statistical power that can be achieved with a specific
number of repeats is a key step in RNA-Seq analysis. The R library proper was
developed to provide realistic empirical power analysis. However, proper uses
differential expression methods more suited for power calculation of gene-level
expression data. We propose extensions to this tool that would allow for power
analysis which takes into account the specificities of isoforms expression. This 
was achieved by enabling the use of EBSeq, a DE approach well-tailored for
isoform-level expression, as an additional analysis method within PROPER. The new
extensions and exemplar code for their usage are freely available online at:
https://github.com/agaye/proper_extension.

DOI: 10.3389/fgene.2016.00225 
PMCID: PMC5222866
PMID: 28119735  [PubMed - in process]


15. Bioinformatics. 2017 Jan 24. pii: btx007. doi: 10.1093/bioinformatics/btx007.
[Epub ahead of print]

ASCIIGenome: A command line genome browser for console terminals.

Beraldi D(1).

Author information: 
(1)Cancer Research UK, Cambridge Institute, Li Ka Shing Centre, Cambridge, UK
dario.beraldi@gmail.com.

MOTIVATION: Current genome browsers are designed to work via graphical user
interfaces (GUIs), which, however intuitive, are not amenable to operate within
console terminals and therefore are difficult to streamline or integrate in
scripts. To circumvent these limitations, ASCIIGenome runs exclusively via
command line interface to display genomic data directly in a terminal window. By 
following the same philosophy of UNIX tools, ASCIIGenome aims to be easily
integrated with the command line, including batch processing of data, and
therefore enables an effective exploration of the data.
IMPLEMENTATION: ASCIIGenome is written in Java. Consequently it is a
cross-platform tool and requires minimal or no installation. Some of the common
genomic data types are supported and data access on remote ftp servers is
possible. Speed and memory footprint are comparable to or better than those of
common genome browsers.
AVAILABILITY: Software and source code (MIT License) are available at
https://github.com/dariober/ASCIIGenome with detailed documentation at
http://asciigenome.readthedocs.io CONTACT: :
Dario.beraldi@cruk.cam.ac.ukSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2017. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btx007 
PMID: 28119307  [PubMed - as supplied by publisher]


16. PLoS One. 2017 Jan 24;12(1):e0170339. doi: 10.1371/journal.pone.0170339.
eCollection 2017.

MEDICI: Mining Essentiality Data to Identify Critical Interactions for Cancer
Drug Target Discovery and Development.

Harati S(1,)(2), Cooper LA(1,)(3,)(4), Moran JD(5,)(6), Giuste FO(7), Du
Y(3,)(8), Ivanov AA(8), Johns MA(8), Khuri FR(3,)(9), Fu H(3,)(8), Moreno
CS(1,)(3,)(6).

Author information: 
(1)Department of Biomedical Informatics, Emory University, Atlanta, Georgia,
United States of America. (2)Graduate Program in Biomedical Informatics, Emory
University, Atlanta, Georgia, United States of America. (3)Winship Cancer
Institute, Emory University, Atlanta, Georgia, United States of America.
(4)Department of Biomedical Engineering, Emory University, Atlanta, Georgia,
United States of America. (5)Graduate Program in Cancer Biology, Emory
University, Atlanta, Georgia, United States of America. (6)Department of
Pathology and Laboratory Medicine, Emory University, Atlanta, Georgia, United
States of America. (7)Medical Scientist Training Program, Emory University,
Atlanta, Georgia, United States of America. (8)Department of Pharmacology, Emory 
University, Atlanta, Georgia, United States of America. (9)Department of
Hematology & Medical Oncology, Emory University, Atlanta, Georgia, United States 
of America.

Protein-protein interactions (PPIs) mediate the transmission and regulation of
oncogenic signals that are essential to cellular proliferation and survival, and 
thus represent potential targets for anti-cancer therapeutic discovery. Despite
their significance, there is no method to experimentally disrupt and interrogate 
the essentiality of individual endogenous PPIs. The ability to computationally
predict or infer PPI essentiality would help prioritize PPIs for drug discovery
and help advance understanding of cancer biology. Here we introduce a
computational method (MEDICI) to predict PPI essentiality by combining gene
knockdown studies with network models of protein interaction pathways in an
analytic framework. Our method uses network topology to model how gene silencing 
can disrupt PPIs, relating the unknown essentialities of individual PPIs to
experimentally observed protein essentialities. This model is then deconvolved to
recover the unknown essentialities of individual PPIs. We demonstrate the
validity of our approach via prediction of sensitivities to compounds based on
PPI essentiality and differences in essentiality based on genetic mutations. We
further show that lung cancer patients have improved overall survival when
specific PPIs are no longer present, suggesting that these PPIs may be
potentially new targets for therapeutic development. Software is freely available
at https://github.com/cooperlab/MEDICI. Datasets are available at
https://ctd2.nci.nih.gov/dataPortal.

DOI: 10.1371/journal.pone.0170339 
PMID: 28118365  [PubMed - in process]


17. Biostatistics. 2017 Jan 23. pii: kxw057. doi: 10.1093/biostatistics/kxw057. [Epub
ahead of print]

Discriminating sample groups with multi-way data.

Lyu T(1), Lock EF(1), Eberly LE(1).

Author information: 
(1)Division of Biostatistics, School of Public Health, University of Minnesota,
Minneapolis, MN 55455, USA.

High-dimensional linear classifiers, such as distance weighted discrimination
(DWD) and versions of the support vector machine (SVM), are commonly used in
biomedical research to distinguish groups of subjects based on a large number of 
features. However, their use is limited to applications where a single vector of 
features is measured for each subject. In practice, data are often multi-way, or 
measured over multiple dimensions. For example, metabolite abundance may be
measured over multiple regions or tissues, or gene expression may be measured
over multiple time points, for the same subjects. We propose a framework for
linear classification of high-dimensional multi-way data, in which coefficients
can be factorized into weights that are specific to each dimension. More
generally, the coefficients for each measurement in a multi-way dataset are
assumed to have low-rank structure. This framework extends existing
classification techniques from single vector to multi-way features, and we have
implemented multi-way versions of SVM and DWD. We describe informative simulation
results, and apply multi-way DWD to data for two very different clinical research
studies. The first study uses magnetic resonance spectroscopy metabolite data
over multiple brain regions to compare participants with and without
spinocerebellar ataxia; the second uses publicly available gene expression
time-course data to compare degrees of treatment response among patients with
multiple sclerosis. Our multi-way method can improve performance and simplify
interpretation over naive applications of full rank linear and non-linear
classification to multi-way data. The R package is available at
https://github.com/lockEF/MultiwayClassification.

© The Author 2017. Published by Oxford University Press. All rights reserved. For
permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/biostatistics/kxw057 
PMID: 28115314  [PubMed - as supplied by publisher]


18. IEEE Trans Image Process. 2016 Nov 14. doi: 10.1109/TIP.2016.2628583. [Epub ahead
of print]

Learning to Detect Video Saliency with HEVC Features.

Xu M, Jiang L, Sun X, Ye Z, Wang Z.

Saliency detection has been widely studied to predict human fixations, with
various applications in computer vision and image processing. For saliency
detection, we argue in this paper that the state-of-the-art high efficiency video
coding (HEVC) standard can be used to generate the useful features in compressed 
domain. Therefore, this paper proposes to learn the video saliency model, with
regard to HEVC features. First, we establish an eye tracking database for video
saliency detection, which can be downloaded from https://github.com/remega/video 
database. Through the statistical analysis on our eye tracking database, we find 
out that human fixations tend to fall into the regions with large-valued HEVC
features on splitting depth, bit allocation, and motion vector (MV). In addition,
three observations are obtained with the further analysis on our eye tracking
database. Accordingly, several features in HEVC domain are proposed on the basis 
of splitting depth, bit allocation, and MV. Next, a kind of support vector
machine (SVM) is learned to integrate those HEVC features together, for video
saliency detection. Since almost all video data are stored in the compressed
form, our method is able to avoid both the computational cost on decoding and the
storage cost on raw data. More importantly, experimental results show that the
proposed method is superior to other stateof- the-art saliency detection methods,
either in compressed or uncompressed domain.

DOI: 10.1109/TIP.2016.2628583 
PMID: 28113934  [PubMed - as supplied by publisher]


19. IEEE/ACM Trans Comput Biol Bioinform. 2016 May 10. doi:
10.1109/TCBB.2016.2565475. [Epub ahead of print]

Normalizing kernels in the Billera-Holmes-Vogtmann treespace.

Weyenberg G, Yoshida R, Howe D.

As costs of genome sequencing have dropped precipitously, development of
efficient bioinformatic methods to analyze genome structure and evolution have
become ever more urgent. For example, most published phylogenomic studies involve
either massive concatenation of sequences, or informal comparisons of phylogenies
inferred on a small subset of orthologous genes, neither of which provides a
comprehensive overview of evolution or systematic identification of genes with
unusual and interesting evolution (e.g. horizontal gene transfers, gene
duplication and subsequent neofunctionalization). We are interested in
identifying such "outlying" gene trees from the set of gene trees and estimating 
the distribution of trees over the "tree space". This paper describes an
improvement to the KDETREES algorithm, an adaptation of classical kernel density 
estimation to the metric space of phylogenetic trees (Billera-Holmes-Vogtman
treespace), whereby the kernel normalizing constants, are estimated through the
use of the novel holonomic gradient methods. As in the original kdetrees paper,
we have applied kdetrees to a set of Apicomplexa genes. The analysis identified
several unreliable sequence alignments that had escaped previous detection, as
well as a gene independently reported as a possible case of horizontal gene
transfer. The updated version of the KDETREES software package is available both 
from CRAN (the official R package system), as well as from the official
development repository on Github. (github.com/grady/kdetrees).

DOI: 10.1109/TCBB.2016.2565475 
PMID: 28113725  [PubMed - as supplied by publisher]


20. IEEE/ACM Trans Comput Biol Bioinform. 2016 Oct 13. doi:
10.1109/TCBB.2016.2606620. [Epub ahead of print]

Complexity and algorithms for finding a perfect phylogeny from mixed tumor
samples.

Hujdurovic A, Kacar U, Milanic M, Ries B, Tomescu AI.

Recently, Hajirasouliha and Raphael (WABI 2014) proposed a model for
deconvoluting mixed tumor samples measured from a collection of high-throughput
sequencing reads. This is related to understanding tumor evolution and critical
cancer mutations. In short, their formulation asks to split each row of a binary 
matrix so that the resulting matrix corresponds to a perfect phylogeny and has
the minimum number of rows among all matrices with this property. In this paper
we disprove several claims about this problem, including an NP-hardness proof of 
it. However, we show that the problem is indeed NP-hard, by providing a different
proof. We also prove NP-completeness of a variant of this problem proposed in the
same paper. On the positive side, we propose an efficient (though not necessarily
optimal) heuristic algorithm based on coloring co-comparability graphs, and a
polynomial time algorithm for solving the problem optimally on matrix instances
in which no column is contained in both columns of a pair of conflicting columns.
Implementations of these algorithms are freely available at
https://github.com/alexandrutomescu/MixedPerfectPhylogeny.

DOI: 10.1109/TCBB.2016.2606620 
PMID: 28113405  [PubMed - as supplied by publisher]


21. Version 2. F1000Res. 2016 Sep 20 [revised 2017 Jan 9];5:2348. doi:
10.12688/f1000research.9618.2. eCollection 2016.

biojs-io-biom, a BioJS component for handling data in Biological Observation
Matrix (BIOM) format.

Ankenbrand MJ(1), Terhoeven N(2), Hohlfeld S(1), Förster F(3), Keller A(1).

Author information: 
(1)Department of Animal Ecology and Tropical Biology (Zoology III), University of
Würzburg, Würzburg, Germany. (2)Department of Plant Physiology and Biophysics
(Botany I), University of Würzburg, Würzburg, Germany; Center for Computational
and Theoretical Biology (CCTB), University of Würzburg, Würzburg, Germany.
(3)Center for Computational and Theoretical Biology (CCTB), University of
Würzburg, Würzburg, Germany; Department of Bioinformatics, University of
Würzburg, Würzburg, Germany.

The Biological Observation Matrix (BIOM) format is widely used to store data from
high-throughput studies. It aims at increasing interoperability of bioinformatic 
tools that process this data. However, due to multiple versions and
implementation details, working with this format can be tricky. Currently,
libraries in Python, R and Perl are available, whilst such for JavaScript are
lacking. Here, we present a BioJS component for parsing BIOM data in all format
versions. It supports import, modification, and export via a unified interface.
This module aims to facilitate the development of web applications that use BIOM 
data. Finally, we demonstrate its usefulness by two applications that already use
this component. Availability: https://github.com/molbiodiv/biojs-io-biom,
https://dx.doi.org/10.5281/zenodo.218277.

DOI: 10.12688/f1000research.9618.2 
PMCID: PMC5224677
PMID: 28105307  [PubMed - in process]


22. Bioinformatics. 2017 Jan 20. pii: btw821. doi: 10.1093/bioinformatics/btw821.
[Epub ahead of print]

Biomartr: genomic data retrieval with R.

Drost HG(1), Paszkowski J(1).

Author information: 
(1)The Sainsbury Laboratory, University of Cambridge, Cambridge, United Kingdom.

MOTIVATION: Retrieval and reproducible functional annotation of genomic data are 
crucial in biology. However, the current poor usability and transparency of
retrieval methods hinders reproducibility. Here we present an open source R
package, biomartr, which provides a comprehensive easy-to-use framework for
automating data retrieval and functional annotation for meta-genomic approaches. 
The functions of biomartr achieve a high degree of clarity, transparency and
reproducibility of analyses.
RESULTS: The biomartr package implements straightforward functions for bulk
retrieval of all genomic data or data for selected genomes, proteomes, coding
sequences and annotation files present in databases hosted by the National Center
for Biotechnology Information (NCBI) and European Bioinformatics Institute
(EMBL-EBI). In addition, biomartr communicates with the BioMart database for
functional annotation of retrieved sequences. Comprehensive documentation of
biomartr functions and five tutorial vignettes provide step-by-step instructions 
on how to use the package in a reproducible manner.
AVAILABILITY AND IMPLEMENTATION: The open source biomartr package is available at
https://github.com/HajkD/biomartr and
https://cran.r-project.org/web/packages/biomartr/index.html CONTACT:
hgd23@cam.ac.ukSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2017. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw821 
PMID: 28110292  [PubMed - as supplied by publisher]


23. Bioinformatics. 2017 Jan 19. pii: btx022. doi: 10.1093/bioinformatics/btx022.
[Epub ahead of print]

NetLand: quantitative modeling and visualization of Waddington's epigenetic
landscape using probabilistic potential.

Guo J(1,)(2), Lin F(1), Zhang X(1), Tanavde V(2), Zheng J(3,)(4,)(5).

Author information: 
(1)Biomedical Informatics Lab, School of Computer Science and Engineering,
Nanyang Technological University, Singapore 639798, Singapore. (2)Bioinformatics 
Institute, Agency for Science, Technology, and Research (A*STAR), Singapore
138671, Singapore. (3)Biomedical Informatics Lab, School of Computer Science and 
Engineering, Nanyang Technological University, Singapore 639798, Singapore,
zhengjie@ntu.edu.sg. (4)Genome Institute of Singapore, A*STAR, Singapore 138672, 
Singapore and. (5)Complexity Institute, Nanyang Technological University,
Singapore 637723, Singapore.

Waddington's epigenetic landscape is a powerful metaphor for cellular dynamics
driven by gene regulatory networks. Its quantitative modeling and visualization, 
however, remains a challenge, especially when there are more than two genes in
the network. A software tool for Waddington's landscape has not been available in
the literature. We present NetLand, an open-source software tool for modeling and
simulating the kinetic dynamics of gene regulatory networks (GRNs), and
visualizing the corresponding Waddington's epigenetic landscape in three
dimensions without restriction on the number of genes in a GRN. With an
interactive and graphical user interface, NetLand can facilitate the knowledge
discovery and experimental design in the study of cell fate regulation (e.g. stem
cell differentiation and reprogramming).AVAILABILITY: NetLand can run under
operating systems including Windows, Linux and OS X. The executive files and
source code of NetLand as well as a user manual and example models, etc. can be
downloaded from http://netland-ntu.github.io/NetLand/ CONTACT:
zhengjie@ntu.edu.sg.

© The Author(s) 2017. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btx022 
PMID: 28108450  [PubMed - as supplied by publisher]


24. Bioinformatics. 2017 Jan 19. pii: btx026. doi: 10.1093/bioinformatics/btx026.
[Epub ahead of print]

Quantification of fibrous spatial point patterns from single-molecule
localization microscopy (SMLM) data.

Peters R(1), Benthem Muñiz M(1), Griffié J(1), Williamson DJ(1), Ashdown GW(1),
Lorenz CD(1), Owen DM(2).

Author information: 
(1)Department of Physics and Randall Division of Cell and Molecular Biophysics.
(2)Department of Physics and Randall Division of Cell and Molecular Biophysics.
dylan.owen@kcl.ac.uk.

MOTIVATION: Unlike conventional microscopy which produces pixelated images, SMLM 
produces data in the form of a list of localization coordinates - a spatial point
pattern (SPP). Often, such SPPs are analyzed using cluster analysis algorithms to
quantify molecular clustering within, for example, the plasma membrane. While
SMLM cluster analysis is now well developed, techniques for analyzing fibrous
structures remain poorly explored.
RESULTS: Here, we demonstrate statistical methodology, based on Ripley's
K-function to quantitatively assess fibrous structures in 2D SMLM data sets.
Using simulated data, we present the underlying theory to describe fiber spatial 
arrangements and show how these descriptions can be quantitatively derived from
pointillist data sets. We also demonstrate the techniques on experimental data
acquired using the image reconstruction by integrating exchangeable
single-molecule localization (IRIS) approach to SMLM, in the context of the
fibrous actin meshwork at the T cell immunological synapse, whose structure has
been shown to be important for T cell activation.
AVAILABILITY: Freely available on the web at
https://github.com/RubyPeters/Angular-Ripleys-K Implemented in MatLab.
CONTACT: dylan.owen@kcl.ac.uk SUPPLEMENTARY INFORMATION: Supplementary data are
available at Bioinformatics online.

© The Author (2017). Published by Oxford University Press. All rights reserved.
For Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btx026 
PMID: 28108449  [PubMed - as supplied by publisher]


25. Bioinformatics. 2017 Jan 19. pii: btx023. doi: 10.1093/bioinformatics/btx023.
[Epub ahead of print]

aRNApipe: A balanced, efficient and distributed pipeline for processing RNA-seq
data in high performance computing environments.

Alonso A(1,)(2), Lasseigne BN(1), Williams K(1), Nielsen J(1), Ramaker RC(1,)(3),
Hardigan AA(1,)(3), Johnston B(1), Roberts BS(1), Cooper SJ(1), Marsal S(2),
Myers RM(4).

Author information: 
(1)HudsonAlpha Institute for Biotechnology, Huntsville, AL 35806, USA.
(2)Rheumatology Research Group, Vall d'Hebron Hospital Research Institute,
Barcelona, Spain. (3)Department of Genetics, The University of Alabama at
Birmingham, Birmingham, AL 35294, USA. (4)HudsonAlpha Institute for
Biotechnology, Huntsville, AL 35806, USA. rmyers@hudsonalpha.org.

The wide range of RNA-seq applications and their high computational needs require
the development of pipelines orchestrating the entire workflow and optimizing
usage of available computational resources. We present aRNApipe, a
project-oriented pipeline for processing of RNA-seq data in high performance
cluster environments. aRNApipe is highly modular and can be easily migrated to
any high performance computing (HPC) environment. The current applications
included in aRNApipe combine the essential RNA-seq primary analyses, including
quality control metrics, transcript alignment, count generation, transcript
fusion identification, alternative splicing, and sequence variant calling.
aRNApipe is project-oriented and dynamic so users can easily update analyses to
include or exclude samples or enable additional processing modules. Workflow
parameters are easily set using a single configuration file that provides
centralized tracking of all analytical processes. Finally, aRNApipe incorporates 
interactive web reports for sample tracking and a tool for managing the genome
assemblies available to perform an analysis.Availability and documentation:
https://github.com/HudsonAlpha/aRNAPipe; DOI: 10.5281/zenodo.202950 CONTACT:
rmyers@hudsonalpha.org SUPPLEMENTARY INFORMATION: Supplementary data are
available at Bioinformatics online.

© The Author(s) 2017. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btx023 
PMID: 28108448  [PubMed - as supplied by publisher]


26. Bioinformatics. 2017 Jan 19. pii: btx024. doi: 10.1093/bioinformatics/btx024.
[Epub ahead of print]

chainCleaner improves genome alignment specificity and sensitivity.

Suarez HG(1,)(2), Langer BE(1,)(2), Ladde P(1,)(2), Hiller M(3,)(2).

Author information: 
(1)Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany.
(2)Max Planck Institute for the Physics of Complex Systems, Dresden, Germany.
(3)Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany;
hiller@mpi-cbg.de.

MOTIVATION: Accurate alignments between entire genomes are crucial for
comparative genomics. However, computing sensitive and accurate genome alignments
is a challenging problem, complicated by genomic rearrangements.
RESULTS: Here we present a fast approach, called chainCleaner, that improves the 
specificity in genome alignments by accurately detecting and removing local
alignments that obscure the evolutionary history of genomic rearrangements.
Systematic tests on alignments between the human and other vertebrate genomes
show that chainCleaner (i) improves the alignment of numerous orthologous genes, 
(ii) exposes alignments between exons of orthologous genes that were masked
before by alignments to pseudogenes, and (iii) recovers hundreds of kilobases in 
local alignments that otherwise would fall below a minimum score threshold. Our
approach has broad applicability to improve the sensitivity and specificity of
genome alignments.
AVAILABILITY: http://bds.mpi-cbg.de/hillerlab/chainCleaner/ or
https://github.com/ucscGenomeBrowser/kent SUPPLEMENTARY INFORMATION:
Supplementary data are available at Bioinformatics online.

© The Author (2017). Published by Oxford University Press. All rights reserved.
For Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btx024 
PMID: 28108446  [PubMed - as supplied by publisher]


27. Bioinformatics. 2017 Jan 19. pii: btx025. doi: 10.1093/bioinformatics/btx025.
[Epub ahead of print]

Multi-rate Poisson Tree Processes for single-locus species delimitation under
Maximum Likelihood and Markov Chain Monte Carlo.

Kapli P(1), Lutteropp S(2,)(3), Zhang J(2), Kobert K(2), Pavlidis P(4),
Stamatakis A(1,)(3), Flouri T(1,)(3).

Author information: 
(1)The Exelixis Lab, Scientific Computing Group, Heidelberg Institute for
Theoretical Studies, Schloss-Wolfsbrunnenweg 35, D-68159 Heidelberg, Germany,
Tomas.Flouri@h-its.org. (2)The Exelixis Lab, Scientific Computing Group,
Heidelberg Institute for Theoretical Studies, Schloss-Wolfsbrunnenweg 35, D-68159
Heidelberg, Germany. (3)Department of Informatics, Institute of Theoretical
Informatics, Karlsruhe Institute of Technology, 76128 Karlsruhe, Germany.
(4)Foundation for Research and Technology - Hellas Institute of Computer Science 
GR - 711 10, Heraklion, Crete, Greece.

MOTIVATION: In recent years, molecular species delimitation has become a routine 
approach for quantifying and classifying biodiversity. Barcoding methods are of
particular importance in large-scale surveys as they promote fast species
discovery and biodiversity estimates. Among those, distance-based methods are the
most common choice as they scale well with large datasets; however, they are
sensitive to similarity threshold parameters and they ignore evolutionary
relationships. The recently introduced "Poisson Tree Processes" (PTP) method is a
phylogeny-aware approach that does not rely on such thresholds. Yet, two
weaknesses of PTP impact its accuracy and practicality when applied to large
datasets; it does not account for divergent intraspecific variation and is slow
for a large number of sequences.
RESULTS: We introduce the multi-rate PTP (mPTP), an improved method that
alleviates the theoretical and technical shortcomings of PTP. It incorporates
different levels of intraspecific genetic diversity deriving from differences in 
either the evolutionary history or sampling of each species. Results on empirical
data suggest that mPTP is superior to PTP and popular distance-based methods as
it, consistently yields more accurate delimitations with respect to the taxonomy 
(i.e., identifies more taxonomic species, infers species numbers closer to the
taxonomy). Moreover, mPTP does not require any similarity threshold as input. The
novel dynamic programming algorithm attains a speedup of at least five orders of 
magnitude compared to PTP, allowing it to delimit species in large (meta-)
barcoding data. In addition, Markov Chain Monte Carlo sampling provides a
comprehensive evaluation of the inferred delimitation in just a few seconds for
millions of steps, independently of tree size.
AVAILABILITY: mPTP is implemented in C and is available for download at
http://github.com/Pas-Kapli/mptp under the GNU Affero 3 license. A web-service is
available at http://mptp.h-its.org CONTACT: Paschalia.Kapli@h-its.org,
Alexandros.Stamatakis@h-its.org, Tomas.Flouri@h-its.org.

© The Author(s) 2017. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btx025 
PMID: 28108445  [PubMed - as supplied by publisher]


28. Bioinformatics. 2017 Jan 18. pii: btw791. doi: 10.1093/bioinformatics/btw791.
[Epub ahead of print]

Historian: accurate reconstruction of ancestral sequences and evolutionary rates.

Holmes IH(1).

Author information: 
(1)Department of Bioengineering, University of California, Berkeley, CA 94720,
USA.

MOTIVATION: Reconstruction of ancestral sequence histories, and estimation of
parameters like indel rates, are improved by using explicit evolutionary models
and summing over uncertain alignments. The previous best tool for this purpose
(according to simulation benchmarks) was ProtPal, but this tool was too slow for 
practical use.
RESULTS: Historian combines an efficient reimplementation of the ProtPal
algorithm with performance-improving heuristics from other alignment tools.
Simulation results on fidelity of rate estimation via ancestral reconstruction,
along with evaluations on the structurally informed alignment dataset BAliBase
3.0, recommend Historian over other alignment tools for evolutionary
applications.
AVAILABILITY AND IMPLEMENTATION: Historian is available at
https://github.com/evoldoers/historian under the Creative Commons Attribution
3.0 US license.
CONTACT: ihholmes.historian@gmail.com.

© The Author 2017. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw791 
PMID: 28104629  [PubMed - as supplied by publisher]


29. Bioinformatics. 2017 Jan 18. pii: btx014. doi: 10.1093/bioinformatics/btx014.
[Epub ahead of print]

MAPPI-DAT: data management and analysis for protein-protein interaction data from
the high-throughput MAPPIT cell microarray platform.

Gupta S(1,)(2,)(3), De Puysseleyr V(1,)(2), Van der Heyden J(1,)(2), Maddelein
D(1,)(2,)(3), Lemmens I(1,)(2), Lievens S(1,)(2,)(4), Degroeve S(1,)(2,)(3),
Tavernier J(5,)(2), Martens L(5,)(2,)(3).

Author information: 
(1)Medical Biotechnology Center, VIB, Ghent, Belgium. (2)Department of
Biochemistry, Ghent University, Ghent, Belgium. (3)Bioinformatics Institute
Ghent, Ghent University, Ghent, Belgium. (4)Current address: Orionis Biosciences,
Ghent, Belgium. (5)Medical Biotechnology Center, VIB, Ghent, Belgium
lennart.martens@UGent.be.

Protein-protein interaction (PPI) studies have dramatically expanded our
knowledge about cellular behaviour and development in different conditions. A
multitude of high-throughput PPI techniques have been developed to achieve
proteome-scale coverage for PPI studies, including the microarray based Mammalian
Protein-Protein Interaction Trap (MAPPIT) system. Because such high-throughput
techniques typically report thousands of interactions, managing and analysing the
large amounts of acquired data is a challenge. We have therefore built the MAPPIT
cell microArray Protein Protein Interaction- Data management & Analysis Tool
(MAPPI-DAT) as an automated data management and analysis tool for MAPPIT cell
microarray experiments. MAPPI-DAT stores the experimental data and metadata in a 
systematic and structured way, automates data analysis and interpretation, and
enables the meta-analysis of MAPPIT cell microarray data across all stored
experiments.IMPLEMENTATION: MAPPI-DAT is developed in Python, using R for data
analysis and MySQL as data management system. MAPPI-DAT is cross-platform and can
be ran on Microsoft Windows, Linux and OS X/macOS. The source code and a
Microsoft Windows executable are freely available under the permissive Apache2
open source license at https://github.com/compomics/MAPPI-DAT CONTACT:
jan.tavernier@vib-ugent.be, lennart.martens@vib-ugent.beSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author(s) 2017. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btx014 
PMID: 28104627  [PubMed - as supplied by publisher]


30. Microbiome. 2017 Jan 19;5(1):7. doi: 10.1186/s40168-016-0219-5.

A fast and robust protocol for metataxonomic analysis using RNAseq data.

Cox JW(1,)(2), Ballweg RA(2), Taft DH(2), Velayutham P(3), Haslam DB(4), Porollo 
A(5,)(6).

Author information: 
(1)Department of Electrical Engineering and Computing Systems, University of
Cincinnati, 2901 Woodside Drive, Cincinnati, OH, 45221, USA. (2)The Center for
Autoimmune Genomics and Etiology, Cincinnati Children's Hospital Medical Center, 
3333 Burnet Avenue, MLC 15012, Cincinnati, OH, 45229-3039, USA. (3)Division of
Biomedical Informatics, Cincinnati Children's Hospital Medical Center, 3333
Burnet Avenue, Cincinnati, OH, 45229, USA. (4)Division of Infectious Diseases,
Cincinnati Children's Hospital Medical Center, 3333 Burnet Avenue, Cincinnati,
OH, 45229, USA. (5)The Center for Autoimmune Genomics and Etiology, Cincinnati
Children's Hospital Medical Center, 3333 Burnet Avenue, MLC 15012, Cincinnati,
OH, 45229-3039, USA. Alexey.Porollo@cchmc.org. (6)Division of Biomedical
Informatics, Cincinnati Children's Hospital Medical Center, 3333 Burnet Avenue,
Cincinnati, OH, 45229, USA. Alexey.Porollo@cchmc.org.

BACKGROUND: Metagenomics is a rapidly emerging field aimed to analyze microbial
diversity and dynamics by studying the genomic content of the microbiota.
Metataxonomics tools analyze high-throughput sequencing data, primarily from 16S 
rRNA gene sequencing and DNAseq, to identify microorganisms and viruses within a 
complex mixture. With the growing demand for analysis of the functional
microbiome, metatranscriptome studies attract more interest. To make
metatranscriptomic data sufficient for metataxonomics, new analytical workflows
are needed to deal with sparse and taxonomically less informative sequencing
data.
RESULTS: We present a new protocol, IMSA+A, for accurate taxonomy classification 
based on metatranscriptome data of any read length that can efficiently and
robustly identify bacteria, fungi, and viruses in the same sample. The new
protocol improves accuracy by using a conservative reference database, employing 
a new counting scheme, and by assembling shotgun reads. Assembly also reduces
analysis runtime. Simulated data were utilized to evaluate the protocol by
permuting common experimental variables. When applied to the real
metatranscriptome data for mouse intestines colonized by ASF, the protocol showed
superior performance in detection of the microorganisms compared to the existing 
metataxonomics tools. IMSA+A is available at
https://github.com/JeremyCoxBMI/IMSA-A .
CONCLUSIONS: The developed protocol addresses the need for taxonomy
classification from RNAseq data. Previously not utilized, i.e., unmapped to a
reference genome, RNAseq reads can now be used to gather taxonomic information
about the microbiota present in a biological sample without conducting additional
sequencing. Any metatranscriptome pipeline that includes assembly of reads can
add this analysis with minimal additional cost of compute time. The new protocol 
also creates an opportunity to revisit old metatranscriptome data, where
taxonomic content may be important but was not analyzed.

DOI: 10.1186/s40168-016-0219-5 
PMCID: PMC5244565
PMID: 28103917  [PubMed - in process]


31. PLoS Comput Biol. 2017 Jan 19;13(1):e1005340. doi: 10.1371/journal.pcbi.1005340. 
[Epub ahead of print]

Contextual Refinement of Regulatory Targets Reveals Effects on Breast Cancer
Prognosis of the Regulome.

Andrews E(1,)(2), Wang Y(1,)(3), Xia T(3), Cheng W(3), Cheng C(1,)(2,)(4).

Author information: 
(1)Department of Genetics, Geisel School of Medicine at Dartmouth, Hanover, New
Hampshire, United States of America. (2)Institute for Quantitative Biomedical
Sciences, Geisel School of Medicine at Dartmouth, Lebanon, New Hampshire, United 
States of America. (3)School of Electronic Information and Communications,
Huazhong University of Science and Technology, Wuhan, Hubei, China. (4)Norris
Cotton Cancer Center, Geisel School of Medicine at Dartmouth, Lebanon, New
Hampshire, United States of America.

Gene expression regulators, such as transcription factors (TFs) and microRNAs
(miRNAs), have varying regulatory targets based on the tissue and physiological
state (context) within which they are expressed. While the emergence of
regulator-characterizing experiments has inferred the target genes of many
regulators across many contexts, methods for transferring regulator target genes 
across contexts are lacking. Further, regulator target gene lists frequently are 
not curated or have permissive inclusion criteria, impairing their use. Here, we 
present a method called iterative Contextual Transcriptional Activity Inference
of Regulators (icTAIR) to resolve these issues. icTAIR takes a regulator's
previously-identified target gene list and combines it with gene expression data 
from a context, quantifying that regulator's activity for that context. It then
calculates the correlation between each listed target gene's expression and the
quantitative score of regulatory activity, removes the uncorrelated genes from
the list, and iterates the process until it derives a stable list of refined
target genes. To validate and demonstrate icTAIR's power, we use it to refine the
MSigDB c3 database of TF, miRNA and unclassified motif target gene lists for
breast cancer. We then use its output for survival analysis with
clinicopathological multivariable adjustment in 7 independent breast cancer
datasets covering 3,430 patients. We uncover many novel prognostic regulators
that were obscured prior to refinement, in particular NFY, and offer a detailed
look at the composition and relationships among the breast cancer prognostic
regulome. We anticipate icTAIR will be of general use in contextually refining
regulator target genes for discoveries across many contexts. The icTAIR algorithm
can be downloaded from https://github.com/icTAIR.

DOI: 10.1371/journal.pcbi.1005340 
PMID: 28103241  [PubMed - as supplied by publisher]


32. Mol Biol Evol. 2017 Jan 18. pii: msw075. doi: 10.1093/molbev/msw275. [Epub ahead 
of print]

Genomic infectious disease epidemiology in partially sampled and ongoing
outbreaks.

Didelot X(1), Fraser C(1,)(2), Gardy J(3,)(4), Colijn C(5).

Author information: 
(1)1 Department of Infectious Disease Epidemiology, Imperial 4 College London,
Norfolk Place, London, W2 1PG, United Kingdom. (2)2 Oxford Big Data Institute, Li
Ka Shing Centre for Health Information and Discovery, Nuffield Department of
Medicine, University of Oxford, Oxford OX3 7BN, United Kingdom. (3)3 Communicable
Disease Prevention and Control Services, British Columbia Centre for Disease
Control, Vancouver, British Columbia, Canada. (4)4 School of Population and
Public Health, University of British Columbia, Vancouver, British, Columbia,
Canada. (5)5 Department of Mathematics, Imperial College, London SW7 2AZ, UK.

Genomic data is increasingly being used to understand infectious disease
epidemiology. Isolates from a given outbreak are sequenced, and the patterns of
shared variation are used to infer which isolates within the outbreak are most
closely related to each other. Unfortunately, the phylogenetic trees typically
used to represent this variation are not directly informative about who infected 
whom - a phylogenetic tree is not a transmission tree. However, a transmission
tree can be inferred from a phylogeny while accounting for within-host genetic
diversity by colouring the branches of a phylogeny according to which host those 
branches were in. Here we extend this approach and show that it can be applied to
partially sampled and ongoing outbreaks. This requires computing the correct
probability of an observed transmission tree and we herein demonstrate how to do 
this for a large class of epidemiological models. We also demonstrate how the
branch colouring approach can incorporate a variable number of unique colours to 
represent unsampled intermediates in transmission chains. The resulting algorithm
is a reversible jump Monte-Carlo Markov Chain, which we apply to both simulated
data and real data from an outbreak of tuberculosis. By accounting for unsampled 
cases and an outbreak which may not have reached its end, our method is uniquely 
suited to use in a public health environment during real-time outbreak
investigations. We implemented this transmission tree inference methodology in an
R package called TransPhylo, which is freely available from
https://github.com/xavierdidelot/TransPhylo.

© The Author 2017. Published by Oxford University Press on behalf of the Society 
for Molecular Biology and Evolution. All rights reserved. For permissions, please
e-mail: journals.permissions@oup.com.

DOI: 10.1093/molbev/msw275 
PMID: 28100788  [PubMed - as supplied by publisher]


33. Nucleic Acids Res. 2017 Jan 18. pii: gkw1358. doi: 10.1093/nar/gkw1358. [Epub
ahead of print]

PBrowse: a web-based platform for real-time collaborative exploration of genomic 
data.

Szot PS(1,)(2), Yang A(1,)(3), Wang X(1,)(3), Parsania C(4), Röhm U(2), Wong
KH(4), Ho JW(5,)(3).

Author information: 
(1)Victor Chang Cardiac Research Institute, Darlinghurst, NSW 2010, Australia.
(2)School of Information Technologies, University of Sydney, NSW 2006, Australia.
(3)St. Vincent's Clinical School, University of New South Wales, Darlinghurst,
NSW 2010, Australia. (4)Faculty of Health Sciences, University of Macau, Macau
SAR, China. (5)Victor Chang Cardiac Research Institute, Darlinghurst, NSW 2010,
Australia j.ho@victorchang.edu.au.

Genome browsers are widely used for individually exploring various types of
genomic data. A handful of genome browsers offer limited tools for collaboration 
among multiple users. Here, we describe PBrowse, an integrated real-time
collaborative genome browser that enables multiple users to simultaneously view
and access genomic data, thereby harnessing the wisdom of the crowd. PBrowse is
based on the Dalliance genome browser and has a re-designed user and data
management system with novel collaborative functionalities, including real-time
collaborative view, track comment and an integrated group chat feature. Through
the Distributed Annotation Server protocol, PBrowse can easily access a wide
range of publicly available genomic data, such as the ENCODE data sets. We argue 
that PBrowse represents a paradigm shift from using a genome browser as a static 
data visualization tool to a platform that enables real-time human-human
interaction and knowledge exchange in a collaborative setting. PBrowse is
available at http://pbrowse.victorchang.edu.au, and its source code is available 
via an open source BSD 3 license at http://github.com/VCCRI/PBrowse.

© The Author(s) 2017. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkw1358 
PMID: 28100700  [PubMed - as supplied by publisher]


34. Plant Cell Physiol. 2017 Jan 18. pii: pcw201. doi: 10.1093/pcp/pcw201. [Epub
ahead of print]

MarpoDB: An open registry for Marchantia polymorpha genetic parts.

Delmans M(1), Pollak B(1), Haseloff J(1).

Author information: 
(1)Department of Plant Sciences, University of Cambridge, Downing Street,
Cambridge, CB2 3EA, United Kingdom.

Marchantia polymorpha is an extant relative of the earliest terrestrial plants
and has attracted a substantial interest as a model organism for evolutionary and
developmental studies. Given its relatively simple genome, compact gene families,
simple morphology, ease of propagation and transformation, M. polymorpha is
becoming a promising platform for plant synthetic biology. Modular genetic parts 
have been essential for development of synthetic biology approaches, so we sought
to design an engineering oriented database for M. polymorpha genetic parts where 
each gene is a stand-alone functional unit. MarpoDB is a database of M.
polymorpha genes and genetic parts, which is tailored to become an integral tool 
for a synthetic biology workflow. Among its features are precompiled
cross-database querying to InterPro, Pfam signatures and non redundant
Viridiplantae BLAST annotations; BLAST querying to M. polymorpha genes; sequence 
export in GenBank format; recoding of sequences to the common syntax for type IIS
assembly and exchange of DNA parts; and a minimalistic, intuitive and interactive
user interface for gene models and sequence exploration. Furthermore, we have
implemented user input to encourage feedback, collaboration and exchange between 
the MarpoDB community. MarpoDB source-code is released on GitHub to promote
development of computational tools for synthetic biology.

© The Author(s) 2017. Published by Oxford University Press on behalf of Japanese 
Society of Plant Physiologists.

DOI: 10.1093/pcp/pcw201 
PMID: 28100647  [PubMed - as supplied by publisher]


35. Biometrics. 2017 Jan 18. doi: 10.1111/biom.12640. [Epub ahead of print]

BayesCAT: Bayesian co-estimation of alignment and tree.

Shim H(1), Larget B(2).

Author information: 
(1)Department of Statistics, Purdue University, West Lafayette, Indiana, U.S.A.
(2)Departments of Statistics and of Botany, University of Wisconsin, Madison,
Wisconsin, U.S.A.

Traditionally, phylogeny and sequence alignment are estimated separately: first
estimate a multiple sequence alignment and then infer a phylogeny based on the
sequence alignment estimated in the previous step. However, uncertainty in the
alignment is ignored, resulting, possibly, in overstated certainty in phylogeny
estimates. We develop a joint model for co-estimating phylogeny and sequence
alignment which improves estimates from the traditional approach by accounting
for uncertainty in the alignment in phylogenetic inferences. Our insertion and
deletion (indel) model allows arbitrary-length overlapping indel events and a
general distribution for indel fragment size. We employ a Bayesian approach using
MCMC to estimate the joint posterior distribution of a phylogenetic tree and a
multiple sequence alignment. Our approach has a tree and a complete history of
indel events mapped onto the tree as the state space of the Markov Chain while
alternative previous approaches have a tree and an alignment. A large state space
containing a complete history of indel events makes our MCMC approach more
challenging, but it enables us to infer more information about the indel process.
The performances of this joint method and traditional sequential methods are
compared using simulated data as well as real data. Software named BayesCAT
(Bayesian Co-estimation of Alignment and Tree) is available at
https://github.com/heejungshim/BayesCAT.

© 2017, The International Biometric Society.

DOI: 10.1111/biom.12640 
PMID: 28099991  [PubMed - as supplied by publisher]


36. PeerJ. 2017 Jan 11;5:e2836. doi: 10.7717/peerj.2836. eCollection 2017.

Rhea: a transparent and modular R pipeline for microbial profiling based on 16S
rRNA gene amplicons.

Lagkouvardos I(1), Fischer S(1), Kumar N(1), Clavel T(1).

Author information: 
(1)ZIEL-Core Facility Microbiome/NGS, Technical University of Munich , Freising ,
Germany.

The importance of 16S rRNA gene amplicon profiles for understanding the influence
of microbes in a variety of environments coupled with the steep reduction in
sequencing costs led to a surge of microbial sequencing projects. The expanding
crowd of scientists and clinicians wanting to make use of sequencing datasets can
choose among a range of multipurpose software platforms, the use of which can be 
intimidating for non-expert users. Among available pipeline options for
high-throughput 16S rRNA gene analysis, the R programming language and software
environment for statistical computing stands out for its power and increased
flexibility, and the possibility to adhere to most recent best practices and to
adjust to individual project needs. Here we present the Rhea pipeline, a set of R
scripts that encode a series of well-documented choices for the downstream
analysis of Operational Taxonomic Units (OTUs) tables, including normalization
steps, alpha- and beta-diversity analysis, taxonomic composition, statistical
comparisons, and calculation of correlations. Rhea is primarily a straightforward
starting point for beginners, but can also be a framework for advanced users who 
can modify and expand the tool. As the community standards evolve, Rhea will
adapt to always represent the current state-of-the-art in microbial profiles
analysis in the clear and comprehensive way allowed by the R language. Rhea
scripts and documentation are freely available at
https://lagkouvardos.github.io/Rhea.

DOI: 10.7717/peerj.2836 
PMCID: PMC5234437
PMID: 28097056  [PubMed - in process]


37. Bioinformatics. 2017 Jan 17. pii: btw770. doi: 10.1093/bioinformatics/btw770.
[Epub ahead of print]

LRSSL: predict and interpret drug-disease associations based on data integration 
using sparse subspace learning.

Liang X(1), Zhang P(1), Yan L(1), Fu Y(1), Peng F(1), Qu L(1), Shao M(1), Chen
Y(1), Chen Z(1).

Author information: 
(1)Key Laboratory of Cancer Proteomics of Chinese Ministry of Health, XiangYa
Hospital, Central South University, ChangSha, HuNan 410008, People's Republic of 
China.

MOTIVATION: Exploring the potential curative effects of drugs is crucial for
effective drug development. Previous studies have indicated that integration of
multiple types of information could be conducive to discovering novel indications
of drugs. However, how to efficiently identify the mechanism behind drug-disease 
associations while integrating data from different sources remains a challenging 
problem.
RESULTS: In this research, we present a novel method for indication prediction of
both new drugs and approved drugs. This method is based on Laplacian regularized 
sparse subspace learning (LRSSL), which integrates drug chemical information,
drug target domain information and target annotation information. Experimental
results show that the proposed method outperforms several recent approaches for
predicting drug-disease associations. Some drug therapeutic effects predicted by 
the method could be validated by database records or literatures. Moreover, with 
L1-norm constraint, important drug features have been extracted from multiple
drug feature profiles. Case studies suggest that the extracted drug features
could be beneficial to interpretation of the predicted results.
AVAILABILITY AND IMPLEMENTATION: https://github.com/LiangXujun/LRSSL CONTACT:
proteomics@csu.edu.cnSupplementary information: Supplementary data are available 
at Bioinformatics online.

© The Author 2017. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw770 
PMID: 28096083  [PubMed - as supplied by publisher]


38. Neural Comput. 2017 Jan 17:1-50. doi: 10.1162/NECO_a_00939. [Epub ahead of print]

Semisupervised, Multilabel, Multi-Instance Learning for Structured Data.

Soleimani H(1), Miller DJ(2).

Author information: 
(1)School of Electrical Engineering and Computer Science, Pennsylvania State
University, University Park, PA 16802, U.S.A. hsoleimani@psu.edu. (2)School of
Electrical Engineering and Computer Science, Pennsylvania State University,
University Park, PA 16802, U.S.A. djmiller@psu.edu.

Many classification tasks require both labeling objects and determining label
associations for parts of each object. Example applications include labeling
segments of images or determining relevant parts of a text document when the
training labels are available only at the image or document level. This task is
usually referred to as multi-instance (MI) learning, where the learner typically 
receives a collection of labeled (or sometimes unlabeled) bags, each containing
several segments (instances). We propose a semisupervised MI learning method for 
multilabel classification. Most MI learning methods treat instances in each bag
as independent and identically distributed samples. However, in many practical
applications, instances are related to each other and should not be considered
independent. Our model discovers a latent low-dimensional space that captures
structure within each bag. Further, unlike many other MI learning methods, which 
are primarily developed for binary classification, we model multiple classes
jointly, thus also capturing possible dependencies between different classes. We 
develop our model within a semisupervised framework, which leverages both labeled
and, typically, a larger set of unlabeled bags for training. We develop several
efficient inference methods for our model. We first introduce a Markov chain
Monte Carlo method for inference, which can handle arbitrary relations between
bag labels and instance labels, including the standard hard-max MI assumption. We
also develop an extension of our model that uses stochastic variational Bayes'
methods for inference, and thus scales better to massive data sets. Experiments
show that our approach outperforms several MI learning and standard
classification methods on both bag-level and instance-level label prediction. All
code for replicating our experiments is available from
https://github.com/hsoleimani/MLTM .

DOI: 10.1162/NECO_a_00939 
PMID: 28095193  [PubMed - as supplied by publisher]


39. Bioinformatics. 2017 Jan 16. pii: btx009. doi: 10.1093/bioinformatics/btx009.
[Epub ahead of print]

DeuteRater: a Tool for Quantifying Peptide Isotope Precision and Kinetic
Proteomics.

Naylor BC(1), Porter MT(2), Wilson E(2), Herring A(2), Lofthouse S(2), Hannemann 
A(2), Piccolo SR(3), Rockwood AL(4,)(5), Price JC(1).

Author information: 
(1)Dept. Chemistry and Biochemistry, Brigham Young University, Provo, Utah,
86402, bnaylor2@byu.edu. (2)Dept. Chemistry and Biochemistry, Brigham Young
University, Provo, Utah, 86402. (3)Dept. of Biology, Brigham Young University,
Provo, Utah, 86402. (4)Dept. Pathology, University of Utah, Salt Lake City, Utah,
84112. (5)ARUP Laboratories, Salt Lake City, Utah, 84112.

MOTIVATION: Using mass spectrometry to measure the concentration and turnover of 
the individual proteins in a proteome, enables the calculation of individual
synthesis and degradation rates for each protein. Software to analyze
concentration is readily available, but software to analyze turnover is lacking. 
Data analysis workflows typically don't access the full breadth of information
about instrument precision and accuracy that is present in each peptide isotopic 
envelope measurement. This method utilizes both isotope distribution and changes 
in neutromer spacing which benefits the analysis of both concentration and
turnover.
RESULTS: We have developed a data analysis tool, DeuteRater, to measure protein
turnover from metabolic D2O suping. DeuteRater uses theoretical predictions for
sup-dependent change in isotope abundance and inter-peak (neutromer) spacing
within the isotope envelope to calculate protein turnover rate. We have also used
these metrics to evaluate the accuracy and precision of peptide measurements, and
thereby determined the optimal data acquisition parameters of different
instruments, as well as the effect of data processing steps. We show that these
combined measurements can be used to remove noise and increase confidence in the 
protein turnover measurement for each protein.
AVAILABILITY: Source code and ReadMe for Python 2 and 3 versions of DeuteRater
are available at https://github.com/JC-Price/DeuteRater Data is at
https://chorusproject.org/pages/index.html project number 1147. Critical
Intermediate calculation files provided as Tables S3 and S4. Software has only
been tested on Windows machines.
CONTACT: jcprice@chem.byu.eduSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author (2017). Published by Oxford University Press. All rights reserved.
For Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btx009 
PMID: 28093409  [PubMed - as supplied by publisher]


40. Bioinformatics. 2017 Jan 16. pii: btx011. doi: 10.1093/bioinformatics/btx011.
[Epub ahead of print]

VCF-kit: Assorted utilities for the variant call format.

Cook DE(1), Andersen EC(2).

Author information: 
(1)Interdisciplinary Biological Sciences Program, Northwestern University,
Evanston, IL 60208. (2)Department of Molecular Biosciences, Northwestern
University, Evanston, IL 60208 erik.andersen@northwestern.edu.

The variant call format (VCF) is a popular standard for storing genetic variation
data. As a result, a large collection of tools has been developed that perform
diverse analyses using VCF files. However, some tasks common to statistical and
population geneticists have not been created yet. To streamline these types of
analyses, we created novel tools that analyze or annotate VCF files and organized
these tools into a command-line based utility named VCF-kit. VCF-kit adds
essential utilities to process and analyze VCF files, including primer generation
for variant validation, dendrogram production, genotype imputation from sequence 
data in linkage studies, and additional tools.AVAILABILITY:
https://github.com/AndersenLab/VCF-kit CONTACT: erik.andersen@northwestern.edu.

© The Author(s) 2017. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btx011 
PMID: 28093408  [PubMed - as supplied by publisher]


41. Bioinformatics. 2017 Jan 16. pii: btw838. doi: 10.1093/bioinformatics/btw838.
[Epub ahead of print]

DistributedFBA.jl: High-level, high-performance flux balance analysis in Julia.

Heirendt L(1), Thiele I(2), Fleming RM(2).

Author information: 
(1)Luxembourg Centre for Systems Biomedicine, University of Luxembourg, Campus
Belval, Esch-sur-Alzette, Luxembourg. (2)Luxembourg Centre for Systems
Biomedicine, University of Luxembourg, Campus Belval, Esch-sur-Alzette,
Luxembourg ines.thiele@gmail.com.

MOTIVATION: Flux balance analysis, and its variants, are widely used methods for 
predicting steady-state reaction rates in biochemical reaction networks. The
exploration of high dimensional networks with such methods is currently hampered 
by software performance limitations.
RESULTS: DistributedFBA.jl is a high-level, high-performance, open-source
implementation of flux balance analysis in Julia. It is tailored to solve
multiple flux balance analyses on a subset or all the reactions of large and
huge-scale networks, on any number of threads or nodes.
AVAILABILITY: The code is freely available on github.com/opencobra/COBRA.jl. The 
documentation can be found at opencobra.github.io/COBRA.jl.
CONTACT: ronan.mt.fleming@gmail.com.

© The Author(s) 2017. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw838 
PMID: 28093405  [PubMed - as supplied by publisher]


42. IEEE Trans Med Imaging. 2017 Jan 16. doi: 10.1109/TMI.2017.2653623. [Epub ahead
of print]

Sub-Category Classifiers for Multiple-Instance Learning and its Application to
Retinal Nerve Fiber Layer Visibility Classification.

Manivannan S, Cobb C, Burgess S, Trucco E.

We propose a novel multiple instance learning method to assess the visibility
(visible/not visible) of the retinal nerve fiber layer (RNFL) in fundus camera
images. Using only image-level labels, our approach learns to classify the images
as well as to localize the RNFL visible regions. We transform the original
feature space to a discriminative subspace, and learn a region-level classifier
in that subspace. We propose a margin-based loss function to jointly learn this
subspace and the region-level classifier. Experiments with a RNFL dataset
containing 884 images annotated by two ophthalmologists give a system-annotator
agreement (kappa values) of 0:73 and 0:72 respectively, with an inter-annotator
agreement of 0:73. Our system agrees better with the more experienced annotator. 
Comparative tests with three public datasets (MESSIDOR and DR for diabetic
retinopathy, UCSB for breast cancer) show that our novel MIL approach improves
performance over the state-of-the-art. Our Matlab code is publicly available at
https://github.com/ManiShiyam/Sub-category-classifiersfor-
Multiple-Instance-Learning/wiki.

DOI: 10.1109/TMI.2017.2653623 
PMID: 28092529  [PubMed - as supplied by publisher]


43. Metabolomics. 2017;13(2):14. doi: 10.1007/s11306-016-1142-2. Epub 2016 Dec 27.

MASTR-MS: a web-based collaborative laboratory information management system
(LIMS) for metabolomics.

Hunter A(1), Dayalan S(2), De Souza D(2), Power B(1), Lorrimar R(1), Szabo T(1), 
Nguyen T(3), O'Callaghan S(2), Hack J(4), Pyke J(2), Nahid A(5), Barrero R(1),
Roessner U(6), Likic V(7), Tull D(2), Bacic A(8), McConville M(2), Bellgard M(1).

Author information: 
(1)Australian Bioinformatics Facility, Centre for Comparative Genomics, Murdoch
University, Murdoch, WA 6150 Australia. (2)Metabolomics Australia, The University
of Melbourne, Melbourne, VIC 3010 Australia ; Bio21 Molecular Science and
Biotechnology Institute, The University of Melbourne, Melbourne, VIC 3010
Australia. (3)Bio21 Molecular Science and Biotechnology Institute, The University
of Melbourne, Melbourne, VIC 3010 Australia. (4)Metabolomics Australia, The
Australian Wine Research Institute, Adelaide, SA 5064 Australia. (5)Australian
Bioinformatics Facility, Centre for Comparative Genomics, Murdoch University,
Murdoch, WA 6150 Australia ; Bio21 Molecular Science and Biotechnology Institute,
The University of Melbourne, Melbourne, VIC 3010 Australia. (6)Metabolomics
Australia, The University of Melbourne, Melbourne, VIC 3010 Australia ; School of
Biosciences, The University of Melbourne, Melbourne, VIC 3010 Australia.
(7)Metabolomics Australia, The University of Melbourne, Melbourne, VIC 3010
Australia. (8)Metabolomics Australia, The University of Melbourne, Melbourne, VIC
3010 Australia ; Bio21 Molecular Science and Biotechnology Institute, The
University of Melbourne, Melbourne, VIC 3010 Australia ; ARC Centre of Excellence
in Plant Cell Walls, School of Biosciences, The University of Melbourne,
Melbourne, VIC 3010 Australia.

BACKGROUND: An increasing number of research laboratories and core analytical
facilities around the world are developing high throughput metabolomic analytical
and data processing pipelines that are capable of handling hundreds to thousands 
of individual samples per year, often over multiple projects, collaborations and 
sample types. At present, there are no Laboratory Information Management Systems 
(LIMS) that are specifically tailored for metabolomics laboratories that are
capable of tracking samples and associated metadata from the beginning to the end
of an experiment, including data processing and archiving, and which are also
suitable for use in large institutional core facilities or multi-laboratory
consortia as well as single laboratory environments.
RESULTS: Here we present MASTR-MS, a downloadable and installable LIMS solution
that can be deployed either within a single laboratory or used to link workflows 
across a multisite network. It comprises a Node Management System that can be
used to link and manage projects across one or multiple collaborating
laboratories; a User Management System which defines different user groups and
privileges of users; a Quote Management System where client quotes are managed; a
Project Management System in which metadata is stored and all aspects of project 
management, including experimental setup, sample tracking and instrument
analysis, are defined, and a Data Management System that allows the automatic
capture and storage of raw and processed data from the analytical instruments to 
the LIMS.
CONCLUSION: MASTR-MS is a comprehensive LIMS solution specifically designed for
metabolomics. It captures the entire lifecycle of a sample starting from project 
and experiment design to sample analysis, data capture and storage. It acts as an
electronic notebook, facilitating project management within a single laboratory
or a multi-node collaborative environment. This software is being developed in
close consultation with members of the metabolomics research community. It is
freely available under the GNU GPL v3 licence and can be accessed from,
https://muccg.github.io/mastr-ms/.

DOI: 10.1007/s11306-016-1142-2 
PMCID: PMC5192047
PMID: 28090199  [PubMed]


44. Int J Epidemiol. 2017 Jan 15. pii: dyw341. doi: 10.1093/ije/dyw341. [Epub ahead
of print]

Robust causal inference using directed acyclic graphs: the R package 'dagitty'.

Textor J(1), van der Zander B(2), Gilthorpe MS(3,)(4), Liśkiewicz M(2), Ellison
GT(3,)(4).

Author information: 
(1)Department of Tumour Immunology, Radboud University Medical Center, P.O. Box
9101, 6500 HB Nijmegen, The Netherlands, johannes.textor@radboudumc.nl.
(2)Institute for Theoretical Computer Science, University of Luebeck, Luebeck,
Germany. (3)Leeds Institute of Cardiovascular and Metabolic Medicine. (4)Leeds
Institute for Data Analytics, University of Leeds, Leeds, UK.

Directed acyclic graphs (DAGs), which offer systematic representations of causal 
relationships, have become an established framework for the analysis of causal
inference in epidemiology, often being used to determine covariate adjustment
sets for minimizing confounding bias. DAGitty is a popular web application for
drawing and analysing DAGs. Here we introduce the R package 'dagitty', which
provides access to all of the capabilities of the DAGitty web application within 
the R platform for statistical computing, and also offers several new functions. 
We describe how the R package 'dagitty' can be used to: evaluate whether a DAG is
consistent with the dataset it is intended to represent; enumerate 'statistically
equivalent' but causally different DAGs; and identify exposure-outcome adjustment
sets that are valid for causally different but statistically equivalent DAGs.
This functionality enables epidemiologists to detect causal misspecifications in 
DAGs and make robust inferences that remain valid for a range of different DAGs. 
The R package 'dagitty' is available through the comprehensive R archive network 
(CRAN) at [https://cran.r-project.org/web/packages/dagitty/]. The source code is 
available on github at [https://github.com/jtextor/dagitty]. The web application 
'DAGitty' is free software, licensed under the GNU general public licence (GPL)
version 2 and is available at [http://dagitty.net/].

© The Author 2017; all rights reserved. Published by Oxford University Press on
behalf of the International Epidemiological Association.

DOI: 10.1093/ije/dyw341 
PMID: 28089956  [PubMed - as supplied by publisher]


45. Bioinformatics. 2017 Jan 14. pii: btw773. doi: 10.1093/bioinformatics/btw773.
[Epub ahead of print]

The super-n-motifs model: a novel alignment-free approach for representing and
comparing RNA secondary structures.

Glouzon JS(1,)(2), Perreault JP(2), Wang S(1).

Author information: 
(1)Department of Computer Science, Faculty of Science, Université de Sherbrooke, 
Sherbrooke, QC J1H 5N4, Canada. (2)RNA Group, Department of Biochemistry, Faculty
of Medicine and Health Sciences, Applied Cancer Research Pavilion, Université de 
Sherbrooke, Sherbrooke, QC J1E 4K8, Canada.

MOTIVATION: Comparing ribonucleic acid (RNA) secondary structures of arbitrary
size uncovers structural patterns that can provide a better understanding of RNA 
functions. However, performing fast and accurate secondary structure comparisons 
is challenging when we take into account the RNA configuration (i.e. linear or
circular), the presence of pseudoknot and G-quadruplex (G4) motifs and the
increasing number of secondary structures generated by high-throughput probing
techniques. To address this challenge, we propose the super-n-motifs model based 
on a latent analysis of enhanced motifs comprising not only basic motifs but also
adjacency relations. The super-n-motifs model computes a vector representation of
secondary structures as linear combinations of these motifs.
RESULTS: We demonstrate the accuracy of our model for comparison of secondary
structures from linear and circular RNA while also considering pseudoknot and G4 
motifs. We show that the super-n-motifs representation effectively captures the
most important structural features of secondary structures, as compared to other 
representations such as ordered tree, arc-annotated and string representations.
Finally, we demonstrate the time efficiency of our model, which is alignment free
and capable of performing large-scale comparisons of 10 000 secondary structures 
with an efficiency up to 4 orders of magnitude faster than existing approaches.
AVAILABILITY AND IMPLEMENTATION: The super-n-motifs model was implemented in
C ++. Source code and Linux binary are freely available at
http://jpsglouzon.github.io/supernmotifs/ CONTACT:
Shengrui.Wang@Usherbrooke.caSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2017. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw773 
PMID: 28088762  [PubMed - as supplied by publisher]


46. Bioinformatics. 2017 Jan 13. pii: btw769. doi: 10.1093/bioinformatics/btw769.
[Epub ahead of print]

H-BLAST: a fast protein sequence alignment toolkit on heterogeneous computers
with GPUs.

Ye W(1), Chen Y(1), Zhang Y(1), Xu Y(1,)(2).

Author information: 
(1)School of Data and Computer Science, and Guangdong Province Key Laboratory of 
Computational Science, Sun Yat-sen University, Guangzhou 510275, People's
Republic of China. (2)Professor Emeritus of Department of Mathematics, Syracuse
University, Syracuse, NY 13244, USA.

MOTIVATION: The sequence alignment is a fundamental problem in bioinformatics.
BLAST is a routinely used tool for this purpose with over 118 000 citations in
the past two decades. As the size of bio-sequence databases grows exponentially, 
the computational speed of alignment softwares must be improved.
RESULTS: We develop the heterogeneous BLAST (H-BLAST), a fast parallel search
tool for a heterogeneous computer that couples CPUs and GPUs, to accelerate
BLASTX and BLASTP-basic tools of NCBI-BLAST. H-BLAST employs a locally decoupled 
seed-extension algorithm for better performance on GPUs, and offers a performance
tuning mechanism for better efficiency among various CPUs and GPUs combinations. 
H-BLAST produces identical alignment results as NCBI-BLAST and its computational 
speed is much faster than that of NCBI-BLAST. Speedups achieved by H-BLAST over
sequential NCBI-BLASTP (resp. NCBI-BLASTX) range mostly from 4 to 10 (resp. 5 to 
7.2). With 2 CPU threads and 2 GPUs, H-BLAST can be faster than 16-threaded
NCBI-BLASTX. Furthermore, H-BLAST is 1.5-4 times faster than GPU-BLAST.
AVAILABILITY AND IMPLEMENTATION: https://github.com/Yeyke/H-BLAST.git CONTACT:
yux06@syr.eduSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2017. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw769 
PMID: 28087515  [PubMed - as supplied by publisher]


47. Biometrics. 2017 Jan 12. doi: 10.1111/biom.12649. [Epub ahead of print]

Bayesian genome- and epigenome-wide association studies with gene level
dependence.

Lock EF(1), Dunson DB(2).

Author information: 
(1)Division of Biostatistics, University of Minnesota, Minneapolis, Minnesota
55455, U.S.A. (2)Department of Statistical Science, Duke University, Durham,
North Carolina 27708, U.S.A.

High-throughput genetic and epigenetic data are often screened for associations
with an observed phenotype. For example, one may wish to test hundreds of
thousands of genetic variants, or DNA methylation sites, for an association with 
disease status. These genomic variables can naturally be grouped by the gene they
encode, among other criteria. However, standard practice in such applications is 
independent screening with a universal correction for multiplicity. We propose a 
Bayesian approach in which the prior probability of an association for a given
genomic variable depends on its gene, and the gene-specific probabilities are
modeled nonparametrically. This hierarchical model allows for appropriate gene
and genome-wide multiplicity adjustments, and can be incorporated into a variety 
of Bayesian association screening methodologies with negligible increase in
computational complexity. We describe an application to screening for differences
in DNA methylation between lower grade glioma and glioblastoma multiforme tumor
samples from The Cancer Genome Atlas. Software is available via the package
BayesianScreening for R:github.com/lockEF/BayesianScreening.

© 2017, The International Biometric Society.

DOI: 10.1111/biom.12649 
PMID: 28083869  [PubMed - as supplied by publisher]


48. Bioinformatics. 2017 Jan 12. pii: btw836. doi: 10.1093/bioinformatics/btw836.
[Epub ahead of print]

Modeling Gene-Wise Dependencies Improves the Identification of Drug Response
Biomarkers in Cancer Studies.

Nikolova O(1), Moser R(2), Kemp C(2), Gönen M(3,)(4), Margolin AA(1).

Author information: 
(1)Computational Biology, Oregon Health & Science University, Portland, OR, USA
nikolova@ohsu.edu olga.nikolova@gmail.com. (2)Division of Human Biology, Fred
Hutchinson Cancer Research Center, Seattle, WA, USA. (3)Computational Biology,
Oregon Health & Science University, Portland, OR, USA. (4)Department of
Industrial Engineering, Koç University, ˙Istanbul, Turkey.

MOTIVATION: In recent years, vast advances in biomedical technologies and
comprehensive sequencing have revealed the genomic landscape of common forms of
human cancer in unprecedented detail. The broad heterogeneity of the disease
calls for rapid development of personalized therapies. Translating the readily
available genomic data into useful knowledge that can be applied in the clinic
remains a challenge. Computational methods are needed to aid these efforts by
robustly analyzing genome-scale data from distinct experimental platforms for
prioritization of targets and treatments.
RESULTS: We propose a novel, biologically-motivated, Bayesian multitask approach,
which explicitly models gene-centric dependencies across multiple and distinct
genomic platforms. We introduce a genewise prior and present a fully Bayesian
formulation of a group factor analysis model. In supervised prediction
applications, our multitask approach leverages similarities in response profiles 
of groups of drugs that are more likely to be related to true biological signal, 
which leads to more robust performance and improved generalization ability. We
evaluate the performance of our method on molecularly characterized collections
of cell lines profiled against two compound panels, namely the Cancer Cell Line
Encyclopedia and the Cancer Therapeutics Response Portal. We demonstrate that
accounting for the gene-centric dependencies enables leveraging information from 
multi-omic input data and improves prediction and feature selection performance. 
We further demonstrate the applicability of our method in an unsupervised
dimensionality reduction application by inferring genes essential to
tumorigenesis in the pancreatic ductal adenocarcinoma and lung adenocarcinoma
patient cohorts from The Cancer Genome Atlas.
AVAILABILITY: The code for this work is available at
https://github.com/olganikolova/gbgfa CONTACT:
nikolova@ohsu.edu,margolin@ohsu.edu.

© The Author (2017). Published by Oxford University Press. All rights reserved.
For Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw836 
PMID: 28082455  [PubMed - as supplied by publisher]


49. Database (Oxford). 2017 Jan 10;2017. pii: baw166. doi: 10.1093/database/baw166.
Print 2017.

Automatic query generation using word embeddings for retrieving passages
describing experimental methods.

Aydın F(1), Hüsünbeyi ZM(1), Özgür A(2).

Author information: 
(1)Department of Computer Engineering, Boğaziçi University, TR-34342 Bebek,
Istanbul, Turkey. (2)Department of Computer Engineering, Boğaziçi University,
TR-34342 Bebek, Istanbul, Turkey arzucan.ozgur@boun.edu.tr.

Information regarding the physical interactions among proteins is crucial, since 
protein-protein interactions (PPIs) are central for many biological processes.
The experimental techniques used to verify PPIs are vital for characterizing and 
assessing the reliability of the identified PPIs. A lot of information about PPIs
and the experimental methods are only available in the text of the scientific
publications that report them. In this study, we approach the problem of
identifying passages with experimental methods for physical interactions between 
proteins as an information retrieval search task. The baseline system is based on
query matching, where the queries are generated by utilizing the names (including
synonyms) of the experimental methods in the Proteomics Standard
Initiative-Molecular Interactions (PSI-MI) ontology. We propose two methods,
where the baseline queries are expanded by including additional relevant terms.
The first method is a supervised approach, where the most salient terms for each 
experimental method are obtained by using the term frequency-relevance frequency 
(tf.rf) metric over 13 articles from our manually annotated data set of 30 full
text articles, which is made publicly available. On the other hand, the second
method is an unsupervised approach, where the queries for each experimental
method are expanded by using the word embeddings of the names of the experimental
methods in the PSI-MI ontology. The word embeddings are obtained by utilizing a
large unlabeled full text corpus. The proposed methods are evaluated on the test 
set consisting of 17 articles. Both methods obtain higher recall scores compared 
with the baseline, with a loss in precision. Besides higher recall, the word
embeddings based approach achieves higher F-measure than the baseline and the
tf.rf based methods. We also show that incorporating gene name and interaction
keyword identification leads to improved precision and F-measure scores for all
three evaluated methods. The tf.rf based approach was developed as part of our
participation in the Collaborative Biocurator Assistant Task of the BioCreative V
challenge assessment, whereas the word embeddings based approach is a novel
contribution of this article.Database URL:
https://github.com/ferhtaydn/biocemid/.

© The Author(s) 2017. Published by Oxford University Press.

DOI: 10.1093/database/baw166 
PMCID: PMC5225401
PMID: 28077568  [PubMed - in process]


50. Database (Oxford). 2017 Jan 10;2017. pii: baw154. doi: 10.1093/database/baw154.
Print 2017.

blend4php: a PHP API for galaxy.

Wytko C(1,)(2), Soto B(1,)(2), Ficklin SP(3).

Author information: 
(1)Department of Horticulture and. (2)School of Electrical Engineering and
Computer Science, Washington State University, Pullman, WA 99164, USA.
(3)Department of Horticulture and stephen.ficklin@wsu.edu.

Galaxy is a popular framework for execution of complex analytical pipelines
typically for large data sets, and is a commonly used for (but not limited to)
genomic, genetic and related biological analysis. It provides a web front-end and
integrates with high performance computing resources. Here we report the
development of the blend4php library that wraps Galaxy's RESTful API into a
PHP-based library. PHP-based web applications can use blend4php to automate
execution, monitoring and management of a remote Galaxy server, including its
users, workflows, jobs and more. The blend4php library was specifically developed
for the integration of Galaxy with Tripal, the open-source toolkit for the
creation of online genomic and genetic web sites. However, it was designed as an 
independent library for use by any application, and is freely available under
version 3 of the GNU Lesser General Public License (LPGL v3.0) at
https://github.com/galaxyproject/blend4phpDatabase URL:
https://github.com/galaxyproject/blend4php.

© The Author(s) 2017. Published by Oxford University Press. All rights reserved. 
For Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/database/baw154 
PMCID: PMC5225400
PMID: 28077564  [PubMed - in process]


51. Hum Hered. 2016;81(2):117-126. doi: 10.1159/000448733. Epub 2017 Jan 12.

Identifying Host Genetic Variants Associated with Microbiome Composition by
Testing Multiple Beta Diversity Matrices.

Hua X(1), Goedert JJ, Landi MT, Shi J.

Author information: 
(1)Division of Cancer Epidemiology and Genetics, National Cancer Institute,
National Institute of Health, Bethesda, Md., USA.

OBJECTIVES: Host genetics have been recently reported to affect human microbiome 
composition. We previously developed a statistical framework, microbiomeGWAS, to 
identify host genetic variants associated with microbiome composition by testing 
a distance matrix. However, statistical power depends on the choice of a
microbiome distance matrix. To achieve more robust statistical power, we aim to
extend microbiomeGWAS to test the association with many distance matrices, which 
are defined based on multilevel taxa abundances and phylogenetic information.
METHODS: The main challenge is to accurately and rapidly evaluate the
significance for millions of SNPs. We propose methods for approximating p values 
by correcting for the multiple testing introduced by testing many distance
matrices and by correcting for the skewness and kurtosis of score statistics.
RESULTS: The accuracy of p value approximation was verified by simulations. We
applied our method to a set of 147 lung cancer patients with 16S rRNA microbiome 
profiles from nonmalignant lung tissues. We show that correcting for skewness and
kurtosis eliminated dramatic deviations in the quantile-quantile plot.
CONCLUSION: We developed computationally efficient methods for identifying host
genetic variants associated with microbiome composition by testing many distance 
matrices. The algorithms are implemented in the package microbiomeGWAS
(https://github.com/lsncibb/microbiomeGWAS).

© 2017 S. Karger AG, Basel.

DOI: 10.1159/000448733 
PMID: 28076867  [PubMed - in process]


52. Bioinformatics. 2017 Jan 10. pii: btw837. doi: 10.1093/bioinformatics/btw837.
[Epub ahead of print]

Better diagnostic signatures from RNAseq data through use of auxiliary co-data.

Novianti PW(1,)(2), Snoek BC(2), Wilting SM(2), van de Wiel MA(3,)(4).

Author information: 
(1)Department of Epidemiology and Biostatistics, VU University medical center,
Amsterdam, the Netherlands. (2)Department of Pathology, VU University medical
center, Amsterdam, the Netherlands. (3)Department of Epidemiology and
Biostatistics, VU University medical center, Amsterdam, the Netherlands,
p.novianti@vumc.nl. (4)Department of Mathematics, VU University, Amsterdam, the
Netherlands.

Our aim is to improve omics based prediction and feature selection using multiple
sources of auxiliary information: co-data. Adaptive group regularized ridge
regression (GRridge) was proposed to achieve this by estimating additional
group-based penalty parameters through an empirical Bayes method at a low
computational cost. We illustrate the GRridge method and software on RNA
sequencing data sets. The method boosts the performance of an ordinary ridge
regression and outperforms other classifiers. Post-hoc feature selection
maintains the predictive ability of the classifier with far fewer
markers.AVAILABILITY AND IMPLEMENTATION: The GRridge method is implemented in R
package and it is freely available at
(https://bioconductor.org/packages/GRridge/). All information and R scripts
related to the co-data used in this study are available from
http://github.com/markvdwiel/GRridgeCodata CONTACT:
mark.vdwiel@vumc.nlSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author (2017). Published by Oxford University Press. All rights reserved.
For Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw837 
PMID: 28073760  [PubMed - as supplied by publisher]


53. Bioinformatics. 2017 Jan 10. pii: btw816. doi: 10.1093/bioinformatics/btw816.
[Epub ahead of print]

The Genetic Map Comparator: a user-friendly application to display and compare
genetic maps.

Holtz Y(1), David J(2), Ranwez V(1).

Author information: 
(1)Montpellier SupAgro, UMR AGAP, 34060 Montpellier, France yan.holtz@supagro.fr.
(2)Montpellier SupAgro, UMR AGAP, 34060 Montpellier, France.

MOTIVATION: Marker-assisted selection strongly relies on genetic maps to
accelerate breeding programs. High-density maps are now available for numerous
species. Dedicated tools are required to compare several high-density maps on the
basis of their key characteristics, while pinpointing their differences and
similarities.
RESULTS: We developed the Genetic Map Comparator-a web-based application for easy
comparison of different maps according to their key statistics and the relative
positions of common markers.
AVAILABILITY: The Genetic Map Comparator is available online at:
http://bioweb.supagro.inra.fr/geneticMapComparator The source code is freely
available on GitHub under the under the CeCILL general public license:
https://github.com/holtzy/GenMap-Comparator CONTACT: Holtz@supagro.fr;
Ranwez@supagro.frSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author (2017). Published by Oxford University Press. All rights reserved.
For Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw816 
PMID: 28073759  [PubMed - as supplied by publisher]


54. Bioinformatics. 2017 Jan 10. pii: btw771. doi: 10.1093/bioinformatics/btw771.
[Epub ahead of print]

Feature selection using a one dimensional naïve Bayes' classifier increases the
accuracy of support vector machine classification of CDR3 repertoires.

Cinelli M(1), Sun Y(2), Best K(1,)(3), Heather JM(1), Reich-Zeliger S(4), Shifrut
E(4), Friedman N(4), Shawe-Taylor J(2), Chain B(1).

Author information: 
(1)Division of Infection and Immunity. (2)Department of Computer Science.
(3)Complex, UCL, London, UK. (4)Department of Immunology, Weizmann Institute,
Rehovot, Israel.

MOTIVATION: Somatic DNA recombination, the hallmark of vertebrate adaptive
immunity, has the potential to generate a vast diversity of antigen receptor
sequences. How this diversity captures antigen specificity remains incompletely
understood. In this study we use high throughput sequencing to compare the global
changes in T cell receptor β chain complementarity determining region 3 (CDR3β)
sequences following immunization with ovalbumin administered with complete
Freund's adjuvant (CFA) or CFA alone.
RESULTS: The CDR3β sequences were deconstructed into short stretches of
overlapping contiguous amino acids. The motifs were ranked according to a
one-dimensional Bayesian classifier score comparing their frequency in the
repertoires of the two immunization classes. The top ranking motifs were selected
and used to create feature vectors which were used to train a support vector
machine. The support vector machine achieved high classification scores in a
leave-one-out validation test reaching  : >90% in some cases.
SUMMARY: The study describes a novel two-stage classification strategy combining 
a one-dimensional Bayesian classifier with a support vector machine. Using this
approach we demonstrate that the frequency of a small number of linear motifs
three amino acids in length can accurately identify a CD4 T cell response to
ovalbumin against a background response to the complex mixture of antigens which 
characterize Complete Freund's Adjuvant.
AVAILABILITY AND IMPLEMENTATION: The sequence data is available at
www.ncbi.nlm.nih.gov/sra/?term¼SRP075893 The Decombinator package is available at
github.com/innate2adaptive/Decombinator The R package e1071 is available at the
CRAN repository https://cran.r-project.org/web/packages/e1071/index.html CONTACT:
b.chain@ucl.ac.ukSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2017. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw771 
PMID: 28073756  [PubMed - as supplied by publisher]


55. Bioinformatics. 2017 Jan 10. pii: btw747. doi: 10.1093/bioinformatics/btw747.
[Epub ahead of print]

Advanced Boolean modeling of biological networks applied to systems pharmacology.

Irurzun-Arana I(1), Pastor JM(1), Trocóniz IF(1), Gómez-Mantilla JD(1).

Author information: 
(1)Pharmacometrics & Systems Pharmacology, Department of Pharmacy and
Pharmaceutical Technology, School of Pharmacy, University of Navarra, Pamplona
31008, Spain.

MOTIVATION: Literature on complex diseases is abundant but not always
quantitative. Many molecular pathways are qualitatively well described but this
information cannot be used in traditional quantitative mathematical models
employed in drug development. Tools for analysis of discrete networks are useful 
to capture the available information in the literature but have not been
efficiently integrated by the pharmaceutical industry. We propose an expansion of
the usual analysis of discrete networks that facilitates the
identification/validation of therapeutic targets.
RESULTS: In this article, we propose a methodology to perform Boolean modeling of
Systems Biology/Pharmacology networks by using SPIDDOR (Systems Pharmacology for 
effIcient Drug Development On R) R package. The resulting models can be used to
analyze the dynamics of signaling networks associated to diseases to predict the 
pathogenesis mechanisms and identify potential therapeutic targets.
AVAILABILITY AND IMPLEMENTATION: The source code is available at
https://github.com/SPIDDOR/SPIDDOR CONTACT: itzirurzun@alumni.unav.es,
itroconiz@unav.esSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw747 
PMID: 28073755  [PubMed - as supplied by publisher]


56. BMC Genomics. 2017 Jan 10;18(1):65. doi: 10.1186/s12864-016-3444-1.

Discovery of large genomic inversions using long range information.

Eslami Rasekh M(1), Chiatante G(2), Miroballo M(2), Tang J(3), Ventura M(2),
Amemiya CT(3), Eichler EE(4), Antonacci F(5), Alkan C(6).

Author information: 
(1)Department of Computer Engineering, Bilkent University, Bilkent, 06800,
Ankara, Turkey. (2)Department of Biology, University of Bari, Via Orabona 4,
70125, Bari, Italy. (3)Benaroya Research Institute, 1201 Ninth Avenue, 98101,
Seattle, WA, USA. (4)Department of Genome Sciences and Howard Hughes Medical
Institute, University of Washington, 3720 15th Avenue NE, 98195, Seattle, WA,
USA. (5)Department of Biology, University of Bari, Via Orabona 4, 70125, Bari,
Italy. francesca.antonacci@uniba.it. (6)Department of Computer Engineering,
Bilkent University, Bilkent, 06800, Ankara, Turkey. calkan@cs.bilkent.edu.tr.

BACKGROUND: Although many algorithms are now available that aim to characterize
different classes of structural variation, discovery of balanced rearrangements
such as inversions remains an open problem. This is mainly due to the fact that
breakpoints of such events typically lie within segmental duplications or common 
repeats, which reduces the mappability of short reads. The algorithms developed
within the 1000 Genomes Project to identify inversions are limited to relatively 
short inversions, and there are currently no available algorithms to discover
large inversions using high throughput sequencing technologies.
RESULTS: Here we propose a novel algorithm, VALOR, to discover large inversions
using new sequencing methods that provide long range information such as 10X
Genomics linked-read sequencing, pooled clone sequencing, or other similar
technologies that we commonly refer to as long range sequencing. We demonstrate
the utility of VALOR using both pooled clone sequencing and 10X Genomics
linked-read sequencing generated from the genome of an individual from the HapMap
project (NA12878). We also provide a comprehensive comparison of VALOR against
several state-of-the-art structural variation discovery algorithms that use whole
genome shotgun sequencing data.
CONCLUSIONS: In this paper, we show that VALOR is able to accurately discover all
previously identified and experimentally validated large inversions in the same
genome with a low false discovery rate. Using VALOR, we also predicted a novel
inversion, which we validated using fluorescent in situ hybridization. VALOR is
available at https://github.com/BilkentCompGen/VALOR.

DOI: 10.1186/s12864-016-3444-1 
PMCID: PMC5223412
PMID: 28073353  [PubMed - in process]


57. Bioinformatics. 2017 Jan 9. pii: btx004. doi: 10.1093/bioinformatics/btx004.
[Epub ahead of print]

SigMod: an exact and efficient method to identify a strongly interconnected
disease-associated module in a gene network.

Liu Y(1,)(2), Brossard M(3,)(2), Roqueiro D(4), Margaritte-Jeannin P(3,)(2),
Sarnowski C(3,)(2), Bouzigon E(3,)(2), Demenais F(3,)(2).

Author information: 
(1)INSERM, Genetic Variation and Human Diseases Unit, UMR-946, Paris, France
yuanlong.liu@inserm.fr. (2)Université Paris Diderot, Sorbonne Paris Cité,
Institut Universitaire d'Hématologie, Paris, France. (3)INSERM, Genetic Variation
and Human Diseases Unit, UMR-946, Paris, France. (4)Machine Learning and
Computational Biology Lab, Department of Biosystems Science and Engineering, ETH 
Zurich, Switzerland.

MOTIVATION: Apart from single marker-based tests classically used in genome-wide 
association studies (GWAS), network-assisted analysis has become a promising
approach to identify a set of genes associated with disease. To date, most
network-assisted methods aim at finding genes connected in a background network, 
whatever the density or strength of their connections. This can hamper the
findings as sparse connections are non-robust against noise from either the GWAS 
results or the network resource.
RESULTS: We present SigMod, a novel and efficient method integrating GWAS results
and gene network to identify a strongly interconnected gene module enriched in
high association signals. Our method is formulated as a binary quadratic
optimization problem, which can be solved exactly through min-cut algorithms.
Compared to existing methods, SigMod has several desirable properties: (i) edge
weights quantifying confidence of connections between genes are taken into
account, (ii) the selection path can be computed rapidly, (iii) the identified
gene module is strongly interconnected, hence includes genes of high functional
relevance, and (iv) the method is robust against noise from either the GWAS
results or the network resource. We applied SigMod to both simulated and real
data. It was found to outperform state-of-the-art network-assisted methods in
identifying disease-associated genes. When SigMod was applied to childhood-onset 
asthma GWAS results, it successfully identified a gene module enriched in
consistently high association signals and made of functionally related genes that
are biologically relevant for asthma.
AVAILABILITY: An R package SigMod is available at:
https://github.com/YuanlongLiu/SigMod CONTACT: yuanlong.liu@inserm.fr,
florence.demenais@inserm.frSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author (2017). Published by Oxford University Press. All rights reserved.
For Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btx004 
PMID: 28069594  [PubMed - as supplied by publisher]


58. Bioinformatics. 2017 Jan 9. pii: btx003. doi: 10.1093/bioinformatics/btx003.
[Epub ahead of print]

KNIME4NGS: a comprehensive toolbox for Next Generation Sequencing analysis.

Hastreiter M(1), Jeske T(1), Hoser J(1), Kluge M(1), Ahomaa K(1), Friedl MS(1),
Kopetzky SJ(1), Quell JD(1), Werner Mewes H(1), Küffner R(2).

Author information: 
(1)Institute of Bioinformatics and Systems Biology, Helmholtz Zentrum München,
Ingolstädter Landstraße 1, 85764 Neuherberg, Germany. (2)Institute of
Bioinformatics and Systems Biology, Helmholtz Zentrum München, Ingolstädter
Landstraße 1, 85764 Neuherberg, Germany robert.kueffner@bio.ifi.lmu.de.

Analysis of Next Generation Sequencing (NGS) data requires the processing of
large datasets by chaining various tools with complex input and output formats.
In order to automate data analysis, we propose to standardize NGS tasks into
modular workflows. This simplifies reliable handling and processing of NGS data, 
and corresponding solutions become substantially more reproducible and easier to 
maintain. Here, we present a documented, linux-based, toolbox of 42 processing
modules that are combined to construct workflows facilitating a variety of tasks 
such as DNAseq and RNAseq analysis. We also describe important technical
extensions. The high throughput executor (HTE) helps to increase the reliability 
and to reduce manual interventions when processing complex datasets. We also
provide a dedicated binary manager that assists users in obtaining the modules'
executables and keeping them up to date. As basis for this actively developed
toolbox we use the workflow management software KNIME.AVAILABILITY: See
http://ibisngs.github.io/knime4ngs for nodes and user manual (GPLv3 license)
CONTACT: robert.kueffner@helmholtz-muenchen.de.

© The Author (2017). Published by Oxford University Press. All rights reserved.
For Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btx003 
PMID: 28069593  [PubMed - as supplied by publisher]


59. mSystems. 2017 Jan 3;2(1). pii: e00127-16. doi: 10.1128/mSystems.00127-16.

Microbiome Helper: a Custom and Streamlined Workflow for Microbiome Research.

Comeau AM(1), Douglas GM(1), Langille MG(1).

Author information: 
(1)CGEB-Integrated Microbiome Resource (IMR) and Department of Pharmacology,
Dalhousie University, Halifax, Canada.

Sequence-based approaches to study microbiomes, such as 16S rRNA gene sequencing 
and metagenomics, are uncovering associations between microbial taxa and a myriad
of factors. A drawback of these approaches is that the necessary sequencing
library preparation and bioinformatic analyses are complicated and continuously
changing, which can be a barrier for researchers new to the field. We present
three essential components to conducting a microbiome experiment from start to
finish: first, a simplified and step-by-step custom gene sequencing protocol that
requires limited lab equipment, is cost-effective, and has been thoroughly tested
and utilized on various sample types; second, a series of scripts to integrate
various commonly used bioinformatic tools that is available as a standalone
installation or as a single downloadable virtual image; and third, a set of
bioinformatic workflows and tutorials to provide step-by-step guidance and
education for those new to the microbiome field. This resource will provide the
foundations for those newly entering the microbiome field and will provide
much-needed guidance and best practices to ensure that quality microbiome
research is undertaken. All protocols, scripts, workflows, tutorials, and virtual
images are freely available through the Microbiome Helper website
(https://github.com/mlangill/microbiome_helper/wiki). IMPORTANCE As the
microbiome field continues to grow, a multitude of researchers are learning how
to conduct proper microbiome experiments. We outline here a streamlined and
custom approach to processing samples from detailed sequencing library
construction to step-by-step bioinformatic standard operating procedures. This
allows for rapid and reliable microbiome analysis, allowing researchers to focus 
more on their experiment design and results. Our sequencing protocols,
bioinformatic tutorials, and bundled software are freely available through
Microbiome Helper. As the microbiome research field continues to evolve,
Microbiome Helper will be updated with new protocols, scripts, and training
materials.

DOI: 10.1128/mSystems.00127-16 
PMCID: PMC5209531
PMID: 28066818  [PubMed - in process]


60. mSystems. 2016 Dec 27;1(6). pii: e00101-16. doi: 10.1128/mSystems.00101-16.

From Genomes to Phenotypes: Traitar, the Microbial Trait Analyzer.

Weimann A(1), Mooren K(2), Frank J(3), Pope PB(3), Bremges A(4), McHardy AC(1).

Author information: 
(1)Computational Biology of Infection Research, Helmholtz Center for Infection
Research, Braunschweig, Germany; German Center for Infection Research (DZIF),
Partner Site Hannover-Braunschweig, Braunschweig, Germany; Department for
Algorithmic Bioinformatics, Heinrich Heine University, Düsseldorf, Germany.
(2)Computational Biology of Infection Research, Helmholtz Center for Infection
Research, Braunschweig, Germany; Department for Algorithmic Bioinformatics,
Heinrich Heine University, Düsseldorf, Germany. (3)Department of Chemistry,
Biotechnology and Food Science, Norwegian University of Life Sciences, Ås,
Norway. (4)Computational Biology of Infection Research, Helmholtz Center for
Infection Research, Braunschweig, Germany; German Center for Infection Research
(DZIF), Partner Site Hannover-Braunschweig, Braunschweig, Germany.

The number of sequenced genomes is growing exponentially, profoundly shifting the
bottleneck from data generation to genome interpretation. Traits are often used
to characterize and distinguish bacteria and are likely a driving factor in
microbial community composition, yet little is known about the traits of most
microbes. We describe Traitar, the microbial trait analyzer, which is a fully
automated software package for deriving phenotypes from a genome sequence.
Traitar provides phenotype classifiers to predict 67 traits related to the use of
various substrates as carbon and energy sources, oxygen requirement, morphology, 
antibiotic susceptibility, proteolysis, and enzymatic activities. Furthermore, it
suggests protein families associated with the presence of particular phenotypes. 
Our method uses L1-regularized L2-loss support vector machines for phenotype
assignments based on phyletic patterns of protein families and their evolutionary
histories across a diverse set of microbial species. We demonstrate reliable
phenotype assignment for Traitar to bacterial genomes from 572 species of eight
phyla, also based on incomplete single-cell genomes and simulated draft genomes. 
We also showcase its application in metagenomics by verifying and complementing a
manual metabolic reconstruction of two novel Clostridiales species based on draft
genomes recovered from commercial biogas reactors. Traitar is available at
https://github.com/hzi-bifo/traitar. IMPORTANCE Bacteria are ubiquitous in our
ecosystem and have a major impact on human health, e.g., by supporting digestion 
in the human gut. Bacterial communities can also aid in biotechnological
processes such as wastewater treatment or decontamination of polluted soils.
Diverse bacteria contribute with their unique capabilities to the functioning of 
such ecosystems, but lab experiments to investigate those capabilities are
labor-intensive. Major advances in sequencing techniques open up the opportunity 
to study bacteria by their genome sequences. For this purpose, we have developed 
Traitar, software that predicts traits of bacteria on the basis of their genomes.
It is applicable to studies with tens or hundreds of bacterial genomes. Traitar
may help researchers in microbiology to pinpoint the traits of interest, reducing
the amount of wet lab work required.

DOI: 10.1128/mSystems.00101-16 
PMCID: PMC5192078
PMID: 28066816  [PubMed - in process]


61. Front Mol Biosci. 2016 Dec 20;3:82. doi: 10.3389/fmolb.2016.00082. eCollection
2016.

PIPE-chipSAD: A Pipeline for the Analysis of High Density Arrays of Bacterial
Transcriptomes.

Bottini S(1), Del Tordello E(1), Fagnocchi L(1), Donati C(2), Muzzi A(1).

Author information: 
(1)GSK Vaccines Srl Siena, Italy. (2)Computational Biology Unit, Research and
Innovation Centre, Fondazione Edmund Mach San Michele all'Adige, Italy.

PIPE-chipSAD is a pipeline for bacterial transcriptome studies based on
high-density microarray experiments. The main algorithm chipSAD, integrates the
analysis of the hybridization signal with the genomic position of probes and
identifies portions of the genome transcribing for mRNAs. The pipeline includes a
procedure, align-chipSAD, to build a multiple alignment of transcripts
originating in the same locus in multiple experiments and provides a method to
compare mRNA expression across different conditions. Finally, the pipeline
includes anno-chipSAD a method to annotate the detected transcripts in comparison
to the genome annotation. Overall, our pipeline allows transcriptional profile
analysis of both coding and non-coding portions of the chromosome in a single
framework. Importantly, due to its versatile characteristics, it will be of wide 
applicability to analyse, not only microarray signals, but also data from other
high throughput technologies such as RNA-sequencing. The current PIPE-chipSAD
implementation is written in Python programming language and is freely available 
at https://github.com/silviamicroarray/chipSAD.

DOI: 10.3389/fmolb.2016.00082 
PMCID: PMC5167695
PMID: 28066774  [PubMed - in process]


62. Front Plant Sci. 2016 Dec 23;7:1936. doi: 10.3389/fpls.2016.01936. eCollection
2016.

A Machine Learning Approach to Predict Gene Regulatory Networks in Seed
Development in Arabidopsis.

Ni Y(1), Aghamirzaie D(2), Elmarakeby H(1), Collakova E(3), Li S(4), Grene R(3), 
Heath LS(1).

Author information: 
(1)Department of Computer Science, Virginia Polytechnic Institute and State
University Blacksburg, VA, USA. (2)Genetics, Bioinformatics and Computational
Biology, Virginia Polytechnic Institute and State University Blacksburg, VA, USA.
(3)Department of Plant Pathology, Physiology, and Weed Science, Virginia
Polytechnic Institute and State University Blacksburg, VA, USA. (4)Department of 
Crop and Soil Environmental Sciences, Virginia Polytechnic Institute and State
University Blacksburg, VA, USA.

Gene regulatory networks (GRNs) provide a representation of relationships between
regulators and their target genes. Several methods for GRN inference, both
unsupervised and supervised, have been developed to date. Because regulatory
relationships consistently reprogram in diverse tissues or under different
conditions, GRNs inferred without specific biological contexts are of limited
applicability. In this report, a machine learning approach is presented to
predict GRNs specific to developing Arabidopsis thaliana embryos. We developed
the Beacon GRN inference tool to predict GRNs occurring during seed development
in Arabidopsis based on a support vector machine (SVM) model. We developed both
global and local inference models and compared their performance, demonstrating
that local models are generally superior for our application. Using both the
expression levels of the genes expressed in developing embryos and prior known
regulatory relationships, GRNs were predicted for specific embryonic
developmental stages. The targets that are strongly positively correlated with
their regulators are mostly expressed at the beginning of seed development.
Potential direct targets were identified based on a match between the promoter
regions of these inferred targets and the cis elements recognized by specific
regulators. Our analysis also provides evidence for previously unknown inhibitory
effects of three positive regulators of gene expression. The Beacon GRN inference
tool provides a valuable model system for context-specific GRN inference and is
freely available at
https://github.com/BeaconProjectAtVirginiaTech/beacon_network_inference.git.

DOI: 10.3389/fpls.2016.01936 
PMCID: PMC5179539
PMID: 28066488  [PubMed - in process]


63. Bioinformatics. 2017 Jan 8. pii: btw738. doi: 10.1093/bioinformatics/btw738.
[Epub ahead of print]

caspo: a toolbox for automated reasoning on the response of logical signaling
networks families.

Videla S(1), Saez-Rodriguez J(2,)(3), Guziolowski C(4), Siegel A(5,)(6).

Author information: 
(1)LBSI, Fundación Instituto Leloir (IIBBA-CONICET), Buenos Aires, C1405BWE,
Argentina. (2)RWTH Aachen University, Faculty of Medicine, Joint Research Centre 
for Computational Biomedicine, Aachen D-52074, Germany. (3)European Molecular
Biology Laboratory-European Bioinformatics Institute (EMBL-EBI), Wellcome Trust
Genome Campus, Hinxton CB10 1SD, UK. (4)IRCCyN UMR CNRS 6597, École Centrale de
Nantes, Nantes 44321, France. (5)CNRS, UMR 6074-IRISA, 35042 Rennes, France.
(6)Dyliss project, INRIA, Campus de Beaulieu, Rennes 35000, France.

We introduce the caspo toolbox, a python package implementing a workflow for
reasoning on logical networks families. Our software allows researchers to (i)
LEARN: a family of logical networks derived from a given topology and explaining 
the experimental response to various perturbations; (ii) CLASSIFY: all logical
networks in a given family by their input-output behaviors; (iii) PREDICT: the
response of the system to every possible perturbation based on the ensemble of
predictions; (iv) DESIGN: new experimental perturbations to discriminate among a 
family of logical networks; and (v) CONTROL: a family of logical networks by
finding all interventions strategies forcing a set of targets into a desired
steady state.AVAILABILITY AND IMPLEMENTATION: caspo is open-source software
distributed under the GPLv3 license. Source code is publicly hosted at
http://github.com/bioasp/caspo CONTACT: anne.siegel@irisa.fr.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw738 
PMID: 28065903  [PubMed - as supplied by publisher]


64. Bioinformatics. 2017 Jan 8. pii: btw758. doi: 10.1093/bioinformatics/btw758.
[Epub ahead of print]

PRINCESS: Privacy-protecting Rare disease International Network Collaboration via
Encryption through Software guard extensionS.

Chen F(1), Wang S(1), Jiang X(1), Ding S(1), Lu Y(2), Kim J(1), Sahinalp SC(3),
Shimizu C(4), Burns JC(4), Wright VJ(5), Png E(6), Hibberd ML(6), Lloyd DD(7),
Yang H(1), Telenti A(8), Bloss CS(9), Fox D(10), Lauter K(11), Ohno-Machado L(1).

Author information: 
(1)Health System Department of Biomedical Informatics. (2)Department of
Electrical and Computer Engineering, University of California San Diego, La
Jolla, CA 92093, USA. (3)Department of Computer Science and Informatics, Indiana 
University, Bloomington, IN 47408, USA. (4)Department of Pediatrics, University
of California San Diego, La Jolla, CA 92093, USA. (5)Section of Pediatrics,
Imperial College London, London W2 1PG, UK. (6)Genome Institute of Singapore,
ASTAR, Singapore 138672, Singapore. (7)Deparment of Pediatrics, School of
Medicine, Emory University, Atlanta, GA 30322, USA. (8)J. Craig Venter Institute,
La Jolla, CA 92037, USA. (9)Department of Psychiatry, University of California
San Diego, La Jolla, CA 92093, USA. (10)School of Law, University of San Diego,
San Diego, CA 92110, USA. (11)Cryptography Group, Microsoft Research, San Diego, 
CA 92122, USA.

MOTIVATION: We introduce PRINCESS, a privacy-preserving international
collaboration framework for analyzing rare disease genetic data that are
distributed across different continents. PRINCESS leverages Software Guard
Extensions (SGX) and hardware for trustworthy computation. Unlike a traditional
international collaboration model, where individual-level patient DNA are
physically centralized at a single site, PRINCESS performs a secure and
distributed computation over encrypted data, fulfilling institutional policies
and regulations for protected health information.
RESULTS: To demonstrate PRINCESS' performance and feasibility, we conducted a
family-based allelic association study for Kawasaki Disease, with data hosted in 
three different continents. The experimental results show that PRINCESS provides 
secure and accurate analyses much faster than alternative solutions, such as
homomorphic encryption and garbled circuits (over 40 000× faster).
AVAILABILITY AND IMPLEMENTATION:
https://github.com/achenfengb/PRINCESS_opensource CONTACT:
shw070@ucsd.eduSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2017. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw758 
PMID: 28065902  [PubMed - as supplied by publisher]


65. Bioinformatics. 2017 Jan 8. pii: btw735. doi: 10.1093/bioinformatics/btw735.
[Epub ahead of print]

RENT+: an improved method for inferring local genealogical trees from haplotypes 
with recombination.

Mirzaei S(1), Wu Y(1).

Author information: 
(1)Department of Computer Science and Engineering, University of Connecticut,
Storrs, CT 06269, USA.

MOTIVATION: Haplotypes from one or multiple related populations share a common
genealogical history. If this shared genealogy can be inferred from haplotypes,
it can be very useful for many population genetics problems. However, with the
presence of recombination, the genealogical history of haplotypes is complex and 
cannot be represented by a single genealogical tree. Therefore, inference of
genealogical history with recombination is much more challenging than the case of
no recombination.
RESULTS: In this paper, we present a new approach called RENT+ for the inference 
of local genealogical trees from haplotypes with the presence of recombination.
RENT+ builds on a previous genealogy inference approach called RENT, which infers
a set of related genealogical trees at different genomic positions.
RENT+ represents a significant improvement over RENT in the sense that it is more
effective in extracting information contained in the haplotype data about the
underlying genealogy than RENT The key components of RENT+ are several greatly
enhanced genealogy inference rules. Through simulation, we show that RENT+ is
more efficient and accurate than several existing genealogy inference methods. As
an application, we apply RENT+ in the inference of population demographic history
from haplotypes, which outperforms several existing methods.
AVAILABILITY AND IMPLEMENTATION: RENT+ is implemented in Java, and is freely
available for download from: https://github.com/SajadMirzaei/RentPlus CONTACTS: :
sajad@engr.uconn.edu or ywu@engr.uconn.eduSupplementary information:
Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw735 
PMID: 28065901  [PubMed - as supplied by publisher]


66. Bioinformatics. 2017 Jan 8. pii: btw750. doi: 10.1093/bioinformatics/btw750.
[Epub ahead of print]

MetaSpark: a spark-based distributed processing tool to recruit metagenomic reads
to reference genomes.

Zhou W(1), Li R(2,)(3), Yuan S(1), Liu C(1), Yao S(1), Luo J(4), Niu B(2,)(3).

Author information: 
(1)School of Software, Yunnan University, Kunming, China. (2)Computer Network
Information Center of Chinese Academy of Sciences, Beijing, China. (3)University 
of Chinese Academy of Sciences, Beijing 100190, China. (4)School of Life Sciences
and State Key Laboratory for Conservation and Utilization of Bio-Resources in
Yunnan, Yunnan University, Kunming, China.

With the advent of next-generation sequencing, traditional bioinformatics tools
are challenged by massive raw metagenomic datasets. One of the bottlenecks of
metagenomic studies is lack of large-scale and cloud computing suitable data
analysis tools. In this paper, we proposed a Spark -: based tool, called
MetaSpark, to recruit metagenomic reads to reference genomes. MetaSpark benefits 
from the distributed data set (RDD) of Spark, which makes it able to cache data
set in memory across cluster nodes and scale well with the datasets. Compared
with previous metagenomics recruitment tools, MetaSpark recruited significantly
more reads than many programs such as SOAP2, BWA and LAST and increased recruited
reads by ∼4% compared with FR-HIT when there were 1 million reads and 0.75 GB
references. Different test cases demonstrate MetaSpark's scalability and overall 
high performance.AVAILABILITY: https://github.com/zhouweiyg/metaspark CONTACT:
bniu@sccas.cn, jingluo@ynu.edu.cnSupplementary information: Supplementary data
are available at Bioinformatics online.

© The Author 2017. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw750 
PMID: 28065898  [PubMed - as supplied by publisher]


67. Database (Oxford). 2017 Jan 6;2017. pii: baw160. doi: 10.1093/database/baw160.
Print 2017.

FirebrowseR: an R client to the Broad Institute's Firehose Pipeline.

Deng M(1), Brägelmann J(2), Kryukov I(3), Saraiva-Agostinho N(4,)(5), Perner
S(6).

Author information: 
(1)Pathology of the University Medical Center Schleswig-Holstein, Campus Luebeck 
and the Research Center Borstel, Leibniz Center for Medicine and Biosciences,
23538 Luebeck and 23845 Borstel, Germany mario.deng@uksh.de. (2)Molecular
Pathology & Department of Translational Genomics, University Hospital Cologne,
Weyertal 115b, Cologne, 50931, Germany. (3)Department of Biochemistry and
Molecular Biology and Alberta Children's Hospital Research Institute Calgary
Biochemistry and Molecular Biology Doctoral Program in Bioinformatics, University
of Calgary, Cumming School of Medicine, Alberta, Canada. (4)Instituto de Medicina
Molecular, Faculdade de Medicina, Universidade de Lisboa, 1649-028 Lisboa,
Portugal and. (5)Departamento de Informática, Faculdade de Ciências, Universidade
de Lisboa, 1749-016 Lisboa, Portugal. (6)Pathology of the University Medical
Center Schleswig-Holstein, Campus Luebeck and the Research Center Borstel,
Leibniz Center for Medicine and Biosciences, 23538 Luebeck and 23845 Borstel,
Germany.

With its Firebrowse service (http://firebrowse.org/) the Broad Institute is
making large-scale multi-platform omics data analysis results publicly available 
through a Representational State Transfer (REST) Application Programmable
Interface (API). Querying this database through an API client from an arbitrary
programming environment is an essential task, allowing other developers and
researchers to focus on their analysis and avoid data wrangling. Hence, as a
first result, we developed a workflow to automatically generate, test and deploy 
such clients for rapid response to API changes. Its underlying infrastructure, a 
combination of free and publicly available web services, facilitates the
development of API clients. It decouples changes in server software from the
client software by reacting to changes in the RESTful service and removing direct
dependencies on a specific implementation of an API. As a second result,
FirebrowseR, an R client to the Broad Institute's RESTful Firehose Pipeline, is
provided as a working example, which is built by the means of the presented
workflow. The package's features are demonstrated by an example analysis of
cancer gene expression data.Database URL: https://github.com/mariodeng/.

© The Author(s) 2017. Published by Oxford University Press.

DOI: 10.1093/database/baw160 
PMCID: PMC5216271
PMID: 28062517  [PubMed - in process]


68. Bioinformatics. 2017 Jan 5. pii: btw749. doi: 10.1093/bioinformatics/btw749.
[Epub ahead of print]

Algorithm sensitivity analysis and parameter tuning for tissue image segmentation
pipelines.

Teodoro G(1,)(2), Kurç TM(2,)(3), Taveira LF(1), Melo AC(1), Gao Y(2), Kong J(4),
Saltz JH(2).

Author information: 
(1)Department of Computer Science, University of Brasília, Brasília 70910-900,
Brazil. (2)Biomedical Informatics Department, Stony Brook University, Stony
Brook, NY 11794-8322, USA. (3)Scientific Data Group, Oak Ridge National
Laboratory, Oak Ridge, TN, USA. (4)Biomedical Informatics Department, Emory
University, Atlanta, GA 30322, USA.

MOTIVATION: Sensitivity analysis and parameter tuning are important processes in 
large-scale image analysis. They are very costly because the image analysis
workflows are required to be executed several times to systematically correlate
output variations with parameter changes or to tune parameters. An integrated
solution with minimum user interaction that uses effective methodologies and high
performance computing is required to scale these studies to large imaging
datasets and expensive analysis workflows.
RESULTS: The experiments with two segmentation workflows show that the proposed
approach can (i) quickly identify and prune parameters that are non-influential; 
(ii) search a small fraction (about 100 points) of the parameter search space
with billions to trillions of points and improve the quality of segmentation
results (Dice and Jaccard metrics) by as much as 1.42× compared to the results
from the default parameters; (iii) attain good scalability on a high performance 
cluster with several effective optimizations.
CONCLUSIONS: Our work demonstrates the feasibility of performing sensitivity
analyses, parameter studies and auto-tuning with large datasets. The proposed
framework can enable the quantification of error estimations and output
variations in image segmentation pipelines.
AVAILABILITY AND IMPLEMENTATION: Source code:
https://github.com/SBU-BMI/region-templates/ CONTACT: teodoro@unb.brSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2017. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw749 
PMID: 28062445  [PubMed - as supplied by publisher]


69. Bioinformatics. 2017 Jan 6. pii: btw718. doi: 10.1093/bioinformatics/btw718.
[Epub ahead of print]

SINE_scan: an efficient tool to discover short interspersed nuclear elements
(SINEs) in large-scale genomic datasets.

Mao H(1), Wang H(1,)(2).

Author information: 
(1)T-Life Research Center, Department of Physics, Fudan University, Shanghai
200433, People's Republic of China. (2)Department of Genetics, University of
Georgia, Athens, GA 30602, USA.

MOTIVATION: Short Interspersed Nuclear Elements (SINEs) are transposable elements
(TEs) that amplify through a copy-and-paste mode via RNA intermediates. The
computational identification of new SINEs are challenging because of their weak
structural signals and rapid diversification in sequences.
RESULTS: Here we report SINE_Scan, a highly efficient program to predict SINE
elements in genomic DNA sequences. SINE_Scan integrates hallmark of SINE
transposition, copy number and structural signals to identify a SINE element.
SINE_Scan outperforms the previously published de novo SINE discovery program. It
shows high sensitivity and specificity in 19 plant and animal genome assemblies, 
of which sizes vary from 120 Mb to 3.5 Gb. It identifies numerous new families
and substantially increases the estimation of the abundance of SINEs in these
genomes.
AVAILABILITY AND IMPLEMENTATION: The code of SINE_Scan is freely available at
http://github.com/maohlzj/SINE_Scan, implemented in PERL and supported on Linux.
CONTACT: wangh8@fudan.edu.cnSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2017. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw718 
PMID: 28062442  [PubMed - as supplied by publisher]


70. BMC Microbiol. 2017 Jan 7;17(1):12. doi: 10.1186/s12866-016-0920-3.

Pyviko: an automated Python tool to design gene knockouts in complex viruses with
overlapping genes.

Taylor LJ(1,)(2), Strebel K(3).

Author information: 
(1)Viral Biochemistry Section, Laboratory of Molecular Microbiology, National
Institute of Allergy and Infectious Diseases, National Institutes of Health,
Bethesda, MD, USA. louist@upenn.edu. (2)Cell and Molecular Biology Graduate
Group, Perelman School of Medicine, University of Pennsylvania Philadelphia,
Pennsylvania, USA. louist@upenn.edu. (3)Viral Biochemistry Section, Laboratory of
Molecular Microbiology, National Institute of Allergy and Infectious Diseases,
National Institutes of Health, Bethesda, MD, USA.

BACKGROUND: Gene knockouts are a common tool used to study gene function in
various organisms. However, designing gene knockouts is complicated in viruses,
which frequently contain sequences that code for multiple overlapping genes.
Designing mutants that can be traced by the creation of new or elimination of
existing restriction sites further compounds the difficulty in experimental
design of knockouts of overlapping genes. While software is available to rapidly 
identify restriction sites in a given nucleotide sequence, no existing software
addresses experimental design of mutations involving multiple overlapping amino
acid sequences in generating gene knockouts.
RESULTS: Pyviko performed well on a test set of over 240,000 gene pairs collected
from viral genomes deposited in the National Center for Biotechnology Information
Nucleotide database, identifying a point mutation which added a premature stop
codon within the first 20 codons of the target gene in 93.2% of all tested
gene-overprinted gene pairs. This shows that Pyviko can be used successfully in a
wide variety of contexts to facilitate the molecular cloning and study of viral
overprinted genes.
CONCLUSIONS: Pyviko is an extensible and intuitive Python tool for designing
knockouts of overlapping genes. Freely available as both a Python package and a
web-based interface ( http://louiejtaylor.github.io/pyViKO/ ), Pyviko simplifies 
the experimental design of gene knockouts in complex viruses with overlapping
genes.

DOI: 10.1186/s12866-016-0920-3 
PMCID: PMC5219722
PMID: 28061810  [PubMed - in process]


71. BMC Genomics. 2017 Jan 7;18(1):49. doi: 10.1186/s12864-016-3412-9.

Organelle_PBA, a pipeline for assembling chloroplast and mitochondrial genomes
from PacBio DNA sequencing data.

Soorni A(1,)(2), Haak D(3), Zaitlin D(4), Bombarely A(5).

Author information: 
(1)Department of Horticulture, Virginia Polytechnic Institute and State
University, Blacksburg, VA, 24061, USA. (2)Department of Horticulture, Faculty of
Horticultural Sciences and Plant Protection, University of Tehran, Karaj, 31587, 
Iran. (3)Department of Plant Pathology, Physiology and Weed Science, Virginia
Polytechnic Institute and State University, Blacksburg, VA, 24061, USA.
(4)Kentucky Tobacco Research and Development Center (KTRDC), University of
Kentucky, Lexington, KY, 40546, USA. (5)Department of Horticulture, Virginia
Polytechnic Institute and State University, Blacksburg, VA, 24061, USA.
aurebg@vt.edu.

BACKGROUND: The development of long-read sequencing technologies, such as
single-molecule real-time (SMRT) sequencing by PacBio, has produced a revolution 
in the sequencing of small genomes. Sequencing organelle genomes using PacBio
long-read data is a cost effective, straightforward approach. Nevertheless, the
availability of simple-to-use software to perform the assembly from raw reads is 
limited at present.
RESULTS: We present Organelle-PBA, a Perl program designed specifically for the
assembly of chloroplast and mitochondrial genomes. For chloroplast genomes, the
program selects the chloroplast reads from a whole genome sequencing pool, maps
the reads to a reference sequence from a closely related species, and then
performs read correction and de novo assembly using Sprai. Organelle-PBA
completes the assembly process with the additional step of scaffolding by
SSPACE-LongRead. The program then detects the chloroplast inverted repeats and
reassembles and re-orients the assembly based on the organelle origin of the
reference. We have evaluated the performance of the software using PacBio reads
from different species, read coverage, and reference genomes. Finally, we present
the assembly of two novel chloroplast genomes from the species Picea glauca
(Pinaceae) and Sinningia speciosa (Gesneriaceae).
CONCLUSION: Organelle-PBA is an easy-to-use Perl-based software pipeline that was
written specifically to assemble mitochondrial and chloroplast genomes from whole
genome PacBio reads. The program is available at
https://github.com/aubombarely/Organelle_PBA .

DOI: 10.1186/s12864-016-3412-9 
PMCID: PMC5219736
PMID: 28061749  [PubMed - in process]


72. Syst Biol. 2017 Jan 5. pii: syw121. doi: 10.1093/sysbio/syw121. [Epub ahead of
print]

ProtASR: An Evolutionary Framework for Ancestral Protein Reconstruction with
Selection on Folding Stability.

Arenas M(1,)(2,)(3,)(4), Weber CC(5), Liberles DA(6,)(5), Bastolla U(3).

Author information: 
(1)Instituto de Investigação e Inovação em Saúde (i3S), University of Porto,
Porto, Portugal. (2)Institute of Molecular Pathology and Immunology of the
University of Porto (IPATIMUP), Porto, Portugal. (3)Centre for Molecular Biology 
Severo Ochoa (CBMSO), Consejo Superior de Investigaciones Científicas (CSIC),
Madrid, Spain. (4)Department of Biochemistry, Genetics and Immunology, University
of Vigo, Vigo, Spain. (5)Department of Biology and Center for Computational
Genetics and Genomics, Temple University, Philadelphia, PA 19122, USA.
(6)Department of Molecular Biology, University of Wyoming, Laramie, WY 82071,
USA.

The computational reconstruction of ancestral proteins provides information on
past biological events and has practical implications for biomedicine and
biotechnology. Currently available tools for ancestral sequence reconstruction
(ASR) are often based on empirical amino acid substitution models that assume
that all sites evolve at the same rate and under the same process. However, this 
assumption is frequently violated because protein evolution is highly
heterogeneous due to different selective constraints among sites. Here, we
present ProtASR, a new evolutionary framework to infer ancestral protein
sequences accounting for selection on protein stability. First, ProtASR generates
site-specific substitution matrices through the structurally constrained
mean-field substitution model (MF), which considers both unfolding and misfolding
stability. We previously showed that MF models outperform empirical amino acid
substitution models, as well as other structurally constrained substitution
models, both in terms of likelihood and correctly inferring amino acid
distributions across sites. In the second step, ProtASR adapts a well-established
maximum-likelihood (ML) ASR procedure to infer ancestral proteins under MF
models. A known bias of ML ASR methods is that they tend to overestimate the
stability of ancestral proteins by under-estimating the frequency of deleterious 
mutations. We compared ProtASR under MF to two empirical substitution models (JTT
and CAT), reconstructing the ancestral sequences of simulated proteins. ProtASR
yields reconstructed proteins with less biased stabilities, which are
significantly closer to those of the simulated proteins. Analysis of extant
protein families suggests that folding stability evolves through time across
protein families, potentially reflecting neutral fluctuation. Some families
exhibit a more constant protein folding stability, while others are more
variable. ProtASR is freely available from
https://github.com/miguelarenas/protasr and includes detailed documentation and
ready-to-use examples. It runs in seconds/minutes depending on protein length and
alignment size.

© The Author(s) 2017. Published by Oxford University Press, on behalf of the
Society of Systematic Biologists. All rights reserved. For Permissions, please
email: journals.permissions@oup.com.

DOI: 10.1093/sysbio/syw121 
PMID: 28057858  [PubMed - as supplied by publisher]


73. Mol Biol Cell. 2017 Jan 5. pii: mbc.E16-06-0370. doi: 10.1091/mbc.E16-06-0370.
[Epub ahead of print]

Nano Random Forests to mine protein complexes and their relationships in
quantitative proteomics data.

Montaño-Gutierrez LF(1), Ohta S(1,)(2), Kustatscher G(1), Earnshaw WC(3),
Rappsilber J(3,)(4).

Author information: 
(1)*Wellcome Trust Centre for Cell Biology, School of Biological Sciences,
University of Edinburgh, Edinburgh EH9 3BF, United Kingdom. (2)Center for
Innovative and Translational Medicine, Medical School, Kochi University, Kohasu, 
Oko-cho, Nankoku, Kochi 783-8505, JAPAN. (3)*Wellcome Trust Centre for Cell
Biology, School of Biological Sciences, University of Edinburgh, Edinburgh EH9
3BF, United Kingdom Bill.Earnshaw@ed.ac.uk Juri.Rappsilber@ed.ac.uk. (4)Chair of 
Bioanalytics, Institute of Biotechnology, Technische Universität Berlin, 13355
Berlin, Germany.

Ever-increasing numbers of quantitative proteomics datasets constitute a
currently underexploited resource for investigating protein function.
Multi-protein complexes often follow consistent trends in these experiments,
which could provide insights about their biology. Yet, as more experiments are
considered, a complex's signature may become conditional and less
identifiable. Previously, we successfully distinguished the general proteomic
signature of genuine chromosomal proteins from hitchhikers using the Random
Forests (RFs) machine learning algorithm. In this technical note, we tested
whether small protein complexes could define distinguishable signatures of their 
own, despite the assumption that machine learning needs large training sets. We
show, with simulated and real proteomics data, that RFs can detect small protein 
complexes and relationships between them. We identified several complexes in
quantitative proteomics results of wild-type and knock-out mitotic chromosomes.
Other proteins covaried strongly with these complexes, suggesting novel
functional links for later study. Integrating the RF analysis for several
complexes revealed known interdependencies among kinetochore subunits, and a
novel dependency between the inner kinetochore and condensin. Ribosomal proteins,
although identified, remained independent of kinetochore subcomplexes. Together, 
these results show that this complex-oriented RF (NanoRF) approach can integrate 
proteomics data to uncover subtle protein relationships. Our NanoRF pipeline is
available at https://github.com/EarnshawLab/NanoRF.

© 2017 by The American Society for Cell Biology.

DOI: 10.1091/mbc.E16-06-0370 
PMID: 28057767  [PubMed - as supplied by publisher]


74. Bioinformatics. 2017 Jan 5. pii: btx001. doi: 10.1093/bioinformatics/btx001.
[Epub ahead of print]

AFRESh: an adaptive framework for compression of reads and assembled sequences
with random access functionality.

Paridaens T(1), Van Wallendael G(1), De Neve W(1,)(2,)(3), Lambert P(1).

Author information: 
(1)Data Science Lab, Ghent University - iMinds, Ghent 9000, Belgium. (2)Center
for Biotech Data Science, Ghent University Global Campus, Songdo, Incheon
305-701, Republic of Korea. (3)Image and Video Systems Lab, KAIST, Daejeon
305-732, Republic of Korea.

MOTIVATION: The past decade has seen the introduction of new technologies that
lowered the cost of genomic sequencing increasingly. We can even observe that the
cost of sequencing is dropping significantly faster than the cost of storage and 
transmission. The latter motivates a need for continuous improvements in the area
of genomic data compression, not only at the level of effectiveness (compression 
rate), but also at the level of functionality (e.g. random access),
configurability (effectiveness versus complexity, coding tool set …) and
versatility (support for both sequenced reads and assembled sequences). In that
regard, we can point out that current approaches mostly do not support random
access, requiring full files to be transmitted, and that current approaches are
restricted to either read or sequence compression.
RESULTS: We propose AFRESh, an adaptive framework for no-reference compression of
genomic data with random access functionality, targeting the effective
representation of the raw genomic symbol streams of both reads and assembled
sequences. AFRESh makes use of a configurable set of prediction and encoding
tools, extended by a Context-Adaptive Binary Arithmetic Coding scheme (CABAC), to
compress raw genetic codes. To the best of our knowledge, our paper is the first 
to describe an effective implementation CABAC outside of its' original
application. By applying CABAC, the compression effectiveness improves by up to
19% for assembled sequences and up to 62% for reads. By applying AFRESh to the
genomic symbols of the MPEG genomic compression test set for reads, a compression
gain is achieved of up to 51% compared to SCALCE, 42% compared to LFQC and 44%
compared to ORCOM. When comparing to generic compression approaches, a
compression gain is achieved of up to 41% compared to GNU Gzip and 22% compared
to 7-Zip at the Ultra setting. Additionaly, when compressing assembled sequences 
of the Human Genome, a compression gain is achieved up to 34% compared to GNU
Gzip and 16% compared to 7-Zip at the Ultra setting.
AVAILABILITY AND IMPLEMENTATION: A Windows executable version can be downloaded
at https://github.com/tparidae/AFresh CONTACT: tom.paridaens@ugent.be.

© The Author 2017. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btx001 
PMID: 28057687  [PubMed - as supplied by publisher]


75. Bioinformatics. 2017 Jan 5. pii: btw832. doi: 10.1093/bioinformatics/btw832.
[Epub ahead of print]

ntCard: a streaming algorithm for cardinality estimation in genomics data.

Mohamadi H(1,)(2), Khan H(1,)(2), Birol I(1,)(2).

Author information: 
(1)Canada's Michael Smith Genome Sciences Centre, British Columbia Cancer Agency,
Vancouver, BC, V5Z 4S6, Canada. (2)Faculty of Science, University of British
Columbia, Vancouver, BC, V6T 1Z4, Canada.

MOTIVATION: Many bioinformatics algorithms are designed for the analysis of
sequences of some uniform length, conventionally referred to as k-mers. These
include de Bruijn graph assembly methods and sequence alignment tools. An
efficient algorithm to enumerate the number of unique k-mers, or even better, to 
build a histogram of k-mer frequencies would be desirable for these tools and
their downstream analysis pipelines. Among other applications, estimated
frequencies can be used to predict genome sizes, measure sequencing error rates, 
and tune runtime parameters for analysis tools. However, calculating a k-mer
histogram from large volumes of sequencing data is a challenging task.
RESULTS: Here, we present ntCard, a streaming algorithm for estimating the
frequencies of k-mers in genomics datasets. At its core, ntCard uses the ntHash
algorithm to efficiently compute hash values for streamed sequences. It then
samples the calculated hash values to build a reduced representation multiplicity
table describing the sample distribution. Finally, it uses a statistical model to
reconstruct the population distribution from the sample distribution. We have
compared the performance of ntCard and other cardinality estimation algorithms.
We used three datasets of 480 GB, 500 GB and 2.4 TB in size, where the first two 
representing whole genome shotgun sequencing experiments on the human genome and 
the last one on the white spruce genome. Results show ntCard estimates k-mer
coverage frequencies >15× faster than the state-of-the-art algorithms, using
similar amount of memory, and with higher accuracy rates. Thus, our benchmarks
demonstrate ntCard as a potentially enabling technology for large-scale genomics 
applications.
AVAILABILITY AND IMPLEMENTATION: ntCard is written in C ++ and is released under 
the GPL license. It is freely available at https://github.com/bcgsc/ntCard
CONTACT: hmohamadi@bcgsc.ca or ibirol@bcgsc.caSupplementary information:
Supplementary data are available at Bioinformatics online.

© The Author 2017. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw832 
PMID: 28057681  [PubMed - as supplied by publisher]


76. Bioinformatics. 2017 Jan 5. pii: btw761. doi: 10.1093/bioinformatics/btw761.
[Epub ahead of print]

PanViz: interactive visualization of the structure of functionally annotated
pangenomes.

Pedersen TL(1,)(2), Nookaew I(3,)(4), Wayne Ussery D(3,)(4), Månsson M(2).

Author information: 
(1)Center for Biological Sequence Analysis, Department of Systems Biology, The
Technical University of Denmark, DK-2800 Lyngby, Denmark. (2)Assays, Culture and 
Enzymes Division, DK-2970 Hørsholm, Denmark. (3)Comparative Genomics Group,
Biosciences Division, Oak Ridge National Laboratory, Oak Ridge, TN, USA.
(4)Department Biomedical Informatics, College of Medicine, University of Arkansas
for Medical Sciences, Little Rock, AR, USA.

PanViz is a novel, interactive, visualization tool for pangenome analysis. PanViz
allows visualization of changes in gene group (groups of similar genes across
genomes) classification as different subsets of pangenomes are selected, as well 
as comparisons of individual genomes to pangenomes with gene ontology based
navigation of gene groups. Furthermore it allows for rich and complex visual
querying of gene groups in the pangenome. PanViz visualizations require no
external programs and are easily sharable, allowing for rapid pangenome
analyses.AVAILABILITY AND IMPLEMENTATION: PanViz is written entirely in
JavaScript and is available on https://github.com/thomasp85/PanViz A companion R 
package that facilitates the creation of PanViz visualizations from a range of
data formats is released through Bioconductor and is available at
https://bioconductor.org/packages/PanVizGenerator CONTACT:
thomasp85@gmail.comSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2017. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw761 
PMID: 28057677  [PubMed - as supplied by publisher]


77. J Biomed Inform. 2017 Jan 2. pii: S1532-0464(16)30188-5. doi:
10.1016/j.jbi.2016.12.014. [Epub ahead of print]

SemanticSCo: a Platform to Support the Semantic Composition of Services for Gene 
Expression Analysis.

Guardia GD(1), Pires LF(2), da Silva EG(2), de Farias CR(3).

Author information: 
(1)Department of Computer Science and Mathematics - Faculty of Philosophy,
Sciences and Letters at Ribeirão Preto (FFCLRP) - University of São Paulo (USP), 
Ribeirão Preto, Brazil. (2)Faculty of Electrical Engineering, Mathematics and
Computer Science - University of Twente, Enschede, Netherlands. (3)Department of 
Computer Science and Mathematics - Faculty of Philosophy, Sciences and Letters at
Ribeirão Preto (FFCLRP) - University of São Paulo (USP), Ribeirão Preto, Brazil. 
Electronic address: farias@ffclrp.usp.br.

Gene expression studies often require the combined use of a number of analysis
tools. However, manual integration of analysis tools can be cumbersome and error 
prone. To support a higher level of automation in the integration process,
efforts have been made in the biomedical domain towards the development of
semantic web services and supporting composition environments. Yet, most
environments consider only the execution of simple service behaviours and
requires users to focus on technical details of the composition process. We
propose a novel approach to the semantic composition of gene expression analysis 
services that addresses the shortcomings of the existing solutions. Our approach 
includes an architecture designed to support the service composition process for 
gene expression analysis, and a flexible strategy for the (semi) automatic
composition of semantic web services. Finally, we implement a supporting platform
called SemanticSCo to realize the proposed composition approach and demonstrate
its functionality by successfully reproducing a microarray study documented in
the literature. The SemanticSCo platform provides support for the composition of 
RESTful web services semantically annotated using SAWSDL. Our platform also
supports the definition of constraints/conditions regarding the order in which
service operations should be invoked, thus enabling the definition of complex
service behaviours. Our proposed solution for semantic web service composition
takes into account the requirements of different stakeholders and addresses all
phases of the service composition process. It also provides support for the
definition of analysis workflows at a high-level of abstraction, thus enabling
users to focus on biological research issues rather than on the technical details
of the composition process. The SemanticSCo source code is available at
https://github.com/usplssb/SemanticSCo.

Copyright © 2017. Published by Elsevier Inc.

DOI: 10.1016/j.jbi.2016.12.014 
PMID: 28057566  [PubMed - as supplied by publisher]


78. BMC Bioinformatics. 2017 Jan 5;18(1):18. doi: 10.1186/s12859-016-1415-9.

Predicting potential drug-drug interactions by integrating chemical, biological, 
phenotypic and network data.

Zhang W(1,)(2), Chen Y(3), Liu F(4), Luo F(5,)(6), Tian G(5,)(6), Li X(5,)(6).

Author information: 
(1)State Key Lab of Software Engineering, Wuhan University, Wuhan, 430072, China.
zhangwen@whu.edu.cn. (2)School of Computer, Wuhan University, Wuhan, 430072,
China. zhangwen@whu.edu.cn. (3)School of Mathematics and Statistics, Wuhan
University, Wuhan, 430072, China. (4)International School of software, Wuhan
University, Wuhan, 430072, China. (5)State Key Lab of Software Engineering, Wuhan
University, Wuhan, 430072, China. (6)School of Computer, Wuhan University, Wuhan,
430072, China.

BACKGROUND: Drug-drug interactions (DDIs) are one of the major concerns in drug
discovery. Accurate prediction of potential DDIs can help to reduce unexpected
interactions in the entire lifecycle of drugs, and are important for the drug
safety surveillance.
RESULTS: Since many DDIs are not detected or observed in clinical trials, this
work is aimed to predict unobserved or undetected DDIs. In this paper, we collect
a variety of drug data that may influence drug-drug interactions, i.e., drug
substructure data, drug target data, drug enzyme data, drug transporter data,
drug pathway data, drug indication data, drug side effect data, drug off side
effect data and known drug-drug interactions. We adopt three representative
methods: the neighbor recommender method, the random walk method and the matrix
perturbation method to build prediction models based on different data. Thus, we 
evaluate the usefulness of different information sources for the DDI prediction. 
Further, we present flexible frames of integrating different models with suitable
ensemble rules, including weighted average ensemble rule and classifier ensemble 
rule, and develop ensemble models to achieve better performances.
CONCLUSIONS: The experiments demonstrate that different data sources provide
diverse information, and the DDI network based on known DDIs is one of most
important information for DDI prediction. The ensemble methods can produce better
performances than individual methods, and outperform existing state-of-the-art
methods. The datasets and source codes are available at
https://github.com/zw9977129/drug-drug-interaction/ .

DOI: 10.1186/s12859-016-1415-9 
PMCID: PMC5217341
PMID: 28056782  [PubMed - in process]


79. IEEE/ACM Trans Comput Biol Bioinform. 2015 Dec 23. doi:
10.1109/TCBB.2015.2511750. [Epub ahead of print]

A graph-theoretical approach for motif discovery in protein sequences.

Czeizler E, Hirvola T, Karhu K.

Motif recognition is a challenging problem in bioinformatics due to the diversity
of protein motifs. Many existing algorithms identify motifs of a given length,
thus being either not applicable or not efficient when searching simultaneously
for motifs of various lengths. Searching for gapped motifs, although very
important, is a highly time-consuming task due to the combinatorial explosion of 
possible combinations implied by the consideration of long gaps. We introduce a
new graph theoretical approach to identify motifs of various lengths, both with
and without gaps. We compare our approach with two widely used methods: MEME and 
GLAM2 analyzing both the quality of the results and the required computational
time. Our method provides results of a slightly higher level of quality than MEME
but at a much faster rate, i.e., one eighth of MEME's query time. By using
similarity indexing, we drop the query times down to an average of approximately 
one sixth of the ones required by GLAM2, while achieving a slightly higher level 
of quality of the results. More precisely, for sequence collections smaller than 
50000 bytes GLAM2 is 13 times slower, while being at least as fast as our method 
on larger ones. The source code of our C++ implementation is freely available in 
GitHub: https://github.com/hirvolt1/debruijn-motif.

DOI: 10.1109/TCBB.2015.2511750 
PMID: 28055896  [PubMed - as supplied by publisher]


80. J Cheminform. 2016 Dec 20;8:72. doi: 10.1186/s13321-016-0185-8. eCollection 2016.

osFP: a web server for predicting the oligomeric states of fluorescent proteins.

Simeon S(1), Shoombuatong W(1), Anuwongcharoen N(1), Preeyanon L(2),
Prachayasittikul V(2), Wikberg JE(3), Nantasenamat C(1).

Author information: 
(1)Center of Data Mining and Biomedical Informatics, Faculty of Medical
Technology, Mahidol University, Bangkok, 10700 Thailand. (2)Department of
Community Medical Technology, Faculty of Medical Technology, Mahidol University, 
Bangkok, 10700 Thailand. (3)Department of Pharmaceutical Biosciences, Uppsala
University, 751 24 Uppsala, Sweden.

BACKGROUND: Currently, monomeric fluorescent proteins (FP) are ideal markers for 
protein tagging. The prediction of oligomeric states is helpful for enhancing
live biomedical imaging. Computational prediction of FP oligomeric states can
accelerate the effort of protein engineering efforts of creating monomeric FPs.
To the best of our knowledge, this study represents the first computational model
for predicting and analyzing FP oligomerization directly from the amino acid
sequence.
RESULTS: After data curation, an exhaustive data set consisting of 397
non-redundant FP oligomeric states was compiled from the literature. Results from
benchmarking of the protein descriptors revealed that the model built with amino 
acid composition descriptors was the top performing model with accuracy,
sensitivity and specificity in excess of 80% and MCC greater than 0.6 for all
three data subsets (e.g. training, tenfold cross-validation and external sets).
The model provided insights on the important residues governing the
oligomerization of FP. To maximize the benefit of the generated predictive model,
it was implemented as a web server under the R programming environment.
CONCLUSION: osFP affords a user-friendly interface that can be used to predict
the oligomeric state of FP using the protein sequence. The advantage of osFP is
that it is platform-independent meaning that it can be accessed via a web browser
on any operating system and device. osFP is freely accessible at
http://codes.bio/osfp/ while the source code and data set is provided on GitHub
at https://github.com/chaninn/osFP/.Graphical Abstract.

DOI: 10.1186/s13321-016-0185-8 
PMCID: PMC5167684
PMID: 28053671  [PubMed - in process]


81. Nucleic Acids Res. 2017 Jan 3. pii: gkw1306. doi: 10.1093/nar/gkw1306. [Epub
ahead of print]

FEELnc: a tool for long non-coding RNA annotation and its application to the dog 
transcriptome.

Wucher V(1), Legeai F(2,)(3), Hédan B(1), Rizk G(3), Lagoutte L(1), Leeb T(4),
Jagannathan V(4), Cadieu E(1), David A(2), Lohi H(5,)(6), Cirera S(7), Fredholm
M(7), Botherel N(1), Leegwater PA(8), Le Béguec C(1), Fieten H(8), Johnson J(9), 
Alföldi J(9), André C(1), Lindblad-Toh K(9,)(10), Hitte C(1), Derrien T(11).

Author information: 
(1)Institut Génétique et Développement de Rennes, CNRS, UMR6290, University
Rennes1, Rennes, Cedex 35043, France. (2)IGEPP, BIPAA, INRA, Campus Beaulieu, Le 
Rheu 35653, France. (3)Institut National de Recherche en Informatique et en
Automatique, Institut de Recherche en Informatique et Systèmes Aléatoires,
Genscale, Campus Beaulieu, Rennes 35042, France. (4)Institute of Genetics,
Vetsuisse Faculty, University of Bern, Bern 3001, Switzerland. (5)Department of
Veterinary Biosciences and Research Programs Unit, Molecular Neurology,
University of Helsinki, PO Box 63, Helsinki 00014, Finland. (6)The Folkhälsan
Institute of Genetics, Helsinki 00014, Finland. (7)Department of Veterinary
Clinical and Animal Sciences, Faculty of Health and Medical Sciences, University 
of Copenhagen, Copenhagen 1870, Denmark. (8)Department of Clinical Sciences of
Companion Animals, Faculty of Veterinary Medicine, Utrecht University, Utrecht
3584CM, the Netherlands. (9)Broad Institute of MIT and Harvard, Cambridge, MA
02142, USA. (10)Science for Life Laboratory, Department of Medical Biochemistry
and Microbiology, Uppsala University, Uppsala 751 23, Sweden. (11)Institut
Génétique et Développement de Rennes, CNRS, UMR6290, University Rennes1, Rennes, 
Cedex 35043, France tderrien@univ-rennes1.fr.

Whole transcriptome sequencing (RNA-seq) has become a standard for cataloguing
and monitoring RNA populations. One of the main bottlenecks, however, is to
correctly identify the different classes of RNAs among the plethora of
reconstructed transcripts, particularly those that will be translated (mRNAs)
from the class of long non-coding RNAs (lncRNAs). Here, we present FEELnc
(FlExible Extraction of LncRNAs), an alignment-free program that accurately
annotates lncRNAs based on a Random Forest model trained with general features
such as multi k-mer frequencies and relaxed open reading frames. Benchmarking
versus five state-of-the-art tools shows that FEELnc achieves similar or better
classification performance on GENCODE and NONCODE data sets. The program also
provides specific modules that enable the user to fine-tune classification
accuracy, to formalize the annotation of lncRNA classes and to identify lncRNAs
even in the absence of a training set of non-coding RNAs. We used FEELnc on a
real data set comprising 20 canine RNA-seq samples produced by the European LUPA 
consortium to substantially expand the canine genome annotation to include 10 374
novel lncRNAs and 58 640 mRNA transcripts. FEELnc moves beyond conventional
coding potential classifiers by providing a standardized and complete solution
for annotating lncRNAs and is freely available at
https://github.com/tderrien/FEELnc.

© The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkw1306 
PMID: 28053114  [PubMed - as supplied by publisher]


82. Bioinformatics. 2017 Jan 3. pii: btw817. doi: 10.1093/bioinformatics/btw817.
[Epub ahead of print]

Planning bioinformatics workflows using an expert system.

Chen X(1), Chang JT(1,)(2,)(3).

Author information: 
(1)School of Biomedical Informatics. (2)Department of Integrative Biology &
Pharmacology, University of Texas Health Science Center at Houston, Houston, TX
77030, USA. (3)Department of Bioinformatics and Computational Biology, University
of Texas MD Anderson Cancer Center, Houston, TX 77030, USA.

MOTIVATION: Bioinformatic analyses are becoming formidably more complex due to
the increasing number of steps required to process the data, as well as the
proliferation of methods that can be used in each step. To alleviate this
difficulty, pipelines are commonly employed. However, pipelines are typically
implemented to automate a specific analysis, and thus are difficult to use for
exploratory analyses requiring systematic changes to the software or parameters
used.
RESULTS: To automate the development of pipelines, we have investigated expert
systems. We created the Bioinformatics ExperT SYstem (BETSY) that includes a
knowledge base where the capabilities of bioinformatics software is explicitly
and formally encoded. BETSY is a backwards-chaining rule-based expert system
comprised of a data model that can capture the richness of biological data, and
an inference engine that reasons on the knowledge base to produce workflows.
Currently, the knowledge base is populated with rules to analyze microarray and
next generation sequencing data. We evaluated BETSY and found that it could
generate workflows that reproduce and go beyond previously published
bioinformatics results. Finally, a meta-investigation of the workflows generated 
from the knowledge base produced a quantitative measure of the technical burden
imposed by each step of bioinformatics analyses, revealing the large number of
steps devoted to the pre-processing of data. In sum, an expert system approach
can facilitate exploratory bioinformatic analysis by automating the development
of workflows, a task that requires significant domain expertise.
AVAILABILITY AND IMPLEMENTATION: https://github.com/jefftc/changlab CONTACT:
jeffrey.t.chang@uth.tmc.edu.

© The Author 2017. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw817 
PMID: 28052928  [PubMed - as supplied by publisher]


83. Bioinformatics. 2017 Jan 3. pii: btw815. doi: 10.1093/bioinformatics/btw815.
[Epub ahead of print]

Lineage-specific mutational clustering in protein structures predicts
evolutionary shifts in function.

Adams J(1), Mansfield MJ(1), Richard DJ(1), Doxey AC(2).

Author information: 
(1)Department of Biology, University of Waterloo, 200 University Ave. West,
Waterloo, Ontario, N2L 3G1, Canada. (2)Department of Biology, University of
Waterloo, 200 University Ave. West, Waterloo, Ontario, N2L 3G1, Canada.
acdoxey@uwaterloo.ca.

MOTIVATION: Spatially clustered mutations within specific regions of protein
structure are thought to result from strong positive selection for altered
protein functions and are a common feature of oncoproteins in cancer. Although
previous studies have used spatial substitution clustering to identify positive
selection between pairs of proteins, the ability of this approach to identify
functional shifts in protein phylogenies has not been explored.
RESULTS: We implemented a previous measure of spatial substitution clustering
(the P3D statistic) and extended it to detect spatially clustered substitutions
at specific branches of phylogenetic trees. We then applied the analysis to
423,690 phylogenetic branches from 9,261 vertebrate protein families, and
examined its ability to detect historical shifts in protein function. Our
analysis identified 19,607 lineages from 5,362 protein families in which
substitutions were spatially clustered on protein structures at P3D < 0.01.
Spatially clustered substitutions were overrepresented among ligand-binding
residues and were significantly enriched among particular protein families and
functions including C2H2 transcription factors and protein kinases. A small but
significant proportion of branches with spatially clustered substitution also
were under positive selection according to the branch-site test. Lastly,
exploration of the top-scoring candidates revealed historical substitution events
in vertebrate protein families that have generated new functions and protein
interactions, including ancient adaptations in SLC7A2, PTEN, and SNAP25
Ultimately, our work shows that lineage-specific, spatially clustered
substitutions are a useful feature for identifying functional shifts in protein
families, and reveal new candidates for future experimental study.
AVAILABILITY: Source code and predictions for analyses performed in this study
are available at: https://github.com/doxeylab/evoclust3d CONTACT:
acdoxey@uwaterloo.ca SUPPLEMENTARY INFORMATION: Supplementary data are available 
at Bioinformatics online.

© The Author 2017. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw815 
PMID: 28052926  [PubMed - as supplied by publisher]


84. BMC Bioinformatics. 2017 Jan 3;18(1):11. doi: 10.1186/s12859-016-1434-6.

Accelerating metagenomic read classification on CUDA-enabled GPUs.

Kobus R(1), Hundt C(2), Müller A(2), Schmidt B(2).

Author information: 
(1)Institute of Computer Science, Johannes Gutenberg University Mainz,
Staudingerweg 9, Mainz, 55435, Germany. rkobus@students.uni-mainz.de.
(2)Institute of Computer Science, Johannes Gutenberg University Mainz,
Staudingerweg 9, Mainz, 55435, Germany.

BACKGROUND: Metagenomic sequencing studies are becoming increasingly popular with
prominent examples including the sequencing of human microbiomes and diverse
environments. A fundamental computational problem in this context is read
classification; i.e. the assignment of each read to a taxonomic label. Due to the
large number of reads produced by modern high-throughput sequencing technologies 
and the rapidly increasing number of available reference genomes software tools
for fast and accurate metagenomic read classification are urgently needed.
RESULTS: We present cuCLARK, a read-level classifier for CUDA-enabled GPUs, based
on the fast and accurate classification of metagenomic sequences using reduced
k-mers (CLARK) method. Using the processing power of a single Titan X GPU,
cuCLARK can reach classification speeds of up to 50 million reads per minute.
Corresponding speedups for species- (genus-)level classification range between
3.2 and 6.6 (3.7 and 6.4) compared to multi-threaded CLARK executed on a 16-core 
Xeon CPU workstation.
CONCLUSION: cuCLARK can perform metagenomic read classification at superior
speeds on CUDA-enabled GPUs. It is free software licensed under GPL and can be
downloaded at https://github.com/funatiq/cuclark free of charge.

DOI: 10.1186/s12859-016-1434-6 
PMCID: PMC5209836
PMID: 28049411  [PubMed - in process]


85. BMC Bioinformatics. 2017 Jan 3;18(1):4. doi: 10.1186/s12859-016-1441-7.

Negative binomial mixed models for analyzing microbiome count data.

Zhang X(1), Mallick H(2,)(3), Tang Z(4), Zhang L(4), Cui X(1), Benson AK(5), Yi
N(6).

Author information: 
(1)Department of Biostatistics, University of Alabama at Birmingham, Birmingham, 
AL, 35294-0022, USA. (2)Department of Biostatistics, Harvard T.H. Chan School of 
Public Health, Boston, MA, 02115, USA. (3)Program in Medical and Population
Genetics, the Broad Institute, Cambridge, MA, 02142, USA. (4)Department of
Biostatistics, School of Public Health, Medical College of Soochow University,
Suzhou, 215123, China. (5)Department of Food Science and Technology and Core for 
Applied Genomics and Ecology, University of Nebraska, Lincoln, NE, 68583, USA.
(6)Department of Biostatistics, University of Alabama at Birmingham, Birmingham, 
AL, 35294-0022, USA. nyi@uab.edu.

BACKGROUND: Recent advances in next-generation sequencing (NGS) technology enable
researchers to collect a large volume of metagenomic sequencing data. These data 
provide valuable resources for investigating interactions between the microbiome 
and host environmental/clinical factors. In addition to the well-known properties
of microbiome count measurements, for example, varied total sequence reads across
samples, over-dispersion and zero-inflation, microbiome studies usually collect
samples with hierarchical structures, which introduce correlation among the
samples and thus further complicate the analysis and interpretation of microbiome
count data.
RESULTS: In this article, we propose negative binomial mixed models (NBMMs) for
detecting the association between the microbiome and host environmental/clinical 
factors for correlated microbiome count data. Although having not dealt with
zero-inflation, the proposed mixed-effects models account for correlation among
the samples by incorporating random effects into the commonly used fixed-effects 
negative binomial model, and can efficiently handle over-dispersion and varying
total reads. We have developed a flexible and efficient IWLS (Iterative Weighted 
Least Squares) algorithm to fit the proposed NBMMs by taking advantage of the
standard procedure for fitting the linear mixed models.
CONCLUSIONS: We evaluate and demonstrate the proposed method via extensive
simulation studies and the application to mouse gut microbiome data. The results 
show that the proposed method has desirable properties and outperform the
previously used methods in terms of both empirical power and Type I error. The
method has been incorporated into the freely available R package BhGLM (
http://www.ssg.uab.edu/bhglm/ and http://github.com/abbyyan3/BhGLM ), providing a
useful tool for analyzing microbiome data.

DOI: 10.1186/s12859-016-1441-7 
PMCID: PMC5209949
PMID: 28049409  [PubMed - in process]


86. Med Phys. 2016 Jun;43(6):3377. doi: 10.1118/1.4955790.

SU-F-R-18: Updates to the Computational Environment for Radiological Research for
Image Analysis.

Apte AP(1), Deasy JO(1).

Author information: 
(1)Memorial Sloan Kettering Cancer Center, New York, NY.

PURPOSE: To present new tools in CERR for Texture Analysis and Visualization.
METHOD: (1) Quantitative Image Analysis: We added the ability to compute Haralick
texture features based on local neighbourhood. The Texture features depend on
many parameters used in their derivation. For example: (a) directionality, (b)
quantization of image, (c) patch-size for the neighborhood, (d) handling of the
edge voxels within the region of interest, (e) Averaging co-occurance matrix vs
texture features for different directions etc. A graphical user interface was
built to set these parameters and then visualize their impact on the resulting
texture maps. The entire functionality was written in Matlab. Array indexing was 
used to speed up the texture calculation. The computation speed is very
competitive with the ITK library. Moreover, our implementation works with
multiple CPUs and the computation time can be further reduced by using multiple
processor threads. In order to reduce the Haralick texture maps into scalar
features, we propose the use of Texture Volume Histograms. This lets users make
use of the entire distribution of texture values within the region of interest
rather than using just the mean and the standard deviations. (2)
Qualitative/Visualization tools: The derived texture maps are stored as a new
scan (derived) within CERR's planC data structure. A display that compares
various scans was built to show the raw image and the derived texture maps
side-by-side. These images are positionally linked and can be navigated together.
CERR's graphics handling was updated and sped-up to be compatible with the newer 
Matlab versions. As a result, the users can use (a) different window levels and
colormaps for different viewports, (b) click-and-drag or use mouse scroll-wheel
to navigate slices.
RESULTS: The new features and updates are available via
https://www.github.com/adityaapte/cerr.
CONCLUSION: Features added to CERR increase its utility in Radiomics and Outcomes
modeling.

© 2016 American Association of Physicists in Medicine.

DOI: 10.1118/1.4955790 
PMID: 28048842  [PubMed - in process]


87. Med Phys. 2016 Jun;43(6):3328-3329. doi: 10.1118/1.4955593.

SU-C-209-04: Calculation of Two-Material Tissue Parameterizations for Dual-Energy
Imaging.

Jennings R(1).

Author information: 
(1)FDA Center for Devices & Radiological, Silver Spring, MD.

PURPOSE: The characterization of the energy dependences of tissue attenuation
coefficients is fundamental in dual-energy imaging. It has been posited that a
two-parameter model is both necessary and sufficient to describe these
dependences for tissues of medical interest in the diagnostic energy range. In
one approach the two parameters are the weighting factors for the
energy-dependent linear attenuation coefficients of two distinct materials. This 
is commonly known as the basis material decomposition method. The purpose of this
work is to describe and evaluate a method for determining these weighting factors
for user-selected basis materials and tissues of interest.
METHODS: The method essentially says that the linear attenuation coefficient of
the tissue of interest is equal, to a good approximation, to the weighted sum of 
the coefficients of two other distinct materials. The weights can be obtained
from the resulting equation, evaluated at two different energies. Not all pairs
of energies produce weights that yield accurate results. The method for finding a
quasi-optimal pair of weights is described.
RESULTS: The method has been applied to a variety of combinations of tissue of
interest and materials chosen to represent it. In most instances, the accuracy of
the match is of the order of a few tenths of one percent over a large energy
range. Even for combinations that might be expected to give poor results, water
represented by PMMA and aluminum for example, the maximum deviations are of the
order of one percent.
CONCLUSION: The method produces characterizations that are at least as good as,
and usually better than, the accuracy of x-ray measurements obtainable with
reasonable patient doses and currently available hardware. The results also show 
that many different materials are reasonable choices for basis materials. The
software used for this study is available on GitHub.

© 2016 American Association of Physicists in Medicine.

DOI: 10.1118/1.4955593 
PMID: 28048470  [PubMed - in process]


88. Bioinformatics. 2016 Dec 31. pii: btw764. doi: 10.1093/bioinformatics/btw764.
[Epub ahead of print]

Parameter estimation for dynamical systems with discrete events and logical
operations.

Fröhlich F(1,)(2), Theis FJ(1,)(2), Rädler JO(3), Hasenauer J(1,)(2).

Author information: 
(1)Institute of Computational Biology, Helmholtz Zentrum München, Neuherberg
85764, Germany. (2)Center for Mathematics, Technische Universität München,
Garching 85748, Germany. (3)Faculty of Physics, Ludwig-Maximilians-Universität,
München 80539, Germany.

MOTIVATION: Ordinary differential equation (ODE) models are frequently used to
describe the dynamic behaviour of biochemical processes. Such ODE models are
often extended by events to describe the effect of fast latent processes on the
process dynamics. To exploit the predictive power of ODE models, their parameters
have to be inferred from experimental data. For models without events, gradient
based optimization schemes perform well for parameter estimation, when
sensitivity equations are used for gradient computation. Yet, sensitivity
equations for models with parameter- and state-dependent events and
event-triggered observations are not supported by existing toolboxes.
RESULTS: In this manuscript, we describe the sensitivity equations for
differential equation models with events and demonstrate how to estimate
parameters from event-resolved data using event-triggered observations in
parameter estimation. We consider a model for GFP expression after transfection
and a model for spiking neurons and demonstrate that we can improve computational
efficiency and robustness of parameter estimation by using sensitivity equations 
for systems with events. Moreover, we demonstrate that, by using event-outputs,
it is possible to consider event-resolved data, such as time-to-event data, for
parameter estimation with ODE models. By providing a user-friendly, modular
implementation in the toolbox AMICI, the developed methods are made publicly
available and can be integrated in other systems biology toolboxes.
AVAILABILITY AND IMPLEMENTATION: We implement the methods in the open-source
toolbox Advanced MATLAB Interface for CVODES and IDAS (AMICI,
https://github.com/ICB-DCM/AMICI).
CONTACT: jan.hasenauer@helmholtz-muenchen.deSupplementary information:
Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw764 
PMID: 28040696  [PubMed - as supplied by publisher]


89. J Struct Biol. 2016 Dec 27. pii: S1047-8477(16)30252-0. doi:
10.1016/j.jsb.2016.12.006. [Epub ahead of print]

Robust image alignment for cryogenic transmission electron microscopy.

McLeod RA(1), Kowal J(2), Ringler P(2), Stahlberg H(2).

Author information: 
(1)Center for Cellular Imaging and NanoAnalytics, Biozentrum, Universität Basel, 
Basel, Switzerland. Electronic address: robbmcleod@gmail.com. (2)Center for
Cellular Imaging and NanoAnalytics, Biozentrum, Universität Basel, Basel,
Switzerland.

Cryo-electron microscopy recently experienced great improvements in structure
resolution due to direct electron detectors with improved contrast and fast
read-out leading to single electron counting. High frames rates enabled dose
fractionation, where a long exposure is broken into a movie, permitting specimen 
drift to be registered and corrected. The typical approach for image
registration, with high shot noise and low contrast, is multi-reference (MR)
cross-correlation. Here we present the software package Zorro, which provides
robust drift correction for dose fractionation by use of an intensity-normalized 
cross-correlation and logistic noise model to weight each cross-correlation in
the MR model and filter each cross-correlation optimally. Frames are reliably
registered by Zorro with low dose and defocus. Methods to evaluate performance
are presented, by use of independently-evaluated even- and odd-frame stacks by
trajectory comparison and Fourier ring correlation. Alignment of tiled sub-frames
is also introduced, and demonstrated on an example dataset. Zorro source code is 
available at github.com/CINA/zorro.

Copyright © 2016 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.jsb.2016.12.006 
PMID: 28038834  [PubMed - as supplied by publisher]


90. ACS Synth Biol. 2017 Jan 25. doi: 10.1021/acssynbio.6b00273. [Epub ahead of
print]

sbml-diff: A Tool for Visually Comparing SBML Models in Synthetic Biology.

Scott-Brown J(1), Papachristodoulou A(1).

Author information: 
(1)Department of Engineering Science, University of Oxford , Parks Road, Oxford
OX1 3PJ, U.K.

We present sbml-diff, a tool that is able to read a model of a biochemical
reaction network in SBML format and produce a range of diagrams showing different
levels of detail. Each diagram type can be used to visualize a single model or to
visually compare two or more models. The default view depicts species as
ellipses, reactions as rectangles, rules as parallelograms, and events as
diamonds. A cartoon view replaces the symbols used for reactions on the basis of 
the associated Systems Biology Ontology terms. An abstract view represents
species as ellipses and draws edges between them to indicate whether a species
increases or decreases the production or degradation of another species.
sbml-diff is freely licensed under the three-clause BSD license and can be
downloaded from https://github.com/jamesscottbrown/sbml-diff and used as a python
package called from other software, as a free-standing command-line application, 
or online using the form at http://sysos.eng.ox.ac.uk/tebio/upload.

DOI: 10.1021/acssynbio.6b00273 
PMID: 28035814  [PubMed - as supplied by publisher]


91. Bioinformatics. 2016 Dec 29. pii: btw786. doi: 10.1093/bioinformatics/btw786.
[Epub ahead of print]

Using genotype array data to compare multi- and single-sample variant calls and
improve variant call sets from deep coverage whole-genome sequencing data.

Shringarpure SS(1,)(2), Mathias RA(2,)(3), Hernandez RD(4,)(5,)(6), O'Connor
TD(7,)(8,)(9), Szpiech ZA(4), Torres R(10), De La Vega FM(1), Bustamante CD(1),
Barnes KC(2,)(3), Taub MA(11); CAAPA Consortium.

Author information: 
(1)Departments of Genetics and Biomedical Data Science, Stanford University
School of Medicine, Stanford, CA, USA. (2)23 and Me Inc, Mountain View, CA, USA. 
(3)Department of Medicine, Johns Hopkins University, Baltimore, MD, USA.
(4)Department of Epidemiology, Bloomberg School of Public Health, JHU, Baltimore,
MD, USA. (5)Department of Bioengineering and Therapeutic Sciences. (6)Institute
for Human Genetics and. (7)Quantitative Biosciences Institute, University of
California, San Francisco, San Francisco, CA, USA. (8)Institute for Genome
Sciences. (9)Program in Personalized and Genomic Medicine. (10)Department of
Medicine, University of Maryland School of Medicine, Baltimore, MD, USA.
(11)Biomedical Sciences Graduate Program, University of California, San
Francisco, San Francisco, CA, USA.

MOTIVATION: Variant calling from next-generation sequencing (NGS) data is
susceptible to false positive calls due to sequencing, mapping and other errors. 
To better distinguish true from false positive calls, we present a method that
uses genotype array data from the sequenced samples, rather than public data such
as HapMap or dbSNP, to train an accurate classifier using Random Forests. We
demonstrate our method on a set of variant calls obtained from 642
African-ancestry genomes from the Consortium on Asthma among African-ancestry
Populations in the Americas (CAAPA), sequenced to high depth (30X).
RESULTS: We have applied our classifier to compare call sets generated with
different calling methods, including both single-sample and multi-sample callers.
At a False Positive Rate of 5%, our method determines true positive rates of
97.5%, 95% and 99% on variant calls obtained using Illuminas single-sample caller
CASAVA, Real Time Genomics multisample variant caller, and the GATK
UnifiedGenotyper, respectively. Since NGS sequencing data may be accompanied by
genotype data for the same samples, either collected concurrent to sequencing or 
from a previous study, our method can be trained on each dataset to provide a
more accurate computational validation of site calls compared to generic methods.
Moreover, our method allows for adjustment based on allele frequency (e.g. a
different set of criteria to determine quality for rare versus common variants)
and thereby provides insight into sequencing characteristics that indicate call
quality for variants of different frequencies.
AVAILABILITY AND IMPLEMENTATION: Code is available on Github at:
https://github.com/suyashss/variant_validation CONTACTS: : suyashs@stanford.edu
or mtaub@jhsph.eduSupplementary information: Supplementary data are available at 
Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw786 
PMID: 28035032  [PubMed - as supplied by publisher]


92. Bioinformatics. 2016 Dec 29. pii: btw781. doi: 10.1093/bioinformatics/btw781.
[Epub ahead of print]

AnglerFish: a webserver for defining the geometry of α-helices in membrane
proteins.

Colledge M(1), Wallace BA(1).

Author information: 
(1)Institute of Structural and Molecular Biology, Birkbeck College, University of
London, London, WC1E 7HX, UK.

Integral membrane proteins that form helical pores and bundles constitute major
drug targets, and many of their structures have been defined by crystallography
and cryo-electron microscopy. The gating of channels and ligand binding of
transporters generally involve changes in orientation of one or more the
constituent helices in the structures. At present there is no standard easily
accessible means for defining the orientation of a helix in a membrane protein
structure. AnglerFish is a web-based tool for parameterising the angles of
transmembrane helices based on PDB coordinates, with the helical orientations
defined by the angles 'tilt' and 'swing'. AnglerFish is particularly useful for
defining changes in structure between different states, including both symmetric 
and asymmetric transitions, and can be used to quantitate differences between
related structures or different subunits within the same structure.AVAILABILITY
AND IMPLEMENTATION: AnglerFish is freely available at
http://anglerfish.cryst.bbk.ac.uk The website is implemented in Perl-cgi and
Apache and operation in all major browsers is supported. The source code is
available at GitHub.
CONTACT: b.wallace@mail.cryst.bbk.ac.ukSupplementary information: Supplementary
data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw781 
PMID: 28035031  [PubMed - as supplied by publisher]


93. Bioinformatics. 2016 Dec 28. pii: btw696. doi: 10.1093/bioinformatics/btw696.
[Epub ahead of print]

seXY: a tool for sex inference from genotype arrays.

Qian DC(1), Busam JA(2), Xiao X(1), O'Mara TA(3), Eeles RA(4), Schumacher FR(5), 
Phelan CM(6), Amos CI(1).

Author information: 
(1)Department of Biomedical Data Science, Dartmouth Geisel School of Medicine,
Lebanon, NH 03756, USA. (2)Department of Biological Sciences, Dartmouth College, 
Hanover, NH 03755, USA. (3)Department of Genetics and Computational Biology, QIMR
Berghofer Medical Research Institute, Brisbane, QLD 4006, Australia. (4)Division 
of Genetics and Epidemiology, Institute of Cancer Research, London SW7 3RP, UK.
(5)Department of Epidemiology and Biostatistics, Case Western Reserve University,
Cleveland, OH 44106, USA. (6)Department of Cancer Epidemiology, Moffitt Cancer
Center, Tampa, FL 33612, USA.

MOTIVATION: Checking concordance between reported sex and genotype-inferred sex
is a crucial quality control measure in genome-wide association studies (GWAS).
However, limited insights exist regarding the true accuracy of software that
infer sex from genotype array data.
RESULTS: We present seXY, a logistic regression model trained on both X
chromosome heterozygosity and Y chromosome missingness, that consistently
demonstrated >99.5% sex inference accuracy in cross-validation for 889 males and 
5,361 females enrolled in prostate cancer and ovarian cancer GWAS. Compared to
PLINK, one of the most popular tools for sex inference in GWAS that assesses only
X chromosome heterozygosity, seXY achieved marginally better male classification 
and 3% more accurate female classification.
AVAILABILITY AND IMPLEMENTATION: https://github.com/Christopher-Amos-Lab/seXY
CONTACT: Christopher.I.Amos@dartmouth.eduSupplementary information: Supplementary
data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw696 
PMID: 28035028  [PubMed - as supplied by publisher]


94. ACS Synth Biol. 2016 Dec 29. doi: 10.1021/acssynbio.6b00277. [Epub ahead of
print]

A Validator and Converter for the Synthetic Biology Open Language.

Zundel Z, Samineni M, Zhang Z, Myers CJ.

This paper presents a new validation and conversion utility for the Synthetic
Biology Open Language (SBOL). This utility can be accessed directly in software
using the libSBOLj library, through a web interface, or using a web service via
RESTful API calls. The validator checks all required and best practice rules set 
forth in the SBOL specification document, and it reports back to the user the
location within the document of any errors found. The converter is capable of
translating from/to SBOL 1, GenBank, and FASTA formats to/from SBOL 2. The SBOL
Validator/Converter utility is released freely and open source under the Apache
2.0 license. The online version of the validator/converter utility can be found
here: http://www.async.ece.utah.edu/sbol-validator/. The source code for the
validator/converter can be found here:
http://github.com/SynBioDex/SBOL-Validator/.

DOI: 10.1021/acssynbio.6b00277 
PMID: 28033703  [PubMed - as supplied by publisher]


95. Bioinformatics. 2016 Dec 28. pii: btw789. doi: 10.1093/bioinformatics/btw789.
[Epub ahead of print]

SVScore: an impact prediction tool for structural variation.

Ganel L(1,)(2), Abel HJ(1); FinMetSeq Consortium, Hall IM(1,)(2).

Author information: 
(1)McDonnell Genome Institute. (2)Department of Medicine, Washington University
School of Medicine, St. Louis, MO, USA.

Here we present SVScore, a tool for in silico structural variation (SV) impact
prediction. SVScore aggregates per-base single nucleotide polymorphism (SNP)
pathogenicity scores across relevant genomic intervals for each SV in a manner
that considers variant type, gene features and positional uncertainty. We show
that the allele frequency spectrum of high-scoring SVs is strongly skewed toward 
lower frequencies, suggesting that they are under purifying selection, and that
SVScore identifies deleterious variants more effectively than alternative
methods. Notably, our results also suggest that duplications are under
surprisingly strong selection relative to deletions, and that there are a similar
number of strongly pathogenic SVs and SNPs in the human population.AVAILABILITY
AND IMPLEMENTATION: SVScore is implemented in Perl and available freely at
{{http://www.github.com/lganel/SVScore}} for use under the MIT license.
CONTACT: ihall@wustl.eduSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw789 
PMID: 28031184  [PubMed - as supplied by publisher]


96. BMC Bioinformatics. 2016 Dec 28;17(1):546. doi: 10.1186/s12859-016-1381-2.

UQlust: combining profile hashing with linear-time ranking for efficient
clustering and analysis of big macromolecular data.

Adamczak R(1), Meller J(2,)(3,)(4).

Author information: 
(1)Department of Informatics, Faculty of Physics, Astronomy and Informatics,
Nicolaus Copernicus University, Grudziadzka 5, 87-100, Torun, Poland.
raad@is.umk.pl. (2)Department of Informatics, Faculty of Physics, Astronomy and
Informatics, Nicolaus Copernicus University, Grudziadzka 5, 87-100, Torun,
Poland. jmeller@cchmc.org. (3)Departments of Environmental Health and Electrical 
Engineering & Computing Systems, University of Cincinnati, Cincinnati, USA.
jmeller@cchmc.org. (4)Division of Biomedical Informatics, Cincinnati Children's
Hospital Medical Center, Cincinnati, USA. jmeller@cchmc.org.

BACKGROUND: Advances in computing have enabled current protein and RNA structure 
prediction and molecular simulation methods to dramatically increase their
sampling of conformational spaces. The quickly growing number of experimentally
resolved structures, and databases such as the Protein Data Bank, also implies
large scale structural similarity analyses to retrieve and classify
macromolecular data. Consequently, the computational cost of structure comparison
and clustering for large sets of macromolecular structures has become a
bottleneck that necessitates further algorithmic improvements and development of 
efficient software solutions.
RESULTS: uQlust is a versatile and easy-to-use tool for ultrafast ranking and
clustering of macromolecular structures. uQlust makes use of structural profiles 
of proteins and nucleic acids, while combining a linear-time algorithm for
implicit comparison of all pairs of models with profile hashing to enable
efficient clustering of large data sets with a low memory footprint. In addition 
to ranking and clustering of large sets of models of the same protein or RNA
molecule, uQlust can also be used in conjunction with fragment-based profiles in 
order to cluster structures of arbitrary length. For example, hierarchical
clustering of the entire PDB using profile hashing can be performed on a typical 
laptop, thus opening an avenue for structural explorations previously limited to 
dedicated resources. The uQlust package is freely available under the GNU General
Public License at https://github.com/uQlust .
CONCLUSION: uQlust represents a drastic reduction in the computational complexity
and memory requirements with respect to existing clustering and model quality
assessment methods for macromolecular structure analysis, while yielding results 
on par with traditional approaches for both proteins and RNAs.

DOI: 10.1186/s12859-016-1381-2 
PMCID: PMC5198500
PMID: 28031034  [PubMed - in process]


97. IEEE/ACM Trans Comput Biol Bioinform. 2016 Dec 20. doi:
10.1109/TCBB.2016.2642107. [Epub ahead of print]

Evolutionary Graph Clustering for Protein Complex Identification.

He T, Chan KC.

This paper presents a graph clustering algorithm, called EGCPI, to discover
protein complexes in protein-protein interaction (PPI) networks. In performing
its task, EGCPI takes into consideration both network topologies and attributes
of interacting proteins, both of which have been shown to be important for
protein complex discovery. EGCPI formulates the problem as an optimization
problem and tackles it with evolutionary clustering. Given a PPI network, EGCPI
first annotates each protein with corresponding attributes that are provided in
Gene Ontology database. It then adopts a similarity measure to evaluate how
similar the connected proteins are taking into consideration the network
topology. Given this measure, EGCPI then discovers a number of graph clusters
within which proteins are densely connected, based on an evolutionary strategy.
At last, EGCPI identifies protein complexes in each discovered cluster based on
the homogeneity of attributes performed by pairwise proteins. EGCPI has been
tested with several real data sets and the experimental results show EGCPI is
very effective on protein complex discovery, and the evolutionary clustering is
helpful to identify protein complexes in PPI networks. The software of EGCPI can 
be downloaded via: https://github.com/hetiantian1985/EGCPI.

DOI: 10.1109/TCBB.2016.2642107 
PMID: 28029628  [PubMed - as supplied by publisher]


98. PeerJ. 2016 Dec 20;4:e2690. doi: 10.7717/peerj.2690. eCollection 2016.

Seqenv: linking sequences to environments through text mining.

Sinclair L(1), Ijaz UZ(2), Jensen LJ(3), Coolen MJ(4), Gubry-Rangin C(5),
Chroňáková A(6), Oulas A(7), Pavloudi C(8), Schnetzer J(9), Weimann A(10), Ijaz
A(11), Eiler A(1), Quince C(12), Pafilis E(8).

Author information: 
(1)Department of Ecology and Genetics, Limnology, Uppsala University , Uppsala , 
Sweden. (2)Infrastructure and Environment Research Division, School of
Engineering, University of Glasgow , Glasgow , United Kingdom. (3)The Novo
Nordisk Foundation Center for Protein Research, Faculty of Health and Medical
Sciences, University of Copenhagen , Copenhagen , Denmark. (4)Western Australia
Organic and Isotope Geochemistry Centre (WA-OIGC), Department of Chemistry,
Curtin University of Technology , Bentley , WA , Australia. (5)Institute of
Biological & Environmental Sciences, University of Aberdeen , Aberdeen , United
Kingdom. (6)Institute of Soil Biology, Biology Centre, Czech Academy of Sciences 
, České Budějovice , Czech Republic. (7)Bioinformatics Group, The Cyprus
Institute of Neurology and Genetics, Nicosia, Cyprus; Institute of Marine Biology
Biotechnology and Aquaculture (IMBBC), Hellenic Centre for Marine Research
(HCMR), Heraklion Crete, Greece. (8)Institute of Marine Biology Biotechnology and
Aquaculture (IMBBC), Hellenic Centre for Marine Research (HCMR) , Heraklion Crete
, Greece. (9)Department of Molecular Ecology, Microbial Genomics and
Bioinformatics Group, Max Planck Institute for Marine Microbiology , Bremen ,
Germany. (10)Computational Biology of Infection Research, Helmholtz Centre for
Infection Research , Braunschweig , Germany. (11)Hawkesbury Institute for the
Environment, University of Western Sydney, Hawkesbury , Sydney , Australia.
(12)Warwick Medical School, University of Warwick , Warwick , United Kingdom.

Understanding the distribution of taxa and associated traits across different
environments is one of the central questions in microbial ecology.
High-throughput sequencing (HTS) studies are presently generating huge volumes of
data to address this biogeographical topic. However, these studies are often
focused on specific environment types or processes leading to the production of
individual, unconnected datasets. The large amounts of legacy sequence data with 
associated metadata that exist can be harnessed to better place the genetic
information found in these surveys into a wider environmental context. Here we
introduce a software program, seqenv, to carry out precisely such a task. It
automatically performs similarity searches of short sequences against the "nt"
nucleotide database provided by NCBI and, out of every hit, extracts-if it is
available-the textual metadata field. After collecting all the isolation sources 
from all the search results, we run a text mining algorithm to identify and parse
words that are associated with the Environmental Ontology (EnvO) controlled
vocabulary. This, in turn, enables us to determine both in which environments
individual sequences or taxa have previously been observed and, by weighted
summation of those results, to summarize complete samples. We present two
demonstrative applications of seqenv to a survey of ammonia oxidizing archaea as 
well as to a plankton paleome dataset from the Black Sea. These demonstrate the
ability of the tool to reveal novel patterns in HTS and its utility in the fields
of environmental source tracking, paleontology, and studies of microbial
biogeography. To install seqenv, go to: https://github.com/xapple/seqenv.

DOI: 10.7717/peerj.2690 
PMCID: PMC5178346
PMID: 28028456  [PubMed]


99. Mol Biol Evol. 2016 Dec 25. pii: msw252. doi: 10.1093/molbev/msw252. [Epub ahead 
of print]

IMGui-A Desktop GUI Application for Isolation with Migration Analyses.

Knoblauch J(1), Sethuraman A(2,)(3), Hey J(1).

Author information: 
(1)Department of Biology, Center for Computational Genetics and Genomics, Temple 
University, Philadelphia, PA. (2)Department of Biology, Center for Computational 
Genetics and Genomics, Temple University, Philadelphia, PA asethuraman@csusm.edu.
(3)Department of Biological Sciences, California State University San Marcos, San
Marcos, CA.

The Isolation with Migration (IM) programs (e.g., IMa2) have been utilized
extensively by evolutionary biologists for model-based inference of demographic
parameters including effective population sizes, migration rates, and divergence 
times. Here, we describe a graphical user interface for the latest IM program.
IMGui provides a comprehensive set of tools for performing demographic analyses, 
tracking progress of runs, and visualizing results. Developed using node. js and 
the Electron framework, IMGui is an application that runs on any desktop
operating system, and is available for download at
https://github.com/jaredgk/IMgui-electron-packages.

© The Author 2016. Published by Oxford University Press on behalf of the Society 
for Molecular Biology and Evolution. All rights reserved. For permissions, please
e-mail: journals.permissions@oup.com.

DOI: 10.1093/molbev/msw252 
PMID: 28025276  [PubMed - as supplied by publisher]


100. Bioinformatics. 2016 Dec 25. pii: btw720. doi: 10.1093/bioinformatics/btw720.
[Epub ahead of print]

Novel probabilistic models of spatial genetic ancestry with applications to
stratification correction in genome-wide association studies.

Bhaskar A(1,)(2), Javanmard A(3), Courtade TA(4), Tse D(4,)(5).

Author information: 
(1)Department of Genetics, Stanford University, Stanford, CA 94305, USA.
(2)Howard Hughes Medical Institute, Stanford University, Stanford, CA 94305, USA.
(3)Marshall School of Business, University of Southern California, Los Angeles,
CA 90089, USA. (4)Department of Electrical Engineering and Computer Sciences,
University of California, Berkeley, CA 94720, USA. (5)Department of Electrical
Engineering, Stanford University, Stanford, CA 94305, USA.

MOTIVATION: Genetic variation in human populations is influenced by geographic
ancestry due to spatial locality in historical mating and migration patterns.
Spatial population structure in genetic datasets has been traditionally analyzed 
using either model-free algorithms, such as principal components analysis (PCA)
and multidimensional scaling, or using explicit spatial probabilistic models of
allele frequency evolution. We develop a general probabilistic model and an
associated inference algorithm that unify the model-based and data-driven
approaches to visualizing and inferring population structure. Our spatial
inference algorithm can also be effectively applied to the problem of population 
stratification in genome-wide association studies (GWAS), where hidden population
structure can create fictitious associations when population ancestry is
correlated with both the genotype and the trait.
RESULTS: Our algorithm Geographic Ancestry Positioning (GAP) relates local
genetic distances between samples to their spatial distances, and can be used for
visually discerning population structure as well as accurately inferring the
spatial origin of individuals on a two-dimensional continuum. On both simulated
and several real datasets from diverse human populations, GAP exhibits
substantially lower error in reconstructing spatial ancestry coordinates compared
to PCA. We also develop an association test that uses the ancestry coordinates
inferred by GAP to accurately account for ancestry-induced correlations in GWAS. 
Based on simulations and analysis of a dataset of 10 metabolic traits measured in
a Northern Finland cohort, which is known to exhibit significant population
structure, we find that our method has superior power to current approaches.
AVAILABILITY AND IMPLEMENTATION: Our software is available at
https://github.com/anand-bhaskar/gap CONTACTS: : abhaskar@stanford.edu or
ajavanma@usc.eduSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw720 
PMID: 28025204  [PubMed - as supplied by publisher]


101. Bioinformatics. 2016 Dec 24. pii: btw714. doi: 10.1093/bioinformatics/btw714.
[Epub ahead of print]

tranSMART-XNAT Connector tranSMART-XNAT connector-image selection based on
clinical phenotypes and genetic profiles.

He S(1), Yong M(2), Matthews PM(3), Guo Y(2).

Author information: 
(1)European Bioinformatics Institute, Cambridge, UK. (2)Data Science Institute,
Imperial College London, London, UK. (3)Division of Brain Sciences, Imperial
College London, London, UK.

MOTIVATION: TranSMART has a wide range of functionalities for translational
research and a large user community, but it does not support imaging data. In
this context, imaging data typically includes 2D or 3D sets of magnitude data and
metadata information. Imaging data may summarise complex feature descriptions in 
a less biased fashion than user defined plain texts and numeric numbers. Imaging 
data also is contextualised by other data sets and may be analysed jointly with
other data that can explain features or their variation.
RESULTS: Here we describe the tranSMART-XNAT Connector we have developed. This
connector consists of components for data capture, organisation and analysis.
Data capture is responsible for imaging capture either from PACS system or
directly from an MRI scanner, or from raw data files. Data are organised in a
similar fashion as tranSMART and are stored in a format that allows direct
analysis within tranSMART. The connector enables selection and download of DICOM 
images and associated resources using subjects' clinical phenotypic and genotypic
criteria.
AVAILABILITY AND IMPLEMENTATION: tranSMART-XNAT connector is written in
Java/Groovy/Grails. It is maintained and available for download at
https://github.com/sh107/transmart-xnat-connector.gitContact:sijin@ebi.ac.uk.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw714 
PMID: 28025201  [PubMed - as supplied by publisher]


102. Bioinformatics. 2016 Dec 24. pii: btw732. doi: 10.1093/bioinformatics/btw732.
[Epub ahead of print]

Falco: a quick and flexible single-cell RNA-seq processing framework on the
cloud.

Yang A(1,)(2), Troup M(1), Lin P(1,)(2), Ho JW(1,)(2).

Author information: 
(1)Victor Chang Cardiac Research Institute, Sydney, NSW, Australia. (2)St.
Vincent's Clinical School, University of New South Wales, Sydney, NSW, Australia.

: Single-cell RNA-seq (scRNA-seq) is increasingly used in a range of biomedical
studies. Nonetheless, current RNA-seq analysis tools are not specifically
designed to efficiently process scRNA-seq data due to their limited scalability. 
Here we introduce Falco, a cloud-based framework to enable paralellization of
existing RNA-seq processing pipelines using big data technologies of Apache
Hadoop and Apache Spark for performing massively parallel analysis of large scale
transcriptomic data. Using two public scRNA-seq datasets and two popular RNA-seq 
alignment/feature quantification pipelines, we show that the same processing
pipeline runs 2.6-145.4 times faster using Falco than running on a highly
optimized standalone computer. Falco also allows users to utilize low-cost spot
instances of Amazon Web Services, providing a ∼65% reduction in cost of
analysis.AVAILABILITY AND IMPLEMENTATION: Falco is available via a GNU General
Public License at https://github.com/VCCRI/Falco/ CONTACT:
j.ho@victorchang.edu.auSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw732 
PMID: 28025200  [PubMed - as supplied by publisher]


103. Bioinformatics. 2016 Dec 23. pii: btw722. doi: 10.1093/bioinformatics/btw722.
[Epub ahead of print]

DACE: A Scalable DP-means Algorithm for Clustering Extremely Large Sequence Data.

Jiang L(1), Dong Y(2), Chen N(3), Chen T(3,)(2).

Author information: 
(1)MOE Key Lab of Bioinformatics; Bioinformatics Division and Center for
Synthetic & Systems Biology, TNLIST; Department of Computer Science and
Technology, Tsinghua University, Beijing 100084, China. (2)Program in
Computational Biology and Bioinformatics, University of Southern California, Los 
Angeles, CA 90089, USA. (3)MOE Key Lab of Bioinformatics; Bioinformatics Division
and Center for Synthetic & Systems Biology, TNLIST; Department of Computer
Science and Technology, Tsinghua University, Beijing 100084, China
ningchen@mail.tsinghua.edu.cn tingchen@mail.tsinghua.edu.cn.

MOTIVATION: Advancements in next-generation sequencing technology have produced
large amounts of reads at low cost in a short time. In metagenomics, 16S and 18S 
rRNA gene have been widely used as marker genes to profile diversity of
microorganisms in environmental samples. Through clustering of sequencing reads
we can determine both number of OTUs and their relative abundance. In many
applications, clustering of very large sequencing data with high efficiency and
accuracy is essential for downstream analysis.
RESULTS: Here, we report a scalable Dirichlet Process Means (DP-means) algorithm 
for clustering extremely large sequencing data, termed DACE: With an efficient
random projection partition strategy for parallel clustering, DACE can cluster
billions of sequences within a couple of hours. Experimental results show that
DACE runs between 6 to 80 times faster than state-of-the-art programs, while
maintaining overall better clustering accuracy. Using 80 cores, DACE clustered
the Lake Taihu 16S rRNA gene sequencing data (~316M reads, 30GB) in 25 minutes,
and the Ocean TARA Eukaryotic 18S rRNA gene sequencing data (~500M reads, 88GB)
into ~100,000 clusters within an hour. When applied to the IGC gene catalogs in
human gut microbiome (~10M genes), DACE produced 9.8M clusters with 52K redundant
genes in 1.5 hours of running time.
AVAILABILITY: DACE is available at https://github.com/tinglab/DACE CONTACT:
tingchen@mail.tsinghua.edu.cn and ningchen@mail.tsinghua.edu.cn SUPPLEMENTARY
INFORMATION: Supplementary data are available at Bioinformatics online.

© The Author(s) 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw722 
PMID: 28025198  [PubMed - as supplied by publisher]


104. Brief Bioinform. 2016 Dec 26. pii: bbw118. doi: 10.1093/bib/bbw118. [Epub ahead
of print]

MTGIpick allows robust identification of genomic islands from a single genome.

Dai Q, Bao C, Hai Y, Ma S, Zhou T, Wang C, Wang Y, Huo W, Liu X, Yao Y, Xuan Z,
Chen M, Zhang MQ.

Genomic islands (GIs) that are associated with microbial adaptations and carry
sequence patterns different from that of the host are sporadically distributed
among closely related species. This bias can dominate the signal of interest in
GI detection. However, variations still exist among the segments of the host,
although no uniform standard exists regarding the best methods of discriminating 
GIs from the rest of the genome in terms of compositional bias. In the present
work, we proposed a robust software, MTGIpick, which used regions with pattern
bias showing multiscale difference levels to identify GIs from the host. MTGIpick
can identify GIs from a single genome without annotated information of genomes or
prior knowledge from other data sets. When real biological data were used,
MTGIpick demonstrated better performance than existing methods, as well as
revealed potential GIs with accurate sizes missed by existing methods because of 
a uniform standard. Software and supplementary are freely available at
http://bioinfo.zstu.edu.cn/MTGI or https://github.com/bioinfo0706/MTGIpick.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bib/bbw118 
PMID: 28025178  [PubMed - as supplied by publisher]


105. R Soc Open Sci. 2016 Nov 9;3(11):160582. doi: 10.1098/rsos.160582. eCollection
2016.

Using Fisher information to track stability in multivariate systems.

Ahmad N(1), Derrible S(1), Eason T(2), Cabezas H(3).

Author information: 
(1)Complex and Sustainable Urban Networks (CSUN) Laboratory , University of
Illinois at Chicago , Chicago, IL , USA. (2)Sustainable Technology Division,
Office of Research and Development , US Environmental Protection Agency ,
Cincinnati, OH , USA. (3)Sustainable Technology Division, Office of Research and 
Development, US Environmental Protection Agency, Cincinnati, OH, USA; Faculty of 
Information Technology and Bionics, Pazmany Peter Catholic University, Budapest, 
Hungary.

With the current proliferation of data, the proficient use of statistical and
mining techniques offer substantial benefits to capture useful information from
any dataset. As numerous approaches make use of information theory concepts,
here, we discuss how Fisher information (FI) can be applied to sustainability
science problems and used in data mining applications by analysing patterns in
data. FI was developed as a measure of information content in data, and it has
been adapted to assess order in complex system behaviour. The main advantage of
the approach is the ability to collapse multiple variables into an index that can
be used to assess stability and track overall trends in a system, including its
regimes and regime shifts. Here, we provide a brief overview of FI theory,
followed by a simple step-by-step numerical example on how to compute FI.
Furthermore, we introduce an open source Python library that can be freely
downloaded from GitHub and we use it in a simple case study to evaluate the
evolution of FI for the global-mean temperature from 1880 to 2015. Results
indicate significant declines in FI starting in 1978, suggesting a possible
regime shift.

DOI: 10.1098/rsos.160582 
PMCID: PMC5180148
PMID: 28018650  [PubMed]


106. Mol Biol Evol. 2016 Dec 23. pii: msw260. doi: 10.1093/molbev/msw260. [Epub ahead 
of print]

PartitionFinder 2: New Methods for Selecting Partitioned Models of Evolution for 
Molecular and Morphological Phylogenetic Analyses.

Lanfear R(1,)(2), Frandsen PB(3), Wright AM(4), Senfeld T(2), Calcott B(5).

Author information: 
(1)Research School of Biology, Australian National University, Canberra, ACT,
Australia rob.lanfear@anu.edu.au. (2)Department of Biological Sciences, Macquarie
University, Sydney, Australia. (3)Office of Research Information Services, Office
of the Chief Information Officer, Smithsonian Institution, Washington, DC.
(4)Ecology, Evolution and Organismal Biology, Iowa State University, Ames, IA.
(5)Department of Philosophy, University of Sydney, Sydney, NSW, Australia.

PartitionFinder 2 is a program for automatically selecting best-fit partitioning 
schemes and models of evolution for phylogenetic analyses. PartitionFinder 2 is
substantially faster and more efficient than version 1, and incorporates many new
methods and features. These include the ability to analyze morphological
datasets, new methods to analyze genome-scale datasets, new output formats to
facilitate interoperability with downstream software, and many new models of
molecular evolution. PartitionFinder 2 is freely available under an open source
license and works on Windows, OSX, and Linux operating systems. It can be
downloaded from www.robertlanfear.com/partitionfinder The source code is
available at https://github.com/brettc/partitionfinder.

© The Author 2016. Published by Oxford University Press on behalf of the Society 
for Molecular Biology and Evolution. All rights reserved. For permissions, please
e-mail: journals.permissions@oup.com.

DOI: 10.1093/molbev/msw260 
PMID: 28013191  [PubMed - as supplied by publisher]


107. Bioinformatics. 2016 Dec 23. pii: btw794. doi: 10.1093/bioinformatics/btw794.
[Epub ahead of print]

Image-based correction of continuous and discontinuous non-planar axial
distortion in serial section microscopy.

Hanslovsky P(1), Bogovic JA(1), Saalfeld S(1).

Author information: 
(1)HHMI Janelia Research Campus, Ashburn, VA 20147, USA.

MOTIVATION: Serial section microscopy is an established method for detailed
anatomy reconstruction of biological specimen. During the last decade, high
resolution electron microscopy (EM) of serial sections has become the de-facto
standard for reconstruction of neural connectivity at ever increasing scales (EM 
connectomics). In serial section microscopy, the axial dimension of the volume is
sampled by physically removing thin sections from the embedded specimen and
subsequently imaging either the block-face or the section series. This process
has limited precision leading to inhomogeneous non-planar sampling of the axial
dimension of the volume which, in turn, results in distorted image volumes. This 
includes that section series may be collected and imaged in unknown order.
RESULTS: We developed methods to identify and correct these distortions through
image-based signal analysis without any additional physical apparatus or
measurements. We demonstrate the efficacy of our methods in proof of principle
experiments and application to real world problems.
AVAILABILITY AND IMPLEMENTATION: We made our work available as libraries for the 
ImageJ distribution Fiji and for deployment in a high performance parallel
computing environment. Our sources are open and available at
http://github.com/saalfeldlab/section-sort,
http://github.com/saalfeldlab/z-spacing and
http://github.com/saalfeldlab/z-spacing-spark CONTACT: :
saalfelds@janelia.hhmi.orgSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw794 
PMID: 28011788  [PubMed - as supplied by publisher]


108. Bioinformatics. 2016 Dec 23. pii: btw797. doi: 10.1093/bioinformatics/btw797.
[Epub ahead of print]

VarMatch: robust matching of small variant datasets using flexible scoring
schemes.

Sun C(1), Medvedev P(2,)(3,)(4).

Author information: 
(1)Department of Computer Science and Engineering, The Pennsylvania State
University, USA chensun@cse.psu.edu. (2)Department of Computer Science and
Engineering, The Pennsylvania State University, USA. (3)Department of
Biochemistry and Molecular Biology, The Pennsylvania State University, USA.
(4)Genome Sciences Institute at the Huck, The Pennsylvania State University, USA.

MOTIVATION: Small variant calling is an important component of many analyses,
and, in many instances, it is important to determine the set of variants which
appear in multiple callsets. Variant matching is complicated by variants that
have multiple equivalent representations. Normalization and decomposition
algorithms have been proposed, but are not robust to different representation of 
complex variants. Variant matching is also usually done to maximize the number of
matches, as opposed to other optimization criteria.
RESULTS: We present the VarMatch algorithm for the variant matching problem. Our 
algorithm is based on a theoretical result which allows us to partition the input
into smaller subproblems without sacrificing accuracy. VarMatch is robust to
different representation of complex variants and is particularly effective in low
complexity regions or those dense in variants. VarMatch is able to detect more
matches than either the normalization or decomposition algorithms on tested
datasets. It also implements different optimization criteria, such as edit
distance, that can improve robustness to different variant representations.
Finally, the VarMatch software provides summary statistics, annotations, and
visualizations that are useful for understanding callers' performance.
AVAILABILITY: VarMatch is freely available at:
https://github.com/medvedevgroup/varmatch CONTACT: chensun@cse.psu.edu.

© The Author (2016). Published by Oxford University Press. All rights reserved.
For Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw797 
PMID: 28011786  [PubMed - as supplied by publisher]


109. Bioinformatics. 2016 Dec 23. pii: btw802. doi: 10.1093/bioinformatics/btw802.
[Epub ahead of print]

Wright-Fisher Exact Solver (WFES): Scalable analysis of population genetic models
without simulation or diffusion theory.

Krukov I(1,)(2), de Sanctis B(1), de Koning AP(3,)(2,)(4).

Author information: 
(1)Dept. of Biochemistry and Molecular Biology, Cumming School of Medicine,
University of Calgary, Calgary, Alberta, T2N 1N4, Canada. (2)Doctoral Program in 
Biochemistry and Molecular Biology, Bioinformatics Stream, University of Calgary.
(3)Dept. of Biochemistry and Molecular Biology, Cumming School of Medicine,
University of Calgary, Calgary, Alberta, T2N 1N4, Canada
Jason.DeKoning@ucalgary.ca. (4)Dept. of Medical Genetics & Alberta Children's
Hospital Research Institute, University of Calgary, Calgary, Alberta, T2N 1N4,
Canada.

MOTIVATION: The simplifying assumptions that are used widely in theoretical
population genetics may not always be appropriate for empirical population
genetics. General computational approaches that do not require the assumptions of
classical theory are therefore quite desirable. One such general approach is
provided by the theory of absorbing Markov chains, which can be used to obtain
exact results by directly analyzing population genetic Markov models, such as the
classic bi-allelic Wright-Fisher model. Although these approaches are sometimes
used, they are usually forgone in favour of simulation methods, due to the
perception that they are too computationally burdensome. Here we show that,
surprisingly, direct analysis of virtually any Markov chain model in population
genetics can be made quite efficient by exploiting transition matrix sparsity and
by solving restricted systems of linear equations, allowing a wide variety of
exact calculations (within machine precision) to be easily and rapidly made on
modern workstation computers.
RESULTS: We introduce Wright-Fisher Exact Solver (WFES), a fast and scalable
method for direct analysis of Markov chain models in population genetics. WFES
can rapidly solve for both longterm and transient behaviours including fixation
and extinction probabilities, expected times to fixation or extinction, sojourn
times, expected allele age and variance, and others. Our implementation requires 
only seconds to minutes of runtime on modern workstations and scales to
biological population sizes ranging from humans to model organisms.
AVAILABILITY: The code is available at https://github.com/dekoning-lab/wfes
CONTACT: jason.dekoning@ucalgary.ca SUPPLEMENTARY INFORMATION: Supplementary data
are available at Bioinformatics online.

© The Author(s) 2016. Published by Oxford University Press on behalf of the
Society for Molecular Biology and Evolution.

DOI: 10.1093/bioinformatics/btw802 
PMID: 28011785  [PubMed - as supplied by publisher]


110. Bioinformatics. 2016 Dec 23. pii: btw795. doi: 10.1093/bioinformatics/btw795.
[Epub ahead of print]

GppFst: genomic posterior predictive simulations of FST and dXY for identifying
outlier loci from population genomic data.

Adams RH(1), Schield DR(1), Card DC(1), Blackmon H(2), Castoe TA(1).

Author information: 
(1)Department of Biology, The University of Texas at Arlington, Arlington, TX
76019, USA. (2)Department of Ecology, Evolution & Behavior, University of
Minnesota, Saint Paul, MN 55108, USA.

We introduce GppFst, an open source R package that generates posterior predictive
distributions of FST and dx under a neutral coalescent model to identify putative
targets of selection from genomic data.AVAILABILITY AND IMPLEMENTATION: GppFst is
available at (https://github.com/radamsRHA/GppFst).
CONTACT: todd.castoe@uta.eduSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw795 
PMID: 28011784  [PubMed - as supplied by publisher]


111. Bioinformatics. 2016 Dec 23. pii: btw793. doi: 10.1093/bioinformatics/btw793.
[Epub ahead of print]

A new method for decontamination of de novo transcriptomes using a hierarchical
clustering algorithm.

Lafond-Lapalme J(1,)(2), Duceppe MO(1), Wang S(3), Moffett P(2), Mimee B(4).

Author information: 
(1)Agriculture and Agri-Food Canada, 430 Gouin Boulevard,
Saint-Jean-sur-Richelieu, QC, Canada, J3B 3E6. (2)Département de biologie,
Université de Sherbrooke, Sherbrooke, QC, Canada, J1K 2R1. (3)Département
d'informatique, Université de Sherbrooke, Sherbrooke, QC, Canada, J1K 2R1.
(4)Agriculture and Agri-Food Canada, 430 Gouin Boulevard,
Saint-Jean-sur-Richelieu, QC, Canada, J3B 3E6 benjamin.mimee@agr.gc.ca.

MOTIVATION: The identification of contaminating sequences in a de novo assembly
is challenging because of the absence of information on the target species. For
sample types where the target organism is impossible to isolate from its matrix, 
such as endoparasites, endosymbionts and soil-harvested samples, contamination is
unavoidable. A few post-assembly decontamination methods are currently available 
but are based only on alignments to databases, which can lead to poor
decontamination.
RESULTS: We present a new decontamination method based on a hierarchical
clustering algorithm called MCSC. This method uses frequent patterns found in
sequences to create clusters. These clusters are then linked to the target
species or tagged as contaminants using classic alignment tools. The main
advantage of this decontamination method is that it allows sequences to be tagged
correctly even if they are unknown or misaligned to a database.
AVAILABILITY: Scripts and documentation about the MCSC decontamination method are
available at https://github.com/Lafond-LapalmeJ/MCSC_Decontamination CONTACT:
benjamin.mimee@agr.gc.ca SUPPLEMENTARY INFORMATION: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press on behalf of the Society 
for Molecular Biology and Evolution. All rights reserved. For permissions, please
e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw793 
PMID: 28011783  [PubMed - as supplied by publisher]


112. Bioinformatics. 2016 Dec 23. pii: btw796. doi: 10.1093/bioinformatics/btw796.
[Epub ahead of print]

Inference of cellular level signaling networks using single-cell gene expression 
data in C. elegans reveals mechanisms of cell fate specification.

Huang XT(1,)(2), Zhu Y(3), Hang Chan LL(2), Zhao Z(4), Yan H(2).

Author information: 
(1)School of Computer Science and Technology, Xidian University, Xi'an, Shaanxi, 
China. (2)Department of Electronic Engineering, City University of Hong Kong,
Hong Kong, China. (3)School of Automation, China University of Geosciences,
Wuhan, China zhuyuan@cug.edu.cn. (4)Department of Biology, Hong Kong Baptist
University, Hong Kong, China.

MOTIVATION: Cell fate specification plays a key role to generate distinct cell
types during metazoan development. However, most of the underlying signaling
networks at cellular level are not well understood. Availability of time lapse
single-cell gene expression data collected throughout C. elegans embryogenesis
provides an excellent opportunity for investigating signaling networks underlying
cell fate specification at systems, cellular and molecular levels.
RESULTS: We propose a framework to infer signaling networks at cellular level by 
exploring the single-cell gene expression data. Through analyzing the expression 
data of nhr-25, a hypodermis-specific transcription factor, in every cells of
both wild-type and mutant C. elegans embryos through RNAi against 55 genes, we
have inferred a total of 23 genes that regulate (activate or inhibit) nhr-25
expression in cell-specific fashion. We also infer the signaling pathways
consisting of each of these genes and nhr-25 based on a probabilistic graphical
model for the selected five founder cells, 'ABarp', 'ABpla', 'Bpra', 'Caa' and
'Cpa', which express nhr-25 and mostly develop into hypodermis. By integrating
the inferred pathways, we reconstruct five signaling networks with one each for
the five founder cells. Using RNAi gene knockdown as a validation method, the
inferred networks are able to predict the effects of the knockdown genes. These
signaling networks in the five founder cells are likely to ensure faithful
hypodermis cell fate specification in C. elegans at cellular level.
AVAILABILITY: All source codes and data are available at the github repository
https://github.com/xthuang226/Worm_Single_Cell_Data_and_Codes.git CONTACT:
zhuyuan@cug.edu.cn SUPPLEMENTARY INFORMATION: Supplementary data are available at
Bioinformatics online.

© The Author 2016. Published by Oxford University Press on behalf of the Society 
for Molecular Biology and Evolution. All rights reserved. For permissions, please
e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw796 
PMID: 28011782  [PubMed - as supplied by publisher]


113. Bioinformatics. 2016 Dec 22. pii: btw726. doi: 10.1093/bioinformatics/btw726.
[Epub ahead of print]

cerebroViz: An R package for anatomical visu-alization of spatiotemporal brain
data.

Bahl E(1), Koomar T(2), Michaelson JJ(1).

Author information: 
(1)Department of Psychiatry; University of Iowa Carver College of Medicine; Iowa 
City, IA, USA. ethan-bahl@uiowa.edu jacob-michaelson@uiowa.edu. (2)Department of 
Psychiatry; University of Iowa Carver College of Medicine; Iowa City, IA, USA.

Spatiotemporal transcriptomic profiling has provided valuable insight into the
patterning of gene expression throughout the human brain from early fetal
development to adulthood. When combined with prior knowledge of a disease's age
at onset and region-specificity, these expression profiles have provided the
necessary context to both strengthen putative gene-disease associations and infer
new associations. While a wealth of spatiotemporal expression data exists, there 
are currently no tools available to visualize this data within the anatomical
context of the brain, thus limiting the intuitive interpretation of many such
findings. We present cerebroViz, an R package to map spatiotemporal brain data to
vector graphic diagrams of the human brain. Our tool allows rapid generation of
publication-quality figures that highlight spatiotemporal trends in the input
data, while striking a balance between usability and customization. cerebroViz is
generalizable to any data quantifiable at a brain-regional resolution and
currently supports visualization of up to thirty regions of the brain found in
databases such as BrainSpan, GTEx, and Roadmap Epigenomics.AVAILABILITY:
cerebroViz is freely available through GitHub
(https://github.com/ethanbahl/cerebroViz). The tutorial is available at
http://ethanbahl.github.io/cerebroViz/ CONTACT: ethan-bahl@uiowa.edu and
jacob-michaelson@uiowa.edu SUPPLEMENTARY INFORMATION: Supplementary data are
available at Bioinformatics online.

© The Author(s) 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw726 
PMID: 28011779  [PubMed - as supplied by publisher]


114. Bioinformatics. 2016 Dec 22. pii: btw688. doi: 10.1093/bioinformatics/btw688.
[Epub ahead of print]

ALTRE: workflow for defining ALTered Regulatory Elements using chromatin
accessibility data.

Baskin E(1), Farouni R(1), Mathé EA(1).

Author information: 
(1)Department of Biomedical Informatics, College of Medicine, The Ohio State
University, Columbus, OH 43210, USA.

: Regulatory elements regulate gene transcription, and their location and
accessibility is cell-type specific, particularly for enhancers. Mapping and
comparing chromatin accessibility between different cell types may identify
mechanisms involved in cellular development and disease progression. To
streamline and simplify differential analysis of regulatory elements genome-wide 
using chromatin accessibility data, such as DNase-seq, ATAC-seq, we developed
ALTRE (ALTered Regulatory Elements), an R package and associated R Shiny web app.
ALTRE makes such analysis accessible to a wide range of users-from novice to
practiced computational biologists.AVAILABILITY AND IMPLEMENTATION:
https://github.com/Mathelab/ALTRE CONTACT: ewy.mathe@osumc.eduSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw688 
PMID: 28011773  [PubMed - as supplied by publisher]


115. Bioinformatics. 2016 Oct 6. pii: btw622. doi: 10.1093/bioinformatics/btw622.
[Epub ahead of print]

Simulation-based estimation of branching models for LTR retrotransposons.

Moulin S(1), Seux N(2), Chrétien S(3), Guyeux C(1), Lerat E(4).

Author information: 
(1)Département d'Informatique des Systèmes Complexes, FEMTO-ST Institute, UMR
6174 CNRS, Université de Bourgogne Franche-Comté, 25030 Besançon, France.
(2)Laboratoire de Mathématiques de Besançon, UMR 6623 CNRS, Université de
Bourgogne Franche-Comté, 25030 Besançon, France. (3)National Physical Laboratory,
Teddington, UK. (4)Université de Lyon, Université Claude Bernard Lyon 1, CNRS,
UMR 5558, Laboratoire Biométrie et Biologie Evolutive, F-69622 Villeurbanne,
France.

MOTIVATION: LTR retrotransposons are mobile elements that are able, like
retroviruses, to copy and move inside eukaryotic genomes. In the present work, we
propose a branching model for studying the propagation of LTR retrotransposons in
these genomes. This model allows us to take into account both the positions and
the degradation level of LTR retrotransposons copies. In our model, the
duplication rate is also allowed to vary with the degradation level.
RESULTS: Various functions have been implemented in order to simulate their
spread and visualization tools are proposed. Based on these simulation tools, we 
have developed a first method to evaluate the parameters of this propagation
model. We applied this method to the study of the spread of the transposable
elements ROO, GYPSY and DM412 on a chromosome of Drosophila
melanogasterAvailability and Implementation: Our proposal has been implemented
using Python software. Source code is freely available on the web at
https://github.com/SergeMOULIN/retrotransposons-spread CONTACT:
serge.moulin@univ-fcomte.fr SUPPLEMENTARY INFORMATION: : are available at
Bioinformatics online.

© The Authors 2016. Published by Oxford University Press. All rights reserved.
For Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw622 
PMID: 28011770  [PubMed - as supplied by publisher]


116. Bioinformatics. 2016 Dec 22. pii: btw741. doi: 10.1093/bioinformatics/btw741.
[Epub ahead of print]

SeqLib: a C ++ API for rapid BAM manipulation, sequence alignment and sequence
assembly.

Wala J(1,)(2,)(3), Beroukhim R(1,)(2,)(3).

Author information: 
(1)The Broad Institute of Harvard and MIT, Cambridge, MA 02142, USA.
(2)Bioinformatics and Integrative Genomics, Harvard University, Cambridge, MA
02138, USA. (3)Department of Cancer Biology, Dana-Farber Cancer Institute,
Boston, MA 02115, USA.

We present SeqLib, a C ++ API and command line tool that provides a rapid and
user-friendly interface to BAM/SAM/CRAM files, global sequence alignment
operations and sequence assembly. Four C libraries perform core operations in
SeqLib: HTSlib for BAM access, BWA-MEM and BLAT for sequence alignment and Fermi 
for error correction and sequence assembly. Benchmarking indicates that SeqLib
has lower CPU and memory requirements than leading C ++ sequence analysis APIs.
We demonstrate an example of how minimal SeqLib code can extract, error-correct
and assemble reads from a CRAM file and then align with BWA-MEM. SeqLib also
provides additional capabilities, including chromosome-aware interval queries and
read plotting. Command line tools are available for performing integrated error
correction, micro-assemblies and alignment.AVAILABILITY AND IMPLEMENTATION:
SeqLib is available on Linux and OSX for the C ++98 standard and later at
github.com/walaj/SeqLib. SeqLib is released under the Apache2 license. Additional
capabilities for BLAT alignment are available under the BLAT license.
CONTACT: jwala@broadinstitue.org; rameen@broadinstitute.org.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw741 
PMID: 28011768  [PubMed - as supplied by publisher]


117. Bioinformatics. 2016 Dec 22. pii: btw782. doi: 10.1093/bioinformatics/btw782.
[Epub ahead of print]

Analyzing user-generated online content for drug discovery: development and use
of MedCrawler.

Helfenstein A(1), Tammela P(1).

Author information: 
(1)Division of Pharmaceutical Biosciences, Faculty of Pharmacy, Centre for Drug
Research, University of Helsinki, Helsinki FI-00014, Finland.

MOTIVATION: Ethnopharmacology, or the scientific validation of traditional
medicine, is a respected starting point in drug discovery. Home remedies and
traditional use of plants are still widespread, also in Western societies.
Instead of perusing ancient pharmacopeias, we developed MedCrawler, which we used
to analyze blog posts for mentions of home remedies and their applications. This 
method is free and accessible from the office computer.
RESULTS: We developed MedCrawler, a data mining tool for analyzing user-generated
blog posts aiming to find modern 'traditional' medicine or home remedies. It
searches user-generated blog posts and analyzes them for correlations between
medically relevant terms. We also present examples and show that this method is
capable of delivering both scientifically validated uses as well as not so well
documented applications, which might serve as a starting point for follow-up
research.
AVAILABILITY AND IMPLEMENTATION: Source code is available on GitHub at
{{https://github.com/a-hel/medcrawler}} CONTACT:
paivi.tammela@helsinki.fiSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw782 
PMID: 28011767  [PubMed - as supplied by publisher]


118. Front Genet. 2016 Dec 8;7:214. doi: 10.3389/fgene.2016.00214. eCollection 2016.

MICADo - Looking for Mutations in Targeted PacBio Cancer Data: An Alignment-Free 
Method.

Rudewicz J(1), Soueidan H(2), Uricaru R(2), Bonnefoi H(3), Iggo R(3), Bergh J(4),
Nikolski M(2).

Author information: 
(1)Centre de BioInformatique de Bordeaux, University of BordeauxBordeaux, France;
Laboratoire Bordelais de Recherche en Informatique, Centre National de la
Recherche Scientifique, University of BordeauxBordeaux, France; Bergonié Cancer
Institute, Institut National de la Santé et de la Recherche Médicale U1218,
University of BordeauxBordeaux, France. (2)Centre de BioInformatique de Bordeaux,
University of BordeauxBordeaux, France; Laboratoire Bordelais de Recherche en
Informatique, Centre National de la Recherche Scientifique, University of
BordeauxBordeaux, France. (3)Bergonié Cancer Institute, Institut National de la
Santé et de la Recherche Médicale U1218, University of Bordeaux Bordeaux, France.
(4)Karolinska Institute and University Hospital Stockholm, Sweden.

Targeted sequencing is commonly used in clinical application of NGS technology
since it enables generation of sufficient sequencing depth in the targeted genes 
of interest and thus ensures the best possible downstream analysis. This
notwithstanding, the accurate discovery and annotation of disease causing
mutations remains a challenging problem even in such favorable context. The
difficulty is particularly salient in the case of third generation sequencing
technology, such as PacBio. We present MICADo, a de Bruijn graph based method,
implemented in python, that makes possible to distinguish between patient
specific mutations and other alterations for targeted sequencing of a cohort of
patients. MICADo analyses NGS reads for each sample within the context of the
data of the whole cohort in order to capture the differences between
specificities of the sample with respect to the cohort. MICADo is particularly
suitable for sequencing data from highly heterogeneous samples, especially when
it involves high rates of non-uniform sequencing errors. It was validated on
PacBio sequencing datasets from several cohorts of patients. The comparison with 
two widely used available tools, namely VarScan and GATK, shows that MICADo is
more accurate, especially when true mutations have frequencies close to backgound
noise. The source code is available at http://github.com/cbib/MICADo.

DOI: 10.3389/fgene.2016.00214 
PMCID: PMC5143680
PMID: 28008336  [PubMed]


119. Genetics. 2016 Dec 22. pii: genetics.116.193425. doi:
10.1534/genetics.116.193425. [Epub ahead of print]

Inferring Ancestral Recombination Graphs from Bacterial Genomic Data.

Vaughan TG(1), Welch D(2), Drummond AJ(2), Biggs PJ(3), George T(3), French
NP(3).

Author information: 
(1)University of Auckland; tgvaughan@gmail.com. (2)University of Auckland.
(3)Massey University.

Homologous recombination is a central feature of bacterial evolution, yet
confounds traditional phylogenetic methods. While a number of methods specific to
bacterial evolution have been developed, none of these permit joint inference of 
a bacterial recombination graph and associated parameters. In this paper, we
present a new method which addresses this shortcoming. Our method uses a novel
Markov chain Monte Carlo algorithm to perform phylogenetic inference under the
ClonalOrigin model of Didelot et al. (Genetics, 2010). We demonstrate the utility
of our method by applying it to rMLST data sequenced from pathogenic and
non-pathogenic Escherichia coli serotype O157 and O26 isolates collected in rural
New Zealand. The method is implemented as an open source BEAST 2 package, Bacter,
which is available via the project web page at http://tgvaughan.github.io/bacter.

Copyright © 2016, The Genetics Society of America.

DOI: 10.1534/genetics.116.193425 
PMID: 28007885  [PubMed - as supplied by publisher]


120. Bioinformatics. 2016 Dec 21. pii: btw805. doi: 10.1093/bioinformatics/btw805.
[Epub ahead of print]

GWAlpha: genome-wide estimation of additive effects (alpha) based on trait
quantile distribution from pool-sequencing experiments.

Fournier-Level A(1), Robin C(1), Balding DJ(1,)(2).

Author information: 
(1)School of BioSciences and Centre for Systems Genomics. (2)School of
Mathematics and Statistics, The University of Melbourne, Parkville 3010,
Australia.

MOTIVATION: Sequencing pools of individuals (Pool-Seq) is a cost-effective way to
gain insight into the genetics of complex traits, but as yet no parametric method
has been developed to both test for genetic effects and estimate their magnitude.
Here, we propose GWAlpha, a flexible method to obtain parametric estimates of
genetic effects genome-wide from Pool-Seq experiments.
RESULTS: We showed that GWAlpha powerfully replicates the results of Genome-Wide 
Association Studies (GWAS) from model organisms. We perform simulation studies
that illustrate the effect on power of sample size and number of pools and test
the method on different experimental data.
AVAILABILITY AND IMPLEMENTATION: GWAlpha is implemented in python, designed to
run on Linux operating system and tested on Mac OS. It is freely available at
https://github.com/aflevel/GWAlpha CONTACT: afournier@unimelb.edu.auSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw805 
PMID: 28003266  [PubMed - as supplied by publisher]


121. Bioinformatics. 2016 Dec 21. pii: btw810. doi: 10.1093/bioinformatics/btw810.
[Epub ahead of print]

Defining the clonality of peripheral T cell lymphomas using RNA-seq.

Brown SD(1,)(2), Hapgood G(3), Steidl C(4), Weng AP(5), Savage KJ(3), Holt
RA(1,)(2,)(6,)(7).

Author information: 
(1)Canada's Michael Smith Genome Sciences Centre, BC Cancer Agency, Vancouver,
British Columbia V5Z 1L3, Canada. (2)Genome Science and Technology Program,
University of British Columbia, Vancouver, British Columbia V6T 1Z4, Canada.
(3)Centre for Lymphoid Cancer, Department of Medical Oncology, British Columbia
Cancer Agency, Vancouver, Canada. (4)Centre for Lymphoid Cancer, Department of
Lymphoid Cancer Research, British Columbia Cancer Agency, Vancouver, Canada.
(5)Terry Fox Laboratory and Department of Pathology, British Columbia Cancer
Agency, Vancouver, Canada. (6)Department of Molecular Biology and Biochemistry,
Simon Fraser University, Burnaby, British Columbia V5A 1S6, Canada. (7)Department
of Medical Genetics, University of British Columbia, Vancouver, British Columbia 
V6T 1Z4, Canada.

MOTIVATION: In T-cell lymphoma, malignant T cells arising from a founding clone
share an identical T cell receptor (TCR) and can be identified by the
over-representation of this TCR relative to TCRs from the patient's repertoire of
normal T cells. Here, we demonstrate that TCR information extracted from RNA-seq 
data can provide a higher resolution view of peripheral T cell lymphomas (PTCLs) 
than that provided by conventional methods.
RESULTS: For 60 subjects with PTCL, flow cytometry/FACS was used to identify and 
sort aberrant T cell populations from diagnostic lymph node cell suspensions. For
samples that did not appear to contain aberrant T cell populations, T helper
(TH), T follicular helper (TFH) and cytotoxic T lymphocyte (CTL) subsets were
sorted. RNA-seq was performed on sorted T cell populations, and TCR alpha and
beta chain sequences were extracted and quantified directly from the RNA-seq
data. 96% of the immunophenotypically aberrant samples had a dominant T cell
clone readily identifiable by RNA-seq. Of the samples where no aberrant
population was found by flow cytometry, 80% had a dominant clone by RNA-seq. This
demonstrates the increased sensitivity and diagnostic ability of RNA-seq over
flow cytometry and shows that the presence of a normal immunophenotype does not
exclude clonality.
AVAILABILITY AND IMPLEMENTATION: R scripts used in the processing of the data are
available online at https://www.github.com/scottdbrown/RNAseq-TcellClonality
CONTACTS: rholt@bcgsc.ca or ksavage@bccancer.bc.caSupplementary information:
Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw810 
PMID: 28003262  [PubMed - as supplied by publisher]


122. Bioinformatics. 2016 Dec 21. pii: btw809. doi: 10.1093/bioinformatics/btw809.
[Epub ahead of print]

MEGA-V: detection of variant gene sets in patient cohorts.

Gambardella G(1), Cereda M(1), Benedetti L(1), Ciccarelli FD(1).

Author information: 
(1)Division of Cancer Studies, King's College London, SE11UL London, UK.

: Detecting significant associations between genetic variants and disease may
prove particularly challenging when the variants are rare in the population
and/or act together with other variants to cause the disease. We have developed a
statistical framework named Mutation Enrichment Gene set Analysis of Variants
(MEGA-V) that specifically detects the enrichments of genetic alterations within 
a process in a cohort of interest. By focusing on the mutations of several genes 
contributing to the same function rather than on those affecting a single gene,
MEGA-V increases the power to detect statistically significant
associations.AVAILABILITY AND IMPLEMENTATION: MEGA-V is available at
https://github.com/ciccalab/MEGA CONTACT:
francesca.ciccarelli@kcl.ac.ukSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw809 
PMID: 28003259  [PubMed - as supplied by publisher]


123. Bioinformatics. 2016 Dec 21. pii: btw675. doi: 10.1093/bioinformatics/btw675.
[Epub ahead of print]

The Ark: a customizable web-based data management tool for health and medical
research.

Bickerstaffe A(1), Ranaweera T(1), Endersby T(2,)(3), Ellis C(2,)(3),
Maddumarachchi S(1), Gooden GE(4), White P(2,)(3), Moses EK(2,)(3), Hewitt AW(5),
Hopper JL(1).

Author information: 
(1)Centre for Epidemiology and Biostatistics, The University of Melbourne,
Carlton, 3010, Australia. (2)Curtin UWA Centre for Genetic Origins of Health and 
Disease, Faculty of Health Sciences, Curtin University, Bentley, 6102, Australia.
(3)Faculty of Medicine, Dentistry and Health Sciences, The University of Western 
Australia, Perth, 6000, Australia. (4)Genetics and Epidemiology, Lions Eye
Institute, Nedlands, 6009, Australia. (5)Centre for Eye Research Australia, Royal
Victorian Eye and Ear Hospital, East Melbourne, 3002, Australia.

The Ark is an open-source web-based tool that allows researchers to manage health
and medical research data for humans and animals without specialized database
skills or programming expertise. The system provides data management for core
research information including demographic, phenotype, biospecimen and pedigree
data, in addition to supporting typical investigator requirements such as
tracking participant consent and correspondence, whilst also being able to
generate custom data exports and reports. The Ark is 'study generic' by design
and highly configurable via its web interface, allowing researchers to tailor the
system to the specific data management requirements of their study.AVAILABILITY
AND IMPLEMENTATION: Source code for The Ark can be obtained freely from the
website https://github.com/The-Ark-Informatics/ark/ The source code can be
modified and redistributed under the terms of the GNU GPL v3 license.
Documentation and a pre-configured virtual appliance can be found at the website 
http://sphinx.org.au/the-ark/ CONTACT: adrianb@unimelb.edu.auSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw675 
PMID: 28003258  [PubMed - as supplied by publisher]


124. Bioinformatics. 2016 Dec 21. pii: btw685. doi: 10.1093/bioinformatics/btw685.
[Epub ahead of print]

HYSYS: have you swapped your samples?

Schröder J(1,)(2,)(3), Corbin V(1,)(4), Papenfuss AT(1,)(4,)(3,)(5).

Author information: 
(1)Bioinformatics Division, The Walter & Eliza Hall Institute, Parkville 3052,
Australia. (2)Computing and Information Systems. (3)Peter MacCallum Cancer
Centre, Melbourne 3000, Australia. (4)Department of Medical Biology, The
University of Melbourne, Melbourne 3010, Australia. (5)Sir Peter MacCallum
Department of Oncology, University of Melbourne, Melbourne 3010, Australia.

MOTIVATION: The application of a genomics assay to samples from a cohort is a
frequently applied experimental design in cancer genomics studies. The collection
and analysis of cancer sequencing data in the clinical setting is an elaborate
process that may involve consenting patients, obtaining possibly-multiple DNA
samples, sequencing and analysis. Many of these steps are manual. At any stage
mistakes can occur that cause a DNA sample to be labelled incorrectly. However,
there is a paucity of methods in the literature to identify such swaps
specifically in cancer studies.
RESULTS: Here, we introduce a simple method, HYSYS, to estimate the relatedness
of samples and test for sample swaps and contamination. The test uses the
concordance of homozygous SNPs between samples. The method is motivated by the
observation that homozygous germline population variants rarely change in the
disease and are not affected by loss of heterozygosity. Our tools include
visualization and a testing framework to flag possible sample swaps. We
demonstrate the utility of this approach on a small cohort.
AVAILABILITY AND IMPLEMENTATION:
http://github.com/PapenfussLab/HaveYouSwappedYourSamples CONTACT:
papenfuss@wehi.edu.auSupplementary information: Supplementary data are available 
at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw685 
PMID: 28003257  [PubMed - as supplied by publisher]


125. Bioinformatics. 2016 Dec 21. pii: btw651. doi: 10.1093/bioinformatics/btw651.
[Epub ahead of print]

Recycler: an algorithm for detecting plasmids from de novo assembly graphs.

Rozov R(1), Brown Kav A(2), Bogumil D(2), Shterzer N(2), Halperin E(1,)(3,)(4),
Mizrahi I(2), Shamir R(1).

Author information: 
(1)Blavatnik School of Computer Science, Tel-Aviv University, Tel Aviv, Israel.
(2)The Department of Life Sciences & the National Institute for Biotechnology in 
the Negev, Ben-Gurion University of the Negev, Beer-Sheva, Israel. (3)Molecular
Microbiology and Biotechnology Department, Tel-Aviv University, Tel Aviv, Israel.
(4)International Computer Science Institute, Berkeley, CA, USA.

MOTIVATION: Plasmids and other mobile elements are central contributors to
microbial evolution and genome innovation. Recently, they have been found to have
important roles in antibiotic resistance and in affecting production of
metabolites used in industrial and agricultural applications. However, their
characterization through deep sequencing remains challenging, in spite of rapid
drops in cost and throughput increases for sequencing. Here, we attempt to
ameliorate this situation by introducing a new circular element assembly
algorithm, leveraging assembly graphs provided by a conventional de novo
assembler and alignments of paired-end reads to assemble cyclic sequences likely 
to be plasmids, phages and other circular elements.
RESULTS: We introduce Recycler, the first tool that can extract complete circular
contigs from sequence data of isolate microbial genomes, plasmidome and
metagenome sequence data. We show that Recycler greatly increases the number of
true plasmids recovered relative to other approaches while remaining highly
accurate. We demonstrate this trend via simulations of plasmidomes, comparisons
of predictions with reference data for isolate samples, and assessments of
annotation accuracy on metagenome data. In addition, we provide validation by DNA
amplification of 77 plasmids predicted by Recycler from the different sequenced
samples in which Recycler showed mean accuracy of 89% across all data
types-isolate, microbiome and plasmidome.
AVAILABILITY AND IMPLEMENTATION: Recycler is available at
http://github.com/Shamir-Lab/Recycler CONTACT: imizrahi@bgu.ac.ilSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw651 
PMID: 28003256  [PubMed - as supplied by publisher]


126. PLoS One. 2016 Dec 21;11(12):e0168392. doi: 10.1371/journal.pone.0168392.
eCollection 2016.

Integrated Strategy Improves the Prediction Accuracy of miRNA in Large Dataset.

Xue B(1), Lipps D(1), Devineni S(1).

Author information: 
(1)Department of Cell Biology, Microbiology and Molecular Biology, School of
Natural Sciences and Mathematics, College of Arts and Sciences, University of
South Florida, Tampa, Florida, United States of America.

MiRNAs are short non-coding RNAs of about 22 nucleotides, which play critical
roles in gene expression regulation. The biogenesis of miRNAs is largely
determined by the sequence and structural features of their parental RNA
molecules. Based on these features, multiple computational tools have been
developed to predict if RNA transcripts contain miRNAs or not. Although being
very successful, these predictors started to face multiple challenges in recent
years. Many predictors were optimized using datasets of hundreds of miRNA
samples. The sizes of these datasets are much smaller than the number of known
miRNAs. Consequently, the prediction accuracy of these predictors in large
dataset becomes unknown and needs to be re-tested. In addition, many predictors
were optimized for either high sensitivity or high specificity. These
optimization strategies may bring in serious limitations in applications.
Moreover, to meet continuously raised expectations on these computational tools, 
improving the prediction accuracy becomes extremely important. In this study, a
meta-predictor mirMeta was developed by integrating a set of non-linear
transformations with meta-strategy. More specifically, the outputs of five
individual predictors were first preprocessed using non-linear transformations,
and then fed into an artificial neural network to make the meta-prediction. The
prediction accuracy of meta-predictor was validated using both multi-fold
cross-validation and independent dataset. The final accuracy of meta-predictor in
newly-designed large dataset is improved by 7% to 93%. The meta-predictor is also
proved to be less dependent on datasets, as well as has refined balance between
sensitivity and specificity. This study has two folds of importance: First, it
shows that the combination of non-linear transformations and artificial neural
networks improves the prediction accuracy of individual predictors. Second, a new
miRNA predictor with significantly improved prediction accuracy is developed for 
the community for identifying novel miRNAs and the complete set of miRNAs. Source
code is available at: https://github.com/xueLab/mirMeta.

DOI: 10.1371/journal.pone.0168392 
PMCID: PMC5176297
PMID: 28002428  [PubMed - in process]


127. Bioinformatics. 2016 Dec 20. pii: btw687. doi: 10.1093/bioinformatics/btw687.
[Epub ahead of print]

A pipeline for local assembly of minisatellite alleles from single-molecule
sequencing data.

Ogeh D(1), Badge R(1).

Author information: 
(1)Department of Genetics, University of Leicester, Leicester, UK.

MOTIVATION: The advent of Next Generation Sequencing (NGS) has led to the
generation of enormous volumes of short read sequence data, cheaply and in
reasonable time scales. Nevertheless, the quality of genome assemblies generated 
using NGS technologies has been greatly affected, compared to those generated
using Sanger DNA sequencing. This is largely due to the inability of short read
sequence data to scaffold repetitive structures, creating gaps, inversions and
rearrangements and resulting in assemblies that are, at best, draft forms. Third 
generation single-molecule sequencing (SMS) technologies (e.g. Pacific
Biosciences Single Molecule Real Time (SMRT) system) address this challenge by
generating sequences with increased read lengths, offering the prospect to better
recover these complex repetitive structures, concomitantly improving assembly
quality.
RESULTS: Here, we evaluate the ability of SMS data (specifically human genome
Pacific Biosciences SMRT data) to recover poorly represented repetitive sequences
(specifically, GC-rich human minisatellites). To do this we designed a pipeline
for the collection, processing and local assembly of single-molecule sequence
data to form accurate contiguous local reconstructions. Our results show the
recovery of an allele of the non-coding minisatellite MS1 (located on chromosome 
1 at 1p33-35) at greater than 97% identity to reference (GRCh38) from the
unprocessed sequence data of a haploid complete hydatidiform mole (CHM1) cell
line. Furthermore, our assembly revealed an allele of over 500 repeat units; much
larger than the reference (GRCh38), but consistent in structure with naturally
occurring alleles that are segregating in human populations. This local
assembly's reconstruction was validated with the release of the whole genome
assemblies GCA_001297185.1 and GCA_000772585.3, where this allele occurs.
Additionally, application of this pipeline to coding minisatellites in the PRDM9 
and ZNF93 genes enabled recovery of high identity allele structures for these
sequence regions whose length was confirmed by PCR from cell line genomic DNA.
The internal repeat structure of the PRDM9 allele recovered was consistent with
common human-specific alleles.
AVAILABILITY AND IMPLEMENTATION: Code available at
https://github.com/ndliberial/smrt_pipeline CONTACT: dno2@le.ac.uk.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw687 
PMID: 27998939  [PubMed - as supplied by publisher]


128. Bioinformatics. 2016 Dec 20. pii: btw707. doi: 10.1093/bioinformatics/btw707.
[Epub ahead of print]

CymeR: cytometry analysis using KNIME, Docker and R.

Muchmore B(1), Alarcon-Riquelme ME(2,)(3).

Author information: 
(1)Centre for Genomics and Oncological Research (GENYO), Pfizer-University of
Granada-Andalusian Regional Government, Health Sciences Technology Park, Granada 
18016, Spain. (2)Centre for Genomics and Oncological Research (GENYO),
Pfizer-University of Granada-Andalusian Regional Government, Health Sciences
Technology Park, Granada 18016, Spain., brian.muchmore@genyo.es. (3)IMM, Unit for
Chronic Inflammatory Diseases, Karolinska Institutet, Stockholm, 17177, Sweden.

Here we present open-source software for the analysis of high-dimensional
cytometry data using state of the art algorithms. Importantly, use of the
software requires no programming ability, and output files can either be
interrogated directly in CymeR or they can be used downstream with any other
cytometric data analysis platform. Also, because we use Docker to integrate the
multitude of components that form the basis of CymeR, we have additionally
developed a proof-of-concept of how future open-source bioinformatic programs
with graphical user interfaces could be developed.AVAILABILITY AND
IMPLEMENTATION: CymeR is open-source software that ties several components into a
single program that is perhaps best thought of as a self-contained data analysis 
operating system. Please see https://github.com/bmuchmore/CymeR/wiki for detailed
installation instructions.
CONTACT: brian.muchmore@genyo.es, marta.alarcon@genyo.es SUPPLEMENTARY
INFORMATION: Within CymeR, every function contains detailed instructions as well 
as links to resources when appropriate.

© The Author(s) 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw707 
PMID: 27998935  [PubMed - as supplied by publisher]


129. Nucleic Acids Res. 2016 Dec 19. pii: gkw1270. [Epub ahead of print]

Flexible model-based clustering of mixed binary and continuous data: application 
to genetic regulation and cancer.

Zainul Abidin FN(1,)(2), Westhead DR(3).

Author information: 
(1)School of Molecular and Cellular Biology, University of Leeds, Leeds, West
Yorkshire LS2 9JT, UK. (2)Institute of Systems Biology (INBIOSIS), Universiti
Kebangsaan Malaysia, 43600 Bangi, Selangor D.E., Malaysia. (3)School of Molecular
and Cellular Biology, University of Leeds, Leeds, West Yorkshire LS2 9JT, UK
D.R.Westhead@leeds.ac.uk.

Clustering is used widely in 'omics' studies and is often tackled with standard
methods, e.g. hierarchical clustering. However, the increasing need for
integration of multiple data sets leads to a requirement for clustering methods
applicable to mixed data types, where the straightforward application of standard
methods is not necessarily the best approach. A particularly common problem
involves clustering entities characterized by a mixture of binary data (e.g.
presence/absence of mutations, binding, motifs and epigenetic marks) and
continuous data (e.g. gene expression, protein abundance, metabolite levels).
Here, we present a generic method based on a probabilistic model for clustering
this type of data, and illustrate its application to genetic regulation and the
clustering of cancer samples. We show that the resulting clusters lead to useful 
hypotheses: in the case of genetic regulation these concern regulation of groups 
of genes by specific sets of transcription factors and in the case of cancer
samples combinations of gene mutations are related to patterns of gene
expression. The clusters have potential mechanistic significance and in the
latter case are significantly linked to survival. The method is available as a
stand-alone software package (GNU General Public Licence) from
http://github.com/BioToolsLeeds/FlexiCoClusteringPackage.git.

© The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkw1270 
PMID: 27994031  [PubMed - as supplied by publisher]


130. Bioinformatics. 2016 Dec 19. pii: btw708. doi: 10.1093/bioinformatics/btw708.
[Epub ahead of print]

SPADEVizR: an R package for Visualization, Analysis and Integration of SPADE
results.

Gautreau G(1), Pejoski D(1), Le Grand R(1), Cosma A(1), Beignon AS(1), Tchitchek 
N(2).

Author information: 
(1)CEA - Université Paris Sud 11 - INSERM U1184, Immunology of viral infections
and autoimmune diseases, Fontenay-aux-Roses, France. (2)CEA - Université Paris
Sud 11 - INSERM U1184, Immunology of viral infections and autoimmune diseases,
Fontenay-aux-Roses, France nicolas.tchitchek@gmail.com.

MOTIVATION: Flow, hyperspectral and mass cytometry are experimental techniques
measuring cell marker expressions at the single cell level. The recent increase
of the number of markers simultaneously measurable has led to the development of 
new automatic gating algorithms. Especially, the SPADE algorithm has been
proposed as a novel way to identify clusters of cells having similar phenotypes
in high-dimensional cytometry data. While SPADE or other cell clustering
algorithms are powerful approaches, complementary analysis features are needed to
better characterize the identified cell clusters.
RESULTS: We have developed SPADEVizR, an R package designed for the
visualization, analysis, and integration of cell clustering results. The
available statistical methods allow highlighting cell clusters with relevant
biological behaviors or integrating them with additional biological variables.
Moreover, several visualization methods are available to better characterize the 
cell clusters, such as volcano plots, streamgraphs, parallel coordinates,
heatmaps, or distograms. SPADEVizR can also generate linear, Cox or random forest
models to predict biological outcomes, based on the cell cluster abundances.
Additionally, SPADEVizR has several features allowing to quantify and to
visualize the quality of the cell clustering results. These analysis features are
essential to better interpret the behaviors and phenotypes of the identified cell
clusters. Importantly, SPADEVizR can handle clustering results from other
algorithms than SPADE.
AVAILABILITY: SPADEVizR is distributed under the GPL-3 license and is available
at https://github.com/tchitchek-lab/SPADEVizR CONTACT:
nicolas.tchitchek@gmail.com SUPPLEMENTARY INFORMATION: Supplementary data are
available at Bioinformatics online.

© The Author(s) 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw708 
PMID: 27993789  [PubMed - as supplied by publisher]


131. Bioinformatics. 2016 Dec 19. pii: btw713. doi: 10.1093/bioinformatics/btw713.
[Epub ahead of print]

Predict drug permeability to blood-brain-barrier from clinical phenotypes: drug
side effects and drug indications.

Gao Z(1), Chen Y(1), Cai X(2), Xu R(1).

Author information: 
(1)Department of Epidemiology and Biostatistics. (2)Department of Electrical
Engineering and Computer Science, Case Western Reserve University, Cleveland, OH 
44106, USA.

MOTIVATION: Blood-Brain-Barrier (BBB) is a rigorous permeability barrier for
maintaining homeostasis of Central Nervous System (CNS). Determination of
compound's permeability to BBB is prerequisite in CNS drug discovery. Existing
computational methods usually predict drug BBB permeability from chemical
structure and they generally apply to small compounds passing BBB through passive
diffusion. As abundant information on drug side effects and indications has been 
recorded over time through extensive clinical usage, we aim to explore BBB
permeability prediction from a new angle and introduce a novel approach to
predict BBB permeability from drug clinical phenotypes (drug side effects and
drug indications). This method can apply to both small compounds and
macro-molecules penetrating BBB through various mechanisms besides passive
diffusion.
RESULTS: We composed a training dataset of 213 drugs with known brain and blood
steady-state concentrations ratio and extracted their side effects and
indications as features. Next, we trained SVM models with polynomial kernel and
obtained accuracy of 76.0%, AUC 0.739, and F1 score (macro weighted) 0.760 with
Monte Carlo cross validation. The independent test accuracy was 68.3%, AUC 0.692,
F1 score 0.676. When both chemical features and clinical phenotypes were
available, combining the two types of features achieved significantly better
performance than chemical feature based approach (accuracy 85.5% versus 72.9%,
AUC 0.854 versus 0.733, F1 score 0.854 versus 0.725; P < e(-90)). We also
conducted de novo prediction and identified 110 drugs in SIDER database having
the potential to penetrate BBB, which could serve as start point for CNS drug
repositioning research.
AVAILABILITY AND IMPLEMENTATION:
https://github.com/bioinformatics-gao/CASE-BBB-prediction-Data CONTACT:
rxx@case.eduSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw713 
PMID: 27993785  [PubMed - as supplied by publisher]


132. Bioinformatics. 2016 Dec 19. pii: btw667. doi: 10.1093/bioinformatics/btw667.
[Epub ahead of print]

ReconMap: an interactive visualization of human metabolism.

Noronha A(1), Daníelsdóttir AD(2), Gawron P(1), Jóhannsson F(2), Jónsdóttir S(2),
Jarlsson S(2), Gunnarsson JP(2), Brynjólfsson S(2), Schneider R(1), Thiele I(1), 
Fleming RM(1).

Author information: 
(1)Luxembourg Centre for Systems Biomedicine, University of Luxembourg, Campus
Belval, Esch-sur-Alzette, Luxembourg. (2)Center for Systems Biology, University
of Iceland, Reykjavik, Iceland.

MOTIVATION: A genome-scale reconstruction of human metabolism, Recon 2, is
available but no interface exists to interactively visualize its content
integrated with omics data and simulation results.
RESULTS: We manually drew a comprehensive map, ReconMap 2.0, that is consistent
with the content of Recon 2. We present it within a web interface that allows
content query, visualization of custom datasets and submission of feedback to
manual curators.
AVAILABILITY AND IMPLEMENTATION: ReconMap can be accessed via http://vmh.uni.lu, 
with network export in a Systems Biology Graphical Notation compliant format
released under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0
International License. A Constraint-Based Reconstruction and Analysis (COBRA)
Toolbox extension to interact with ReconMap is available via
https://github.com/opencobra/cobratoolbox CONTACT: : ronan.mt.fleming@gmail.com.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw667 
PMID: 27993782  [PubMed - as supplied by publisher]


133. Bioinformatics. 2016 Dec 19. pii: btw731. doi: 10.1093/bioinformatics/btw731.
[Epub ahead of print]

Recon2Neo4j: applying graph database technologies for managing comprehensive
genome-scale networks.

Balaur I(1), Mazein A(1), Saqi M(1), Lysenko A(2), Rawlings CJ(2), Auffray C(1).

Author information: 
(1)European Institute for Systems Biology and Medicine (EISBM), CIRI CNRS UMR
5308, CNRS-ENS-UCBL-INSERM, Lyon, France. (2)Rothamsted Research, Harpenden, West
Common, Hertfordshire AL5 2JQ, UK.

The goal of this work is to offer a computational framework for exploring data
from the Recon2 human metabolic reconstruction model. Advanced user access
features have been developed using the Neo4j graph database technology and this
paper describes key features such as efficient management of the network data,
examples of the network querying for addressing particular tasks, and how query
results are converted back to the Systems Biology Markup Language (SBML) standard
format. The Neo4j-based metabolic framework facilitates exploration of highly
connected and comprehensive human metabolic data and identification of metabolic 
subnetworks of interest. A Java-based parser component has been developed to
convert query results (available in the JSON format) into SBML and SIF formats in
order to facilitate further results exploration, enhancement or network
sharing.AVAILABILITY AND IMPLEMENTATION: The Neo4j-based metabolic framework is
freely available from: https://diseaseknowledgebase.etriks.org/metabolic/browser/
The java code files developed for this work are available from the following url:
https://github.com/ibalaur/MetabolicFramework CONTACT:
ibalaur@eisbm.orgSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw731 
PMID: 27993779  [PubMed - as supplied by publisher]


134. Bioinformatics. 2016 Dec 19. pii: btw728. doi: 10.1093/bioinformatics/btw728.
[Epub ahead of print]

A comprehensive benchmark of RNA-RNA interaction prediction tools for all domains
of life.

Umu SU(1,)(2), Gardner PP(1,)(2,)(3).

Author information: 
(1)School of Biological Sciences. (2)Biomolecular Interaction Centre.
(3)Bio-Protection Research Centre, University of Canterbury, Christchurch, New
Zealand.

MOTIVATION: The aim of this study is to assess the performance of RNA-RNA
interaction prediction tools for all domains of life.
RESULTS: Minimum free energy (MFE) and alignment methods constitute most of the
current RNA interaction prediction algorithms. The MFE tools that include
accessibility (i.e. RNAup, IntaRNA and RNAplex) to the final predicted binding
energy have better true positive rates (TPRs) with a high positive predictive
values (PPVs) in all datasets than other methods. They can also differentiate
almost half of the native interactions from background. The algorithms that
include effects of internal binding energies to their model and alignment methods
seem to have high TPR but relatively low associated PPV compared to accessibility
based methods.
AVAILABILITY AND IMPLEMENTATION: We shared our wrapper scripts and datasets at
Github (github.com/UCanCompBio/RNA_Interactions_Benchmark). All parameters are
documented for personal use.
CONTACT: sinan.umu@pg.canterbury.ac.nzSupplementary information: Supplementary
data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw728 
PMID: 27993777  [PubMed - as supplied by publisher]


135. Bioinformatics. 2016 Dec 19. pii: btw695. [Epub ahead of print]

EGAD: ultra-fast functional analysis of gene networks.

Ballouz S(1), Weber M(2), Pavlidis P(3), Gillis J(1).

Author information: 
(1)Stanley Institute for Cognitive Genomics, Cold Spring Harbor Laboratory,
Woodbury, NY 11797, USA. (2)Department of Mathematics and Computer Science,
University of Leipzig, Leipzig, Germany. (3)Department of Psychiatry and Michael 
Smith Laboratories, University of British Columbia, Vancouver, Canada.

Evaluating gene networks with respect to known biology is a common task but often
a computationally costly one. Many computational experiments are difficult to
apply exhaustively in network analysis due to run-times. To permit
high-throughput analysis of gene networks, we have implemented a set of very
efficient tools to calculate functional properties in networks based on
guilt-by-association methods. EGAD: ( E: xtending ' G: uilt-by- A: ssociation' by
D: egree) allows gene networks to be evaluated with respect to hundreds or
thousands of gene sets. The methods predict novel members of gene groups, assess 
how well a gene network groups known sets of genes, and determines the degree to 
which generic predictions drive performance. By allowing fast evaluations,
whether of random sets or real functional ones, EGAD: provides the user with an
assessment of performance which can easily be used in controlled evaluations
across many parameters.AVAILABILITY AND IMPLEMENTATION: The software package is
freely available at https://github.com/sarbal/EGAD and implemented for use in R
and Matlab. The package is also freely available under the LGPL license from the 
Bioconductor web site (http://bioconductor.org).
CONTACT: JGillis@cshl.eduSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw695 
PMID: 27993773  [PubMed - as supplied by publisher]


136. PLoS One. 2016 Dec 19;11(12):e0168607. doi: 10.1371/journal.pone.0168607.
eCollection 2016.

iFORM: Incorporating Find Occurrence of Regulatory Motifs.

Ren C(1), Chen H(1), Yang B(1), Liu F(1), Ouyang Z(1), Bo X(1), Shu W(1).

Author information: 
(1)Department of Biotechnology, Beijing Institute of Radiation Medicine, Beijing,
China.

Accurately identifying the binding sites of transcription factors (TFs) is
crucial to understanding the mechanisms of transcriptional regulation and human
disease. We present incorporating Find Occurrence of Regulatory Motifs (iFORM),
an easy-to-use and efficient tool for scanning DNA sequences with TF motifs
described as position weight matrices (PWMs). Both performance assessment with a 
receiver operating characteristic (ROC) curve and a correlation-based approach
demonstrated that iFORM achieves higher accuracy and sensitivity by integrating
five classical motif discovery programs using Fisher's combined probability test.
We have used iFORM to provide accurate results on a variety of data in the ENCODE
Project and the NIH Roadmap Epigenomics Project, and the tool has demonstrated
its utility in further elucidating individual roles of functional elements. Both 
the source and binary codes for iFORM can be freely accessed at
https://github.com/wenjiegroup/iFORM. The identified TF binding sites across
human cell and tissue types using iFORM have been deposited in the Gene
Expression Omnibus under the accession ID GSE53962.

DOI: 10.1371/journal.pone.0168607 
PMCID: PMC5167396
PMID: 27992540  [PubMed - in process]


137. Cytometry A. 2016 Dec;89(12):1084-1096. doi: 10.1002/cyto.a.23030. Epub 2016 Dec 
19.

Comparison of clustering methods for high-dimensional single-cell flow and mass
cytometry data.

Weber LM(1,)(2), Robinson MD(1,)(2).

Author information: 
(1)Institute of Molecular Life Sciences, University of Zurich, Zurich,
Switzerland. (2)SIB Swiss Institute of Bioinformatics, University of Zurich,
Zurich, Switzerland.

Recent technological developments in high-dimensional flow cytometry and mass
cytometry (CyTOF) have made it possible to detect expression levels of dozens of 
protein markers in thousands of cells per second, allowing cell populations to be
characterized in unprecedented detail. Traditional data analysis by "manual
gating" can be inefficient and unreliable in these high-dimensional settings,
which has led to the development of a large number of automated analysis methods.
Methods designed for unsupervised analysis use specialized clustering algorithms 
to detect and define cell populations for further downstream analysis. Here, we
have performed an up-to-date, extensible performance comparison of clustering
methods for high-dimensional flow and mass cytometry data. We evaluated methods
using several publicly available data sets from experiments in immunology,
containing both major and rare cell populations, with cell population identities 
from expert manual gating as the reference standard. Several methods performed
well, including FlowSOM, X-shift, PhenoGraph, Rclusterpp, and flowMeans. Among
these, FlowSOM had extremely fast runtimes, making this method well-suited for
interactive, exploratory analysis of large, high-dimensional data sets on a
standard laptop or desktop computer. These results extend previously published
comparisons by focusing on high-dimensional data and including new methods
developed for CyTOF data. R scripts to reproduce all analyses are available from 
GitHub (https://github.com/lmweber/cytometry-clustering-comparison), and
pre-processed data files are available from FlowRepository (FR-FCM-ZZPH),
allowing our comparisons to be extended to include new clustering methods and
reference data sets. © 2016 The Authors. Cytometry Part A published by Wiley
Periodicals, Inc. on behalf of ISAC.

© 2016 The Authors. Cytometry Part A Published by Wiley Periodicals, Inc. on
behalf of ISAC.

DOI: 10.1002/cyto.a.23030 
PMID: 27992111  [PubMed - in process]


138. Version 2. F1000Res. 2016 Nov 22 [revised 2017 Jan 24];5:2741. doi:
10.12688/f1000research.10082.2. eCollection 2016.

Disambiguate: An open-source application for disambiguating two species in next
generation sequencing data from grafted samples.

Ahdesmäki MJ(1), Gray SR(2), Johnson JH(3), Lai Z(3).

Author information: 
(1)AstraZeneca IMED Oncology, Cambridge, UK. (2)AstraZeneca R&D Information,
Cambridge, UK. (3)AstraZeneca Oncology iMed, Waltham, USA.

Grafting of cell lines and primary tumours is a crucial step in the drug
development process between cell line studies and clinical trials. Disambiguate
is a program for computationally separating the sequencing reads of two species
derived from grafted samples. Disambiguate operates on DNA or RNA-seq alignments 
to the two species and separates the components at very high sensitivity and
specificity as illustrated in artificially mixed human-mouse samples. This allows
for maximum recovery of data from target tumours for more accurate variant
calling and gene expression quantification. Given that no general use open source
algorithm accessible to the bioinformatics community exists for the purposes of
separating the two species data, the proposed Disambiguate tool presents a novel 
approach and improvement to performing sequence analysis of grafted samples. Both
Python and C++ implementations are available and they are integrated into several
open and closed source pipelines. Disambiguate is open source and is freely
available at https://github.com/AstraZeneca-NGS/disambiguate.

DOI: 10.12688/f1000research.10082.2 
PMID: 27990269  [PubMed - in process]


139. J Appl Crystallogr. 2016 Nov 2;49(Pt 6):2252-2258. eCollection 2016.

ContaMiner and ContaBase: a webserver and database for early identification of
unwantedly crystallized protein contaminants.

Hungler A(1), Momin A(1), Diederichs K(2), Arold ST(1).

Author information: 
(1)King Abdullah University of Science and Technology (KAUST) , Center for
Computational Bioscience Research (CBRC), Division of Biological and
Environmental Sciences and Engineering (BESE), Thuwal, 23955-6900, Saudi Arabia. 
(2)Fachbereich Biologie, Universität Konstanz , M647, D-78457 Konstanz, Germany.

Solving the phase problem in protein X-ray crystallography relies heavily on the 
identity of the crystallized protein, especially when molecular replacement (MR) 
methods are used. Yet, it is not uncommon that a contaminant crystallizes instead
of the protein of interest. Such contaminants may be proteins from the expression
host organism, protein fusion tags or proteins added during the purification
steps. Many contaminants co-purify easily, crystallize and give good diffraction 
data. Identification of contaminant crystals may take time, since the presence of
the contaminant is unexpected and its identity unknown. A webserver (ContaMiner) 
and a contaminant database (ContaBase) have been established, to allow fast
MR-based screening of crystallographic data against currently 62 known
contaminants. The web-based ContaMiner (available at
http://strube.cbrc.kaust.edu.sa/contaminer/) currently produces results in 5 min 
to 4 h. The program is also available in a github repository and can be installed
locally. ContaMiner enables screening of novel crystals at synchrotron beamlines,
and it would be valuable as a routine safety check for 'crystallization and
preliminary X-ray analysis' publications. Thus, in addition to potentially saving
X-ray crystallographers much time and effort, ContaMiner might considerably lower
the risk of publishing erroneous data.

DOI: 10.1107/S1600576716014965 
PMCID: PMC5140001
PMID: 27980519  [PubMed]


140. Genome Med. 2016 Dec 13;8(1):130.

Alternate-locus aware variant calling in whole genome sequencing.

Jäger M(1,)(2), Schubach M(1), Zemojtel T(1), Reinert K(3), Church DM(4),
Robinson PN(5,)(6,)(7,)(8,)(9).

Author information: 
(1)Institute for Medical and Human Genetics, Charité-Universitätsmedizin Berlin, 
Augustenburger Platz 1, Berlin, 13353, Germany. (2)Berlin Brandenburg Center for 
Regenerative Therapies (BCRT), Charité-Universitätsmedizin Berlin, Augustenburger
Platz 1, Berlin, 13353, Germany. (3)Institute for Bioinformatics, Department of
Mathematics and Computer Science, Freie Universität Berlin, Arnimallee 14,
Berlin, 14195, Germany. (4)10x Genomics, 7068 Koll Center Parkway, Suite 401,
Pleasanton, 94566, CA, USA. (5)Institute for Medical and Human Genetics,
Charité-Universitätsmedizin Berlin, Augustenburger Platz 1, Berlin, 13353,
Germany. peter.robinson@jax.org. (6)Berlin Brandenburg Center for Regenerative
Therapies (BCRT), Charité-Universitätsmedizin Berlin, Augustenburger Platz 1,
Berlin, 13353, Germany. peter.robinson@jax.org. (7)Institute for Bioinformatics, 
Department of Mathematics and Computer Science, Freie Universität Berlin,
Arnimallee 14, Berlin, 14195, Germany. peter.robinson@jax.org. (8)The Jackson
Laboratory for Genomic Medicine, 10 Discovery Drive, Farmington, 06032, CT, USA. 
peter.robinson@jax.org. (9)Institute for Systems Genomics, University of
Connecticut, Farmington, 06032, CT, USA. peter.robinson@jax.org.

BACKGROUND: The last two human genome assemblies have extended the previous
linear golden-path paradigm of the human genome to a graph-like model to better
represent regions with a high degree of structural variability. The new model
offers opportunities to improve the technical validity of variant calling in
whole-genome sequencing (WGS).
METHODS: We developed an algorithm that analyzes the patterns of variant calls in
the 178 structurally variable regions of the GRCh38 genome assembly, and infers
whether a given sample is most likely to contain sequences from the primary
assembly, an alternate locus, or their heterozygous combination at each of these 
178 regions. We investigate 121 in-house WGS datasets that have been aligned to
the GRCh37 and GRCh38 assemblies.
RESULTS: We show that stretches of sequences that are largely but not entirely
identical between the primary assembly and an alternate locus can result in
multiple variant calls against regions of the primary assembly. In WGS analysis, 
this results in characteristic and recognizable patterns of variant calls at
positions that we term alignable scaffold-discrepant positions (ASDPs). In 121
in-house genomes, on average 51.8±3.8 of the 178 regions were found to correspond
best to an alternate locus rather than the primary assembly sequence, and
filtering these genomes with our algorithm led to the identification of 7863
variant calls per genome that colocalized with ASDPs. Additionally, we found that
437 of 791 genome-wide association study hits located within one of the regions
corresponded to ASDPs.
CONCLUSIONS: Our algorithm uses the information contained in the 178 structurally
variable regions of the GRCh38 genome assembly to avoid spurious variant calls in
cases where samples contain an alternate locus rather than the corresponding
segment of the primary assembly. These results suggest the great potential of
fully incorporating the resources of graph-like genome assemblies into variant
calling, but also underscore the importance of developing computational resources
that will allow a full reconstruction of the genotype in personal genomes. Our
algorithm is freely available at https://github.com/charite/asdpex .

DOI: 10.1186/s13073-016-0383-z 
PMCID: PMC5155401
PMID: 27964746  [PubMed - in process]


141. J Open Res Softw. 2016;4(1). pii: e44. Epub 2016 Nov 29.

Walking the Talk: Adopting and Adapting Sustainable Scientific Software
Development processes in a Small Biology Lab.

Crusoe MR(1), Brown CT(2).

Author information: 
(1)Microbiology and Molecular Genetics, Michigan State University, East Lansing, 
MI, USA. (2)Computer Science and Engineering, Michigan State University, East
Lansing, MI, USA.

The khmer software project provides both research and production functionality
for largescale nucleic-acid sequence analysis. The software implements several
novel data structures and algorithms that perform data pre-fltering for common
bioinformatics tasks, including sequence mapping and de novo assembly.
Development is driven by a small lab with one full-time developer (MRC), as well 
as several graduate students and a professor (CTB) who contribute regularly to
research features. Here we describe our efforts to bring better design, testing, 
and more open development to the khmer software project as of version 1.1. The
khmer software is developed openly at http://github.com/dib-lab/khmer/.

DOI: 10.5334/jors.35 
PMCID: PMC5142744
PMID: 27942385  [PubMed]


142. Curr Protoc Bioinformatics. 2016 Dec 8;56:15.9.1-15.9.17. doi: 10.1002/cpbi.17.

ascatNgs: Identifying Somatically Acquired Copy-Number Alterations from
Whole-Genome Sequencing Data.

Raine KM(1), Van Loo P(1,)(2), Wedge DC(1,)(3), Jones D(1), Menzies A(1), Butler 
AP(1), Teague JW(1), Tarpey P(1), Nik-Zainal S(1), Campbell PJ(1).

Author information: 
(1)Cancer Genome Project, Wellcome Trust Sanger Institute, Cambridge, United
Kingdom. (2)The Francis Crick Institute, Lincoln's Inn Fields Laboratory, London,
United Kingdom. (3)Oxford Big Data Institute, Wellcome Trust Centre for Human
Genetics, Oxford, United Kingdom.

We have developed ascatNgs to aid researchers in carrying out Allele-Specific
Copy number Analysis of Tumours (ASCAT). ASCAT is capable of detecting DNA copy
number changes affecting a tumor genome when comparing to a matched normal
sample. Additionally, the algorithm estimates the amount of tumor DNA in the
sample, known as Aberrant Cell Fraction (ACF). ASCAT itself is an R-package which
requires the generation of many file types. Here, we present a suite of tools to 
help handle this for the user. Our code is available on our GitHub site
(https://github.com/cancerit). This unit describes both 'one-shot' execution and 
approaches more suitable for large-scale compute farms. © 2016 by John Wiley &
Sons, Inc.

Copyright © 2016 John Wiley & Sons, Inc.

DOI: 10.1002/cpbi.17 
PMID: 27930809  [PubMed - in process]


143. Proc Natl Acad Sci U S A. 2016 Dec 20;113(51):14662-14667. doi:
10.1073/pnas.1617317113. Epub 2016 Dec 7.

Simultaneous dimension reduction and adjustment for confounding variation.

Lin Z(1), Yang C(2), Zhu Y(3,)(4), Duchi J(1,)(5), Fu Y(6), Wang Y(7), Jiang
B(1), Zamanighomi M(1), Xu X(4), Li M(4), Sestan N(4,)(8,)(9), Zhao H(10), Wong
WH(11,)(12).

Author information: 
(1)Department of Statistics, Stanford University, Stanford, CA 94305.
(2)Department of Mathematics, Hong Kong Baptist University, Kowloon Tong, Hong
Kong. (3)Department of Biostatistics, Yale School of Public Health, New Haven, CT
06520. (4)Department of Neuroscience, Kavli Institute for Neuroscience, Yale
School of Medicine, New Haven, CT 06510. (5)Department of Electrical Engineering,
Stanford University, Stanford, CA 94305. (6)Program of Computational Biology &
Bioinformatics, Yale University, New Haven, CT 06511. (7)Academy of Mathematics &
Systems Science, Chinese Academy of Sciences, Beijing 100080, China.
(8)Department of Genetics, Yale School of Medicine, New Haven, CT 06510.
(9)Department of Psychiatry, Section of Comparative Medicine, Program in Cellular
Neuroscience, Neurodegeneration and Repair, Yale School of Medicine, New Haven,
CT 06510. (10)Department of Biostatistics, Yale School of Public Health, New
Haven, CT 06520; hongyu.zhao@yale.edu whwong@stanford.edu. (11)Department of
Statistics, Stanford University, Stanford, CA 94305; hongyu.zhao@yale.edu
whwong@stanford.edu. (12)Department of Health Research & Policy, Stanford
University, Stanford, CA 94305.

Dimension reduction methods are commonly applied to high-throughput biological
datasets. However, the results can be hindered by confounding factors, either
biological or technical in origin. In this study, we extend principal component
analysis (PCA) to propose AC-PCA for simultaneous dimension reduction and
adjustment for confounding (AC) variation. We show that AC-PCA can adjust for (i)
variations across individual donors present in a human brain exon array dataset
and (ii) variations of different species in a model organism ENCODE RNA
sequencing dataset. Our approach is able to recover the anatomical structure of
neocortical regions and to capture the shared variation among species during
embryonic development. For gene selection purposes, we extend AC-PCA with
sparsity constraints and propose and implement an efficient algorithm. The
methods developed in this paper can also be applied to more general settings. The
R package and MATLAB source code are available at
https://github.com/linzx06/AC-PCA.

DOI: 10.1073/pnas.1617317113 
PMCID: PMC5187682 [Available on 2017-06-20]
PMID: 27930330  [PubMed - in process]


144. Data Brief. 2016 Nov 18;9:1122-1129. eCollection 2016.

A dataset of multiresolution functional brain parcellations in an elderly
population with no or mild cognitive impairment.

Tam A(1), Dansereau C(2), Badhwar A(2), Orban P(3), Belleville S(2), Chertkow
H(4), Dagher A(4), Hanganu A(5), Monchi O(6), Rosa-Neto P(7), Shmuel A(4),
Breitner J(7), Bellec P(2); Alzheimer׳s Disease Neuroimaging Initiative.

Author information: 
(1)McGill University, Montreal, QC, Canada; Douglas Mental Health University
Institute, Research Centre, Montreal, QC, Canada; Centre de recherche de
l'institut universitaire de gériatrie de Montréal, QC, Canada. (2)Centre de
recherche de l'institut universitaire de gériatrie de Montréal, QC, Canada;
Université de Montréal, QC, Canada. (3)Douglas Mental Health University
Institute, Research Centre, Montreal, QC, Canada; Centre de recherche de
l'institut universitaire de gériatrie de Montréal, QC, Canada. (4)McGill
University, Montreal, QC, Canada. (5)Centre de recherche de l'institut
universitaire de gériatrie de Montréal, QC, Canada; University of Calgary, AB,
Canada; Hotchkiss Brain Institute, Calgary, AB, Canada. (6)Centre de recherche de
l'institut universitaire de gériatrie de Montréal, QC, Canada; Université de
Montréal, QC, Canada; University of Calgary, AB, Canada; Hotchkiss Brain
Institute, Calgary, AB, Canada. (7)McGill University, Montreal, QC, Canada;
Douglas Mental Health University Institute, Research Centre, Montreal, QC,
Canada.

We present group eight resolutions of brain parcellations for clusters generated 
from resting-state functional magnetic resonance images for 99 cognitively normal
elderly persons and 129 patients with mild cognitive impairment, pooled from four
independent datasets. This dataset was generated as part of the following study: 
Common Effects of Amnestic Mild Cognitive Impairment on Resting-State
Connectivity Across Four Independent Studies (Tam et al., 2015) [1]. The brain
parcellations have been registered to both symmetric and asymmetric MNI brain
templates and generated using a method called bootstrap analysis of stable
clusters (BASC) (Bellec et al., 2010) [2]. We present two variants of these
parcellations. One variant contains bihemisphereic parcels (4, 6, 12, 22, 33, 65,
111, and 208 total parcels across eight resolutions). The second variant contains
spatially connected regions of interest (ROIs) that span only one hemisphere (10,
17, 30, 51, 77, 199, and 322 total ROIs across eight resolutions). We also
present maps illustrating functional connectivity differences between patients
and controls for four regions of interest (striatum, dorsal prefrontal cortex,
middle temporal lobe, and medial frontal cortex). The brain parcels and
associated statistical maps have been publicly released as 3D volumes, available 
in .mnc and .nii file formats on figshare and on Neurovault. Finally, the code
used to generate this dataset is available on Github.

DOI: 10.1016/j.dib.2016.11.036 
PMCID: PMC5128734
PMID: 27924300  [PubMed - in process]


145. Nucleic Acids Res. 2016 Oct 24. pii: gkw955. [Epub ahead of print]

NOVOPlasty: de novo assembly of organelle genomes from whole genome data.

Dierckxsens N(1), Mardulyn P(2,)(3), Smits G(2,)(4,)(5).

Author information: 
(1)Interuniversity Institute of Bioinformatics in Brussels, Université Libre de
Bruxelles and Vrije Universiteit Brussel, Triomflaan CP 263, 1050 Brussels,
Belgium nicolasdierckxsens@hotmail.com. (2)Interuniversity Institute of
Bioinformatics in Brussels, Université Libre de Bruxelles and Vrije Universiteit 
Brussel, Triomflaan CP 263, 1050 Brussels, Belgium. (3)Evolutionary Biology and
Ecology Unit, CP 160/12, Faculté des Sciences, Université Libre de Bruxelles, Av.
F. D. Roosevelt 50, B-1050 Brussels, Belgium. (4)Genetics, Hôpital Universitaire 
des Enfants Reine Fabiola, Université Libre de Bruxelles, Brussels, Belgium.
(5)Center for Medical Genetics, Hôpital Erasme, Université Libre de Bruxelles,
Route de Lennik 808, 1070 Brussels, Belgium.

The evolution in next-generation sequencing (NGS) technology has led to the
development of many different assembly algorithms, but few of them focus on
assembling the organelle genomes. These genomes are used in phylogenetic studies,
food identification and are the most deposited eukaryotic genomes in GenBank.
Producing organelle genome assembly from whole genome sequencing (WGS) data would
be the most accurate and least laborious approach, but a tool specifically
designed for this task is lacking. We developed a seed-and-extend algorithm that 
assembles organelle genomes from whole genome sequencing (WGS) data, starting
from a related or distant single seed sequence. The algorithm has been tested on 
several new (Gonioctena intermedia and Avicennia marina) and public (Arabidopsis 
thaliana and Oryza sativa) whole genome Illumina data sets where it outperforms
known assemblers in assembly accuracy and coverage. In our benchmark, NOVOPlasty 
assembled all tested circular genomes in less than 30 min with a maximum memory
requirement of 16 GB and an accuracy over 99.99%. In conclusion, NOVOPlasty is
the sole de novo assembler that provides a fast and straightforward extraction of
the extranuclear genomes from WGS data in one circular high quality contig. The
software is open source and can be downloaded at
https://github.com/ndierckx/NOVOPlasty.

© The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkw955 
PMID: 27924028  [PubMed - as supplied by publisher]


146. Nucleic Acids Res. 2016 Oct 19. pii: gkw953. [Epub ahead of print]

TEtools facilitates big data expression analysis of transposable elements and
reveals an antagonism between their activity and that of piRNA genes.

Lerat E(1), Fablet M(1), Modolo L(1), Lopez-Maestre H(1), Vieira C(2).

Author information: 
(1)Laboratoire de Biométrie et Biologie Evolutive, UMR CNRS 5558, Université Lyon
1, Université de Lyon, Villeurbanne 69622, France. (2)Laboratoire de Biométrie et
Biologie Evolutive, UMR CNRS 5558, Université Lyon 1, Université de Lyon,
Villeurbanne 69622, France cristina.vieira@univ-lyon1.fr.

Over recent decades, substantial efforts have been made to understand the
interactions between host genomes and transposable elements (TEs). The impact of 
TEs on the regulation of host genes is well known, with TEs acting as platforms
of regulatory sequences. Nevertheless, due to their repetitive nature it is
considerably hard to integrate TE analysis into genome-wide studies. Here, we
developed a specific tool for the analysis of TE expression: TEtools This tool
takes into account the TE sequence diversity of the genome, it can be applied to 
unannotated or unassembled genomes and is freely available under the GPL3
(https://github.com/l-modolo/TEtools). TETOOLS: performs the mapping of RNA-seq
data obtained from classical mRNAs or small RNAs onto a list of TE sequences and 
performs differential expression analyses with statistical relevance. Using this 
tool, we analyzed TE expression from five Drosophila wild-type strains. Our data 
show for the first time that the activity of TEs is strictly linked to the
activity of the genes implicated in the piwi-interacting RNA biogenesis and
therefore fits an arms race scenario between TE sequences and host control genes.

© The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkw953 
PMID: 27924026  [PubMed - as supplied by publisher]


147. PLoS Comput Biol. 2016 Dec 5;12(12):e1005224. doi: 10.1371/journal.pcbi.1005224. 
eCollection 2016.

A Graph-Centric Approach for Metagenome-Guided Peptide and Protein Identification
in Metaproteomics.

Tang H(1), Li S(1), Ye Y(1).

Author information: 
(1)School of Informatics and Computing, Indiana University, Bloomington, Indiana,
United States of America.

Metaproteomic studies adopt the common bottom-up proteomics approach to
investigate the protein composition and the dynamics of protein expression in
microbial communities. When matched metagenomic and/or metatranscriptomic data of
the microbial communities are available, metaproteomic data analyses often employ
a metagenome-guided approach, in which complete or fragmental protein-coding
genes are first directly predicted from metagenomic (and/or metatranscriptomic)
sequences or from their assemblies, and the resulting protein sequences are then 
used as the reference database for peptide/protein identification from MS/MS
spectra. This approach is often limited because protein coding genes predicted
from metagenomes are incomplete and fragmental. In this paper, we present a
graph-centric approach to improving metagenome-guided peptide and protein
identification in metaproteomics. Our method exploits the de Bruijn graph
structure reported by metagenome assembly algorithms to generate a comprehensive 
database of protein sequences encoded in the community. We tested our method
using several public metaproteomic datasets with matched metagenomic and
metatranscriptomic sequencing data acquired from complex microbial communities in
a biological wastewater treatment plant. The results showed that many more
peptides and proteins can be identified when assembly graphs were utilized,
improving the characterization of the proteins expressed in the microbial
communities. The additional proteins we identified contribute to the
characterization of important pathways such as those involved in degradation of
chemical hazards. Our tools are released as open-source software on github at
https://github.com/COL-IU/Graph2Pro.

DOI: 10.1371/journal.pcbi.1005224 
PMCID: PMC5137872
PMID: 27918579  [PubMed - in process]


148. Genetics. 2016 Dec 2. pii: genetics.116.194878. [Epub ahead of print]

Evaluating Sequence-Based Genomic Prediction with an Efficient New Simulator.

Pérez-Enciso M(1), Forneris N(2), de Los Campos G(3), Legarra A(4).

Author information: 
(1)Universidad Autònoma Barcelona; miguel.perez@uab.es. (2)CRAG. (3)Michigan
State University. (4)INRA.

The vast amount of sequence data to analyze complex traits is posing new
challenges in terms of analysis and interpretation of the results. Although
simulation is a fundamental tool to investigate the reliability of genomic
analyses and to optimize experimental design, existing software cannot simulate
complete genomes realistically. To remedy this, we have developed a new strategy 
(Sequence Based Virtual Breeding, SBVB) that consists of using real sequence data
and simulating new offspring genomes and phenotypes in a very efficient and
flexible manner. Using this tool, we studied the efficiency of full sequence in
genomic prediction compared to SNP arrays. We used real porcine sequences from
three breeds as founder genomes of a 2,500 animal pedigree and two genetic
architectures: 'neutral' and 'selective'. In the neutral architecture,
frequencies and allele effects were sampled independently whereas, in the
selective case, SNPs were sites putatively under selection after domestication
and a negative correlation between effect and frequency was induced. We compared 
the effectiveness of different genotyping strategies for genomic selection,
including the use of full sequence, commercial arrays or randomly chosen SNP sets
in both outbred and crossbred experimental designs. We found that accuracy
increases using sequence instead of commercial chips but modestly, perhaps by up 
to 4%. This result was robust to extreme genetic architectures. We conclude that 
full sequence is unlikely to offset commercial arrays for predicting genetic
value when the number of loci is relatively large and the prior given to each SNP
is uniform. Using sequence to improve selection shall thus require optimized
prior information and, likely, increased population sizes. Code and manual for
SBVB are available at https://github.com/mperezenciso/sbvb0.

Copyright © 2016, The Genetics Society of America.

DOI: 10.1534/genetics.116.194878 
PMID: 27913617  [PubMed - as supplied by publisher]


149. BMC Bioinformatics. 2016 Dec 1;17(1):491.

MeFiT: merging and filtering tool for illumina paired-end reads for 16S rRNA
amplicon sequencing.

Parikh HI(1), Koparde VN(2), Bradley SP(1), Buck GA(1,)(2), Sheth NU(3).

Author information: 
(1)Department of Microbiology and Immunology, Virginia Commonwealth University,
Richmond, Virginia, USA. (2)Center for the Study of Biological Complexity,
Virginia Commonwealth University, Richmond, Virginia, USA. (3)Center for the
Study of Biological Complexity, Virginia Commonwealth University, Richmond,
Virginia, USA. nsheth@vcu.edu.

BACKGROUND: Recent advances in next-generation sequencing have revolutionized
genomic research. 16S rRNA amplicon sequencing using paired-end sequencing on the
MiSeq platform from Illumina, Inc., is being used to characterize the composition
and dynamics of extremely complex/diverse microbial communities. For this
analysis on the Illumina platform, merging and quality filtering of paired-end
reads are essential first steps in data analysis to ensure the accuracy and
reliability of downstream analysis.
RESULTS: We have developed the Merging and Filtering Tool (MeFiT) to combine
these pre-processing steps into one simple, intuitive pipeline. MeFiT invokes
CASPER (context-aware scheme for paired-end reads) for merging paired-end reads
and provides users the option to quality filter the reads using the traditional
average Q-score metric or using a maximum expected error cut-off threshold.
CONCLUSIONS: MeFiT provides an open-source solution that permits users to merge
and filter paired end illumina reads. The tool has been implemented in python and
the source-code is freely available at https://github.com/nisheth/MeFiT .

DOI: 10.1186/s12859-016-1358-1 
PMCID: PMC5134250
PMID: 27905885  [PubMed - in process]


150. BMC Bioinformatics. 2016 Dec 1;17(1):490.

The Lair: a resource for exploratory analysis of published RNA-Seq data.

Pimentel H(1), Sturmfels P(2), Bray N(3), Melsted P(4), Pachter L(5,)(6).

Author information: 
(1)Department of Computer Science, University of California, Berkeley, 387 Soda
Hall, Berkeley, 94720, USA. (2)Department of Computer Science, University of
Michigan, 486 Vassar Avenue, Berkeley, CA, 94708, USA. (3)Innovative Genomics
Initiative, University of California, Berkeley, 188 Li Ka Shing Center, Berkeley,
CA, 94720, USA. (4)Faculty of Industrial Engineering, Mechanical Engineering and 
Computer Science, University of Iceland, Dunhagi 5, 107, Reykjavík, Iceland.
(5)Department of Computer Science, University of California, Berkeley, 387 Soda
Hall, Berkeley, 94720, USA. lpachter@math.berkeley.edu. (6)Departments of
Mathematics and Molecular & Cell Biology, University of California at Berkeley,
Berkeley, CA, 94720-3840, USA. lpachter@math.berkeley.edu.

Increased emphasis on reproducibility of published research in the last few years
has led to the large-scale archiving of sequencing data. While this data can, in 
theory, be used to reproduce results in papers, it is difficult to use in
practice. We introduce a series of tools for processing and analyzing RNA-Seq
data in the Sequence Read Archive, that together have allowed us to build an
easily extendable resource for analysis of data underlying published papers. Our 
system makes the exploration of data easily accessible and usable without
technical expertise. Our database and associated tools can be accessed at The
Lair: http://pachterlab.github.io/lair .

DOI: 10.1186/s12859-016-1357-2 
PMCID: PMC5131447
PMID: 27905880  [PubMed - in process]


151. BMC Evol Biol. 2016 Dec 1;16(1):262.

PhyInformR: phylogenetic experimental design and phylogenomic data exploration in
R.

Dornburg A(1), Fisk JN(2), Tamagnan J(3), Townsend JP(2,)(4,)(5).

Author information: 
(1)North Carolina Museum of Natural Sciences, Raleigh, North Carolina, 27601,
USA. alex.dornburg@naturalsciences.org. (2)Department of Biostatistics, Yale
University, New Haven, Connecticut, 06510, USA. (3)Center for Infectious Disease 
Modeling and Analysis, Yale School of Public Health, Yale University, New Haven, 
Connecticut, 06510, USA. (4)Department of Ecology and Evolutionary Biology, Yale 
University, New Haven, Connecticut, 06525, USA. (5)Program in Computational
Biology and Bioinformatics, Yale University, New Haven, Connecticut, 06511, USA.

BACKGROUND: Analyses of phylogenetic informativeness represent an important step 
in screening potential or existing datasets for their proclivity toward
convergent or parallel evolution of molecular sites. However, while new theory
has been developed from which to predict the utility of sequence data, adoption
of these advances have been stymied by a lack of software enabling application of
advances in theory, especially for large next-generation sequence data sets.
Moreover, there are no theoretical barriers to application of the phylogenetic
informativeness or the calculation of quartet internode resolution probabilities 
in a Bayesian setting that more robustly accounts for uncertainty, yet there is
no software with which a computationally intensive Bayesian approach to
experimental design could be implemented.
RESULTS: We introduce PhyInformR, an open source software package that performs
rapid calculation of phylogenetic information content using the latest advances
in phylogenetic informativeness based theory. These advances include
modifications that incorporate uneven branch lengths and any model of nucleotide 
substitution to provide assessments of the phylogenetic utility of any given
dataset or dataset partition. PhyInformR provides new tools for data
visualization and routines optimized for rapid statistical calculations,
including approaches making use of Bayesian posterior distributions and parallel 
processing. By implementing the computation on user hardware, PhyInformR
increases the potential power users can apply toward screening datasets for
phylogenetic/genomic information content by orders of magnitude.
CONCLUSIONS: PhyInformR provides a means to implement diverse substitution models
and specify uneven branch lengths for phylogenetic informativeness or
calculations providing quartet based probabilities of resolution, produce novel
visualizations, and facilitate analyses of next-generation sequence datasets
while incorporating phylogenetic uncertainty through the use parallel processing.
As an open source program, PhyInformR is fully customizable and expandable,
thereby allowing for advanced methodologies to be readily integrated into local
bioinformatics pipelines. Software is available through CRAN and a package
containing the software, a detailed manual, and additional sample data is also
provided freely through github: https://github.com/carolinafishes/PhyInformR .

DOI: 10.1186/s12862-016-0837-3 
PMCID: PMC5134231
PMID: 27905871  [PubMed - in process]


152. Pac Symp Biocomput. 2016;22:402-413.

FREQUENT SUBGRAPH MINING OF PERSONALIZED SIGNALING PATHWAY NETWORKS GROUPS
PATIENTS WITH FREQUENTLY DYSREGULATED DISEASE PATHWAYS AND PREDICTS PROGNOSIS.

Durmaz A(1), Henderson TA, Brubaker D, Bebek G.

Author information: 
(1)Systems Biology and Bioinformatics Graduate Program, Case Western Reserve
University, 10900 Euclid Avenue, Cleveland, Ohio 44106, USA*Co-first Author,
arda.durmaz@case.edu.

MOTIVATION: Large scale genomics studies have generated comprehensive molecular
characterization of numerous cancer types. Subtypes for many tumor types have
been established; however, these classifications are based on molecular
characteristics of a small gene sets with limited power to detect dysregulation
at the patient level. We hypothesize that frequent graph mining of pathways to
gather pathways functionally relevant to tumors can characterize tumor types and 
provide opportunities for personalized therapies.
RESULTS: In this study we present an integrative omics approach to group patients
based on their altered pathway characteristics and show prognostic differences
within breast cancer (p < 9:57E - 10) and glioblastoma multiforme (p < 0:05)
patients. We were able validate this approach in secondary RNA-Seq datasets with 
p < 0:05 and p < 0:01 respectively. We also performed pathway enrichment analysis
to further investigate the biological relevance of dysregulated pathways. We
compared our approach with network-based classifier algorithms and showed that
our unsupervised approach generates more robust and biologically relevant
clustering whereas previous approaches failed to report specific functions for
similar patient groups or classify patients into prognostic groups.
CONCLUSIONS: These results could serve as a means to improve prognosis for future
cancer patients, and to provide opportunities for improved treatment options and 
personalized interventions. The proposed novel graph mining approach is able to
integrate PPI networks with gene expression in a biologically sound approach and 
cluster patients in to clinically distinct groups. We have utilized breast cancer
and glioblastoma multiforme datasets from microarray and RNA-Seq platforms and
identified disease mechanisms differentiating samples.
SUPPLEMENTARY INFORMATION: Supplementary methods, figures, tables and code are
available at https://github.com/bebeklab/dysprog.


PMID: 27896993  [PubMed - in process]


153. Pac Symp Biocomput. 2016;22:132-143.

REPRODUCIBLE DRUG REPURPOSING: WHEN SIMILARITY DOES NOT SUFFICE.

Guney E(1).

Author information: 
(1)Joint IRB-BSC-CRG Program in Computational Biology, Institute for Research in 
Biomedicine, c/ Baldiri Reixac 10-12, Barcelona, 08028, Spain,
emre.guney@irbbarcelona.org.

Repurposing existing drugs for new uses has attracted considerable attention over
the past years. To identify potential candidates that could be repositioned for a
new indication, many studies make use of chemical, target, and side effect
similarity between drugs to train classifiers. Despite promising prediction
accuracies of these supervised computational models, their use in practice, such 
as for rare diseases, is hindered by the assumption that there are already known 
and similar drugs for a given condition of interest. In this study, using
publicly available data sets, we question the prediction accuracies of supervised
approaches based on drug similarity when the drugs in the training and the test
set are completely disjoint. We first build a Python platform to generate
reproducible similarity-based drug repurposing models. Next, we show that, while 
a simple chemical, target, and side effect similarity based machine learning
method can achieve good performance on the benchmark data set, the prediction
performance drops sharply when the drugs in the folds of the cross validation are
not overlapping and the similarity information within the training and test sets 
are used independently. These intriguing results suggest revisiting the
assumptions underlying the validation scenarios of similarity-based methods and
underline the need for unsupervised approaches to identify novel drug uses inside
the unexplored pharmacological space. We make the digital notebook containing the
Python code to replicate our analysis that involves the drug repurposing platform
based on machine learning models and the proposed disjoint cross fold generation 
method freely available at github.com/emreg00/repurpose.


PMID: 27896969  [PubMed - in process]


154. PLoS One. 2016 Nov 28;11(11):e0167047. doi: 10.1371/journal.pone.0167047.
eCollection 2016.

Simulating Next-Generation Sequencing Datasets from Empirical Mutation and
Sequencing Models.

Stephens ZD(1), Hudson ME(2,)(3), Mainzer LS(3,)(4), Taschuk M(5), Weber MR(4),
Iyer RK(1).

Author information: 
(1)Department of Electrical and Computer Engineering, Univ. of Illinois at
Urbana-Champaign, Urbana, IL, United States of America. (2)Department of Crop
Sciences, Univ. of Illinois at Urbana-Champaign, Urbana, IL, United States of
America. (3)Institute for Genomic Biology, Univ. of Illinois at Urbana-Champaign,
Urbana, IL, United States of America. (4)National Center for Supercomputing
Applications, Univ. of Illinois at Urbana-Champaign, Urbana, IL, United States of
America. (5)Ontario Institute for Cancer Research, Toronto, ON, Canada.

An obstacle to validating and benchmarking methods for genome analysis is that
there are few reference datasets available for which the "ground truth" about the
mutational landscape of the sample genome is known and fully validated.
Additionally, the free and public availability of real human genome datasets is
incompatible with the preservation of donor privacy. In order to better analyze
and understand genomic data, we need test datasets that model all variants,
reflecting known biology as well as sequencing artifacts. Read simulators can
fulfill this requirement, but are often criticized for limited resemblance to
true data and overall inflexibility. We present NEAT (NExt-generation sequencing 
Analysis Toolkit), a set of tools that not only includes an easy-to-use read
simulator, but also scripts to facilitate variant comparison and tool evaluation.
NEAT has a wide variety of tunable parameters which can be set manually on the
default model or parameterized using real datasets. The software is freely
available at github.com/zstephens/neat-genreads.

DOI: 10.1371/journal.pone.0167047 
PMCID: PMC5125660
PMID: 27893777  [PubMed - in process]


155. IEEE Trans Biomed Eng. 2016 Nov 23. [Epub ahead of print]

BLASST: Band Limited Atomic Sampling with Spectral Tuning with Applications to
Utility Line Noise Filtering.

Ball KR, Hairston WD, Franaszczuk PJ, Robbins KA.

OBJECTIVE: In this paper we present and test a new method for the identification 
and removal of non-stationary utility line noise from biomedical signals.
METHODS: The method, Band Limited Atomic Sampling with Spectral Tuning (BLASST), 
is an iterative approach that is designed to (1) fit non-stationarities in line
noise by searching for best-fit Gabor atoms at predetermined time points, (2)
self-modulate its fit by leveraging information from frequencies surrounding the 
target frequency, and (3) terminate based on a convergence criterion obtained
from the same surrounding frequencies. To evaluate the performance of the
proposed algorithm, we generate several simulated and real instances of
non-stationary line noise and test BLASST along with alternative filtering
approaches.
RESULTS: We find that BLASST is capable of fitting line noise well and/or
preserving local signal features relative to tested alternative filtering
techniques.
CONCLUSION: BLASST may present a useful alternative to bandpass, notch, or other 
filtering methods when experimentally relevant features have significant power in
a spectrum that is contaminated by utility line noise, or when the the line noise
in question is highly non-stationary.
SIGNIFICANCE: This is of particular significance in electroencephalography (EEG) 
experiments, where line noise may be present in the frequency bands of
neurological interest and measurements are typically of low enough strength that 
induced line noise can dominate the recorded signals. In conjunction with this
paper, the authors have released a MATLAB toolbox that performs BLASST on real,
vectorvalued signals (available at https://github.com/VisLab/blasst).

DOI: 10.1109/TBME.2016.2632119 
PMID: 27893379  [PubMed - as supplied by publisher]


156. Comput Biol Chem. 2017 Feb;66:36-43. doi: 10.1016/j.compbiolchem.2016.10.009.
Epub 2016 Nov 9.

Development of a sugar-binding residue prediction system from protein sequences
using support vector machine.

Banno M(1), Komiyama Y(2), Cao W(1), Oku Y(1), Ueki K(1), Sumikoshi K(1),
Nakamura S(1), Terada T(1), Shimizu K(3).

Author information: 
(1)Graduate School of Agricultural and Life Sciences, The University of Tokyo,
1-1-1 Yayoi, Bunkyo-Ward, Tokyo 113-8657, Japan. (2)Digital Content and Media
Sciences Research Division, National Institute of Informatics, 2-1-2
Hitotsubashi, Chiyoda-Ward, Tokyo 101-8430, Japan. (3)Graduate School of
Agricultural and Life Sciences, The University of Tokyo, 1-1-1 Yayoi,
Bunkyo-Ward, Tokyo 113-8657, Japan. Electronic address:
shimizu@bi.a.u-tokyo.ac.jp.

Several methods have been proposed for protein-sugar binding site prediction
using machine learning algorithms. However, they are not effective to learn
various properties of binding site residues caused by various interactions
between proteins and sugars. In this study, we classified sugars into acidic and 
nonacidic sugars and showed that their binding sites have different amino acid
occurrence frequencies. By using this result, we developed sugar-binding residue 
predictors dedicated to the two classes of sugars: an acid sugar binding
predictor and a nonacidic sugar binding predictor. We also developed a
combination predictor which combines the results of the two predictors. We showed
that when a sugar is known to be an acidic sugar, the acidic sugar binding
predictor achieves the best performance, and showed that when a sugar is known to
be a nonacidic sugar or is not known to be either of the two classes, the
combination predictor achieves the best performance. Our method uses only amino
acid sequences for prediction. Support vector machine was used as a machine
learning algorithm and the position-specific scoring matrix created by the
position-specific iterative basic local alignment search tool was used as the
feature vector. We evaluated the performance of the predictors using five-fold
cross-validation. We have launched our system, as an open source freeware tool on
the GitHub repository (https://doi.org/10.5281/zenodo.61513).

Copyright © 2016 The Authors. Published by Elsevier Ltd.. All rights reserved.

DOI: 10.1016/j.compbiolchem.2016.10.009 
PMID: 27889654  [PubMed - in process]


157. Database (Oxford). 2016 Nov 25;2016. pii: baw141. Print 2016.

ToxReporter: viewing the genome through the eyes of a toxicologist.

Gosink M(1).

Author information: 
(1)Department of Investigative Toxicology, Pfizer Inc, Eastern Point Rd, MS
8274-1246, Groton, CT 06340, USA Mark.M.Gosink@Pfizer.com.

One of the many roles of a toxicologist is to determine if an observed adverse
event (AE) is related to a previously unrecognized function of a given
gene/protein. Towards that end, he or she will search a variety of public and
propriety databases for information linking that protein to the observed AE.
However, these databases tend to present all available information about a
protein, which can be overwhelming, limiting the ability to find information
about the specific toxicity being investigated. ToxReporter compiles information 
from a broad selection of resources and limits display of the information to
user-selected areas of interest. ToxReporter is a PERL-based web-application
which utilizes a MySQL database to streamline this process by categorizing public
and proprietary domain-derived information into predefined safety categories
according to a customizable lexicon. Users can view gene information that is
'red-flagged' according to the safety issue under investigation. ToxReporter also
uses a scoring system based on relative counts of the red-flags to rank all genes
for the amount of information pertaining to each safety issue and to display
their scored ranking as an easily interpretable 'Tox-At-A-Glance' chart. Although
ToxReporter was originally developed to display safety information, its flexible 
design could easily be adapted to display disease information as well.Database
URL: ToxReporter is freely available at https://github.com/mgosink/ToxReporter.

© The Author(s) 2016. Published by Oxford University Press.

DOI: 10.1093/database/baw141 
PMCID: PMC5199150
PMID: 27888230  [PubMed - in process]


158. Genome Biol. 2016 Nov 25;17(1):238.

Rapid scoring of genes in microbial pan-genome-wide association studies with
Scoary.

Brynildsrud O(1), Bohlin J(2), Scheffer L(2,)(3), Eldholm V(2).

Author information: 
(1)Domain of Infectious Disease Control and Environmental Health, Norwegian
Institute of Public Health, Oslo, Norway. ola.brynildsrud@fhi.no. (2)Domain of
Infectious Disease Control and Environmental Health, Norwegian Institute of
Public Health, Oslo, Norway. (3)Hanze University of Applied Sciences, Groningen, 
The Netherlands.

Erratum in
    Genome Biol. 2016 Dec 19;17 (1):262.

Genome-wide association studies (GWAS) have become indispensable in human
medicine and genomics, but very few have been carried out on bacteria. Here we
introduce Scoary, an ultra-fast, easy-to-use, and widely applicable software tool
that scores the components of the pan-genome for associations to observed
phenotypic traits while accounting for population stratification, with minimal
assumptions about evolutionary processes. We call our approach pan-GWAS to
distinguish it from traditional, single nucleotide polymorphism (SNP)-based GWAS.
Scoary is implemented in Python and is available under an open source GPLv3
license at https://github.com/AdmiralenOla/Scoary .

DOI: 10.1186/s13059-016-1108-8 
PMCID: PMC5124306
PMID: 27887642  [PubMed - in process]


159. BMC Bioinformatics. 2016 Nov 25;17(1):482.

SPECtre: a spectral coherence--based classifier of actively translated
transcripts from ribosome profiling sequence data.

Chun SY(1), Rodriguez CM(2), Todd PK(2,)(3), Mills RE(4,)(5).

Author information: 
(1)Department of Computational Medicine and Bioinformatics, University of
Michigan, Ann Arbor, MI, 48109, USA. (2)Department of Neurology, University of
Michigan, Ann Arbor, MI, 48109, USA. (3)Veterans Affairs Medical Center, Ann
Arbor, MI, 48105, USA. (4)Department of Computational Medicine and
Bioinformatics, University of Michigan, Ann Arbor, MI, 48109, USA.
remills@umich.edu. (5)Department of Human Genetics, University of Michigan, Ann
Arbor, MI, 48109, USA. remills@umich.edu.

BACKGROUND: Active protein translation can be assessed and measured using
ribosome profiling sequencing strategies. Prevailing analytical approaches
applied to this technology make use of sequence fragment length profiling or
reading frame occupancy enrichment to differentiate between active translation
and background noise, however they do not consider additional characteristics
inherent to the technology which limits their overall accuracy.
RESULTS: Here, we present an analytical tool that models the overall
tri-nucleotide periodicity of ribosomal occupancy using a classifier based on
spectral coherence. Our software, SPECtre, examines the relationship of
normalized ribosome profiling read coverage over a rolling series of windows
along a transcript relative to an idealized reference signal without the matched 
requirement of mRNA-Seq.
CONCLUSIONS: A comparison of SPECtre against previously published methods on
existing data shows a marked improvement in accuracy for detecting active
translation and exhibits overall high accuracy at a low false discovery rate. In 
addition, SPECtre performs comparably to a recently published method similarly
based on spectral coherence, however with reduced runtime and memory
requirements. SPECtre is available as an open source software package at
https://github.com/mills-lab/spectreok .

DOI: 10.1186/s12859-016-1355-4 
PMCID: PMC5123373
PMID: 27884106  [PubMed - in process]


160. Hum Brain Mapp. 2016 Nov 23. doi: 10.1002/hbm.23463. [Epub ahead of print]

fMRI single trial discovery of spatio-temporal brain activity patterns.

Allegra M(1), Seyed-Allaei S(2,)(3,)(4), Pizzagalli F(1,)(5), Baftizadeh F(6),
Maieron M(7), Reverberi C(2,)(3), Laio A(1), Amati D(1).

Author information: 
(1)SISSA-International School for Advanced Studies, Via Bonomea, Trieste, 265,
Italy. (2)Psychology Department, University of Milan Bicocca, Milan, Italy.
(3)Milan Center for Neuroscience, Milan, Italy. (4)Department of Electrical and
Computer Engineering, University of Tehran, Tehran, Iran. (5)Imaging Genetics
Center, Mark and Mary Stevens Neuroimaging & Informatics Institute, Keck School
of Medicine, the University of Southern California, Marina del Rey, California.
(6)Department of Chemical Engineering, Massachusetts Institute of Technology,
Cambridge, Massachusetts. (7)Medical Physics Department, AOUD S. Maria
dellaMisericordia Hospital, Udine, Italy.

There is growing interest in the description of short-lived patterns in the
spatiotemporal cortical activity monitored via neuroimaging. Most traditional
analysis methods, designed to estimate relatively long-term brain dynamics, are
not always appropriate to capture these patterns. Here we introduce a novel
data-driven approach for detecting short-lived fMRI brain activity patterns.
Exploiting Density Peak Clustering (Rodriguez and Laio [2014]), our approach
reveals well localized clusters by identifying and grouping together voxels whose
time-series are similar, irrespective of their brain location, even when very
short time windows (∼10 volumes) are used. The method, which we call Coherence
Density Peak Clustering (CDPC), is first tested on simulated data and compared
with a standard unsupervised approach for fMRI analysis, independent component
analysis (ICA). CDPC identifies activated voxels with essentially no
false-positives and proves more reliable than ICA, which is troubled by a number 
of false positives comparable to that of true positives. The reliability of the
method is demonstrated on real fMRI data from a simple motor task, containing
brief iterations of the same movement. The clusters identified are found in
regions expected to be involved in the task, and repeat synchronously with the
paradigm. The methodology proposed is especially suitable for the study of
short-time brain dynamics and single trial experiments, where the event or task
of interest cannot be repeated for the same subject, as happens, for instance, in
problem-solving, learning and decision-making. A GUI implementation of our method
is available for download at https://github.com/micheleallegra/CDPC. Hum Brain
Mapp, 2016. © 2016 Wiley Periodicals, Inc.

© 2016 Wiley Periodicals, Inc.

DOI: 10.1002/hbm.23463 
PMID: 27879036  [PubMed - as supplied by publisher]


161. Am J Infect Control. 2016 Nov 18. pii: S0196-6553(16)30915-4. doi:
10.1016/j.ajic.2016.09.021. [Epub ahead of print]

Process control charts in infection prevention: Make it simple to make it happen.

Wiemken TL(1), Furmanek SP(2), Carrico RM(2), Mattingly WA(2), Persaud AK(2),
Guinn BE(2), Kelley RR(3), Ramirez JA(2).

Author information: 
(1)Division of Infectious Diseases, University of Louisville, Louisville, KY.
Electronic address: tim.wiemken@louisville.edu. (2)Division of Infectious
Diseases, University of Louisville, Louisville, KY. (3)Department of Math and
Computer Science, St Mary's College of Maryland, St Mary's City, MD.

BACKGROUND: Quality improvement is central to Infection Prevention and Control
(IPC) programs. Challenges may occur when applying quality improvement
methodologies like process control charts, often due to the limited exposure of
typical IPs. Because of this, our team created an open-source database with a
process control chart generator for IPC programs. The objectives of this report
are to outline the development of the application and demonstrate application
using simulated data.
METHODS: We used Research Electronic Data Capture (REDCap Consortium, Vanderbilt 
University, Nashville, TN), R (R Foundation for Statistical Computing, Vienna,
Austria), and R Studio Shiny (R Foundation for Statistical Computing) to create
an open source data collection system with automated process control chart
generation. We used simulated data to test and visualize both in-control and
out-of-control processes for commonly used metrics in IPC programs.
RESULTS: The R code for implementing the control charts and Shiny application can
be found on our Web site (https://github.com/ul-research-support/spcapp). Screen 
captures of the workflow and simulated data indicating both common cause and
special cause variation are provided.
CONCLUSIONS: Process control charts can be easily developed based on individual
facility needs using freely available software. Through providing our work free
to all interested parties, we hope that others will be able to harness the power 
and ease of use of the application for improving the quality of care and patient 
safety in their facilities.

Copyright © 2016 Association for Professionals in Infection Control and
Epidemiology, Inc. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.ajic.2016.09.021 
PMID: 27876163  [PubMed - as supplied by publisher]


162. IEEE Trans Vis Comput Graph. 2017 Jan;23(1):251-260.

VisFlow - Web-based Visualization Framework for Tabular Data with a Subset Flow
Model.

Yu B, Silva CT.

Data flow systems allow the user to design a flow diagram that specifies the
relations between system components which process, filter or visually present the
data. Visualization systems may benefit from user-defined data flows as an
analysis typically consists of rendering multiple plots on demand and performing 
different types of interactive queries across coordinated views. In this paper,
we propose VisFlow, a web-based visualization framework for tabular data that
employs a specific type of data flow model called the subset flow model. VisFlow 
focuses on interactive queries within the data flow, overcoming the limitation of
interactivity from past computational data flow systems. In particular, VisFlow
applies embedded visualizations and supports interactive selections, brushing and
linking within a visualization-oriented data flow. The model requires all data
transmitted by the flow to be a data item subset (i.e. groups of table rows) of
some original input table, so that rendering properties can be assigned to the
subset unambiguously for tracking and comparison. VisFlow features the analysis
flexibility of a flow diagram, and at the same time reduces the diagram
complexity and improves usability. We demonstrate the capability of VisFlow on
two case studies with domain experts on real-world datasets showing that VisFlow 
is capable of accomplishing a considerable set of visualization and analysis
tasks. The VisFlow system is available as open source on GitHub.

DOI: 10.1109/TVCG.2016.2598497 
PMID: 27875142  [PubMed - in process]


163. Nat Methods. 2017 Jan;14(1):68-70. doi: 10.1038/nmeth.4078. Epub 2016 Nov 21.

TACO produces robust multisample transcriptome assemblies from RNA-seq.

Niknafs YS(1,)(2), Pandian B(1), Iyer HK(3), Chinnaiyan
AM(1,)(2,)(4,)(5,)(6,)(7), Iyer MK(1).

Author information: 
(1)Michigan Center for Translational Pathology, University of Michigan, Ann
Arbor, Michigan, USA. (2)Department of Cellular and Molecular Biology, University
of Michigan, Ann Arbor, Michigan, USA. (3)Department of Statistics, Colorado
State University, Fort Collins, Colorado, USA. (4)Department of Pathology,
University of Michigan, Ann Arbor, Michigan, USA. (5)Howard Hughes Medical
Institute, University of Michigan, Ann Arbor, Michigan, USA. (6)Comprehensive
Cancer Center, University of Michigan, Ann Arbor, Michigan, USA. (7)Department of
Urology, University of Michigan, Ann Arbor, Michigan, USA.

Accurate transcript structure and abundance inference from RNA sequencing
(RNA-seq) data is foundational for molecular discovery. Here we present TACO, a
computational method to reconstruct a consensus transcriptome from multiple
RNA-seq data sets. TACO employs novel change-point detection to demarcate
transcript start and end sites, leading to improved reconstruction accuracy
compared with other tools in its class. The tool is available at
http://tacorna.github.io and can be readily incorporated into RNA-seq analysis
workflows.

DOI: 10.1038/nmeth.4078 
PMCID: PMC5199618 [Available on 2017-05-21]
PMID: 27869815  [PubMed - in process]


164. Front Immunol. 2016 Nov 4;7:457. eCollection 2016.

IMPre: An Accurate and Efficient Software for Prediction of T- and B-Cell
Receptor Germline Genes and Alleles from Rearranged Repertoire Data.

Zhang W(1), Wang IM(2), Wang C(1), Lin L(1), Chai X(1), Wu J(1), Bett AJ(2),
Dhanasekaran G(2), Casimiro DR(2), Liu X(1).

Author information: 
(1)Beijing Genomics Institute (BGI-Shenzhen) , Shenzhen , China. (2)Merck
Research Laboratories , West Point, PA , USA.

Large-scale study of the properties of T-cell receptor (TCR) and B-cell receptor 
(BCR) repertoires through next-generation sequencing is providing excellent
insights into the understanding of adaptive immune responses.
Variable(Diversity)Joining [V(D)J] germline genes and alleles must be
characterized in detail to facilitate repertoire analyses. However, most species 
do not have well-characterized TCR/BCR germline genes because of their high
homology. Also, more germline alleles are required for humans and other species, 
which limits the capacity for studying immune repertoires. Herein, we developed
"Immune Germline Prediction" (IMPre), a tool for predicting germline V/J genes
and alleles using deep-sequencing data derived from TCR/BCR repertoires. We
developed a new algorithm, "Seed_Clust," for clustering, produced a multiway tree
for assembly and optimized the sequence according to the characteristics of
rearrangement. We trained IMPre on human samples of T-cell receptor beta (TRB)
and immunoglobulin heavy chain and then tested it on additional human samples.
Accuracy of 97.7, 100, 92.9, and 100% was obtained for TRBV, TRBJ, IGHV, and
IGHJ, respectively. Analyses of subsampling performance for these samples showed 
IMPre to be robust using different data quantities. Subsequently, IMPre was
tested on samples from rhesus monkeys and human long sequences: the highly
accurate results demonstrated IMPre to be stable with animal and multiple data
types. With rapid accumulation of high-throughput sequence data for TCR and BCR
repertoires, IMPre can be applied broadly for obtaining novel genes and a large
number of novel alleles. IMPre is available at
https://github.com/zhangwei2015/IMPre.

DOI: 10.3389/fimmu.2016.00457 
PMID: 27867380  [PubMed - in process]


165. Cell Syst. 2016 Nov 23;3(5):491-495.e5. doi: 10.1016/j.cels.2016.10.021. Epub
2016 Nov 15.

The BLUEPRINT Data Analysis Portal.

Fernández JM(1), de la Torre V(1), Richardson D(2), Royo R(3), Puiggròs M(4),
Moncunill V(4), Fragkogianni S(4), Clarke L(2); BLUEPRINT Consortium(5), Flicek
P(2), Rico D(6), Torrents D(7), Carrillo de Santa Pau E(8), Valencia A(9).

Author information: 
(1)Structural Biology and BioComputing Programme, Spanish National Cancer
Research Centre (CNIO), Madrid 28029, Spain; Spanish Bioinformatics Institute
INB-ISCIII ES-ELIXIR, Madrid 28029, Spain. (2)European Molecular Biology
Laboratory, European Bioinformatics Institute, Wellcome Genome Campus, Hinxton,
Cambridge CB10 1SD, UK. (3)Spanish Bioinformatics Institute INB-ISCIII ES-ELIXIR,
Madrid 28029, Spain; Barcelona Supercomputing Center (BSC), Joint BSC-CRG-IRB,
Research Program in Computational Biology, BSC - CRG - IRB, Barcelona 08028,
Spain. (4)Barcelona Supercomputing Center (BSC), Joint BSC-CRG-IRB, Research
Program in Computational Biology, BSC - CRG - IRB, Barcelona 08028, Spain.
(5)http://www.blueprint-epigenome.eu/. (6)Structural Biology and BioComputing
Programme, Spanish National Cancer Research Centre (CNIO), Madrid 28029, Spain.
(7)Barcelona Supercomputing Center (BSC), Joint BSC-CRG-IRB, Research Program in 
Computational Biology, BSC - CRG - IRB, Barcelona 08028, Spain; Institució
Catalana de Recerca i Estudis Avançats (ICREA), Barcelona 08010, Spain.
(8)Structural Biology and BioComputing Programme, Spanish National Cancer
Research Centre (CNIO), Madrid 28029, Spain. Electronic address:
ecarrillo@cnio.es. (9)Structural Biology and BioComputing Programme, Spanish
National Cancer Research Centre (CNIO), Madrid 28029, Spain; Spanish
Bioinformatics Institute INB-ISCIII ES-ELIXIR, Madrid 28029, Spain. Electronic
address: valencia@cnio.es.

The impact of large and complex epigenomic datasets on biological insights or
clinical applications is limited by the lack of accessibility by easy, intuitive,
and fast tools. Here, we describe an epigenomics comparative cyber-infrastructure
(EPICO), an open-access reference set of libraries to develop comparative
epigenomic data portals. Using EPICO, large epigenome projects can make available
their rich datasets to the community without requiring specific technical skills.
As a first instance of EPICO, we implemented the BLUEPRINT Data Analysis Portal
(BDAP). BDAP provides a desktop for the comparative analysis of epigenomes of
hematopoietic cell types based on results, such as the position of epigenetic
features, from basic analysis pipelines. The BDAP interface facilitates
interactive exploration of genomic regions, genes, and pathways in the context of
differentiation of hematopoietic lineages. This work represents initial steps
toward broadly accessible integrative analysis of epigenomic data across
international consortia. EPICO can be accessed at https://github.com/inab, and
BDAP can be accessed at http://blueprint-data.bsc.es.

Copyright Â© 2016 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.cels.2016.10.021 
PMID: 27863955  [PubMed - in process]


166. Mol Cancer. 2016 Nov 16;15(1):72.

Systems analysis identifies miR-29b regulation of invasiveness in melanoma.

Andrews MC(1,)(2,)(3,)(4), Cursons J(5,)(6,)(7,)(8), Hurley DG(5,)(7,)(8), Anaka 
M(2,)(9), Cebon JS(10,)(11,)(12,)(13), Behren A(14,)(15,)(16), Crampin
EJ(17,)(18,)(19,)(20,)(21).

Author information: 
(1)Olivia Newton-John Cancer Research Institute, Heidelberg, VIC, 3084,
Australia. (2)Ludwig Institute for Cancer Research, Melbourne-Austin Branch,
Cancer Immunobiology Laboratory, Heidelberg, VIC, 3084, Australia. (3)School of
Cancer Medicine, La Trobe University, Heidelberg, VIC, 3084, Australia.
(4)Department of Medicine, University of Melbourne, Parkville, VIC, 3010,
Australia. (5)Systems Biology Laboratory, University of Melbourne, Parkville,
VIC, 3010, Australia. (6)ARC Centre of Excellence in Convergent Bio-Nano Science,
University of Melbourne, Parkville, VIC, 3010, Australia. (7)School of
Mathematics and Statistics, University of Melbourne, Parkville, VIC, 3010,
Australia. (8)Centre for Systems Genomics, University of Melbourne, Parkville,
VIC, 3010, Australia. (9)Department of Medicine, University of Toronto, Toronto, 
ON, Canada. (10)Olivia Newton-John Cancer Research Institute, Heidelberg, VIC,
3084, Australia. jonathan.cebon@onjcri.org.au. (11)Ludwig Institute for Cancer
Research, Melbourne-Austin Branch, Cancer Immunobiology Laboratory, Heidelberg,
VIC, 3084, Australia. jonathan.cebon@onjcri.org.au. (12)School of Cancer
Medicine, La Trobe University, Heidelberg, VIC, 3084, Australia.
jonathan.cebon@onjcri.org.au. (13)Department of Medicine, University of
Melbourne, Parkville, VIC, 3010, Australia. jonathan.cebon@onjcri.org.au.
(14)Olivia Newton-John Cancer Research Institute, Heidelberg, VIC, 3084,
Australia. andreas.behren@onjcri.org.au. (15)Ludwig Institute for Cancer
Research, Melbourne-Austin Branch, Cancer Immunobiology Laboratory, Heidelberg,
VIC, 3084, Australia. andreas.behren@onjcri.org.au. (16)School of Cancer
Medicine, La Trobe University, Heidelberg, VIC, 3084, Australia.
andreas.behren@onjcri.org.au. (17)Department of Medicine, University of
Melbourne, Parkville, VIC, 3010, Australia. edmund.crampin@unimelb.edu.au.
(18)Systems Biology Laboratory, University of Melbourne, Parkville, VIC, 3010,
Australia. edmund.crampin@unimelb.edu.au. (19)ARC Centre of Excellence in
Convergent Bio-Nano Science, University of Melbourne, Parkville, VIC, 3010,
Australia. edmund.crampin@unimelb.edu.au. (20)School of Mathematics and
Statistics, University of Melbourne, Parkville, VIC, 3010, Australia.
edmund.crampin@unimelb.edu.au. (21)Centre for Systems Genomics, University of
Melbourne, Parkville, VIC, 3010, Australia. edmund.crampin@unimelb.edu.au.

BACKGROUND: In many cancers, microRNAs (miRs) contribute to metastatic
progression by modulating phenotypic reprogramming processes such as
epithelial-mesenchymal plasticity. This can be driven by miRs targeting multiple 
mRNA transcripts, inducing regulated changes across large sets of genes. The
miR-target databases TargetScan and DIANA-microT predict putative relationships
by examining sequence complementarity between miRs and mRNAs. However, it remains
a challenge to identify which miR-mRNA interactions are active at endogenous
expression levels, and of biological consequence.
METHODS: We developed a workflow to integrate TargetScan and DIANA-microT
predictions into the analysis of data-driven associations calculated from
transcript abundance (RNASeq) data, specifically the mutual information and
Pearson's correlation metrics. We use this workflow to identify putative
relationships of miR-mediated mRNA repression with strong support from both lines
of evidence. Applying this approach systematically to a large, published
collection of unique melanoma cell lines - the Ludwig Melbourne melanoma (LM-MEL)
cell line panel - we identified putative miR-mRNA interactions that may
contribute to invasiveness. This guided the selection of interactions of interest
for further in vitro validation studies.
RESULTS: Several miR-mRNA regulatory relationships supported by TargetScan and
DIANA-microT demonstrated differential activity across cell lines of varying
matrigel invasiveness. Strong negative statistical associations for these
putative regulatory relationships were consistent with target mRNA inhibition by 
the miR, and suggest that differential activity of such miR-mRNA relationships
contribute to differences in melanoma invasiveness. Many of these relationships
were reflected across the skin cutaneous melanoma TCGA dataset, indicating that
these observations also show graded activity across clinical samples. Several of 
these miRs are implicated in cancer progression (miR-211, -340, -125b, -221, and 
-29b). The specific role for miR-29b-3p in melanoma has not been well studied. We
experimentally validated the predicted miR-29b-3p regulation of LAMC1 and PPIC
and LASP1, and show that dysregulation of miR-29b-3p or these mRNA targets can
influence cellular invasiveness in vitro.
CONCLUSIONS: This analytic strategy provides a comprehensive, systems-level
approach to identify miR-mRNA regulation in high-throughput cancer data,
identifies novel putative interactions with functional phenotypic relevance, and 
can be used to direct experimental resources for subsequent experimental
validation. Computational scripts are available:
http://github.com/uomsystemsbiology/LMMEL-miR-miner.

DOI: 10.1186/s12943-016-0554-y 
PMCID: PMC5112703
PMID: 27852308  [PubMed - in process]


167. Gene. 2017 Feb 5;600:77-84. doi: 10.1016/j.gene.2016.11.025. Epub 2016 Nov 13.

PanGeT: Pan-genomics tool.

Yuvaraj I(1), Sridhar J(2), Michael D(1), Sekar K(3).

Author information: 
(1)Department of Computational and Data Sciences, Indian Institute of Science,
Bangalore 560012, India. (2)Centre of Excellence in Bioinformatics, School of
Biotechnology, Madurai Kamaraj University, Madurai 625021, India; Department of
Biotechnology (DDE), Madurai Kamaraj University, Madurai 625021, India.
(3)Department of Computational and Data Sciences, Indian Institute of Science,
Bangalore 560012, India. Electronic address: sekar@cds.iisc.ac.in.

A decade after the concept of Pan-genome was first introduced; research in this
field has spread its tentacles to areas such as pathogenesis of diseases,
bacterial evolutionary studies and drug resistance. Gene content-based
differentiation of virulent and a virulent strains of bacteria and identification
of pathogen specific genes is imperative to understand their physiology and gain 
insights into the mechanism of genome evolution. Subsequently, this will aid in
identifying diagnostic targets and in developing and selecting vaccines. The root
of pan-genomic studies, however, is to identify the core genes, dispensable genes
and strain specific genes across the genomes belonging to a clade. To this end,
we have developed a tool, "PanGeT - Pan-genomics Tool" to compute the
'pan-genome' based on comparisons at the genome as well as the proteome levels.
This automated tool is implemented using LaTeX libraries for effective
visualization of overall pan-genome through graphical plots. Links to retrieve
sequence information and functional annotations have also been provided. PanGeT
can be downloaded from http://pranag.physics.iisc.ernet.in/PanGeT/ or
https://github.com/PanGeTv1/PanGeT.

Copyright © 2016 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.gene.2016.11.025 
PMID: 27851981  [PubMed - indexed for MEDLINE]


168. IEEE Trans Nanobioscience. 2016 Dec;15(8):946-958. doi: 10.1109/TNB.2016.2625823.
Epub 2016 Nov 7.

Collaborative Completion of Transcription Factor Binding Profiles via Local
Sensitive Unified Embedding.

Zhu L, Guo WL, Lu C, Huang DS.

Although the newly available ChIP-seq data provides immense opportunities for
comparative study of regulatory activities across different biological
conditions, due to cost, time or sample material availability, it is not always
possible for researchers to obtain binding profiles for every protein in every
sample of interest, which considerably limits the power of integrative studies.
Recently, by leveraging related information from measured data, Ernst et al.
proposed ChromImpute for predicting additional ChIP-seq and other types of
datasets, it is demonstrated that the imputed signal tracks accurately
approximate the experimentally measured signals, and thereby could potentially
enhance the power of integrative analysis. Despite the success of ChromImpute, in
this paper, we reexamine its learning process, and show that its performance may 
degrade substantially and sometimes may even fail to output a prediction when the
available data is scarce. This limitation could hurt its applicability to
important predictive tasks, such as the imputation of TF binding data. To
alleviate this problem, we propose a novel method called Local Sensitive Unified 
Embedding (LSUE) for imputing new ChIP-seq datasets. In LSUE, the ChIP-seq data
compendium are fused together by mapping proteins, samples, and genomic positions
simultaneously into the Euclidean space, thereby making their underling
associations directly evaluable using simple calculations. In contrast to
ChromImpute which mainly makes use of the local correlations between available
datasets, LSUE can better estimate the overall data structure by formulating the 
representation learning of all involved entities as a single unified optimization
problem. Meanwhile, a novel form of local sensitive low rank regularization is
also proposed to further improve the performance of LSUE. Experimental
evaluations on the ENCODE TF ChIP-seq data illustrate the performance of the
proposed model. The code of LSUE is available at https://github.com/ekffar/LSUE.

DOI: 10.1109/TNB.2016.2625823 
PMID: 27845669  [PubMed - in process]


169. Nat Methods. 2017 Jan;14(1):57-60. doi: 10.1038/nmeth.4072. Epub 2016 Nov 14.

FDR-controlled metabolite annotation for high-resolution imaging mass
spectrometry.

Palmer A(1), Phapale P(1), Chernyavsky I(2), Lavigne R(3,)(4), Fay D(1), Tarasov 
A(1), Kovalev V(1), Fuchser J(5), Nikolenko S(1,)(6,)(7), Pineau C(3,)(4), Becker
M(5), Alexandrov T(1,)(8,)(9).

Author information: 
(1)Structural and Computational Biology Unit, European Molecular Biology
Laboratory, Heidelberg, Germany. (2)Center for Industrial Mathematics, University
of Bremen, Bremen, Germany. (3)Protim, Inserm U1085, IRSET, Rennes, France.
(4)Université de Rennes I, Rennes, France. (5)Bruker Daltonik GmbH, Bremen,
Germany. (6)National Research University Higher School of Economics, St.
Petersburg, Russia. (7)Higher Institute of Information Technologies and
Information Systems, Kazan Federal University, Kazan, Russia. (8)SCiLS GmbH,
Bremen, Germany. (9)Skaggs School of Pharmacy and Pharmaceutical Sciences,
University of California, San Diego, La Jolla, California, USA.

High-mass-resolution imaging mass spectrometry promises to localize hundreds of
metabolites in tissues, cell cultures, and agar plates with cellular resolution, 
but it is hampered by the lack of bioinformatics tools for automated metabolite
identification. We report pySM, a framework for false discovery rate
(FDR)-controlled metabolite annotation at the level of the molecular sum formula,
for high-mass-resolution imaging mass spectrometry
(https://github.com/alexandrovteam/pySM). We introduce a metabolite-signal match 
score and a target-decoy FDR estimate for spatial metabolomics.

DOI: 10.1038/nmeth.4072 
PMID: 27842059  [PubMed - in process]


170. J Open Res Softw. 2016;4(1). pii: e27. Epub 2016 Jul 19.

Channeling Community Contributions to Scientific Software: A Sprint Experience.

Crusoe MR(1), Brown CT(2).

Author information: 
(1)Microbiology and Molecular Genetics, Michigan State University, East Lansing, 
MI, USA. (2)Microbiology and Molecular Genetics, Michigan State University, East 
Lansing, MI, USA; Computer Science and Engineering, Michigan State University,
East Lansing, MI, USA.

In 2014, the khmer software project participated in a two-day global sprint
coordinated by the Mozilla Science Lab. We offered a mentored experience in
contributing to a scientific software project for anyone who was interested. We
provided entry-level tasks and worked with contributors as they worked through
our development process. The experience was successful on both a social and a
technical level, bringing in 13 contributions from 9 new contributors and
validating our development process. In this experience paper we describe the
sprint preparation and process, relate anecdotal experiences, and draw
conclusions about what other projects could do to enable a similar outcome. The
khmer software is developed openly at http://github.com/dib-lab/khmer/.

DOI: 10.5334/jors.96 
PMCID: PMC5104275
PMID: 27840675  [PubMed]


171. Behav Res Methods. 2016 Nov 11. [Epub ahead of print]

Psynteract: A flexible, cross-platform, open framework for interactive
experiments.

Henninger F(1,)(2,)(3), Kieslich PJ(4,)(5), Hilbig BE(6,)(7).

Author information: 
(1)Cognitive Psychology Lab, University of Koblenz-Landau, Campus Landau,
Building K, Fortstra ße 7, D-76829, Landau, Germany. mailbox@felixhenninger.com. 
(2)Center for Doctoral Studies in Social and Behavioral Sciences, University of
Mannheim, Mannheim, Germany. mailbox@felixhenninger.com. (3)Max Planck Institute 
for Research on Collective Goods, Bonn, Germany. mailbox@felixhenninger.com.
(4)Experimental Psychology, School of Social Sciences, University of Mannheim,
Schloss Ehrenhof Ost, D-68131, Mannheim, Germany. (5)Center for Doctoral Studies 
in Social and Behavioral Sciences, University of Mannheim, Mannheim, Germany.
(6)Cognitive Psychology Lab, University of Koblenz-Landau, Campus Landau,
Building K, Fortstra ße 7, D-76829, Landau, Germany. (7)Max Planck Institute for 
Research on Collective Goods, Bonn, Germany.

We introduce a novel platform for interactive studies, that is, any form of study
in which participants' experiences depend not only on their own responses, but
also on those of other participants who complete the same study in parallel, for 
example a prisoner's dilemma or an ultimatum game. The software thus especially
serves the rapidly growing field of strategic interaction research within
psychology and behavioral economics. In contrast to all available software
packages, our platform does not handle stimulus display and response collection
itself. Instead, we provide a mechanism to extend existing experimental software 
to incorporate interactive functionality. This approach allows us to draw upon
the capabilities already available, such as accuracy of temporal measurement,
integration with auxiliary hardware such as eye-trackers or (neuro-)physiological
apparatus, and recent advances in experimental software, for example capturing
response dynamics through mouse-tracking. Through integration with OpenSesame, an
open-source graphical experiment builder, studies can be assembled via a
drag-and-drop interface requiring little or no further programming skills. In
addition, by using the same communication mechanism across software packages, we 
also enable interoperability between systems. Our source code, which provides
support for all major operating systems and several popular experimental
packages, can be freely used and distributed under an open source license. The
communication protocols underlying its functionality are also well documented and
easily adapted to further platforms. Code and documentation are available at
https://github.com/psynteract/ .

DOI: 10.3758/s13428-016-0801-6 
PMID: 27837568  [PubMed - as supplied by publisher]


172. PLoS Genet. 2016 Nov 11;12(11):e1006423. doi: 10.1371/journal.pgen.1006423.
eCollection 2016.

Survey of the Heritability and Sparse Architecture of Gene Expression Traits
across Human Tissues.

Wheeler HE(1,)(2), Shah KP(3), Brenner J(2), Garcia T(4), Aquino-Michaels K(3);
GTEx Consortium, Cox NJ(5), Nicolae DL(3), Im HK(3).

Author information: 
(1)Department of Biology, Loyola University Chicago, Chicago, Illinois, United
States of America. (2)Department of Computer Science, Loyola University Chicago, 
Chicago, Illinois, United States of America. (3)Section of Genetic Medicine,
Department of Medicine, University of Chicago, Chicago, Illinois, United States
of America. (4)Center for Research Informatics, University of Chicago, Chicago,
Illinois, United States of America. (5)Division of Genetic Medicine, Vanderbilt
University, Nashville, Tennessee, United States of America.

Understanding the genetic architecture of gene expression traits is key to
elucidating the underlying mechanisms of complex traits. Here, for the first
time, we perform a systematic survey of the heritability and the distribution of 
effect sizes across all representative tissues in the human body. We find that
local h2 can be relatively well characterized with 59% of expressed genes showing
significant h2 (FDR < 0.1) in the DGN whole blood cohort. However, current sample
sizes (n ≤ 922) do not allow us to compute distal h2. Bayesian Sparse Linear
Mixed Model (BSLMM) analysis provides strong evidence that the genetic
contribution to local expression traits is dominated by a handful of genetic
variants rather than by the collective contribution of a large number of variants
each of modest size. In other words, the local architecture of gene expression
traits is sparse rather than polygenic across all 40 tissues (from DGN and GTEx) 
examined. This result is confirmed by the sparsity of optimal performing gene
expression predictors via elastic net modeling. To further explore the tissue
context specificity, we decompose the expression traits into cross-tissue and
tissue-specific components using a novel Orthogonal Tissue Decomposition (OTD)
approach. Through a series of simulations we show that the cross-tissue and
tissue-specific components are identifiable via OTD. Heritability and sparsity
estimates of these derived expression phenotypes show similar characteristics to 
the original traits. Consistent properties relative to prior GTEx multi-tissue
analysis results suggest that these traits reflect the expected biology. Finally,
we apply this knowledge to develop prediction models of gene expression traits
for all tissues. The prediction models, heritability, and prediction performance 
R2 for original and decomposed expression phenotypes are made publicly available 
(https://github.com/hakyimlab/PrediXcan).

DOI: 10.1371/journal.pgen.1006423 
PMCID: PMC5106030
PMID: 27835642  [PubMed - in process]


173. BMC Genomics. 2016 Nov 9;17(1):899.

CASTIN: a system for comprehensive analysis of cancer-stromal interactome.

Komura D(1), Isagawa T(1), Kishi K(1,)(2), Suzuki R(1,)(3), Sato R(1), Tanaka
M(4), Katoh H(1), Yamamoto S(5), Tatsuno K(5), Fukayama M(4), Aburatani H(5),
Ishikawa S(6).

Author information: 
(1)Department of Genomic Pathology, Medical Research Institute, Tokyo Medical and
Dental University, Tokyo, Japan. (2)Graduate School of Interdisciplinary
Information Studies, The University of Tokyo, Tokyo, Japan. (3)Graduate School of
Information and Science and Technology, The University of Tokyo, Tokyo, Japan.
(4)Department of Pathology, Graduate School of Medicine, The University of Tokyo,
Tokyo, Japan. (5)Genome Science Division, Research Center for Advanced Science
and Technology, The University of Tokyo, Tokyo, Japan. (6)Department of Genomic
Pathology, Medical Research Institute, Tokyo Medical and Dental University,
Tokyo, Japan. sish.gpat@mri.tmd.ac.jp.

BACKGROUND: Cancer microenvironment plays a vital role in cancer development and 
progression, and cancer-stromal interactions have been recognized as important
targets for cancer therapy. However, identifying relevant and druggable
cancer-stromal interactions is challenging due to the lack of quantitative
methods to analyze whole cancer-stromal interactome.
RESULTS: We present CASTIN (CAncer-STromal INteractome analysis), a novel
framework for the evaluation of cancer-stromal interactome from RNA-Seq data
using cancer xenograft models. For each ligand-receptor interaction which is
derived from curated protein-protein interaction database, CASTIN summarizes gene
expression profiles of cancer and stroma into three evaluation indices. These
indices provide quantitative evaluation and comprehensive visualization of
interactome, and thus enable to identify critical cancer-microenvironment
interactions, which would be potential drug targets. We applied CASTIN to the
dataset of pancreas ductal adenocarcinoma, and successfully characterized the
individual cancer in terms of cancer-stromal relationships, and identified both
well-known and less-characterized druggable interactions.
CONCLUSIONS: CASTIN provides comprehensive view of cancer-stromal interactome and
is useful to identify critical interactions which may serve as potential drug
targets in cancer-microenvironment. CASTIN is available at:
http://github.com/tmd-gpat/CASTIN .

DOI: 10.1186/s12864-016-3207-z 
PMCID: PMC5103609
PMID: 27829362  [PubMed - in process]


174. BMC Bioinformatics. 2016 Nov 10;17(1):453.

Disease gene prioritization by integrating tissue-specific molecular networks
using a robust multi-network model.

Ni J(1), Koyuturk M(1), Tong H(2), Haines J(3), Xu R(3), Zhang X(4).

Author information: 
(1)Department of Electrical Engineering and Computer Science, Case Western
Reserve University, 10900 Euclid Avenue, Cleveland, 44106, OH, USA. (2)School of 
Computing, Informatics, Decision Systems Engineering, Arizona State University,
699 S. Mill Ave., Tempe, 85281, AZ, USA. (3)Department of Epidemiology and
Biostatistics, Case Western Reserve University, 10900 Euclid Avenue, Cleveland,
44106, OH, USA. (4)College of Information Sciences and Technology, Pennsylvania
State University, 332 Information Sciences and Technology Building, University
Park, 16802, PA, USA. xzhang@ist.psu.edu.

BACKGROUND: Accurately prioritizing candidate disease genes is an important and
challenging problem. Various network-based methods have been developed to predict
potential disease genes by utilizing the disease similarity network and molecular
networks such as protein interaction or gene co-expression networks. Although
successful, a common limitation of the existing methods is that they assume all
diseases share the same molecular network and a single generic molecular network 
is used to predict candidate genes for all diseases. However, different diseases 
tend to manifest in different tissues, and the molecular networks in different
tissues are usually different. An ideal method should be able to incorporate
tissue-specific molecular networks for different diseases.
RESULTS: In this paper, we develop a robust and flexible method to integrate
tissue-specific molecular networks for disease gene prioritization. Our method
allows each disease to have its own tissue-specific network(s). We formulate the 
problem of candidate gene prioritization as an optimization problem based on
network propagation. When there are multiple tissue-specific networks available
for a disease, our method can automatically infer the relative importance of each
tissue-specific network. Thus it is robust to the noisy and incomplete network
data. To solve the optimization problem, we develop fast algorithms which have
linear time complexities in the number of nodes in the molecular networks. We
also provide rigorous theoretical foundations for our algorithms in terms of
their optimality and convergence properties. Extensive experimental results show 
that our method can significantly improve the accuracy of candidate gene
prioritization compared with the state-of-the-art methods.
CONCLUSIONS: In our experiments, we compare our methods with 7 popular
network-based disease gene prioritization algorithms on diseases from Online
Mendelian Inheritance in Man (OMIM) database. The experimental results
demonstrate that our methods recover true associations more accurately than other
methods in terms of AUC values, and the performance differences are significant
(with paired t-test p-values less than 0.05). This validates the importance to
integrate tissue-specific molecular networks for studying disease gene
prioritization and show the superiority of our network models and ranking
algorithms toward this purpose. The source code and datasets are available at
http://nijingchao.github.io/CRstar/ .

DOI: 10.1186/s12859-016-1317-x 
PMCID: PMC5103411
PMID: 27829360  [PubMed - in process]


175. Curr Protein Pept Sci. 2016 Nov 7. [Epub ahead of print]

Identifying drug-target interactions with decision template.

Yan XY, Zhang SW(1).

Author information: 
(1)Key Laboratory of Information Fusion Technology of Ministry of Education,
School of Automation, Northwestern Polytechnical University, Xi'an, 710072,
China.

During the development process of new drugs, identification of the drug-target
interactions wins primary concerns. However, the chemical or biological
experiments bear the limitation in coverage as well as the huge cost of both time
and money. Based on drug similarity and target similarity, chemogenomic methods
can be able to predict potential drug-target interactions (DTIs) on a large scale
and have no luxurious need about target structures or ligand entries.
Nevertheless, existing methods of drug chemical structure-based similarity and
target sequence-based similarity may not reflect the cases that the drugs having 
variant structures interact with common targets and the targets having dissimilar
sequences interact with same drugs. In addition, though several other similarity 
metrics have been developed to predict DTIs, the combination of multiple
similarity metrics (especially heterogeneous similarities) is too naïve to
sufficiently explore the multiple similarities. In this paper, based on Gene
Ontology and pathway annotation, we introduce two novel target similarity metrics
to address above issues. More importantly, we propose a more effective strategy
via decision template to integrate multiple classifiers designed with multiple
similarity metrics. In the scenarios that predict existing targets for new drugs 
and predict approved drugs for new protein targets, the results on the DTI
benchmark datasets show that our target similarity metrics are able to enhance
the predictive accuracies in two scenarios, and the elaborate fusion strategy of 
multiple classifiers has better predictive power than the naïve combination of
multiple similarity metrics. Compared with other two state-of-the-art approaches 
on the four popular benchmark datasets of binary drug-target interactions, our
method achieves the best results in terms of AUC and AUPR for predicting
available targets for new drugs (S2), and predicting approved drugs for new
protein targets (S3). These results demonstrate that our method can effectively
predict the drug-target interactions. The software package can freely available
at https://github.com/NwpuSY/DT_all.git for academic users.


PMID: 27829344  [PubMed - as supplied by publisher]


176. mSystems. 2016 Oct 18;1(5). pii: e00062-16.

mockrobiota: a Public Resource for Microbiome Bioinformatics Benchmarking.

Bokulich NA(1), Rideout JR(1), Mercurio WG(1), Shiffer A(1), Wolfe B(2), Maurice 
CF(3), Dutton RJ(4), Turnbaugh PJ(5), Knight R(6), Caporaso JG(7).

Author information: 
(1)Center for Microbial Genetics and Genomics, Northern Arizona University,
Flagstaff, Arizona, USA. (2)Department of Biology, Tufts University, Medford,
Massachusetts, USA. (3)Department of Microbiology & Immunology Department,
Microbiome and Disease Tolerance Centre, McGill University, Montreal, Quebec,
Canada. (4)Division of Biological Sciences, University of California San Diego,
La Jolla, California, USA. (5)Department of Microbiology and Immunology, GW
Hooper Foundation, University of California, San Francisco, San Francisco,
California, USA. (6)Department of Computer Science and Engineering, University of
California San Diego, La Jolla, California, USA; Department of Pediatrics,
University of California San Diego, La Jolla, California, USA; Center for
Microbiome Innovation, University of California San Diego, La Jolla, California, 
USA. (7)Center for Microbial Genetics and Genomics, Northern Arizona University, 
Flagstaff, Arizona, USA; Department of Biological Sciences, Northern Arizona
University, Flagstaff, Arizona, USA.

Mock communities are an important tool for validating, optimizing, and comparing 
bioinformatics methods for microbial community analysis. We present mockrobiota, 
a public resource for sharing, validating, and documenting mock community data
resources, available at http://caporaso-lab.github.io/mockrobiota/. The materials
contained in mockrobiota include data set and sample metadata, expected
composition data (taxonomy or gene annotations or reference sequences for mock
community members), and links to raw data (e.g., raw sequence data) for each mock
community data set. mockrobiota does not supply physical sample materials
directly, but the data set metadata included for each mock community indicate
whether physical sample materials are available. At the time of this writing,
mockrobiota contains 11 mock community data sets with known species compositions,
including bacterial, archaeal, and eukaryotic mock communities, analyzed by
high-throughput marker gene sequencing. IMPORTANCE The availability of standard
and public mock community data will facilitate ongoing method optimizations,
comparisons across studies that share source data, and greater transparency and
access and eliminate redundancy. These are also valuable resources for
bioinformatics teaching and training. This dynamic resource is intended to expand
and evolve to meet the changing needs of the omics community.

DOI: 10.1128/mSystems.00062-16 
PMCID: PMC5080401
PMID: 27822553  [PubMed - in process]


177. mSystems. 2016 Jun 7;1(3). pii: e00020-16.

MetaPalette: a k-mer Painting Approach for Metagenomic Taxonomic Profiling and
Quantification of Novel Strain Variation.

Koslicki D(1), Falush D(2).

Author information: 
(1)Mathematics Department, Oregon State University, Corvallis, Oregon, USA.
(2)Institute of Life Sciences, University of Swansea, Singleton Park, Swansea,
United Kingdom.

Metagenomic profiling is challenging in part because of the highly uneven
sampling of the tree of life by genome sequencing projects and the limitations
imposed by performing phylogenetic inference at fixed taxonomic ranks. We present
the algorithm MetaPalette, which uses long k-mer sizes (k = 30, 50) to fit a
k-mer "palette" of a given sample to the k-mer palette of reference organisms. By
modeling the k-mer palettes of unknown organisms, the method also gives an
indication of the presence, abundance, and evolutionary relatedness of novel
organisms present in the sample. The method returns a traditional, fixed-rank
taxonomic profile which is shown on independently simulated data to be one of the
most accurate to date. Tree figures are also returned that quantify the
relatedness of novel organisms to reference sequences, and the accuracy of such
figures is demonstrated on simulated spike-ins and a metagenomic soil sample. The
software implementing MetaPalette is available at:
https://github.com/dkoslicki/MetaPalette. Pretrained databases are included for
Archaea, Bacteria, Eukaryota, and viruses. IMPORTANCE Taxonomic profiling is a
challenging first step when analyzing a metagenomic sample. This work presents a 
method that facilitates fine-scale characterization of the presence, abundance,
and evolutionary relatedness of organisms present in a given sample but absent
from the training database. We calculate a "k-mer palette" which summarizes the
information from all reads, not just those in conserved genes or containing
taxon-specific markers. The compositions of palettes are easy to model, allowing 
rapid inference of community composition. In addition to providing strain-level
information where applicable, our approach provides taxonomic profiles that are
more accurate than those of competing methods. Author Video: An author video
summary of this article is available.

DOI: 10.1128/mSystems.00020-16 
PMCID: PMC5069763
PMID: 27822531  [PubMed - in process]


178. BMC Genomics. 2016 Nov 7;17(1):880.

Visualizing tumor evolution with the fishplot package for R.

Miller CA(1,)(2), McMichael J(3), Dang HX(3,)(4), Maher CA(3,)(4), Ding L(3,)(4),
Ley TJ(3,)(4), Mardis ER(3,)(4,)(5), Wilson RK(3,)(6,)(4,)(5).

Author information: 
(1)McDonnell Genome Institute, Washington University School of Medicine, St.
Louis, MO, 63108, USA. c.a.miller@wustl.edu. (2)Department of Medicine, Division 
of Genomics and Bioinformatics, Washington University School of Medicine, St.
Louis, MO, 63108, USA. c.a.miller@wustl.edu. (3)McDonnell Genome Institute,
Washington University School of Medicine, St. Louis, MO, 63108, USA.
(4)Department of Medicine, Division of Oncology, Washington University School of 
Medicine, St. Louis, MO, 63108, USA. (5)Department of Genetics, Washington
University School of Medicine, St. Louis, MO, 63108, USA. (6)Department of
Medicine, Division of Genomics and Bioinformatics, Washington University School
of Medicine, St. Louis, MO, 63108, USA.

BACKGROUND: Massively-parallel sequencing at depth is now enabling tumor
heterogeneity and evolution to be characterized in unprecedented detail. Tracking
these changes in clonal architecture often provides insight into therapeutic
response and resistance. In complex cases involving multiple timepoints, standard
visualizations, such as scatterplots, can be difficult to interpret. Current data
visualization methods are also typically manual and laborious, and often only
approximate subclonal fractions.
RESULTS: We have developed an R package that accurately and intuitively displays 
changes in clonal structure over time. It requires simple input data and produces
illustrative and easy-to-interpret graphs suitable for diagnosis, presentation,
and publication.
CONCLUSIONS: The simplicity, power, and flexibility of this tool make it valuable
for visualizing tumor evolution, and it has potential utility in both research
and clinical settings. The fishplot package is available at
https://github.com/chrisamiller/fishplot .

DOI: 10.1186/s12864-016-3195-z 
PMCID: PMC5100182
PMID: 27821060  [PubMed - in process]


179. J Theor Biol. 2017 Jan 7;412:138-145. doi: 10.1016/j.jtbi.2016.10.013. Epub 2016 
Nov 2.

Identification of repeats in DNA sequences using nucleotide distribution
uniformity.

Yin C(1).

Author information: 
(1)Department of Mathematics, Statistics and Computer Science, The University of 
Illinois at Chicago, Chicago, IL 60607-7045, USA. Electronic address:
cyin1@uic.edu.

Repetitive elements are important in genomic structures, functions and
regulations, yet effective methods in precisely identifying repetitive elements
in DNA sequences are not fully accessible, and the relationship between
repetitive elements and periodicities of genomes is not clearly understood. We
present an ab initio method to quantitatively detect repetitive elements and
infer the consensus repeat pattern in repetitive elements. The method uses the
measure of the distribution uniformity of nucleotides at periodic positions in
DNA sequences or genomes. It can identify periodicities, consensus repeat
patterns, copy numbers and perfect levels of repetitive elements. The results of 
using the method on different DNA sequences and genomes demonstrate efficacy and 
accuracy in identifying repeat patterns and periodicities. The complexity of the 
method is linear with respect to the lengths of the analyzed sequences. The
Python programs in this study are freely available to the public upon request or 
at https://github.com/cyinbox/DNADU.

Copyright © 2016 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.jtbi.2016.10.013 
PMID: 27816675  [PubMed - in process]


180. BMC Genomics. 2016 Nov 4;17(1):873.

Q-nexus: a comprehensive and efficient analysis pipeline designed for ChIP-nexus.

Hansen P(1,)(2), Hecht J(3,)(4), Ibn-Salem J(5,)(6), Menkuec BS(1), Roskosch
S(7), Truss M(8), Robinson PN(9,)(10,)(11,)(12,)(13).

Author information: 
(1)Institute for Medical and Human Genetics, Charité-Universitätsmedizin Berlin, 
Augustenburger Platz 1, Berlin, 13353, Germany. (2)Berlin Brandenburg Center for 
Regenerative Therapies (BCRT), Charité-Universitätsmedizin Berlin, Augustenburger
Platz 1, Berlin, 13353, Germany. (3)Centre for Genomic Regulation (CRG), The
Barcelona Institute of Science and Technology, Dr. Aiguader 88, Barcelona, 08003,
Spain. (4)Universitat Pompeu Fabra (UPF), Barcelona, Spain. (5)Faculty of
Biology, Johannes Gutenberg University Mainz, Ackermannweg 4, Mainz, 55128,
Germany. (6)Institute of Molecular Biology, Ackermannweg 4, Mainz, 55128,
Germany. (7)Institute for Bioinformatics, Department of Mathematics and Computer 
Science, Freie Universität Berlin, Arnimallee 14, Berlin, 14195, Germany.
(8)Labor für Pädiatrische Molekularbiologie, Charité-Universitätsmedizin Berlin, 
Augustenburger Platz 1, Berlin, 13353, Germany. (9)Institute for Medical and
Human Genetics, Charité-Universitätsmedizin Berlin, Augustenburger Platz 1,
Berlin, 13353, Germany. peter.robinson@jax.org. (10)Berlin Brandenburg Center for
Regenerative Therapies (BCRT), Charité-Universitätsmedizin Berlin, Augustenburger
Platz 1, Berlin, 13353, Germany. peter.robinson@jax.org. (11)Institute for
Bioinformatics, Department of Mathematics and Computer Science, Freie Universität
Berlin, Arnimallee 14, Berlin, 14195, Germany. peter.robinson@jax.org. (12)Max
Planck Institute for Molecular Genetics, Inhestr. 63-73, Berlin, 14195, Germany. 
peter.robinson@jax.org. (13)Current address: The Jackson Laboratory for Genomic
Medicine, 10 Discovery Drive, Farmington, 06032, CT, USA. peter.robinson@jax.org.

BACKGROUND: ChIP-nexus, an extension of the ChIP-exo protocol, can be used to map
the borders of protein-bound DNA sequences at nucleotide resolution, requires
less input DNA and enables selective PCR duplicate removal using random barcodes.
However, the use of random barcodes requires additional preprocessing of the
mapping data, which complicates the computational analysis. To date, only a very 
limited number of software packages are available for the analysis of ChIP-exo
data, which have not yet been systematically tested and compared on ChIP-nexus
data.
RESULTS: Here, we present a comprehensive software package for ChIP-nexus data
that exploits the random barcodes for selective removal of PCR duplicates and for
quality control. Furthermore, we developed bespoke methods to estimate the width 
of the protected region resulting from protein-DNA binding and to infer binding
positions from ChIP-nexus data. Finally, we applied our peak calling method as
well as the two other methods MACE and MACS2 to the available ChIP-nexus data.
CONCLUSIONS: The Q-nexus software is efficient and easy to use. Novel statistics 
about duplication rates in consideration of random barcodes are calculated. Our
method for the estimation of the width of the protected region yields unbiased
signatures that are highly reproducible for biological replicates and at the same
time very specific for the respective factors analyzed. As judged by the
irreproducible discovery rate (IDR), our peak calling algorithm shows a
substantially better reproducibility. An implementation of Q-nexus is available
at http://charite.github.io/Q/ .

DOI: 10.1186/s12864-016-3164-6 
PMCID: PMC5097360
PMID: 27814676  [PubMed - in process]


181. PeerJ. 2016 Oct 27;4:e2619. eCollection 2016.

The PARA-suite: PAR-CLIP specific sequence read simulation and processing.

Kloetgen A(1), Borkhardt A(2), Hoell JI(2), McHardy AC(3).

Author information: 
(1)Department for Algorithmic Bioinformatics, Heinrich-Heine Universität
Düsseldorf, Düsseldorf, Germany; Department of Pediatric Oncology, Hematology and
Clinical Immunology, Medical Faculty, Heinrich-Heine Universität Düsseldorf,
Düsseldorf, Germany; Computational Biology of Infection Research, Helmholtz
Center for Infection Research, Braunschweig, Germany. (2)Department of Pediatric 
Oncology, Hematology and Clinical Immunology, Medical Faculty, Heinrich-Heine
Universität Düsseldorf , Düsseldorf , Germany. (3)Department for Algorithmic
Bioinformatics, Heinrich-Heine Universität Düsseldorf, Düsseldorf, Germany;
Computational Biology of Infection Research, Helmholtz Center for Infection
Research, Braunschweig, Germany.

BACKGROUND: Next-generation sequencing technologies have profoundly impacted
biology over recent years. Experimental protocols, such as photoactivatable
ribonucleoside-enhanced cross-linking and immunoprecipitation (PAR-CLIP), which
identifies protein-RNA interactions on a genome-wide scale, commonly employ deep 
sequencing. With PAR-CLIP, the incorporation of photoactivatable nucleosides into
nascent transcripts leads to high rates of specific nucleotide conversions during
reverse transcription. So far, the specific properties of PAR-CLIP-derived
sequencing reads have not been assessed in depth.
METHODS: We here compared PAR-CLIP sequencing reads to regular transcriptome
sequencing reads (RNA-Seq) to identify distinctive properties that are relevant
for reference-based read alignment of PAR-CLIP datasets. We developed a set of
freely available tools for PAR-CLIP data analysis, called the PAR-CLIP analyzer
suite (PARA-suite). The PARA-suite includes error model inference, PAR-CLIP read 
simulation based on PAR-CLIP specific properties, a full read alignment pipeline 
with a modified Burrows-Wheeler Aligner algorithm and CLIP read clustering for
binding site detection.
RESULTS: We show that differences in the error profiles of PAR-CLIP reads
relative to regular transcriptome sequencing reads (RNA-Seq) make a distinct
processing advantageous. We examine the alignment accuracy of commonly applied
read aligners on 10 simulated PAR-CLIP datasets using different parameter
settings and identified the most accurate setup among those read aligners. We
demonstrate the performance of the PARA-suite in conjunction with different
binding site detection algorithms on several real PAR-CLIP and HITS-CLIP
datasets. Our processing pipeline allowed the improvement of both alignment and
binding site detection accuracy.
AVAILABILITY: The PARA-suite toolkit and the PARA-suite aligner are available at 
https://github.com/akloetgen/PARA-suite and
https://github.com/akloetgen/PARA-suite_aligner, respectively, under the GNU
GPLv3 license.

DOI: 10.7717/peerj.2619 
PMCID: PMC5088580
PMID: 27812418  [PubMed - in process]


182. BMC Genomics. 2016 Nov 2;17(1):847.

In silico region of difference (RD) analysis of Mycobacterium tuberculosis
complex from sequence reads using RD-Analyzer.

Faksri K(1,)(2), Xia E(3), Tan JH(4), Teo YY(3,)(4,)(5,)(6,)(7), Ong RT(8).

Author information: 
(1)Department of Microbiology Faculty of Medicine, Khon Kaen University, Khon
Kaen, Thailand. (2)Research and Diagnostic Center for Emerging Infectious
Diseases (RCEID), Khon Kaen University, Khon Kaen, Thailand. (3)NUS Graduate
School for Integrative Sciences and Engineering, National University of
Singapore, Singapore, Singapore. (4)Saw Swee Hock School of Public Health,
National University of Singapore, Tahir Foundation Building, 12 Science Drive 2, 
#10-01, Singapore, 117549, Singapore. (5)Department of Statistics and Applied
Probability, National University of Singapore, Singapore, Singapore. (6)Life
Sciences Institute, National University of Singapore, Singapore, Singapore.
(7)Genome Institute of Singapore, Singapore, Singapore. (8)Saw Swee Hock School
of Public Health, National University of Singapore, Tahir Foundation Building, 12
Science Drive 2, #10-01, Singapore, 117549, Singapore. twee_hee_ong@nuhs.edu.sg.

BACKGROUND: Whole-genome sequencing is increasingly used in clinical diagnosis of
tuberculosis and study of Mycobacterium tuberculosis complex (MTC). MTC consists 
of several genetically homogenous mycobacteria species which can cause
tuberculosis in humans and animals. Regions of difference (RDs) are commonly
regarded as gold standard genetic markers for MTC classification.
RESULTS: We develop RD-Analyzer, a tool that can accurately infer the species and
lineage of MTC isolates from sequence reads based on the presence and absence of 
a set of 31 RDs. Applied on a publicly available diverse set of 377 sequenced MTC
isolates from known major species and lineages, RD-Analyzer achieved an accuracy 
of 98.14 % (370/377) in species prediction and a concordance of 98.47 % (257/261)
in Mycobacterium tuberculosis lineage prediction compared to predictions based on
single nucleotide polymorphism markers. By comparing respective sequencing read
depths on each genomic position between isolates of different sublineages, we
were able to identify the known RD markers in different sublineages of Lineage 4 
and provide support for six potential delineating markers having high
sensitivities and specificities for sublineage prediction. An extended version of
RD-Analyzer was thus developed to allow user-defined RDs for lineage prediction.
CONCLUSIONS: RD-Analyzer is a useful and accurate tool for species, lineage and
sublineage prediction using known RDs of MTC from sequence reads and is
extendable to accepting user-defined RDs for analysis. RD-Analyzer is written in 
Python and is freely available at https://github.com/xiaeryu/RD-Analyzer .

DOI: 10.1186/s12864-016-3213-1 
PMCID: PMC5093977
PMID: 27806686  [PubMed - in process]


183. J Bioinform Comput Biol. 2016 Oct;14(5):1644003.

KDSNP: A kernel-based approach to detecting high-order SNP interactions.

Kodama K(1), Saigo H(1).

Author information: 
(1)1 Department of Bioscience and Bioinformatics, Kyushu Institute of Technology,
680-4 Kawazu, Iizuka 820-8502, Fukuoka, Japan.

Despite the accumulation of quantitative trait loci (QTL) data in many complex
human diseases, most of current approaches that have attempted to relate genotype
to phenotype have achieved limited success, and genetic factors of many common
diseases are yet remained to be elucidated. One of the reasons that makes this
problem complex is the existence of single nucleotide polymorphism (SNP)
interaction, or epistasis. Due to excessive amount of computation for searching
the combinatorial space, existing approaches cannot fully incorporate high-order 
SNP interactions into their models, but limit themselves to detecting only
lower-order SNP interactions. We present an empirical approach based on ridge
regression with polynomial kernels and model selection technique for determining 
the true degree of epistasis among SNPs. Computer experiments in simulated data
show the ability of the proposed method to correctly predict the number of
interacting SNPs provided that the number of samples is large enough relative to 
the number of SNPs. For cases in which the number of the available samples is
limited, we propose to perform sliding window approach to ensure sufficiently
large sample/SNP ratio in each window. In computational experiments using
heterogeneous stock mice data, our approach has successfully detected subregions 
that harbor known causal SNPs. Our analysis further suggests the existence of
additional candidate causal SNPs interacting to each other in the neighborhood of
the known causal gene. Software is available from
https://github.com/HirotoSaigo/KDSNP .

DOI: 10.1142/S0219720016440030 
PMID: 27806683  [PubMed - in process]


184. Bioinformatics. 2016 Oct 22. pii: btw619. [Epub ahead of print]

Uncertainty estimation of predictions of peptides' chromatographic retention
times in shotgun proteomics.

Maboudi Afkham H(1), Qiu X(1), The M(1), Käll L(1).

Author information: 
(1)Science for Life Laboratory, School of Biotechnology, KTH - Royal Institute of
Technology, 17121 Solna, Sweden.

MOTIVATION: Liquid chromatography is frequently used as a means to reduce the
complexity of peptide-mixtures in shotgun proteomics. For such systems, the time 
when a peptide is released from a chromatography column and registered in the
mass spectrometer is referred to as the peptide's retention time Using heuristics
or machine learning techniques, previous studies have demonstrated that it is
possible to predict the retention time of a peptide from its amino acid sequence.
In this paper, we are applying Gaussian Process Regression to the feature
representation of a previously described predictor Elude Using this framework, we
demonstrate that it is possible to estimate the uncertainty of the prediction
made by the model. Here we show how this uncertainty relates to the actual error 
of the prediction.
RESULTS: In our experiments, we observe a strong correlation between the
estimated uncertainty provided by Gaussian Process Regression and the actual
prediction error. This relation provides us with new means for assessment of the 
predictions. We demonstrate how a subset of the peptides can be selected with
lower prediction error compared to the whole set. We also demonstrate how such
predicted standard deviations can be used for designing adaptive windowing
strategies.
CONTACT: lukas.kall@scilifelab.seAvailability and Implementation: Our software
and the data used in our experiments is publicly available and can be downloaded 
from https://github.com/statisticalbiotechnology/GPTime.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw619 
PMID: 27797755  [PubMed - as supplied by publisher]


185. Biom J. 2016 Nov;58(6):1376-1389. doi: 10.1002/bimj.201500098. Epub 2016 May 25.

Bayesian model selection in logistic regression for the detection of adverse drug
reactions.

Marbac M(1), Tubert-Bitter P(1), Sedki M(2,)(3).

Author information: 
(1)Inserm, UMR 1181 B2PHI, Institut-Pasteur and Université Versailles St-Quentin,
France. (2)Inserm, UMR 1181 B2PHI, Institut-Pasteur and Université Versailles
St-Quentin, France. mohammed.sedki@u-psud.fr. (3)Faculté de médecine, Université 
Paris-Sud, France. mohammed.sedki@u-psud.fr.

Spontaneous adverse event reports have a high potential for detecting adverse
drug reactions. However, due to their dimension, the analysis of such databases
requires statistical methods. In this context, disproportionality measures can be
used. Their main idea is to project the data onto contingency tables in order to 
measure the strength of associations between drugs and adverse events. However,
due to the data projection, these methods are sensitive to the problem of
coprescriptions and masking effects. Recently, logistic regressions have been
used with a Lasso type penalty to perform the detection of associations between
drugs and adverse events. On different examples, this approach limits the
drawbacks of the disproportionality methods, but the choice of the penalty value 
is open to criticism while it strongly influences the results. In this paper, we 
propose to use a logistic regression whose sparsity is viewed as a model
selection challenge. Since the model space is huge, a Metropolis-Hastings
algorithm carries out the model selection by maximizing the BIC criterion. Thus, 
we avoid the calibration of penalty or threshold. During our application on the
French pharmacovigilance database, the proposed method is compared to
well-established approaches on a reference dataset, and obtains better rates of
positive and negative controls. However, many signals (i.e., specific drug-event 
associations) are not detected by the proposed method. So, we conclude that this 
method should be used in parallel to existing measures in pharmacovigilance. Code
implementing the proposed method is available at the following url:
https://github.com/masedki/MHTrajectoryR.

© 2016 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim.

DOI: 10.1002/bimj.201500098 
PMID: 27225325  [PubMed - in process]


186. Mol Ecol Resour. 2017 Jan;17(1):96-100. doi: 10.1111/1755-0998.12630. Epub 2016
Nov 21.

phylodyn: an R package for phylodynamic simulation and inference.

Karcher MD(1), Palacios JA(2,)(3), Lan S(4), Minin VN(1,)(5).

Author information: 
(1)Department of Statistics, University of Washington, Seattle, WA, USA.
(2)Department of Statistics, Stanford University, Stanford, CA, USA.
(3)Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
(4)Department of Statistics, University of Warwick, Coventry, UK. (5)Department
of Biology, University of Washington, Seattle, WA, USA.

We introduce phylodyn, an r package for phylodynamic analysis based on gene
genealogies. The package's main functionality is Bayesian nonparametric
estimation of effective population size fluctuations over time. Our
implementation includes several Markov chain Monte Carlo-based methods and an
integrated nested Laplace approximation-based approach for phylodynamic inference
that have been developed in recent years. Genealogical data describe the timed
ancestral relationships of individuals sampled from a population of interest.
Here, individuals are assumed to be sampled at the same point in time
(isochronous sampling) or at different points in time (heterochronous sampling); 
in addition, sampling events can be modelled with preferential sampling, which
means that the intensity of sampling events is allowed to depend on the effective
population size trajectory. We assume the coalescent and the sequentially Markov 
coalescent processes as generative models of genealogies. We include several
coalescent simulation functions that are useful for testing our phylodynamics
methods via simulation studies. We compare the performance and outputs of various
methods implemented in phylodyn and outline their strengths and weaknesses. r
package phylodyn is available at https://github.com/mdkarcher/phylodyn.

© 2016 John Wiley & Sons Ltd.

DOI: 10.1111/1755-0998.12630 
PMID: 27801980  [PubMed - in process]


187. Bioinformatics. 2016 Oct 26. pii: btw684. doi: 10.1093/bioinformatics/btw684.
[Epub ahead of print]

BoostGAPFILL: improving the fidelity of metabolic network reconstructions through
integrated constraint and pattern-based methods.

Oyetunde T(1), Zhang M(2), Chen Y(2), Tang Y(1), Lo C(1).

Author information: 
(1)Department of Energy, Environmental and Chemical Engineering. (2)Department of
Computer Science and Engineering, Washington University, Saint Louis, MO 63130,
USA.

MOTIVATION: Metabolic network reconstructions are often incomplete.
Constraint-based and pattern-based methodologies have been used for automated gap
filling of these networks, each with its own strengths and weaknesses. Moreover, 
since validation of hypotheses made by gap filling tools require experimentation,
it is challenging to benchmark performance and make improvements other than that 
related to speed and scalability.
RESULTS: We present BoostGAPFILL, an open source tool that leverages both
constraint-based and machine learning methodologies for hypotheses generation in 
gap filling and metabolic model refinement. BoostGAPFILL uses metabolite patterns
in the incomplete network captured using a matrix factorization formulation to
constrain the set of reactions used to fill gaps in a metabolic network. We
formulate a testing framework based on the available metabolic reconstructions
and demonstrate the superiority of BoostGAPFILL to state-of-the-art gap filling
tools. We randomly delete a number of reactions from a metabolic network and rate
the different algorithms on their ability to both predict the deleted reactions
from a universal set and to fill gaps. For most metabolic network reconstructions
tested, BoostGAPFILL shows above 60% precision and recall, which is more than
twice that of other existing tools.
AVAILABILITY AND IMPLEMENTATION: MATLAB open source implementation
(https://github.com/Tolutola/BoostGAPFILL) CONTACTS: toyetunde@wustl.edu or
muhan@wustl.eduSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw684 
PMID: 27797784  [PubMed - as supplied by publisher]


188. Bioinformatics. 2016 Oct 26. pii: btw682. doi: 10.1093/bioinformatics/btw682.
[Epub ahead of print]

PyBoolNet: a python package for the generation, analysis and visualization of
boolean networks.

Klarner H(1), Streck A(1), Siebert H(1).

Author information: 
(1)Institut für Mathematik, Freie Universität Berlin, 14195 Berlin, Germany.

MOTIVATION: The goal of this project is to provide a simple interface to working 
with Boolean networks. Emphasis is put on easy access to a large number of common
tasks including the generation and manipulation of networks, attractor and basin 
computation, model checking and trap space computation, execution of established 
graph algorithms as well as graph drawing and layouts.
RESULTS: PyBoolNet is a Python package for working with Boolean networks that
supports simple access to model checking via NuSMV, standard graph algorithms via
NetworkX and visualization via dot In addition, state of the art attractor
computation exploiting Potassco ASP is implemented. The package is function-based
and uses only native Python and NetworkX data types.
AVAILABILITY AND IMPLEMENTATION: https://github.com/hklarner/PyBoolNet CONTACT: :
hannes.klarner@fu-berlin.de.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw682 
PMID: 27797783  [PubMed - as supplied by publisher]


189. Bioinformatics. 2016 Oct 26. pii: btw679. [Epub ahead of print]

Big Data Smart Socket (BDSS): a system that abstracts data transfer habits from
end users.

Watts NA(1), Feltus FA(2).

Author information: 
(1)Clemson Computing & Information Technology. (2)Clemson University Department
of Genetics & Biochemistry, Clemson, SC 29634, USA.

MOTIVATION: The ability to centralize and store data for long periods on an end
user's computational resources is increasingly difficult for many scientific
disciplines. For example, genomics data is increasingly large and distributed,
and the data needs to be moved into workflow execution sites ranging from lab
workstations to the cloud. However, the typical user is not always informed on
emerging network technology or the most efficient methods to move and share data.
Thus, the user defaults to using inefficient methods for transfer across the
commercial internet.
RESULTS: To accelerate large data transfer, we created a tool called the Big Data
Smart Socket (BDSS) that abstracts data transfer methodology from the user. The
user provides BDSS with a manifest of datasets stored in a remote storage
repository. BDSS then queries a metadata repository for curated data transfer
mechanisms and optimal path to move each of the files in the manifest to the site
of workflow execution. BDSS functions as a standalone tool or can be directly
integrated into a computational workflow such as provided by the Galaxy Project. 
To demonstrate applicability, we use BDSS within a biological context, although
it is applicable to any scientific domain.
AVAILABILITY AND IMPLEMENTATION: BDSS is available under version 2 of the GNU
General Public License at https://github.com/feltus/BDSS CONTACT:
ffeltus@clemson.edu.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw679 
PMID: 27797780  [PubMed - as supplied by publisher]


190. Bioinformatics. 2016 Oct 24. pii: btw674. [Epub ahead of print]

INTEGRATE-neo: a pipeline for personalized gene fusion neoantigen discovery.

Zhang J(1,)(2,)(3), Mardis ER(1,)(3,)(4,)(5,)(6), Maher CA(1,)(2,)(3,)(7).

Author information: 
(1)McDonnell Genome Institute. (2)Department of Internal Medicine. (3)Siteman
Cancer Center. (4)Department of Molecular Microbiology. (5)Department of
Medicine. (6)Department of Genetics, Washington University School of Medicine,
St. Louis, MO 63110, USA. (7)Department of Biomedical Engineering, Washington
University in St. Louis, St. Louis, MO 63105, USA.

MOTIVATION: While high-throughput sequencing (HTS) has been used successfully to 
discover tumor-specific mutant peptides (neoantigens) from somatic missense
mutations, the field currently lacks a method for identifying which gene fusions 
may generate neoantigens.
RESULTS: We demonstrate the application of our gene fusion neoantigen discovery
pipeline, called INTEGRATE-Neo, by identifying gene fusions in prostate cancers
that may produce neoantigens.
AVAILABILITY AND IMPLEMENTATION: INTEGRATE-Neo is implemented in C ++ and Python.
Full source code and installation instructions are freely available from
https://github.com/ChrisMaherLab/INTEGRATE-Neo CONTACT:
christophermaher@wustl.eduSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw674 
PMID: 27797777  [PubMed - as supplied by publisher]


191. Bioinformatics. 2016 Oct 24. pii: btw672. doi: 10.1093/bioinformatics/btw672.
[Epub ahead of print]

Optimizing ChIP-seq peak detectors using visual labels and supervised machine
learning.

Hocking TD(1), Goerner-Potvin P(1), Morin A(1), Shao X(1), Pastinen T(1), Bourque
G(1).

Author information: 
(1)Department of Human Genetics, McGill University, H3A-1A4, Montréal, Canada.

MOTIVATION: Many peak detection algorithms have been proposed for ChIP-seq data
analysis, but it is not obvious which algorithm and what parameters are optimal
for any given dataset. In contrast, regions with and without obvious peaks can be
easily labeled by visual inspection of aligned read counts in a genome browser.
We propose a supervised machine learning approach for ChIP-seq data analysis,
using labels that encode qualitative judgments about which genomic regions
contain or do not contain peaks. The main idea is to manually label a small
subset of the genome, and then learn a model that makes consistent peak
predictions on the rest of the genome.
RESULTS: We created 7 new histone mark datasets with 12 826 visually determined
labels, and analyzed 3 existing transcription factor datasets. We observed that
default peak detection parameters yield high false positive rates, which can be
reduced by learning parameters using a relatively small training set of labeled
data from the same experiment type. We also observed that labels from different
people are highly consistent. Overall, these data indicate that our supervised
labeling method is useful for quantitatively training and testing peak detection 
algorithms.
AVAILABILITY AND IMPLEMENTATION: Labeled histone mark data
http://cbio.ensmp.fr/thocking/chip-seq-chunk-db/, R package to compute the label 
error of predicted peaks https://github.com/tdhock/PeakError CONTACTS:
toby.hocking@mail.mcgill.ca or guil.bourque@mcgill.caSupplementary information:
Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw672 
PMID: 27797775  [PubMed - as supplied by publisher]


192. Bioinformatics. 2016 Oct 22. pii: btw663. [Epub ahead of print]

KAT: a K-mer analysis toolkit to quality control NGS datasets and genome
assemblies.

Mapleson D(1), Garcia Accinelli G(1), Kettleborough G(1), Wright J(1), Clavijo
BJ(1).

Author information: 
(1)Earlham Institute, Norwich Research Park, Norwich, UK.

MOTIVATION: De novo assembly of whole genome shotgun (WGS) next-generation
sequencing (NGS) data benefits from high-quality input with high coverage.
However, in practice, determining the quality and quantity of useful reads
quickly and in a reference-free manner is not trivial. Gaining a better
understanding of the WGS data, and how that data is utilized by assemblers,
provides useful insights that can inform the assembly process and result in
better assemblies.
RESULTS: We present the K-mer Analysis Toolkit (KAT): a multi-purpose software
toolkit for reference-free quality control (QC) of WGS reads and de novo genome
assemblies, primarily via their k-mer frequencies and GC composition. KAT enables
users to assess levels of errors, bias and contamination at various stages of the
assembly process. In this paper we highlight KAT's ability to provide valuable
insights into assembly composition and quality of genome assemblies through
pairwise comparison of k-mers present in both input reads and the assemblies.
AVAILABILITY AND IMPLEMENTATION: KAT is available under the GPLv3 license at:
https://github.com/TGAC/KAT CONTACT: bernardo.clavijo@earlham.ac.ukSupplementary 
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw663 
PMID: 27797770  [PubMed - as supplied by publisher]


193. Bioinformatics. 2016 Oct 22. pii: btw658. [Epub ahead of print]

yMap: An automated method to map yeast variants to protein modifications and
functional regions.

Arslan A(1), van Noort V(2).

Author information: 
(1)KU Leuven, Centre for Microbial and Plants Genetics (CMPG), Kasteelpark
Arenberg 22 - box 2460, 3001, Leuven, Belgium. (2)KU Leuven, Centre for Microbial
and Plants Genetics (CMPG), Kasteelpark Arenberg 22 - box 2460, 3001, Leuven,
Belgium. vera.vannoort@biw.kuleuven.be.

Recent advances in sequence technology result in large datasets of sequence
variants. For the human genome, several tools are available to predict the impact
of these variants on gene and protein functions. However, for model organisms
such as yeast such tools are lacking, specifically to predict the effect of
protein sequence altering variants on the protein level. We present a python
framework that enables users to map in a fully automated fashion large set of
variants to protein functional regions and post-translationally modified
residues. Furthermore, we provide the user with the possibility to retrieve
predicted functional information on modified residues from other resources for
example that are predicted to play a role in protein-protein interactions. The
results are complemented by statistical tests to highlight the significance of
underlying functions and pathways affected by mutations. We show the application 
of this package on a yeast dataset derived from a recent evolutionary experiment 
on adaptation to ethanol.AVAILABILITY: The package is available from
https://github.com/CSB-KUL/yMap and is implemented in Python.
CONTACT: vera.vannoort@biw.kuleuven.be SUPPLEMENTARY INFORMATION: Supplementary
data are available at Bioinformatics online.

© The Author(s) 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw658 
PMID: 27797766  [PubMed - as supplied by publisher]


194. Bioinformatics. 2016 Oct 22. pii: btw654. [Epub ahead of print]

Rabifier2: an improved bioinformatic classifier of Rab GTPases.

Surkont J(1), Diekmann Y(1), Pereira-Leal JB(1).

Author information: 
(1)Instituto Gulbenkian de Ciência, 2780-156 Oeiras, Portugal.

The Rab family of small GTPases regulates and provides specificity to the
endomembrane trafficking system; each Rab subfamily is associated with specific
pathways. Thus, characterization of Rab repertoires provides functional
information about organisms and evolution of the eukaryotic cell. Yet, the
complex structure of the Rab family limits the application of existing methods
for protein classification. Here, we present a major redesign of the Rabifier, a 
bioinformatic pipeline for detection and classification of Rab GTPases. It is
more accurate, significantly faster than the original version and is now open
source, both the code and the data, allowing for community
participation.AVAILABILITY AND IMPLEMENTATION: Rabifier and RabDB are freely
available through the web at http://rabdb.org The Rabifier package can be
downloaded from the Python Package Index at
https://pypi.python.org/pypi/rabifier, the source code is available at Github
https://github.com/evocell/rabifier CONTACT: jsurkont@igc.gulbenkian.pt or
jleal@igc.gulbenkian.ptSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw654 
PMID: 27797763  [PubMed - as supplied by publisher]


195. Bioinformatics. 2016 Oct 25. pii: btw652. [Epub ahead of print]

Isomorphic semantic mapping of variant call format (VCF2RDF).

Penha ED(1), Iriabho E(1), Dussaq A(1), de Oliveira DM(2), Almeida JS(3).

Author information: 
(1)Department of Pathology, Informatics Division, University of Alabama at
Birmingham, Birmingham, AL 35233, USA. (2)Rede Nordeste de Biotecnologia,
Universidade Estadual do Ceará, Fortaleza CE 60740-000, Brazil. (3)Department of 
Biomedical Informatics, Stony Brook University, Stony Brook, NY 11794, USA.

The move of computational genomics workflows to Cloud Computing platforms is
associated with a new level of integration and interoperability that challenges
existing data representation formats. The Variant Calling Format (VCF) is in a
particularly sensitive position in that regard, with both clinical and
consumer-facing analysis tools relying on this self-contained description of
genomic variation in Next Generation Sequencing (NGS) results. In this report we 
identify an isomorphic map between VCF and the reference Resource Description
Framework. RDF is advanced by the World Wide Web Consortium (W3C) to enable
representations of linked data that are both distributed and discoverable. The
resulting ability to decompose VCF reports of genomic variation without loss of
context addresses the need to modularize and govern NGS pipelines for Precision
Medicine. Specifically, it provides the flexibility (i.e. the indexing) needed to
support the wide variety of clinical scenarios and patient-facing governance
where only part of the VCF data is fitting.AVAILABILITY AND IMPLEMENTATION:
Software libraries with a claim to be both domain-facing and consumer-facing have
to pass the test of portability across the variety of devices that those
consumers in fact adopt. That is, ideally the implementation should itself take
place within the space defined by web technologies. Consequently, the isomorphic 
mapping function was implemented in JavaScript, and was tested in a variety of
environments and devices, client and server side alike. These range from web
browsers in mobile phones to the most popular micro service platform, NodeJS. The
code is publicly available at https://github.com/ibl/VCFr, with a live deployment
at: http://ibl.github.io/VCFr/ CONTACT: jonas.almeida@stonybrookmedicine.edu.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw652 
PMID: 27797761  [PubMed - as supplied by publisher]


196. Bioinformatics. 2016 Oct 22. pii: btw646. doi: 10.1093/bioinformatics/btw646.
[Epub ahead of print]

MIToS.jl: mutual information tools for protein sequence analysis in the Julia
language.

Zea DJ(1), Anfossi D(1), Nielsen M(2,)(3), Marino-Buslje C(1).

Author information: 
(1)Structural Bioinformatics Unit, Fundación Instituto Leloir, C1405BWE, Ciudad
Autónoma de Buenos Aires, Argentina. (2)Center for Biological Sequence Analysis, 
Technical University of Denmark, DK-2800 Kgs. Lyngby, Denmark. (3)Instituto de
Investigaciones Biotecnológicas, Universidad Nacional de San Martín, 1650 San
Martín, Buenos Aires, Argentina.

MOTIVATION: MIToS is an environment for mutual information analysis and a
framework for protein multiple sequence alignments (MSAs) and protein structures 
(PDB) management in Julia language. It integrates sequence and structural
information through SIFTS, making Pfam MSAs analysis straightforward. MIToS
streamlines the implementation of any measure calculated from residue contingency
tables and its optimization and testing in terms of protein contact prediction.
As an example, we implemented and tested a BLOSUM62-based pseudo-count strategy
in mutual information analysis.
AVAILABILITY AND IMPLEMENTATION: The software is totally implemented in Julia and
supported for Linux, OS X and Windows. It's freely available on GitHub under MIT 
license: http://mitos.leloir.org.ar CONTACTS: diegozea@gmail.com or
cmb@leloir.org.arSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw646 
PMID: 27797756  [PubMed - as supplied by publisher]


197. Bioinformatics. 2015 Oct 31. pii: btv633. [Epub ahead of print]

The Discordant Method: A Novel Approach for Differential Correlation.

Siska C(1), Bowler R(2), Kechris K(3).

Author information: 
(1)Computational Bioscience Program, University of Colorado Denver, Denver, CO.
(2)National Jewish Health, Department of Medicine, Denver, CO. (3)Department of
Biostatistics and Informatics, University of Colorado Denver, Denver, CO
katerina.kechris@ucdenver.edu.

MOTIVATION: Current differential correlation methods are built to determine
molecular feature pairs that have the largest magnitude of difference between
correlation coefficients. These methods do not easily capture molecular feature
pairs that experience no correlation in one group but correlation in another,
which may reflect certain types of biological interactions. We have developed a
tool, the Discordant method, which categorizes the correlation types for each
group to make this possible.
RESULTS: We compare the Discordant method to existing approaches using
simulations and two biological datasets with different types of -omics. In
contrast to other methods, Discordant identifies phenotype-related features at a 
similar or higher rate while maintaining reasonable computational tractability
and usability.
AVAILABILITY AND IMPLEMENTATION: R code and sample data is available at
https://github.com/siskac/discordant.
CONTACT: katerina.kechris@ucdenver.edu SUPPLEMENTARY INFORMATION: Supplementary
data are available at Bioinformatics online.

© The Author (2015). Published by Oxford University Press. All rights reserved.
For Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv633 
PMID: 27797747  [PubMed - as supplied by publisher]


198. J Cheminform. 2016 Oct 14;8:55. eCollection 2016.

The Open Spectral Database: an open platform for sharing and searching spectral
data.

Chalk SJ(1).

Author information: 
(1)Department of Chemistry, University of North Florida, Jacksonville, FL 32224
USA.

BACKGROUND: A number of websites make available spectral data for download
(typically as JCAMP-DX text files) and one (ChemSpider) that also allows users to
contribute spectral files. As a result, searching and retrieving such spectral
data can be time consuming, and difficult to reuse if the data is compressed in
the JCAMP-DX file. What is needed is a single resource that allows submission of 
JCAMP-DX files, export of the raw data in multiple formats, searching based on
multiple chemical identifiers, and is open in terms of license and access. To
address these issues a new online resource called the Open Spectral Database
(OSDB) http://osdb.info/ has been developed and is now available. Built using
open source tools, using open code (hosted on GitHub), providing open data, and
open to community input about design and functionality, the OSDB is available for
anyone to submit spectral data, making it searchable and available to the
scientific community. This paper details the concept and coding, internal
architecture, export formats, Representational State Transfer (REST) Application 
Programming Interface and options for submission of data.
RESULTS: The OSDB website went live in November 2015. Concurrently, the GitHub
repository was made available at https://github.com/stuchalk/OSDB/, and is open
for collaborators to join the project, submit issues, and contribute code.
CONCLUSION: The combination of a scripting environment (PHPStorm), a PHP
Framework (CakePHP), a relational database (MySQL) and a code repository (GitHub)
provides all the capabilities to easily develop REST based websites for
ingestion, curation and exposure of open chemical data to the community at all
levels. It is hoped this software stack (or equivalent ones in other scripting
languages) will be leveraged to make more chemical data available for both humans
and computers.

DOI: 10.1186/s13321-016-0170-2 
PMCID: PMC5065085
PMID: 27795739  [PubMed - in process]


199. J Cheminform. 2016 Oct 14;8:54. eCollection 2016.

SciData: a data model and ontology for semantic representation of scientific
data.

Chalk SJ(1).

Author information: 
(1)Department of Chemistry, University of North Florida, Jacksonville, FL 32224
USA.

With the move toward global, Internet enabled science there is an inherent need
to capture, store, aggregate and search scientific data across a large corpus of 
heterogeneous data silos. As a result, standards development is needed to create 
an infrastructure capable of representing the diverse nature of scientific data. 
This paper describes a fundamental data model for scientific data that can be
applied to data currently stored in any format, and an associated ontology that
affords semantic representation of the structure of scientific data (and its
metadata), upon which discipline specific semantics can be applied. Application
of this data model to experimental and computational chemistry data are
presented, implemented using JavaScript Object Notation for Linked Data. Full
examples are available at the project website (Chalk in SciData: a scientific
data model. http://stuchalk.github.io/scidata/, 2016).

DOI: 10.1186/s13321-016-0168-9 
PMCID: PMC5064921
PMID: 27795738  [PubMed - in process]


200. Bioinformatics. 2016 Oct 6. pii: btw626. [Epub ahead of print]

A Cytoscape app for motif enumeration with ISMAGS.

Van Parys T(1,)(2,)(3), Melckenbeeck I(4), Houbraken M(4), Audenaert P(3,)(4),
Colle D(3,)(4), Pickavet M(3,)(4), Demeester P(3,)(4), Van de Peer
Y(1,)(2,)(3,)(5).

Author information: 
(1)Department of Plant Systems Biology, VIB, Ghent 9052, Belgium. (2)Department
of Plant Biotechnology and Bioinformatics, Ghent University, Ghent 9052, Belgium.
(3)Bioinformatics Institute Ghent, Ghent University, Ghent, Belgium.
(4)Department of Information Technology (INTEC), Ghent University - iMinds, Ghent
9052, Belgium. (5)Genomics Research Institute, University of Pretoria, Pretoria, 
South Africa.

We present a Cytoscape app for the ISMAGS algorithm, which can enumerate all
instances of a motif in a graph, making optimal use of the motif's symmetries to 
make the search more efficient. The Cytoscape app provides a handy interface for 
this algorithm, which allows more efficient network analysis.AVAILABILITY AND
IMPLEMENTATION: The Cytoscape app for ISMAGS can be freely downloaded from the
Cytoscape App store http://apps.cytoscape.org/apps/ismags Source code and
documentation for ISMAGS are available at https://github.com/biointec/ismags
Source code and documentation for the Cytoscape app are available at
https://gitlab.psb.ugent.be/thpar/ISMAGS_Cytoscape CONTACTS:
Pieter.Audenaert@intec.ugent.be or Yves.VanDePeer@psb.vib-ugent.beSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Authors 2016. Published by Oxford University Press. All rights reserved.
For Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw626 
PMID: 27794559  [PubMed - as supplied by publisher]


201. Bioinformatics. 2016 Oct 29. pii: btw666. [Epub ahead of print]

FractBias: a graphical tool for assessing fractionation bias following
polyploidy.

Joyce BL(1), Haug-Baltzell A(2), Davey S(1), Bomhoff M(1), Schnable JC(3), Lyons 
E(1,)(2).

Author information: 
(1)BIO5 Institute, School of Plant Sciences, University of Arizona, Tucson, AZ
85721, USA. (2)Genetis GIDP, University of Arizona, Tucson, AZ 85721, USA.
(3)Department of Agronomy and Horticulture, University of Nebraska-Lincoln,
Lincoln, NE 68583, USA.

Following polyploidy events, genomes undergo massive reduction in gene content
through a process known as fractionation. Importantly, the fractionation process 
is not always random, and a bias as to which homeologous chromosome retains or
loses more genes can be observed in some species. The process of characterizing
whole genome fractionation requires identifying syntenic regions across genomes
followed by post-processing of those syntenic datasets to identify and plot gene 
retention patterns. We have developed a tool, FractBias, to calculate and
visualize gene retention and fractionation patterns across whole genomes. Through
integration with SynMap and its parent platform CoGe, assembled genomes are
pre-loaded and available for analysis, as well as letting researchers integrate
their own data with security options to keep them private or make them publicly
available.AVAILABILITY AND IMPLEMENTATION: FractBias is freely available as a web
application at https://genomevolution.org/CoGe/SynMap.pl The software is open
source (MIT license) and executable with Python 2.7 or iPython notebook, and
available on GitHub (https://goo.gl/PaAtqy). Documentation for FractBias is
available on CoGepedia (https://goo.gl/ou9dt6) CONTACT:
ericlyons@email.arizona.eduSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw666 
PMID: 27794557  [PubMed - as supplied by publisher]


202. Bioinformatics. 2016 Oct 29. pii: btw670. [Epub ahead of print]

gargammel: a sequence simulator for ancient DNA.

Renaud G(1), Hanghøj K(1,)(2), Willerslev E(1,)(3,)(4), Orlando L(1,)(2).

Author information: 
(1)Center for GeoGenetics, Natural History Museum of Denmark, University of
Copenhagen, 1350K Copenhagen, Denmark. (2)Université de Toulouse, University Paul
Sabatier (UPS), Laboratoire AMIS, CNRS UMR 5288, Toulouse, France. (3)Department 
of Zoology, University of Cambridge, Cambridge, CB2 3EJ, UK. (4)Wellcome Trust
Sanger Institute, Wellcome Genome Campus, Hinxton, Cambridge, CB10 1SA, UK.

Ancient DNA has emerged as a remarkable tool to infer the history of extinct
species and past populations. However, many of its characteristics, such as
extensive fragmentation, damage and contamination, can influence downstream
analyses. To help investigators measure how these could impact their analyses in 
silico, we have developed gargammel, a package that simulates ancient DNA
fragments given a set of known reference genomes. Our package simulates the
entire molecular process from post-mortem DNA fragmentation and DNA damage to
experimental sequencing errors, and reproduces most common bias observed in
ancient DNA datasets.AVAILABILITY AND IMPLEMENTATION: The package is publicly
available on github: https://grenaud.github.io/gargammel/ and released under the 
GPL.
CONTACT: gabriel.renaud@snm.ku.dkSupplementary information: Supplementary data
are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw670 
PMID: 27794556  [PubMed - as supplied by publisher]


203. Nat Methods. 2016 Dec;13(12):1050-1054. doi: 10.1038/nmeth.4035. Epub 2016 Oct
17.

Phased diploid genome assembly with single-molecule real-time sequencing.

Chin CS(1), Peluso P(1), Sedlazeck FJ(2), Nattestad M(3), Concepcion GT(1), Clum 
A(4), Dunn C(1), O'Malley R(5), Figueroa-Balderas R(6), Morales-Cruz A(6), Cramer
GR(7), Delledonne M(8), Luo C(5), Ecker JR(5), Cantu D(6), Rank DR(1), Schatz
MC(2,)(3,)(9).

Author information: 
(1)Pacific Biosciences, Menlo Park, California, USA. (2)Department of Computer
Science, Johns Hopkins University, Baltimore, Maryland, USA. (3)Simons Center for
Quantitative Biology, Cold Spring Harbor Laboratory, Cold Spring Harbor, New
York, USA. (4)DOE Joint Genome Institute, Walnut Creek, California, USA.
(5)Genomic Analysis Laboratory, The Salk Institute for Biological Studies, La
Jolla, California, USA. (6)Department of Viticulture and Enology, University of
California Davis, Davis, California, USA. (7)Department of Biochemistry and
Molecular Biology, University of Nevada, Reno, Nevada, USA. (8)Dipartimento di
Biotecnologie, Universita' degli Studi di Verona, Verona, Italy. (9)Department of
Biology, Johns Hopkins University, Baltimore, Maryland, USA.

While genome assembly projects have been successful in many haploid and inbred
species, the assembly of noninbred or rearranged heterozygous genomes remains a
major challenge. To address this challenge, we introduce the open-source FALCON
and FALCON-Unzip algorithms (https://github.com/PacificBiosciences/FALCON/) to
assemble long-read sequencing data into highly accurate, contiguous, and
correctly phased diploid genomes. We generate new reference sequences for
heterozygous samples including an F1 hybrid of Arabidopsis thaliana, the widely
cultivated Vitis vinifera cv. Cabernet Sauvignon, and the coral fungus
Clavicorona pyxidata, samples that have challenged short-read assembly
approaches. The FALCON-based assemblies are substantially more contiguous and
complete than alternate short- or long-read approaches. The phased diploid
assembly enabled the study of haplotype structure and heterozygosities between
homologous chromosomes, including the identification of widespread heterozygous
structural variation within coding sequences.

DOI: 10.1038/nmeth.4035 
PMID: 27749838  [PubMed - in process]


204. Bioinformatics. 2016 Oct 13. pii: btw638. [Epub ahead of print]

PyMod 2.0: improvements in protein sequence-structure analysis and homology
modeling within PyMOL.

Janson G(1), Zhang C(2), Prado MG(1), Paiardini A(3).

Author information: 
(1)Department of Biochemical Sciences "A. Rossi Fanelli", Sapienza Università di 
Roma, 00185 Rome, Italy. (2)Department of Computational Medicine and
Bioinformatics, University of Michigan, Ann Arbor, MI 48109, USA. (3)Department
of Biology and Biotechnology "Charles Darwin", Sapienza Università di Roma, 00185
Rome, Italy.

MOTIVATION: The recently released PyMod GUI integrates many of the individual
steps required for protein sequence-structure analysis and homology modeling
within the interactive visualization capabilities of PyMOL. Here we describe the 
improvements introduced into the version 2.0 of PyMod.
RESULTS: The original code of PyMod has been completely rewritten and improved in
version 2.0 to extend PyMOL with packages such as Clustal Omega, PSIPRED and
CAMPO. Integration with the popular web services ESPript and WebLogo is also
provided. Finally, a number of new MODELLER functionalities have also been
implemented, including SALIGN, modeling of quaternary structures, DOPE scores,
disulfide bond modeling and choice of heteroatoms to be included in the final
model.
AVAILABILITY AND IMPLEMENTATION: PyMod 2.0 installer packages for Windows, Linux 
and Mac OS X and user guides are available at
http://schubert.bio.uniroma1.it/pymod/index.html The open source code of the
project is hosted at https://github.com/pymodproject/pymod CONTACTS:
alessandro.paiardini@uniroma1.it or giacomo.janson@uniroma1.it.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw638 
PMID: 27742701  [PubMed - as supplied by publisher]


205. Bioinformatics. 2016 Sep 30. pii: btw628. [Epub ahead of print]

Granular clustering of de novo protein models.

Guzenko D(1), Strelkov SV(1).

Author information: 
(1)Department of Pharmaceutical and Pharmacological Sciences, KU Leuven, Leuven
3000, Belgium.

MOTIVATION: Modern algorithms for de novo prediction of protein structures
typically output multiple full-length models (decoys) rather than a single
solution. Subsequent clustering of such decoys is used both to gauge the success 
of the modelling and to decide on the most native-like conformation. At the same 
time, partial protein models are sufficient for some applications such as
crystallographic phasing by molecular replacement (MR) in particular, provided
these models represent a certain part of the target structure with reasonable
accuracy.
RESULTS: Here we propose a novel clustering algorithm that natively operates in
the space of partial models through an approach known as granular clustering
(GC). The algorithm is based on growing local similarities found in a pool of
initial decoys. We demonstrate that the resulting clusters of partial models
provide a substantially more accurate structural detail on the target protein
than those obtained upon a global alignment of decoys. As the result, the partial
models output by our GC algorithm are also much more effective towards the MR
procedure, compared to the models produced by existing software.
AVAILABILITY AND IMPLEMENTATION: The source code is freely available at
https://github.com/biocryst/gc CONTACT: sergei.strelkov@kuleuven.beSupplementary 
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw628 
PMID: 27694199  [PubMed - as supplied by publisher]


206. Bioinformatics. 2016 Sep 30. pii: btw624. [Epub ahead of print]

The START App: a web-based RNAseq analysis and visualization resource.

Nelson JW(1), Sklenar J(1), Barnes AP(2), Minnier J(1,)(3).

Author information: 
(1)The Knight Cardiovascular Institute. (2)Department of Pediatrics. (3)School of
Public Health, Oregon Health & Science University, Portland, OR 97239-3098, USA.

Transcriptional profiling using RNA sequencing (RNAseq) has emerged as a powerful
methodology to quantify global gene expression patterns in various contexts from 
single cells to whole tissues. The tremendous amount of data generated by this
profiling technology presents a daunting challenge in terms of effectively
visualizing and interpreting results. Convenient and intuitive data interfaces
are critical for researchers to easily upload, analyze and visualize their RNAseq
data. We designed the START (Shiny Transcriptome Analysis Resource Tool) App with
these requirements in mind. This application has the power and flexibility to be 
resident on a local computer or serve as a web-based environment, enabling easy
sharing of data between researchers and collaborators.AVAILABILITY AND
IMPLEMENTATION: Source Code for the START App is written entirely in R and can be
freely available to download at https://github.com/jminnier/STARTapp with the
code licensed under GPLv3. It can be launched on any system that has R installed.
The START App is also hosted on https://kcvi.shinyapps.io/START for researchers
to temporarily upload their data.
CONTACT: minnier@ohsu.edu.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw624 
PMID: 27694193  [PubMed - as supplied by publisher]


207. Bioinformatics. 2017 Jan 15;33(2):192-201. doi: 10.1093/bioinformatics/btw594.
Epub 2016 Sep 25.

LAMSA: fast split read alignment with long approximate matches.

Liu B(1), Gao Y(1), Wang Y(1).

Author information: 
(1)Center for Bioinformatics, Harbin Institute of Technology, Harbin,
Heilongjiang 150001, China.

MOTIVATION: Read length is continuously increasing with the development of novel 
high-throughput sequencing technologies, which has enormous potentials on
cutting-edge genomic studies. However, longer reads could more frequently span
the breakpoints of structural variants (SVs) than that of shorter reads. This may
greatly influence read alignment, since most state-of-the-art aligners are
designed for handling relatively small variants in a co-linear alignment
framework. Meanwhile, long read alignment is still not as efficient as that of
short reads, which could be also a bottleneck for the upcoming wide application.
RESULTS: We propose long approximate matches-based split aligner (LAMSA), a novel
split read alignment approach. It takes the advantage of the rareness of SVs to
implement a specifically designed two-step strategy. That is, LAMSA initially
splits the read into relatively long fragments and co-linearly align them to
solve the small variations or sequencing errors, and mitigate the effect of
repeats. The alignments of the fragments are then used for implementing a sparse 
dynamic programming-based split alignment approach to handle the large or
non-co-linear variants. We benchmarked LAMSA with simulated and real datasets
having various read lengths and sequencing error rates, the results demonstrate
that it is substantially faster than the state-of-the-art long read aligners;
meanwhile, it also has good ability to handle various categories of SVs.
AVAILABILITY AND IMPLEMENTATION: LAMSA is available at
https://github.com/hitbc/LAMSA CONTACT: Ydwang@hit.edu.cnSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw594 
PMID: 27667793  [PubMed - in process]


208. Bioinformatics. 2016 Sep 23. pii: btw600. [Epub ahead of print]

FastRFS: fast and accurate Robinson-Foulds Supertrees using constrained exact
optimization.

Vachaspati P(1), Warnow T(1,)(2,)(3).

Author information: 
(1)Department of Computer Science. (2)National Center for Supercomputing
Applications. (3)Department of Bioengineering, University of Illinois,
Urbana-Champaign, Urbana, IL 61801, USA.

MOTIVATION: The estimation of phylogenetic trees is a major part of many
biological dataset analyses, but maximum likelihood approaches are NP-hard and
Bayesian MCMC methods do not scale well to even moderate-sized datasets.
Supertree methods, which are used to construct trees from trees computed on
subsets, are critically important tools for enabling the statistical estimation
of phylogenies for large and potentially heterogeneous datasets. Supertree
estimation is itself NP-hard, and no current supertree method has sufficient
accuracy and scalability to provide good accuracy on the large datasets that
supertree methods were designed for, containing thousands of species and many
subset trees.
RESULTS: We present FastRFS, a new method based on a dynamic programming method
we have developed to find an exact solution to the Robinson-Foulds Supertree
problem within a constrained search space. FastRFS has excellent accuracy in
terms of criterion scores and topological accuracy of the resultant trees,
substantially improving on competing methods on a large collection of biological 
and simulated data. In addition, FastRFS is extremely fast, finishing in minutes 
on even very large datasets, and in under an hour on a biological dataset with
2228 species.
AVAILABILITY AND IMPLEMENTATION: FastRFS is available on github at
https://github.com/pranjalv123/FastRFS CONTACT: warnow@illinois.eduSupplementary 
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw600 
PMID: 27663499  [PubMed - as supplied by publisher]


209. Bioinformatics. 2017 Jan 15;33(2):227-234. doi: 10.1093/bioinformatics/btw599.
Epub 2016 Sep 23.

A generative model for the behavior of RNA polymerase.

Azofeifa JG(1), Dowell RD(1,)(2,)(3).

Author information: 
(1)Department of Computer Science, University of Colorado, Boulder, CO, USA.
(2)Department of Molecular, Cellular and Developmental Biology, University of
Colorado, Boulder, CO, USA. (3)BioFrontiers Institute, University of Colorado,
Boulder, CO, USA.

MOTIVATION: Transcription by RNA polymerase is a highly dynamic process involving
multiple distinct points of regulation. Nascent transcription assays are a
relatively new set of high throughput techniques that measure the location of
actively engaged RNA polymerase genome wide. Hence, nascent transcription is a
rich source of information on the regulation of RNA polymerase activity. To fully
dissect this data requires the development of stochastic models that can both
deconvolve the stages of polymerase activity and identify significant changes in 
activity between experiments.
RESULTS: We present a generative, probabilistic model of RNA polymerase that
fully describes loading, initiation, elongation and termination. We fit this
model genome wide and profile the enzymatic activity of RNA polymerase across
various loci and following experimental perturbation. We observe striking
correlation of predicted loading events and regulatory chromatin marks. We
provide principled statistics that compute probabilities reminiscent of
traveler's and divergent ratios. We finish with a systematic comparison of RNA
Polymerase activity at promoter versus non-promoter associated loci.
AVAILABILITY AND IMPLEMENTATION: Transcription Fit (Tfit) is a freely available, 
open source software package written in C/C ++ that requires GNU compilers 4.7.3 
or greater. Tfit is available from GitHub (https://github.com/azofeifa/Tfit).
CONTACT: robin.dowell@colorado.eduSupplementary information: Supplementary data
are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw599 
PMID: 27663494  [PubMed - in process]


210. Bioinformatics. 2016 Dec 1;32(23):3654-3660. Epub 2016 Aug 13.

CGDM: collaborative genomic data model for molecular profiling data using NoSQL.

Wang S(1), Mares MA(1), Guo YK(1,)(2).

Author information: 
(1)Data Science Institute, Imperial College London, London, UK. (2)School of
Computer Science, Shanghai University, Shanghai, China.

MOTIVATION: High-throughput molecular profiling has greatly improved patient
stratification and mechanistic understanding of diseases. With the increasing
amount of data used in translational medicine studies in recent years, there is a
need to improve the performance of data warehouses in terms of data retrieval and
statistical processing. Both relational and Key Value models have been used for
managing molecular profiling data. Key Value models such as SeqWare have been
shown to be particularly advantageous in terms of query processing speed for
large datasets. However, more improvement can be achieved, particularly through
better indexing techniques of the Key Value models, taking advantage of the types
of queries which are specific for the high-throughput molecular profiling data.
RESULTS: In this article, we introduce a Collaborative Genomic Data Model (CGDM),
aimed at significantly increasing the query processing speed for the main classes
of queries on genomic databases. CGDM creates three Collaborative Global
Clustering Index Tables (CGCITs) to solve the velocity and variety issues at the 
cost of limited extra volume. Several benchmarking experiments were carried out, 
comparing CGDM implemented on HBase to the traditional SQL data model (TDM)
implemented on both HBase and MySQL Cluster, using large publicly available
molecular profiling datasets taken from NCBI and HapMap. In the microarray case, 
CGDM on HBase performed up to 246 times faster than TDM on HBase and 7 times
faster than TDM on MySQL Cluster. In single nucleotide polymorphism case, CGDM on
HBase outperformed TDM on HBase by up to 351 times and TDM on MySQL Cluster by up
to 9 times.
AVAILABILITY AND IMPLEMENTATION: The CGDM source code is available at
https://github.com/evanswang/CGDM.
CONTACT: y.guo@imperial.ac.uk.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw531 
PMID: 27522085  [PubMed - in process]


211. BMC Genomics. 2016 Oct 28;17(1):845.

CoSpliceNet: a framework for co-splicing network inference from transcriptomics
data.

Aghamirzaie D(1), Collakova E(2), Li S(3,)(4), Grene R(3,)(2).

Author information: 
(1)Genetics, Bioinformatics and Computational Biology, Virginia Tech, Blacksburg,
VA, 24061, USA. delasa@vt.edu. (2)Department of Plant Pathology, Physiology, and 
Weed Science, Virginia Tech, Blacksburg, VA, 24061, USA. (3)Genetics,
Bioinformatics and Computational Biology, Virginia Tech, Blacksburg, VA, 24061,
USA. (4)Department of Crop and Soil Environmental Sciences, Virginia Tech,
Blacksburg, VA, 24061, USA.

BACKGROUND: Alternative splicing has been proposed to increase transcript
diversity and protein plasticity in eukaryotic organisms, but the extent to which
this is the case is currently unclear, especially with regard to the
diversification of molecular function. Eukaryotic splicing involves complex
interactions of splicing factors and their targets. Inference of co-splicing
networks capturing these types of interactions is important for understanding
this crucial, highly regulated post-transcriptional process at the systems level.
RESULTS: First, several transcript and protein attributes, including coding
potential of transcripts and differences in functional domains of proteins, were 
compared between splice variants and protein isoforms to assess transcript and
protein diversity in a biological system. Alternative splicing was shown to
increase transcript and function-related protein diversity in developing
Arabidopsis embryos. Second, CoSpliceNet, which integrates co-expression and
motif discovery at splicing regulatory regions to infer co-splicing networks, was
developed. CoSpliceNet was applied to temporal RNA sequencing data to identify
candidate regulators of splicing events and predict RNA-binding motifs, some of
which are supported by prior experimental evidence. Analysis of inferred splicing
factor targets revealed an unexpected role for the unfolded protein response in
embryo development.
CONCLUSIONS: The methods presented here can be used in any biological system to
assess transcript diversity and protein plasticity and to predict candidate
regulators, their targets, and RNA-binding motifs for splicing factors.
CoSpliceNet is freely available at http://delasa.github.io/co-spliceNet/ .

DOI: 10.1186/s12864-016-3172-6 
PMCID: PMC5086072
PMID: 27793091  [PubMed - in process]


212. J Biomol Tech. 2016 Dec;27(4):129-131. Epub 2016 Oct 17.

Automated Sanger Analysis Pipeline (ASAP): A Tool for Rapidly Analyzing Sanger
Sequencing Data with Minimum User Interference.

Singh A(1), Bhatia P(1).

Author information: 
(1)Advanced Paediatrics Centre, Post Graduate Institute of Medical Education and 
Research, Chandigarh, India.

Sanger sequencing platforms, such as applied biosystems instruments, generate
chromatogram files. Generally, for 1 region of a sequence, we use both forward
and reverse primers to sequence that area, in that way, we have 2 sequences that 
need to be aligned and a consensus generated before mutation detection studies.
This work is cumbersome and takes time, especially if the gene is large with many
exons. Hence, we devised a rapid automated command system to filter, build, and
align consensus sequences and also optionally extract exonic regions, translate
them in all frames, and perform an amino acid alignment starting from raw
sequence data within a very short time. In full capabilities of Automated
Mutation Analysis Pipeline (ASAP), it is able to read "*.ab1" chromatogram files 
through command line interface, convert it to the FASTQ format, trim the
low-quality regions, reverse-complement the reverse sequence, create a consensus 
sequence, extract the exonic regions using a reference exonic sequence, translate
the sequence in all frames, and align the nucleic acid and amino acid sequences
to reference nucleic acid and amino acid sequences, respectively. All files are
created and can be used for further analysis. ASAP is available as Python 3.x
executable at https://github.com/aditya-88/ASAP. The version described in this
paper is 0.28.

DOI: 10.7171/jbt.16-2704-005 
PMCID: PMC5066597
PMID: 27790076  [PubMed - in process]


213. Biosystems. 2016 Dec;150:78-86. doi: 10.1016/j.biosystems.2016.08.004. Epub 2016 
Aug 13.

C-DEVA: Detection, evaluation, visualization and annotation of clusters from
biological networks.

Li M(1), Tang Y(2), Wu X(3), Wang J(4), Wu FX(5), Pan Y(6).

Author information: 
(1)School of Information Science and Engineering, Central South University,
Changsha, 410083, China. Electronic address: limin@mail.csu.edu.cn. (2)School of 
Information Science and Engineering, Central South University, Changsha, 410083, 
China. Electronic address: tang_yu@csu.edu.cn. (3)School of Information Science
and Engineering, Central South University, Changsha, 410083, China. Electronic
address: csu.xhwu@csu.edu.cn. (4)School of Information Science and Engineering,
Central South University, Changsha, 410083, China. Electronic address:
jxwang@mail.csu.edu.cn. (5)School of Information Science and Engineering, Central
South University, Changsha, 410083, China; Division of Biomedical Engineering and
Department of Mechanical Engineering, University of Saskatchewan, Saskatoon, SK, 
S7N 5A9, Canada. Electronic address: faw341@mail.usask.ca. (6)School of
Information Science and Engineering, Central South University, Changsha, 410083, 
China; Department of Computer Science, Georgia State University, Atlanta, GA,
30302-4110, USA. Electronic address: pan@cs.gsu.edu.

With the progress of studies and researches on the biological networks, plenty of
excellent clustering algorithms have been proposed. Nevertheless, not only
different algorithms but also the same algorithms with different characteristics 
result in different performances on the same biological networks. Therefore, it
might be difficult for researchers to choose an appropriate clustering algorithm 
to use for a specific network. Here we present C-DEVA, a comprehensive platform
for Detecting clusters from biological networks and its Evaluation, Visualization
and Annotation analysis. Ten clustering methods are provided in C-DEVA, covering 
different types of clustering algorithms, with a discrepancy in principle of each
type. For the identified complexes, there are over ten popular and traditional
bio-statistical measurements to assess them. And multi-source biological
information has been integrated in C-DEVA, such as biology-functional
annotations, and gold standard complex sets, which are collected from latest
datasets in major databases or related papers. Furthermore, visualization
analyses are available throughout the whole workflow, which endows C-DEVA with
good usability and simple manipulation. To assure extensibility, development
interfaces are offered in C-DEVA, for integrating new clustering as well as
evaluating methods. Additionally, operations to the network as for example
network randomization are also supported. C-DEVA provides a complete tool for
identifying clusters from biological networks. Multiple options are offered
during the analysis process, including detection methods, evaluation metrics and 
visualization modules. In addition, researchers could customize C-DEVA for the
workflow according to the properties of their networks, and find the most ideal
results. C-DEVA is released under the GNU General Public License (GPL), and the
source code and binaries are freely available at
https://github.com/cici333/c-deva.

Copyright Â© 2016 Elsevier Ireland Ltd. All rights reserved.

DOI: 10.1016/j.biosystems.2016.08.004 
PMID: 27530307  [PubMed - in process]


214. Bioinformatics. 2016 Nov 1;32(21):3215-3223. Epub 2016 Jul 13.

LightAssembler: fast and memory-efficient assembly algorithm for high-throughput 
sequencing reads.

El-Metwally S(1), Zakaria M(2), Hamza T(2).

Author information: 
(1)Molecular and Computational Biology, University of Southern California, Los
Angeles, CA 90089, USA Department of Computer Science, Faculty of Computers and
Information, Mansoura University, Mansoura 35516, Egypt. (2)Department of
Computer Science, Faculty of Computers and Information, Mansoura University,
Mansoura 35516, Egypt.

MOTIVATION: The deluge of current sequenced data has exceeded Moore's Law, more
than doubling every 2 years since the next-generation sequencing (NGS)
technologies were invented. Accordingly, we will able to generate more and more
data with high speed at fixed cost, but lack the computational resources to
store, process and analyze it. With error prone high throughput NGS reads and
genomic repeats, the assembly graph contains massive amount of redundant nodes
and branching edges. Most assembly pipelines require this large graph to reside
in memory to start their workflows, which is intractable for mammalian genomes.
Resource-efficient genome assemblers combine both the power of advanced computing
techniques and innovative data structures to encode the assembly graph
efficiently in a computer memory.
RESULTS: LightAssembler is a lightweight assembly algorithm designed to be
executed on a desktop machine. It uses a pair of cache oblivious Bloom filters,
one holding a uniform sample of [Formula: see text]-spaced sequenced [Formula:
see text]-mers and the other holding [Formula: see text]-mers classified as
likely correct, using a simple statistical test. LightAssembler contains a light 
implementation of the graph traversal and simplification modules that achieves
comparable assembly accuracy and contiguity to other competing tools. Our method 
reduces the memory usage by [Formula: see text] compared to the
resource-efficient assemblers using benchmark datasets from GAGE and Assemblathon
projects. While LightAssembler can be considered as a gap-based sequence
assembler, different gap sizes result in an almost constant assembly size and
genome coverage.
AVAILABILITY AND IMPLEMENTATION:
https://github.com/SaraEl-Metwally/LightAssembler CONTACT:
sarah_almetwally4@mans.edu.egSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw470 
PMID: 27412092  [PubMed - in process]


215. Bioinformatics. 2016 Nov 1;32(21):3366-3368. Epub 2016 Jul 8.

BioNetGen 2.2: advances in rule-based modeling.

Harris LA(1), Hogg JS(1), Tapia JJ(1), Sekar JA(1), Gupta S(1), Korsunsky I(1),
Arora A(1), Barua D(1), Sheehan RP(1), Faeder JR(1).

Author information: 
(1)Department of Computational and Systems Biology, University of Pittsburgh
School of Medicine, Pittsburgh, PA, USA.

: BioNetGen is an open-source software package for rule-based modeling of complex
biochemical systems. Version 2.2 of the software introduces numerous new features
for both model specification and simulation. Here, we report on these additions, 
discussing how they facilitate the construction, simulation and analysis of
larger and more complex models than previously possible.AVAILABILITY AND
IMPLEMENTATION: Stable BioNetGen releases (Linux, Mac OS/X and Windows), with
documentation, are available at http://bionetgen.org Source code is available at 
http://github.com/RuleWorld/bionetgen CONTACT:
bionetgen.help@gmail.comSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw469 
PMCID: PMC5079481 [Available on 2017-11-01]
PMID: 27402907  [PubMed - in process]


216. Bioinformatics. 2016 Nov 1;32(21):3363-3365. Epub 2016 Jul 10.

PyPanda: a Python package for gene regulatory network reconstruction.

van IJzendoorn DG(1), Glass K(2), Quackenbush J(3), Kuijjer ML(4).

Author information: 
(1)Department of Pathology, Leiden University Medical Center, 2300RC Leiden, The 
Netherlands. (2)Channing Division of Network Medicine, Department of Medicine,
Brigham and Women's Hospital, Harvard Medical School, Boston, MA 02215, USA.
(3)Department of Biostatistics and Computational Biology, Dana-Farber Cancer
Institute, Boston, MA 02215, USA Department of Biostatistics, Harvard T.H. Chan
School of Public Health, Boston, MA 02215, USA Department of Cancer Biology,
Dana-Farber Cancer Institute, Boston, MA 02215, USA. (4)Department of
Biostatistics and Computational Biology, Dana-Farber Cancer Institute, Boston, MA
02215, USA Department of Biostatistics, Harvard T.H. Chan School of Public
Health, Boston, MA 02215, USA.

PANDA (Passing Attributes between Networks for Data Assimilation) is a gene
regulatory network inference method that uses message-passing to integrate
multiple sources of 'omics data. PANDA was originally coded in C ++. In this
application note we describe PyPanda, the Python version of PANDA. PyPanda runs
considerably faster than the C ++ version and includes additional features for
network analysis.AVAILABILITY AND IMPLEMENTATION: The open source PyPanda Python 
package is freely available at http://github.com/davidvi/pypanda CONTACT:
mkuijjer@jimmy.harvard.edu or d.g.p.van_ijzendoorn@lumc.nl.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw422 
PMCID: PMC5079480
PMID: 27402905  [PubMed - in process]


217. Bioinformatics. 2016 Nov 1;32(21):3369-3370. Epub 2016 Jul 10.

MIMEAnTo: profiling functional RNA in mutational interference mapping
experiments.

Smith MR(1), Smyth RP(2), Marquet R(2), von Kleist M(1).

Author information: 
(1)Systems Pharmacology & Disease Control, Department of Mathematics and Computer
Science, Freie Universität Berlin, Berlin, Germany. (2)Architecture et Réactivité
de l'ARN, Institut de Biologie Moléculaire et Cellulaire du Centre National de la
Recherche Scientifique, Université de Strasbourg, Strasbourg, France.

The mutational interference mapping experiment (MIME) is a powerful method that, 
coupled to a bioinformatics analysis pipeline, allows the identification of
domains and structures in RNA that are important for its function. In MIME,
target RNAs are randomly mutated, selected by function, physically separated and 
sequenced using next-generation sequencing (NGS). Quantitative effects of each
mutation at each position in the RNA can be recovered with statistical certainty 
using the herein developed user-friendly, cross-platform software MIMEAnTo (MIME 
Analysis Tool).AVAILABILITY AND IMPLEMENTATION: MIMEAnTo is implemented in
C ++ using the boost library as well as Qt for the graphical user interface and
is distributed under GPL (http://www.gnu.org/licences/gpl). The libraries are
statically linked in a stand alone executable and are not required on the system.
The plots are generated with gnuplot. Gnuplot-iostream
(https://github.com/dstahlke/gnuplot-iostream) serves as gnuplot interface.
Standalone executables including examples and source code can be downloaded from 
https://github.com/maureensmith/MIMEAnTo CONTACTS: msmith@zedat.fu-berlin.de or
vkleist@zedat.fu-berlin.deSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw479 
PMID: 27402903  [PubMed - in process]


218. Bioinformatics. 2016 Nov 1;32(21):3351-3353. Epub 2016 Jul 4.

MetaCycle: an integrated R package to evaluate periodicity in large scale data.

Wu G(1), Anafi RC(2), Hughes ME(3), Kornacker K(4), Hogenesch JB(1).

Author information: 
(1)Department of Systems Pharmacology and Translational Therapeutics, Institute
for Translational Medicine and Therapeutics. (2)Division of Sleep Medicine Center
for Sleep and Circadian Neurobiology, University of Pennsylvania School of
Medicine, Philadelphia, PA 19104, USA. (3)Department of Biology, University of
Missouri-St. Louis, St. Louis, MO 63121, USA. (4)Emeritus Professor of Sensory
Biophysics, the Ohio State University, Columbus, OH 43210, USA.

Detecting periodicity in large scale data remains a challenge. While efforts have
been made to identify best of breed algorithms, relatively little research has
gone into integrating these methods in a generalizable method. Here, we present
MetaCycle, an R package that incorporates ARSER, JTK_CYCLE and Lomb-Scargle to
conveniently evaluate periodicity in time-series data. MetaCycle has two
functions, meta2d and meta3d, designed to analyze two-dimensional and
three-dimensional time-series datasets, respectively. Meta2d implements N-version
programming concepts using a suite of algorithms and integrating their
results.AVAILABILITY AND IMPLEMENTATION: MetaCycle package is available on the
CRAN repository (https://cran.r-project.org/web/packages/MetaCycle/index.html)
and GitHub (https://github.com/gangwug/MetaCycle).
CONTACT: hogenesch@gmail.comSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw405 
PMCID: PMC5079475 [Available on 2017-11-01]
PMID: 27378304  [PubMed - in process]


219. Bioinformatics. 2016 Nov 1;32(21):3224-3232. Epub 2016 Jul 4.

deBGA: read alignment with de Bruijn graph-based seed and extension.

Liu B(1), Guo H(1), Brudno M(2), Wang Y(1).

Author information: 
(1)Center for Bioinformatics, Harbin Institute of Technology, Harbin,
Heilongjiang 150001, China. (2)Department of Computer Science, University of
Toronto, ON M5S 3G4, Canada Genetics and Genome Biology Program, The Hospital for
Sick Children, Toronto, ON M5G 1L7, Canada Centre for Computational Medicine, The
Hospital for Sick Children, Toronto, ON M5G 1L7, Canada.

MOTIVATION: As high-throughput sequencing (HTS) technology becomes ubiquitous and
the volume of data continues to rise, HTS read alignment is becoming increasingly
rate-limiting, which keeps pressing the development of novel read alignment
approaches. Moreover, promising novel applications of HTS technology require
aligning reads to multiple genomes instead of a single reference; however, it is 
still not viable for the state-of-the-art aligners to align large numbers of
reads to multiple genomes.
RESULTS: We propose de Bruijn Graph-based Aligner (deBGA), an innovative
graph-based seed-and-extension algorithm to align HTS reads to a reference genome
that is organized and indexed using a de Bruijn graph. With its well-handling of 
repeats, deBGA is substantially faster than state-of-the-art approaches while
maintaining similar or higher sensitivity and accuracy. This makes it
particularly well-suited to handle the rapidly growing volumes of sequencing
data. Furthermore, it provides a promising solution for aligning reads to
multiple genomes and graph-based references in HTS applications.
AVAILABILITY AND IMPLEMENTATION: deBGA is available at:
https://github.com/hitbc/deBGA CONTACT: ydwang@hit.edu.cnSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw371 
PMID: 27378303  [PubMed - in process]


220. Bioinformatics. 2016 Nov 1;32(21):3354-3356. Epub 2016 Jul 4.

Heat*seq: an interactive web tool for high-throughput sequencing experiment
comparison with public data.

Devailly G(1), Mantsoki A(1), Joshi A(1).

Author information: 
(1)Department of Developmental Biology, The Roslin Institute, University of
Edinburgh, Easter Bush Campus, Midlothian EH25 9RG, UK.

Better protocols and decreasing costs have made high-throughput sequencing
experiments now accessible even to small experimental laboratories. However,
comparing one or few experiments generated by an individual lab to the vast
amount of relevant data freely available in the public domain might be limited
due to lack of bioinformatics expertise. Though several tools, including genome
browsers, allow such comparison at a single gene level, they do not provide a
genome-wide view. We developed Heat*seq, a web-tool that allows genome scale
comparison of high throughput experiments chromatin immuno-precipitation followed
by sequencing, RNA-sequencing and Cap Analysis of Gene Expression) provided by a 
user, to the data in the public domain. Heat*seq currently contains over 12 000
experiments across diverse tissues and cell types in human, mouse and drosophila.
Heat*seq displays interactive correlation heatmaps, with an ability to
dynamically subset datasets to contextualize user experiments. High quality
figures and tables are produced and can be downloaded in multiple
formats.AVAILABILITY AND IMPLEMENTATION: Web application:
http://www.heatstarseq.roslin.ed.ac.uk/ Source code: https://github.com/gdevailly
CONTACT: Guillaume.Devailly@roslin.ed.ac.uk or
Anagha.Joshi@roslin.ed.ac.ukSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw407 
PMCID: PMC5079476
PMID: 27378302  [PubMed - in process]


221. Bioinformatics. 2016 Nov 1;32(21):3339-3341. Epub 2016 Jul 4.

MetaPred2CS: a sequence-based meta-predictor for protein-protein interactions of 
prokaryotic two-component system proteins.

Kara A(1), Vickers M(1), Swain M(1), Whitworth DE(1), Fernandez-Fuentes N(1).

Author information: 
(1)Institute of Biological, Environmental and Rural Sciences, Aberystwyth
University, Aberystwyth SY23 3EB, UK.

MOTIVATION: Two-component systems (TCS) are the main signalling pathways of
prokaryotes, and control a wide range of biological phenomena. Their functioning 
depends on interactions between TCS proteins, the specificity of which is poorly 
understood.
RESULTS: The MetaPred2CS web-server interfaces a sequence-based meta-predictor
specifically designed to predict pairing of the histidine kinase and
response-regulator proteins forming TCSs. MetaPred2CS integrates six
sequence-based methods using a support vector machine classifier and has been
intensively tested under different benchmarking conditions: (i) species specific 
gene sets; (ii) neighbouring versus orphan pairs; and (iii) k-fold cross
validation on experimentally validated datasets.
AVAILABILITY AND IMPLEMENTATION: Web server at:
http://metapred2cs.ibers.aber.ac.uk/, Source code:
https://github.com/martinjvickers/MetaPred2CS or implemented as Virtual Machine
at: http://metapred2cs.ibers.aber.ac.uk/download CONTACT:
naf4@aber.ac.ukSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw403 
PMID: 27378293  [PubMed - in process]


222. Bioinformatics. 2016 Nov 1;32(21):3333-3335. Epub 2016 Jul 4.

w4CSeq: software and web application to analyze 4C-seq data.

Cai M(1), Gao F(2), Lu W(3), Wang K(4).

Author information: 
(1)Department of Preventive Medicine Eli and Edythe Broad Center for Regenerative
Medicine and Stem Cell Research Zilkha Neurogenetic Institute. (2)Eli and Edythe 
Broad Center for Regenerative Medicine and Stem Cell Research Zilkha Neurogenetic
Institute. (3)Eli and Edythe Broad Center for Regenerative Medicine and Stem Cell
Research Department of Stem Cell Biology and Regenerative Medicine. (4)Zilkha
Neurogenetic Institute Department of Psychiatry, Keck School of Medicine,
University of Southern California, Los Angeles, CA 90033, USA.

Circularized Chromosome Conformation Capture followed by deep sequencing (4C-Seq)
is a powerful technique to identify genome-wide partners interacting with a
pre-specified genomic locus. Here, we present a computational and statistical
approach to analyze 4C-Seq data generated from both enzyme digestion and
sonication fragmentation-based methods. We implemented a command line software
tool and a web interface called w4CSeq, which takes in the raw 4C sequencing data
(FASTQ files) as input, performs automated statistical analysis and presents
results in a user-friendly manner. Besides providing users with the list of
candidate interacting sites/regions, w4CSeq generates figures showing genome-wide
distribution of interacting regions, and sketches the enrichment of key features 
such as TSSs, TTSs, CpG sites and DNA replication timing around 4C
sites.AVAILABILITY AND IMPLEMENTATION: Users can establish their own web server
by downloading source codes at https://github.com/WGLab/w4CSeq Additionally, a
demo web server is available at http://w4cseq.wglab.org CONTACT: kaiwang@usc.edu 
or wangelu@usc.eduSupplementary information: Supplementary data are available at 
Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw408 
PMCID: PMC5079477 [Available on 2017-11-01]
PMID: 27378289  [PubMed - in process]


223. BMC Bioinformatics. 2016 Oct 26;17(1):434.

AlignStat: a web-tool and R package for statistical comparison of alternative
multiple sequence alignments.

Shafee T(1), Cooke I(2,)(3).

Author information: 
(1)Department of Biochemistry and Genetics, La Trobe Institute for Molecular
Science, La Trobe University, Melbourne, 3086, Australia.
T.Shafee@LaTrobe.edu.au. (2)Department of Biochemistry and Genetics, La Trobe
Institute for Molecular Science, La Trobe University, Melbourne, 3086, Australia.
(3)Department of Molecular and Cell Biology, James Cook University, Townsville,
4811, Australia.

BACKGROUND: Alternative sequence alignment algorithms yield different results. It
is therefore useful to quantify the similarities and differences between
alternative alignments of the same sequences. These measurements can identify
regions of consensus that are likely to be most informative in downstream
analysis. They can also highlight systematic differences between alignments that 
relate to differences in the alignment algorithms themselves.
RESULTS: Here we present a simple method for aligning two alternative multiple
sequence alignments to one another and assessing their similarity. Differences
are categorised into merges, splits or shifts in one alignment relative to the
other. A set of graphical visualisations allow for intuitive interpretation of
the data.
CONCLUSIONS: AlignStat enables the easy one-off online use of MSA similarity
comparisons or into R pipelines. The web-tool is available at
AlignStat.Science.LaTrobe.edu.au. The R package, readme and example data are
available on CRAN and GitHub.com/TS404/AlignStat.

DOI: 10.1186/s12859-016-1300-6 
PMCID: PMC5081975
PMID: 27784265  [PubMed - in process]


224. BMC Bioinformatics. 2016 Oct 26;17(1):433.

TRIg: a robust alignment pipeline for non-regular T-cell receptor and
immunoglobulin sequences.

Hung SJ(1), Chen YL(2,)(3), Chu CH(1), Lee CC(2,)(3), Chen WL(2,)(3), Lin
YL(2,)(3), Lin MC(2,)(3), Ho CL(2,)(3), Liu T(4).

Author information: 
(1)Department of Biotechnology and Bioindustry Sciences, National Cheng Kung
University, Tainan City, Taiwan. (2)Molecular Diagnostic Laboratory, Department
of Pathology, National Cheng Kung University Hospital, Tainan City, Taiwan.
(3)Molecular Medicine Core Laboratory, Research Center of Clinical Medicine,
National Cheng Kung University Hospital, Tainan City, Taiwan. (4)Department of
Biotechnology and Bioindustry Sciences, National Cheng Kung University, Tainan
City, Taiwan. tsunglin@mail.ncku.edu.tw.

BACKGROUND: T cells and B cells are essential in the adaptive immunity via
expressing T cell receptors and immunoglogulins respectively for recognizing
antigens. To recognize a wide variety of antigens, a highly diverse repertoire of
receptors is generated via complex recombination of the receptor genes.
Reasonably, frequencies of the recombination events have been shown to predict
immune diseases and provide insights into the development of immunity. The field 
is further boosted by high-throughput sequencing and several computational tools 
have been released to analyze the recombined sequences. However, all current
tools assume regular recombination of the receptor genes, which is not always
valid in data prepared using a RACE approach. Compared to the traditional
multiplex PCR approach, RACE is free of primer bias, therefore can provide
accurate estimation of recombination frequencies. To handle the non-regular
recombination events, a new computational program is needed.
RESULTS: We propose TRIg to handle non-regular T cell receptor and immunoglobulin
sequences. Unlike all current programs, TRIg does alignments to the whole
receptor gene instead of only to the coding regions. This brings new
computational challenges, e.g., ambiguous alignments due to multiple hits to
repetitive regions. To reduce ambiguity, TRIg applies a heuristic strategy and
incorporates gene annotation to identify authentic alignments. On our own and
public RACE datasets, TRIg correctly identified non-regularly recombined
sequences, which could not be achieved by current programs. TRIg also works well 
for regularly recombined sequences.
CONCLUSIONS: TRIg takes into account non-regular recombination of T cell receptor
and immunoglobulin genes, therefore is suitable for analyzing RACE data. Such
analysis will provide accurate estimation of recombination events, which will
benefit various immune studies directly. In addition, TRIg is suitable for
studying aberrant recombination in immune diseases. TRIg is freely available at
https://github.com/TLlab/trig .

DOI: 10.1186/s12859-016-1304-2 
PMCID: PMC5080739
PMID: 27782801  [PubMed - in process]


225. J Exp Zool B Mol Dev Evol. 2016 Nov;326(7):394-402. doi: 10.1002/jez.b.22707.
Epub 2016 Oct 26.

TreeExp1.0: R Package for Analyzing Expression Evolution Based on RNA-Seq Data.

Ruan H(1), Su Z(1), Gu X(1,)(2).

Author information: 
(1)State Key Laboratory of Genetic Engineering, MOE Key Laboratory of
Contemporary Anthropology, and Collaborative Innovation Center of Genetics and
Development, School of Life Sciences, Fudan University, Shanghai, China.
(2)Department of Genetics, Development and Cell Biology, Iowa State University,
Ames, Iowa.

Recent innovation of RNA-seq technology has shed insightful light on the
transcriptomic evolution studies, especially on researches of tissue-specific
expression evolution. Phylogenetic analysis of transcriptome data may help to
identify causal gene expression differences underlying the evolutionary changes
in morphological, physiological, and developmental characters of interest.
However, there is a deficiency of software to phylogenetically analyze
transcriptome data. To address this need, we have developed an R package TreeExp 
that can perform comparative expression evolution analysis based on RNA-seq data,
which includes optimized input formatting, normalization, pairwise expression
distance estimation, expression character tree inference, and preliminary
expression phylogenetic network analysis. TreeExp also enables user to map
expression distance onto a customized phylogenetic tree. By applying TreeExp on
two cases of mammalian gene expression evolution, we observed that (1) expression
trees of brain and testis are largely consistent with known mammalian species
tree with minor discrepancies; (2) intertissues expression divergences (brain and
testis) are more substantial than interspecies expression divergences across
mammalian species; and (3) expression pattern of gene modules related to nervous 
system development exhibits specific expression pattern in brain of primates
compared to housekeeping genes. These tissue-specific expression patterns might
give insights underlying evo-devo mechanisms of complex organisms. TreeExp is
released under the GPL v3 open source license, and its current stable version 1.0
is freely available at the Github developer site
(https://github.com/hr1912/TreeExp).

© 2016 Wiley Periodicals, Inc.

DOI: 10.1002/jez.b.22707 
PMID: 27781409  [PubMed - in process]


226. PeerJ. 2016 Oct 18;4:e2584. eCollection 2016.

VSEARCH: a versatile open source tool for metagenomics.

Rognes T(1), Flouri T(2), Nichols B(3), Quince C(4), Mahé F(5).

Author information: 
(1)Department of Informatics, University of Oslo, Oslo, Norway; Department of
Microbiology, Oslo University Hospital, Oslo, Norway. (2)Heidelberg Institute for
Theoretical Studies, Heidelberg, Germany; Institute for Theoretical Informatics, 
Karlsruhe Institute of Technology, Karlsruhe, Germany. (3)School of Engineering, 
University of Glasgow , Glasgow , United Kingdom. (4)School of Engineering,
University of Glasgow, Glasgow, United Kingdom; Warwick Medical School,
University of Warwick, Coventry, United Kingdom. (5)Department of Ecology,
University of Kaiserslautern, Kaiserslautern, Germany; UMR LSTM, CIRAD,
Montpellier, France.

BACKGROUND: VSEARCH is an open source and free of charge multithreaded 64-bit
tool for processing and preparing metagenomics, genomics and population genomics 
nucleotide sequence data. It is designed as an alternative to the widely used
USEARCH tool (Edgar, 2010) for which the source code is not publicly available,
algorithm details are only rudimentarily described, and only a memory-confined
32-bit version is freely available for academic use.
METHODS: When searching nucleotide sequences, VSEARCH uses a fast heuristic based
on words shared by the query and target sequences in order to quickly identify
similar sequences, a similar strategy is probably used in USEARCH. VSEARCH then
performs optimal global sequence alignment of the query against potential target 
sequences, using full dynamic programming instead of the seed-and-extend
heuristic used by USEARCH. Pairwise alignments are computed in parallel using
vectorisation and multiple threads.
RESULTS: VSEARCH includes most commands for analysing nucleotide sequences
available in USEARCH version 7 and several of those available in USEARCH version 
8, including searching (exact or based on global alignment), clustering by
similarity (using length pre-sorting, abundance pre-sorting or a user-defined
order), chimera detection (reference-based or de novo), dereplication (full
length or prefix), pairwise alignment, reverse complementation, sorting, and
subsampling. VSEARCH also includes commands for FASTQ file processing, i.e.,
format detection, filtering, read quality statistics, and merging of paired
reads. Furthermore, VSEARCH extends functionality with several new commands and
improvements, including shuffling, rereplication, masking of low-complexity
sequences with the well-known DUST algorithm, a choice among different similarity
definitions, and FASTQ file format conversion. VSEARCH is here shown to be more
accurate than USEARCH when performing searching, clustering, chimera detection
and subsampling, while on a par with USEARCH for paired-ends read merging.
VSEARCH is slower than USEARCH when performing clustering and chimera detection, 
but significantly faster when performing paired-end reads merging and
dereplication. VSEARCH is available at https://github.com/torognes/vsearch under 
either the BSD 2-clause license or the GNU General Public License version 3.0.
DISCUSSION: VSEARCH has been shown to be a fast, accurate and full-fledged
alternative to USEARCH. A free and open-source versatile tool for sequence
analysis is now available to the metagenomics community.

DOI: 10.7717/peerj.2584 
PMCID: PMC5075697
PMID: 27781170  [PubMed - in process]


227. Sci Data. 2016 Oct 25;3:160096. doi: 10.1038/sdata.2016.96.

A database of human exposomes and phenomes from the US National Health and
Nutrition Examination Survey.

Patel CJ(1), Pho N(1), McDuffie M(1), Easton-Marks J(1), Kothari C(1), Kohane
IS(1), Avillach P(1).

Author information: 
(1)Department of Biomedical Informatics, Harvard Medical School, 10 Shattuck St.,
Boston, Massachusetts 02115, USA.

The National Health and Nutrition Examination Survey (NHANES) is a population
survey implemented by the Centers for Disease Control and Prevention (CDC) to
monitor the health of the United States whose data is publicly available in
hundreds of files. This Data Descriptor describes a single unified and
universally accessible data file, merging across 255 separate files and stitching
data across 4 surveys, encompassing 41,474 individuals and 1,191 variables. The
variables consist of phenotype and environmental exposure information on each
individual, specifically (1) demographic information, physical exam results
(e.g., height, body mass index), laboratory results (e.g., cholesterol, glucose, 
and environmental exposures), and (4) questionnaire items. Second, the data
descriptor describes a dictionary to enable analysts find variables by category
and human-readable description. The datasets are available on DataDryad and a
hands-on analytics tutorial is available on GitHub. Through a new big data
platform, BD2K Patient Centered Information Commons (http://pic-sure.org), we
provide a new way to browse the dataset via a web browser
(https://nhanes.hms.harvard.edu) and provide application programming interface
for programmatic access.

DOI: 10.1038/sdata.2016.96 
PMCID: PMC5079122
PMID: 27779619  [PubMed - indexed for MEDLINE]


228. J Chem Inf Model. 2016 Oct 24;56(10):2013-2023. Epub 2016 Sep 26.

OCEAN: Optimized Cross rEActivity estimatioN.

Czodrowski P(1), Bolick WG(1).

Author information: 
(1)Discovery Technologies, Merck Serono Research, Merck KGaA , Frankfurter Straße
250, 64293 Darmstadt, Germany.

The prediction of molecular targets is highly beneficial during the drug
discovery process, be it for off-target elucidation or deconvolution of
phenotypic screens. Here, we present OCEAN, a target prediction tool exclusively 
utilizing publically available ChEMBL data. OCEAN uses a heuristics approach
based on a validation set containing almost 1000 drug ← → target relationships.
New ChEMBL data (ChEMBL20 as well as ChEMBL21) released after the validation was 
used for a prospective OCEAN performance check. The success rates of OCEAN to
predict correctly the targets within the TOP10 ranks are 77% for recently
marketed drugs and 62% for all new ChEMBL20 compounds and 51% for all new
ChEMBL21 compounds. OCEAN is also capable of identifying polypharmacological
compounds; the success rate for molecules simultaneously hitting at least two
targets is 64% to be correctly predicted within the TOP10 ranks. The source code 
of OCEAN can be found at http://www.github.com/rdkit/OCEAN.

DOI: 10.1021/acs.jcim.6b00067 
PMID: 27668814  [PubMed - in process]


229. J Proteomics. 2017 Jan 6;150:170-182. doi: 10.1016/j.jprot.2016.08.002. Epub 2016
Aug 4.

In-depth analysis of protein inference algorithms using multiple search engines
and well-defined metrics.

Audain E(1), Uszkoreit J(2), Sachsenberg T(3), Pfeuffer J(4), Liang X(4),
Hermjakob H(5), Sanchez A(6), Eisenacher M(2), Reinert K(4), Tabb DL(7),
Kohlbacher O(8), Perez-Riverol Y(9).

Author information: 
(1)Department of Proteomics, Center of Molecular Immunology, Ciudad de la Habana,
Cuba; Center for Bioinformatics, Quantitative Biology Center and Department of
Computer Science, University of Tübingen, Sand 14, 72076 Tübingen, Germany.
(2)Medizinisches Proteom-Center, Ruhr-Universität Bochum, Universitätsstr. 150,
D-44801 Bochum, Germany. (3)Center for Bioinformatics, Quantitative Biology
Center and Department of Computer Science, University of Tübingen, Sand 14, 72076
Tübingen, Germany. (4)Algorithmic Bioinformatics, Institut für Informatik, Freie 
Universität Berlin, Takustraße 9, 14195 Berlin, Germany. (5)European Molecular
Biology Laboratory, European Bioinformatics Institute (EMBL- EBI), Wellcome Trust
Genome Campus, Hinxton, Cambridge CB10 1SD, UK; National Center for Protein
Sciences Beijing, No. 38, Life Science Park Road, Changping District, 102206
Beijing. (6)Department of Translational Medicine, Faculty of Medicine, Lund
University Malmo, Sweden. (7)Department of Biomedical Informatics, Vanderbilt
University School of Medicine, Nashville, TN 37232, United States. (8)Center for 
Bioinformatics, Quantitative Biology Center and Department of Computer Science,
University of Tübingen, Sand 14, 72076 Tübingen, Germany; Biomolecular
Interactions, Max Planck Institute for Developmental Biology, Spemannstr. 35,
72076 Tübingen, Germany. (9)European Molecular Biology Laboratory, European
Bioinformatics Institute (EMBL- EBI), Wellcome Trust Genome Campus, Hinxton,
Cambridge CB10 1SD, UK. Electronic address: yperez@ebi.ac.uk.

In mass spectrometry-based shotgun proteomics, protein identifications are
usually the desired result. However, most of the analytical methods are based on 
the identification of reliable peptides and not the direct identification of
intact proteins. Thus, assembling peptides identified from tandem mass spectra
into a list of proteins, referred to as protein inference, is a critical step in 
proteomics research. Currently, different protein inference algorithms and tools 
are available for the proteomics community. Here, we evaluated five software
tools for protein inference (PIA, ProteinProphet, Fido, ProteinLP, MSBayesPro)
using three popular database search engines: Mascot, X!Tandem, and MS-GF+. All
the algorithms were evaluated using a highly customizable KNIME workflow using
four different public datasets with varying complexities (different sample
preparation, species and analytical instruments). We defined a set of quality
control metrics to evaluate the performance of each combination of search
engines, protein inference algorithm, and parameters on each dataset. We show
that the results for complex samples vary not only regarding the actual numbers
of reported protein groups but also concerning the actual composition of groups. 
Furthermore, the robustness of reported proteins when using databases of
differing complexities is strongly dependant on the applied inference algorithm. 
Finally, merging the identifications of multiple search engines does not
necessarily increase the number of reported proteins, but does increase the
number of peptides per protein and thus can generally be
recommended.SIGNIFICANCE: Protein inference is one of the major challenges in
MS-based proteomics nowadays. Currently, there are a vast number of protein
inference algorithms and implementations available for the proteomics community. 
Protein assembly impacts in the final results of the research, the quantitation
values and the final claims in the research manuscript. Even though protein
inference is a crucial step in proteomics data analysis, a comprehensive
evaluation of the many different inference methods has never been performed.
Previously Journal of proteomics has published multiple studies about other
benchmark of bioinformatics algorithms (PMID: 26585461; PMID: 22728601) in
proteomics studies making clear the importance of those studies for the
proteomics community and the journal audience. This manuscript presents a new
bioinformatics solution based on the KNIME/OpenMS platform that aims at providing
a fair comparison of protein inference algorithms
(https://github.com/KNIME-OMICS). Six different algorithms - ProteinProphet,
MSBayesPro, ProteinLP, Fido and PIA- were evaluated using the highly customizable
workflow on four public datasets with varying complexities. Five popular database
search engines Mascot, X!Tandem, MS-GF+ and combinations thereof were evaluated
for every protein inference tool. In total >186 proteins lists were analyzed and 
carefully compare using three metrics for quality assessments of the protein
inference results: 1) the numbers of reported proteins, 2) peptides per protein, 
and the 3) number of uniquely reported proteins per inference method, to address 
the quality of each inference method. We also examined how many proteins were
reported by choosing each combination of search engines, protein inference
algorithms and parameters on each dataset. The results show that using 1) PIA or 
Fido seems to be a good choice when studying the results of the analyzed
workflow, regarding not only the reported proteins and the high-quality
identifications, but also the required runtime. 2) Merging the identifications of
multiple search engines gives almost always more confident results and increases 
the number of peptides per protein group. 3) The usage of databases containing
not only the canonical, but also known isoforms of proteins has a small impact on
the number of reported proteins. The detection of specific isoforms could,
concerning the question behind the study, compensate for slightly shorter reports
using the parsimonious reports. 4) The current workflow can be easily extended to
support new algorithms and search engine combinations.

Copyright © 2016. Published by Elsevier B.V.

DOI: 10.1016/j.jprot.2016.08.002 
PMID: 27498275  [PubMed - in process]


230. BMC Bioinformatics. 2016 Oct 6;17(Suppl 13):337.

PGen: large-scale genomic variations analysis workflow and browser in SoyKB.

Liu Y(1,)(2), Khan SM(1,)(2), Wang J(2,)(3), Rynge M(4), Zhang Y(3), Zeng
S(2,)(3), Chen S(2,)(3), Maldonado Dos Santos JV(5), Valliyodan B(5,)(6), Calyam 
PP(3), Merchant N(7), Nguyen HT(5,)(6), Xu D(1,)(2,)(3), Joshi
T(8,)(9,)(10,)(11).

Author information: 
(1)Informatics Institute, University of Missouri, Columbia, MO, USA.
(2)Christopher S. Bond Life Sciences Center, University of Missouri, Columbia,
MO, USA. (3)Department of Computer Science, University of Missouri, Columbia, MO,
USA. (4)Information Sciences Institute, University of Southern California, Los
Angeles, CA, USA. (5)Division of Plant Sciences, University of Missouri,
Columbia, MO, USA. (6)National Center of Soybean Biotechnology, Columbia, MO,
USA. (7)iPlant Collaborative, University of Arizona, Tucson, AZ, USA.
(8)Informatics Institute, University of Missouri, Columbia, MO, USA.
joshitr@missouri.edu. (9)Christopher S. Bond Life Sciences Center, University of 
Missouri, Columbia, MO, USA. joshitr@missouri.edu. (10)Department of Computer
Science, University of Missouri, Columbia, MO, USA. joshitr@missouri.edu.
(11)Department of Molecular Microbiology and Immunology and Office of Research,
School of Medicine, University of Missouri, Columbia, MO, USA.
joshitr@missouri.edu.

BACKGROUND: With the advances in next-generation sequencing (NGS) technology and 
significant reductions in sequencing costs, it is now possible to sequence large 
collections of germplasm in crops for detecting genome-scale genetic variations
and to apply the knowledge towards improvements in traits. To efficiently
facilitate large-scale NGS resequencing data analysis of genomic variations, we
have developed "PGen", an integrated and optimized workflow using the Extreme
Science and Engineering Discovery Environment (XSEDE) high-performance computing 
(HPC) virtual system, iPlant cloud data storage resources and Pegasus workflow
management system (Pegasus-WMS). The workflow allows users to identify single
nucleotide polymorphisms (SNPs) and insertion-deletions (indels), perform SNP
annotations and conduct copy number variation analyses on multiple resequencing
datasets in a user-friendly and seamless way.
RESULTS: We have developed both a Linux version in GitHub (
https://github.com/pegasus-isi/PGen-GenomicVariations-Workflow ) and a web-based 
implementation of the PGen workflow integrated within the Soybean Knowledge Base 
(SoyKB), ( http://soykb.org/Pegasus/index.php ). Using PGen, we identified
10,218,140 single-nucleotide polymorphisms (SNPs) and 1,398,982 indels from
analysis of 106 soybean lines sequenced at 15X coverage. 297,245 non-synonymous
SNPs and 3330 copy number variation (CNV) regions were identified from this
analysis. SNPs identified using PGen from additional soybean resequencing
projects adding to 500+ soybean germplasm lines in total have been integrated.
These SNPs are being utilized for trait improvement using genotype to phenotype
prediction approaches developed in-house. In order to browse and access NGS data 
easily, we have also developed an NGS resequencing data browser (
http://soykb.org/NGS_Resequence/NGS_index.php ) within SoyKB to provide easy
access to SNP and downstream analysis results for soybean researchers.
CONCLUSION: PGen workflow has been optimized for the most efficient analysis of
soybean data using thorough testing and validation. This research serves as an
example of best practices for development of genomics data analysis workflows by 
integrating remote HPC resources and efficient data management with ease of use
for biological users. PGen workflow can also be easily customized for analysis of
data in other species.

DOI: 10.1186/s12859-016-1227-y 
PMCID: PMC5074001
PMID: 27766951  [PubMed - in process]


231. Neuroimage. 2016 Oct 18. pii: S1053-8119(16)30581-X. doi:
10.1016/j.neuroimage.2016.10.027. [Epub ahead of print]

Manual segmentation of the fornix, fimbria, and alveus on high-resolution 3T MRI:
Application via fully-automated mapping of the human memory circuit white and
grey matter in healthy and pathological aging.

Amaral RS(1), Park MT(2), Devenyi GA(3), Lynn V(4), Pipitone J(5), Winterburn
J(6), Chavez S(7), Schira M(8), Lobaugh NJ(9), Voineskos AN(10), Pruessner
JC(11), Chakravarty MM(12); Alzheimer’s Disease Neuroimaging Initiative.

Author information: 
(1)Computational Brain Anatomy Laboratory, Cerebral Imaging Centre, Douglas
Mental Health University Institute, Montreal, Canada; Integrated Program in
Neuroscience, McGill University, Montreal, Canada. Electronic address:
robert.s.c.amaral@gmail.com. (2)Computational Brain Anatomy Laboratory, Cerebral 
Imaging Centre, Douglas Mental Health University Institute, Montreal, Canada;
Schulich School of Medicine and Dentistry, Western University, London, Canada.
(3)Computational Brain Anatomy Laboratory, Cerebral Imaging Centre, Douglas
Mental Health University Institute, Montreal, Canada; Department of Psychiatry,
McGill University, Montreal, Canada. (4)Computational Brain Anatomy Laboratory,
Cerebral Imaging Centre, Douglas Mental Health University Institute, Montreal,
Canada. (5)Kimel Family Translational Imaging-Genetics Laboratory, Campbell
Family Mental Health Institute, CAMH, Toronto, Canada. (6)Computational Brain
Anatomy Laboratory, Cerebral Imaging Centre, Douglas Mental Health University
Institute, Montreal, Canada; Institute of Biomaterials and Biomedical
Engineering, University of Toronto, Canada. (7)Department of Psychiatry,
University of Toronto, Toronto, Canada; MRI Unit, Research Imaging Centre, Centre
for Addiction and Mental Health, Toronto, Canada. (8)School of Psychology,
University of Wollongong, Wollongong, NSW, Australia; Neuroscience Research
Australia, Sydney, NSW, Australia. (9)MRI Unit, Research Imaging Centre, Centre
for Addiction and Mental Health, Toronto, Canada; Division of Neurology,
Department of Medicine, University of Toronto, Toronto, Canada. (10)Kimel Family 
Translational Imaging-Genetics Laboratory, Campbell Family Mental Health
Institute, CAMH, Toronto, Canada; Department of Psychiatry, University of
Toronto, Toronto, Canada. (11)McGill Centre for Studies in Aging, McGill
University, Montreal, Canada. (12)Computational Brain Anatomy Laboratory,
Cerebral Imaging Centre, Douglas Mental Health University Institute, Montreal,
Canada; Integrated Program in Neuroscience, McGill University, Montreal, Canada; 
Department of Psychiatry, McGill University, Montreal, Canada; Department of
Biological and Biomedical Engineering, McGill University, Montreal, Canada.
Electronic address: mallar@cobralab.ca.

Recently, much attention has been focused on the definition and structure of the 
hippocampus and its subfields, while the projections from the hippocampus have
been relatively understudied. Here, we derive a reliable protocol for manual
segmentation of hippocampal white matter regions (alveus, fimbria, and fornix)
using high-resolution magnetic resonance images that are complementary to our
previous definitions of the hippocampal subfields, both of which are freely
available at https://github.com/cobralab/atlases. Our segmentation methods
demonstrated high inter- and intra-rater reliability, were validated as inputs in
automated segmentation, and were used to analyze the trajectory of these regions 
in both healthy aging (OASIS), and Alzheimer's disease (AD) and mild cognitive
impairment (MCI; using ADNI). We observed significant bilateral decreases in the 
fornix in healthy aging while the alveus and cornu ammonis (CA) 1 were well
preserved (all p's<0.006). MCI and AD demonstrated significant decreases in
fimbriae and fornices. Many hippocampal subfields exhibited decreased volume in
both MCI and AD, yet no significant differences were found between MCI and AD
cohorts themselves. Our results suggest a neuroprotective or compensatory role
for the alveus and CA1 in healthy aging and suggest that an improved
understanding of the volumetric trajectories of these structures is required.

Copyright © 2016 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2016.10.027 
PMID: 27765611  [PubMed - as supplied by publisher]


232. J Proteome Res. 2016 Dec 2;15(12):4747-4754. Epub 2016 Oct 21.

APOSTL: An Interactive Galaxy Pipeline for Reproducible Analysis of Affinity
Proteomics Data.

Kuenzi BM(1,)(2), Borne AL(3), Li J(4), Haura EB(3), Eschrich SA(4), Koomen
JM(5), Rix U(1), Stewart PA(3).

Author information: 
(1)Department of Drug Discovery, H. Lee Moffitt Cancer Center & Research
Institute , Tampa, Florida 33612-9497, United States. (2)Cancer Biology Ph.D.
Program, University of South Florida , Tampa, Florida 33620, United States.
(3)Department of Thoracic Oncology, H. Lee Moffitt Cancer Center & Research
Institute , Tampa, Florida 33612-9497, United States. (4)Department of
Biostatistics and Bioinformatics, H. Lee Moffitt Cancer Center & Research
Institute , Tampa, Florida 33612-9497, United States. (5)Molecular Oncology, H.
Lee Moffitt Cancer Center & Research Institute , Tampa, Florida 33612-9497,
United States.

With continuously increasing scale and depth of coverage in affinity proteomics
(AP-MS) data, the analysis and visualization is becoming more challenging. A
number of tools have been developed to identify high-confidence interactions;
however, a cohesive and intuitive pipeline for analysis and visualization is
still needed. Here we present Automated Processing of SAINT Templated Layouts
(APOSTL), a freely available Galaxy-integrated software suite and analysis
pipeline for reproducible, interactive analysis of AP-MS data. APOSTL contains a 
number of tools woven together using Galaxy workflows, which are intuitive for
the user to move from raw data to publication-quality figures within a single
interface. APOSTL is an evolving software project with the potential to customize
individual analyses with additional Galaxy tools and widgets using the R web
application framework, Shiny. The source code, data, and documentation are freely
available from GitHub ( https://github.com/bornea/APOSTL ) and other sources.

DOI: 10.1021/acs.jproteome.6b00660 
PMCID: PMC5231908 [Available on 2017-12-02]
PMID: 27680298  [PubMed - in process]


233. BMC Bioinformatics. 2016 Oct 19;17(1):425.

Convert your favorite protein modeling program into a mutation predictor:
"MODICT".

Tanyalcin I(1,)(2), Stouffs K(3), Daneels D(3), Al Assaf C(4), Lissens W(3),
Jansen A(5,)(6,)(7), Gheldof A(3).

Author information: 
(1)Center for Medical Genetics, UZ Brussel, Laarbeeklaan 101, Brussel, 1090,
Belgium. itanyalc@vub.ac.be. (2)Neurogenetics Research Group, Reproduction
Genetics and Regenerative Medicine Research Group, Vrije Universiteit Brussel
(VUB), Laarbeeklaan 101, Brussel, 1090, Belgium. itanyalc@vub.ac.be. (3)Center
for Medical Genetics, Reproduction and Genetics, Reproduction Genetics and
Regenerative Medicine, Vrije Universiteit Brussel (VUB), UZ Brussel, Laarbeeklaan
101, Brussel, 1090, Belgium. (4)Center for Human Genetics, KU Leuven and
University Hospitals Leuven, Herestraat 49, Leuven, 3000, Belgium. (5)Center for 
Medical Genetics, UZ Brussel, Laarbeeklaan 101, Brussel, 1090, Belgium.
(6)Neurogenetics Research Group, Reproduction Genetics and Regenerative Medicine 
Research Group, Vrije Universiteit Brussel (VUB), Laarbeeklaan 101, Brussel,
1090, Belgium. (7)Pediatric Neurology Unit, Department of Pediatrics, UZ Brussel,
Laarbeeklaan 101, Brussel, 1090, Belgium.

BACKGROUND: Predict whether a mutation is deleterious based on the custom 3D
model of a protein.
RESULTS: We have developed MODICT, a mutation prediction tool which is based on
per residue RMSD (root mean square deviation) values of superimposed 3D protein
models. Our mathematical algorithm was tested for 42 described mutations in
multiple genes including renin (REN), beta-tubulin (TUBB2B), biotinidase (BTD),
sphingomyelin phosphodiesterase-1 (SMPD1), phenylalanine hydroxylase (PAH) and
medium chain Acyl-Coa dehydrogenase (ACADM). Moreover, MODICT scores corresponded
to experimentally verified residual enzyme activities in mutated biotinidase,
phenylalanine hydroxylase and medium chain Acyl-CoA dehydrogenase. Several
commercially available prediction algorithms were tested and results were
compared. The MODICT PERL package and the manual can be downloaded from
https://github.com/IbrahimTanyalcin/MODICT .
CONCLUSIONS: We show here that MODICT is capable tool for mutation effect
prediction at the protein level, using superimposed 3D protein models instead of 
sequence based algorithms used by POLYPHEN and SIFT.

DOI: 10.1186/s12859-016-1286-0 
PMCID: PMC5070100
PMID: 27760515  [PubMed - in process]


234. Biostatistics. 2016 Oct 17. pii: kxw041. [Epub ahead of print]

False discovery rates: a new deal.

Stephens M(1).

Author information: 
(1)Department of Statistics and Department of Human Genetics, University of
Chicago, 5801 S Ellis Ave, Chicago, IL 60637 USA mstephens@uchicago.edu.

SummaryWe introduce a new Empirical Bayes approach for large-scale hypothesis
testing, including estimating false discovery rates (FDRs), and effect sizes.
This approach has two key differences from existing approaches to FDR analysis.
First, it assumes that the distribution of the actual (unobserved) effects is
unimodal, with a mode at 0. This "unimodal assumption" (UA), although natural in 
many contexts, is not usually incorporated into standard FDR analysis, and we
demonstrate how incorporating it brings many benefits. Specifically, the UA
facilitates efficient and robust computation-estimating the unimodal distribution
involves solving a simple convex optimization problem-and enables more accurate
inferences provided that it holds. Second, the method takes as its input two
numbers for each test (an effect size estimate and corresponding standard error),
rather than the one number usually used ([Formula: see text] value or [Formula:
see text] score). When available, using two numbers instead of one helps account 
for variation in measurement precision across tests. It also facilitates
estimation of effects, and unlike standard FDR methods, our approach provides
interval estimates (credible regions) for each effect in addition to measures of 
significance. To provide a bridge between interval estimates and significance
measures, we introduce the term "local false sign rate" to refer to the
probability of getting the sign of an effect wrong and argue that it is a
superior measure of significance than the local FDR because it is both more
generally applicable and can be more robustly estimated. Our methods are
implemented in an R package ashr available from
http://github.com/stephens999/ashr.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/biostatistics/kxw041 
PMID: 27756721  [PubMed - as supplied by publisher]


235. PLoS One. 2016 Oct 18;11(10):e0164726. doi: 10.1371/journal.pone.0164726.
eCollection 2016.

Accurate Classification of RNA Structures Using Topological Fingerprints.

Huang J(1,)(2), Li K(1,)(3), Gribskov M(1,)(4).

Author information: 
(1)Department of Biological Sciences, Purdue University, West Lafayette, Indiana,
United States of America. (2)Life Sciences Solutions Group, Thermo Fisher
Scientific, South San Francisco, California, United States of America.
(3)Computational Biology Department, Biogen Idec, Cambridge, Massachusetts,
United States of America. (4)Department of Computer Science, Purdue University,
West Lafayette, Indiana, United States of America.

While RNAs are well known to possess complex structures, functionally similar
RNAs often have little sequence similarity. While the exact size and spacing of
base-paired regions vary, functionally similar RNAs have pronounced similarity in
the arrangement, or topology, of base-paired stems. Furthermore, predicted RNA
structures often lack pseudoknots (a crucial aspect of biological activity), and 
are only partially correct, or incomplete. A topological approach addresses all
of these difficulties. In this work we describe each RNA structure as a graph
that can be converted to a topological spectrum (RNA fingerprint). The set of
subgraphs in an RNA structure, its RNA fingerprint, can be compared with the
fingerprints of other RNA structures to identify and correctly classify
functionally related RNAs. Topologically similar RNAs can be identified even when
a large fraction, up to 30%, of the stems are omitted, indicating that highly
accurate structures are not necessary. We investigate the performance of the RNA 
fingerprint approach on a set of eight highly curated RNA families, with diverse 
sizes and functions, containing pseudoknots, and with little sequence
similarity-an especially difficult test set. In spite of the difficult test set, 
the RNA fingerprint approach is very successful (ROC AUC > 0.95). Due to the
inclusion of pseudoknots, the RNA fingerprint approach both covers a wider range 
of possible structures than methods based only on secondary structure, and its
tolerance for incomplete structures suggests that it can be applied even to
predicted structures. Source code is freely available at
https://github.rcac.purdue.edu/mgribsko/XIOS_RNA_fingerprint.

DOI: 10.1371/journal.pone.0164726 
PMCID: PMC5068708
PMID: 27755571  [PubMed - in process]


236. Mol Ecol Resour. 2016 Oct 18. doi: 10.1111/1755-0998.12609. [Epub ahead of print]

swinger: a user-friendly computer program to establish captive breeding groups
that minimize relatedness without pedigree information.

Sandoval-Castillo J(1), Attard CR(1,)(2), Marri S(3), Brauer CJ(1), Möller
LM(1,)(2), Beheregaray LB(1).

Author information: 
(1)Molecular Ecology Lab, School of Biological Sciences, Flinders University, GPO
Box 2100, Adelaide, SA, 5001, Australia. (2)Cetacean Ecology, Behaviour and
Evolution Lab, School of Biological Sciences, Flinders University, GPO Box 2100, 
Adelaide, SA, 5001, Australia. (3)Flinders Genomics Facility, Flinders
University, GPO Box 2100, Adelaide, SA, 5001, Australia.

Captive breeding programmes are often a necessity for the continued persistence
of a population or species. They typically have the goal of maintaining genetic
diversity and minimizing inbreeding. However, most captive breeding programmes
have been based on the assumption that the founding breeders are unrelated and
outbred, even though in situ anthropogenic impacts often mean these founders may 
have high relatedness and substantial inbreeding. In addition, polygamous
group-breeding species in captivity often have uncertain pedigrees, making it
difficult to select the group composition for subsequent breeding.
Molecular-based estimates of relatedness and inbreeding may instead be used to
select breeding groups (≥two individuals) that minimize relatedness and filter
out inbred individuals. swinger constructs breeding groups based on molecular
estimates of relatedness and inbreeding. The number of possible combinations of
breeding groups quickly becomes intractable by hand. swinger was designed to
overcome this major issue in ex situ conservation biology. The user can specify
parameters within swinger to reach breeding solutions that suit the mating system
of the target species and available resources. We provide evidence of the
efficiency of the software with an empirical example and using simulations. The
only data required are a typical molecular marker data set, such as a
microsatellite or SNP data set, from which estimates of inbreeding and pairwise
relatedness may be obtained. Such molecular data sets are becoming easier to
gather from non-model organisms with next-generation sequencing technology.
swinger is an open-source software with a user-friendly interface and
is available at
http://www.molecularecology.flinders.edu.au/molecular-ecology-lab/software/swinge
r/swinger/ and https://github.com/Yuma248/Swinger.

© 2016 John Wiley & Sons Ltd.

DOI: 10.1111/1755-0998.12609 
PMID: 27754599  [PubMed - as supplied by publisher]


237. Bioinformatics. 2016 Oct 14. pii: btw645. [Epub ahead of print]

CloudPhylo: a fast and scalable tool for phylogeny reconstruction.

Xu X(1,)(2,)(3), Ji Z(4,)(5,)(6), Zhang Z(1,)(2).

Author information: 
(1)CAS Key Laboratory of Genome Sciences and Information. (2)BIG Data Center,
Beijing Institute of Genomics (BIG), Chinese Academy of Sciences (CAS), Beijing
100101, China. (3)University of Chinese Academy of Sciences, Beijing 100101,
China. (4)College of Computer and Information Engineering, Inner Mongolia Normal 
University, Hohhot 010010, China. (5)College of Environment and Energy
Engineering, Beijing University of Technology, Beijing 100124, China. (6)Inner
Mongolia Xing'an Vocational and Technical College, Wulanhaote 137400, China.

Phylogeny reconstruction is fundamentally crucial for molecular evolutionary
studies but remains computationally challenging. Here we present CloudPhylo, a
tool built on Spark that is capable of processing large-scale datasets for
phylogeny reconstruction. As testified on empirical data, CloudPhylo is well
suited for big data analysis, achieving high efficiency and good scalability on
phylogenetic tree inference.AVAILABILITY AND IMPLEMENTATION:
https://github.com/XingjianXu/cloudphylo CONTACT:
zhangzhang@big.ac.cnSupplementary information: Supplementary data are available
at Bioinformatics online.

© The Authors 2016. Published by Oxford University Press. All rights reserved.
For Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw645 
PMID: 27742698  [PubMed - as supplied by publisher]


238. Bioinformatics. 2016 Oct 14. pii: btw643. doi: 10.1093/bioinformatics/btw643.
[Epub ahead of print]

Visualizing the geography of genetic variants.

Marcus JH(1), Novembre J(1,)(2).

Author information: 
(1)Department of Human Genetics. (2)Department of Ecology and Evolution,
University of Chicago, Chicago, 60637, USA.

One of the key characteristics of any genetic variant is its geographic
distribution. The geographic distribution can shed light on where an allele first
arose, what populations it has spread to, and in turn on how migration, genetic
drift, and natural selection have acted. The geographic distribution of a genetic
variant can also be of great utility for medical/clinical geneticists and
collectively many genetic variants can reveal population structure. Here we
develop an interactive visualization tool for rapidly displaying the geographic
distribution of genetic variants. Through a REST API and dynamic front-end, the
Geography of Genetic Variants (GGV) browser (http://popgen.uchicago.edu/ggv/)
provides maps of allele frequencies in populations distributed across the
globe.AVAILABILITY AND IMPLEMENTATION: GGV is implemented as a website
(http://popgen.uchicago.edu/ggv/) which employs an API to access frequency data
(http://popgen.uchicago.edu/freq_api/). Python and javascript source code for the
website and the API are available at: http://github.com/NovembreLab/ggv/ and
http://github.com/NovembreLab/ggv-api/ CONTACT:
jnovembre@uchicago.eduSupplementary information: Supplementary data are available
at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw643 
PMID: 27742697  [PubMed - as supplied by publisher]


239. Bioinformatics. 2016 Oct 14. pii: btw641. [Epub ahead of print]

Assocplots: a Python package for static and interactive visualization of
multiple-group GWAS results.

Khramtsova EA(1,)(2), Stranger BE(1,)(2,)(3).

Author information: 
(1)Department of Medicine, Section of Genetic Medicine. (2)Institute for Genomics
and Systems Biology. (3)Center for Data Intensive Science, The University of
Chicago, Chicago, IL, USA.

Over the last decade, genome-wide association studies (GWAS) have generated vast 
amounts of analysis results, requiring development of novel tools for data
visualization. Quantile-quantile (QQ) plots and Manhattan plots are classical
tools which have been utilized to visually summarize GWAS results and identify
genetic variants significantly associated with traits of interest. However,
static visualizations are limiting in the information that can be shown. Here, we
present ASSOCPLOTS: , a Python package for viewing and exploring GWAS results not
only using classic static Manhattan and QQ plots, but also through a dynamic
extension which allows to interactively visualize the relationships between GWAS 
results from multiple cohorts or studies.AVAILABILITY AND IMPLEMENTATION: The
Assocplots package is open source and distributed under the MIT license via
GitHub (https://github.com/khramts/assocplots) along with examples, documentation
and installation instructions.
CONTACT: ekhramts@medicine.bsd.uchicago.edu or
bstranger@medicine.bsd.uchicago.edu.

© The Authors 2016. Published by Oxford University Press. All rights reserved.
For Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw641 
PMID: 27742694  [PubMed - as supplied by publisher]


240. PLoS One. 2016 Oct 13;11(10):e0164228. doi: 10.1371/journal.pone.0164228.
eCollection 2016.

DNApi: A De Novo Adapter Prediction Algorithm for Small RNA Sequencing Data.

Tsuji J(1), Weng Z(1).

Author information: 
(1)Program in Bioinformatics and Integrative Biology, University of Massachusetts
Medical School, Worcester, Massachusetts, United States of America.

With the rapid accumulation of publicly available small RNA sequencing datasets, 
third-party meta-analysis across many datasets is becoming increasingly powerful.
Although removing the 3´ adapter is an essential step for small RNA sequencing
analysis, the adapter sequence information is not always available in the
metadata. The information can be also erroneous even when it is available. In
this study, we developed DNApi, a lightweight Python software package that
predicts the 3´ adapter sequence de novo and provides the user with cleansed
small RNA sequences ready for down stream analysis. Tested on 539 publicly
available small RNA libraries accompanied with 3´ adapter sequences in their
metadata, DNApi shows near-perfect accuracy (98.5%) with fast runtime (~2.85
seconds per library) and efficient memory usage (~43 MB on average). In addition 
to 3´ adapter prediction, it is also important to classify whether the input
small RNA libraries were already processed, i.e. the 3´ adapters were removed.
DNApi perfectly judged that given another batch of datasets, 192 publicly
available processed libraries were "ready-to-map" small RNA sequence. DNApi is
compatible with Python 2 and 3, and is available at
https://github.com/jnktsj/DNApi. The 731 small RNA libraries used for DNApi
evaluation were from human tissues and were carefully and manually collected.
This study also provides readers with the curated datasets that can be integrated
into their studies.

DOI: 10.1371/journal.pone.0164228 
PMCID: PMC5063419
PMID: 27736901  [PubMed - in process]


241. BMC Genomics. 2016 Oct 12;17(1):799.

CNARA: reliability assessment for genomic copy number profiles.

Ai N(1), Cai H(2), Solovan C(3), Baudis M(4).

Author information: 
(1)Institute of Molecular Life Sciences and Swiss Institute of Bioinformatics,
University of Zurich, Winterthurerstrasse 190, Zurich, CH-8057, Switzerland.
ni.ai@uzh.ch. (2)Center of Growth, Metabolism and Aging, Key Laboratory of
Bio-Resources and Eco-Environment, College of Life Sciences, Sichuan University, 
Chengdu, Sichuan, 610064, China. (3)Department of Dermatology, "Victor Babeş"
University of Medicine and Pharmacy, Timisoara, Romania. (4)Institute of
Molecular Life Sciences and Swiss Institute of Bioinformatics, University of
Zurich, Winterthurerstrasse 190, Zurich, CH-8057, Switzerland.
michael.baudis@imls.uzh.ch.

BACKGROUND: DNA copy number profiles from microarray and sequencing experiments
sometimes contain wave artefacts which may be introduced during sample
preparation and cannot be removed completely by existing preprocessing methods.
Besides, large derivative log ratio spread (DLRS) of the probes correlating with 
poor DNA quality is sometimes observed in genome screening experiments and may
lead to unreliable copy number profiles. Depending on the extent of these
artefacts and the resulting misidentification of copy number
alterations/variations (CNA/CNV), it may be desirable to exclude such samples
from analyses or to adapt the downstream data analysis strategy accordingly.
RESULTS: Here, we propose a method to distinguish reliable genomic copy number
profiles from those containing heavy wave artefacts and/or large DLRS. We define 
four features that adequately summarize the copy number profiles for reliability 
assessment, and train a classifier on a dataset of 1522 copy number profiles from
various microarray platforms. The method can be applied to predict the
reliability of copy number profiles irrespective of the underlying microarray
platform and may be adapted for those sequencing platforms from which copy number
estimates could be computed as a piecewise constant signal. Further details can
be found at https://github.com/baudisgroup/CNARA .
CONCLUSIONS: We have developed a method for the assessment of genomic copy number
profiling data, and suggest to apply the method in addition to and after other
state-of-the-art noise correction and quality control procedures. CNARA could be 
instrumental in improving the assessment of data used for genomic data mining
experiments and support the reliable functional attribution of copy number
aberrations especially in cancer research.

DOI: 10.1186/s12864-016-3074-7 
PMCID: PMC5062840
PMID: 27733115  [PubMed - in process]


242. Evol Bioinform Online. 2016 Oct 2;12:223-228. eCollection 2016.

Approaching Long Genomic Regions and Large Recombination Rates with msParSm as an
Alternative to MaCS.

Montemuiño C(1), Espinosa A(1), Moure JC(1), Vera G(2), Hernández P(1),
Ramos-Onsins S(2).

Author information: 
(1)Computer Architecture and Operating Systems Department (CAOS), Universitat
Autònoma de Barcelona, Bellaterra, Spain. (2)Centre for Research in Agricultural 
Genomics (CRAG) Consortium CSIC-IRTA-UAB-UB Edifici CRAG, Campus UAB, Bellaterra,
Spain.

The msParSm application is an evolution of msPar, the parallel version of the
coalescent simulation program ms, which removes the limitation for simulating
long stretches of DNA sequences with large recombination rates, without
compromising the accuracy of the standard coalescence. This work introduces
msParSm, describes its significant performance improvements over msPar and its
shared memory parallelization details, and shows how it can get better, if not
similar, execution times than MaCS. Two case studies with different mutation
rates were analyzed, one approximating the human average and the other
approximating the Drosophila melanogaster average. Source code is available at
https://github.com/cmontemuino/msparsm.

DOI: 10.4137/EBO.S40268 
PMCID: PMC5047705
PMID: 27721650  [PubMed - in process]


243. PLoS Comput Biol. 2016 Oct 7;12(10):e1005135. doi: 10.1371/journal.pcbi.1005135. 
eCollection 2016.

Large-Scale Off-Target Identification Using Fast and Accurate Dual Regularized
One-Class Collaborative Filtering and Its Application to Drug Repurposing.

Lim H(1), Poleksic A(2), Yao Y(3), Tong H(4), He D(1), Zhuang L(5), Meng P(6),
Xie L(1,)(7).

Author information: 
(1)The Graduate Center, The City University of New York, New York, New York,
United States. (2)Department of Computer Science, University of Northern Iowa,
Cedar Falls, Iowa, United States. (3)Department of Computer Science and
Technology, Nanjing University, Nanjing, Jiangsu, China. (4)School of Computing, 
Informatics and Decision Systems Engineering, Arizona State University, Tempe,
Arizona, United States. (5)Academy for Information Technology, Union County
Vocational-Technical Schools, Scotch Plains, New Jersey, United States. (6)High
Technology High School, Lincroft, New Jersey, United States. (7)Department of
Computer Science, Hunter College, The City University of New York, New York, New 
York, United States.

Erratum in
    PLoS Comput Biol. 2017 Jan 3;13(1):e1005312.

Target-based screening is one of the major approaches in drug discovery. Besides 
the intended target, unexpected drug off-target interactions often occur, and
many of them have not been recognized and characterized. The off-target
interactions can be responsible for either therapeutic or side effects. Thus,
identifying the genome-wide off-targets of lead compounds or existing drugs will 
be critical for designing effective and safe drugs, and providing new
opportunities for drug repurposing. Although many computational methods have been
developed to predict drug-target interactions, they are either less accurate than
the one that we are proposing here or computationally too intensive, thereby
limiting their capability for large-scale off-target identification. In addition,
the performances of most machine learning based algorithms have been mainly
evaluated to predict off-target interactions in the same gene family for hundreds
of chemicals. It is not clear how these algorithms perform in terms of detecting 
off-targets across gene families on a proteome scale. Here, we are presenting a
fast and accurate off-target prediction method, REMAP, which is based on a dual
regularized one-class collaborative filtering algorithm, to explore continuous
chemical space, protein space, and their interactome on a large scale. When
tested in a reliable, extensive, and cross-gene family benchmark, REMAP
outperforms the state-of-the-art methods. Furthermore, REMAP is highly scalable. 
It can screen a dataset of 200 thousands chemicals against 20 thousands proteins 
within 2 hours. Using the reconstructed genome-wide target profile as the
fingerprint of a chemical compound, we predicted that seven FDA-approved drugs
can be repurposed as novel anti-cancer therapies. The anti-cancer activity of six
of them is supported by experimental evidences. Thus, REMAP is a valuable
addition to the existing in silico toolbox for drug target identification, drug
repurposing, phenotypic screening, and side effect prediction. The software and
benchmark are available at https://github.com/hansaimlim/REMAP.

DOI: 10.1371/journal.pcbi.1005135 
PMCID: PMC5055357
PMID: 27716836  [PubMed - in process]


244. BMC Bioinformatics. 2016 Oct 3;17(1):404.

ChiLin: a comprehensive ChIP-seq and DNase-seq quality control and analysis
pipeline.

Qin Q(1,)(2), Mei S(1,)(2), Wu Q(1,)(2), Sun H(1,)(2), Li L(3), Taing L(4,)(3),
Chen S(1,)(2), Li F(3), Liu T(5), Zang C(4), Xu H(4), Chen Y(4), Meyer CA(4),
Zhang Y(2), Brown M(3,)(6), Long HW(7), Liu XS(8,)(9,)(10,)(11).

Author information: 
(1)Shanghai Key laboratory of tuberculosis, Shanghai Pulmonary Hospital,
Shanghai, China. (2)Department of Bioinformatics, School of Life Science and
Technology, Tongji University, Shanghai, China. (3)Center for Functional Cancer
Epigenetics, Dana-Farber Cancer Institute, Boston, MA, USA. (4)Department of
Biostatistics and Computational Biology, Dana-Farber Cancer Institute and Harvard
School of Public Health, Boston, MA, USA. (5)Department of Biochemistry,
University at Buffalo, Buffalo, NY, USA. (6)Division of Molecular and Cellular
Oncology, Department of Medical Oncology, Dana-Farber Cancer Institute and
Department of Medicine, Brigham and Women's Hospital and Harvard Medical School, 
Boston, MA, USA. (7)Center for Functional Cancer Epigenetics, Dana-Farber Cancer 
Institute, Boston, MA, USA. henry_long@dfci.harvard.edu. (8)Shanghai Key
laboratory of tuberculosis, Shanghai Pulmonary Hospital, Shanghai, China.
xsliu@jimmy.harvard.edu. (9)Department of Bioinformatics, School of Life Science 
and Technology, Tongji University, Shanghai, China. xsliu@jimmy.harvard.edu.
(10)Department of Biostatistics and Computational Biology, Dana-Farber Cancer
Institute and Harvard School of Public Health, Boston, MA, USA.
xsliu@jimmy.harvard.edu. (11)Center for Functional Cancer Epigenetics,
Dana-Farber Cancer Institute, Boston, MA, USA. xsliu@jimmy.harvard.edu.

BACKGROUND: Transcription factor binding, histone modification, and chromatin
accessibility studies are important approaches to understanding the biology of
gene regulation. ChIP-seq and DNase-seq have become the standard techniques for
studying protein-DNA interactions and chromatin accessibility respectively, and
comprehensive quality control (QC) and analysis tools are critical to extracting 
the most value from these assay types. Although many analysis and QC tools have
been reported, few combine ChIP-seq and DNase-seq data analysis and quality
control in a unified framework with a comprehensive and unbiased reference of
data quality metrics.
RESULTS: ChiLin is a computational pipeline that automates the quality control
and data analyses of ChIP-seq and DNase-seq data. It is developed using a
flexible and modular software framework that can be easily extended and modified.
ChiLin is ideal for batch processing of many datasets and is well suited for
large collaborative projects involving ChIP-seq and DNase-seq from different
designs. ChiLin generates comprehensive quality control reports that include
comparisons with historical data derived from over 23,677 public ChIP-seq and
DNase-seq samples (11,265 datasets) from eight literature-based classified
categories. To the best of our knowledge, this atlas represents the most
comprehensive ChIP-seq and DNase-seq related quality metric resource currently
available. These historical metrics provide useful heuristic quality references
for experiment across all commonly used assay types. Using representative
datasets, we demonstrate the versatility of the pipeline by applying it to
different assay types of ChIP-seq data. The pipeline software is available open
source at https://github.com/cfce/chilin .
CONCLUSION: ChiLin is a scalable and powerful tool to process large batches of
ChIP-seq and DNase-seq datasets. The analysis output and quality metrics have
been structured into user-friendly directories and reports. We have successfully 
compiled 23,677 profiles into a comprehensive quality atlas with fine
classification for users.

DOI: 10.1186/s12859-016-1274-4 
PMCID: PMC5048594
PMID: 27716038  [PubMed - in process]


245. Microb Genom. 2016 Jan 19;2(1). doi: 10.1099/mgen.0.000044.

SimBac: simulation of whole bacterial genomes with homologous recombination.

Brown T(1), Didelot X(2), Wilson DJ(3), De Maio N(4).

Author information: 
(1)Doctoral Training Centre, University of Oxford, Oxford, UK. (2)Department of
Infectious Disease Epidemiology, Imperial College, London, UK. (3)Institute for
Emerging Infections, Oxford Martin School, Oxford, UK; Nuffield Department of
Medicine, University of Oxford, Oxford, UK; Wellcome Trust Centre for Human
Genetics, University of Oxford, Oxford, UK. (4)Institute for Emerging Infections,
Oxford Martin School, Oxford, UK; Nuffield Department of Medicine, University of 
Oxford, Oxford, UK.

Bacteria can exchange genetic material, or acquire genes found in the
environment. This process, generally known as bacterial recombination, can have a
strong impact on the evolution and phenotype of bacteria, for example causing the
spread of antibiotic resistance across clades and species, but can also disrupt
phylogenetic and transmission inferences. With the increasing affordability of
whole genome sequencing, the need has emerged for an efficient simulator of
bacterial evolution to test and compare methods for phylogenetic and population
genetic inference, and for simulation-based estimation. We present SimBac, a
whole-genome bacterial evolution simulator that is roughly two orders of
magnitude faster than previous software and includes a more general model of
bacterial evolution, allowing both within- and between-species homologous
recombination. Since methods modelling bacterial recombination generally focus on
only one of these two modes of recombination, the possibility to simulate both
allows for a general and fair benchmarking. SimBac is available from
https://github.com/tbrown91/SimBac and is distributed as open source under the
terms of the GNU General Public Licence.

DOI: 10.1099/mgen.0.000044 
PMCID: PMC5049688
PMID: 27713837  [PubMed]


246. PLoS One. 2016 Oct 6;11(10):e0164023. doi: 10.1371/journal.pone.0164023.
eCollection 2016.

Language-Agnostic Reproducible Data Analysis Using Literate Programming.

Vassilev B(1), Louhimo R(2), Ikonen E(1,)(3), Hautaniemi S(2).

Author information: 
(1)Department of Anatomy, Faculty of Medicine, University of Helsinki, Helsinki, 
Finland. (2)Research Programs Unit, Genome-Scale Biology, University of Helsinki,
Helsinki, Finland. (3)Minerva Foundation Institute for Medical Research,
Helsinki, Finland.

A modern biomedical research project can easily contain hundreds of analysis
steps and lack of reproducibility of the analyses has been recognized as a severe
issue. While thorough documentation enables reproducibility, the number of
analysis programs used can be so large that in reality reproducibility cannot be 
easily achieved. Literate programming is an approach to present computer programs
to human readers. The code is rearranged to follow the logic of the program, and 
to explain that logic in a natural language. The code executed by the computer is
extracted from the literate source code. As such, literate programming is an
ideal formalism for systematizing analysis steps in biomedical research. We have 
developed the reproducible computing tool Lir (literate, reproducible computing) 
that allows a tool-agnostic approach to biomedical data analysis. We demonstrate 
the utility of Lir by applying it to a case study. Our aim was to investigate the
role of endosomal trafficking regulators to the progression of breast cancer. In 
this analysis, a variety of tools were combined to interpret the available data: 
a relational database, standard command-line tools, and a statistical computing
environment. The analysis revealed that the lipid transport related genes LAPTM4B
and NDRG1 are coamplified in breast cancer patients, and identified genes
potentially cooperating with LAPTM4B in breast cancer progression. Our case study
demonstrates that with Lir, an array of tools can be combined in the same data
analysis to improve efficiency, reproducibility, and ease of understanding. Lir
is an open-source software available at github.com/borisvassilev/lir.

DOI: 10.1371/journal.pone.0164023 
PMCID: PMC5053501
PMID: 27711123  [PubMed - in process]


247. Front Immunol. 2016 Sep 21;7:372. eCollection 2016.

SONAR: A High-Throughput Pipeline for Inferring Antibody Ontogenies from
Longitudinal Sequencing of B Cell Transcripts.

Schramm CA(1), Sheng Z(2), Zhang Z(2), Mascola JR(3), Kwong PD(4), Shapiro L(1).

Author information: 
(1)Department of Biochemistry and Molecular Biophysics, Columbia University, New 
York, NY, USA; Department of Systems Biology, Columbia University, New York, NY, 
USA; Vaccine Research Center, National Institute of Allergy and Infectious
Diseases, National Institutes of Health, Bethesda, MD, USA. (2)Department of
Biochemistry and Molecular Biophysics, Columbia University, New York, NY, USA;
Department of Systems Biology, Columbia University, New York, NY, USA. (3)Vaccine
Research Center, National Institute of Allergy and Infectious Diseases, National 
Institutes of Health , Bethesda, MD , USA. (4)Department of Biochemistry and
Molecular Biophysics, Columbia University, New York, NY, USA; Vaccine Research
Center, National Institute of Allergy and Infectious Diseases, National
Institutes of Health, Bethesda, MD, USA.

The rapid advance of massively parallel or next-generation sequencing
technologies has made possible the characterization of B cell receptor
repertoires in ever greater detail, and these developments have triggered a
proliferation of software tools for processing and annotating these data. Of
especial interest, however, is the capability to track the development of
specific antibody lineages across time, which remains beyond the scope of most
current programs. We have previously reported on the use of techniques such as
inter- and intradonor analysis and CDR3 tracing to identify transcripts related
to an antibody of interest. Here, we present Software for the Ontogenic aNalysis 
of Antibody Repertoires (SONAR), capable of automating both general repertoire
analysis and specialized techniques for investigating specific lineages. SONAR
annotates next-generation sequencing data, identifies transcripts in a lineage of
interest, and tracks lineage development across multiple time points. SONAR also 
generates figures, such as identity-divergence plots and longitudinal
phylogenetic "birthday" trees, and provides interfaces to other programs such as 
DNAML and BEAST. SONAR can be downloaded as a ready-to-run Docker image or
manually installed on a local machine. In the latter case, it can also be
configured to take advantage of a high-performance computing cluster for the most
computationally intensive steps, if available. In summary, this software provides
a useful new tool for the processing of large next-generation sequencing datasets
and the ontogenic analysis of neutralizing antibody lineages. SONAR can be found 
at https://github.com/scharch/SONAR, and the Docker image can be obtained from
https://hub.docker.com/r/scharch/sonar/.

DOI: 10.3389/fimmu.2016.00372 
PMCID: PMC5030719
PMID: 27708645  [PubMed - in process]


248. Front Behav Neurosci. 2016 Sep 21;10:177. eCollection 2016.

Non-parametric Algorithm to Isolate Chunks in Response Sequences.

Alamia A(1), Solopchuk O(1), Olivier E(1), Zenon A(1).

Author information: 
(1)Institute of Neuroscience, Université catholique de Louvain Bruxelles,
Belgique.

Chunking consists in grouping items of a sequence into small clusters, named
chunks, with the assumed goal of lessening working memory load. Despite extensive
research, the current methods used to detect chunks, and to identify different
chunking strategies, remain discordant and difficult to implement. Here, we
propose a simple and reliable method to identify chunks in a sequence and to
determine their stability across blocks. This algorithm is based on a ranking
method and its major novelty is that it provides concomitantly both the features 
of individual chunk in a given sequence, and an overall index that quantifies the
chunking pattern consistency across sequences. The analysis of simulated data
confirmed the validity of our method in different conditions of noise, chunk
lengths and chunk numbers; moreover, we found that this algorithm was
particularly efficient in the noise range observed in real data, provided that at
least 4 sequence repetitions were included in each experimental block.
Furthermore, we applied this algorithm to actual reaction time series gathered
from 3 published experiments and were able to confirm the findings obtained in
the original reports. In conclusion, this novel algorithm is easy to implement,
is robust to outliers and provides concurrent and reliable estimation of chunk
position and chunking dynamics, making it useful to study both sequence-specific 
and general chunking effects. The algorithm is available at:
https://github.com/artipago/Non-parametric-algorithm-to-isolate-chunks-in-respons
e-sequences.

DOI: 10.3389/fnbeh.2016.00177 
PMCID: PMC5030762
PMID: 27708565  [PubMed - in process]


249. Sci Rep. 2016 Oct 6;6:34838. doi: 10.1038/srep34838.

lncScore: alignment-free identification of long noncoding RNA from assembled
novel transcripts.

Zhao J(1,)(2), Song X(1), Wang K(2,)(3,)(4,)(5).

Author information: 
(1)Department of Biomedical Engineering, Nanjing University of Aeronautics and
Astronautics, Nanjing 210016, China. (2)Zilkha Neurogenetic Institute, Keck
School of Medicine, University of Southern California, Los Angeles, CA 90089,
USA. (3)Division of Bioinformatics, Department of Preventive Medicine, Keck
School of Medicine, University of Southern California, Los Angeles, CA 90089,
USA. (4)Institute for Genomic Medicine, Columbia University Medical Center, New
York, NY 10032, USA. (5)Department of Biomedical Informatics, Columbia University
Medical Center, New York, NY 10032, USA.

RNA-Seq based transcriptome assembly has been widely used to identify novel
lncRNAs. However, the best-performing transcript reconstruction methods merely
identified 21% of full-length protein-coding transcripts from H. sapiens. Those
partial-length protein-coding transcripts are more likely to be classified as
lncRNAs due to their incomplete CDS, leading to higher false positive rate for
lncRNA identification. Furthermore, potential sequencing or assembly error that
gain or abolish stop codons also complicates ORF-based prediction of lncRNAs.
Therefore, it remains a challenge to identify lncRNAs from the assembled
transcripts, particularly the partial-length ones. Here, we present a novel
alignment-free tool, lncScore, which uses a logistic regression model with 11
carefully selected features. Compared to other state-of-the-art alignment-free
tools (e.g. CPAT, CNCI, and PLEK), lncScore outperforms them on accurately
distinguishing lncRNAs from mRNAs, especially partial-length mRNAs in the human
and mouse datasets. In addition, lncScore also performed well on transcripts from
five other species (Zebrafish, Fly, C. elegans, Rat, and Sheep). To speed up the 
prediction, multithreading is implemented within lncScore, and it only took
2 minute to classify 64,756 transcripts and 54 seconds to train a new model with 
21,000 transcripts with 12 threads, which is much faster than other tools.
lncScore is available at https://github.com/WGLab/lncScore.

DOI: 10.1038/srep34838 
PMCID: PMC5052565
PMID: 27708423  [PubMed - in process]


250. Nature. 2016 Oct 6;538(7623):127-128. doi: 10.1038/538127a.

Democratic databases: science on GitHub.

Perkel J.

Erratum in
    Nature. 2016 Oct 31;539(7627):126.

DOI: 10.1038/538127a 
PMID: 27708327  [PubMed - indexed for MEDLINE]


251. PLoS One. 2016 Oct 5;11(10):e0163962. doi: 10.1371/journal.pone.0163962.
eCollection 2016.

SeqKit: A Cross-Platform and Ultrafast Toolkit for FASTA/Q File Manipulation.

Shen W(1), Le S(1), Li Y(2), Hu F(1).

Author information: 
(1)Department of Microbiology, College of Basic Medical Sciences, Third Military 
Medical University, 30# Gaotanyan St., Shapingba District, Chongqing, China.
(2)Medical Research Center, Southwest hospital, Third Military Medical
University, 29# Gaotanyan St., Shapingba District, Chongqing, China.

FASTA and FASTQ are basic and ubiquitous formats for storing nucleotide and
protein sequences. Common manipulations of FASTA/Q file include converting,
searching, filtering, deduplication, splitting, shuffling, and sampling. Existing
tools only implement some of these manipulations, and not particularly
efficiently, and some are only available for certain operating systems.
Furthermore, the complicated installation process of required packages and
running environments can render these programs less user friendly. This paper
describes a cross-platform ultrafast comprehensive toolkit for FASTA/Q
processing. SeqKit provides executable binary files for all major operating
systems, including Windows, Linux, and Mac OSX, and can be directly used without 
any dependencies or pre-configurations. SeqKit demonstrates competitive
performance in execution time and memory usage compared to similar tools. The
efficiency and usability of SeqKit enable researchers to rapidly accomplish
common FASTA/Q file manipulations. SeqKit is open source and available on Github 
at https://github.com/shenwei356/seqkit.

DOI: 10.1371/journal.pone.0163962 
PMCID: PMC5051824
PMID: 27706213  [PubMed - in process]


252. PLoS One. 2016 Oct 5;11(10):e0163794. doi: 10.1371/journal.pone.0163794.
eCollection 2016.

PubMedPortable: A Framework for Supporting the Development of Text Mining
Applications.

Döring K(1), Grüning BA(2), Telukunta KK(2), Thomas P(3), Günther S(1).

Author information: 
(1)Pharmaceutical Bioinformatics, Institute of Pharmaceutical Sciences,
Albert-Ludwigs University, 79104 Freiburg, Germany. (2)Bioinformatics, Institute 
of Computer Science, Albert-Ludwigs University, 79110 Freiburg, Germany.
(3)Language Technology Lab, German Research Center for Artificial Intelligence,
DFKI GmbH, 10559 Berlin, Germany.

Information extraction from biomedical literature is continuously growing in
scope and importance. Many tools exist that perform named entity recognition,
e.g. of proteins, chemical compounds, and diseases. Furthermore, several
approaches deal with the extraction of relations between identified entities. The
BioCreative community supports these developments with yearly open challenges,
which led to a standardised XML text annotation format called BioC. PubMed
provides access to the largest open biomedical literature repository, but there
is no unified way of connecting its data to natural language processing tools.
Therefore, an appropriate data environment is needed as a basis to combine
different software solutions and to develop customised text mining applications. 
PubMedPortable builds a relational database and a full text index on PubMed
citations. It can be applied either to the complete PubMed data set or an
arbitrary subset of downloaded PubMed XML files. The software provides the
infrastructure to combine stand-alone applications by exporting different data
formats, e.g. BioC. The presented workflows show how to use PubMedPortable to
retrieve, store, and analyse a disease-specific data set. The provided use cases 
are well documented in the PubMedPortable wiki. The open-source software library 
is small, easy to use, and scalable to the user's system requirements. It is
freely available for Linux on the web at
https://github.com/KerstenDoering/PubMedPortable and for other operating systems 
as a virtual container. The approach was tested extensively and applied
successfully in several projects.

DOI: 10.1371/journal.pone.0163794 
PMCID: PMC5051953
PMID: 27706202  [PubMed - in process]


253. PLoS Comput Biol. 2016 Oct 5;12(10):e1005096. doi: 10.1371/journal.pcbi.1005096. 
eCollection 2016.

AlignerBoost: A Generalized Software Toolkit for Boosting Next-Gen Sequencing
Mapping Accuracy Using a Bayesian-Based Mapping Quality Framework.

Zheng Q(1), Grice EA(1).

Author information: 
(1)Department of Dermatology, Perelman School of Medicine, University of
Pennsylvania, Philadelphia, Pennsylvania, United States of America.

Accurate mapping of next-generation sequencing (NGS) reads to reference genomes
is crucial for almost all NGS applications and downstream analyses. Various
repetitive elements in human and other higher eukaryotic genomes contribute in
large part to ambiguously (non-uniquely) mapped reads. Most available NGS
aligners attempt to address this by either removing all non-uniquely mapping
reads, or reporting one random or "best" hit based on simple heuristics. Accurate
estimation of the mapping quality of NGS reads is therefore critical albeit
completely lacking at present. Here we developed a generalized software toolkit
"AlignerBoost", which utilizes a Bayesian-based framework to accurately estimate 
mapping quality of ambiguously mapped NGS reads. We tested AlignerBoost with both
simulated and real DNA-seq and RNA-seq datasets at various thresholds. In most
cases, but especially for reads falling within repetitive regions, AlignerBoost
dramatically increases the mapping precision of modern NGS aligners without
significantly compromising the sensitivity even without mapping quality filters. 
When using higher mapping quality cutoffs, AlignerBoost achieves a much lower
false mapping rate while exhibiting comparable or higher sensitivity compared to 
the aligner default modes, therefore significantly boosting the detection power
of NGS aligners even using extreme thresholds. AlignerBoost is also SNP-aware,
and higher quality alignments can be achieved if provided with known SNPs.
AlignerBoost's algorithm is computationally efficient, and can process one
million alignments within 30 seconds on a typical desktop computer. AlignerBoost 
is implemented as a uniform Java application and is freely available at
https://github.com/Grice-Lab/AlignerBoost.

DOI: 10.1371/journal.pcbi.1005096 
PMCID: PMC5051939
PMID: 27706155  [PubMed - in process]


254. PeerJ. 2016 Sep 28;4:e2436. eCollection 2016.

RBioplot: an easy-to-use R pipeline for automated statistical analysis and data
visualization in molecular biology and biochemistry.

Zhang J(1), Storey KB(1).

Author information: 
(1)Institute of Biochemistry, Departments of Biology and Chemistry, Carleton
University , Ottawa, ON , Canada.

BACKGROUND: Statistical analysis and data visualization are two crucial aspects
in molecular biology and biology. For analyses that compare one dependent
variable between standard (e.g., control) and one or multiple independent
variables, a comprehensive yet highly streamlined solution is valuable. The
computer programming language R is a popular platform for researchers to develop 
tools that are tailored specifically for their research needs. Here we present an
R package RBioplot that takes raw input data for automated statistical analysis
and plotting, highly compatible with various molecular biology and biochemistry
lab techniques, such as, but not limited to, western blotting, PCR, and enzyme
activity assays.
METHOD: The package is built based on workflows operating on a simple raw data
layout, with minimum user input or data manipulation required. The package is
distributed through GitHub, which can be easily installed through one single-line
R command. A detailed installation guide is available at
http://kenstoreylab.com/?page_id=2448. Users can also download demo datasets from
the same website.
RESULTS AND DISCUSSION: By integrating selected functions from existing
statistical and data visualization packages with extensive customization,
RBioplot features both statistical analysis and data visualization
functionalities. Key properties of RBioplot include: -Fully automated and
comprehensive statistical analysis, including normality test, equal variance
test, Student's t-test and ANOVA (with post-hoc tests);-Fully automated
histogram, heatmap and joint-point curve plotting modules;-Detailed output files 
for statistical analysis, data manipulation and high quality graphs;-Axis range
finding and user customizable tick settings;-High user-customizability.

DOI: 10.7717/peerj.2436 
PMCID: PMC5045883
PMID: 27703842  [PubMed - in process]


255. Front Genet. 2016 Sep 15;7:160. eCollection 2016.

SRBreak: A Read-Depth and Split-Read Framework to Identify Breakpoints of
Different Events Inside Simple Copy-Number Variable Regions.

Nguyen HT(1), Boocock J(2), Merriman TR(3), Black MA(3).

Author information: 
(1)Department of Biochemistry, University of OtagoDunedin, New Zealand; Virtual
Institute of Statistical GeneticsDunedin, New Zealand; Department of Psychiatry, 
Mount Sinai School of Medicine, New YorkNY, USA; Department of Mathematics, Cao
Thang College of TechnologyHo Chi Minh City, Vietnam. (2)Department of
Biochemistry, University of OtagoDunedin, New Zealand; Virtual Institute of
Statistical GeneticsDunedin, New Zealand; Department of Psychiatry, Mount Sinai
School of Medicine, New YorkNY, USA. (3)Department of Biochemistry, University of
OtagoDunedin, New Zealand; Virtual Institute of Statistical GeneticsDunedin, New 
Zealand.

Copy-number variation (CNV) has been associated with increased risk of complex
diseases. High-throughput sequencing (HTS) technologies facilitate the detection 
of copy-number variable regions (CNVRs) and their breakpoints. This helps in
understanding genome structure as well as their evolution process. Various
approaches have been proposed for detecting CNV breakpoints, but currently it is 
still challenging for tools based on a single analysis method to identify
breakpoints of CNVs. It has been shown, however, that pipelines which integrate
multiple approaches are able to report more reliable breakpoints. Here, based on 
HTS data, we have developed a pipeline to identify approximate breakpoints (±10
bp) relating to different ancestral events within a specific CNVR. The pipeline
combines read-depth and split-read information to infer breakpoints, using
information from multiple samples to allow an imputation approach to be taken.
The main steps involve using a normal mixture model to cluster samples into
different groups, followed by simple kernel-based approaches to maximize
information obtained from read-depth and split-read approaches, after which
common breakpoints of groups are inferred. The pipeline uses split-read
information directly from CIGAR strings of BAM files, without using a
re-alignment step. On simulated data sets, it was able to report breakpoints for 
very low-coverage samples including those for which only single-end reads were
available. When applied to three loci from existing human resequencing data sets 
(NEGR1, LCE3, IRGM) the pipeline obtained good concordance with results from the 
1000 Genomes Project (92, 100, and 82%, respectively). The package is available
at https://github.com/hoangtn/SRBreak, and also as a docker-based application at 
https://registry.hub.docker.com/u/hoangtn/srbreak/.

DOI: 10.3389/fgene.2016.00160 
PMCID: PMC5023681
PMID: 27695476  [PubMed - in process]


256. Database (Oxford). 2016 Oct 2;2016. pii: baw133. Print 2016.

ASAP: a machine learning framework for local protein properties.

Brandes N(1), Ofer D(1), Linial M(2).

Author information: 
(1)Department of Biological Chemistry, The Alexander Silberman Institute of Life 
Sciences, The Hebrew University, Jerusalem 91904, Israel. (2)Department of
Biological Chemistry, The Alexander Silberman Institute of Life Sciences, The
Hebrew University, Jerusalem 91904, Israel michall@cc.huji.ac.il
michall@ias.huji.ac.il.

Determining residue-level protein properties, such as sites of post-translational
modifications (PTMs), is vital to understanding protein function. Experimental
methods are costly and time-consuming, while traditional rule-based computational
methods fail to annotate sites lacking substantial similarity. Machine Learning
(ML) methods are becoming fundamental in annotating unknown proteins and their
heterogeneous properties. We present ASAP (Amino-acid Sequence Annotation
Prediction), a universal ML framework for predicting residue-level properties.
ASAP extracts numerous features from raw sequences, and supports easy integration
of external features such as secondary structure, solvent accessibility,
intrinsically disorder or PSSM profiles. Features are then used to train ML
classifiers. ASAP can create new classifiers within minutes for a variety of
tasks, including PTM prediction (e.g. cleavage sites by convertase, phosphoserine
modification). We present a detailed case study for ASAP: CleavePred, an
ASAP-based model to predict protein precursor cleavage sites, with
state-of-the-art results. Protein cleavage is a PTM shared by a wide variety of
proteins sharing minimal sequence similarity. Current rule-based methods suffer
from high false positive rates, making them suboptimal. The high performance of
CleavePred makes it suitable for analyzing new proteomes at a genomic scale. The 
tool is attractive to protein design, mass spectrometry search engines and the
discovery of new bioactive peptides from precursors. ASAP functions as a baseline
approach for residue-level protein sequence prediction. CleavePred is freely
accessible as a web-based application. Both ASAP and CleavePred are open-source
with a flexible Python API.Database URL: ASAP's and CleavePred source code,
webtool and tutorials are available at: https://github.com/ddofer/asap;
http://protonet.cs.huji.ac.il/cleavepred.

© The Author(s) 2016. Published by Oxford University Press.

DOI: 10.1093/database/baw133 
PMCID: PMC5045867
PMID: 27694209  [PubMed - in process]


257. Bioinformatics. 2016 Sep 30. pii: btw620. [Epub ahead of print]

OMBlast: alignment tool for optical mapping using a seed-and-extend approach.

Leung AK(1), Kwok TP(2), Wan R(1), Xiao M(3), Kwok PY(4,)(5), Yip KY(2,)(6), Chan
TF(1,)(2,)(6,)(7).

Author information: 
(1)School of Life Sciences. (2)Department of Computer Science and Engineering,
The Chinese University of Hong Kong, Hong Kong, China. (3)School of Biomedical
Engineering, Science and Health System, Drexel University, Philadelphia, PA, USA.
(4)Institute for Human Genetics. (5)Cardiovascular Research Institute, University
of California San Francisco, San Francisco, CA, USA. (6)Hong Kong Bioinformatics 
Centre. (7)Centre for Soybean Research, State Key Laboratory of
Agrobiotechnology, The Chinese University of Hong Kong, Hong Kong, China.

MOTIVATION: Optical mapping is a technique for capturing fluorescent signal
patterns of long DNA molecules (in the range of 0.1-1 Mbp). Recently, it has been
complementing the widely used short-read sequencing technology by assisting with 
scaffolding and detecting large and complex structural variations (SVs). Here, we
introduce a fast, robust and accurate tool called OMBlast for aligning optical
maps, the set of signal locations on the molecules generated from optical
mapping. Our method is based on the seed-and-extend approach from sequence
alignment, with modifications specific to optical mapping.
RESULTS: Experiments with both synthetic and our real data demonstrate that
OMBlast has higher accuracy and faster mapping speed than existing alignment
methods. Our tool also shows significant improvement when aligning data with SVs.
AVAILABILITY AND IMPLEMENTATION: OMBlast is implemented for Java 1.7 and is
released under a GPL license. OMBlast can be downloaded from
https://github.com/aldenleung/OMBlast and run directly on machines equipped with 
a Java virtual machine.
CONTACT: kevinyip@cse.cuhk.edu.hk and tf.chan@cuhk.edu.hkSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw620 
PMID: 27694200  [PubMed - as supplied by publisher]


258. PLoS One. 2016 Sep 29;11(9):e0163111. doi: 10.1371/journal.pone.0163111.

MetaPhinder-Identifying Bacteriophage Sequences in Metagenomic Data Sets.

Jurtz VI(1), Villarroel J(1), Lund O(1), Voldby Larsen M(1), Nielsen M(1).

Author information: 
(1)Department of Systems Biology, Technical University of Denmark, Lyngby,
Denmark.

Bacteriophages are the most abundant biological entity on the planet, but at the 
same time do not account for much of the genetic material isolated from most
environments due to their small genome sizes. They also show great genetic
diversity and mosaic genomes making it challenging to analyze and understand
them. Here we present MetaPhinder, a method to identify assembled genomic
fragments (i.e.contigs) of phage origin in metagenomic data sets. The method is
based on a comparison to a database of whole genome bacteriophage sequences,
integrating hits to multiple genomes to accomodate for the mosaic genome
structure of many bacteriophages. The method is demonstrated to out-perform both 
BLAST methods based on single hits and methods based on k-mer comparisons.
MetaPhinder is available as a web service at the Center for Genomic Epidemiology 
https://cge.cbs.dtu.dk/services/MetaPhinder/, while the source code can be
downloaded from https://bitbucket.org/genomicepidemiology/metaphinder or
https://github.com/vanessajurtz/MetaPhinder.

DOI: 10.1371/journal.pone.0163111 
PMCID: PMC5042410
PMID: 27684958  [PubMed - as supplied by publisher]


259. PLoS One. 2016 Sep 28;11(9):e0163527. doi: 10.1371/journal.pone.0163527.

WEVOTE: Weighted Voting Taxonomic Identification Method of Microbial Sequences.

Metwally AA(1,)(2), Dai Y(1), Finn PW(2), Perkins DL(1,)(2).

Author information: 
(1)Department of Bioengineering, University of Illinois at Chicago, Chicago, IL, 
United States of America. (2)Department of Medicine, University of Illinois at
Chicago, Chicago, IL, United States of America.

BACKGROUND: Metagenome shotgun sequencing presents opportunities to identify
organisms that may prevent or promote disease. The analysis of sample diversity
is achieved by taxonomic identification of metagenomic reads followed by
generating an abundance profile. Numerous tools have been developed based on
different design principles. Tools achieving high precision can lack sensitivity 
in some applications. Conversely, tools with high sensitivity can suffer from low
precision and require long computation time.
METHODS: In this paper, we present WEVOTE (WEighted VOting Taxonomic
idEntification), a method that classifies metagenome shotgun sequencing DNA reads
based on an ensemble of existing methods using k-mer-based, marker-based, and
naive-similarity based approaches. Our evaluation on fourteen benchmarking
datasets shows that WEVOTE improves the classification precision by reducing
false positive annotations while preserving a high level of sensitivity.
CONCLUSIONS: WEVOTE is an efficient and automated tool that combines multiple
individual taxonomic identification methods to produce more precise and sensitive
microbial profiles. WEVOTE is developed primarily to identify reads generated by 
MetaGenome Shotgun sequencing. It is expandable and has the potential to
incorporate additional tools to produce a more accurate taxonomic profile. WEVOTE
was implemented using C++ and shell scripting and is available at
www.github.com/aametwally/WEVOTE.

DOI: 10.1371/journal.pone.0163527 
PMCID: PMC5040256
PMID: 27683082  [PubMed - as supplied by publisher]


260. Brief Bioinform. 2016 Sep 26. pii: bbw083. [Epub ahead of print]

Rare variant association test in family-based sequencing studies.

Wang X, Zhang Z, Morris N, Cai T, Lee S, Wang C, Yu TW, Walsh CA, Lin X.

The objective of this article is to introduce valid and robust methods for the
analysis of rare variants for family-based exome chips, whole-exome sequencing or
whole-genome sequencing data. Family-based designs provide unique opportunities
to detect genetic variants that complement studies of unrelated individuals.
Currently, limited methods and software tools have been developed to assist
family-based association studies with rare variants, especially for analyzing
binary traits. In this article, we address this gap by extending existing burden 
and kernel-based gene set association tests for population data to related
samples, with a particular emphasis on binary phenotypes. The proposed approach
blends the strengths of kernel machine methods and generalized estimating
equations. Importantly, the efficient generalized kernel score test can be
applied as a mega-analysis framework to combine studies with different designs.
We illustrate the application of the proposed method using data from an exome
sequencing study of autism. Methods discussed in this article are implemented in 
an R package 'gskat', which is available on CRAN and GitHub.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bib/bbw083 
PMID: 27677958  [PubMed - as supplied by publisher]


261. BMC Genomics. 2016 Sep 26;17(1):754.

Predictive computational phenotyping and biomarker discovery using reference-free
genome comparisons.

Drouin A(1), Giguère S(2), Déraspe M(3), Marchand M(4,)(5), Tyers M(2), Loo
VG(6,)(7), Bourgault AM(6,)(7), Laviolette F(4,)(5), Corbeil J(3,)(5).

Author information: 
(1)Department of Computer Science and Software Engineering, Université Laval,
Québec, Canada. alexandre.drouin.8@ulaval.ca. (2)Institute for Research in
Immunology and Cancer, Université de Montréal, Montréal, Canada. (3)Department of
Molecular Medicine, Université Laval, Québec, Canada. (4)Department of Computer
Science and Software Engineering, Université Laval, Québec, Canada. (5)Big Data
Research Centre, Université Laval, Québec, Canada. (6)Division of Infectious
Diseases, Departments of Medicine and Microbiology, McGill University Health
Centre, Montréal, Canada. (7)Department of Medicine, McGill University, Montréal,
Canada.

BACKGROUND: The identification of genomic biomarkers is a key step towards
improving diagnostic tests and therapies. We present a reference-free method for 
this task that relies on a k-mer representation of genomes and a machine learning
algorithm that produces intelligible models. The method is computationally
scalable and well-suited for whole genome sequencing studies.
RESULTS: The method was validated by generating models that predict the
antibiotic resistance of C. difficile, M. tuberculosis, P. aeruginosa, and S.
pneumoniae for 17 antibiotics. The obtained models are accurate, faithful to the 
biological pathways targeted by the antibiotics, and they provide insight into
the process of resistance acquisition. Moreover, a theoretical analysis of the
method revealed tight statistical guarantees on the accuracy of the obtained
models, supporting its relevance for genomic biomarker discovery.
CONCLUSIONS: Our method allows the generation of accurate and interpretable
predictive models of phenotypes, which rely on a small set of genomic variations.
The method is not limited to predicting antibiotic resistance in bacteria and is 
applicable to a variety of organisms and phenotypes. Kover, an efficient
implementation of our method, is open-source and should guide biological efforts 
to understand a plethora of phenotypes ( http://github.com/aldro61/kover/ ).

DOI: 10.1186/s12864-016-2889-6 
PMCID: PMC5037627
PMID: 27671088  [PubMed - as supplied by publisher]


262. Bioinformatics. 2016 Dec 15;32(24):3829-3832. Epub 2016 Sep 25.

LongISLND: in silico sequencing of lengthy and noisy datatypes.

Lau B(1), Mohiyuddin M(1), Mu JC(1), Fang LT(1), Bani Asadi N(1), Dallett C(2),
Lam HY(1).

Author information: 
(1)Roche Sequencing Solutions, Belmont, CA 94002, USA. (2)Roche Sequencing
Solutions, Pleasanton, CA 94588, USA.

LongISLND is a software package designed to simulate sequencing data according to
the characteristics of third generation, single-molecule sequencing technologies.
The general software architecture is easily extendable, as demonstrated by the
emulation of Pacific Biosciences (PacBio) multi-pass sequencing with P5 and P6
chemistries, producing data in FASTQ, H5, and the latest PacBio BAM format. We
demonstrate its utility by downstream processing with consensus building and
variant calling.AVAILABILITY AND IMPLEMENTATION: LongISLND is implemented in Java
and available at http://bioinform.github.io/longislnd CONTACT:
hugo.lam@roche.comSupplementary information: Supplementary data are available at 
Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw602 
PMCID: PMC5167071
PMID: 27667791  [PubMed - in process]


263. Bioinformatics. 2017 Jan 15;33(2):266-271. doi: 10.1093/bioinformatics/btw612.
Epub 2016 Sep 25.

cMapper: gene-centric connectivity mapper for EBI-RDF platform.

Shoaib M(1,)(2), Ansari AA(1,)(2), Ahn SM(2,)(3,)(4).

Author information: 
(1)Department of Biomedical Engineering, College of Medicine, University of
Ulsan, Asan Medical Center, Seoul, Republic of Korea. (2)Gachon Institute of
Genome Medicine and Sciences. (3)Division of Hematology and Oncology, Department 
of Internal Medicine, Gachon University Gil Medical Center, Incheon, Republic of 
Korea. (4)Department of Genome Medicine and Science, College of Medicine, Gachon 
University, Seongnam, Republic of Korea.

MOTIVATION: In this era of biological big data, data integration has become a
common task and a challenge for biologists. The Resource Description Framework
(RDF) was developed to enable interoperability of heterogeneous datasets. The
EBI-RDF platform enables an efficient data integration of six independent
biological databases using RDF technologies and shared ontologies. However, to
take advantage of this platform, biologists need to be familiar with RDF
technologies and SPARQL query language. To overcome this practical limitation of 
the EBI-RDF platform, we developed cMapper, a web-based tool that enables
biologists to search the EBI-RDF databases in a gene-centric manner without a
thorough knowledge of RDF and SPARQL.
RESULTS: cMapper allows biologists to search data entities in the EBI-RDF
platform that are connected to genes or small molecules of interest in multiple
biological contexts. The input to cMapper consists of a set of genes or small
molecules, and the output are data entities in six independent EBI-RDF databases 
connected with the given genes or small molecules in the user's query. cMapper
provides output to users in the form of a graph in which nodes represent data
entities and the edges represent connections between data entities and inputted
set of genes or small molecules. Furthermore, users can apply filters based on
database, taxonomy, organ and pathways in order to focus on a core connectivity
graph of their interest. Data entities from multiple databases are differentiated
based on background colors. cMapper also enables users to investigate shared
connections between genes or small molecules of interest. Users can view the
output graph on a web browser or download it in either GraphML or JSON formats.
AVAILABILITY AND IMPLEMENTATION: cMapper is available as a web application with
an integrated MySQL database. The web application was developed using Java and
deployed on Tomcat server. We developed the user interface using HTML5, JQuery
and the Cytoscape Graph API. cMapper can be accessed at
http://cmapper.ewostech.net Readers can download the development manual from the 
website http://cmapper.ewostech.net/docs/cMapperDocumentation.pdf. Source Code is
available at
https://github.com/muhammadshoaib/cmapperContact:smahn@gachon.ac.krSupplementary 
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw612 
PMID: 27667790  [PubMed - in process]


264. Bioinformatics. 2017 Jan 15;33(2):306-308. doi: 10.1093/bioinformatics/btw611.
Epub 2016 Sep 22.

FoldAtlas: a repository for genome-wide RNA structure probing data.

Norris M(1), Kwok CK(2), Cheema J(1), Hartley M(1), Morris RJ(1), Aviran S(3),
Ding Y(1).

Author information: 
(1)John Innes Centre, Norwich Research Park, Norwich, UK. (2)Department of
Biology and Chemistry, City University of Hong Kong, Kowloon Tong, Hong Kong SAR,
China. (3)Department of Biomedical Engineering and Genome Center, UC Davis,
Davis, CA, USA.

Most RNA molecules form internal base pairs, leading to a folded secondary
structure. Some of these structures have been demonstrated to be functionally
significant. High-throughput RNA structure chemical probing methods generate
millions of sequencing reads to provide structural constraints for RNA secondary 
structure prediction. At present, processed data from these experiments are
difficult to access without computational expertise. Here we present FoldAtlas, a
web interface for accessing raw and processed structural data across thousands of
transcripts. FoldAtlas allows a researcher to easily locate, view, and retrieve
probing data for a given RNA molecule. We also provide in silico and in vivo
secondary structure predictions for comparison, visualized in the browser as
circle plots and topology diagrams. Data currently integrated into FoldAtlas are 
from a new high-depth Structure-seq data analysis in Arabidopsis thaliana,
released with this work.AVAILABILITY AND IMPLEMENTATION: The FoldAtlas website
can be accessed at www.foldatlas.com Source code is freely available at
github.com/mnori/foldatlas under the MIT license. Raw reads data are available
under the NCBI SRA accession SRP066985.
CONTACT: yiliang.ding@jic.ac.uk or matthew.norris@jic.ac.ukSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw611 
PMCID: PMC5254078
PMID: 27663500  [PubMed - in process]


265. Bioinformatics. 2017 Jan 15;33(2):235-242. doi: 10.1093/bioinformatics/btw607.
Epub 2016 Sep 23.

Robust classification of single-cell transcriptome data by nonnegative matrix
factorization.

Shao C(1,)(2), Höfer T(1,)(2).

Author information: 
(1)Division of Theoretical Systems Biology, German Cancer Research Center (DKFZ),
69120 Heidelberg, Germany. (2)Bioquant Center, University of Heidelberg, 69120
Heidelberg, Germany.

MOTIVATION: Single-cell transcriptome data provide unprecedented resolution to
study heterogeneity in cell populations and present a challenge for unsupervised 
classification. Popular methods, like principal component analysis (PCA), often
suffer from the high level of noise in the data.
RESULTS: Here we adapt Nonnegative Matrix Factorization (NMF) to study the
problem of identifying subpopulations in single-cell transcriptome data. In
contrast to the conventional gene-centered view of NMF, identifying metagenes, we
used NMF in a cell-centered direction, identifying cell subtypes ('metacells').
Using three different datasets (based on RT-qPCR and single cell RNA-seq data,
respectively), we show that NMF outperforms PCA in identifying subpopulations in 
an accurate and robust way, without the need for prior feature selection;
moreover, NMF successfully recovered the broad classes on a large dataset
(thousands of single-cell transcriptomes), as identified by a computationally
sophisticated method. NMF allows to identify feature genes in a direct, unbiased 
manner. We propose novel approaches for determining a biologically meaningful
number of subpopulations based on minimizing the ambiguity of classification. In 
conclusion, our study shows that NMF is a robust, informative and simple method
for the unsupervised learning of cell subtypes from single-cell gene expression
data.
AVAILABILITY AND IMPLEMENTATION: https://github.com/ccshao/nimfa CONTACTS:
c.shao@Dkfz-Heidelberg.de or t.hoefer@Dkfz-Heidelberg.deSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw607 
PMID: 27663498  [PubMed - in process]


266. Bioinformatics. 2017 Jan 15;33(2):202-209. doi: 10.1093/bioinformatics/btw603.
Epub 2016 Sep 23.

An accessibility-incorporated method for accurate prediction of RNA-RNA
interactions from sequence data.

Kato Y(1), Mori T(2), Sato K(3), Maegawa S(4), Hosokawa H(4), Akutsu T(5).

Author information: 
(1)Department of RNA Biology and Neuroscience, Graduate School of Medicine, Osaka
University, Suita, Osaka 565-0871, Japan. (2)Center for iPS Cell Research and
Application (CiRA), Kyoto University, Shogoin, Sakyo-ku, Kyoto 606-8507, Japan.
(3)Faculty of Science and Technology, Keio University, Kohoku-ku, Yokohama,
Kanagawa 223-8522, Japan. (4)Graduate School of Informatics, Kyoto University,
Sakyo-ku, Kyoto 606-8501, Japan. (5)Bioinformatics Center, Institute for Chemical
Research, Kyoto University, Gokasho, Uji, Kyoto 611-0011, Japan.

MOTIVATION: RNA-RNA interactions via base pairing play a vital role in the
post-transcriptional regulation of gene expression. Efficient identification of
targets for such regulatory RNAs needs not only discriminative power for positive
and negative RNA-RNA interacting sequence data but also accurate prediction of
interaction sites from positive data. Recently, a few studies have incorporated
interaction site accessibility into their prediction methods, indicating the
enhancement of predictive performance on limited positive data.
RESULTS: Here we show the efficacy of our accessibility-based prediction model
RactIPAce on newly compiled datasets. The first experiment in interaction site
prediction shows that RactIPAce achieves the best predictive performance on the
newly compiled dataset of experimentally verified interactions in the literature 
as compared with the state-of-the-art methods. In addition, the second experiment
in discrimination between positive and negative interacting pairs reveals that
the combination of accessibility-based methods including our approach can be
effective to discern real interacting RNAs. Taking these into account, our
prediction model can be effective to predict interaction sites after screening
for real interacting RNAs, which will boost the functional analysis of regulatory
RNAs.
AVAILABILITY AND IMPLEMENTATION: The program RactIPAce along with data used in
this work is available at https://github.com/satoken/ractip/releases/tag/v1.0.1
CONTACT: : ykato@rna.med.osaka-u.ac.jp or shingo@i.kyoto-u.ac.jpSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw603 
PMID: 27663495  [PubMed - in process]


267. BMC Bioinformatics. 2016 Sep 23;17(1):394.

rapidGSEA: Speeding up gene set enrichment analysis on multi-core CPUs and
CUDA-enabled GPUs.

Hundt C(1), Hildebrandt A(2), Schmidt B(2).

Author information: 
(1)Department of Computer Science, Johannes Gutenberg University, Staudingerweg
9, Mainz, 55128, Germany. hundt@uni-mainz.de. (2)Department of Computer Science, 
Johannes Gutenberg University, Staudingerweg 9, Mainz, 55128, Germany.

BACKGROUND: Gene Set Enrichment Analysis (GSEA) is a popular method to reveal
significant dependencies between predefined sets of gene symbols and observed
phenotypes by evaluating the deviation of gene expression values between cases
and controls. An established measure of inter-class deviation, the enrichment
score, is usually computed using a weighted running sum statistic over the whole 
set of gene symbols. Due to the lack of analytic expressions the significance of 
enrichment scores is determined using a non-parametric estimation of their null
distribution by permuting the phenotype labels of the probed patients.
Accordingly, GSEA is a time-consuming task due to the large number of required
permutations to accurately estimate the nominal p-value - a circumstance that is 
even more pronounced during multiple hypothesis testing since its estimate is
lower-bounded by the inverse number of samples in permutation space.
RESULTS: We present rapidGSEA - a software suite consisting of two tools for
facilitating permutation-based GSEA: cudaGSEA and ompGSEA. cudaGSEA is a
CUDA-accelerated tool using fine-grained parallelization schemes on massively
parallel architectures while ompGSEA is a coarse-grained multi-threaded tool for 
multi-core CPUs. Nominal p-value estimation of 4,725 gene sets on a data set
consisting of 20,639 unique gene symbols and 200 patients (183 cases + 17
controls) each probing one million permutations takes 19 hours on a Xeon CPU and 
less than one hour on a GeForce Titan X GPU while the established GSEA tool from 
the Broad Institute (broadGSEA) takes roughly 13 days.
CONCLUSION: cudaGSEA outperforms broadGSEA by around two orders-of-magnitude on a
single Tesla K40c or GeForce Titan X GPU. ompGSEA provides around one
order-of-magnitude speedup to broadGSEA on a standard Xeon CPU. The rapidGSEA
suite is open-source software and can be downloaded at
https://github.com/gravitino/cudaGSEA as standalone application or package for
the R framework.

DOI: 10.1186/s12859-016-1244-x 
PMCID: PMC5035472
PMID: 27663265  [PubMed - as supplied by publisher]


268. PLoS One. 2016 Sep 23;11(9):e0163453. doi: 10.1371/journal.pone.0163453.

Image-Based Single Cell Profiling: High-Throughput Processing of Mother Machine
Experiments.

Sachs CC(1), Grünberger A(1), Helfrich S(1), Probst C(1), Wiechert W(1),
Kohlheyer D(1), Nöh K(1).

Author information: 
(1)Institute for Bio- and Geosciences, IBG-1: Biotechnology, Forschungszentrum
Jülich GmbH, Jülich, Germany.

BACKGROUND: Microfluidic lab-on-chip technology combined with live-cell imaging
has enabled the observation of single cells in their spatio-temporal context. The
mother machine (MM) cultivation system is particularly attractive for the
long-term investigation of rod-shaped bacteria since it facilitates continuous
cultivation and observation of individual cells over many generations in a highly
parallelized manner. To date, the lack of fully automated image analysis software
limits the practical applicability of the MM as a phenotypic screening tool.
RESULTS: We present an image analysis pipeline for the automated processing of MM
time lapse image stacks. The pipeline supports all analysis steps, i.e., image
registration, orientation correction, channel/cell detection, cell tracking, and 
result visualization. Tailored algorithms account for the specialized MM layout
to enable a robust automated analysis. Image data generated in a two-day growth
study (≈ 90 GB) is analyzed in ≈ 30 min with negligible differences in growth
rate between automated and manual evaluation quality. The proposed methods are
implemented in the software molyso (MOther machine AnaLYsis SOftware) that
provides a new profiling tool to analyze unbiasedly hitherto inaccessible
large-scale MM image stacks.
CONCLUSION: Presented is the software molyso, a ready-to-use open source software
(BSD-licensed) for the unsupervised analysis of MM time-lapse image stacks.
molyso source code and user manual are available at
https://github.com/modsim/molyso.

DOI: 10.1371/journal.pone.0163453 
PMCID: PMC5035088
PMID: 27661996  [PubMed - as supplied by publisher]


269. BMC Bioinformatics. 2016 Sep 22;17(1):390.

MicroScope: ChIP-seq and RNA-seq software analysis suite for gene expression
heatmaps.

Khomtchouk BB(1), Hennessy JR(2), Wahlestedt C(3).

Author information: 
(1)Center for Therapeutic Innovation and Department of Psychiatry and Behavioral 
Sciences, University of Miami Miller School of Medicine, 1120 NW 14th ST, Miami, 
33136, FL, USA. b.khomtchouk@med.miami.edu. (2)Department of Mathematics,
University of Miami, 1365 Memorial Drive, Coral Gables, 33146, FL, USA. (3)Center
for Therapeutic Innovation and Department of Psychiatry and Behavioral Sciences, 
University of Miami Miller School of Medicine, 1120 NW 14th ST, Miami, 33136, FL,
USA.

BACKGROUND: Heatmaps are an indispensible visualization tool for examining
large-scale snapshots of genomic activity across various types of next-generation
sequencing datasets. However, traditional heatmap software do not typically offer
multi-scale insight across multiple layers of genomic analysis (e.g.,
differential expression analysis, principal component analysis, gene ontology
analysis, and network analysis) or multiple types of next-generation sequencing
datasets (e.g., ChIP-seq and RNA-seq). As such, it is natural to want to interact
with a heatmap's contents using an extensive set of integrated analysis tools
applicable to a broad array of genomic data types.
RESULTS: We propose a user-friendly ChIP-seq and RNA-seq software suite for the
interactive visualization and analysis of genomic data, including integrated
features to support differential expression analysis, interactive heatmap
production, principal component analysis, gene ontology analysis, and dynamic
network analysis.
CONCLUSIONS: MicroScope is hosted online as an R Shiny web application based on
the D3 JavaScript library: http://microscopebioinformatics.org/ . The methods are
implemented in R, and are available as part of the MicroScope project at:
https://github.com/Bohdan-Khomtchouk/Microscope .

DOI: 10.1186/s12859-016-1260-x 
PMCID: PMC5034416
PMID: 27659774  [PubMed - as supplied by publisher]


270. Bioinformatics. 2016 Sep 21. pii: btw609. doi: 10.1093/bioinformatics/btw609.
[Epub ahead of print]

TwoPaCo: an efficient algorithm to build the compacted de Bruijn graph from many 
complete genomes.

Minkin I(1), Pham S(2), Medvedev P(1,)(3,)(4).

Author information: 
(1)Department of Computer Science and Engineering, The Pennsylvania State
University, University Park, PA 16802, USA. (2)BioTuring Inc., San Diego, CA
92121, USA. (3)Department of Biochemistry and Molecular Biology. (4)Genomic
Sciences Institute of the Huck, The Pennsylvania State University, University
Park, PA 16802, USA.

MOTIVATION: de Bruijn graphs have been proposed as a data structure to facilitate
the analysis of related whole genome sequences, in both a population and
comparative genomic settings. However, current approaches do not scale well to
many genomes of large size (such as mammalian genomes).
RESULTS: In this article, we present TwoPaCo, a simple and scalable low memory
algorithm for the direct construction of the compacted de Bruijn graph from a set
of complete genomes. We demonstrate that it can construct the graph for 100
simulated human genomes in less than a day and eight real primates in < 2 h, on a
typical shared-memory machine. We believe that this progress will enable novel
biological analyses of hundreds of mammalian-sized genomes.
AVAILABILITY AND IMPLEMENTATION: Our code and data is available for download from
github.com/medvedevgroup/TwoPaCo.
CONTACT: ium125@psu.eduSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw609 
PMID: 27659452  [PubMed - as supplied by publisher]


271. Bioinformatics. 2017 Jan 15;33(2):294-296. doi: 10.1093/bioinformatics/btw606.
Epub 2016 Sep 21.

GeneEvolve: a fast and memory efficient forward-time simulator of realistic
whole-genome sequence and SNP data.

Tahmasbi R(1), Keller MC(1,)(2).

Author information: 
(1)Institute for Behavioral Genetics (IBG). (2)Department of Psychology and
Neuroscience, University of Colorado, Boulder, CO 80309, USA.

MOTIVATION: Computer simulations are excellent tools for understanding the
evolutionary and genetic consequences of complex processes that cannot be
analytically predicted and for creating realistic genetic data. There are many
software packages that simulate genetic data, but they are typically not fast or 
memory efficient enough to simulate realistic, individual-level genome-wide
SNP/sequence data.
RESULTS: GeneEvolve is a user-friendly and efficient population genetics
simulator that handles complex evolutionary and life history scenarios and
generates individual-level phenotypes and realistic whole-genome sequence or SNP 
data. GeneEvolve runs forward-in-time, which allows it to provide a wide range of
scenarios for mating systems, selection, population size and structure,
migration, recombination and environmental effects. The software is designed to
use as input data from real or previously simulated phased haplotypes, allowing
it to mimic very closely the properties of real genomic data.
AVAILABILITY AND IMPLEMENTATION: GeneEvolve is freely available at
https://github.com/rtahmasbi/GeneEvolve CONTACT:
Rasool.Tahmasbi@Colorado.eduSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw606 
PMID: 27659450  [PubMed - in process]


272. Comput Biol Chem. 2016 Dec;65:178-184. doi: 10.1016/j.compbiolchem.2016.09.004.
Epub 2016 Sep 9.

SnpFilt: A pipeline for reference-free assembly-based identification of SNPs in
bacterial genomes.

Chan CH(1), Octavia S(1), Sintchenko V(2), Lan R(3).

Author information: 
(1)School of Biotechnology and Biomolecular Sciences, University of New South
Wales, Sydney, New South Wales, 2052, Australia. (2)Centre for Infectious
Diseases and Microbiology-Public Health, Institute of Clinical Pathology and
Medical Research, Westmead Hospital, New South Wales, Australia; Marie Bashir
Institute for Infectious Diseases and Biosecurity, The University of Sydney, New 
South Wales, Australia. (3)School of Biotechnology and Biomolecular Sciences,
University of New South Wales, Sydney, New South Wales, 2052, Australia.
Electronic address: r.lan@unsw.edu.au.

De novo assembly of bacterial genomes from next-generation sequencing (NGS) data 
allows a reference-free discovery of single nucleotide polymorphisms (SNP).
However, substantial rates of errors in genomes assembled by this approach remain
a major barrier for the reference-free analysis of genome variations in medically
important bacteria. The aim of this report was to improve the quality of SNP
identification in bacterial genomes without closely related references. We
developed a bioinformatics pipeline (SnpFilt) that constructs an assembly using
SPAdes and then removes unreliable regions based on the quality and coverage of
re-aligned reads at neighbouring regions. The performance of the pipeline was
compared against reference-based SNP calling for Illumina HiSeq, MiSeq and
NextSeq reads from a range of bacterial pathogens including Salmonella, which is 
one of the most common causes of food-borne disease. The SnpFilt pipeline removed
all false SNP in all test NGS datasets consisting of paired-end Illumina reads.
We also showed that for reliable and complete SNP calls, at least 40-fold
coverage is required. Analysis of bacterial isolates associated with
epidemiologically confirmed outbreaks using the SnpFilt pipeline produced results
consistent with previously published findings. The SnpFilt pipeline improves the 
quality of de-novo assembly and precision of SNP calling in bacterial genomes by 
removal of regions of the assembly that may potentially contain assembly errors. 
SnpFilt is available from https://github.com/LanLab/SnpFilt.

Copyright Â© 2016 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.compbiolchem.2016.09.004 
PMID: 27647159  [PubMed - in process]


273. Genetics. 2016 Nov;204(3):921-931. doi: 10.1534/genetics.116.190454. Epub 2016
Sep 19.

Boosting Gene Mapping Power and Efficiency with Efficient Exact Variance
Component Tests of Single Nucleotide Polymorphism Sets.

Zhou JJ(1), Hu T(2,)(3), Qiao D(4), Cho MH(5,)(6,)(7), Zhou H(8).

Author information: 
(1)Division of Epidemiology and Biostatistics, Mel and Enid Zuckerman College of 
Public Health, University of Arizona, Tucson, Arizona 85724
jzhou@email.arizona.edu. (2)Bioinformatics Research Center, North Carolina State 
University, Raleigh, North Carolina 27695. (3)Department of Statistics, North
Carolina State University, Raleigh, North Carolina 27695. (4)Department of
Biostatistics, Harvard School of Public Health, Boston, Massachusetts.
(5)Channing Division of Network Medicine, Department of Medicine, Brigham and
Women's Hospital, Boston, Massachusetts. (6)Harvard Medical School, Boston,
Massachusetts. (7)Division of Pulmonary and Critical Care Medicine, Department of
Medicine, Brigham and Women's Hospital, Boston, Massachusetts 02115.
(8)Department of Biostatistics, University of California, Los Angeles, California
90095.

Single nucleotide polymorphism (SNP) set tests have been a powerful method in
analyzing next-generation sequencing (NGS) data. The popular sequence kernel
association test (SKAT) method tests a set of variants as random effects in the
linear mixed model setting. Its P-value is calculated based on asymptotic theory 
that requires a large sample size. Therefore, it is known that SKAT is
conservative and can lose power at small or moderate sample sizes. Given the
current cost of sequencing technology, scales of NGS are still limited. In this
report, we derive and implement computationally efficient, exact (nonasymptotic) 
score (eScore), likelihood ratio (eLRT), and restricted likelihood ratio (eRLRT) 
tests, ExactVCTest, that can achieve high power even when sample sizes are small.
We perform simulation studies under various genetic scenarios. Our ExactVCTest
(i.e., eScore, eLRT, eRLRT) exhibits well-controlled type I error. Under the
alternative model, eScore P-values are universally smaller than those from SKAT. 
eLRT and eRLRT demonstrate significantly higher power than eScore, SKAT, and SKAT
optimal (SKAT-o) across all scenarios and various samples sizes. We applied these
tests to an exome sequencing study. Our findings replicate previous results and
shed light on rare variant effects within genes. The software package is
implemented in the open source, high-performance technical computing language
Julia, and is freely available at
https://github.com/Tao-Hu/VarianceComponentTest.jl Analysis of each trait in the 
exome sequencing data set with 399 individuals and 16,619 genes takes around 1
min on a desktop computer.

Copyright © 2016 by the Genetics Society of America.

DOI: 10.1534/genetics.116.190454 
PMCID: PMC5105869
PMID: 27646141  [PubMed - in process]


274. BMC Bioinformatics. 2016 Sep 17;17:383. doi: 10.1186/s12859-016-1237-9.

Structural alignment of protein descriptors - a combinatorial model.

Antczak M(1), Kasprzak M(2,)(3), Lukasiak P(2,)(3), Blazewicz J(2,)(3).

Author information: 
(1)Institute of Computing Science, Poznan University of Technology, Piotrowo 2,
Poznan, 60-965, Poland. maciej.antczak@cs.put.poznan.pl. (2)Institute of
Computing Science, Poznan University of Technology, Piotrowo 2, Poznan, 60-965,
Poland. (3)Institute of Bioorganic Chemistry, Polish Academy of Sciences,
Noskowskiego 12/14, Poznan, 61-704, Poland.

BACKGROUND: Structural alignment of proteins is one of the most challenging
problems in molecular biology. The tertiary structure of a protein strictly
correlates with its function and computationally predicted structures are
nowadays a main premise for understanding the latter. However, computationally
derived 3D models often exhibit deviations from the native structure. A way to
confirm a model is a comparison with other structures. The structural alignment
of a pair of proteins can be defined with the use of a concept of protein
descriptors. The protein descriptors are local substructures of protein
molecules, which allow us to divide the original problem into a set of
subproblems and, consequently, to propose a more efficient algorithmic solution. 
In the literature, one can find many applications of the descriptors concept that
prove its usefulness for insight into protein 3D structures, but the proposed
approaches are presented rather from the biological perspective than from the
computational or algorithmic point of view. Efficient algorithms for
identification and structural comparison of descriptors can become crucial
components of methods for structural quality assessment as well as tertiary
structure prediction.
RESULTS: In this paper, we propose a new combinatorial model and new
polynomial-time algorithms for the structural alignment of descriptors. The model
is based on the maximum-size assignment problem, which we define here and prove
that it can be solved in polynomial time. We demonstrate suitability of this
approach by comparison with an exact backtracking algorithm. Besides a
simplification coming from the combinatorial modeling, both on the conceptual and
complexity level, we gain with this approach high quality of obtained results, in
terms of 3D alignment accuracy and processing efficiency.
CONCLUSIONS: All the proposed algorithms were developed and integrated in a
computationally efficient tool descs-standalone, which allows the user to
identify and structurally compare descriptors of biological molecules, such as
proteins and RNAs. Both PDB (Protein Data Bank) and mmCIF (macromolecular
Crystallographic Information File) formats are supported. The proposed tool is
available as an open source project stored on GitHub (
https://github.com/mantczak/descs-standalone ).

DOI: 10.1186/s12859-016-1237-9 
PMCID: PMC5027075
PMID: 27639380  [PubMed - in process]


275. G3 (Bethesda). 2016 Sep 16. pii: g3.116.034249. doi: 10.1534/g3.116.034249. [Epub
ahead of print]

in silico Whole Genome Sequencer & Analyzer (iWGS): A Computational Pipeline to
Guide the Design and Analysis of de novo Genome Sequencing Studies.

Zhou X(1), Peris D(2), Kominek J(2), Kurtzman CP(3), Hittinger CT(4), Rokas A(5).

Author information: 
(1)Vanderbilt University; (2)University of Wisconsin-Madison; (3)US Department of
Agriculture. (4)University of Wisconsin-Madison; cthittinger@wisc.edu.
(5)Vanderbilt University; antonis.rokas@vanderbilt.edu.

The availability of genomes across the tree of life is highly biased toward
vertebrates, pathogens, human disease models, and organisms with relatively small
and simple genomes. Recent progress in genomics has enabled the de novo decoding 
of the genome of virtually any organism, greatly expanding its potential for
understanding the biology and evolution of the full spectrum of biodiversity. The
increasing diversity of sequencing technologies, assays, and de novo assembly
algorithms have augmented the complexity of de novo genome sequencing projects in
non-model organisms. To reduce the costs and challenges in de novo genome
sequencing projects and streamline their experimental design and analysis, we
developed iWGS (in silico Whole Genome Sequencer and Analyzer), an automated
pipeline for guiding the choice of appropriate sequencing strategy and assembly
protocols. iWGS seamlessly integrates the four key steps of a de novo genome
sequencing project: data generation (through simulation), data quality control,
de novo assembly, and assembly evaluation and validation. The last three steps
can also be applied to the analysis of real data. iWGS is designed to enable the 
user to have great flexibility in testing the range of experimental designs
available for genome sequencing projects, and supports all major sequencing
technologies and popular assembly tools. Three case studies illustrate how iWGS
can guide the design of de novo genome sequencing projects and evaluate the
performance of a wide variety of user-specified sequencing strategies and
assembly protocols on genomes of differing architectures. iWGS, along with a
detailed documentation, is freely available at
https://github.com/zhouxiaofan1983/iWGS.

Copyright © 2016 Author et al.

DOI: 10.1534/g3.116.034249 
PMCID: PMC5100864
PMID: 27638685  [PubMed - as supplied by publisher]


276. Bioinformatics. 2017 Jan 15;33(2):169-176. doi: 10.1093/bioinformatics/btw597.
Epub 2016 Sep 14.

BOSS: a novel scaffolding algorithm based on an optimized scaffold graph.

Luo J(1,)(2), Wang J(1), Zhang Z(1), Li M(1), Wu FX(3).

Author information: 
(1)School of Information Science and Engineering, Central South University,
ChangSha 410083, China. (2)College of Computer Science and Technology, Henan
Polytechnic University, JiaoZuo 454000, China. (3)Division of Biomedical
Engineering, University of Saskatchewan, Saskatchewan S7N 5A9, Canada.

MOTIVATION: While aiming to determine orientations and orders of fragmented
contigs, scaffolding is an essential step of assembly pipelines and can make
assembly results more complete. Most existing scaffolding tools adopt scaffold
graph approaches. However, due to repetitive regions in genome, sequencing errors
and uneven sequencing depth, constructing an accurate scaffold graph is still a
challenge task.
RESULTS: In this paper, we present a novel algorithm (called BOSS), which employs
paired reads for scaffolding. To construct a scaffold graph, BOSS utilizes the
distribution of insert size to decide whether an edge between two vertices
(contigs) should be added and how an edge should be weighed. Moreover, BOSS
adopts an iterative strategy to detect spurious edges whose removal can guarantee
no contradictions in the scaffold graph. Based on the scaffold graph constructed,
BOSS employs a heuristic algorithm to sort vertices (contigs) and then generates 
scaffolds. The experimental results demonstrate that BOSS produces more
satisfactory scaffolds, compared with other popular scaffolding tools on real
sequencing data of four genomes.
AVAILABILITY AND IMPLEMENTATION: BOSS is publicly available for download at
https://github.com/bioinfomaticsCSU/BOSS CONTACT:
jxwang@mail.csu.edu.cnSupplementary information: Supplementary data are available
at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw597 
PMID: 27634951  [PubMed - in process]


277. Bioinformatics. 2017 Jan 1;33(1):139-141. doi: 10.1093/bioinformatics/btw585.
Epub 2016 Sep 14.

RiboDiff: detecting changes of mRNA translation efficiency from ribosome
footprints.

Zhong Y(1), Karaletsos T(1), Drewe P(2), Sreedharan VT(1), Kuo D(1), Singh K(3), 
Wendel HG(3), Rätsch G(1,)(4).

Author information: 
(1)Computational Biology Program, Sloan Kettering Institute, New York, NY 1275,
USA. (2)Max Delbrück Center for Molecular Medicine, 13125 Berlin, Germany.
(3)Cancer Biology Program, Sloan Kettering Institute, New York, NY, USA.
(4)Department of Computer Science, ETH Zurich, Universitatsstrasse 6, 8092 Zrich,
Switzerland.

MOTIVATION: Deep sequencing based ribosome footprint profiling can provide novel 
insights into the regulatory mechanisms of protein translation. However, the
observed ribosome profile is fundamentally confounded by transcriptional
activity. In order to decipher principles of translation regulation, tools that
can reliably detect changes in translation efficiency in case-control studies are
needed.
RESULTS: We present a statistical framework and an analysis tool, RiboDiff, to
detect genes with changes in translation efficiency across experimental
treatments. RiboDiff uses generalized linear models to estimate the
over-dispersion of RNA-Seq and ribosome profiling measurements separately, and
performs a statistical test for differential translation efficiency using both
mRNA abundance and ribosome occupancy.
AVAILABILITY AND IMPLEMENTATION: RiboDiff webpage http://bioweb.me/ribodiff
Source code including scripts for preprocessing the FASTQ data are available at
http://github.com/ratschlab/ribodiff CONTACTS: zhongy@cbio.mskcc.org or
raetsch@inf.ethz.chSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw585 
PMCID: PMC5198522
PMID: 27634950  [PubMed - in process]


278. Bioinformatics. 2017 Jan 15;33(2):184-191. doi: 10.1093/bioinformatics/btw591.
Epub 2016 Sep 14.

Seeksv: an accurate tool for somatic structural variation and virus integration
detection.

Liang Y(1,)(2), Qiu K(2), Liao B(1), Zhu W(1), Huang X(2), Li L(2), Chen X(1), Li
K(1,)(3).

Author information: 
(1)College of Information Science and Engineering, Hunan University, Changsha,
Hunan 410082, China. (2)BGI, Shenzhen, Guangdong 518083, China. (3)Department of 
Computer Science State, University of New York, New Paltz, NY 12561, USA.

MOTIVATION: Many forms of variations exist in the human genome including single
nucleotide polymorphism, small insert/deletion (DEL) (indel) and structural
variation (SV). Somatically acquired SV may regulate the expression of
tumor-related genes and result in cell proliferation and uncontrolled growth,
eventually inducing tumor formation. Virus integration with host genome sequence 
is a type of SV that causes the related gene instability and normal cells to
transform into tumor cells. Cancer SVs and viral integration sites must be
discovered in a genome-wide scale for clarifying the mechanism of tumor
occurrence and development.
RESULTS: In this paper, we propose a new tool called seeksv to detect somatic SVs
and viral integration events. Seeksv simultaneously uses split read signal,
discordant paired-end read signal, read depth signal and the fragment with two
ends unmapped. Seeksv can detect DEL, insertion, inversion and inter-chromosome
transfer at single-nucleotide resolution. Different types of sequencing data,
such as single-end sequencing data or paired-end sequencing data can accommodate 
to detect SV. Seeksv develops a rescue model for SV with breakpoints located in
sequence homology regions. Results on simulated and real data from the 1000
Genomes Project and esophageal squamous cell carcinoma samples show that seeksv
has higher efficiency and precision compared with other similar software in
detecting SVs. For the discovery of hepatitis B virus integration sites from
probe capture data, the verified experiments show that more than 90% viral
integration sequences detected by seeksv are true.
AVAILABILITY AND IMPLEMENTATION: seeksv is implemented in C ++ and can be
downloaded from https://github.com/qkl871118/seeksv CONTACT: :
dragonbw@163.comSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw591 
PMID: 27634948  [PubMed - in process]


279. Bioinformatics. 2017 Jan 15;33(2):300-302. doi: 10.1093/bioinformatics/btw588.
Epub 2016 Sep 14.

IsotopicLabelling: an R package for the analysis of MS isotopic patterns of
labelled analytes.

Ferrazza R(1,)(2,)(3), Griffin JL(3,)(4), Guella G(1,)(5), Franceschi P(6).

Author information: 
(1)Bioorganic Chemistry Laboratory, Department of Physics. (2)Centre for
Integrative Biology (CIBIO), University of Trento, 38123 Povo (TN), Italy.
(3)Department of Biochemistry, University of Cambridge, Cambridge CB2 1GA, UK.
(4)Medical Research Council (MRC) Human Nutrition Research (HNR), Cambridge CB1
9NL, UK. (5)Biophysical Institute, CNR, 38123 Povo (TN), Italy. (6)Edmund Mach
Foundation, Research and Innovation Centre, Computational Biology Unit, I-38010
San Michele All'Adige (TN), Italy.

MOTIVATION: Labelling experiments in biology usually make use of isotopically
enriched substrates, with the two most commonly employed isotopes for metabolism 
being (2)H and (13)C. At the end of the experiment some metabolites will have
incorporated the labelling isotope, to a degree that depends on the metabolic
turnover. In order to propose a meaningful biological interpretation, it is
necessary to estimate the amount of labelling, and one possible route is to
exploit the fact that MS isotopic patterns reflect the isotopic distributions.
RESULTS: We developed the IsotopicLabelling R package, a tool able to extract and
analyze isotopic patterns from liquid chromatography-mass spectrometry (LC-MS)
and gas chromatography-MS (GC-MS) data relative to labelling experiments. This
package estimates the isotopic abundance of the employed stable isotope (either
(2)H or (13)C) within a specified list of analytes.
AVAILABILITY AND IMPLEMENTATION: The IsotopicLabelling R package is freely
available at https://github.com/RuggeroFerrazza/IsotopicLabelling CONTACTS:
r.ferrazza@unitn.itSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw588 
PMID: 27634947  [PubMed - in process]


280. Bioinformatics. 2017 Jan 1;33(1):142-144. doi: 10.1093/bioinformatics/btw576.
Epub 2016 Sep 14.

AKT: ancestry and kinship toolkit.

Arthur R(1), Schulz-Trieglaff O(1), Cox AJ(1), O'Connell J(1).

Author information: 
(1)Illumina Cambridge Ltd., Chesterford Research Park, Little Chesterford, Essex 
CB10 1XL, UK.

MOTIVATION: Ancestry and Kinship Toolkit (AKT) is a statistical genetics tool for
analysing large cohorts of whole-genome sequenced samples. It can rapidly detect 
related samples, characterize sample ancestry, calculate correlation between
variants, check Mendel consistency and perform data clustering. AKT brings
together the functionality of many state-of-the-art methods, with a focus on
speed and a unified interface. We believe it will be an invaluable tool for the
curation of large WGS datasets.
AVAILABILITY AND IMPLEMENTATION: The source code is available at
https://illumina.github.io/akt CONTACTS: joconnell@illumina.com or
rudy.d.arthur@gmail.comSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw576 
PMID: 27634946  [PubMed - in process]


281. Bioinformatics. 2017 Jan 15;33(2):219-226. doi: 10.1093/bioinformatics/btw598.
Epub 2016 Sep 15.

Reference point insensitive molecular data analysis.

Altenbuchinger M(1), Rehberg T(1), Zacharias HU(2), Stämmler F(1,)(3), Dettmer
K(2), Weber D(4), Hiergeist A(3), Gessner A(3), Holler E(4), Oefner PJ(2), Spang 
R(1).

Author information: 
(1)Statistical Bioinformatics, Institute of Functional Genomics, University of
Regensburg, Regensburg, Germany. (2)Institute of Functional Genomics, University 
of Regensburg, Regensburg, Germany. (3)Institute of Clinical Microbiology and
Hygiene, University Medical Center, Regensburg, Germany. (4)Department of
Hematology and Oncology, Internal Medicine III, University Medical Center,
Regensburg, Germany.

MOTIVATION: In biomedicine, every molecular measurement is relative to a
reference point, like a fixed aliquot of RNA extracted from a tissue, a defined
number of blood cells, or a defined volume of biofluid. Reference points are
often chosen for practical reasons. For example, we might want to assess the
metabolome of a diseased organ but can only measure metabolites in blood or
urine. In this case, the observable data only indirectly reflects the disease
state. The statistical implications of these discrepancies in reference points
have not yet been discussed.
RESULTS: Here, we show that reference point discrepancies compromise the
performance of regression models like the LASSO. As an alternative, we suggest
zero-sum regression for a reference point insensitive analysis. We show that
zero-sum regression is superior to the LASSO in case of a poor choice of
reference point both in simulations and in an application that integrates
intestinal microbiome analysis with metabolomics. Moreover, we describe a novel
coordinate descent based algorithm to fit zero-sum elastic nets.
AVAILABILITY AND IMPLEMENTATION: The R-package "zeroSum" can be downloaded at
https://github.com/rehbergT/zeroSum Moreover, we provide all R-scripts and data
used to produce the results of this manuscript as Supplementary Material CONTACT:
Michael.Altenbuchinger@ukr.de, Thorsten.Rehberg@ukr.de and
Rainer.Spang@ukr.deSupplementary information: Supplementary material is available
at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw598 
PMID: 27634945  [PubMed - in process]


282. Mol Biol Evol. 2016 Dec;33(12):3314-3316. Epub 2016 Sep 15.

TreeScaper: Visualizing and Extracting Phylogenetic Signal from Sets of Trees.

Huang W(1), Zhou G(2), Marchand M(3), Ash JR(4), Morris D(2), Van Dooren P(5),
Brown JM(2), Gallivan KA(3), Wilgenbusch JC(6).

Author information: 
(1)Department of Computational and Applied Mathematics, Rice University, St.
Housten, TX huwst08@gmail.com. (2)Department of Biological Sciences and Museum of
Natural Science, Louisiana State University, Baton Rouge, LA. (3)Department of
Mathematics, Florida State University, Tallahassee, FL. (4)Bioinformatics
Research Center, North Carolina State University, Raleigh, NC. (5)Department of
Mathematical Engineering, ICTEAM, Université catholique de Louvain, Belgium,
Germany. (6)Minnesota Supercomputing Institute, University of Minnesota,
Minneapolis, MN.

Modern phylogenomic analyses often result in large collections of phylogenetic
trees representing uncertainty in individual gene trees, variation across genes, 
or both. Extracting phylogenetic signal from these tree sets can be challenging, 
as they are difficult to visualize, explore, and quantify. To overcome some of
these challenges, we have developed TreeScaper, an application for tree set
visualization as well as the identification of distinct phylogenetic signals. GUI
and command-line versions of TreeScaper and a manual with tutorials can be
downloaded from https://github.com/whuang08/TreeScaper/releases TreeScaper is
distributed under the GNU General Public License.

© The Author 2016. Published by Oxford University Press on behalf of the Society 
for Molecular Biology and Evolution. All rights reserved. For permissions, please
e-mail: journals.permissions@oup.com.

DOI: 10.1093/molbev/msw196 
PMID: 27634869  [PubMed - in process]


283. BMC Bioinformatics. 2016 Sep 15;17(1):380. doi: 10.1186/s12859-016-1245-9.

EnsCat: clustering of categorical data via ensembling.

Clarke BS(1), Amiri S(2), Clarke JL(3,)(4).

Author information: 
(1)Department of Statistics, University of Nebraska-Lincoln, Lincoln, NE, USA.
(2)Department of Natural and Applied Sciences, University of Wisconsin Madison,
Iowa City, IA, USA. (3)Department of Statistics, University of Nebraska-Lincoln, 
Lincoln, NE, USA. jclarke3@unl.edu. (4)Department of Food Science and Technology,
University of Nebraska-Lincoln, Lincoln, NE, USA. jclarke3@unl.edu.

BACKGROUND: Clustering is a widely used collection of unsupervised learning
techniques for identifying natural classes within a data set. It is often used in
bioinformatics to infer population substructure. Genomic data are often
categorical and high dimensional, e.g., long sequences of nucleotides. This makes
inference challenging: The distance metric is often not well-defined on
categorical data; running time for computations using high dimensional data can
be considerable; and the Curse of Dimensionality often impedes the interpretation
of the results. Up to the present, however, the literature and software
addressing clustering for categorical data has not yet led to a standard
approach.
RESULTS: We present software for an ensemble method that performs well in
comparison with other methods regardless of the dimensionality of the data. In an
ensemble method a variety of instantiations of a statistical object are found and
then combined into a consensus value. It has been known for decades that
ensembling generally outperforms the components that comprise it in many
settings. Here, we apply this ensembling principle to clustering. We begin by
generating many hierarchical clusterings with different clustering sizes. When
the dimension of the data is high, we also randomly select subspaces also of
variable size, to generate clusterings. Then, we combine these clusterings into a
single membership matrix and use this to obtain a new, ensembled dissimilarity
matrix using Hamming distance.
CONCLUSIONS: Ensemble clustering, as implemented in R and called EnsCat, gives
more clearly separated clusters than other clustering techniques for categorical 
data. The latest version with manual and examples is available at
https://github.com/jlp2duke/EnsCat .

DOI: 10.1186/s12859-016-1245-9 
PMCID: PMC5025633
PMID: 27634377  [PubMed - in process]


284. BMC Bioinformatics. 2016 Sep 15;17(1):379. doi: 10.1186/s12859-016-1231-2.

Pathogen metadata platform: software for accessing and analyzing pathogen strain 
information.

Chang WE(1), Peterson MW(2), Garay CD(2), Korves T(3).

Author information: 
(1)Data Analytics Department, The MITRE Corporation, 2280 Historic Decatur Rd,
San Diego, CA, 92106, USA. (2)Data Analytics Department, The MITRE Corporation,
202 Burlington Rd, Bedford, MA, 01730, USA. (3)Data Analytics Department, The
MITRE Corporation, 202 Burlington Rd, Bedford, MA, 01730, USA. tkorves@mitre.org.

BACKGROUND: Pathogen metadata includes information about where and when a
pathogen was collected and the type of environment it came from. Along with
genomic nucleotide sequence data, this metadata is growing rapidly and becoming a
valuable resource not only for research but for biosurveillance and public
health. However, current freely available tools for analyzing this data are
geared towards bioinformaticians and/or do not provide summaries and
visualizations needed to readily interpret results.
RESULTS: We designed a platform to easily access and summarize data about
pathogen samples. The software includes a PostgreSQL database that captures
metadata useful for disease outbreak investigations, and scripts for downloading 
and parsing data from NCBI BioSample and BioProject into the database. The
software provides a user interface to query metadata and obtain standardized
results in an exportable, tab-delimited format. To visually summarize results,
the user interface provides a 2D histogram for user-selected metadata types and
mapping of geolocated entries. The software is built on the LabKey data platform,
an open-source data management platform, which enables developers to add
functionalities. We demonstrate the use of the software in querying for a
pathogen serovar and for genome sequence identifiers.
CONCLUSIONS: This software enables users to create a local database for pathogen 
metadata, populate it with data from NCBI, easily query the data, and obtain
visual summaries. Some of the components, such as the database, are modular and
can be incorporated into other data platforms. The source code is freely
available for download at https://github.com/wchangmitre/bioattribution .

DOI: 10.1186/s12859-016-1231-2 
PMCID: PMC5025631
PMID: 27634291  [PubMed - in process]


285. BMC Bioinformatics. 2016 Sep 15;17(1):378. doi: 10.1186/s12859-016-1202-7.

Development of a prediction system for tail-anchored proteins.

Shigemitsu S(1), Cao W(1), Terada T(2), Shimizu K(3).

Author information: 
(1)Department of Biotechnology, Graduate School of Agricultural and Life
Sciences, The University of Tokyo, 1-1-1 Yayoi, Bunkyo-ku, Tokyo, 113-8657,
Japan. (2)Agricultural Bioinformatics Research Unit, Graduate School of
Agricultural and Life Sciences, The University of Tokyo, 1-1-1 Yayoi, Bunkyo-ku, 
Tokyo, 113-8657, Japan. (3)Department of Biotechnology, Graduate School of
Agricultural and Life Sciences, The University of Tokyo, 1-1-1 Yayoi, Bunkyo-ku, 
Tokyo, 113-8657, Japan. shimizu@bi.a.u-tokyo.ac.jp.

BACKGROUND: "Tail-anchored (TA) proteins" is a collective term for transmembrane 
proteins with a C-terminal transmembrane domain (TMD) and without an N-terminal
signal sequence. TA proteins account for approximately 3-5 % of all transmembrane
proteins that mediate membrane fusion, regulation of apoptosis, and vesicular
transport. The combined use of TMD and signal sequence prediction tools is
typically required to predict TA proteins.
RESULTS: Here we developed a prediction system named TAPPM that predicted TA
proteins solely from target amino acid sequences according to the knowledge of
the sequence features of TMDs and the peripheral regions of TA proteins. Manually
curated TA proteins were collected from published literature. We constructed
hidden markov models of TA proteins as well as three different types of
transmembrane proteins with similar structures and compared their likelihoods as 
TA proteins.
CONCLUSIONS: Using the HMM models, we achieved high prediction accuracy; area
under the receiver operator curve values reaching 0.963. A command line tool
written in Python is available at https://github.com/davecao/tappm_cli .

DOI: 10.1186/s12859-016-1202-7 
PMCID: PMC5025589
PMID: 27634135  [PubMed - in process]


286. J Mol Graph Model. 2016 Sep;69:127-43. doi: 10.1016/j.jmgm.2016.07.008. Epub 2016
Jul 30.

Open source molecular modeling.

Pirhadi S(1), Sunseri J(2), Koes DR(3).

Author information: 
(1)Young Researchers and Elites Club, Science and Research Branch, Islamic Azad
University, Tehran, Iran. (2)Department of Computational and Systems Biology,
University of Pittsburgh, United States. (3)Department of Computational and
Systems Biology, University of Pittsburgh, United States. Electronic address:
dkoes@pitt.edu.

The success of molecular modeling and computational chemistry efforts are, by
definition, dependent on quality software applications. Open source software
development provides many advantages to users of modeling applications, not the
least of which is that the software is free and completely extendable. In this
review we categorize, enumerate, and describe available open source software
packages for molecular modeling and computational chemistry. An updated online
version of this catalog can be found at
https://opensourcemolecularmodeling.github.io.

Copyright © 2016 The Author(s). Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.jmgm.2016.07.008 
PMCID: PMC5037051
PMID: 27631126  [PubMed - in process]


287. J Biomed Semantics. 2016 Sep 14;7(1):53. doi: 10.1186/s13326-016-0100-2.

The Ontology of Biological and Clinical Statistics (OBCS) for standardized and
reproducible statistical analysis.

Zheng J(1), Harris MR(2), Masci AM(3), Lin Y(4), Hero A(5), Smith B(6), He Y(7).

Author information: 
(1)Department of Genetics, University of Pennsylvania Perelman School of
Medicine, Philadelphia, PA, 19104, USA. jiezheng@upenn.edu. (2)Division of
Systems Leadership and Effectiveness Science, University of Michigan School of
Nursing, Ann Arbor, MI, 48109, USA. (3)Department of Biostatistics and
Bioinformatics, Duke Medical Center, Duke University, Durham, NC, 27710, USA.
(4)Department of Microbiology and Immunology, Unit for Laboratory Animal
Medicine, University of Michigan Medical School, Ann Arbor, MI, 48109, USA.
(5)Department of Electrical Engineering and Computer Science, Department of
Biomedical Engineering, and Department of Statistics, Michigan Institute of Data 
Science, University of Michigan, Ann Arbor, MI, 48109, USA. (6)Department of
Philosophy and National Center for Ontological Research, University at Buffalo,
Buffalo, NY, 14203, USA. (7)Department of Microbiology and Immunology, Unit for
Laboratory Animal Medicine, University of Michigan Medical School, Ann Arbor, MI,
48109, USA. yongqunh@med.umich.edu.

BACKGROUND: Statistics play a critical role in biological and clinical research. 
However, most reports of scientific results in the published literature make it
difficult for the reader to reproduce the statistical analyses performed in
achieving those results because they provide inadequate documentation of the
statistical tests and algorithms applied. The Ontology of Biological and Clinical
Statistics (OBCS) is put forward here as a step towards solving this problem.
RESULTS: The terms in OBCS including 'data collection', 'data transformation in
statistics', 'data visualization', 'statistical data analysis', and 'drawing a
conclusion based on data', cover the major types of statistical processes used in
basic biological research and clinical outcome studies. OBCS is aligned with the 
Basic Formal Ontology (BFO) and extends the Ontology of Biomedical Investigations
(OBI), an OBO (Open Biological and Biomedical Ontologies) Foundry ontology
supported by over 20 research communities. Currently, OBCS comprehends 878 terms,
representing 20 BFO classes, 403 OBI classes, 229 OBCS specific classes, and 122 
classes imported from ten other OBO ontologies. We discuss two examples
illustrating how the ontology is being applied. In the first (biological) use
case, we describe how OBCS was applied to represent the high throughput
microarray data analysis of immunological transcriptional profiles in human
subjects vaccinated with an influenza vaccine. In the second (clinical outcomes) 
use case, we applied OBCS to represent the processing of electronic health care
data to determine the associations between hospital staffing levels and patient
mortality. Our case studies were designed to show how OBCS can be used for the
consistent representation of statistical analysis pipelines under two different
research paradigms. Other ongoing projects using OBCS for statistical data
processing are also discussed. The OBCS source code and documentation are
available at: https://github.com/obcs/obcs .
CONCLUSIONS: The Ontology of Biological and Clinical Statistics (OBCS) is a
community-based open source ontology in the domain of biological and clinical
statistics. OBCS is a timely ontology that represents statistics-related terms
and their relations in a rigorous fashion, facilitates standard data analysis and
integration, and supports reproducible biological and clinical research.

DOI: 10.1186/s13326-016-0100-2 
PMCID: PMC5024438
PMID: 27627881  [PubMed - in process]


288. Nucleic Acids Res. 2017 Jan 9;45(1):e4. doi: 10.1093/nar/gkw809. Epub 2016 Sep
12.

ChIA-PET2: a versatile and flexible pipeline for ChIA-PET data analysis.

Li G(1), Chen Y(1), Snyder MP(2), Zhang MQ(3,)(4).

Author information: 
(1)MOE Key Laboratory of Bioinformatics; Bioinformatics Division and Center for
Synthetic & Systems Biology, TNLIST; Department of Automation, Tsinghua
University, Beijing 100084, China. (2)Department of Genetics, Stanford University
School of Medicine, Stanford, CA 94305, USA mpsnyder@stanford.edu. (3)MOE Key
Laboratory of Bioinformatics; Bioinformatics Division and Center for Synthetic & 
Systems Biology, TNLIST; Department of Automation, Tsinghua University, Beijing
100084, China michael.zhang@utdallas.edu. (4)Department of Biological Sciences,
Center for Systems Biology, University of Texas, Dallas, 800 West Campbell Road, 
RL11, Richardson, TX 75080-3021, USA.

ChIA-PET2 is a versatile and flexible pipeline for analyzing different types of
ChIA-PET data from raw sequencing reads to chromatin loops. ChIA-PET2 integrates 
all steps required for ChIA-PET data analysis, including linker trimming, read
alignment, duplicate removal, peak calling and chromatin loop calling. It
supports different kinds of ChIA-PET data generated from different ChIA-PET
protocols and also provides quality controls for different steps of ChIA-PET
analysis. In addition, ChIA-PET2 can use phased genotype data to call
allele-specific chromatin interactions. We applied ChIA-PET2 to different
ChIA-PET datasets, demonstrating its significantly improved performance as well
as its ability to easily process ChIA-PET raw data. ChIA-PET2 is available at
https://github.com/GuipengLi/ChIA-PET2.

© The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkw809 
PMCID: PMC5224499
PMID: 27625391  [PubMed - in process]


289. BMC Bioinformatics. 2016 Sep 13;17(1):369. doi: 10.1186/s12859-016-1208-1.

NBLDA: negative binomial linear discriminant analysis for RNA-Seq data.

Dong K(1), Zhao H(2), Tong T(1), Wan X(3).

Author information: 
(1)Department of Mathematics, Hong Kong Baptist University, Kowloon Tong, Hong
Kong. (2)Department of Biostatistics, Yale University, New Haven, 06510, CT, USA.
(3)Department of Computer Science and Institute of Computational and Theoretical 
Studies, Hong Kong Baptist University, Kowloon Tong, Hong Kong.
xwan@comp.hkbu.edu.hk.

BACKGROUND: RNA-sequencing (RNA-Seq) has become a powerful technology to
characterize gene expression profiles because it is more accurate and
comprehensive than microarrays. Although statistical methods that have been
developed for microarray data can be applied to RNA-Seq data, they are not ideal 
due to the discrete nature of RNA-Seq data. The Poisson distribution and negative
binomial distribution are commonly used to model count data. Recently, Witten
(Annals Appl Stat 5:2493-2518, 2011) proposed a Poisson linear discriminant
analysis for RNA-Seq data. The Poisson assumption may not be as appropriate as
the negative binomial distribution when biological replicates are available and
in the presence of overdispersion (i.e., when the variance is larger than or
equal to the mean). However, it is more complicated to model negative binomial
variables because they involve a dispersion parameter that needs to be estimated.
RESULTS: In this paper, we propose a negative binomial linear discriminant
analysis for RNA-Seq data. By Bayes' rule, we construct the classifier by fitting
a negative binomial model, and propose some plug-in rules to estimate the unknown
parameters in the classifier. The relationship between the negative binomial
classifier and the Poisson classifier is explored, with a numerical investigation
of the impact of dispersion on the discriminant score. Simulation results show
the superiority of our proposed method. We also analyze two real RNA-Seq data
sets to demonstrate the advantages of our method in real-world applications.
CONCLUSIONS: We have developed a new classifier using the negative binomial model
for RNA-seq data classification. Our simulation results show that our proposed
classifier has a better performance than existing works. The proposed classifier 
can serve as an effective tool for classifying RNA-seq data. Based on the
comparison results, we have provided some guidelines for scientists to decide
which method should be used in the discriminant analysis of RNA-Seq data. R code 
is available at http://www.comp.hkbu.edu.hk/~xwan/NBLDA.R or
https://github.com/yangchadam/NBLDA.

DOI: 10.1186/s12859-016-1208-1 
PMCID: PMC5022247
PMID: 27623864  [PubMed - in process]


290. BMC Bioinformatics. 2016 Sep 13;17(1):371. doi: 10.1186/s12859-016-1164-9.

Protein complex detection based on partially shared multi-view clustering.

Ou-Yang L(1,)(2), Zhang XF(3), Dai DQ(4), Wu MY(5), Zhu Y(6), Liu Z(7), Yan H(2).

Author information: 
(1)College of Information Engineering, Shenzhen University, Nanhai Ave 3688,
Shenzhen, 518060, China. (2)Department of Electronic and Engineering, City
University of Hong Kong, Tat Chee Avenue, Hong Kong, China. (3)School of
Mathematics and Statistics and Hubei Key Laboratory of Mathematical Sciences,
Central China Normal University, Wuhan, 430079, China. (4)Intelligent Data Center
and Department of Mathematics, Sun Yat-Sen University, Xin Gang Road West,
Guangzhou, 510275, China. stsddq@mail.sysu.edu.cn. (5)School of Statistics and
Management, Shanghai University of Finance and Economics, Guoding Road, Shanghai,
200433, China. (6)School of Automation, China University of Geosciences, Wuhan,
China. (7)Shenzhen Polytechnic, Shenzhen, 518055, China.

BACKGROUND: Protein complexes are the key molecular entities to perform many
essential biological functions. In recent years, high-throughput experimental
techniques have generated a large amount of protein interaction data. As a
consequence, computational analysis of such data for protein complex detection
has received increased attention in the literature. However, most existing works 
focus on predicting protein complexes from a single type of data, either physical
interaction data or co-complex interaction data. These two types of data provide 
compatible and complementary information, so it is necessary to integrate them to
discover the underlying structures and obtain better performance in complex
detection.
RESULTS: In this study, we propose a novel multi-view clustering algorithm,
called the Partially Shared Multi-View Clustering model (PSMVC), to carry out
such an integrated analysis. Unlike traditional multi-view learning algorithms
that focus on mining either consistent or complementary information embedded in
the multi-view data, PSMVC can jointly explore the shared and specific
information inherent in different views. In our experiments, we compare the
complexes detected by PSMVC from single data source with those detected from
multiple data sources. We observe that jointly analyzing multi-view data benefits
the detection of protein complexes. Furthermore, extensive experiment results
demonstrate that PSMVC performs much better than 16 state-of-the-art complex
detection techniques, including ensemble clustering and data integration
techniques.
CONCLUSIONS: In this work, we demonstrate that when integrating multiple data
sources, using partially shared multi-view clustering model can help to identify 
protein complexes which are not readily identifiable by conventional
single-view-based methods and other integrative analysis methods. All the results
and source codes are available on https://github.com/Oyl-CityU/PSMVC .

DOI: 10.1186/s12859-016-1164-9 
PMCID: PMC5022186
PMID: 27623844  [PubMed - in process]


291. Comput Biol Chem. 2016 Oct;64:403-413. doi: 10.1016/j.compbiolchem.2016.08.007.
Epub 2016 Sep 6.

Assessing the similarity of ligand binding conformations with the Contact Mode
Score.

Ding Y(1), Fang Y(2), Moreno J(3), Ramanujam J(4), Jarrell M(5), Brylinski M(6).

Author information: 
(1)Department of Physics and Astronomy, Louisiana State University, Baton Rouge, 
LA 70803, USA. Electronic address: yding8@lsu.edu. (2)School of Electrical
Engineering and Computer Science, Louisiana State University, Baton Rouge, LA
70803, USA; Center for Computation & Technology, Louisiana State University,
Baton Rouge, LA 70803, USA. Electronic address: yfang11@lsu.edu. (3)Department of
Physics and Astronomy, Louisiana State University, Baton Rouge, LA 70803, USA;
Center for Computation & Technology, Louisiana State University, Baton Rouge, LA 
70803, USA. Electronic address: moreno@phys.lsu.edu. (4)School of Electrical
Engineering and Computer Science, Louisiana State University, Baton Rouge, LA
70803, USA; Center for Computation & Technology, Louisiana State University,
Baton Rouge, LA 70803, USA. Electronic address: ram@cct.lsu.edu. (5)Department of
Physics and Astronomy, Louisiana State University, Baton Rouge, LA 70803, USA;
Center for Computation & Technology, Louisiana State University, Baton Rouge, LA 
70803, USA. Electronic address: jarrellphysics@gmail.com. (6)Department of
Biological Sciences, Louisiana State University, Baton Rouge, LA 70803, USA;
Center for Computation & Technology, Louisiana State University, Baton Rouge, LA 
70803, USA. Electronic address: michal@brylinski.org.

Structural and computational biologists often need to measure the similarity of
ligand binding conformations. The commonly used root-mean-square deviation (RMSD)
is not only ligand-size dependent, but also may fail to capture biologically
meaningful binding features. To address these issues, we developed the Contact
Mode Score (CMS), a new metric to assess the conformational similarity based on
intermolecular protein-ligand contacts. The CMS is less dependent on the ligand
size and has the ability to include flexible receptors. In order to effectively
compare binding poses of non-identical ligands bound to different proteins, we
further developed the eXtended Contact Mode Score (XCMS). We believe that CMS and
XCMS provide a meaningful assessment of the similarity of ligand binding
conformations. CMS and XCMS are freely available at
http://brylinski.cct.lsu.edu/content/contact-mode-score and
http://geaux-computational-bio.github.io/contact-mode-score/.

Copyright © 2016 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.compbiolchem.2016.08.007 
PMCID: PMC5159245 [Available on 2017-10-01]
PMID: 27620381  [PubMed - in process]


292. Mol Ecol Resour. 2017 Jan;17(1):91-95. doi: 10.1111/1755-0998.12597. Epub 2016
Oct 1.

parallelnewhybrid: an R package for the parallelization of hybrid detection using
newhybrids.

Wringe BF(1), Stanley RR(1), Jeffery NW(1), Anderson EC(2), Bradbury IR(1).

Author information: 
(1)Fisheries and Oceans Canada, Salmonids Section, 80 East White Hills Road, St. 
John's, Newfoundland and Labrador, Canada, A1C 5X1. (2)Fisheries Ecology
Division, National Oceanic and Atmospheric Administration Southwest Fisheries
Science Center, Santa Cruz, CA, 95060, USA.

Hybridization among populations and species is a central theme in many areas of
biology, and the study of hybridization has direct applicability to testing
hypotheses about evolution, speciation and genetic recombination, as well as
having conservation, legal and regulatory implications. Yet, despite being a
topic of considerable interest, the identification of hybrid individuals, and
quantification of the (un)certainty surrounding the identifications, remains
difficult. Unlike other programs that exist to identify hybrids based on
genotypic information, newhybrids is able to assign individuals to specific
hybrid classes (e.g. F1 , F2 ) because it makes use of patterns of gene
inheritance within each locus, rather than just the proportions of gene
inheritance within each individual. For each comparison and set of markers,
multiple independent runs of each data set should be used to develop an estimate 
of the hybrid class assignment accuracy. The necessity of analysing multiple
simulated data sets, constructed from large genomewide data sets, presents
significant computational challenges. To address these challenges, we present
parallelnewhybrid, an r package designed to decrease user burden when undertaking
multiple newhybrids analyses. parallelnewhybrid does so by taking advantage of
the parallel computational capabilities inherent in modern computers to
efficiently and automatically execute separate newhybrids runs in parallel. We
show that parallelization of analyses using this package affords users
several-fold reductions in time over a traditional serial analysis.
parallelnewhybrid consists of an example data set, a readme and three operating
system-specific functions to execute parallel newhybrids analyses on each of a
computer's c cores. parallelnewhybrid is freely available on the long-term
software hosting site github (www.github.com/bwringe/parallelnewhybrid).

© 2016 John Wiley & Sons Ltd.

DOI: 10.1111/1755-0998.12597 
PMID: 27617417  [PubMed - in process]


293. Bioinformatics. 2017 Jan 1;33(1):125-127. doi: 10.1093/bioinformatics/btw571.
Epub 2016 Sep 10.

The OGCleaner: filtering false-positive homology clusters.

Fujimoto MS(1), Suvorov A(2), Jensen NO(2), Clement MJ(1), Snell Q(1), Bybee
SM(2).

Author information: 
(1)Computer Science Department, Brigham Young University, Provo, UT 84602, USA.
(2)Department of Biology, Brigham Young University, Provo, UT 84602, USA.

Detecting homologous sequences in organisms is an essential step in protein
structure and function prediction, gene annotation and phylogenetic tree
construction. Heuristic methods are often employed for quality control of
putative homology clusters. These heuristics, however, usually only apply to
pairwise sequence comparison and do not examine clusters as a whole. We present
the Orthology Group Cleaner (the OGCleaner), a tool designed for filtering
putative orthology groups as homology or non-homology clusters by considering all
sequences in a cluster. The OGCleaner relies on high-quality orthologous groups
identified in OrthoDB to train machine learning algorithms that are able to
distinguish between true-positive and false-positive homology groups. This
package aims to improve the quality of phylogenetic tree construction especially 
in instances of lower-quality transcriptome assemblies.AVAILABILITY AND
IMPLEMENTATION: https://github.com/byucsl/ogcleaner CONTACT:
sfujimoto@gmail.comSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw571 
PMID: 27614349  [PubMed - in process]


294. Bioinformatics. 2017 Jan 1;33(1):49-55. doi: 10.1093/bioinformatics/btw569. Epub 
2016 Sep 10.

Nanocall: an open source basecaller for Oxford Nanopore sequencing data.

David M(1), Dursi LJ(1), Yao D(1), Boutros PC(1,)(2,)(3), Simpson JT(1,)(4).

Author information: 
(1)Ontario Institute for Cancer Research, Toronto M5G 0A3, Canada. (2)Department 
of Pharmacology and Toxicology, University of Toronto, Toronto M5S 1A8, Canada.
(3)Department of Medical Biophysics, University of Toronto, Toronto M5G 1L7,
Canada. (4)Department of Computer Science, University of Toronto, Toronto M5S
3G4, Canada.

MOTIVATION: The highly portable Oxford Nanopore MinION sequencer has enabled new 
applications of genome sequencing directly in the field. However, the MinION
currently relies on a cloud computing platform, Metrichor (metrichor.com), for
translating locally generated sequencing data into basecalls.
RESULTS: To allow offline and private analysis of MinION data, we created
Nanocall. Nanocall is the first freely available, open-source basecaller for
Oxford Nanopore sequencing data and does not require an internet connection.
Using R7.3 chemistry, on two E.coli and two human samples, with natural as well
as PCR-amplified DNA, Nanocall reads have ∼68% identity, directly comparable to
Metrichor '1D' data. Further, Nanocall is efficient, processing ∼2500 Kbp of
sequence per core hour using the fastest settings, and fully parallelized. Using 
a 4 core desktop computer, Nanocall could basecall a MinION sequencing run in
real time. Metrichor provides the ability to integrate the '1D' sequencing of
template and complement strands of a single DNA molecule, and create a '2D' read.
Nanocall does not currently integrate this technology, and addition of this
capability will be an important future development. In summary, Nanocall is the
first open-source, freely available, off-line basecaller for Oxford Nanopore
sequencing data.
AVAILABILITY AND IMPLEMENTATION: Nanocall is available at
github.com/mateidavid/nanocall, released under the MIT license.
CONTACT: matei.david@oicr.on.caSupplementary information: Supplementary data are 
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw569 
PMID: 27614348  [PubMed - in process]


295. Genet Sel Evol. 2016 Sep 10;48(1):65. doi: 10.1186/s12711-016-0242-9.

MaGelLAn 1.0: a software to facilitate quantitative and population genetic
analysis of maternal inheritance by combination of molecular and pedigree
information.

Ristov S(1), Brajkovic V(2), Cubric-Curik V(2), Michieli I(3), Curik I(2).

Author information: 
(1)Ruđer Bošković Institute, Bijenička cesta 54, 10000, Zagreb, Croatia.
ristov@irb.hr. (2)Faculty of Agriculture, University of Zagreb, Svetošimunska
cesta 25, 10000, Zagreb, Croatia. (3)Ruđer Bošković Institute, Bijenička cesta
54, 10000, Zagreb, Croatia.

BACKGROUND: Identification of genes or even nucleotides that are responsible for 
quantitative and adaptive trait variation is a difficult task due to the complex 
interdependence between a large number of genetic and environmental factors. The 
polymorphism of the mitogenome is one of the factors that can contribute to
quantitative trait variation. However, the effects of the mitogenome have not
been comprehensively studied, since large numbers of mitogenome sequences and
recorded phenotypes are required to reach the adequate power of analysis. Current
research in our group focuses on acquiring the necessary mitochondria sequence
information and analysing its influence on the phenotype of a quantitative trait.
To facilitate these tasks we have produced software for processing pedigrees that
is optimised for maternal lineage analysis.
RESULTS: We present MaGelLAn 1.0 (maternal genealogy lineage analyser), a suite
of four Python scripts (modules) that is designed to facilitate the analysis of
the impact of mitogenome polymorphism on quantitative trait variation by
combining molecular and pedigree information. MaGelLAn 1.0 is primarily used to: 
(1) optimise the sampling strategy for molecular analyses; (2) identify and
correct pedigree inconsistencies; and (3) identify maternal lineages and assign
the corresponding mitogenome sequences to all individuals in the pedigree, this
information being used as input to any of the standard software for quantitative 
genetic (association) analysis. In addition, MaGelLAn 1.0 allows computing the
mitogenome (maternal) effective population sizes and probability of mitogenome
(maternal) identity that are useful for conservation management of small
populations.
CONCLUSIONS: MaGelLAn is the first tool for pedigree analysis that focuses on
quantitative genetic analyses of mitogenome data. It is conceived with the
purpose to significantly reduce the effort in handling and preparing large
pedigrees for processing the information linked to maternal lines. The software
source code, along with the manual and the example files can be downloaded at
http://lissp.irb.hr/software/magellan-1-0/ and
https://github.com/sristov/magellan .

DOI: 10.1186/s12711-016-0242-9 
PMCID: PMC5018160
PMID: 27613390  [PubMed - in process]


296. Bioinformatics. 2017 Jan 1;33(1):1-7. doi: 10.1093/bioinformatics/btw552. Epub
2016 Sep 7.

A novel method for predicting activity of cis-regulatory modules, based on a
diverse training set.

Yang W(1), Sinha S(1).

Author information: 
(1)Department of Computer Science, University of Illinois, Urbana-Champaign,
Urbana, IL, USA.

MOTIVATION: With the rapid emergence of technologies for locating cis-regulatory 
modules (CRMs) genome-wide, the next pressing challenge is to assign precise
functions to each CRM, i.e. to determine the spatiotemporal domains or cell-types
where it drives expression. A popular approach to this task is to model the
typical k-mer composition of a set of CRMs known to drive a common expression
pattern, and assign that pattern to other CRMs exhibiting a similar k-mer
composition. This approach does not rely on prior knowledge of transcription
factors relevant to the CRM or their binding motifs, and is thus more widely
applicable than motif-based methods for predicting CRM activity, but is also
prone to false positive predictions.
RESULTS: We present a novel strategy to improve the above-mentioned approach: to 
predict if a CRM drives a specific gene expression pattern, assess not only how
similar the CRM is to other CRMs with similar activity but also to CRMs with
distinct activities. We use a state-of-the-art statistical method to quantify a
CRM's sequence similarity to many different training sets of CRMs, and employ a
classification algorithm to integrate these similarity scores into a single
prediction of the CRM's activity. This strategy is shown to significantly improve
CRM activity prediction over current approaches.
AVAILABILITY AND IMPLEMENTATION: Our implementation of the new method, called
IMMBoost, is freely available as source code, at
https://github.com/weiyangedward/IMMBoost CONTACT:
sinhas@illinois.eduSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw552 
PMID: 27609510  [PubMed - in process]


297. Nucleic Acids Res. 2017 Jan 9;45(1):e2. doi: 10.1093/nar/gkw798. Epub 2016 Sep 7.

COME: a robust coding potential calculation tool for lncRNA identification and
characterization based on multiple features.

Hu L(1,)(2), Xu Z(1), Hu B(1), Lu ZJ(3).

Author information: 
(1)MOE Key Laboratory of Bioinformatics, Center for Synthetic and Systems Biology
and Center for Plant Biology, Tsinghua-Peking Joint Center for Life Sciences,
School of Life Sciences, Tsinghua University, Beijing 100084, China.
(2)PKU-Tsinghua-NIBS Graduate Program, School of Life Sciences, Peking
University, Beijing 100871, China. (3)MOE Key Laboratory of Bioinformatics,
Center for Synthetic and Systems Biology and Center for Plant Biology,
Tsinghua-Peking Joint Center for Life Sciences, School of Life Sciences, Tsinghua
University, Beijing 100084, China zhilu@tsinghua.edu.cn.

Recent genomic studies suggest that novel long non-coding RNAs (lncRNAs) are
specifically expressed and far outnumber annotated lncRNA sequences. To identify 
and characterize novel lncRNAs in RNA sequencing data from new samples, we have
developed COME, a coding potential calculation tool based on multiple features.
It integrates multiple sequence-derived and experiment-based features using a
decompose-compose method, which makes it more accurate and robust than other
well-known tools. We also showed that COME was able to substantially improve the 
consistency of predication results from other coding potential calculators.
Moreover, COME annotates and characterizes each predicted lncRNA transcript with 
multiple lines of supporting evidence, which are not provided by other tools.
Remarkably, we found that one subgroup of lncRNAs classified by such supporting
features (i.e. conserved local RNA secondary structure) was highly enriched in a 
well-validated database (lncRNAdb). We further found that the conserved
structural domains on lncRNAs had better chance than other RNA regions to
interact with RNA binding proteins, based on the recent eCLIP-seq data in human, 
indicating their potential regulatory roles. Overall, we present COME as an
accurate, robust and multiple-feature supported method for the identification and
characterization of novel lncRNAs. The software implementation is available at
https://github.com/lulab/COME.

© The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkw798 
PMCID: PMC5224497
PMID: 27608726  [PubMed - in process]


298. Bioinformatics. 2017 Jan 1;33(1):87-94. doi: 10.1093/bioinformatics/btw557. Epub 
2016 Sep 7.

BeReTa: a systematic method for identifying target transcriptional regulators to 
enhance microbial production of chemicals.

Kim M(1), Sun G(1), Lee DY(2,)(3), Kim BG(1).

Author information: 
(1)School of Chemical and Biological Engineering, Institute of Molecular Biology 
and Genetics, and Bioengineering Institute, Seoul National University, 1,
Gwanak-ro, Gwanak-gu, Seoul 151-742, Republic of Korea. (2)Department of Chemical
and Biomolecular Engineering, National University of Singapore, 4 Engineering
Drive 4, Singapore 117576, Singapore. (3)Bioprocessing Technology Institute;
Agency for Science, Technology and Research (A*STAR), 20 Biopolis Way, #06-01,
Centros, Singapore 138668, Singapore.

MOTIVATION: Modulation of regulatory circuits governing the metabolic processes
is a crucial step for developing microbial cell factories. Despite the prevalence
of in silico strain design algorithms, most of them are not capable of predicting
required modifications in regulatory networks. Although a few algorithms may
predict relevant targets for transcriptional regulator (TR) manipulations, they
have limited reliability and applicability due to their high dependency on the
availability of integrated metabolic/regulatory models.
RESULTS: We present BeReTa (Beneficial Regulator Targeting), a new algorithm for 
prioritization of TR manipulation targets, which makes use of unintegrated
network models. BeReTa identifies TR manipulation targets by evaluating
regulatory strengths of interactions and beneficial effects of reactions, and
subsequently assigning beneficial scores for the TRs. We demonstrate that BeReTa 
can predict both known and novel TR manipulation targets for enhanced production 
of various chemicals in Escherichia coli Furthermore, through a case study of
antibiotics production in Streptomyces coelicolor, we successfully demonstrate
its wide applicability to even less-studied organisms. To the best of our
knowledge, BeReTa is the first strain design algorithm exclusively designed for
predicting TR manipulation targets.
AVAILABILITY AND IMPLEMENTATION: MATLAB code is available at
https://github.com/kms1041/BeReTa (github).
CONTACT: byungkim@snu.ac.krSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw557 
PMID: 27605107  [PubMed - in process]


299. Bioinformatics. 2017 Jan 15;33(2):280-282. doi: 10.1093/bioinformatics/btw589.
Epub 2016 Sep 7.

tHapMix: simulating tumour samples through haplotype mixtures.

Ivakhno S(1), Colombo C(1), Tanner S(2), Tedder P(1), Berri S(1), Cox AJ(1).

Author information: 
(1)Chesterford Research Park, Illumina Cambridge Ltd, Little Chesterford, CB10
1XL, UK. (2)Illumina Inc, San Diego, CA 92122, USA.

MOTIVATION: Large-scale rearrangements and copy number changes combined with
different modes of clonal evolution create extensive somatic genome diversity,
making it difficult to develop versatile and scalable variant calling tools and
create well-calibrated benchmarks.
RESULTS: We developed a new simulation framework tHapMix that enables the
creation of tumour samples with different ploidy, purity and polyclonality
features. It easily scales to simulation of hundreds of somatic genomes, while
re-use of real read data preserves noise and biases present in sequencing
platforms. We further demonstrate tHapMix utility by creating a simulated set of 
140 somatic genomes and showing how it can be used in training and testing of
somatic copy number variant calling tools.
AVAILABILITY AND IMPLEMENTATION: tHapMix is distributed under an open source
license and can be downloaded from https://github.com/Illumina/tHapMix CONTACT:
sivakhno@illumina.comSupplementary information: Supplementary data are available 
at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw589 
PMID: 27605106  [PubMed - in process]


300. Bioinformatics. 2017 Jan 15;33(2):155-160. doi: 10.1093/bioinformatics/btw587.
Epub 2016 Sep 7.

ReliableGenome: annotation of genomic regions with high/low variant calling
concordance.

Popitsch N(1,)(2); WGS500 Consortium, Schuh A(2,)(3), Taylor JC(1,)(2).

Author information: 
(1)Wellcome Trust Centre of Human Genetics, University of Oxford, Oxford OX3 7BN,
UK. (2)National Institute for Health Research (NIHR) Oxford Biomedical Research
Centre, The Churchill Hospital, Old Road OX3 7LE, UK. (3)Department of Oncology, 
University of Oxford, Oxford OX3 7DQ, UK.

MOTIVATION: The increasing adoption of clinical whole-genome resequencing (WGS)
demands for highly accurate and reproducible variant calling (VC) methods. The
observed discordance between state-of-the-art VC pipelines, however, indicates
that the current practice still suffers from non-negligible numbers of false
positive and negative SNV and INDEL calls that were shown to be enriched among
discordant calls but also in genomic regions with low sequence complexity.
RESULTS: Here, we describe our method ReliableGenome (RG) for partitioning
genomes into high and low concordance regions with respect to a set of surveyed
VC pipelines. Our method combines call sets derived by multiple pipelines from
arbitrary numbers of datasets and interpolates expected concordance for genomic
regions without data. By applying RG to 219 deep human WGS datasets, we
demonstrate that VC concordance depends predominantly on genomic context rather
than the actual sequencing data which manifests in high recurrence of regions
that can/cannot be reliably genotyped by a single method. This enables the
application of pre-computed regions to other data created with comparable
sequencing technology and software. RG outperforms comparable efforts in
predicting VC concordance and false positive calls in low-concordance regions
which underlines its usefulness for variant filtering, annotation and
prioritization. RG allows focusing resource-intensive algorithms (e.g. consensus 
calling methods) on the smaller, discordant share of the genome (20-30%) which
might result in increased overall accuracy at reasonable costs. Our method and
analysis of discordant calls may further be useful for development, benchmarking 
and optimization of VC algorithms and for the relative comparison of call sets
between different studies/pipelines.
AVAILABILITY AND IMPLEMENTATION: RG was implemented in Java, source code and
binaries are freely available for non-commercial use at
https://github.com/popitsch/wtchg-rg/ CONTACT: niko@wtchg.ox.ac.ukSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw587 
PMID: 27605105  [PubMed - in process]


301. Bioinformatics. 2017 Jan 1;33(1):137-138. doi: 10.1093/bioinformatics/btw584.
Epub 2016 Sep 6.

MPRAnator: a web-based tool for the design of massively parallel reporter assay
experiments.

Georgakopoulos-Soares I(1), Jain N(2), Gray JM(3), Hemberg M(1).

Author information: 
(1)Department of Computational Genomics, Wellcome Trust Sanger Institute,
Wellcome Genome Campus, Hinxton, CB10 1SA, UK. (2)Department of Life Sciences,
Imperial College London, London, SW7 2AZ, UK. (3)Department of Genetics, Harvard 
Medical School, Boston, MA 02135, USA.

MOTIVATION: With the rapid advances in DNA synthesis and sequencing technologies 
and the continuing decline in the associated costs, high-throughput experiments
can be performed to investigate the regulatory role of thousands of
oligonucleotide sequences simultaneously. Nevertheless, designing high-throughput
reporter assay experiments such as massively parallel reporter assays (MPRAs) and
similar methods remains challenging.
RESULTS: We introduce MPRAnator, a set of tools that facilitate rapid design of
MPRA experiments. With MPRA Motif design, a set of variables provides fine
control of how motifs are placed into sequences, thereby allowing the
investigation of the rules that govern transcription factor (TF) occupancy. MPRA 
single-nucleotide polymorphism design can be used to systematically examine the
functional effects of single or combinations of single-nucleotide polymorphisms
at regulatory sequences. Finally, the Transmutation tool allows for the design of
negative controls by permitting scrambling, reversing, complementing or
introducing multiple random mutations in the input sequences or motifs.
AVAILABILITY AND IMPLEMENTATION: MPRAnator tool set is implemented in Python,
Perl and Javascript and is freely available at www.genomegeek.com and
www.sanger.ac.uk/science/tools/mpranator The source code is available on
www.github.com/hemberg-lab/MPRAnator/ under the MIT license. The REST API allows 
programmatic access to MPRAnator using simple URLs.
CONTACT: igs@sanger.ac.uk or mh26@sanger.ac.ukSupplementary information:
Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw584 
PMCID: PMC5198521
PMID: 27605100  [PubMed - in process]


302. Genome. 2016 Oct;59(10):783-791. Epub 2016 May 11.

bcgTree: automatized phylogenetic tree building from bacterial core genomes.

Ankenbrand MJ(1,)(1), Keller A(1,)(1).

Author information: 
(1)Department of Animal Ecology and Tropical Biology, University of Würzburg,
Germany.

The need for multi-gene analyses in scientific fields such as phylogenetics and
DNA barcoding has increased in recent years. In particular, these approaches are 
increasingly important for differentiating bacterial species, where reliance on
the standard 16S rDNA marker can result in poor resolution. Additionally, the
assembly of bacterial genomes has become a standard task due to advances in
next-generation sequencing technologies. We created a bioinformatic pipeline,
bcgTree, which uses assembled bacterial genomes either from databases or own
sequencing results from the user to reconstruct their phylogenetic history. The
pipeline automatically extracts 107 essential single-copy core genes, found in a 
majority of bacteria, using hidden Markov models and performs a partitioned
maximum-likelihood analysis. Here, we describe the workflow of bcgTree and, as a 
proof-of-concept, its usefulness in resolving the phylogeny of 293 publically
available bacterial strains of the genus Lactobacillus. We also evaluate its
performance in both low- and high-level taxonomy test sets. The tool is freely
available at github ( https://github.com/iimog/bcgTree ) and our institutional
homepage ( http://www.dna-analytics.biozentrum.uni-wuerzburg.de ).

DOI: 10.1139/gen-2015-0175 
PMID: 27603265  [PubMed - in process]


303. PeerJ. 2016 Aug 18;4:e2279. doi: 10.7717/peerj.2279. eCollection 2016.

Microbe-ID: an open source toolbox for microbial genotyping and species
identification.

Tabima JF(1), Everhart SE(2), Larsen MM(3), Weisberg AJ(1), Kamvar ZN(1), Tancos 
MA(4), Smart CD(4), Chang JH(5), Grünwald NJ(6).

Author information: 
(1)Department of Botany and Plant Pathology, Oregon State University , Corvallis 
, OR , United States. (2)Department of Botany and Plant Pathology, Oregon State
University, Corvallis, OR, United States; Current affiliation: Department of
Plant Pathology, University of Nebraska, Lincoln, NE, United States.
(3)Horticultural Crops Research Laboratory, USDA Agricultural Research Service , 
Corvallis , OR , United States. (4)Plant Pathology and Plant-Microbe Biology
Section, School of Integrative Plant Science, Cornell University , Geneva , NY , 
United States. (5)Department of Botany and Plant Pathology, Oregon State
University, Corvallis, OR, United States; Molecular and Cellular Biology Graduate
Program and Center for Genome Biology and Biocomputing, Oregon State University, 
Corvallis, OR, United States. (6)Department of Botany and Plant Pathology, Oregon
State University, Corvallis, OR, United States; Horticultural Crops Research
Laboratory, USDA Agricultural Research Service, Corvallis, OR, United States;
Plant Pathology and Plant-Microbe Biology Section, School of Integrative Plant
Science, Cornell University, Geneva, NY, United States; Molecular and Cellular
Biology Graduate Program and Center for Genome Biology and Biocomputing, Oregon
State University, Corvallis, OR, United States.

Development of tools to identify species, genotypes, or novel strains of invasive
organisms is critical for monitoring emergence and implementing rapid response
measures. Molecular markers, although critical to identifying species or
genotypes, require bioinformatic tools for analysis. However, user-friendly
analytical tools for fast identification are not readily available. To address
this need, we created a web-based set of applications called Microbe-ID that
allow for customizing a toolbox for rapid species identification and strain
genotyping using any genetic markers of choice. Two components of Microbe-ID,
named Sequence-ID and Genotype-ID, implement species and genotype identification,
respectively. Sequence-ID allows identification of species by using BLAST to
query sequences for any locus of interest against a custom reference sequence
database. Genotype-ID allows placement of an unknown multilocus marker in either 
a minimum spanning network or dendrogram with bootstrap support from a
user-created reference database. Microbe-ID can be used for identification of any
organism based on nucleotide sequences or any molecular marker type and several
examples are provided. We created a public website for demonstration purposes
called Microbe-ID (microbe-id.org) and provided a working implementation for the 
genus Phytophthora (phytophthora-id.org). In Phytophthora-ID, the Sequence-ID
application allows identification based on ITS or cox spacer sequences.
Genotype-ID groups individuals into clonal lineages based on simple sequence
repeat (SSR) markers for the two invasive plant pathogen species P. infestans and
P. ramorum. All code is open source and available on github and CRAN.
Instructions for installation and use are provided at
https://github.com/grunwaldlab/Microbe-ID.

DOI: 10.7717/peerj.2279 
PMCID: PMC4994078
PMID: 27602267  [PubMed]


304. Microarrays (Basel). 2016 Jun 9;5(2). pii: E17. doi: 10.3390/microarrays5020017.

SNPConvert: SNP Array Standardization and Integration in Livestock Species.

Nicolazzi EL(1), Marras G(2), Stella A(3,)(4).

Author information: 
(1)Bioinformatics Core Facility, PTP Science Park, Via Einstein-Loc. Cascina
Codazza 26900 Lodi, Italy. ezequiel.nicolazzi@ptp.it. (2)Bioinformatics Core
Facility, PTP Science Park, Via Einstein-Loc. Cascina Codazza 26900 Lodi, Italy. 
gabriele.marras@ptp.it. (3)Bioinformatics Core Facility, PTP Science Park, Via
Einstein-Loc. Cascina Codazza 26900 Lodi, Italy. stella@ibba.cnr.it. (4)Istituto 
di Biologia e Biotecnologia Agraria-Consiglio Nazionale della Ricerca, Via
Einstein-Loc. Cascina Codazza 26900 Lodi, Italy. stella@ibba.cnr.it.

One of the main advantages of single nucleotide polymorphism (SNP) array
technology is providing genotype calls for a specific number of SNP markers at a 
relatively low cost. Since its first application in animal genetics, the number
of available SNP arrays for each species has been constantly increasing. However,
conversely to that observed in whole genome sequence data analysis, SNP array
data does not have a common set of file formats or coding conventions for allele 
calling. Therefore, the standardization and integration of SNP array data from
multiple sources have become an obstacle, especially for users with basic or no
programming skills. Here, we describe the difficulties related to handling SNP
array data, focusing on file formats, SNP allele coding, and mapping. We also
present SNPConvert suite, a multi-platform, open-source, and user-friendly set of
tools to overcome these issues. This tool, which can be integrated with
open-source and open-access tools already available, is a first step towards an
integrated system to standardize and integrate any type of raw SNP array data.
The tool is available at: https://github. com/nicolazzie/SNPConvert.git.

DOI: 10.3390/microarrays5020017 
PMCID: PMC5003493
PMID: 27600083  [PubMed]


305. BMC Syst Biol. 2016 Sep 6;10(1):88. doi: 10.1186/s12918-016-0329-5.

Identification of key player genes in gene regulatory networks.

Nazarieh M(1,)(2), Wiese A(3), Will T(1,)(2), Hamed M(1,)(4), Helms V(5).

Author information: 
(1)Center for Bioinformatics, Saarland University, Saarbruecken, Germany.
(2)Graduate School of Computer Science, Saarland University, Saarbruecken,
Germany. (3)Max Planck Institut fuer Informatik (MPII), Saarbruecken, Germany.
(4)Institute for Biostatistics and Informatics in Medicine and Ageing Research,
University of Rostock, Rostock, Germany. (5)Center for Bioinformatics, Saarland
University, Saarbruecken, Germany. volkhard.helms@bioinformatik.uni-saarland.de.

BACKGROUND: Identifying the gene regulatory networks governing the workings and
identity of cells is one of the main challenges in understanding processes such
as cellular differentiation, reprogramming or cancerogenesis. One particular
challenge is to identify the main drivers and master regulatory genes that
control such cell fate transitions. In this work, we reformulate this problem as 
the optimization problems of computing a Minimum Dominating Set and a Minimum
Connected Dominating Set for directed graphs.
RESULTS: Both MDS and MCDS are applied to the well-studied gene regulatory
networks of the model organisms E. coli and S. cerevisiae and to a pluripotency
network for mouse embryonic stem cells. The results show that MCDS can capture
most of the known key player genes identified so far in the model organisms.
Moreover, this method suggests an additional small set of transcription factors
as novel key players for governing the cell-specific gene regulatory network
which can also be investigated with regard to diseases. To this aim, we
investigated the ability of MCDS to define key drivers in breast cancer. The
method identified many known drug targets as members of the MDS and MCDS.
CONCLUSIONS: This paper proposes a new method to identify key player genes in
gene regulatory networks. The Java implementation of the heuristic algorithm
explained in this paper is available as a Cytoscape plugin at
http://apps.cytoscape.org/apps/mcds . The SageMath programs for solving integer
linear programming formulations used in the paper are available at
https://github.com/maryamNazarieh/KeyRegulatoryGenes and as supplementary
material.

DOI: 10.1186/s12918-016-0329-5 
PMCID: PMC5011974
PMID: 27599550  [PubMed - in process]


306. Front Neuroinform. 2016 Aug 19;10:37. doi: 10.3389/fninf.2016.00037. eCollection 
2016.

AxonSeg: Open Source Software for Axon and Myelin Segmentation and Morphometric
Analysis.

Zaimi A(1), Duval T(1), Gasecka A(2), Côté D(2), Stikov N(3), Cohen-Adad J(4).

Author information: 
(1)Institute of Biomedical Engineering, Polytechnique Montreal Montreal, QC,
Canada. (2)Institut Universitaire en Santé Mentale de QuébecQuebec, QC, Canada;
Centre d'Optique, Photonique et Laser, Université LavalQuebec, QC, Canada.
(3)Institute of Biomedical Engineering, Polytechnique MontrealMontreal, QC,
Canada; Montreal Heart InstituteMontreal, QC, Canada. (4)Institute of Biomedical 
Engineering, Polytechnique MontrealMontreal, QC, Canada; Functional Neuroimaging 
Unit, CRIUGM, Université de MontréalMontreal, QC, Canada.

Segmenting axon and myelin from microscopic images is relevant for studying the
peripheral and central nervous system and for validating new MRI techniques that 
aim at quantifying tissue microstructure. While several software packages have
been proposed, their interface is sometimes limited and/or they are designed to
work with a specific modality (e.g., scanning electron microscopy (SEM) only).
Here we introduce AxonSeg, which allows to perform automatic axon and myelin
segmentation on histology images, and to extract relevant morphometric
information, such as axon diameter distribution, axon density and the myelin
g-ratio. AxonSeg includes a simple and intuitive MATLAB-based graphical user
interface (GUI) and can easily be adapted to a variety of imaging modalities. The
main steps of AxonSeg consist of: (i) image pre-processing; (ii) pre-segmentation
of axons over a cropped image and discriminant analysis (DA) to select the best
parameters based on axon shape and intensity information; (iii) automatic axon
and myelin segmentation over the full image; and (iv) atlas-based statistics to
extract morphometric information. Segmentation results from standard optical
microscopy (OM), SEM and coherent anti-Stokes Raman scattering (CARS) microscopy 
are presented, along with validation against manual segmentations. Being
fully-automatic after a quick manual intervention on a cropped image, we believe 
AxonSeg will be useful to researchers interested in large throughput histology.
AxonSeg is open source and freely available at:
https://github.com/neuropoly/axonseg.

DOI: 10.3389/fninf.2016.00037 
PMCID: PMC4990549
PMID: 27594833  [PubMed]


307. Bioinformatics. 2016 Sep 1. pii: btw568. [Epub ahead of print]

popSTR: population-scale detection of STR variants.

Kristmundsdóttir S(1), Sigurpálsdóttir BD(2), Kehr B(1), Halldórsson BV(3).

Author information: 
(1)deCODE genetics/Amgen. (2)School of Science and Engineering, Reykjavík
University, Reykjavík, 101, Iceland. (3)deCODE genetics/Amgen School of Science
and Engineering, Reykjavík University, Reykjavík, 101, Iceland.

MOTIVATION: Microsatellites, also known as short tandem repeats (STRs), are
tracts of repetitive DNA sequences containing motifs ranging from two to six
bases. Microsatellites are one of the most abundant type of variation in the
human genome, after single nucleotide polymorphisms (SNPs) and Indels.
Microsatellite analysis has a wide range of applications, including medical
genetics, forensics and construction of genetic genealogy. However,
microsatellite variations are rarely considered in whole-genome sequencing
studies, in large due to a lack of tools capable of analyzing them.
RESULTS: Here we present a microsatellite genotyper, optimized for Illumina WGS
data, which is both faster and more accurate than other methods previously
presented. There are two main ingredients to our improvements. First we reduce
the amount of sequencing data necessary for creating microsatellite profiles by
using previously aligned sequencing data. Second, we use population information
to train microsatellite and individual specific error profiles. By comparing our 
genotyping results to genotypes generated by capillary electrophoresis we show
that our error rates are 50% lower than those of lobSTR, another program
specifically developed to determine microsatellite genotypes.
AVAILABILITY AND IMPLEMENTATION: Source code is available on Github:
https://github.com/Decode Genetics/popSTR CONTACT:
snaedis.kristmundsdottir@decode.is or bjarni.halldorsson@decode.is.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw568 
PMID: 27591079  [PubMed - as supplied by publisher]


308. PLoS One. 2016 Sep 2;11(9):e0162366. doi: 10.1371/journal.pone.0162366.
eCollection 2016.

Driving the Model to Its Limit: Profile Likelihood Based Model Reduction.

Maiwald T(1), Hass H(1), Steiert B(1), Vanlier J(1), Engesser R(1), Raue A(2),
Kipkeew F(3), Bock HH(3), Kaschek D(1), Kreutz C(1,)(4), Timmer J(1,)(4,)(5).

Author information: 
(1)Institute of Physics, University of Freiburg, Freiburg im Breisgau, Germany.
(2)Merrimack Pharmaceuticals, Boston, MA, United States of America. (3)Department
of Gastroenterology, Hepatology and Infectiology, University Hospital
Duesseldorf, Duesseldorf, Germany. (4)Center for Biosystems Analysis (ZBSA),
University of Freiburg, Freiburg im Breisgau, Germany. (5)BIOSS Centre for
Biological Signalling Studies, University of Freiburg, Freiburg im Breisgau,
Germany.

In systems biology, one of the major tasks is to tailor model complexity to
information content of the data. A useful model should describe the data and
produce well-determined parameter estimates and predictions. Too small of a model
will not be able to describe the data whereas a model which is too large tends to
overfit measurement errors and does not provide precise predictions. Typically,
the model is modified and tuned to fit the data, which often results in an
oversized model. To restore the balance between model complexity and available
measurements, either new data has to be gathered or the model has to be reduced. 
In this manuscript, we present a data-based method for reducing non-linear
models. The profile likelihood is utilised to assess parameter identifiability
and designate likely candidates for reduction. Parameter dependencies are
analysed along profiles, providing context-dependent suggestions for the type of 
reduction. We discriminate four distinct scenarios, each associated with a
specific model reduction strategy. Iterating the presented procedure eventually
results in an identifiable model, which is capable of generating precise and
testable predictions. Source code for all toy examples is provided within the
freely available, open-source modelling environment Data2Dynamics based on MATLAB
available at http://www.data2dynamics.org/, as well as the R packages dMod/cOde
available at https://github.com/dkaschek/. Moreover, the concept is generally
applicable and can readily be used with any software capable of calculating the
profile likelihood.

DOI: 10.1371/journal.pone.0162366 
PMCID: PMC5010240
PMID: 27588423  [PubMed - in process]


309. Bioinformatics. 2016 Sep 1;32(17):i727-i735. doi: 10.1093/bioinformatics/btw459.

Large-scale inference of conjunctive Bayesian networks.

Montazeri H(1), Kuipers J(1), Kouyos R(2), Böni J(3), Yerly S(4), Klimkait T(5), 
Aubert V(6), Günthard HF(2), Beerenwinkel N(1); Swiss HIV Cohort Study.

Author information: 
(1)Department of Biosystems Science and Engineering, ETH Zurich, Basel,
Switzerland SIB Swiss Institute of Bioinformatics, Basel, Switzerland.
(2)Division of Infectious Diseases and Hospital Epidemiology, University Hospital
Zurich, University of Zurich, Zurich, Switzerland Institute of Medical Virology. 
(3)Swiss National Center for Retroviruses, Institute of Medical Virology,
University of Zurich, Zurich 8057, Switzerland. (4)Laboratory of Virology,
Division of Infectious Diseases, Geneva University Hospital, Geneva, Switzerland.
(5)Department of Biomedicine-Petersplatz, University of Basel, Basel,
Switzerland. (6)Division of Immunology and Allergy, University Hospital Lausanne,
Lausanne, Switzerland.

The continuous time conjunctive Bayesian network (CT-CBN) is a graphical model
for analyzing the waiting time process of the accumulation of genetic changes
(mutations). CT-CBN models have been successfully used in several biological
applications such as HIV drug resistance development and genetic progression of
cancer. However, current approaches for parameter estimation and network
structure learning of CBNs can only deal with a small number of mutations (<20). 
Here, we address this limitation by presenting an efficient and accurate
approximate inference algorithm using a Monte Carlo expectation-maximization
algorithm based on importance sampling. The new method can now be used for a
large number of mutations, up to one thousand, an increase by two orders of
magnitude. In simulation studies, we present the accuracy as well as the running 
time efficiency of the new inference method and compare it with a MLE method,
expectation-maximization, and discrete time CBN model, i.e. a first-order
approximation of the CT-CBN model. We also study the application of the new model
on HIV drug resistance datasets for the combination therapy with zidovudine plus 
lamivudine (AZT + 3TC) as well as under no treatment, both extracted from the
Swiss HIV Cohort Study database.AVAILABILITY AND IMPLEMENTATION: The proposed
method is implemented as an R package available at
https://github.com/cbg-ethz/MC-CBN CONTACT: niko.beerenwinkel@bsse.ethz.ch
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw459 
PMID: 27587695  [PubMed - in process]


310. Bioinformatics. 2016 Sep 1;32(17):i710-i717. doi: 10.1093/bioinformatics/btw442.

A probabilistic model for detecting rigid domains in protein structures.

Nguyen T(1), Habeck M(2).

Author information: 
(1)Felix Bernstein Institute for Mathematical Statistics in the Biosciences,
University of Göttingen. (2)Felix Bernstein Institute for Mathematical Statistics
in the Biosciences, University of Göttingen Max Planck Institute for Biophysical 
Chemistry, Göttingen 37077, Germany.

MOTIVATION: Large-scale conformational changes in proteins are implicated in many
important biological functions. These structural transitions can often be
rationalized in terms of relative movements of rigid domains. There is a need for
objective and automated methods that identify rigid domains in sets of protein
structures showing alternative conformational states.
RESULTS: We present a probabilistic model for detecting rigid-body movements in
protein structures. Our model aims to approximate alternative conformational
states by a few structural parts that are rigidly transformed under the action of
a rotation and a translation. By using Bayesian inference and Markov chain Monte 
Carlo sampling, we estimate all parameters of the model, including a segmentation
of the protein into rigid domains, the structures of the domains themselves, and 
the rigid transformations that generate the observed structures. We find that our
Gibbs sampling algorithm can also estimate the optimal number of rigid domains
with high efficiency and accuracy. We assess the power of our method on several
thousand entries of the DynDom database and discuss applications to various
complex biomolecular systems.
AVAILABILITY AND IMPLEMENTATION: The Python source code for protein ensemble
analysis is available at: https://github.com/thachnguyen/motion_detection
CONTACT: : mhabeck@gwdg.de.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw442 
PMID: 27587693  [PubMed - in process]


311. Bioinformatics. 2016 Sep 1;32(17):i680-i684. doi: 10.1093/bioinformatics/btw445.

SWORD-a highly efficient protein database search.

Vaser R(1), Pavlović D(1), Šikić M(2).

Author information: 
(1)Faculty of Electrical Engineering and Computing, University of Zagreb, Unska
3, Zagreb 10000, Croatia. (2)Faculty of Electrical Engineering and Computing,
University of Zagreb, Unska 3, Zagreb 10000, Croatia Bioinformatics Institute,
a*STAR, #07-01 Matrix, 138671, Singapore.

MOTIVATION: Protein database search is one of the fundamental problems in
bioinformatics. For decades, it has been explored and solved using different
exact and heuristic approaches. However, exponential growth of data in recent
years has brought significant challenges in improving already existing
algorithms. BLAST has been the most successful tool for protein database search, 
but is also becoming a bottleneck in many applications. Due to that, many
different approaches have been developed to complement or replace it. In this
article, we present SWORD, an efficient protein database search implementation
that runs 8-16 times faster than BLAST in the sensitive mode and up to 68 times
faster in the fast and less accurate mode. It is designed to be used in nearly
all database search environments, but is especially suitable for large databases.
Its sensitivity exceeds that of BLAST for majority of input datasets and provides
guaranteed optimal alignments.
AVAILABILITY AND IMPLEMENTATION: Sword is freely available for download from
https://github.com/rvaser/sword
CONTACT: robert.vaser@fer.hr and mile.sikic@fer.hr
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw445 
PMID: 27587689  [PubMed - in process]


312. Bioinformatics. 2016 Sep 1;32(17):i649-i657. doi: 10.1093/bioinformatics/btw426.

Snowball: strain aware gene assembly of metagenomes.

Gregor I(1), Schönhuth A(2), McHardy AC(1).

Author information: 
(1)Department of Algorithmic Bioinformatics, Heinrich-Heine-University
Düsseldorf, Düsseldorf 40225, Germany Computational Biology of Infection
Research, Helmholtz Center for Infection Research, Braunschweig 38124, Germany.
(2)Centrum Wiskunde & Informatica, Amsterdam, XG 1098, The Netherlands.

MOTIVATION: Gene assembly is an important step in functional analysis of shotgun 
metagenomic data. Nonetheless, strain aware assembly remains a challenging task, 
as current assembly tools often fail to distinguish among strain variants or
require closely related reference genomes of the studied species to be available.
RESULTS: We have developed Snowball, a novel strain aware gene assembler for
shotgun metagenomic data that does not require closely related reference genomes 
to be available. It uses profile hidden Markov models (HMMs) of gene domains of
interest to guide the assembly. Our assembler performs gene assembly of
individual gene domains based on read overlaps and error correction using read
quality scores at the same time, which results in very low per-base error rates.
AVAILABILITY AND IMPLEMENTATION: The software runs on a user-defined number of
processor cores in parallel, runs on a standard laptop and is available under the
GPL 3.0 license for installation under Linux or OS X at
https://github.com/hzi-bifo/snowball
CONTACT: AMC14@helmholtz-hzi.de,a.schoenhuth@cwi.nl
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw426 
PMID: 27587685  [PubMed - in process]


313. Bioinformatics. 2016 Sep 1;32(17):i629-i638. doi: 10.1093/bioinformatics/btw448.

PeakXus: comprehensive transcription factor binding site discovery from
ChIP-Nexus and ChIP-Exo experiments.

Hartonen T(1), Sahu B(1), Dave K(2), Kivioja T(1), Taipale J(3).

Author information: 
(1)Genome-Scale Biology Research Program, Research Programs Unit, University of
Helsinki, Helsinki, Finland. (2)Department of Biosciences and Nutrition,
Karolinska Institutet, Stockholm, Sweden. (3)Genome-Scale Biology Research
Program, Research Programs Unit, University of Helsinki, Helsinki, Finland
Department of Biosciences and Nutrition, Karolinska Institutet, Stockholm,
Sweden.

MOTIVATION: Transcription factor (TF) binding can be studied accurately in vivo
with ChIP-exo and ChIP-Nexus experiments. Only fraction of TF binding mechanisms 
are yet fully understood and accurate knowledge of binding locations and patterns
of TFs is key to understanding binding that is not explained by simple positional
weight matrix models. ChIP-exo/Nexus experiments can also offer insight on the
effect of single nucleotide polymorphism (SNP) at TF binding sites on expression 
of the target genes. This is an important mechanism of action for disease-causing
SNPs at non-coding genomic regions.
RESULTS: We describe a peak caller PeakXus that is specifically designed to
leverage the increased resolution of ChIP-exo/Nexus and developed with the aim of
making as few assumptions of the data as possible to allow discoveries of novel
binding patterns. We apply PeakXus to ChIP-Nexus and ChIP-exo experiments
performed both in Homo sapiens and in Drosophila melanogaster cell lines. We show
that PeakXus consistently finds more peaks overlapping with a TF-specific
recognition sequence than published methods. As an application example we
demonstrate how PeakXus can be coupled with unique molecular identifiers (UMIs)
to measure the effect of a SNP overlapping with a TF binding site on the in vivo 
binding of the TF.
AVAILABILITY AND IMPLEMENTATION: Source code of PeakXus is available at
https://github.com/hartonen/PeakXus
CONTACT: tuomo.hartonen@helsinki.fi or jussi.taipale@ki.se.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw448 
PMID: 27587683  [PubMed - in process]


314. Bioinformatics. 2016 Sep 1;32(17):i620-i628. doi: 10.1093/bioinformatics/btw428.

XGSA: A statistical method for cross-species gene set analysis.

Djordjevic D(1), Kusumi K(2), Ho JW(1).

Author information: 
(1)Victor Chang Cardiac Research Institute, Darlinghurst, NSW 2010, Australia, St
Vincent's Clinical School, University of New South Wales Australia, Darlinghurst,
NSW 2010, Australia. (2)School of Life Sciences, Arizona State University, Tempe,
AZ 85287, USA.

MOTIVATION: Gene set analysis is a powerful tool for determining whether an
experimentally derived set of genes is statistically significantly enriched for
genes in other pre-defined gene sets, such as known pathways, gene ontology
terms, or other experimentally derived gene sets. Current gene set analysis
methods do not facilitate comparing gene sets across different organisms as they 
do not explicitly deal with homology mapping between species. There lacks a
systematic investigation about the effect of complex gene homology on
cross-species gene set analysis.
RESULTS: In this study, we show that not accounting for the complex homology
structure when comparing gene sets in two species can lead to false positive
discoveries, especially when comparing gene sets that have complex gene homology 
relationships. To overcome this bias, we propose a straightforward statistical
approach, called XGSA, that explicitly takes the cross-species homology mapping
into consideration when doing gene set analysis. Simulation experiments confirm
that XGSA can avoid false positive discoveries, while maintaining good
statistical power compared to other ad hoc approaches for cross-species gene set 
analysis. We further demonstrate the effectiveness of XGSA with two real-life
case studies that aim to discover conserved or species-specific molecular
pathways involved in social challenge and vertebrate appendage regeneration.
AVAILABILITY AND IMPLEMENTATION: The R source code for XGSA is available under a 
GNU General Public License at http://github.com/VCCRI/XGSA CONTACT:
jho@victorchang.edu.au.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw428 
PMID: 27587682  [PubMed - in process]


315. Bioinformatics. 2016 Sep 1;32(17):i595-i604. doi: 10.1093/bioinformatics/btw423.

Detecting horizontal gene transfer by mapping sequencing reads across species
boundaries.

Trappe K(1), Marschall T(2), Renard BY(1).

Author information: 
(1)Robert Koch Institute, Research Group Bioinformatics (NG4), 13353 Berlin,
Germany. (2)Center for Bioinformatics, Saarland University, and Max Planck
Institute for Informatics, 66123 Saarbrücken, Germany.

MOTIVATION: Horizontal gene transfer (HGT) is a fundamental mechanism that
enables organisms such as bacteria to directly transfer genetic material between 
distant species. This way, bacteria can acquire new traits such as antibiotic
resistance or pathogenic toxins. Current bioinformatics approaches focus on the
detection of past HGT events by exploring phylogenetic trees or genome
composition inconsistencies. However, these techniques normally require the
availability of finished and fully annotated genomes and of sufficiently large
deviations that allow detection and are thus not widely applicable. Especially in
outbreak scenarios with HGT-mediated emergence of new pathogens, like the
enterohemorrhagic Escherichia coli outbreak in Germany 2011, there is need for
fast and precise HGT detection. Next-generation sequencing (NGS) technologies
facilitate rapid analysis of unknown pathogens but, to the best of our knowledge,
so far no approach detects HGTs directly from NGS reads.
RESULTS: We present Daisy, a novel mapping-based tool for HGT detection. Daisy
determines HGT boundaries with split-read mapping and evaluates candidate regions
relying on read pair and coverage information. Daisy successfully detects HGT
regions with base pair resolution in both simulated and real data, and
outperforms alternative approaches using a genome assembly of the reads. We see
our approach as a powerful complement for a comprehensive analysis of HGT in the 
context of NGS data.
AVAILABILITY AND IMPLEMENTATION: Daisy is freely available from
http://github.com/ktrappe/daisy
CONTACT: renardb@rki.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw423 
PMID: 27587679  [PubMed - in process]


316. Bioinformatics. 2016 Sep 1;32(17):i559-i566. doi: 10.1093/bioinformatics/btw453.

Extending partial haplotypes to full genome haplotypes using chromosome
conformation capture data.

Ben-Elazar S(1), Chor B(2), Yakhini Z(3).

Author information: 
(1)Department of Computer Science, Tel-Aviv University, Israel Microsoft R&D,
HerzlyiaIsrael. (2)Department of Computer Science, Tel-Aviv University, Israel.
(3)Agilent Laboratories, Tel-Aviv, Israel Computer Science Department, Technion -
Israel Institute of Technology, Haifa, Israel School of computer science,
Herzeliya Interdisciplinary Center.

MOTIVATION: Complex interactions among alleles often drive differences in
inherited properties including disease predisposition. Isolating the effects of
these interactions requires phasing information that is difficult to measure or
infer. Furthermore, prevalent sequencing technologies used in the essential first
step of determining a haplotype limit the range of that step to the span of
reads, namely hundreds of bases. With the advent of pseudo-long read
technologies, observable partial haplotypes can span several orders of magnitude 
more. Yet, measuring whole-genome-single-individual haplotypes remains a
challenge. A different view of whole genome measurement addresses the 3D
structure of the genome-with great development of Hi-C techniques in recent
years. A shortcoming of current Hi-C, however, is the difficulty in inferring
information that is specific to each of a pair of homologous chromosomes.
RESULTS: In this work, we develop a robust algorithmic framework that takes two
measurement derived datasets: raw Hi-C and partial short-range haplotypes, and
constructs the full-genome haplotype as well as phased diploid Hi-C maps. By
analyzing both data sets together we thus bridge important gaps in both
technologies-from short to long haplotypes and from un-phased to phased Hi-C. We 
demonstrate that our method can recover ground truth haplotypes with high
accuracy, using measured biological data as well as simulated data. We analyze
the impact of noise, Hi-C sequencing depth and measured haplotype lengths on
performance. Finally, we use the inferred 3D structure of a human genome to point
at transcription factor targets nuclear co-localization.
AVAILABILITY AND IMPLEMENTATION: The implementation available at
https://github.com/YakhiniGroup/SpectraPh
CONTACT: zohar.yakhini@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw453 
PMID: 27587675  [PubMed - in process]


317. Bioinformatics. 2016 Sep 1;32(17):i545-i551. doi: 10.1093/bioinformatics/btw463.

CoLoRMap: Correcting Long Reads by Mapping short reads.

Haghshenas E(1), Hach F(2), Sahinalp SC(3), Chauve C(4).

Author information: 
(1)School of Computing Sciences MADD-Gen Graduate Program, Simon Fraser
University, Burnaby, BC V5A 1S6, Canada. (2)School of Computing Sciences
Vancouver Prostate Centre, Vancouver, BC V6H 3Z6, Canada. (3)School of Computing 
Sciences Vancouver Prostate Centre, Vancouver, BC V6H 3Z6, Canada, School of
Informatics and Computing, Indiana University, Bloomington, IN 47405, USA.
(4)Department of Mathematics, Simon Fraser University, Burnaby, BC V5A 1S6,
Canada.

MOTIVATION: Second generation sequencing technologies paved the way to an
exceptional increase in the number of sequenced genomes, both prokaryotic and
eukaryotic. However, short reads are difficult to assemble and often lead to
highly fragmented assemblies. The recent developments in long reads sequencing
methods offer a promising way to address this issue. However, so far long reads
are characterized by a high error rate, and assembling from long reads require a 
high depth of coverage. This motivates the development of hybrid approaches that 
leverage the high quality of short reads to correct errors in long reads.
RESULTS: We introduce CoLoRMap, a hybrid method for correcting noisy long reads, 
such as the ones produced by PacBio sequencing technology, using high-quality
Illumina paired-end reads mapped onto the long reads. Our algorithm is based on
two novel ideas: using a classical shortest path algorithm to find a sequence of 
overlapping short reads that minimizes the edit score to a long read and
extending corrected regions by local assembly of unmapped mates of mapped short
reads. Our results on bacterial, fungal and insect data sets show that CoLoRMap
compares well with existing hybrid correction methods.
AVAILABILITY AND IMPLEMENTATION: The source code of CoLoRMap is freely available 
for non-commercial use at https://github.com/sfu-compbio/colormap
CONTACT: ehaghshe@sfu.ca or cedric.chauve@sfu.ca
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw463 
PMID: 27587673  [PubMed - in process]


318. Bioinformatics. 2016 Sep 1;32(17):i520-i528. doi: 10.1093/bioinformatics/btw456.

Assemble CRISPRs from metagenomic sequencing data.

Lei J(1), Sun Y(1).

Author information: 
(1)Department of Computer Science and Engineering, Michigan State University,
East Lansing, MI 48824, USA.

MOTIVATION: Clustered regularly interspaced short palindromic repeats and
associated proteins (CRISPR-Cas) allows more specific and efficient gene editing 
than all previous genetic engineering systems. These exciting discoveries stem
from the finding of the CRISPR system being an adaptive immune system that
protects the prokaryotes against exogenous genetic elements such as phages.
Despite the exciting discoveries, almost all knowledge about CRISPRs is based
only on microorganisms that can be isolated, cultured and sequenced in labs.
However, about 95% of bacterial species cannot be cultured in labs. The fast
accumulation of metagenomic data, which contains DNA sequences of microbial
species from natural samples, provides a unique opportunity for CRISPR annotation
in uncultivable microbial species. However, the large amount of data,
heterogeneous coverage and shared leader sequences of some CRISPRs pose
challenges for identifying CRISPRs efficiently in metagenomic data.
RESULTS: In this study, we developed a CRISPR finding tool for metagenomic data
without relying on generic assembly, which is error-prone and computationally
expensive for complex data. Our tool can run on commonly available machines in
small labs. It employs properties of CRISPRs to decompose generic assembly into
local assembly. We tested it on both mock and real metagenomic data and
benchmarked the performance with state-of-the-art tools.
AVAILABILITY AND IMPLEMENTATION: The source code and the documentation of
metaCRISPR is available at https://github.com/hangelwen/metaCRISPR CONTACT:
yannisun@msu.edu.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw456 
PMID: 27587670  [PubMed - in process]


319. Bioinformatics. 2016 Sep 1;32(17):i511-i519. doi: 10.1093/bioinformatics/btw468.

LuxGLM: a probabilistic covariate model for quantification of DNA methylation
modifications with complex experimental designs.

Äijö T(1), Yue X(2), Rao A(3), Lähdesmäki H(4).

Author information: 
(1)Center for Computational Biology, Simons Foundation, New York, NY 10010, USA
Department of Computer Science, Aalto University School of Science, Aalto
FI-00076, Finland. (2)La Jolla Institute for Allergy and Immunology, La Jolla, CA
92037, USA. (3)La Jolla Institute for Allergy and Immunology, La Jolla, CA 92037,
USA Department of Pharmacology and Moores Cancer Center, University of
California, La Jolla, CA 92037, USA Sanford Consortium for Regenerative Medicine,
La Jolla, CA 92037, USA. (4)Department of Computer Science, Aalto University
School of Science, Aalto FI-00076, Finland.

MOTIVATION: 5-methylcytosine (5mC) is a widely studied epigenetic modification of
DNA. The ten-eleven translocation (TET) dioxygenases oxidize 5mC into oxidized
methylcytosines (oxi-mCs): 5-hydroxymethylcytosine (5hmC), 5-formylcytosine (5fC)
and 5-carboxylcytosine (5caC). DNA methylation modifications have multiple
functions. For example, 5mC is shown to be associated with diseases and oxi-mC
species are reported to have a role in active DNA demethylation through 5mC
oxidation and DNA repair, among others, but the detailed mechanisms are poorly
understood. Bisulphite sequencing and its various derivatives can be used to gain
information about all methylation modifications at single nucleotide resolution. 
Analysis of bisulphite based sequencing data is complicated due to the convoluted
read-outs and experiment-specific variation in biochemistry. Moreover,
statistical analysis is often complicated by various confounding effects. How to 
analyse 5mC and oxi-mC data sets with arbitrary and complex experimental designs 
is an open and important problem.
RESULTS: We propose the first method to quantify oxi-mC species with arbitrary
covariate structures from bisulphite based sequencing data. Our probabilistic
modeling framework combines a previously proposed hierarchical generative model
for oxi-mC-seq data and a general linear model component to account for
confounding effects. We show that our method provides accurate methylation level 
estimates and accurate detection of differential methylation when compared with
existing methods. Analysis of novel and published data gave insights into to the 
demethylation of the forkhead box P3 (Foxp3) locus during the induced T
regulatory cell differentiation. We also demonstrate how our covariate model
accurately predicts methylation levels of the Foxp3 locus. Collectively, LuxGLM
method improves the analysis of DNA methylation modifications, particularly for
oxi-mC species.
AVAILABILITY AND IMPLEMENTATION: An implementation of the proposed method is
available under MIT license at https://github.org/tare/LuxGLM/ CONTACT:
taijo@simonsfoundation.org or harri.lahdesmaki@aalto.fi
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw468 
PMCID: PMC5013920 [Available on 2017-09-01]
PMID: 27587669  [PubMed - in process]


320. Bioinformatics. 2016 Sep 1;32(17):i494-i502. doi: 10.1093/bioinformatics/btw450.

Information-optimal genome assembly via sparse read-overlap graphs.

Shomorony I(1), Kim SH(1), Courtade TA(1), Tse DN(2).

Author information: 
(1)Department of Electrical Engineering & Computer Sciences, University of
California, Berkeley, CA, USA. (2)Department of Electrical Engineering & Computer
Sciences, University of California, Berkeley, CA, USA Department of Electrical
Engineering, Stanford University, Stanford, CA, USA.

MOTIVATION: In the context of third-generation long-read sequencing technologies,
read-overlap-based approaches are expected to play a central role in the assembly
step. A fundamental challenge in assembling from a read-overlap graph is that the
true sequence corresponds to a Hamiltonian path on the graph, and, under most
formulations, the assembly problem becomes NP-hard, restricting practical
approaches to heuristics. In this work, we avoid this seemingly fundamental
barrier by first setting the computational complexity issue aside, and seeking an
algorithm that targets information limits In particular, we consider a basic
feasibility question: when does the set of reads contain enough information to
allow unambiguous reconstruction of the true sequence?
RESULTS: Based on insights from this information feasibility question, we present
an algorithm-the Not-So-Greedy algorithm-to construct a sparse read-overlap
graph. Unlike most other assembly algorithms, Not-So-Greedy comes with a
performance guarantee: whenever information feasibility conditions are satisfied,
the algorithm reduces the assembly problem to an Eulerian path problem on the
resulting graph, and can thus be solved in linear time. In practice, this
theoretical guarantee translates into assemblies of higher quality. Evaluations
on both simulated reads from real genomes and a PacBio Escherichia coli K12
dataset demonstrate that Not-So-Greedy compares favorably with standard string
graph approaches in terms of accuracy of the resulting read-overlap graph and
contig N50.
AVAILABILITY: Available at github.com/samhykim/nsg
CONTACT: courtade@eecs.berkeley.edu or dntse@stanford.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw450 
PMID: 27587667  [PubMed - in process]


321. Bioinformatics. 2016 Sep 1;32(17):i479-i486. doi: 10.1093/bioinformatics/btw437.

GTRAC: fast retrieval from compressed collections of genomic variants.

Tatwawadi K(1), Hernaez M(1), Ochoa I(1), Weissman T(1).

Author information: 
(1)Department of Electrical Engineering, Stanford University, 350 Serra Mall,
Stanford, CA, USA.

MOTIVATION: The dramatic decrease in the cost of sequencing has resulted in the
generation of huge amounts of genomic data, as evidenced by projects such as the 
UK10K and the Million Veteran Project, with the number of sequenced genomes
ranging in the order of 10 K to 1 M. Due to the large redundancies among genomic 
sequences of individuals from the same species, most of the medical research
deals with the variants in the sequences as compared with a reference sequence,
rather than with the complete genomic sequences. Consequently, millions of
genomes represented as variants are stored in databases. These databases are
constantly updated and queried to extract information such as the common variants
among individuals or groups of individuals. Previous algorithms for compression
of this type of databases lack efficient random access capabilities, rendering
querying the database for particular variants and/or individuals extremely
inefficient, to the point where compression is often relinquished altogether.
RESULTS: We present a new algorithm for this task, called GTRAC, that achieves
significant compression ratios while allowing fast random access over the
compressed database. For example, GTRAC is able to compress a Homo sapiens
dataset containing 1092 samples in 1.1 GB (compression ratio of 160), while
allowing for decompression of specific samples in less than a second and
decompression of specific variants in 17 ms. GTRAC uses and adapts techniques
from information theory, such as a specialized Lempel-Ziv compressor, and
tailored succinct data structures.
AVAILABILITY AND IMPLEMENTATION: The GTRAC algorithm is available for download
at: https://github.com/kedartatwawadi/GTRAC CONTACT: : kedart@stanford.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw437 
PMCID: PMC5013914 [Available on 2017-09-01]
PMID: 27587665  [PubMed - in process]


322. Bioinformatics. 2016 Sep 1;32(17):i473-i478. doi: 10.1093/bioinformatics/btw436.

The Network Library: a framework to rapidly integrate network biology resources.

Summer G(1), Kelder T(2), Radonjic M(2), van Bilsen M(3), Wopereis S(4), Heymans 
S(3).

Author information: 
(1)CARIM, Maastricht University, Maastricht, The Netherlands TNO, Zeist, The
Netherlands. (2)EdgeLeap B.V, Utrecht, The Netherlands. (3)CARIM, Maastricht
University, Maastricht, The Netherlands. (4)TNO, Zeist, The Netherlands.

MOTIVATION: Much of the biological knowledge accumulated over the last decades is
stored in different databases governed by various organizations and institutes.
Integrating and connecting these vast knowledge repositories is an extremely
useful method to support life sciences research and help formulate novel
hypotheses.
RESULTS: We developed the Network Library (NL), a framework and toolset to
rapidly integrate different knowledge sources to build a network biology resource
that matches a specific research question. As a use-case we explore the
interactions of genes related to heart failure with miRNAs and diseases through
the integration of 6 databases.
AVAILABILITY AND IMPLEMENTATION: The NL is open-source, developed in Java and
available on Github (https://github.com/gsummer).
CONTACT: georg.summer@gmail.com.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw436 
PMID: 27587664  [PubMed - in process]


323. Bioinformatics. 2016 Sep 1;32(17):i464-i472. doi: 10.1093/bioinformatics/btw435.

Mutual enrichment in aggregated ranked lists with applications to gene expression
regulation.

Cohn-Alperovich D(1), Rabner A(2), Kifer I(3), Mandel-Gutfreund Y(2), Yakhini
Z(4).

Author information: 
(1)Computer Science Department, Technion - Israel Institute of Technology, Haifa 
3200003, Israel, Microsoft Research and Development Center, Haifa and Herzeliya, 
Israel. (2)Department of Biology, Technion - Israel Institute of Technology,
Haifa 3200003, Israel. (3)Microsoft Research and Development Center, Haifa and
Herzeliya, Israel. (4)Computer Science Department, Technion - Israel Institute of
Technology, Haifa 3200003, Israel, School of Computer Science, The
Interdisciplinary Center, Herzeliya 4610101, Israel.

MOTIVATION: It is often the case in biological measurement data that results are 
given as a ranked list of quantities-for example, differential expression (DE) of
genes as inferred from microarrays or RNA-seq. Recent years brought considerable 
progress in statistical tools for enrichment analysis in ranked lists. Several
tools are now available that allow users to break the fixed set paradigm in
assessing statistical enrichment of sets of genes. Continuing with the example,
these tools identify factors that may be associated with measured differential
expression. A drawback of existing tools is their focus on identifying single
factors associated with the observed or measured ranks, failing to address
relationships between these factors. For example, a scenario in which genes
targeted by multiple miRNAs play a central role in the DE signal but the effect
of each single miRNA is too subtle to be detected, as shown in our results.
RESULTS: We propose statistical and algorithmic approaches for selecting a
sub-collection of factors that can be aggregated into one ranked list that is
heuristically most associated with an input ranked list (pivot). We examine
performance on simulated data and apply our approach to cancer datasets. We find 
small sub-collections of miRNA that are statistically associated with gene DE in 
several types of cancer, suggesting miRNA cooperativity in driving disease
related processes. Many of our findings are consistent with known roles of miRNAs
in cancer, while others suggest previously unknown roles for certain miRNAs.
AVAILABILITY AND IMPLEMENTATION: Code and instructions for our algorithmic
framework, MULSEA, are in:
https://github.com/YakhiniGroup/MULSEAContact:dalia.cohn@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw435 
PMID: 27587663  [PubMed - in process]


324. Bioinformatics. 2016 Sep 1;32(17):i445-i454. doi: 10.1093/bioinformatics/btw434.

Simultaneous discovery of cancer subtypes and subtype features by molecular data 
integration.

Le Van T(1), van Leeuwen M(2), Carolina Fierro A(3), De Maeyer D(3), Van den
Eynden J(4), Verbeke L(3), De Raedt L(1), Marchal K(5), Nijssen S(6).

Author information: 
(1)Department of Computer Science, KULeuven, Leuven, Belgium. (2)Leiden Institute
for Advanced Computer Science, Universiteit Leiden, Leiden, The Netherlands.
(3)Department of Information Technology, iMinds, Ghent University, Gent, Belgium,
Bioinformatics Institute Ghent, 9052 Gent, Belgium, Department of Plant
Biotechnology and Bioinformatics, Ghent University, Gent, Belgium. (4)Department 
of Medical Biochemisty and Cell Biology, Institute of Biomedicine, University of 
Gothenburg, Gothenburg, Sweden. (5)Department of Information Technology, iMinds, 
Ghent University, Gent, Belgium, Bioinformatics Institute Ghent, 9052 Gent,
Belgium, Department of Plant Biotechnology and Bioinformatics, Ghent University, 
Gent, Belgium Department of Genetics, University of Pretoria, Hatfield Campus,
Pretoria 0028, South Africa. (6)Department of Computer Science, KULeuven, Leuven,
Belgium, Leiden Institute for Advanced Computer Science, Universiteit Leiden,
Leiden, The Netherlands.

MOTIVATION: Subtyping cancer is key to an improved and more personalized
prognosis/treatment. The increasing availability of tumor related molecular data 
provides the opportunity to identify molecular subtypes in a data-driven way.
Molecular subtypes are defined as groups of samples that have a similar molecular
mechanism at the origin of the carcinogenesis. The molecular mechanisms are
reflected by subtype-specific mutational and expression features. Data-driven
subtyping is a complex problem as subtyping and identifying the molecular
mechanisms that drive carcinogenesis are confounded problems. Many current
integrative subtyping methods use global mutational and/or expression tumor
profiles to group tumor samples in subtypes but do not explicitly extract the
subtype-specific features. We therefore present a method that solves both tasks
of subtyping and identification of subtype-specific features simultaneously.
Hereto our method integrates` mutational and expression data while taking into
account the clonal properties of carcinogenesis. Key to our method is a
formalization of the problem as a rank matrix factorization of ranked data that
approaches the subtyping problem as multi-view bi-clustering
RESULTS: We introduce a novel integrative framework to identify subtypes by
combining mutational and expression features. The incomparable measurement data
is integrated by transformation into ranked data and subtypes are defined as
multi-view bi-clusters We formalize the model using rank matrix factorization,
resulting in the SRF algorithm. Experiments on simulated data and the TCGA breast
cancer data demonstrate that SRF is able to capture subtle differences that
existing methods may miss.
AVAILABILITY AND IMPLEMENTATION: The implementation is available at:
https://github.com/rankmatrixfactorisation/SRF CONTACT:
kathleen.marchal@intec.ugent.be, siegfried.nijssen@cs.kuleuven.be
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw434 
PMID: 27587661  [PubMed - in process]


325. Bioinformatics. 2016 Sep 1;32(17):i430-i436. doi: 10.1093/bioinformatics/btw438.

Combining dependent P-values with an empirical adaptation of Brown's method.

Poole W(1), Gibbs DL(1), Shmulevich I(1), Bernard B(1), Knijnenburg TA(1).

Author information: 
(1)Institute for Systems Biology, Seattle, WA 98109-5263, USA.

MOTIVATION: Combining P-values from multiple statistical tests is a common
exercise in bioinformatics. However, this procedure is non-trivial for dependent 
P-values. Here, we discuss an empirical adaptation of Brown's method (an
extension of Fisher's method) for combining dependent P-values which is
appropriate for the large and correlated datasets found in high-throughput
biology.
RESULTS: We show that the Empirical Brown's method (EBM) outperforms Fisher's
method as well as alternative approaches for combining dependent P-values using
both noisy simulated data and gene expression data from The Cancer Genome Atlas.
AVAILABILITY AND IMPLEMENTATION: The Empirical Brown's method is available in
Python, R, and MATLAB and can be obtained from
https://github.com/IlyaLab/CombiningDependentPvalues UsingEBM The R code is also 
available as a Bioconductor package from
https://www.bioconductor.org/packages/devel/bioc/html/EmpiricalBrownsMethod.html
CONTACT: Theo.Knijnenburg@systemsbiology.org
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw438 
PMCID: PMC5013915 [Available on 2017-09-01]
PMID: 27587659  [PubMed - in process]


326. Bioinformatics. 2016 Sep 1;32(17):i421-i429. doi: 10.1093/bioinformatics/btw430.

Complementary feature selection from alternative splicing events and gene
expression for phenotype prediction.

Labuzzetta CJ(1), Antonio ML(2), Watson PM(3), Wilson RC(3), Laboissonniere
LA(4), Trimarchi JM(4), Genc B(5), Ozdinler PH(5), Watson DK(3), Anderson PE(6).

Author information: 
(1)Department of Mathematics, Iowa State University, Ames, IA 50011, USA.
(2)Department of Biology, Boston College, Chestnut Hill, MA 02467, USA.
(3)Department of Pathology and Laboratory Medicine, Medical University of South
Carolina, Charleston, NC 29425, USA. (4)Department of Genetics, Development and
Cell Biology, Iowa State University, Ames, IA 50011, USA. (5)Ken and Ruth Davee
Department of Neurology, Feinberg School of Medicine, Northwestern University,
Chicago, IL 60611, USA. (6)Department of Computer Science, College of Charleston,
Charleston, SC 29424, USA.

MOTIVATION: A central task of bioinformatics is to develop sensitive and specific
means of providing medical prognoses from biomarker patterns. Common methods to
predict phenotypes in RNA-Seq datasets utilize machine learning algorithms
trained via gene expression. Isoforms, however, generated from alternative
splicing, may provide a novel and complementary set of transcripts for phenotype 
prediction. In contrast to gene expression, the number of isoforms increases
significantly due to numerous alternative splicing patterns, resulting in a
prioritization problem for many machine learning algorithms. This study
identifies the empirically optimal methods of transcript quantification, feature 
engineering and filtering steps using phenotype prediction accuracy as a metric. 
At the same time, the complementary nature of gene and isoform data is analyzed
and the feasibility of identifying isoforms as biomarker candidates is examined.
RESULTS: Isoform features are complementary to gene features, providing
non-redundant information and enhanced predictive power when prioritized and
filtered. A univariate filtering algorithm, which selects up to the N highest
ranking features for phenotype prediction is described and evaluated in this
study. An empirical comparison of pipelines for isoform quantification is
reported by performing cross-validation prediction tests with datasets from human
non-small cell lung cancer (NSCLC) patients, human patients with chronic
obstructive pulmonary disease (COPD) and amyotrophic lateral sclerosis (ALS)
transgenic mice, each including samples of diseased and non-diseased phenotypes.
AVAILABILITY AND IMPLEMENTATION:
https://github.com/clabuzze/Phenotype-Prediction-Pipeline.git
CONTACT: clabuzze@iastate.edu, antoniom@bc.edu, watsondk@musc.edu,
andersonpe2@cofc.edu.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw430 
PMID: 27587658  [PubMed - in process]


327. Bioinformatics. 2016 Sep 1;32(17):i405-i412. doi: 10.1093/bioinformatics/btw432.

Higher order methylation features for clustering and prediction in epigenomic
studies.

Kapourani CA(1), Sanguinetti G(2).

Author information: 
(1)IANC, School of Informatics, University of Edinburgh, Edinburgh EH8 9AB, UK.
(2)IANC, School of Informatics, University of Edinburgh, Edinburgh EH8 9AB, UK
Synthetic and Systems Biology, University of Edinburgh, Edinburgh EH9 3JD, UK.

MOTIVATION: DNA methylation is an intensely studied epigenetic mark, yet its
functional role is incompletely understood. Attempts to quantitatively associate 
average DNA methylation to gene expression yield poor correlations outside of the
well-understood methylation-switch at CpG islands.
RESULTS: Here, we use probabilistic machine learning to extract higher order
features associated with the methylation profile across a defined region. These
features quantitate precisely notions of shape of a methylation profile,
capturing spatial correlations in DNA methylation across genomic regions. Using
these higher order features across promoter-proximal regions, we are able to
construct a powerful machine learning predictor of gene expression, significantly
improving upon the predictive power of average DNA methylation levels.
Furthermore, we can use higher order features to cluster promoter-proximal
regions, showing that five major patterns of methylation occur at promoters
across different cell lines, and we provide evidence that methylation beyond CpG 
islands may be related to regulation of gene expression. Our results support
previous reports of a functional role of spatial correlations in methylation
patterns, and provide a mean to quantitate such features for downstream analyses.
AVAILABILITY AND IMPLEMENTATION: https://github.com/andreaskapou/BPRMeth
CONTACT: G.Sanguinetti@ed.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw432 
PMID: 27587656  [PubMed - in process]


328. Bioinformatics. 2016 Sep 1;32(17):i396-i404. doi: 10.1093/bioinformatics/btw431.

Estimating real cell size distribution from cross-section microscopy imaging.

Lenz M(1), Roumans NJ(2), Vink RG(2), van Baak MA(2), Mariman EC(2), Arts IC(1), 
de Kok TM(1), Ertaylan G(1).

Author information: 
(1)Maastricht Centre for Systems Biology (MaCSBio), Maastricht University,
Maastricht, The Netherlands. (2)Department of Human Biology NUTRIM School of
Nutrition and Translational Research in Metabolism, Maastricht University,
Maastricht, The Netherlands.

MOTIVATION: Microscopy imaging is an essential tool for medical diagnosis and
molecular biology. It is particularly useful for extracting information about
disease states, tissue heterogeneity and cell specific parameters such as cell
type or cell size from biological specimens. However, the information obtained
from the images is likely to be subjected to sampling and observational bias with
respect to the underlying cell size/type distributions.
RESULTS: We present an algorithm, Estimate Tissue Cell Size/Type Distribution
(EstiTiCS), for the adjustment of the underestimation of the number of small
cells and the size of measured cells while accounting for the section thickness
independent of the tissue type. We introduce the sources of bias under different 
tissue distributions and their effect on the measured values with simulation
experiments. Furthermore, we demonstrate our method on histological sections of
paraffin-embedded adipose tissue sample images from 57 people from a dietary
intervention study. This data consists of measured cell size and its distribution
over the dietary intervention period at four time points. Adjusting for the bias 
with EstiTiCS results in a closer fit to the true/expected adipocyte size
distribution with earlier studies. Therefore, we conclude that our method is
suitable as the final step in estimating the tissue wide cell type/size
distribution from microscopy imaging pipeline.
AVAILABILITY AND IMPLEMENTATION: Source code and its documentation are available 
at https://github.com/michaelLenz/EstiTiCS The whole pipeline of our method is
implemented in R and makes use of the 'nloptr' package. Adipose tissue data used 
for this study are available on request.
CONTACT: Michael.Lenz@Maastrichtuniversity.nl,
Gokhan.Ertaylan@Maastrichtuniversity.nl.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw431 
PMID: 27587655  [PubMed - in process]


329. BMC Syst Biol. 2016 Aug 26;10 Suppl 3:69. doi: 10.1186/s12918-016-0313-0.

XMRF: an R package to fit Markov Networks to high-throughput genetics data.

Wan YW(1,)(2,)(3), Allen GI(4,)(3,)(5), Baker Y(4), Yang E(6), Ravikumar P(7),
Anderson M(1,)(8), Liu Z(9,)(10,)(11).

Author information: 
(1)Computational and Integrative Biomedical Research Center, Baylor College of
Medicine, Houston, Texas, USA. (2)Department of Human Genetics, Baylor College of
Medicine, Houston, Texas, USA. (3)Jan and Dan Duncan Neurological Research
Institute, Texas Children's Hospital, Houston, Texas, USA. (4)Department of
Pediatrics-Neurology, Baylor College of Medicine, Houston, Texas, USA.
(5)Department of Statistics and Electrical & Computer Engineering, Rice
University, Houston, Texas, USA. (6)IBM Thomas J. Waston Research Center,
Yorktown Heights, New York, USA. (7)Department of Computer Science, University of
Texas, Austin, Texas, USA. (8)Department of Obstetrics and Gynecology, Baylor
College of Medicine, Houston, Texas, USA. (9)Computational and Integrative
Biomedical Research Center, Baylor College of Medicine, Houston, Texas, USA.
zhandonl@bcm.edu. (10)Department of Pediatrics-Neurology, Baylor College of
Medicine, Houston, Texas, USA. zhandonl@bcm.edu. (11)Jan and Dan Duncan
Neurological Research Institute, Texas Children's Hospital, Houston, Texas, USA. 
zhandonl@bcm.edu.

BACKGROUND: Technological advances in medicine have led to a rapid proliferation 
of high-throughput "omics" data. Tools to mine this data and discover disrupted
disease networks are needed as they hold the key to understanding complicated
interactions between genes, mutations and aberrations, and epi-genetic markers.
RESULTS: We developed an R software package, XMRF, that can be used to fit Markov
Networks to various types of high-throughput genomics data. Encoding the models
and estimation techniques of the recently proposed exponential family Markov
Random Fields (Yang et al., 2012), our software can be used to learn genetic
networks from RNA-sequencing data (counts via Poisson graphical models), mutation
and copy number variation data (categorical via Ising models), and methylation
data (continuous via Gaussian graphical models).
CONCLUSIONS: XMRF is the only tool that allows network structure learning using
the native distribution of the data instead of the standard Gaussian. Moreover,
the parallelization feature of the implemented algorithms computes the
large-scale biological networks efficiently. XMRF is available from CRAN and
Github ( https://github.com/zhandong/XMRF ).

DOI: 10.1186/s12918-016-0313-0 
PMCID: PMC5009817
PMID: 27586041  [PubMed - in process]


330. J Comput Aided Mol Des. 2016 Nov;30(11):1079-1086. doi:
10.1007/s10822-016-9951-y. Epub 2016 Sep 1.

Calculation of distribution coefficients in the SAMPL5 challenge from atomic
solvation parameters and surface areas.

Santos-Martins D(1), Fernandes PA(2), Ramos MJ(2).

Author information: 
(1)UCIBIO, REQUIMTE, Departamento de Química e Bioquímica, Faculdade de Ciências,
Universidade do Porto, 4169-007, Porto, Portugal. diogom@fc.up.pt. (2)UCIBIO,
REQUIMTE, Departamento de Química e Bioquímica, Faculdade de Ciências,
Universidade do Porto, 4169-007, Porto, Portugal.

In the context of SAMPL5, we submitted blind predictions of the cyclohexane/water
distribution coefficient (D) for a series of 53 drug-like molecules. Our method
is purely empirical and based on the additive contribution of each solute atom to
the free energy of solvation in water and in cyclohexane. The contribution of
each atom depends on the atom type and on the exposed surface area. Comparatively
to similar methods in the literature, we used a very small set of atomic
parameters: only 10 for solvation in water and 1 for solvation in cyclohexane. As
a result, the method is protected from overfitting and the error in the blind
predictions could be reasonably estimated. Moreover, this approach is fast: it
takes only 0.5 s to predict the distribution coefficient for all 53 SAMPL5
compounds, allowing its application in virtual screening campaigns. The
performance of our approach (submission 49) is modest but satisfactory in view of
its efficiency: the root mean square error (RMSE) was 3.3 log D units for the 53 
compounds, while the RMSE of the best performing method (using COSMO-RS) was 2.1 
(submission 16). Our method is implemented as a Python script available at
https://github.com/diogomart/SAMPL5-DC-surface-empirical .

DOI: 10.1007/s10822-016-9951-y 
PMID: 27585473  [PubMed - in process]


331. F1000Res. 2016 Jul 5;5:1574. doi: 10.12688/f1000research.9110.1. eCollection
2016.

An open RNA-Seq data analysis pipeline tutorial with an example of reprocessing
data from a recent Zika virus study.

Wang Z(1), Ma'ayan A(1).

Author information: 
(1)Department of Pharmacology and Systems Therapeutics, Icahn School of Medicine 
at Mount Sinai, New York, NY, Box 1603, USA; BD2K-LINCS Data Coordination and
Integration Center, Icahn School of Medicine at Mount Sinai, New York, NY, Box
1603, USA; Mount Sinai Knowledge Management Center for Illuminating the Druggable
Genome, Icahn School of Medicine at Mount Sinai, New York, NY, Box 1603, USA.

RNA-seq analysis is becoming a standard method for global gene expression
profiling. However, open and standard pipelines to perform RNA-seq analysis by
non-experts remain challenging due to the large size of the raw data files and
the hardware requirements for running the alignment step. Here we introduce a
reproducible open source RNA-seq pipeline delivered as an IPython notebook and a 
Docker image. The pipeline uses state-of-the-art tools and can run on various
platforms with minimal configuration overhead. The pipeline enables the
extraction of knowledge from typical RNA-seq studies by generating interactive
principal component analysis (PCA) and hierarchical clustering (HC) plots,
performing enrichment analyses against over 90 gene set libraries, and obtaining 
lists of small molecules that are predicted to either mimic or reverse the
observed changes in mRNA expression. We apply the pipeline to a recently
published RNA-seq dataset collected from human neuronal progenitors infected with
the Zika virus (ZIKV). In addition to confirming the presence of cell cycle genes
among the genes that are downregulated by ZIKV, our analysis uncovers significant
overlap with upregulated genes that when knocked out in mice induce defects in
brain morphology. This result potentially points to the molecular processes
associated with the microcephaly phenotype observed in newborns from pregnant
mothers infected with the virus. In addition, our analysis predicts small
molecules that can either mimic or reverse the expression changes induced by
ZIKV. The IPython notebook and Docker image are freely available at: 
http://nbviewer.jupyter.org/github/maayanlab/Zika-RNAseq-Pipeline/blob/master/Zik
a.ipynb and  https://hub.docker.com/r/maayanlab/zika/.

DOI: 10.12688/f1000research.9110.1 
PMCID: PMC4972086
PMID: 27583132  [PubMed]


332. PLoS One. 2016 Aug 31;11(8):e0161474. doi: 10.1371/journal.pone.0161474.
eCollection 2016.

BRIDES: A New Fast Algorithm and Software for Characterizing Evolving Similarity 
Networks Using Breakthroughs, Roadblocks, Impasses, Detours, Equals and
Shortcuts.

Lord E(1,)(2), Le Cam M(2), Bapteste É(3,)(4), Méheust R(3), Makarenkov V(1),
Lapointe FJ(2).

Author information: 
(1)Département d'informatique, Université du Québec à Montréal, Montréal, Québec,
Canada. (2)Département de sciences biologiques, Université de Montréal, Montréal,
Québec, Canada. (3)Sorbonne Universités, UPMC Université Paris 06, Institut de
Biologie Paris-Seine, Paris, France. (4)CNRS, UMR7138, Institut de Biologie
Paris-Seine, Paris, France.

Various types of genome and gene similarity networks along with their
characteristics have been increasingly used for retracing different kinds of
evolutionary and ecological relationships. Here, we present a new polynomial time
algorithm and the corresponding software (BRIDES) to provide characterization of 
different types of paths existing in evolving (or augmented) similarity networks 
under the constraint that such paths contain at least one node that was not
present in the original network. These different paths are denoted as
Breakthroughs, Roadblocks, Impasses, Detours, Equal paths, and Shortcuts. The
analysis of their distribution can allow discriminating among different
evolutionary hypotheses concerning genomes or genes at hand. Our approach is
based on an original application of the popular shortest path Dijkstra's and
Yen's algorithms. The C++ and R versions of the BRIDES program are freely
available at: https://github.com/etiennelord/BRIDES.

DOI: 10.1371/journal.pone.0161474 
PMCID: PMC5007014
PMID: 27580188  [PubMed - in process]


333. Bioinformatics. 2017 Jan 1;33(1):133-134. doi: 10.1093/bioinformatics/btw563.
Epub 2016 Aug 29.

FATSLiM: a fast and robust software to analyze MD simulations of membranes.

Buchoux S(1).

Author information: 
(1)Laboratory of Enzyme and Cell Engineering (GEC - FRE3580 CNRS/UPJV/UTC),
Université de Picardie Jules Verne, Amiens, France.

When studying biological membranes, Molecular Dynamics (MD) simulations reveal to
be quite complementary to experimental techniques. Because the simulated systems 
keep increasing both in size and complexity, the analysis of MD trajectories need
to be computationally efficient while being robust enough to perform analysis on 
membranes that may be curved or deformed due to their size and/or protein-lipid
interactions. This work presents a new software named FATSLiM ('Fast Analysis
Toolbox for Simulations of Lipid Membranes') that can extract physical properties
from MD simulations of membranes (with or without interacting proteins). Because 
it relies on the calculation of local normals, FATSLiM does not depend of the
bilayer morphology and thus can handle with the same accuracy vesicles for
instance. Thanks to an efficiency-driven development, it is also fast and
consumes a rather low amount of memory.AVAILABILITY AND IMPLEMENTATION: FATSLiM
(http://fatslim.github.io) is a stand-alone software written in Python. Source
code is released under the GNU GPLv3 and is freely available at
https://github.com/FATSLiM/fatslim A complete online documentation including
instructions for platform-independent installation is available at
http://pythonhosted.org/fatslim CONTACT:
sebastien.buchoux@u-picardie.frSupplementary information: Supplementary data are 
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw563 
PMID: 27578804  [PubMed - in process]


334. BMC Bioinformatics. 2016 Aug 31;17(1):329. doi: 10.1186/s12859-016-1206-3.

A genetic algorithm-based weighted ensemble method for predicting
transposon-derived piRNAs.

Li D(1), Luo L(1), Zhang W(2,)(3), Liu F(4), Luo F(5,)(6).

Author information: 
(1)School of Mathematics and Statistics, Wuhan University, Wuhan, 430072, China. 
(2)State Key Lab of Software Engineering, Wuhan University, Wuhan, 430072, China.
zhangwen@whu.edu.cn. (3)School of Computer, Wuhan University, Wuhan, 430072,
China. zhangwen@whu.edu.cn. (4)International School of Software, Wuhan
University, Wuhan, 430072, China. (5)State Key Lab of Software Engineering, Wuhan
University, Wuhan, 430072, China. (6)School of Computer, Wuhan University, Wuhan,
430072, China.

BACKGROUND: Predicting piwi-interacting RNA (piRNA) is an important topic in the 
small non-coding RNAs, which provides clues for understanding the generation
mechanism of gamete. To the best of our knowledge, several machine learning
approaches have been proposed for the piRNA prediction, but there is still room
for improvements.
RESULTS: In this paper, we develop a genetic algorithm-based weighted ensemble
method for predicting transposon-derived piRNAs. We construct datasets for three 
species: Human, Mouse and Drosophila. For each species, we compile the balanced
dataset and imbalanced dataset, and thus obtain six datasets to build and
evaluate prediction models. In the computational experiments, the genetic
algorithm-based weighted ensemble method achieves 10-fold cross validation AUC of
0.932, 0.937 and 0.995 on the balanced Human dataset, Mouse dataset and
Drosophila dataset, respectively, and achieves AUC of 0.935, 0.939 and 0.996 on
the imbalanced datasets of three species. Further, we use the prediction models
trained on the Mouse dataset to identify piRNAs of other species, and the models 
demonstrate the good performances in the cross-species prediction.
CONCLUSIONS: Compared with other state-of-the-art methods, our method can lead to
better performances. In conclusion, the proposed method is promising for the
transposon-derived piRNA prediction. The source codes and datasets are available 
in https://github.com/zw9977129/piRNAPredictor .

DOI: 10.1186/s12859-016-1206-3 
PMCID: PMC5006569
PMID: 27578422  [PubMed - in process]


335. Nucleic Acids Res. 2016 Dec 15;44(22):e161. Epub 2016 Aug 30.

RNA2DNAlign: nucleotide resolution allele asymmetries through quantitative
assessment of RNA and DNA paired sequencing data.

Movassagh M(1,)(2), Alomran N(1,)(3), Mudvari P(1), Dede M(1), Dede C(1), Kowsari
K(1,)(4), Restrepo P(1), Cauley E(5), Bahl S(5), Li M(1,)(3), Waterhouse W(1),
Tsaneva-Atanasova K(6), Edwards N(3), Horvath A(7,)(5).

Author information: 
(1)McCormick Genomics and Proteomics Center, Department of Biochemistry and
Molecular Medicine, The George Washington University, Washington, DC 20037, USA. 
(2)University of Massachusetts Medical School, Graduate School of Biomedical
Sciences, Program in Bioinformatics and Integrative Biology, Worcester, MA 01605,
USA. (3)Department of Biochemistry and Molecular & Cellular Biology, Georgetown
University, Washington, DC 20057, USA. (4)Department of Computer Science, School 
of Engineering and applied Science, The George Washington University, Washington,
DC 20037, USA. (5)Department of Pharmacology and Physiology, The George
Washington University, Washington, DC 20037, USA. (6)Department of Mathematics,
College of Engineering, Mathematics and Physical Sciences & EPSRC Centre for
Predictive Modelling in Healthcare, University of Exeter, Exeter, EX4 4QJ, UK.
(7)McCormick Genomics and Proteomics Center, Department of Biochemistry and
Molecular Medicine, The George Washington University, Washington, DC 20037, USA
horvatha@gwu.edu.

We introduce RNA2DNAlign, a computational framework for quantitative assessment
of allele counts across paired RNA and DNA sequencing datasets. RNA2DNAlign is
based on quantitation of the relative abundance of variant and reference read
counts, followed by binomial tests for genotype and allelic status at SNV
positions between compatible sequences. RNA2DNAlign detects positions with
differential allele distribution, suggesting asymmetries due to
regulatory/structural events. Based on the type of asymmetry, RNA2DNAlign
outlines positions likely to be implicated in RNA editing, allele-specific
expression or loss, somatic mutagenesis or loss-of-heterozygosity (the first
three also in a tumor-specific setting). We applied RNA2DNAlign on 360 matching
normal and tumor exomes and transcriptomes from 90 breast cancer patients from
TCGA. Under high-confidence settings, RNA2DNAlign identified 2038 distinct SNV
sites associated with one of the aforementioned asymetries, the majority of which
have not been linked to functionality before. The performance assessment shows
very high specificity and sensitivity, due to the corroboration of signals across
multiple matching datasets. RNA2DNAlign is freely available from
http://github.com/HorvathLab/NGS as a self-contained binary package for 64-bit
Linux systems.

© The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkw757 
PMCID: PMC5159535
PMID: 27576531  [PubMed - in process]


336. AMIA Jt Summits Transl Sci Proc. 2016 Jul 20;2016:88-97. eCollection 2016.

A Quantitative and Qualitative Evaluation of Sentence Boundary Detection for the 
Clinical Domain.

Griffis D(1), Shivade C(2), Fosler-Lussier E(2), Lai AM(3).

Author information: 
(1)Department of Computer Science and Engineering,; National Institutes of
Health, Rehabilitation Medicine Department, Mark O. Hatfield Clinical Research
Center, Bethesda, MD. (2)Department of Computer Science and Engineering.
(3)Department of Computer Science and Engineering,; Department of Biomedical
Informatics, The Ohio State University, Columbus, OH.; National Institutes of
Health, Rehabilitation Medicine Department, Mark O. Hatfield Clinical Research
Center, Bethesda, MD.

Sentence boundary detection (SBD) is a critical preprocessing task for many
natural language processing (NLP) applications. However, there has been little
work on evaluating how well existing methods for SBD perform in the clinical
domain. We evaluate five popular off-the-shelf NLP toolkits on the task of SBD in
various kinds of text using a diverse set of corpora, including the GENIA corpus 
of biomedical abstracts, a corpus of clinical notes used in the 2010 i2b2 shared 
task, and two general-domain corpora (the British National Corpus and
Switchboard). We find that, with the exception of the cTAKES system, the toolkits
we evaluate perform noticeably worse on clinical text than on general-domain
text. We identify and discuss major classes of errors, and suggest directions for
future work to improve SBD methods in the clinical domain. We also make the code 
used for SBD evaluation in this paper available for download at
http://github.com/drgriffis/SBD-Evaluation.


PMCID: PMC5001746
PMID: 27570656  [PubMed]


337. J Cheminform. 2016 Aug 26;8(1):42. doi: 10.1186/s13321-016-0155-1. eCollection
2016.

Molmil: a molecular viewer for the PDB and beyond.

Bekker GJ(1), Nakamura H(2), Kinjo AR(2).

Author information: 
(1)Laboratory of Protein Informatics, Institute for Protein Research, Osaka
University, 3-2 Yamadaoka, Suita, Osaka 565-0871 Japan ; Graduate School of
Frontier Biosciences, Osaka University, Suita, Osaka 565-0871 Japan.
(2)Laboratory of Protein Informatics, Institute for Protein Research, Osaka
University, 3-2 Yamadaoka, Suita, Osaka 565-0871 Japan.

We have developed a new platform-independent web-based molecular viewer using
JavaScript and WebGL. The molecular viewer, Molmil, has been integrated into
several services offered by Protein Data Bank Japan and can be easily extended
with new functionality by third party developers. Furthermore, the viewer can be 
used to load files in various formats from the user's local hard drive without
uploading the data to a server. Molmil is available for all platforms supporting 
WebGL (e.g. Windows, Linux, iOS, Android) from http://gjbekker.github.io/molmil/.
The source code is available at http://github.com/gjbekker/molmil under the
LGPLv3 licence.

DOI: 10.1186/s13321-016-0155-1 
PMCID: PMC5002144
PMID: 27570544  [PubMed]


338. PLoS One. 2016 Aug 25;11(8):e0161879. doi: 10.1371/journal.pone.0161879.
eCollection 2016.

DockQ: A Quality Measure for Protein-Protein Docking Models.

Basu S(1), Wallner B(1,)(2).

Author information: 
(1)Bioinformatics Division, Department of Physics, Chemistry and Biology,
Linköping University, Linköping, Sweden. (2)Swedish e-Science Research Center,
Linköping University, Linköping, Sweden.

The state-of-the-art to assess the structural quality of docking models is
currently based on three related yet independent quality measures: Fnat, LRMS,
and iRMS as proposed and standardized by CAPRI. These quality measures quantify
different aspects of the quality of a particular docking model and need to be
viewed together to reveal the true quality, e.g. a model with relatively poor
LRMS (>10Å) might still qualify as 'acceptable' with a descent Fnat (>0.50) and
iRMS (<3.0Å). This is also the reason why the so called CAPRI criteria for
assessing the quality of docking models is defined by applying various ad-hoc
cutoffs on these measures to classify a docking model into the four classes:
Incorrect, Acceptable, Medium, or High quality. This classification has been
useful in CAPRI, but since models are grouped in only four bins it is also rather
limiting, making it difficult to rank models, correlate with scoring functions or
use it as target function in machine learning algorithms. Here, we present DockQ,
a continuous protein-protein docking model quality measure derived by combining
Fnat, LRMS, and iRMS to a single score in the range [0, 1] that can be used to
assess the quality of protein docking models. By using DockQ on CAPRI models it
is possible to almost completely reproduce the original CAPRI classification into
Incorrect, Acceptable, Medium and High quality. An average PPV of 94% at 90%
Recall demonstrating that there is no need to apply predefined ad-hoc cutoffs to 
classify docking models. Since DockQ recapitulates the CAPRI classification
almost perfectly, it can be viewed as a higher resolution version of the CAPRI
classification, making it possible to estimate model quality in a more
quantitative way using Z-scores or sum of top ranked models, which has been so
valuable for the CASP community. The possibility to directly correlate a quality 
measure to a scoring function has been crucial for the development of scoring
functions for protein structure prediction, and DockQ should be useful in a
similar development in the protein docking field. DockQ is available at
http://github.com/bjornwallner/DockQ/.

DOI: 10.1371/journal.pone.0161879 
PMCID: PMC4999177
PMID: 27560519  [PubMed - in process]


339. Bioinformatics. 2016 Dec 15;32(24):3729-3734. Epub 2016 Aug 24.

Assembly-based inference of B-cell receptor repertoires from short read RNA
sequencing data with V'DJer.

Mose LE(1), Selitsky SR(1), Bixby LM(1,)(2), Marron DL(1), Iglesia MD(3), Serody 
JS(1,)(2,)(4), Perou CM(1,)(5), Vincent BG(1,)(2), Parker JS(1,)(6).

Author information: 
(1)Lineberger Comprehensive Cancer Center. (2)Division of Hematology/Oncology,
Department of Internal Medicine. (3)Curriculum in Genetics and Molecular Biology.
(4)Department of Microbiology/Immunology. (5)Departments of Genetics and
Pathology and Laboratory Medicine. (6)Departments of Genetics, University of
North Carolina at Chapel Hill, Chapel Hill, NC 27599, USA.

MOTIVATION: B-cell receptor (BCR) repertoire profiling is an important tool for
understanding the biology of diverse immunologic processes. Current methods for
analyzing adaptive immune receptor repertoires depend upon PCR amplification of
VDJ rearrangements followed by long read amplicon sequencing spanning the VDJ
junctions. While this approach has proven to be effective, it is frequently not
feasible due to cost or limited sample material. Additionally, there are many
existing datasets where short-read RNA sequencing data are available but PCR
amplified BCR data are not.
RESULTS: We present here V'DJer, an assembly-based method that reconstructs
adaptive immune receptor repertoires from short-read RNA sequencing data. This
method captures expressed BCR loci from a standard RNA-seq assay. We applied this
method to 473 Melanoma samples from The Cancer Genome Atlas and demonstrate
V'DJer's ability to accurately reconstruct BCR repertoires from short read
mRNA-seq data.
AVAILABILITY AND IMPLEMENTATION: V'DJer is implemented in C/C ++, freely
available for academic use and can be downloaded from Github:
https://github.com/mozack/vdjer CONTACT: benjamin_vincent@med.unc.edu or
parkerjs@email.unc.eduSupplementary information: Supplementary data are available
at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw526 
PMCID: PMC5167060
PMID: 27559159  [PubMed - in process]


340. Bioinformatics. 2016 Dec 15;32(24):3850-3851. Epub 2016 Aug 24.

AlmostSignificant: simplifying quality control of high-throughput sequencing
data.

Ward J(1), Cole C(1), Febrer M(2), Barton GJ(1).

Author information: 
(1)Division of Computational Biology, School of Life Sciences, University of
Dundee, Dundee, DD1 5EH, UK. (2)Molecular Medicine, School of Life Sciences,
University of Dundee, Dundee, DD1 5RH, UK.

MOTIVATION: The current generation of DNA sequencing technologies produce a large
amount of data quickly. All of these data need to pass some form of quality
control (QC) processing and checking before they can be used for any analysis.
The large number of samples that are run through Illumina sequencing machines
makes the process of QC an onerous and time-consuming task that requires multiple
pieces of information from several sources.
RESULTS: AlmostSignificant is an open-source platform for aggregating multiple
sources of quality metrics as well as run and sample meta-data associated with
DNA sequencing runs from Illumina sequencing machines. AlmostSignificant is a
graphical platform to streamline the QC of DNA sequencing data, to store these
data for future reference together with extra meta-data associated with the
sequencing runs not typically retained. This simplifies the challenge of
monitoring the volume of data produced by Illumina sequencers. AlmostSignificant 
has been used to track the quality of over 80 sequencing runs covering over 2500 
samples produced over the last three years.
AVAILABILITY AND IMPLEMENTATION: The code and documentation for AlmostSignificant
is freely available at https://github.com/bartongroup/AlmostSignificant CONTACTS:
c.cole@dundee.ac.uk or g.j.barton@dundee.ac.ukSupplementary information:
Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw559 
PMCID: PMC5167069
PMID: 27559158  [PubMed - in process]


341. Bioinformatics. 2016 Dec 15;32(24):3847-3849. Epub 2016 Aug 24.

PhenomeScape: a cytoscape app to identify differentially regulated sub-networks
using known disease associations.

Soul J(1), Dunn SL(1), Hardingham TE(1), Boot-Handford RP(1), Schwartz JM(1).

Author information: 
(1)Faculty of Biology, Medicine and Health, University of Manchester, Manchester 
M13 9PT, UK.

PhenomeScape is a Cytoscape app which provides easy access to the PhenomeExpress 
algorithm to interpret gene expression data. PhenomeExpress integrates protein
interaction networks with known phenotype to gene associations to find active
sub-networks enriched in differentially expressed genes. It also incorporates
cross-species phenotypes and associations to include results from animal models
of disease. With expression data imported into PhenomeScape, the user can quickly
generate and visualise interactive sub-networks. PhenomeScape thus enables
researchers to use prior knowledge of a disease to identify differentially
regulated sub-networks and to generate an overview of altered biologically
processes specific to that disease.AVAILABILITY AND IMPLEMENTATION: Freely
available for download at https://github.com/soulj/PhenomeScape CONTACT:
jamie.soul@postgrad.manchester.ac.uk or jean-marc.schwartz@manchester.ac.uk.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw545 
PMCID: PMC5167065
PMID: 27559157  [PubMed - in process]


342. Bioinformatics. 2016 Dec 15;32(24):3839-3841. Epub 2016 Aug 24.

Discoal: flexible coalescent simulations with selection.

Kern AD(1,)(2), Schrider DR(2).

Author information: 
(1)Department of Genetics. (2)Human Genetics Institute of New Jersey, Rutgers
University, Piscataway, NJ 08554, USA.

Here we describe discoal, a coalescent simulator able to generate population
samples that include selective sweeps in a feature-rich, flexible manner. discoal
can perform simulations conditioning on the fixation of an allele due to drift or
either hard or soft sweeps-even those occurring a large genetic distance away
from the simulated locus. discoal can simulate sweeps with recurrent mutation to 
the adaptive allele, recombination, and gene conversion, under non-equilibrium
demographic histories and without specifying an allele frequency trajectory in
advance.AVAILABILITY AND IMPLEMENTATION: discoal is implemented in the C
programming language. Source code is freely available on GitHub
(https://github.com/kern-lab/discoal) under a GNU General Public License.
CONTACT: kern@dls.rutgers.edu or dan.schrider@rutgers.eduSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw556 
PMCID: PMC5167068 [Available on 2017-12-15]
PMID: 27559153  [PubMed - in process]


343. BMC Genomics. 2016 Aug 22;17 Suppl 7:503. doi: 10.1186/s12864-016-2896-7.

Read-Split-Run: an improved bioinformatics pipeline for identification of
genome-wide non-canonical spliced regions using RNA-Seq data.

Bai Y(1,)(2), Kinne J(3), Donham B(3), Jiang F(3), Ding L(4), Hassler JR(5),
Kaufman RJ(5).

Author information: 
(1)Department of Biology, Terre Haute, USA. Yongsheng.Bai@indstate.edu. (2)The
Center for Genomic Advocacy, Indiana State University, 600 Chestnut Street, Terre
Haute, IN, 47809, USA. Yongsheng.Bai@indstate.edu. (3)Department of Mathematics
and Computer Science, Indiana State University, 200 North Seventh Street, Terre
Haute, IN, 47809, USA. (4)Department of Biology, Terre Haute, USA.
(5)Sanford-Burnham-Prebys Medical Discovery Institute, La Jolla, California,
92037, USA.

BACKGROUND: Most existing tools for detecting next-generation sequencing-based
splicing events focus on generic splicing events. Consequently, special types of 
non-canonical splicing events of short mRNA regions (IRE1α targeted) have not yet
been thoroughly addressed at a genome-wide level using bioinformatics approaches 
in conjunction with next-generation technologies. During endoplasmic reticulum
(ER) stress, the gene encoding the RNase Ire1α is known to splice out a short
26 nt region from the mRNA of the transcription factor Xbp1 non-canonically
within the cytosol. This causes an open reading frame-shift that induces
expression of many downstream genes in reaction to ER stress as part of the
unfolded protein response (UPR). We previously published an algorithm termed
"Read-Split-Walk" (RSW) to identify non-canonical splicing regions using RNA-Seq 
data and applied it to ER stress-induced Ire1α heterozygote and knockout mouse
embryonic fibroblast cell lines. In this study, we have developed an improved
algorithm "Read-Split-Run" (RSR) for detecting genome-wide Ire1α-targeted genes
with non-canonical spliced regions at a faster speed. We applied the RSR
algorithm using different combinations of several parameters to the previously
RSW tested mouse embryonic fibroblast cells (MEF) and the human Encyclopedia of
DNA Elements (ENCODE) RNA-Seq data. We also compared the performance of RSR with 
two other alternative splicing events identification tools (TopHat (Trapnell et
al., Bioinformatics 25:1105-1111, 2009) and Alt Event Finder (Zhou et al., BMC
Genomics 13:S10, 2012)) utilizing the context of the spliced Xbp1 mRNA as a
positive control in the data sets we identified it to be the top cleavage target 
present in Ire1α (+/-) but absent in Ire1α (-/-) MEF samples and this comparison 
was also extended to human ENCODE RNA-Seq data.
RESULTS: Proof of principle came in our results by the fact that the 26 nt
non-conventional splice site in Xbp1 was detected as the top hit by our new RSR
algorithm in heterozygote (Het) samples from both Thapsigargin (Tg) and
Dithiothreitol (Dtt) treated experiments but absent in the negative control Ire1α
knock-out (KO) samples. Applying different combinations of parameters to the
mouse MEF RNA-Seq data, we suggest a General Linear Model (GLM) for both Tg and
Dtt treated experiments. We also ran RSR for a human ENCODE RNA-Seq dataset and
identified 32,597 spliced regions for regular chromosomes. TopHat (Trapnell et
al., Bioinformatics 25:1105-1111, 2009) and Alt Event Finder (Zhou et al., BMC
Genomics 13:S10, 2012) identified 237,155 spliced junctions and 9,129 exon
skipping events (excluding chr14), respectively. Our Read-Split-Run algorithm
also outperformed others in the context of ranking Xbp1 gene as the top cleavage 
target present in Ire1α (+/-) but absent in Ire1α (-/-) MEF samples. The RSR
package including source codes is available at http://bioinf1.indstate.edu/RSR
and its pipeline source codes are also freely available at
https://github.com/xuric/read-split-run for academic use.
CONCLUSIONS: Our new RSR algorithm has the capability of processing massive
amounts of human ENCODE RNA-Seq data for identifying novel splice junction sites 
at a genome-wide level in a much more efficient manner when compared to the
previous RSW algorithm. Our proposed model can also predict the number of spliced
regions under any combinations of parameters. Our pipeline can detect novel
spliced sites for other species using RNA-Seq data generated under similar
conditions.

DOI: 10.1186/s12864-016-2896-7 
PMCID: PMC5001233
PMID: 27556805  [PubMed - in process]


344. BMC Genomics. 2016 Aug 18;17 Suppl 4:543. doi: 10.1186/s12864-016-2792-1.

EpiTracer - an algorithm for identifying epicenters in condition-specific
biological networks.

Sambaturu N(1), Mishra M(2), Chandra N(3,)(4).

Author information: 
(1)IISc Mathematics Initiative, Indian Institute of Science, Bangalore, 560012,
India. (2)Department of Biochemistry, Indian Institute of Science, Bangalore,
560012, India. (3)IISc Mathematics Initiative, Indian Institute of Science,
Bangalore, 560012, India. nchandra@biochem.iisc.ernet.in. (4)Department of
Biochemistry, Indian Institute of Science, Bangalore, 560012, India.
nchandra@biochem.iisc.ernet.in.

BACKGROUND: In biological systems, diseases are caused by small perturbations in 
a complex network of interactions between proteins. Perturbations typically
affect only a small number of proteins, which go on to disturb a larger part of
the network. To counteract this, a stress-response is launched, resulting in a
complex pattern of variations in the cell. Identifying the key players involved
in either spreading the perturbation or responding to it can give us important
insights.
RESULTS: We develop an algorithm, EpiTracer, which identifies the key proteins,
or epicenters, from which a large number of changes in the protein-protein
interaction (PPI) network ripple out. We propose a new centrality measure, ripple
centrality, which measures how effectively a change at a particular node can
ripple across the network by identifying highest activity paths specific to the
condition of interest, obtained by mapping gene expression profiles to the PPI
network. We demonstrate the algorithm using an overexpression study and a
knockdown study. In the overexpression study, the gene that was overexpressed
(PARK2) was highlighted as the most important epicenter specific to the
perturbation. The other top-ranked epicenters were involved in either supporting 
the activity of PARK2, or counteracting it. Also, 5 of the identified epicenters 
showed no significant differential expression, showing that our method can find
information which simple differential expression analysis cannot. In the second
dataset (SP1 knockdown), alternative regulators of SP1 targets were highlighted
as epicenters. Also, the gene that was knocked down (SP1) was picked up as an
epicenter specific to the control condition. Sensitivity analysis showed that the
genes identified as epicenters remain largely unaffected by small changes.
CONCLUSIONS: We develop an algorithm, EpiTracer, to find epicenters in
condition-specific biological networks, given the PPI network and gene expression
levels. EpiTracer includes programs which can extract the immediate influence
zone of epicenters and provide a summary of dysregulated genes, facilitating
quick biological analysis. We demonstrate its efficacy on two datasets with
differing characteristics, highlighting its general applicability. We also show
that EpiTracer is not sensitive to minor changes in the network. The source code 
for EpiTracer is provided at Github ( https://github.com/narmada26/EpiTracer ).

DOI: 10.1186/s12864-016-2792-1 
PMCID: PMC5001201
PMID: 27556637  [PubMed - in process]


345. Bioinformatics. 2016 Dec 15;32(24):3833-3835. Epub 2016 Aug 22.

Integrating genomic information with protein sequence and 3D atomic level
structure at the RCSB protein data bank.

Prlić A(1), Kalro T(1), Bhattacharya R(2), Christie C(1), Burley SK(1,)(3), Rose 
PW(1).

Author information: 
(1)RCSB Protein Data Bank, University of California San Diego, San Diego
Supercomputer Center, La Jolla, CA 92093, USA. (2)Bioinformatics and Medical
Informatics, San Diego State University, San Diego, CA 92182, USA. (3)RCSB
Protein Data Bank, Department of Chemistry and Chemical Biology, Center for
Integrative Proteomics Research, Institute for Quantitative Biomedicine, and
Rutgers Cancer Institute of New Jersey, Rutgers, The State University of New
Jersey, Piscataway, NJ 08854, USA.

The Protein Data Bank (PDB) now contains more than 120,000 three-dimensional (3D)
structures of biological macromolecules. To allow an interpretation of how PDB
data relates to other publicly available annotations, we developed a novel data
integration platform that maps 3D structural information across various datasets.
This integration bridges from the human genome across protein sequence to 3D
structure space. We developed novel software solutions for data management and
visualization, while incorporating new libraries for web-based visualization
using SVG graphics.AVAILABILITY AND IMPLEMENTATION: The new views are available
from http://www.rcsb.org and software is available from https://github.com/rcsb/.
CONTACT: andreas.prlic@rcsb.orgSupplementary information: Supplementary data are 
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw547 
PMCID: PMC5167066
PMID: 27551105  [PubMed - in process]


346. J Comput Aided Mol Des. 2016 Aug;30(8):619-24. doi: 10.1007/s10822-016-9944-x.
Epub 2016 Aug 22.

Azahar: a PyMOL plugin for construction, visualization and analysis of glycan
molecules.

Arroyuelo A(1), Vila JA(2), Martin OA(3).

Author information: 
(1)Instituto de Matemática Aplicada San Luis, IMASL, Universidad Nacional de San 
Luis and CONICET, D5700HHW, San Luis, Argentina. aarroyuelo@unsl.edu.ar.
(2)Instituto de Matemática Aplicada San Luis, IMASL, Universidad Nacional de San 
Luis and CONICET, D5700HHW, San Luis, Argentina. (3)Instituto de Matemática
Aplicada San Luis, IMASL, Universidad Nacional de San Luis and CONICET, D5700HHW,
San Luis, Argentina. omarti@unsl.edu.ar.

Glycans are key molecules in many physiological and pathological processes. As
with other molecules, like proteins, visualization of the 3D structures of
glycans adds valuable information for understanding their biological function.
Hence, here we introduce Azahar, a computing environment for the creation,
visualization and analysis of glycan molecules. Azahar is implemented in Python
and works as a plugin for the well known PyMOL package (Schrodinger in The PyMOL 
molecular graphics system, version 1.3r1, 2010). Besides the already available
visualization and analysis options provided by PyMOL, Azahar includes 3
cartoon-like representations and tools for 3D structure caracterization such as a
comformational search using a Monte Carlo with minimization routine and also
tools to analyse single glycans or trajectories/ensembles including the
calculation of radius of gyration, Ramachandran plots and hydrogen bonds. Azahar 
is freely available to download from http://www.pymolwiki.org/index.php/Azahar
and the source code is available at https://github.com/agustinaarroyuelo/Azahar .

DOI: 10.1007/s10822-016-9944-x 
PMID: 27549814  [PubMed - in process]


347. Biometrics. 2016 Aug 22. doi: 10.1111/biom.12577. [Epub ahead of print]

A Bayesian hierarchical model for prediction of latent health states from
multiple data sources with application to active surveillance of prostate cancer.

Coley RY(1), Fisher AJ(1), Mamawala M(2), Carter HB(2,)(3), Pienta KJ(2,)(3,)(4),
Zeger SL(1).

Author information: 
(1)Department of Biostatistics, Johns Hopkins University, Baltimore, Maryland
21205, U.S.A. (2)James Buchanan Brady Urological Institute, Johns Hopkins Medical
Institutions, Baltimore, Maryland 21287, U.S.A. (3)Department of Oncology, Johns 
Hopkins Medical Institutions, Baltimore, Maryland 21287, U.S.A. (4)Department of 
Pharmacology, Johns Hopkins Medical Institutions, Baltimore, Maryland 21287.

In this article, we present a Bayesian hierarchical model for predicting a latent
health state from longitudinal clinical measurements. Model development is
motivated by the need to integrate multiple sources of data to improve clinical
decisions about whether to remove or irradiate a patient's prostate cancer.
Existing modeling approaches are extended to accommodate measurement error in
cancer state determinations based on biopsied tissue, clinical measurements
possibly not missing at random, and informative partial observation of the true
state. The proposed model enables estimation of whether an individual's
underlying prostate cancer is aggressive, requiring surgery and/or radiation, or 
indolent, permitting continued surveillance. These individualized predictions can
then be communicated to clinicians and patients to inform decision-making. We
demonstrate the model with data from a cohort of low-risk prostate cancer
patients at Johns Hopkins University and assess predictive accuracy among a
subset for whom true cancer state is observed. Simulation studies confirm model
performance and explore the impact of adjusting for informative missingness on
true state predictions. R code is provided in an online supplement and at
http://github.com/rycoley/prediction-prostate-surveillance.

© 2016, The International Biometric Society.

DOI: 10.1111/biom.12577 
PMID: 27548645  [PubMed - as supplied by publisher]


348. PeerJ. 2016 Jul 21;4:e2211. doi: 10.7717/peerj.2211. eCollection 2016.

Computer-assisted initial diagnosis of rare diseases.

Alves R(1), Piñol M(2), Vilaplana J(3), Teixidó I(3), Cruz J(1), Comas J(4),
Vilaprinyo E(1), Sorribas A(1), Solsona F(3).

Author information: 
(1)Departament de Cienciès Mèdiques Bàsiques, Universitat de Lleida, Lleida,
Catalunya, Spain; IRBLleida, Lleida, Catalunya, Spain. (2)Departament
d'Informàtica i Enginyeria Industrial, Universitat de Lleida , Lleida , Catalunya
, Spain. (3)Departament d'Informàtica i Enginyeria Industrial, Universitat de
Lleida, Lleida, Catalunya, Spain; INSPIRES, Lleida, Catalunya, Spain.
(4)Departament de Cienciès Mèdiques Bàsiques, Universitat de Lleida, Lleida,
Catalunya, Spain; IRBLleida, Lleida, Catalunya, Spain; Departament d'Informàtica 
i Enginyeria Industrial, Universitat de Lleida, Lleida, Catalunya, Spain;
INSPIRES, Lleida, Catalunya, Spain.

Introduction. Most documented rare diseases have genetic origin. Because of their
low individual frequency, an initial diagnosis based on phenotypic symptoms is
not always easy, as practitioners might never have been exposed to patients
suffering from the relevant disease. It is thus important to develop tools that
facilitate symptom-based initial diagnosis of rare diseases by clinicians. In
this work we aimed at developing a computational approach to aid in that initial 
diagnosis. We also aimed at implementing this approach in a user friendly web
prototype. We call this tool Rare Disease Discovery. Finally, we also aimed at
testing the performance of the prototype. Methods. Rare Disease Discovery uses
the publicly available ORPHANET data set of association between rare diseases and
their symptoms to automatically predict the most likely rare diseases based on a 
patient's symptoms. We apply the method to retrospectively diagnose a cohort of
187 rare disease patients with confirmed diagnosis. Subsequently we test the
precision, sensitivity, and global performance of the system under different
scenarios by running large scale Monte Carlo simulations. All settings account
for situations where absent and/or unrelated symptoms are considered in the
diagnosis. Results. We find that this expert system has high diagnostic precision
(≥80%) and sensitivity (≥99%), and is robust to both absent and unrelated
symptoms. Discussion. The Rare Disease Discovery prediction engine appears to
provide a fast and robust method for initial assisted differential diagnosis of
rare diseases. We coupled this engine with a user-friendly web interface and it
can be freely accessed at http://disease-discovery.udl.cat/. The code and most
current database for the whole project can be downloaded from
https://github.com/Wrrzag/DiseaseDiscovery/tree/no_classifiers.

DOI: 10.7717/peerj.2211 
PMCID: PMC4963223
PMID: 27547534  [PubMed]


349. PeerJ. 2016 Jul 19;4:e2209. doi: 10.7717/peerj.2209. eCollection 2016.

fluff: exploratory analysis and visualization of high-throughput sequencing data.

Georgiou G(1), van Heeringen SJ(1).

Author information: 
(1)Radboud University, Molecular Developmental Biology , Nijmegen , The
Netherlands.

In this article we describe fluff, a software package that allows for simple
exploration, clustering and visualization of high-throughput sequencing data
mapped to a reference genome. The package contains three command-line tools to
generate publication-quality figures in an uncomplicated manner using sensible
defaults. Genome-wide data can be aggregated, clustered and visualized in a
heatmap, according to different clustering methods. This includes a predefined
setting to identify dynamic clusters between different conditions or
developmental stages. Alternatively, clustered data can be visualized in a
bandplot. Finally, fluff includes a tool to generate genomic profiles. As
command-line tools, the fluff programs can easily be integrated into standard
analysis pipelines. The installation is straightforward and documentation is
available at http://fluff.readthedocs.org. Availability. fluff is implemented in 
Python and runs on Linux. The source code is freely available for download at
https://github.com/simonvh/fluff.

DOI: 10.7717/peerj.2209 
PMCID: PMC4957989
PMID: 27547532  [PubMed]


350. Genetics. 2016 Oct;204(2):723-735. Epub 2016 Aug 19.

Estimating the Effective Population Size from Temporal Allele Frequency Changes
in Experimental Evolution.

Jónás Á(1), Taus T(1), Kosiol C(2), Schlötterer C(2), Futschik A(3).

Author information: 
(1)*Vienna Graduate School of Population Genetics, 1210 Vienna, Austria †Institut
für Populationsgenetik, Vetmeduni Vienna, 1210 Vienna, Austria. (2)†Institut für 
Populationsgenetik, Vetmeduni Vienna, 1210 Vienna, Austria. (3)†Institut für
Populationsgenetik, Vetmeduni Vienna, 1210 Vienna, Austria ‡Department of Applied
Statistics, Johannes Kepler Universität Linz, 4040 Linz, Austria
andreas.futschik@jku.at.

The effective population size ([Formula: see text]) is a major factor determining
allele frequency changes in natural and experimental populations. Temporal
methods provide a powerful and simple approach to estimate short-term [Formula:
see text] They use allele frequency shifts between temporal samples to calculate 
the standardized variance, which is directly related to [Formula: see text] Here 
we focus on experimental evolution studies that often rely on repeated sequencing
of samples in pools (Pool-seq). Pool-seq is cost-effective and often outperforms 
individual-based sequencing in estimating allele frequencies, but it is
associated with atypical sampling properties: Additional to sampling individuals,
sequencing DNA in pools leads to a second round of sampling, which increases the 
variance of allele frequency estimates. We propose a new estimator of [Formula:
see text] which relies on allele frequency changes in temporal data and corrects 
for the variance in both sampling steps. In simulations, we obtain accurate
[Formula: see text] estimates, as long as the drift variance is not too small
compared to the sampling and sequencing variance. In addition to genome-wide
[Formula: see text] estimates, we extend our method using a recursive
partitioning approach to estimate [Formula: see text] locally along the
chromosome. Since the type I error is controlled, our method permits the
identification of genomic regions that differ significantly in their [Formula:
see text] estimates. We present an application to Pool-seq data from experimental
evolution with Drosophila and provide recommendations for whole-genome data. The 
estimator is computationally efficient and available as an R package at
https://github.com/ThomasTaus/Nest.

Copyright © 2016 Jónás et al.

DOI: 10.1534/genetics.116.191197 
PMCID: PMC5068858
PMID: 27542959  [PubMed - in process]


351. Database (Oxford). 2016 Aug 19;2016. pii: baw120. doi: 10.1093/database/baw120.
Print 2016.

The Markyt visualisation, prediction and benchmark platform for chemical and gene
entity recognition at BioCreative/CHEMDNER challenge.

Pérez-Pérez M(1), Pérez-Rodríguez G(1), Rabal O(2), Vazquez M(3), Oyarzabal J(2),
Fdez-Riverola F(1), Valencia A(3), Krallinger M(3), Lourenço A(4).

Author information: 
(1)ESEI - Department of Computer Science, University of Vigo, Ourense, Spain.
(2)Small Molecule Discovery Platform, Molecular Therapeutics Program, Center for 
Applied Medical Research (CIMA), University of Navarra, Pamplona, Spain.
(3)Structural Computational Biology Group, Structural Biology and BioComputing
Programme, Spanish National Cancer Research Centre, Madrid, Spain. (4)ESEI -
Department of Computer Science, University of Vigo, Ourense, Spain Small Molecule
Discovery Platform, Molecular Therapeutics Program, Center for Applied Medical
Research (CIMA), University of Navarra, Pamplona, Spain analia@uvigo.es.

Biomedical text mining methods and technologies have improved significantly in
the last decade. Considerable efforts have been invested in understanding the
main challenges of biomedical literature retrieval and extraction and proposing
solutions to problems of practical interest. Most notably, community-oriented
initiatives such as the BioCreative challenge have enabled controlled
environments for the comparison of automatic systems while pursuing practical
biomedical tasks. Under this scenario, the present work describes the Markyt
Web-based document curation platform, which has been implemented to support the
visualisation, prediction and benchmark of chemical and gene mention annotations 
at BioCreative/CHEMDNER challenge. Creating this platform is an important step
for the systematic and public evaluation of automatic prediction systems and the 
reusability of the knowledge compiled for the challenge. Markyt was not only
critical to support the manual annotation and annotation revision process but
also facilitated the comparative visualisation of automated results against the
manually generated Gold Standard annotations and comparative assessment of
generated results. We expect that future biomedical text mining challenges and
the text mining community may benefit from the Markyt platform to better explore 
and interpret annotations and improve automatic system predictions.Database URL: 
http://www.markyt.org, https://github.com/sing-group/Markyt.

© The Author(s) 2016. Published by Oxford University Press.

DOI: 10.1093/database/baw120 
PMCID: PMC5001550
PMID: 27542845  [PubMed - in process]


352. Springerplus. 2016 Aug 5;5(1):1268. doi: 10.1186/s40064-016-2897-7. eCollection
2016.

Influence analysis of Github repositories.

Hu Y(1), Zhang J(1), Bai X(1), Yu S(1), Yang Z(1).

Author information: 
(1)School of Software, Dalian University of Technology, Development Zone, Dalian,
116620 China.

With the support of cloud computing techniques, social coding platforms have
changed the style of software development. Github is now the most popular social 
coding platform and project hosting service. Software developers of various
levels keep entering Github, and use Github to save their public and private
software projects. The large amounts of software developers and software
repositories on Github are posing new challenges to the world of software
engineering. This paper tries to tackle one of the important problems: analyzing 
the importance and influence of Github repositories. We proposed a HITS based
influence analysis on graphs that represent the star relationship between Github 
users and repositories. A weighted version of HITS is applied to the overall star
graph, and generates a different set of top influential repositories other than
the results from standard version of HITS algorithm. We also conduct the
influential analysis on per-month star graph, and study the monthly influence
ranking of top repositories.

DOI: 10.1186/s40064-016-2897-7 
PMCID: PMC4975729
PMID: 27540501  [PubMed]


353. Bioinformatics. 2016 Dec 15;32(24):3717-3728. Epub 2016 Aug 18.

A new correlation clustering method for cancer mutation analysis.

Hou JP(1,)(2), Emad A(3,)(4), Puleo GJ(3,)(4), Ma J(1,)(5,)(6), Milenkovic
O(3,)(4).

Author information: 
(1)Department of Bioengineering, University of Illinois at Urbana-Champaign,
Urbana, IL 61801, USA. (2)Medical Scholars Program, University of Illinois at
Urbana-Champaign, Urbana, IL 61801, USA. (3)Department of Electrical and Computer
Engineering, University of Illinois at Urbana-Champaign, Urbana, IL 61801, USA.
(4)Coordinated Science Lab, University of Illinois at Urbana-Champaign, Urbana,
IL 61801, USA. (5)Carl R. Woese Institute for Genomic Biology, University of
Illinois at Urbana-Champaign, Urbana, IL 61801, USA. (6)Computational Biology
Department, School of Computer Science, Carnegie Mellon University, Pittsburgh,
PA 15213, USA.

MOTIVATION: Cancer genomes exhibit a large number of different alterations that
affect many genes in a diverse manner. An improved understanding of the
generative mechanisms behind the mutation rules and their influence on gene
community behavior is of great importance for the study of cancer.
RESULTS: To expand our capability to analyze combinatorial patterns of cancer
alterations, we developed a rigorous methodology for cancer mutation pattern
discovery based on a new, constrained form of correlation clustering. Our new
algorithm, named C(3) (Cancer Correlation Clustering), leverages mutual
exclusivity of mutations, patient coverage and driver network concentration
principles. To test C(3), we performed a detailed analysis on TCGA breast cancer 
and glioblastoma data and showed that our algorithm outperforms the
state-of-the-art CoMEt method in terms of discovering mutually exclusive gene
modules and identifying biologically relevant driver genes. The proposed agnostic
clustering method represents a unique tool for efficient and reliable
identification of mutation patterns and driver pathways in large-scale cancer
genomics studies, and it may also be used for other clustering problems on
biological graphs.
AVAILABILITY AND IMPLEMENTATION: The source code for the C(3) method can be found
at https://github.com/jackhou2/C3 CONTACTS: jianma@cs.cmu.edu or
milenkov@illinois.eduSupplementary information: Supplementary data are available 
at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw546 
PMID: 27540270  [PubMed - in process]


354. Bioinformatics. 2016 Dec 15;32(24):3782-3789. Epub 2016 Aug 18.

Predicting synergistic effects between compounds through their structural
similarity and effects on transcriptomes.

Liu Y(1), Zhao H(1,)(2).

Author information: 
(1)Department of Biostatistics, School of Public Health, Yale University New
Haven, CT, 06520, USA. (2)Program of Computational Biology and Bioinformatics,
CT0610, Yale University, New Haven, CT, 06511, USA.

MOTIVATION: Combinatorial therapies have been under intensive research for cancer
treatment. However, due to the large number of possible combinations among
candidate compounds, exhaustive screening is prohibitive. Hence, it is important 
to develop computational tools that can predict compound combination effects,
prioritize combinations and limit the search space to facilitate and accelerate
the development of combinatorial therapies.
RESULTS: In this manuscript we consider the NCI-DREAM Drug Synergy Prediction
Challenge dataset to identify features informative about combination effects.
Through systematic exploration of differential expression profiles after single
compound treatments and comparison of molecular structures of compounds, we found
that synergistic levels of combinations are statistically significantly
associated with compounds' dissimilarity in structure and similarity in induced
gene expression changes. These two types of features offer complementary
information in predicting experimentally measured combination effects of compound
pairs. Our findings offer insights on the mechanisms underlying different
combination effects and may help prioritize promising combinations in the very
large search space.
AVAILABILITY AND IMPLEMENTATION: The R code for the analysis is available on
https://github.com/YiyiLiu1/DrugCombination CONTACT:
hongyu.zhao@yale.eduSupplementary information: Supplementary data are available
at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw509 
PMID: 27540269  [PubMed - in process]


355. Bioinformatics. 2016 Dec 15;32(24):3836-3838. Epub 2016 Aug 18.

BatchQC: interactive software for evaluating sample and batch effects in genomic 
data.

Manimaran S(1,)(2), Selby HM(3), Okrah K(4), Ruberman C(5), Leek JT(5),
Quackenbush J(6,)(7), Haibe-Kains B(8,)(9,)(10), Bravo HC(11), Johnson
WE(1,)(2,)(3).

Author information: 
(1)Department of Biostatistics, Boston University, Boston, MA. (2)Division of
Computational Biomedicine, Boston University School of Medicine, Boston, MA.
(3)Bioinformatics Program, Boston University, Boston, MA. (4)gRED Oncology
Biostatistics, Genentech, South San Francisco, CA. (5)Department of
Biostatistics, Johns Hopkins Bloomberg School of Public Health, Baltimore, MD.
(6)Department of Biostatistics and Computational Biology, Dana-Farber Cancer
Institute, Boston, MA. (7)Department of Biostatistics, Harvard T.H. Chan School
of Public Health, Boston, MA. (8)Departments of Medical Biophysics and Computer
Science, University of Toronto, Toronto, Ontario, Canada. (9)Princess Margaret
Cancer Centre, University Health NetworkToronto, Ontario, Canada. (10)Ontario
Institute of Cancer Research, Toronto, Ontario, Canada. (11)Center for
Bioinformatics and Computational Biology, University of Maryland, College Park,
MD.

Sequencing and microarray samples often are collected or processed in multiple
batches or at different times. This often produces technical biases that can lead
to incorrect results in the downstream analysis. There are several existing batch
adjustment tools for '-omics' data, but they do not indicate a priori whether
adjustment needs to be conducted or how correction should be applied. We present 
a software pipeline, BatchQC, which addresses these issues using interactive
visualizations and statistics that evaluate the impact of batch effects in a
genomic dataset. BatchQC can also apply existing adjustment tools and allow users
to evaluate their benefits interactively. We used the BatchQC pipeline on both
simulated and real data to demonstrate the effectiveness of this software
toolkit.AVAILABILITY AND IMPLEMENTATION: BatchQC is available through
Bioconductor: http://bioconductor.org/packages/BatchQC and GitHub:
https://github.com/mani2012/BatchQC CONTACT: wej@bu.eduSupplementary information:
Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw538 
PMCID: PMC5167063
PMID: 27540268  [PubMed - in process]


356. Bioinformatics. 2016 Dec 15;32(24):3709-3716. Epub 2016 Aug 18.

CSAM: Compressed SAM format.

Cánovas R(1,)(2), Moffat A(2), Turpin A(2).

Author information: 
(1)L.I.R.M.M. and Institut Biologie Computationnelle, Université de Montpellier, 
Montpellier Cedex 5, CNRS F-34392, France. (2)Department of Computing and
Information Systems, The University of Melbourne, Victoria 3010, Australia.

MOTIVATION: Next generation sequencing machines produce vast amounts of genomic
data. For the data to be useful, it is essential that it can be stored and
manipulated efficiently. This work responds to the combined challenge of
compressing genomic data, while providing fast access to regions of interest,
without necessitating decompression of whole files.
RESULTS: We describe CSAM (Compressed SAM format), a compression approach
offering lossless and lossy compression for SAM files. The structures and
techniques proposed are suitable for representing SAM files, as well as
supporting fast access to the compressed information. They generate more compact 
lossless representations than BAM, which is currently the preferred lossless
compressed SAM-equivalent format; and are self-contained, that is, they do not
depend on any external resources to compress or decompress SAM files.
AVAILABILITY AND IMPLEMENTATION: An implementation is available at
https://github.com/rcanovas/libCSAM CONTACT: canovas-ba@lirmm.frSupplementary
Information: Supplementary data is available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw543 
PMID: 27540265  [PubMed - in process]


357. Bioinformatics. 2016 Dec 15;32(24):3790-3797. Epub 2016 Aug 16.

Selective mutation accumulation: a computational model of the paternal age
effect.

Whelan EC(1), Nwala AC(2), Osgood C(1), Olariu S(2).

Author information: 
(1)Department of Biology, Old Dominion University, Norfolk, VA, USA.
(2)Department of Computer Science, Old Dominion University, Norfolk, VA 23529,
USA.

MOTIVATION: As the mean age of parenthood grows, the effect of parental age on
genetic disease and child health becomes ever more important. A number of
autosomal dominant disorders show a dramatic paternal age effect due to selfish
mutations: substitutions that grant spermatogonial stem cells (SSCs) a selective 
advantage in the testes of the father, but have a deleterious effect in
offspring. In this paper we present a computational technique to model the SSC
niche in order to examine the phenomenon and draw conclusions across different
genes and disorders.
RESULTS: We used a Markov chain to model the probabilities of mutation and
positive selection with cell divisions. The model was fitted to available data on
disease incidence and also mutation assays of sperm donors. Strength of selective
advantage is presented for a range of disorders including Apert's syndrome and
achondroplasia. Incidence of the diseases was predicted closely for most
disorders and was heavily influenced by the site-specific mutation rate and the
number of mutable alleles. The model also successfully predicted a stronger
selective advantage for more strongly activating gain-of-function mutations
within the same gene. Both positive selection and the rate of copy-error
mutations are important in adequately explaining the paternal age effect.
AVAILABILITY AND IMPLEMENTATION: C ++/R source codes and documentation including 
compilation instructions are available under GNU license at
https://github.com/anwala/NicheSimulation CONTACT: ewhel001@odu.eduSupplementary 
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw528 
PMID: 27531106  [PubMed - in process]


358. Bioinformatics. 2016 Dec 15;32(24):3735-3744. Epub 2016 Aug 16.

H-PoP and H-PoPG: heuristic partitioning algorithms for single individual
haplotyping of polyploids.

Xie M(1), Wu Q(2), Wang J(3), Jiang T(4,)(5).

Author information: 
(1)Key Laboratory of Internet of Things Technologies and Application, College of 
Physics and Information Science, Hunan Normal University, Changsha 410081, China.
(2)State Key Laboratory of Systematic and Evolutionary Botany, Institute of
Botany, Chinese Academy of Sciences, Beijing 100093, China. (3)School of
Information Science and Engineering, Central South University, Changsha 410083,
China. (4)Department of Computer Science and Engineering, University of
California, Riverside, CA 92521, USA. (5)MOE Key Lab of Bioinformatics and
Bioinformatics Division, TNLIST/Department of Computer Science and Technology,
Tsinghua University, Beijing, China.

MOTIVATION: Some economically important plants including wheat and cotton have
more than two copies of each chromosome. With the decreasing cost and increasing 
read length of next-generation sequencing technologies, reconstructing the
multiple haplotypes of a polyploid genome from its sequence reads becomes
practical. However, the computational challenge in polyploid haplotyping is much 
greater than that in diploid haplotyping, and there are few related methods.
RESULTS: This article models the polyploid haplotyping problem as an optimal
poly-partition problem of the reads, called the Polyploid Balanced Optimal
Partition model. For the reads sequenced from a k-ploid genome, the model tries
to divide the reads into k groups such that the difference between the reads of
the same group is minimized while the difference between the reads of different
groups is maximized. When the genotype information is available, the model is
extended to the Polyploid Balanced Optimal Partition with Genotype constraint
problem. These models are all NP-hard. We propose two heuristic algorithms, H-PoP
and H-PoPG, based on dynamic programming and a strategy of limiting the number of
intermediate solutions at each iteration, to solve the two models, respectively. 
Extensive experimental results on simulated and real data show that our
algorithms can solve the models effectively, and are much faster and more
accurate than the recent state-of-the-art polyploid haplotyping algorithms. The
experiments also show that our algorithms can deal with long reads and deep read 
coverage effectively and accurately. Furthermore, H-PoP might be applied to help 
determine the ploidy of an organism.
AVAILABILITY AND IMPLEMENTATION: https://github.com/MinzhuXie/H-PoPG CONTACT:
xieminzhu@hotmail.comSupplementary information: Supplementary data are available 
at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw537 
PMID: 27531103  [PubMed - in process]


359. Bioinformatics. 2017 Jan 1;33(1):26-34. doi: 10.1093/bioinformatics/btw536. Epub 
2016 Aug 16.

SiNVICT: ultra-sensitive detection of single nucleotide variants and indels in
circulating tumour DNA.

Kockan C(1,)(2), Hach F(1,)(3), Sarrafi I(1), Bell RH(3), McConeghy B(3), Beja
K(3), Haegert A(3), Wyatt AW(3,)(4), Volik SV(3), Chi KN(4), Collins CC(3,)(4),
Sahinalp SC(1,)(4,)(5).

Author information: 
(1)School of Computing Science. (2)MADD-Gen Graduate Program, Simon Fraser
University, Burnaby, (BC), V5A 1S6, Canada. (3)Vancouver Prostate Centre,
Vancouver, BC V6H 3Z6, Canada. (4)Department of Urologic Sciences, University of 
British Columbia, Vancouver, BC V6T 1Z4, Canada. (5)School of Informatics and
Computing, Indiana University, Bloomington, IN 47405, USA.

MOTIVATION: Successful development and application of precision oncology
approaches require robust elucidation of the genomic landscape of a patient's
cancer and, ideally, the ability to monitor therapy-induced genomic changes in
the tumour in an inexpensive and minimally invasive manner. Thanks to recent
advances in sequencing technologies, 'liquid biopsy', the sampling of patient's
bodily fluids such as blood and urine, is considered as one of the most promising
approaches to achieve this goal. In many cancer patients, and especially those
with advanced metastatic disease, deep sequencing of circulating cell free DNA
(cfDNA) obtained from patient's blood yields a mixture of reads originating from 
the normal DNA and from multiple tumour subclones-called circulating tumour DNA
or ctDNA. The ctDNA/cfDNA ratio as well as the proportion of ctDNA originating
from specific tumour subclones depend on multiple factors, making comprehensive
detection of mutations difficult, especially at early stages of cancer.
Furthermore, sensitive and accurate detection of single nucleotide variants
(SNVs) and indels from cfDNA is constrained by several factors such as the
sequencing errors and PCR artifacts, and mapping errors related to repeat regions
within the genome. In this article, we introduce SiNVICT, a computational method 
that increases the sensitivity and specificity of SNV and indel detection at very
low variant allele frequencies. SiNVICT has the capability to handle multiple
sequencing platforms with different error properties; it minimizes false
positives resulting from mapping errors and other technology specific artifacts
including strand bias and low base quality at read ends. SiNVICT also has the
capability to perform time-series analysis, where samples from a patient
sequenced at multiple time points are jointly examined to report locations of
interest where there is a possibility that certain clones were wiped out by some 
treatment while some subclones gained selective advantage.
RESULTS: We tested SiNVICT on simulated data as well as prostate cancer cell
lines and cfDNA obtained from castration-resistant prostate cancer patients. On
both simulated and biological data, SiNVICT was able to detect SNVs and indels
with variant allele percentages as low as 0.5%. The lowest amounts of total DNA
used for the biological data where SNVs and indels could be detected with very
high sensitivity were 2.5 ng on the Ion Torrent platform and 10 ng on Illumina.
With increased sequencing and mapping accuracy, SiNVICT might be utilized in
clinical settings, making it possible to track the progress of point mutations
and indels that are associated with resistance to cancer therapies and provide
patients personalized treatment. We also compared SiNVICT with other popular SNV 
callers such as MuTect, VarScan2 and Freebayes. Our results show that SiNVICT
performs better than these tools in most cases and allows further data
exploration such as time-series analysis on cfDNA sequencing data.
AVAILABILITY AND IMPLEMENTATION: SiNVICT is available at:
https://sfu-compbio.github.io/sinvictSupplementary information: Supplementary
data are available at Bioinformatics online.
CONTACT: cenk@sfu.ca.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw536 
PMID: 27531099  [PubMed - in process]


360. Bioinformatics. 2016 Dec 1;32(23):3593-3602. Epub 2016 Aug 13.

SDEAP: a splice graph based differential transcript expression analysis tool for 
population data.

Yang EW(1,)(2), Jiang T(1,)(3,)(4).

Author information: 
(1)Department of Computer Science and Engineering, University of California,
Riverside, CA, USA. (2)Department of Integrative Biology and Physiology,
University of California, Los Angeles, CA, USA. (3)Institute of Integrative
Genome Biology, University of California, Riverside, CA, USA. (4)MOE Key Lab of
Bioinformatics and Bioinformatics Division, TNLIST/Department of Computer Science
and Technology, Tsinghua University, Beijing, China.

MOTIVATION: Differential transcript expression (DTE) analysis without predefined 
conditions is critical to biological studies. For example, it can be used to
discover biomarkers to classify cancer samples into previously unknown subtypes
such that better diagnosis and therapy methods can be developed for the subtypes.
Although several DTE tools for population data, i.e. data without known
biological conditions, have been published, these tools either assume binary
conditions in the input population or require the number of conditions as a part 
of the input. Fixing the number of conditions to binary is unrealistic and may
distort the results of a DTE analysis. Estimating the correct number of
conditions in a population could also be challenging for a routine user.
Moreover, the existing tools only provide differential usages of exons, which may
be insufficient to interpret the patterns of alternative splicing across samples 
and restrains the applications of the tools from many biology studies.
RESULTS: We propose a novel DTE analysis algorithm, called SDEAP, that estimates 
the number of conditions directly from the input samples using a Dirichlet
mixture model and discovers alternative splicing events using a new graph modular
decomposition algorithm. By taking advantage of the above technical improvement, 
SDEAP was able to outperform the other DTE analysis methods in our extensive
experiments on simulated data and real data with qPCR validation. The prediction 
of SDEAP also allowed us to classify the samples of cancer subtypes and
cell-cycle phases more accurately.
AVAILABILITY AND IMPLEMENTATION: SDEAP is publicly available for free at
https://github.com/ewyang089/SDEAP/wiki CONTACT: yyang027@cs.ucr.edu;
jiang@cs.ucr.eduSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw513 
PMID: 27522083  [PubMed - in process]


361. BMC Res Notes. 2016 Aug 11;9(1):402. doi: 10.1186/s13104-016-2203-3.

Mycofier: a new machine learning-based classifier for fungal ITS sequences.

Delgado-Serrano L(1,)(2), Restrepo S(2), Bustos JR(1), Zambrano MM(1), Anzola
JM(3).

Author information: 
(1)Bioinformatics & Computational Biology, Corporación CorpoGen, Bogotá, DC,
Colombia. (2)Department of Biological Sciences, Universidad de Los Andes, Bogotá,
DC, Colombia. (3)Bioinformatics & Computational Biology, Corporación CorpoGen,
Bogotá, DC, Colombia. juan.anzola@corpogen.org.

BACKGROUND: The taxonomic and phylogenetic classification based on sequence
analysis of the ITS1 genomic region has become a crucial component of fungal
ecology and diversity studies. Nowadays, there is no accurate alignment-free
classification tool for fungal ITS1 sequences for large environmental surveys.
This study describes the development of a machine learning-based classifier for
the taxonomical assignment of fungal ITS1 sequences at the genus level.
RESULTS: A fungal ITS1 sequence database was built using curated data. Training
and test sets were generated from it. A Naïve Bayesian classifier was built using
features from the primary sequence with an accuracy of 87 % in the classification
at the genus level.
CONCLUSIONS: The final model was based on a Naïve Bayes algorithm using ITS1
sequences from 510 fungal genera. This classifier, denoted as Mycofier, provides 
similar classification accuracy compared to BLASTN, but the database used for the
classification contains curated data and the tool, independent of alignment, is
more efficient and contributes to the field, given the lack of an accurate
classification tool for large data from fungal ITS1 sequences. The software and
source code for Mycofier are freely available at
https://github.com/ldelgado-serrano/mycofier.git .

DOI: 10.1186/s13104-016-2203-3 
PMCID: PMC4982325
PMID: 27516337  [PubMed - indexed for MEDLINE]


362. Bioinformatics. 2016 Dec 1;32(23):3552-3558. Epub 2016 Aug 11.

Multivariate Welch t-test on distances.

Alekseyenko AV(1).

Author information: 
(1)Departments of Public Health Sciences and Oral Health Sciences, Program for
Human Microbiome Research, The Biomedical Informatics Center Medical University
of South Carolina, 135 Cannon Street, MSC 200, Charleston, SC 29466, USA.

MOTIVATION: Permutational non-Euclidean analysis of variance, PERMANOVA, is
routinely used in exploratory analysis of multivariate datasets to draw
conclusions about the significance of patterns visualized through dimension
reduction. This method recognizes that pairwise distance matrix between
observations is sufficient to compute within and between group sums of squares
necessary to form the (pseudo) F statistic. Moreover, not only Euclidean, but
arbitrary distances can be used. This method, however, suffers from loss of power
and type I error inflation in the presence of heteroscedasticity and sample size 
imbalances.
RESULTS: We develop a solution in the form of a distance-based Welch t-test,
[Formula: see text], for two sample potentially unbalanced and heteroscedastic
data. We demonstrate empirically the desirable type I error and power
characteristics of the new test. We compare the performance of PERMANOVA and
[Formula: see text] in reanalysis of two existing microbiome datasets, where the 
methodology has originated.
AVAILABILITY AND IMPLEMENTATION: The source code for methods and analysis of this
article is available at https://github.com/alekseyenko/Tw2 Further guidance on
application of these methods can be obtained from the author.
CONTACT: alekseye@musc.edu.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw524 
PMCID: PMC5181538
PMID: 27515741  [PubMed - in process]


363. Bioinformatics. 2016 Dec 1;32(23):3584-3592. Epub 2016 Aug 11.

ChemTreeMap: an interactive map of biochemical similarity in molecular datasets.

Lu J(1), Carlson HA(1,)(2).

Author information: 
(1)Department of Computational Medicine and Bioinformatics. (2)Department of
Medicinal Chemistry, University of Michigan, Ann Arbor, MI, USA.

MOTIVATION: What if you could explain complex chemistry in a simple tree and
share that data online with your collaborators? Computational biology often
incorporates diverse chemical data to probe a biological question, but the
existing tools for chemical data are ill-suited for the very large datasets
inherent to bioinformatics. Furthermore, existing visualization methods often
require an expert chemist to interpret the patterns. Biologists need an
interactive tool for visualizing chemical information in an intuitive, accessible
way that facilitates its integration into today's team-based biological research.
RESULTS: ChemTreeMap is an interactive, bioinformatics tool designed to explore
chemical space and mine the relationships between chemical structure, molecular
properties, and biological activity. ChemTreeMap synergistically combines
extended connectivity fingerprints and a neighbor-joining algorithm to produce a 
hierarchical tree with branch lengths proportional to molecular similarity.
Compound properties are shown by leaf color, size and outline to yield a
user-defined visualization of the tree. Two representative analyses are included 
to demonstrate ChemTreeMap's capabilities and utility: assessing dataset overlap 
and mining structure-activity relationships.
AVAILABILITY AND IMPLEMENTATION: The examples from this paper may be accessed at 
http://ajing.github.io/ChemTreeMap/ Code for the server and client are available 
in the Supplementary Information, at the aforementioned github site, and on
Docker Hub (https://hub.docker.com) with the nametag ajing/chemtreemap.
CONTACT: carlsonh@umich.eduSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw523 
PMCID: PMC5181537 [Available on 2017-12-01]
PMID: 27515740  [PubMed - in process]


364. Bioinformatics. 2016 Dec 1;32(23):3535-3542. Epub 2016 Aug 11.

LCA*: an entropy-based measure for taxonomic assignment within assembled
metagenomes.

Hanson NW(1), Konwar KM(2), Hallam SJ(1,)(3,)(4,)(5).

Author information: 
(1)Graduate Program in Bioinformatics University of British Columbia, Vancouver, 
Canada. (2)Computer Science and Artificial Intelligence Laboratory, Massachusetts
Institute of Technology, Cambridge, MA, USA. (3)Department of Microbiology and
Immunology, University of British Columbia, Vancouver, Canada. (4)ECOSCOPE
Training Program, University of British Columbia, Vancouver, British Columbia,
Canada. (5)Peter Wall Institute for Advanced Studies, University of British
Columbia.

MOTIVATION: A perennial problem in the analysis of environmental sequence
information is the assignment of reads or assembled sequences, e.g. contigs or
scaffolds, to discrete taxonomic bins. In the absence of reference genomes for
most environmental microorganisms, the use of intrinsic nucleotide patterns and
phylogenetic anchors can improve assembly-dependent binning needed for more
accurate taxonomic and functional annotation in communities of microorganisms,
and assist in identifying mobile genetic elements or lateral gene transfer
events.
RESULTS: Here, we present a statistic called LCA* inspired by Information and
Voting theories that uses the NCBI Taxonomic Database hierarchy to assign
taxonomy to contigs assembled from environmental sequence information. The LCA*
algorithm identifies a sufficiently strong majority on the hierarchy while
minimizing entropy changes to the observed taxonomic distribution resulting in
improved statistical properties. Moreover, we apply results from the
order-statistic literature to formulate a likelihood-ratio hypothesis test and
P-value for testing the supremacy of the assigned LCA* taxonomy. Using simulated 
and real-world datasets, we empirically demonstrate that voting-based methods,
majority vote and LCA*, in the presence of known reference annotations, are
consistently more accurate in identifying contig taxonomy than the lowest common 
ancestor algorithm popularized by MEGAN, and that LCA* taxonomy strikes a balance
between specificity and confidence to provide an estimate appropriate to the
available information in the data.
AVAILABILITY AND IMPLEMENTATION: The LCA* has been implemented as a stand-alone
Python library compatible with the MetaPathways pipeline; both of which are
available on GitHub with installation instructions and use-cases
(http://www.github.com/hallamlab/LCAStar/).
CONTACT: shallam@mail.ubc.caSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw400 
PMCID: PMC5181528
PMID: 27515739  [PubMed - in process]


365. Bioinformatics. 2016 Dec 1;32(23):3682-3684. Epub 2016 Aug 11.

NVT: a fast and simple tool for the assessment of RNA-seq normalization
strategies.

Eder T(1,)(2), Grebien F(1), Rattei T(2).

Author information: 
(1)Ludwig Boltzmann Institute for Cancer Research, Vienna, 1090, Austria. (2)CUBE
Division of Computational Systems Biology, Department of Microbiology and
Ecosystem Science, University of Vienna, Vienna, 1090, Austria.

MOTIVATION: Measuring differential gene expression is a common task in the
analysis of RNA-Seq data. To identify differentially expressed genes between two 
samples, it is crucial to normalize the datasets. While multiple normalization
methods are available, all of them are based on certain assumptions that may or
may not be suitable for the type of data they are applied on. Researchers
therefore need to select an adequate normalization strategy for each RNA-Seq
experiment. This selection includes exploration of different normalization
methods as well as their comparison. Methods that agree with each other most
likely represent realistic assumptions under the particular experimental
conditions.
RESULTS: We developed the NVT package, which provides a fast and simple way to
analyze and evaluate multiple normalization methods via visualization and
representation of correlation values, based on a user-defined set of uniformly
expressed genes.
AVAILABILITY AND IMPLEMENTATION: The R package is freely available under
https://github.com/Edert/NVT CONTACT: thomas.rattei@univie.ac.atSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw521 
PMCID: PMC5133377
PMID: 27515738  [PubMed - in process]


366. Anal Chem. 2016 Sep 20;88(18):9037-46. doi: 10.1021/acs.analchem.6b01702. Epub
2016 Aug 31.

Defining and Detecting Complex Peak Relationships in Mass Spectral Data: The
Mz.unity Algorithm.

Mahieu NG(1), Spalding JL(1), Gelman SJ(1), Patti GJ(1).

Author information: 
(1)Department of Chemistry, Washington University , St. Louis, Missouri 63130,
United States .

Analysis of a single analyte by mass spectrometry can result in the detection of 
more than 100 degenerate peaks. These degenerate peaks complicate spectral
interpretation and are challenging to annotate. In mass spectrometry-based
metabolomics, this degeneracy leads to inflated false discovery rates, data sets 
containing an order of magnitude more features than analytes, and an inefficient 
use of resources during data analysis. Although software has been introduced to
annotate spectral degeneracy, current approaches are unable to represent several 
important classes of peak relationships. These include heterodimers and higher
complex adducts, distal fragments, relationships between peaks in different
polarities, and complex adducts between features and background peaks. Here we
outline sources of peak degeneracy in mass spectra that are not annotated by
current approaches and introduce a software package called mz.unity to detect
these relationships in accurate mass data. Using mz.unity, we find that data sets
contain many more complex relationships than we anticipated. Examples include the
adduct of glutamate and nicotinamide adenine dinucleotide (NAD), fragments of NAD
detected in the same or opposite polarities, and the adduct of glutamate and a
background peak. Further, the complex relationships we identify show that several
assumptions commonly made when interpreting mass spectral degeneracy do not hold 
in general. These contributions provide new tools and insight to aid in the
annotation of complex spectral relationships and provide a foundation for
improved data set identification. Mz.unity is an R package and is freely
available at https://github.com/nathaniel-mahieu/mz.unity as well as our
laboratory Web site http://pattilab.wustl.edu/software/ .

DOI: 10.1021/acs.analchem.6b01702 
PMID: 27513885  [PubMed - in process]


367. PLoS One. 2016 Aug 9;11(8):e0160303. doi: 10.1371/journal.pone.0160303.
eCollection 2016.

Chromosome Territory Modeller and Viewer.

Tkacz MA(1), Chromiński K(2), Idziak-Helmcke D(3), Robaszkiewicz E(3), Hasterok
R(3).

Author information: 
(1)Institute of Computer Science, Faculty of Material and Computer Science,
University of Silesia in Katowice, Sosnowiec, Poland. (2)Institute of Technology 
and Mechatronics, Faculty of Material and Computer Science, University of Silesia
in Katowice, Sosnowiec, Poland. (3)Department of Plant Anatomy and Cytology,
Faculty of Biology and Environmental Protection, University of Silesia in
Katowice, Katowice, Poland.

This paper presents ChroTeMo, a tool for chromosome territory modelling,
accompanied by ChroTeVi-a chromosome territory visualisation software that uses
the data obtained by ChroTeMo. These tools have been developed in order to
complement the molecular cytogenetic research of interphase nucleus structure in 
a model grass Brachypodium distachyon. Although the modelling tool has been
initially created for one particular species, it has universal application. The
proposed version of ChroTeMo allows for generating a model of chromosome
territory distribution in any given plant or animal species after setting the
initial, species-specific parameters. ChroTeMo has been developed as a fully
probabilistic modeller. Due to this feature, the comparison between the
experimental data on the structure of a nucleus and the results obtained from
ChroTeMo can indicate whether the distribution of chromosomes inside a nucleus is
also fully probabilistic or is subjected to certain non-random patterns. The
presented tools have been written in Python, so they are multiplatform, portable 
and easy to read. Moreover, if necessary they can be further developed by users
writing their portions of code. The source code, documentation, and wiki, as well
as the issue tracker and the list of related articles that use ChroTeMo and
ChroTeVi, are accessible in a public repository at Github under GPL 3.0 license.

DOI: 10.1371/journal.pone.0160303 
PMCID: PMC4978479
PMID: 27505434  [PubMed - in process]


368. Database (Oxford). 2016 Aug 7;2016. pii: baw112. doi: 10.1093/database/baw112.
Print 2016.

Improving the dictionary lookup approach for disease normalization using enhanced
dictionary and query expansion.

Jonnagaddala J(1), Jue TR(2), Chang NW(3), Dai HJ(4).

Author information: 
(1)School of Public Health and Community Medicine, UNSW, Kensington, NSW 2033,
Australia Prince of Wales Clinical School, UNSW, Kensington, NSW 2033, Australia 
z33339253@unsw.edu.au hjdai@nttu.edu.tw. (2)Prince of Wales Clinical School,
UNSW, Kensington, NSW 2033, Australia. (3)Institution of Information Science,
Academia Sinica, Taipei 115, Taiwan Graduate Institute of Biomedical Electronics 
and Bioinformatics, National Taiwan University, Taipei, Taiwan and. (4)Department
of Computer Science and Information Engineering, National Taitung University,
Taipei, Taiwan z33339253@unsw.edu.au hjdai@nttu.edu.tw.

The rapidly increasing biomedical literature calls for the need of an automatic
approach in the recognition and normalization of disease mentions in order to
increase the precision and effectivity of disease based information retrieval. A 
variety of methods have been proposed to deal with the problem of disease named
entity recognition and normalization. Among all the proposed methods, conditional
random fields (CRFs) and dictionary lookup method are widely used for named
entity recognition and normalization respectively. We herein developed a
CRF-based model to allow automated recognition of disease mentions, and studied
the effect of various techniques in improving the normalization results based on 
the dictionary lookup approach. The dataset from the BioCreative V CDR track was 
used to report the performance of the developed normalization methods and compare
with other existing dictionary lookup based normalization methods. The best
configuration achieved an F-measure of 0.77 for the disease normalization, which 
outperformed the best dictionary lookup based baseline method studied in this
work by an F-measure of 0.13.Database URL:
https://github.com/TCRNBioinformatics/DiseaseExtract.

© The Author(s) 2016. Published by Oxford University Press.

DOI: 10.1093/database/baw112 
PMCID: PMC4976299
PMID: 27504009  [PubMed - in process]


369. Bioinformatics. 2016 Dec 1;32(23):3679-3681. Epub 2016 Aug 8.

shinyGEO: a web-based application for analyzing gene expression omnibus datasets.

Dumas J(1), Gargano MA(2), Dancik GM(2).

Author information: 
(1)College of Computing and Digital Media, DePaul University, Chicago, IL, USA.
(2)Department of Mathematics and Computer Science, Eastern Connecticut State
University, Willimantic, CT, USA.

The Gene Expression Omnibus (GEO) is a public repository of gene expression data.
Although GEO has its own tool, GEO2R, for data analysis, evaluation of single
genes is not straightforward and survival analysis in specific GEO datasets is
not possible without bioinformatics expertise. We describe a web application,
shinyGEO, that allows a user to download gene expression data sets directly from 
GEO in order to perform differential expression and survival analysis for a gene 
of interest. In addition, shinyGEO supports customized graphics, sample
selection, data export and R code generation so that all analyses are
reproducible. The availability of shinyGEO makes GEO datasets more accessible to 
non-bioinformaticians, promising to lead to better understanding of biological
processes and genetic diseases such as cancer.AVAILABILITY AND IMPLEMENTATION:
Web application and source code are available from
http://gdancik.github.io/shinyGEO/ CONTACT: dancikg@easternct.eduSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw519 
PMID: 27503226  [PubMed - in process]


370. Bioinformatics. 2016 Dec 1;32(23):3688-3690. Epub 2016 Aug 8.

PathScore: a web tool for identifying altered pathways in cancer data.

Gaffney SG(1), Townsend JP(1,)(2).

Author information: 
(1)Department of Biostatistics, Yale School of Public Health, Yale University,
New Haven, CT 06511, USA. (2)Program in Computational Biology and Bioinformatics,
Yale University, New Haven, CT 06511, USA.

PathScore quantifies the level of enrichment of somatic mutations within curated 
pathways, applying a novel approach that identifies pathways enriched across
patients. The application provides several user-friendly, interactive graphic
interfaces for data exploration, including tools for comparing pathway effect
sizes, significance, gene-set overlap and enrichment differences between
projects.AVAILABILITY AND IMPLEMENTATION: Web application available at
pathscore.publichealth.yale.edu. Site implemented in Python and MySQL, with all
major browsers supported. Source code available at:
github.com/sggaffney/pathscore with a GPLv3 license.
CONTACT: stephen.gaffney@yale.edu.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw512 
PMID: 27503224  [PubMed - in process]


371. Bioinformatics. 2016 Dec 1;32(23):3691-3693. Epub 2016 Aug 8.

BiDiFuse: a FIJI plugin for fusing bi-directionally recorded microscopic image
volumes.

Detrez JR(1), Vanderwinden JM(2), Barbier M(1,)(3), Verschuuren M(1), Nuydens
R(3), Langlois X(3), Timmermans JP(1), De Vos WH(1,)(4).

Author information: 
(1)Laboratory of Cell Biology & Histology, Department of Veterinary Sciences,
University of Antwerp, 2020 Antwerp, Belgium. (2)Light Microscopy Facility &
Laboratory of Neurophysiology, Faculty of Medicine, Free University of Brussels, 
1070 Anderlecht, Belgium. (3)Department of Neuroscience, Janssen Research and
Development, 2340 Beerse, Belgium. (4)Department of Molecular Biotechnology,
Ghent University, 9000 Ghent, Belgium.

Deep tissue imaging is increasingly used for non-destructive interrogation of
intact organs and small model organisms. An intuitive approach to increase the
imaging depth by almost a factor of 2 is to record a sample from two sides and
fuse both image stacks. However, imperfect three-dimensional alignment of both
stacks presents a computational challenge. We have developed a FIJI plugin,
called BiDiFuse, which merges bi-directionally recorded image stacks via 3D rigid
transformations. The method is broadly applicable, considering it is compatible
with all optical sectioning microscopes and it does not rely on fiducial markers 
for image registration.AVAILABILITY AND IMPLEMENTATION: The method is freely
available as a plugin for FIJI from https://github.com/JanDetrez/BiDiFuse/
CONTACT: winnok.devos@uantwerpen.be.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw515 
PMID: 27503222  [PubMed - in process]


372. Bioinformatics. 2016 Dec 1;32(23):3566-3574. Epub 2016 Aug 8.

A profile-based method for identifying functional divergence of orthologous genes
in bacterial genomes.

Wheeler NE(1,)(2), Barquist L(3), Kingsley RA(4,)(5), Gardner PP(1,)(2,)(6).

Author information: 
(1)School of Biological Sciences, University of Canterbury, Christchurch, New
Zealand. (2)Biomolecular Interaction Centre, University of Canterbury,
Christchurch, New Zealand. (3)Institute for Molecular Infection Biology,
University of Wuerzburg, Wuerzburg, Germany. (4)Institute of Food Research,
Norwich Research Park, Norwich, UK. (5)Wellcome Trust Sanger Institute, Hinxton, 
UK. (6)Bio-protection Research Centre, University of Canterbury, Christchurch,
New Zealand.

MOTIVATION: Next generation sequencing technologies have provided us with a
wealth of information on genetic variation, but predicting the functional
significance of this variation is a difficult task. While many comparative
genomics studies have focused on gene flux and large scale changes, relatively
little attention has been paid to quantifying the effects of single nucleotide
polymorphisms and indels on protein function, particularly in bacterial genomics.
RESULTS: We present a hidden Markov model based approach we call delta-bitscore
(DBS) for identifying orthologous proteins that have diverged at the amino acid
sequence level in a way that is likely to impact biological function. We
benchmark this approach with several widely used datasets and apply it to a
proof-of-concept study of orthologous proteomes in an investigation of host
adaptation in Salmonella enterica We highlight the value of the method in
identifying functional divergence of genes, and suggest that this tool may be a
better approach than the commonly used dN/dS metric for identifying functionally 
significant genetic changes occurring in recently diverged organisms.
AVAILABILITY AND IMPLEMENTATION: A program implementing DBS for pairwise genome
comparisons is freely available at: https://github.com/UCanCompBio/deltaBS
CONTACT: nicole.wheeler@pg.canterbury.ac.nz or
lars.barquist@uni-wuerzburg.deSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw518 
PMCID: PMC5181535
PMID: 27503221  [PubMed - in process]


373. BMC Syst Biol. 2016 Aug 8;10(1):59. doi: 10.1186/s12918-016-0318-8.

In silico modeling for tumor growth visualization.

Jeanquartier F(1), Jean-Quartier C(1), Cemernek D(1), Holzinger A(2,)(3).

Author information: 
(1)Holzinger Group, Research Unit HCI-KDD, Institute for Medical Informatics,
Statistics and Documentation, Medical University Graz, Auenbruggerplatz 2/V,
8036, AT, Graz, Austria. (2)Holzinger Group, Research Unit HCI-KDD, Institute for
Medical Informatics, Statistics and Documentation, Medical University Graz,
Auenbruggerplatz 2/V, 8036, AT, Graz, Austria. a.holzinger@hci-kdd.org.
(3)Institute of Information Systems and Computer Media, Graz University of
Technology, Inffeldgasse 16c, Graz, 8010, AT, Austria. a.holzinger@hci-kdd.org.

BACKGROUND: Cancer is a complex disease. Fundamental cellular based studies as
well as modeling provides insight into cancer biology and strategies to treatment
of the disease. In silico models complement in vivo models. Research on tumor
growth involves a plethora of models each emphasizing isolated aspects of benign 
and malignant neoplasms. Biologists and clinical scientists are often overwhelmed
by the mathematical background knowledge necessary to grasp and to apply a model 
to their own research.
RESULTS: We aim to provide a comprehensive and expandable simulation tool to
visualizing tumor growth. This novel Web-based application offers the advantage
of a user-friendly graphical interface with several manipulable input variables
to correlate different aspects of tumor growth. By refining model parameters we
highlight the significance of heterogeneous intercellular interactions on tumor
progression. Within this paper we present the implementation of the Cellular
Potts Model graphically presented through Cytoscape.js within a Web application. 
The tool is available under the MIT license at
https://github.com/davcem/cpm-cytoscape and
http://styx.cgv.tugraz.at:8080/cpm-cytoscape/ .
CONCLUSION: In-silico methods overcome the lack of wet experimental possibilities
and as dry method succeed in terms of reduction, refinement and replacement of
animal experimentation, also known as the 3R principles. Our visualization
approach to simulation allows for more flexible usage and easy extension to
facilitate understanding and gain novel insight. We believe that biomedical
research in general and research on tumor growth in particular will benefit from 
the systems biology perspective.

DOI: 10.1186/s12918-016-0318-8 
PMCID: PMC4977902
PMID: 27503052  [PubMed - in process]


374. Front Neuroinform. 2016 Jul 22;10:27. doi: 10.3389/fninf.2016.00027. eCollection 
2016.

CoSMoMVPA: Multi-Modal Multivariate Pattern Analysis of Neuroimaging Data in
Matlab/GNU Octave.

Oosterhof NN(1), Connolly AC(2), Haxby JV(3).

Author information: 
(1)Center for Mind/Brain Sciences, University of Trento Rovereto, Italy.
(2)Department of Psychological and Brain Sciences, Dartmouth College Hanover, NH,
USA. (3)Center for Mind/Brain Sciences, University of TrentoRovereto, Italy;
Department of Psychological and Brain Sciences, Dartmouth CollegeHanover, NH,
USA.

Recent years have seen an increase in the popularity of multivariate pattern
(MVP) analysis of functional magnetic resonance (fMRI) data, and, to a much
lesser extent, magneto- and electro-encephalography (M/EEG) data. We present
CoSMoMVPA, a lightweight MVPA (MVP analysis) toolbox implemented in the
intersection of the Matlab and GNU Octave languages, that treats both fMRI and
M/EEG data as first-class citizens. CoSMoMVPA supports all state-of-the-art MVP
analysis techniques, including searchlight analyses, classification,
correlations, representational similarity analysis, and the time generalization
method. These can be used to address both data-driven and hypothesis-driven
questions about neural organization and representations, both within and across: 
space, time, frequency bands, neuroimaging modalities, individuals, and species. 
It uses a uniform data representation of fMRI data in the volume or on the
surface, and of M/EEG data at the sensor and source level. Through various
external toolboxes, it directly supports reading and writing a variety of fMRI
and M/EEG neuroimaging formats, and, where applicable, can convert between them. 
As a result, it can be integrated readily in existing pipelines and used with
existing preprocessed datasets. CoSMoMVPA overloads the traditional volumetric
searchlight concept to support neighborhoods for M/EEG and surface-based fMRI
data, which supports localization of multivariate effects of interest across
space, time, and frequency dimensions. CoSMoMVPA also provides a generalized
approach to multiple comparison correction across these dimensions using
Threshold-Free Cluster Enhancement with state-of-the-art clustering and
permutation techniques. CoSMoMVPA is highly modular and uses abstractions to
provide a uniform interface for a variety of MVP measures. Typical analyses
require a few lines of code, making it accessible to beginner users. At the same 
time, expert programmers can easily extend its functionality. CoSMoMVPA comes
with extensive documentation, including a variety of runnable demonstration
scripts and analysis exercises (with example data and solutions). It uses best
software engineering practices including version control, distributed
development, an automated test suite, and continuous integration testing. It can 
be used with the proprietary Matlab and the free GNU Octave software, and it
complies with open source distribution platforms such as NeuroDebian. CoSMoMVPA
is Free/Open Source Software under the permissive MIT license. Website:
http://cosmomvpa.org Source code: https://github.com/CoSMoMVPA/CoSMoMVPA.

DOI: 10.3389/fninf.2016.00027 
PMCID: PMC4956688
PMID: 27499741  [PubMed]


375. J Chem Phys. 2016 Aug 7;145(5):054120. doi: 10.1063/1.4959817.

DMRG-CASPT2 study of the longitudinal static second hyperpolarizability of
all-trans polyenes.

Wouters S(1), Van Speybroeck V(1), Van Neck D(1).

Author information: 
(1)Center for Molecular Modelling, Ghent University, Technologiepark 903, 9052
Zwijnaarde, Belgium.

We have implemented internally contracted complete active space second order
perturbation theory (CASPT2) with the density matrix renormalization group (DMRG)
as active space solver [Y. Kurashige and T. Yanai, J. Chem. Phys. 135, 094104
(2011)]. Internally contracted CASPT2 requires to contract the generalized Fock
matrix with the 4-particle reduced density matrix (4-RDM) of the reference
wavefunction. The required 4-RDM elements can be obtained from 3-particle reduced
density matrices (3-RDM) of different wavefunctions, formed by
symmetry-conserving single-particle excitations op top of the reference
wavefunction. In our spin-adapted DMRG code chemps2
https://github.com/sebwouters/chemps2, we decompose these excited wavefunctions
as spin-adapted matrix product states and calculate their 3-RDM in order to
obtain the required contraction of the generalized Fock matrix with the 4-RDM of 
the reference wavefunction. In this work, we study the longitudinal static second
hyperpolarizability of all-trans polyenes C2nH2n+2 [n = 4-12] in the cc-pVDZ
basis set. DMRG-SCF and DMRG-CASPT2 yield substantially lower values and scaling 
with system size compared to RHF and MP2, respectively.

DOI: 10.1063/1.4959817 
PMID: 27497552  [PubMed]


376. Bioinformatics. 2016 Oct 1;32(19):3038-40. doi: 10.1093/bioinformatics/btw484.
Epub 2016 Aug 6.

scphaser: haplotype inference using single-cell RNA-seq data.

Edsgärd D(1), Reinius B(1), Sandberg R(2).

Author information: 
(1)Department of Cell and Molecular Biology, Karolinska Institutet, 171 77
Stockholm, Sweden. (2)Department of Cell and Molecular Biology, Karolinska
Institutet, 171 77 Stockholm, Sweden Ludwig Institute for Cancer Research, Box
240, 171 77 Stockholm, Sweden.

Determination of haplotypes is important for modelling the phenotypic
consequences of genetic variation in diploid organisms, including cis-regulatory 
control and compound heterozygosity. We realized that single-cell RNA-seq
(scRNA-seq) data are well suited for phasing genetic variants, since both
transcriptional bursts and technical bottlenecks cause pronounced allelic
fluctuations in individual single cells. Here we present scphaser, an R package
that phases alleles at heterozygous variants to reconstruct haplotypes within
transcribed regions of the genome using scRNA-seq data. The devised method
efficiently and accurately reconstructed the known haplotype for ≥93% of phasable
genes in both human and mouse. It also enables phasing of rare and de novo
variants and variants far apart within genes, which is hard to attain with
population-based computational inference.AVAILABILITY AND IMPLEMENTATION:
scphaser is implemented as an R package. Tutorial and code are available at
https://github.com/edsgard/scphaser
CONTACT: rickard.sandberg@ki.se
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw484 
PMCID: PMC5039928
PMID: 27497440  [PubMed - in process]


377. Bioinformatics. 2016 Dec 1;32(23):3661-3663. Epub 2016 Aug 6.

genipe: an automated genome-wide imputation pipeline with automatic reporting and
statistical tools.

Lemieux Perreault LP(1), Legault MA(1,)(2), Asselin G(1), Dubé MP(1,)(3).

Author information: 
(1)Beaulieu-Saucier Université de Montréal Pharmacogenomics Centre, Montreal
Heart Institute Research Center, Montréal, Canada H1T 1C8. (2)Department of
Biochemistry and molecular medicine, Université de Montréal, Montreal, Canada H3T
1J4. (3)Department of Medicine, Université de Montréal, Montreal, Canada H3T 1J4.

Genotype imputation is now commonly performed following genome-wide genotyping
experiments. Imputation increases the density of analyzed genotypes in the
dataset, enabling fine-mapping across the genome. However, the process of
imputation using the most recent publicly available reference datasets can
require considerable computation power and the management of hundreds of large
intermediate files. We have developed genipe, a complete genome-wide imputation
pipeline which includes automatic reporting, imputed data indexing and
management, and a suite of statistical tests for imputed data commonly used in
genetic epidemiology (Sequence Kernel Association Test, Cox proportional hazards 
for survival analysis, and linear mixed models for repeated measurements in
longitudinal studies).AVAILABILITY AND IMPLEMENTATION: The genipe package is an
open source Python software and is freely available for non-commercial use (CC
BY-NC 4.0) at https://github.com/pgxcentre/genipe Documentation and tutorials are
available at http://pgxcentre.github.io/genipe CONTACT:
louis-philippe.lemieux.perreault@statgen.org or
marie-pierre.dube@statgen.orgSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw487 
PMCID: PMC5181529
PMID: 27497439  [PubMed - in process]


378. Bioinformatics. 2016 Nov 15;32(22):3396-3404. Epub 2016 Aug 4.

Detection of differentially methylated regions in whole genome bisulfite
sequencing data using local Getis-Ord statistics.

Wen Y(1,)(2), Chen F(1), Zhang Q(1), Zhuang Y(1), Li Z(1).

Author information: 
(1)Center of Genome and Personalized Medicine, Institute of Cancer Stem Cell,
Cancer Center, Dalian Medical University, Dalian 116044, China. (2)Department of 
Statistics, University of Auckland, Auckland 1142, New Zealand.

MOTIVATION: DNA methylation is an important epigenetic modification that has
essential role in gene regulation, cell differentiation and cancer development.
Bisulfite sequencing is a widely used technique to obtain genome-wide DNA
methylation profiles, and one of the key tasks of analyzing bisulfite sequencing 
data is to detect differentially methylated regions (DMRs) among samples under
different treatment conditions. Although numerous tools have been proposed to
detect differentially methylated single CpG site (DMC) between samples, methods
for direct DMR detection, especially for complex study designs, are largely
limited.
RESULTS: We present a new software, GetisDMR, for direct DMR detection. We use
beta-binomial regression to model the whole-genome bisulfite sequencing data,
where variations in methylation levels and confounding effects have been
accounted for. We employ a region-wise test statistic, which is derived from
local Getis-Ord statistics and considers the spatial correlation between nearby
CpG sites, to detect DMRs. Unlike existing methods, that attempt to infer DMRs
from DMCs based on empirical criteria, we provide statistical inference for
direct DMR detection. Through extensive simulations and an application to two
mouse datasets, we demonstrate that GetisDMR achieves better sensitivities,
positive predictive values, more exact locations and better agreement of DMRs
with current biological knowledge.
AVAILABILITY AND IMPLEMENTATION: It is available at
https://github.com/DMU-lilab/GetisDMR CONTACTS: y.wen@auckland.ac.nz or
zhiguangli@dlmedu.edu.cnSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw497 
PMID: 27493194  [PubMed - in process]


379. PLoS One. 2016 Aug 4;11(8):e0160519. doi: 10.1371/journal.pone.0160519.
eCollection 2016.

Lollipops in the Clinic: Information Dense Mutation Plots for Precision Medicine.

Jay JJ(1,)(2), Brouwer C(1,)(2).

Author information: 
(1)Bioinformatics Services Division, North Carolina Research Campus, Kannapolis, 
North Carolina, United States of America. (2)Bioinformatics and Genomics
Department, University of North Carolina at Charlotte, Charlotte, North Carolina,
United States of America.

INTRODUCTION: Concise visualization is critical to present large amounts of
information in a minimal space that can be interpreted quickly. Clinical
applications in precision medicine present an important use case due to the time 
dependent nature of the interpretations, although visualization is increasingly
necessary across the life sciences. In this paper we describe the Lollipops
software for the presentation of panel or exome sequencing results. Source code
and binaries are freely available at https://github.com/pbnjay/lollipops.
Although other software and web resources exist to produce lollipop diagrams,
these packages are less suited to clinical applications. The demands of precision
medicine require the ability to easily fit into a workflow and incorporate
external information without manual intervention.
RESULTS: The Lollipops software provides a simple command line interface that
only requires an official gene symbol and mutation list making it easily
scriptable. External information is integrated using the publicly available
Uniprot and Pfam resources. Heuristics are used to select the most informative
components and condense them for a concise plot. The output is a flexible
Scalable Vector Graphic (SVG) diagram that can be displayed in a web page or
graphic illustration tool.
CONCLUSION: The Lollipops software creates information-dense, publication-quality
mutation plots for automated pipelines and high-throughput workflows in precision
medicine. The automatic data integration enables clinical data security, and
visualization heuristics concisely present knowledge with minimal user
configuration.

DOI: 10.1371/journal.pone.0160519 
PMCID: PMC4973895
PMID: 27490490  [PubMed - in process]


380. PLoS One. 2016 Aug 4;11(8):e0160270. doi: 10.1371/journal.pone.0160270.
eCollection 2016.

Single Nucleotide Polymorphism Clustering in Systemic Autoimmune Diseases.

Charlon T(1,)(2), Martínez-Bueno M(3), Bossini-Castillo L(4), Carmona FD(4), Di
Cara A(1), Wojcik J(1), Voloshynovskiy S(2), Martín J(4), Alarcón-Riquelme ME(3).

Author information: 
(1)Quartz Bio, Plan-les-Ouates, Geneva, Switzerland. (2)Stochastic Information
Processing, University of Geneva, Geneva, Geneva, Switzerland. (3)Center for
Genomics and Oncological Research: Pfizer/University of Granada/Andalusian
Government, Granada, Granada, Spain. (4)Institute of Parasitology and Biomedicine
López Neyra, Spanish National Research Council, Armilla, Granada, Spain.

Systemic Autoimmune Diseases, a group of chronic inflammatory conditions, have
variable symptoms and difficult diagnosis. In order to reclassify them based on
genetic markers rather than clinical criteria, we performed clustering of Single 
Nucleotide Polymorphisms. However naive approaches tend to group patients
primarily by their geographic origin. To reduce this "ancestry signal", we
developed SNPClust, a method to select large sources of ancestry-independent
genetic variations from all variations detected by Principal Component Analysis. 
Applied to a Systemic Lupus Erythematosus case control dataset, SNPClust
successfully reduced the ancestry signal. Results were compared with association 
studies between the cases and controls without or with reference population
stratification correction methods. SNPClust amplified the disease discriminating 
signal and the ratio of significant associations outside the HLA locus was
greater compared to population stratification correction methods. SNPClust will
enable the use of ancestry-independent genetic information in the
reclassification of Systemic Autoimmune Diseases. SNPClust is available as an R
package and demonstrated on the public Human Genome Diversity Project dataset at 
https://github.com/ThomasChln/snpclust.

DOI: 10.1371/journal.pone.0160270 
PMCID: PMC4973908
PMID: 27490238  [PubMed - in process]


381. Front Neurosci. 2016 Jul 19;10:325. doi: 10.3389/fnins.2016.00325. eCollection
2016.

Manual-Protocol Inspired Technique for Improving Automated MR Image Segmentation 
during Label Fusion.

Bhagwat N(1), Pipitone J(2), Winterburn JL(1), Guo T(3), Duerden EG(3), Voineskos
AN(4), Lepage M(5), Miller SP(3), Pruessner JC(6), Chakravarty MM(7).

Author information: 
(1)Institute of Biomaterials and Biomedical Engineering, University of
TorontoToronto, ON, Canada; Cerebral Imaging Centre, Douglas Mental Health
University InstituteVerdun, QC, Canada; Kimel Family Translational
Imaging-Genetics Research Lab, Research Imaging Centre, Campbell Family Mental
Health Research Institute, Centre for Addiction and Mental HealthToronto, ON,
Canada. (2)Kimel Family Translational Imaging-Genetics Research Lab, Research
Imaging Centre, Campbell Family Mental Health Research Institute, Centre for
Addiction and Mental Health Toronto, ON, Canada. (3)Neurosciences and Mental
Health, The Hospital for Sick Children Research InstituteToronto, ON, Canada;
Department of Paediatrics, The Hospital for Sick Children and the University of
TorontoToronto, ON, Canada. (4)Kimel Family Translational Imaging-Genetics
Research Lab, Research Imaging Centre, Campbell Family Mental Health Research
Institute, Centre for Addiction and Mental HealthToronto, ON, Canada; Department 
of Psychiatry, University of TorontoToronto, ON, Canada. (5)Cerebral Imaging
Centre, Douglas Mental Health University InstituteVerdun, QC, Canada; Department 
of Psychiatry, McGill UniversityMontreal, QC, Canada. (6)Cerebral Imaging Centre,
Douglas Mental Health University InstituteVerdun, QC, Canada; McGill Centre for
Studies in AgingMontreal, QC, Canada. (7)Institute of Biomaterials and Biomedical
Engineering, University of TorontoToronto, ON, Canada; Cerebral Imaging Centre,
Douglas Mental Health University InstituteVerdun, QC, Canada; Department of
Psychiatry, McGill UniversityMontreal, QC, Canada; Biological and Biomedical
Engineering, McGill UniversityMontreal, QC, Canada.

Recent advances in multi-atlas based algorithms address many of the previous
limitations in model-based and probabilistic segmentation methods. However, at
the label fusion stage, a majority of algorithms focus primarily on optimizing
weight-maps associated with the atlas library based on a theoretical objective
function that approximates the segmentation error. In contrast, we propose a
novel method-Autocorrecting Walks over Localized Markov Random Fields
(AWoL-MRF)-that aims at mimicking the sequential process of manual segmentation, 
which is the gold-standard for virtually all the segmentation methods. AWoL-MRF
begins with a set of candidate labels generated by a multi-atlas segmentation
pipeline as an initial label distribution and refines low confidence regions
based on a localized Markov random field (L-MRF) model using a novel sequential
inference process (walks). We show that AWoL-MRF produces state-of-the-art
results with superior accuracy and robustness with a small atlas library compared
to existing methods. We validate the proposed approach by performing hippocampal 
segmentations on three independent datasets: (1) Alzheimer's Disease Neuroimaging
Database (ADNI); (2) First Episode Psychosis patient cohort; and (3) A cohort of 
preterm neonates scanned early in life and at term-equivalent age. We assess the 
improvement in the performance qualitatively as well as quantitatively by
comparing AWoL-MRF with majority vote, STAPLE, and Joint Label Fusion methods.
AWoL-MRF reaches a maximum accuracy of 0.881 (dataset 1), 0.897 (dataset 2), and 
0.807 (dataset 3) based on Dice similarity coefficient metric, offering
significant performance improvements with a smaller atlas library (< 10) over
compared methods. We also evaluate the diagnostic utility of AWoL-MRF by
analyzing the volume differences per disease category in the ADNI1: Complete
Screening dataset. We have made the source code for AWoL-MRF public at:
https://github.com/CobraLab/AWoL-MRF.

DOI: 10.3389/fnins.2016.00325 
PMCID: PMC4949270
PMID: 27486386  [PubMed]


382. Bioinformatics. 2016 Nov 15;32(22):3461-3468. Epub 2016 Aug 2.

An efficient method to estimate the optimum regularization parameter in RLDA.

Bakir D(1), James AP(1), Zollanvari A(1).

Author information: 
(1)Department of Electrical and Electronics Engineering, Nazarbayev University,
Astana, 010000, Kazakhstan.

MOTIVATION: The biomarker discovery process in high-throughput genomic profiles
has presented the statistical learning community with a challenging problem,
namely learning when the number of variables is comparable or exceeding the
sample size. In these settings, many classical techniques including linear
discriminant analysis (LDA) falter. Poor performance of LDA is attributed to the 
ill-conditioned nature of sample covariance matrix when the dimension and sample 
size are comparable. To alleviate this problem, regularized LDA (RLDA) has been
classically proposed in which the sample covariance matrix is replaced by its
ridge estimate. However, the performance of RLDA depends heavily on the
regularization parameter used in the ridge estimate of sample covariance matrix.
RESULTS: We propose a range-search technique for efficient estimation of the
optimum regularization parameter. Using an extensive set of simulations based on 
synthetic and gene expression microarray data, we demonstrate the robustness of
the proposed technique to Gaussianity, an assumption used in developing the core 
estimator. We compare the performance of the technique in terms of accuracy and
efficiency with classical techniques for estimating the regularization parameter.
In terms of accuracy, the results indicate that the proposed method vastly
improves on similar techniques that use classical plug-in estimator. In that
respect, it is better or comparable to cross-validation-based search strategies
while, depending on the sample size and dimensionality, being tens to hundreds of
times faster to compute.
AVAILABILITY AND IMPLEMENTATION: The source code is available at
https://github.com/danik0411/optimum-rlda CONTACT:
amin.zollanvari@nu.edu.kzSupplementary information: Supplementary materials are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw506 
PMID: 27485443  [PubMed - in process]


383. J Biomol NMR. 2016 Aug;65(3-4):217-36. doi: 10.1007/s10858-016-0050-0. Epub 2016 
Aug 2.

Automated assignment of NMR chemical shifts based on a known structure and 4D
spectra.

Trautwein M(1), Fredriksson K(1), Möller HM(2), Exner TE(3).

Author information: 
(1)Institute of Pharmacy, Eberhard Karls Universität Tübingen, Auf der
Morgenstelle 8, 72076, Tübingen, Germany. (2)Institute of Chemistry, University
of Potsdam, Karl-Liebknecht-Str. 24-25, 14476, Potsdam OT Golm, Germany.
(3)Institute of Pharmacy, Eberhard Karls Universität Tübingen, Auf der
Morgenstelle 8, 72076, Tübingen, Germany. thomas.exner@uni-konstanz.de.

Apart from their central role during 3D structure determination of proteins the
backbone chemical shift assignment is the basis for a number of applications,
like chemical shift perturbation mapping and studies on the dynamics of proteins.
This assignment is not a trivial task even if a 3D protein structure is known and
needs almost as much effort as the assignment for structure prediction if
performed manually. We present here a new algorithm based solely on 4D
[(1)H,(15)N]-HSQC-NOESY-[(1)H,(15)N]-HSQC spectra which is able to assign a large
percentage of chemical shifts (73-82 %) unambiguously, demonstrated with proteins
up to a size of 250 residues. For the remaining residues, a small number of
possible assignments is filtered out. This is done by comparing distances in the 
3D structure to restraints obtained from the peak volumes in the 4D spectrum.
Using dead-end elimination, assignments are removed in which at least one of the 
restraints is violated. Including additional information from chemical shift
predictions, a complete unambiguous assignment was obtained for Ubiquitin and
95 % of the residues were correctly assigned in the 251 residue-long N-terminal
domain of enzyme I. The program including source code is available at
https://github.com/thomasexner/4Dassign .

DOI: 10.1007/s10858-016-0050-0 
PMID: 27484442  [PubMed - in process]


384. Sci Rep. 2016 Aug 2;6:30600. doi: 10.1038/srep30600.

Synthesis of Arbitrary Quantum Circuits to Topological Assembly.

Paler A(1), Devitt SJ(2), Fowler AG(3).

Author information: 
(1)Universitatea Transilvania, Facultatea de Matematică si Informatică, Braşov
500091, România. (2)Center for Emergent Matter Sciences, Riken, Saitama 351-0198,
Japan. (3)Google Inc., Santa Barbara, California 93117, USA.

Given a quantum algorithm, it is highly nontrivial to devise an efficient
sequence of physical gates implementing the algorithm on real hardware and
incorporating topological quantum error correction. In this paper, we present a
first step towards this goal, focusing on generating correct and simple
arrangements of topological structures that correspond to a given quantum circuit
and largely neglecting their efficiency. We detail the many challenges that will 
need to be tackled in the pursuit of efficiency. The software source code can be 
consulted at https://github.com/alexandrupaler/tqec.

DOI: 10.1038/srep30600 
PMCID: PMC4969756
PMID: 27481212  [PubMed - in process]


385. Mol Ecol Resour. 2016 Nov;16(6):1449-1454. doi: 10.1111/1755-0998.12578. Epub
2016 Aug 29.

angsd-wrapper: utilities for analysing next-generation sequencing data.

Durvasula A(1), Hoffman PJ(2), Kent TV(1), Liu C(2), Kono TJ(2), Morrell PL(3),
Ross-Ibarra J(4,)(5).

Author information: 
(1)Department of Plant Sciences, University of California, Davis, Davis, CA,
95616, USA. (2)Department of Agronomy and Plant Genetics, University of
Minnesota, St. Paul, MN, 55108, USA. (3)Department of Agronomy and Plant
Genetics, University of Minnesota, St. Paul, MN, 55108, USA. pmorrell@umn.edu.
(4)Department of Plant Sciences, University of California, Davis, Davis, CA,
95616, USA. rossibarra@ucdavis.edu. (5)Center for Population Biology and Genome
Center, University of California, Davis, Davis, CA, 95616, USA.
rossibarra@ucdavis.edu.

High-throughput sequencing has changed many aspects of population genetics,
molecular ecology and related fields, affecting both experimental design and data
analysis. The software package angsd allows users to perform a number of
population genetic analyses on high-throughput sequencing data. angsd uses
probabilistic approaches which can directly make use of genotype likelihoods;
thus, SNP calling is not required for comparative analyses. This takes advantage 
of all the sequencing data and produces more accurate results for samples with
low sequencing depth. Here, we present angsd-wrapper, a set of wrapper scripts
that provides a user-friendly interface for running angsd and visualizing
results. angsd-wrapper supports multiple types of analyses including estimates of
nucleotide sequence diversity neutrality tests, principal component analysis,
estimation of admixture proportions for individual samples and calculation of
statistics that quantify recent introgression. angsd-wrapper also provides
interactive graphing of angsd results to enhance data exploration. We demonstrate
the usefulness of angsd-wrapper by analysing resequencing data from populations
of wild and domesticated Zea. angsd-wrapper is freely available from
https://github.com/mojaveazure/angsd-wrapper.

© 2016 John Wiley & Sons Ltd.

DOI: 10.1111/1755-0998.12578 
PMID: 27480660  [PubMed - in process]


386. PLoS One. 2016 Aug 1;11(8):e0160334. doi: 10.1371/journal.pone.0160334.
eCollection 2016.

MetLab: An In Silico Experimental Design, Simulation and Analysis Tool for Viral 
Metagenomics Studies.

Norling M(1), Karlsson-Lindsjö OE(2,)(3,)(4), Gourlé H(2), Bongcam-Rudloff E(2), 
Hayer J(2).

Author information: 
(1)National Bioinformatics Infrastructure Sweden (NBIS), Uppsala University,
Uppsala, Sweden. (2)SLU Global Bioinformatics Centre, Department of Animal
Breeding and Genetics (HGEN), Swedish University of Agricultural Sciences (SLU), 
Uppsala, Sweden. (3)Department of Biomedical Sciences and Veterinary Public
Health (BVF), Swedish University of Agricultural Sciences (SLU), Uppsala, Sweden.
(4)The OIE Collaborating Centre for the Biotechnology-based Diagnosis of
Infectious Diseases in Veterinary Medicine, Uppsala, Sweden.

Metagenomics, the sequence characterization of all genomes within a sample, is
widely used as a virus discovery tool as well as a tool to study viral diversity 
of animals. Metagenomics can be considered to have three main steps; sample
collection and preparation, sequencing and finally bioinformatics. Bioinformatic 
analysis of metagenomic datasets is in itself a complex process, involving few
standardized methodologies, thereby hampering comparison of metagenomics studies 
between research groups. In this publication the new bioinformatics framework
MetLab is presented, aimed at providing scientists with an integrated tool for
experimental design and analysis of viral metagenomes. MetLab provides support in
designing the metagenomics experiment by estimating the sequencing depth needed
for the complete coverage of a species. This is achieved by applying a
methodology to calculate the probability of coverage using an adaptation of
Stevens' theorem. It also provides scientists with several pipelines aimed at
simplifying the analysis of viral metagenomes, including; quality control,
assembly and taxonomic binning. We also implement a tool for simulating
metagenomics datasets from several sequencing platforms. The overall aim is to
provide virologists with an easy to use tool for designing, simulating and
analyzing viral metagenomes. The results presented here include a benchmark
towards other existing software, with emphasis on detection of viruses as well as
speed of applications. This is packaged, as comprehensive software, readily
available for Linux and OSX users at https://github.com/norling/metlab.

DOI: 10.1371/journal.pone.0160334 
PMCID: PMC4968819
PMID: 27479078  [PubMed - in process]


387. BMC Bioinformatics. 2016 Jul 29;17(1):294. doi: 10.1186/s12859-016-1088-4.

RevEcoR: an R package for the reverse ecology analysis of microbiomes.

Cao Y(1,)(2), Wang Y(3), Zheng X(1), Li F(4), Bo X(5).

Author information: 
(1)Beijing Institute of Radiation Medicine, 27 Taiping Road, Beijing, 100850,
China. (2)Tianjin Key Laboratory of Risk Assessment and Control Technology for
Environment and Food Safety, Tianjin Institute of Health and Environmental
Medicine, Tianjin, 300050, China. (3)Department of Basic Courses, Army Officer
Academy, Hefei, 230031, China. (4)Beijing Institute of Radiation Medicine, 27
Taiping Road, Beijing, 100850, China. pittacus@gmail.com. (5)Beijing Institute of
Radiation Medicine, 27 Taiping Road, Beijing, 100850, China. boxc@bmi.ac.cn.

BACKGROUND: All species live in complex ecosystems. The structure and complexity 
of a microbial community reflects not only diversity and function, but also the
environment in which it occurs. However, traditional ecological methods can only 
be applied on a small scale and for relatively well-understood biological
systems. Recently, a graph-theory-based algorithm called the reverse ecology
approach has been developed that can analyze the metabolic networks of all the
species in a microbial community, and predict the metabolic interface between
species and their environment.
RESULTS: Here, we present RevEcoR, an R package and a Shiny Web application that 
implements the reverse ecology algorithm for determining microbe-microbe
interactions in microbial communities. This software allows users to obtain
large-scale ecological insights into species' ecology directly from
high-throughput metagenomic data. The software has great potential for
facilitating the study of microbiomes.
CONCLUSIONS: RevEcoR is open source software for the study of microbial community
ecology. The RevEcoR R package is freely available under the GNU General Public
License v. 2.0 at http://cran.r-project.org/web/packages/RevEcoR/ with the
vignette and typical usage examples, and the interactive Shiny web application is
available at http://yiluheihei.shinyapps.io/shiny-RevEcoR , or can be installed
locally with the source code accessed from
https://github.com/yiluheihei/shiny-RevEcoR .

DOI: 10.1186/s12859-016-1088-4 
PMCID: PMC4965897
PMID: 27473172  [PubMed - in process]


388. PLoS One. 2016 Jul 28;11(7):e0160227. doi: 10.1371/journal.pone.0160227.
eCollection 2016.

Analysis and Visualization Tool for Targeted Amplicon Bisulfite Sequencing on Ion
Torrent Sequencers.

Pabinger S(1), Ernst K(1), Pulverer W(1), Kallmeyer R(1), Valdes AM(2), Metrustry
S(2), Katic D(3), Nuzzo A(3), Kriegner A(3), Vierlinger K(1), Weinhaeusel A(1).

Author information: 
(1)Health & Environment Department, Molecular Diagnostics, AIT-Austrian Institute
of Technology, Vienna, Austria. (2)The Department of Twin Research & Genetic
Epidemiology, King's College London, St Thomas' Campus, London, United Kingdom.
(3)Platomics GmbH, Vienna, Austria.

Targeted sequencing of PCR amplicons generated from bisulfite deaminated DNA is a
flexible, cost-effective way to study methylation of a sample at single CpG
resolution and perform subsequent multi-target, multi-sample comparisons.
Currently, no platform specific protocol, support, or analysis solution is
provided to perform targeted bisulfite sequencing on a Personal Genome Machine
(PGM). Here, we present a novel tool, called TABSAT, for analyzing targeted
bisulfite sequencing data generated on Ion Torrent sequencers. The workflow
starts with raw sequencing data, performs quality assessment, and uses a tailored
version of Bismark to map the reads to a reference genome. The pipeline
visualizes results as lollipop plots and is able to deduce specific
methylation-patterns present in a sample. The obtained profiles are then
summarized and compared between samples. In order to assess the performance of
the targeted bisulfite sequencing workflow, 48 samples were used to generate 53
different Bisulfite-Sequencing PCR amplicons from each sample, resulting in 2,544
amplicon targets. We obtained a mean coverage of 282X using 1,196,822 aligned
reads. Next, we compared the sequencing results of these targets to the
methylation level of the corresponding sites on an Illumina 450k methylation
chip. The calculated average Pearson correlation coefficient of 0.91 confirms the
sequencing results with one of the industry-leading CpG methylation platforms and
shows that targeted amplicon bisulfite sequencing provides an accurate and
cost-efficient method for DNA methylation studies, e.g., to provide
platform-independent confirmation of Illumina Infinium 450k methylation data.
TABSAT offers a novel way to analyze data generated by Ion Torrent instruments
and can also be used with data from the Illumina MiSeq platform. It can be easily
accessed via the Platomics platform, which offers a web-based graphical user
interface along with sample and parameter storage. TABSAT is freely available
under a GNU General Public License version 3.0 (GPLv3) at
https://github.com/tadkeys/tabsat/ and http://demo.platomics.com/.

DOI: 10.1371/journal.pone.0160227 
PMCID: PMC4965138
PMID: 27467908  [PubMed - in process]


389. Bioinformatics. 2016 Nov 15;32(22):3504-3506. Epub 2016 Jul 27.

Motif comparison based on similarity of binding affinity profiles.

Lambert SA(1), Albu M(2), Hughes TR(1,)(2,)(3), Najafabadi HS(4,)(5).

Author information: 
(1)Department of Molecular Genetics, University of Toronto, Toronto, ON M5S 1A8, 
Canada. (2)Donnelly Centre for Cellular and Biomolecular Research, University of 
Toronto, Toronto, ON M5S 3E1, Canada. (3)Canadian Institutes for Advanced
Research, Toronto, ON M5G 1Z8, Canada. (4)McGill University and Génome Québec
Innovation Centre, Montreal, QC H3A 0G1, Canada. (5)Department of Human Genetics,
McGill University, Montreal, QC H3A 1B1, Canada.

Measuring motif similarity is essential for identifying functionally related
transcription factors (TFs) and RNA-binding proteins, and for annotating de novo 
motifs. Here, we describe Motif Similarity Based on Affinity of Targets (MoSBAT),
an approach for measuring the similarity of motifs by computing their affinity
profiles across a large number of random sequences. We show that MoSBAT
successfully associates de novo ChIP-seq motifs with their respective TFs,
accurately identifies motifs that are obtained from the same TF in different in
vitro assays, and quantitatively reflects the similarity of in vitro binding
preferences for pairs of TFs.AVAILABILITY AND IMPLEMENTATION: MoSBAT is available
as a webserver at mosbat.ccbr.utoronto.ca, and for download at
github.com/csglab/MoSBAT.
CONTACT: t.hughes@utoronto.ca or hamed.najafabadi@mcgill.caSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw489 
PMCID: PMC5181567 [Available on 2017-11-15]
PMID: 27466627  [PubMed - in process]


390. Bioinformatics. 2016 Nov 15;32(22):3507-3509. Epub 2016 Jul 27.

WALT: fast and accurate read mapping for bisulfite sequencing.

Chen H(1), Smith AD(1), Chen T(1).

Author information: 
(1)Molecular and Computational Biology, University of Southern California, Los
Angeles, CA 90089, USA.

Whole-genome bisulfite sequencing (WGBS) has emerged as the gold-standard
technique in genome-scale studies of DNA methylation. Mapping reads from WGBS
requires unique considerations that make the process more time-consuming than in 
other sequencing applications. Typical WGBS data sets contain several hundred
million reads, adding to this analysis challenge. We present the WALT tool for
mapping WGBS reads. WALT uses a strategy of hashing periodic spaced seeds, which 
leads to significant speedup compared with the most efficient methods currently
available. Although many existing WGBS mappers slow down with read length, WALT
improves in speed. Importantly, these speed gains do not sacrifice
accuracy.AVAILABILITY AND IMPLEMENTATION: WALT is available under the GPL v3
license, and downloadable from https://github.com/smithlabcode/walt.
CONTACT: andrewds@usc.edu or tingchen@usc.edu SUPPLEMENTARY INFORMATION:
Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw490 
PMCID: PMC5181568 [Available on 2017-11-15]
PMID: 27466624  [PubMed - in process]


391. Bioinformatics. 2016 Nov 15;32(22):3420-3427. Epub 2016 Jul 27.

Excess positional mutual information predicts both local and allosteric mutations
affecting beta lactamase drug resistance.

Cortina GA(1), Kasson PM(1).

Author information: 
(1)Departments of Biomedical Engineering and Molecular Physiology and Biological 
Physics, University of Virginia, Charlottesville, VA 22908, USA.

MOTIVATION: Bacterial resistance to antibiotics, particularly plasmid-encoded
resistance to beta lactam drugs, poses an increasing threat to human health.
Point mutations to beta-lactamase enzymes can greatly alter the level of
resistance conferred, but predicting the effects of such mutations has been
challenging due to the large combinatorial space involved and the subtle
relationships of distant residues to catalytic function. Therefore we desire an
information-theoretic metric to sensitively and robustly detect both local and
distant residues that affect substrate conformation and catalytic activity.
RESULTS: Here, we report the use of positional mutual information in multiple
microsecond-length molecular dynamics (MD) simulations to predict residues linked
to catalytic activity of the CTX-M9 beta lactamase. We find that motions of the
bound drug are relatively isolated from motions of the protein as a whole, which 
we interpret in the context of prior theories of catalysis. In order to robustly 
identify residues that are weakly coupled to drug motions but nonetheless affect 
catalysis, we utilize an excess mutual information metric. We predict 31 such
residues for the cephalosporin antibiotic cefotaxime. Nine of these have
previously been tested experimentally, and all decrease both enzyme rate
constants and empirical drug resistance. We prospectively validate our method by 
testing eight high-scoring mutations and eight low-scoring controls in bacteria. 
Six of eight predicted mutations decrease cefotaxime resistance greater than
2-fold, while only one control shows such an effect. The ability to prospectively
predict new variants affecting bacterial drug resistance is of great interest to 
clinical and epidemiological surveillance.
AVAILABILITY AND IMPLEMENTATION: Excess mutual information code is available at
https://github.com/kassonlab/positionalmi CONTACT: kasson@virginia.edu.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw492 
PMID: 27466622  [PubMed - in process]


392. Sci Rep. 2016 Jul 27;6:30330. doi: 10.1038/srep30330.

BATCH-GE: Batch analysis of Next-Generation Sequencing data for genome editing
assessment.

Boel A(1), Steyaert W(1), De Rocker N(1), Menten B(1), Callewaert B(1), De Paepe 
A(1), Coucke P(1), Willaert A(1).

Author information: 
(1)Center for Medical Genetics, Ghent University Hospital, Ghent, Belgium.

Targeted mutagenesis by the CRISPR/Cas9 system is currently revolutionizing
genetics. The ease of this technique has enabled genome engineering in-vitro and 
in a range of model organisms and has pushed experimental dimensions to
unprecedented proportions. Due to its tremendous progress in terms of speed, read
length, throughput and cost, Next-Generation Sequencing (NGS) has been
increasingly used for the analysis of CRISPR/Cas9 genome editing experiments.
However, the current tools for genome editing assessment lack flexibility and
fall short in the analysis of large amounts of NGS data. Therefore, we designed
BATCH-GE, an easy-to-use bioinformatics tool for batch analysis of NGS-generated 
genome editing data, available from
https://github.com/WouterSteyaert/BATCH-GE.git. BATCH-GE detects and reports
indel mutations and other precise genome editing events and calculates the
corresponding mutagenesis efficiencies for a large number of samples in parallel.
Furthermore, this new tool provides flexibility by allowing the user to adapt a
number of input variables. The performance of BATCH-GE was evaluated in two
genome editing experiments, aiming to generate knock-out and knock-in zebrafish
mutants. This tool will not only contribute to the evaluation of
CRISPR/Cas9-based experiments, but will be of use in any genome editing
experiment and has the ability to analyze data from every organism with a
sequenced genome.

DOI: 10.1038/srep30330 
PMCID: PMC4962088
PMID: 27461955  [PubMed - in process]


393. Genome Med. 2016 Jul 27;8(1):80. doi: 10.1186/s13073-016-0335-7.

Single-cell TCRseq: paired recovery of entire T-cell alpha and beta chain
transcripts in T-cell receptors from single-cell RNAseq.

Redmond D(1,)(2), Poran A(2), Elemento O(3,)(4).

Author information: 
(1)Tri-Institutional Training Program in Computational Biology and Medicine, New 
York, NY, USA. (2)Institute for Computational Biomedicine & Institute for
Precision Medicine, Weill Cornell Medicine, New York, NY, USA.
(3)Tri-Institutional Training Program in Computational Biology and Medicine, New 
York, NY, USA. ole2001@med.cornell.edu. (4)Institute for Computational
Biomedicine & Institute for Precision Medicine, Weill Cornell Medicine, New York,
NY, USA. ole2001@med.cornell.edu.

Accurate characterization of the repertoire of the T-cell receptor (TCR) alpha
and beta chains is critical to understanding adaptive immunity. Such
characterization has many applications across such fields as vaccine development 
and response, clone-tracking in cancer, and immunotherapy. Here we present a new 
methodology called single-cell TCRseq (scTCRseq) for the identification and
assembly of full-length rearranged V(D)J T-cell receptor sequences from
paired-end single-cell RNA sequencing reads. The method allows accurate
identification of the V(D)J rearrangements for each individual T-cell and has the
novel ability to recover paired alpha and beta segments. Source code is available
at https://github.com/ElementoLab/scTCRseq .

DOI: 10.1186/s13073-016-0335-7 
PMCID: PMC4962388
PMID: 27460926  [PubMed - in process]


394. BMC Bioinformatics. 2016 Jul 19;17 Suppl 9:267. doi: 10.1186/s12859-016-1128-0.

Parallel algorithms for large-scale biological sequence alignment on Xeon-Phi
based clusters.

Lan H(1), Chan Y(1), Xu K(1), Schmidt B(2), Peng S(3), Liu W(4).

Author information: 
(1)School of Computer Science and Technology, Shandong University, Shunhua Road
1500, Jinan, Shandong, China. (2)Johannes Gutenberg University, Mainz, Germany.
(3)School of Computer Science, National University of Defense Technology,
Changsha, Hunan, China. (4)School of Computer Science and Technology, Shandong
University, Shunhua Road 1500, Jinan, Shandong, China. weiguo.liu@sdu.edu.cn.

BACKGROUND: Computing alignments between two or more sequences are common
operations frequently performed in computational molecular biology. The
continuing growth of biological sequence databases establishes the need for their
efficient parallel implementation on modern accelerators.
RESULTS: This paper presents new approaches to high performance biological
sequence database scanning with the Smith-Waterman algorithm and the first stage 
of progressive multiple sequence alignment based on the ClustalW heuristic on a
Xeon Phi-based compute cluster. Our approach uses a three-level parallelization
scheme to take full advantage of the compute power available on this type of
architecture; i.e. cluster-level data parallelism, thread-level coarse-grained
parallelism, and vector-level fine-grained parallelism. Furthermore, we
re-organize the sequence datasets and use Xeon Phi shuffle operations to improve 
I/O efficiency.
CONCLUSIONS: Evaluations show that our method achieves a peak overall performance
up to 220 GCUPS for scanning real protein sequence databanks on a single node
consisting of two Intel E5-2620 CPUs and two Intel Xeon Phi 7110P cards. It also 
exhibits good scalability in terms of sequence length and size, and number of
compute nodes for both database scanning and multiple sequence alignment.
Furthermore, the achieved performance is highly competitive in comparison to
optimized Xeon Phi and GPU implementations. Our implementation is available at
https://github.com/turbo0628/LSDBS-mpi .

DOI: 10.1186/s12859-016-1128-0 
PMCID: PMC4959381
PMID: 27455061  [PubMed - in process]


395. Mol Ecol Resour. 2016 Jul 25. doi: 10.1111/1755-0998.12576. [Epub ahead of print]

discomark: Nuclear marker discovery from orthologous sequences using draft genome
data.

Rutschmann S(1,)(2,)(3), Detering H(1,)(2,)(3), Simon S(4,)(5), Fredslund J(6),
Monaghan MT(1,)(2).

Author information: 
(1)Leibniz-Institute of Freshwater Ecology and Inland Fisheries (IGB),
Müggelseedamm 301, 12587, Berlin, Germany. (2)Berlin Center for Genomics in
Biodiversity Research, Königin-Luise-Straße 6-8, 14195, Berlin, Germany.
(3)Department of Biochemistry, Genetics and Immunology, University of Vigo,
36310, Vigo, Spain. (4)Sackler Institute for Comparative Genomics, American
Museum of Natural History, Central Park West and 79th St., New York, NY, 10024,
USA. (5)Biosystematics Group, Wageningen University, Droevendaalsesteeg 1, 6708
PB Wageningen, The Netherlands. (6)Alexandra Institute, Åbogade 34, 8200, Aarhus,
Denmark.

High-throughput sequencing has laid the foundation for fast and cost-effective
development of phylogenetic markers. Here we present the program discomark, which
streamlines the development of nuclear DNA (nDNA) markers from whole-genome (or
whole-transcriptome) sequencing data, combining local alignment, alignment
trimming, reference mapping and primer design based on multiple sequence
alignments to design primer pairs from input orthologous sequences. To
demonstrate the suitability of discomark, we designed markers for two groups of
species, one consisting of closely related species and one group of distantly
related species. For the closely related members of the species complex of Cloeon
dipterum s.l. (Insecta, Ephemeroptera), the program discovered a total of 78
markers. Among these, we selected eight markers for amplification and Sanger
sequencing. The exon sequence alignments (2526 base pairs) were used to
reconstruct a well-supported phylogeny and to infer clearly structured haplotype 
networks. For the distantly related species, we designed primers for the insect
order Ephemeroptera, using available genomic data from four sequenced species. We
developed primer pairs for 23 markers that are designed to amplify across several
families. The discomark program will enhance the development of new nDNA markers 
by providing a streamlined, automated approach to perform genome-scale scans for 
phylogenetic markers. The program is written in Python, released under a public
licence (GNU GPL version 2), and together with a manual and example data set
available at: https://github.com/hdetering/discomark.

© 2016 John Wiley & Sons Ltd.

DOI: 10.1111/1755-0998.12576 
PMID: 27454666  [PubMed - as supplied by publisher]


396. Front Neuroinform. 2016 Jun 22;10:22. doi: 10.3389/fninf.2016.00022. eCollection 
2016.

Python Executable Script for Estimating Two Effective Parameters to Individualize
Brain-Computer Interfaces: Individual Alpha Frequency and Neurophysiological
Predictor.

Alonso-Valerdi LM(1).

Author information: 
(1)Escuela de Ingeniería y Ciencias, Tecnológico de Monterrey Mexico City,
Mexico.

A brain-computer interface (BCI) aims to establish communication between the
human brain and a computing system so as to enable the interaction between an
individual and his environment without using the brain output pathways.
Individuals control a BCI system by modulating their brain signals through mental
tasks (e.g., motor imagery or mental calculation) or sensory stimulation (e.g.,
auditory, visual, or tactile). As users modulate their brain signals at different
frequencies and at different levels, the appropriate characterization of those
signals is necessary. The modulation of brain signals through mental tasks is
furthermore a skill that requires training. Unfortunately, not all the users
acquire such skill. A practical solution to this problem is to assess the user
probability of controlling a BCI system. Another possible solution is to set the 
bandwidth of the brain oscillations, which is highly sensitive to the users' age,
sex and anatomy. With this in mind, NeuroIndex, a Python executable script,
estimates a neurophysiological prediction index and the individual alpha
frequency (IAF) of the user in question. These two parameters are useful to
characterize the user EEG signals, and decide how to go through the complex
process of adapting the human brain and the computing system on the basis of
previously proposed methods. NeuroIndeX is not only the implementation of those
methods, but it also complements the methods each other and provides an
alternative way to obtain the prediction parameter. However, an important
limitation of this application is its dependency on the IAF value, and some
results should be interpreted with caution. The script along with some
electroencephalographic datasets are available on a GitHub repository in order to
corroborate the functionality and usability of this application.

DOI: 10.3389/fninf.2016.00022 
PMCID: PMC4916201
PMID: 27445783  [PubMed]


397. Math Biosci. 2016 Jul 18. pii: S0025-5564(16)30083-9. doi:
10.1016/j.mbs.2016.07.001. [Epub ahead of print]

A tutorial introduction to Bayesian inference for stochastic epidemic models
using Approximate Bayesian Computation.

Kypraios T(1), Neal P(2), Prangle D(3).

Author information: 
(1)School of Mathematical Sciences, University of Nottingham, UK. Electronic
address: theodore.kypraios@nottingham.ac.uk. (2)Department of Mathematics and
Statistics, Lancaster University, UK. (3)School of Mathematics and Statistics,
Newcastle University, UK.

Likelihood-based inference for disease outbreak data can be very challenging due 
to the inherent dependence of the data and the fact that they are usually
incomplete. In this paper we review recent Approximate Bayesian Computation (ABC)
methods for the analysis of such data by fitting to them stochastic epidemic
models without having to calculate the likelihood of the observed data. We
consider both non-temporal and temporal-data and illustrate the methods with a
number of examples featuring different models and datasets. In addition, we
present extensions to existing algorithms which are easy to implement and provide
an improvement to the existing methodology. Finally, R code to implement the
algorithms presented in the paper is available on
https://github.com/kypraios/epiABC.

Copyright © 2016 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.mbs.2016.07.001 
PMID: 27444577  [PubMed - as supplied by publisher]


398. Appl Plant Sci. 2016 Jul 12;4(7). pii: apps.1600016. doi: 10.3732/apps.1600016.
eCollection 2016.

HybPiper: Extracting coding sequence and introns for phylogenetics from
high-throughput sequencing reads using target enrichment.

Johnson MG(1), Gardner EM(2), Liu Y(3), Medina R(3), Goffinet B(3), Shaw AJ(4),
Zerega NJ(2), Wickett NJ(2).

Author information: 
(1)Chicago Botanic Garden, 1000 Lake Cook Road, Glencoe, Illinois 60022 USA.
(2)Chicago Botanic Garden, 1000 Lake Cook Road, Glencoe, Illinois 60022 USA;
Plant Biology and Conservation, Northwestern University, 2205 Tech Drive,
Evanston, Illinois 60208 USA. (3)Department of Ecology and Evolutionary Biology, 
University of Connecticut, 75 N. Eagleville Road, Storrs, Connecticut 06269 USA. 
(4)Department of Biology, Duke University, Box 90338, Durham, North Carolina
27708 USA.

PREMISE OF THE STUDY: Using sequence data generated via target enrichment for
phylogenetics requires reassembly of high-throughput sequence reads into loci,
presenting a number of bioinformatics challenges. We developed HybPiper as a
user-friendly platform for assembly of gene regions, extraction of exon and
intron sequences, and identification of paralogous gene copies. We test HybPiper 
using baits designed to target 333 phylogenetic markers and 125 genes of
functional significance in Artocarpus (Moraceae).
METHODS AND RESULTS: HybPiper implements parallel execution of sequence assembly 
in three phases: read mapping, contig assembly, and target sequence extraction.
The pipeline was able to recover nearly complete gene sequences for all genes in 
22 species of Artocarpus. HybPiper also recovered more than 500 bp of nontargeted
intron sequence in over half of the phylogenetic markers and identified
paralogous gene copies in Artocarpus.
CONCLUSIONS: HybPiper was designed for Linux and Mac OS X and is freely available
at https://github.com/mossmatters/HybPiper.

DOI: 10.3732/apps.1600016 
PMCID: PMC4948903
PMID: 27437175  [PubMed]


399. Bioinformatics. 2016 Nov 15;32(22):3428-3434. Epub 2016 Jul 19.

Variance adaptive shrinkage (vash): flexible empirical Bayes estimation of
variances.

Lu M(1), Stephens M(1,)(2).

Author information: 
(1)Department of Statistics, University of Chicago, Chicago, 60637, USA.
(2)Department of Human Genetics, University of Chicago, Chicago, 60637, USA.

MOTIVATION: Genomic studies often involve estimation of variances of thousands of
genes (or other genomic units) from just a few measurements on each. For example,
variance estimation is an important step in gene expression analyses aimed at
identifying differentially expressed genes. A common approach to this problem is 
to use an Empirical Bayes (EB) method that assumes the variances among genes
follow an inverse-gamma distribution. This distributional assumption is
relatively inflexible; for example, it may not capture 'outlying' genes whose
variances are considerably bigger than usual. Here we describe a more flexible EB
method, capable of capturing a much wider range of distributions. Indeed, the
main assumption is that the distribution of the variances is unimodal (or, as an 
alternative, that the distribution of the precisions is unimodal). We argue that 
the unimodal assumption provides an attractive compromise between flexibility,
computational tractability and statistical efficiency.
RESULTS: We show that this more flexible approach provides competitive
performance with existing methods when the variances truly come from an
inverse-gamma distribution, and can outperform them when the distribution of the 
variances is more complex. In analyses of several human gene expression datasets 
from the Genotype Tissues Expression consortium, we find that our more flexible
model often fits the data appreciably better than the single inverse gamma
distribution. At the same time we find that in these data this improved model fit
leads to only small improvements in variance estimates and detection of
differentially expressed genes.
AVAILABILITY AND IMPLEMENTATION: Our methods are implemented in an R package
vashr available from http://github.com/mengyin/vashr CONTACT:
mstephens@uchicago.eduSupplementary information: Supplementary data are available
at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw483 
PMCID: PMC5181563 [Available on 2017-11-15]
PMID: 27436563  [PubMed - in process]


400. Bioinformatics. 2016 Nov 15;32(22):3516-3518. Epub 2016 Jul 19.

PReFerSim: fast simulation of demography and selection under the Poisson Random
Field model.

Ortega-Del Vecchyo D(1), Marsden CD(2), Lohmueller KE(1,)(2,)(3).

Author information: 
(1)Interdepartmental Program in Bioinformatics, University of California, Los
Angeles, CA 90095, USA. (2)Department of Ecology and Evolutionary Biology,
University of California, Los Angeles, CA 90095, USA. (3)Department of Human
Genetics, David Geffen School of Medicine, University of California, Los Angeles,
CA 90095, USA.

The Poisson Random Field (PRF) model has become an important tool in population
genetics to study weakly deleterious genetic variation under complicated
demographic scenarios. Currently, there are no freely available software
applications that allow simulation of genetic variation data under this model.
Here we present PReFerSim, an ANSI C program that performs forward simulations
under the PRF model. PReFerSim models changes in population size, arbitrary
amounts of inbreeding, dominance and distributions of selective effects. Users
can track summaries of genetic variation over time and output trajectories of
selected alleles.AVAILABILITY AND IMPLEMENTATION: PReFerSim is freely available
at: https://github.com/LohmuellerLab/PReFerSim CONTACT:
klohmueller@ucla.eduSupplementary information: Supplementary data are available
at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw478 
PMCID: PMC5181561 [Available on 2017-11-15]
PMID: 27436562  [PubMed - in process]


401. BMC Genomics. 2016 Jul 19;17:501. doi: 10.1186/s12864-016-2647-9.

Interpretable per case weighted ensemble method for cancer associations.

Jalali A(1), Pfeifer N(2).

Author information: 
(1)Department of Computational Biology and Applied Algorithmics, Max Planck
Institute for Informatics, Campus E1 4, Saarbrücken, 66123, Germany.
ajalali@mpi-inf.mpg.de. (2)Department of Computational Biology and Applied
Algorithmics, Max Planck Institute for Informatics, Campus E1 4, Saarbrücken,
66123, Germany.

BACKGROUND: Molecular measurements from cancer patients such as gene expression
and DNA methylation can be influenced by several external factors. This makes it 
harder to reproduce the exact values of measurements coming from different
laboratories. Furthermore, some cancer types are very heterogeneous, meaning that
there might be different underlying causes for the same type of cancer among
different individuals. If a model does not take potential biases in the data into
account, this can lead to problems when trying to predict the stage of a certain 
cancer type. This is especially true when these biases differ between the
training and test set.
RESULTS: We introduce a method that can estimate this bias on a per-feature level
and incorporate calculated feature confidences into a weighted combination of
classifiers with disjoint feature sets. In this way, the method provides a
prediction that is adjusted for the potential biases on a per-patient basis,
providing a personalized prediction for each test patient. The new method
achieves state-of-the-art performance on many different cancer data sets with
measured DNA methylation or gene expression. Moreover, we show how to visualize
the learned classifiers to display interesting associations with the target
label. Applied to a leukemia data set, our method finds several ribosomal
proteins associated with the risk group, which might be interesting targets for
follow-up studies. This discovery supports the hypothesis that the ribosomes are 
a new frontier in genadaptivelearninge regulation.
CONCLUSION: We introduce a new method for robust prediction of phenotypes from
molecular measurements such as DNA methylation or gene expression. Furthermore,
the visualization capabilities enable exploratory analysis on the learnt
dependencies and pave the way for a personalized prediction of phenotypes. The
software is available under GPL2+ from
https://github.com/adrinjalali/Network-Classifier/tree/v1.0 .

DOI: 10.1186/s12864-016-2647-9 
PMCID: PMC4952276
PMID: 27435615  [PubMed - in process]


402. Mol Ecol Resour. 2017 Jan;17(1):12-18. doi: 10.1111/1755-0998.12569. Epub 2016
Aug 11.

genepopedit: a simple and flexible tool for manipulating multilocus molecular
data in R.

Stanley RR(1,)(2), Jeffery NW(3), Wringe BF(1,)(3), DiBacco C(1), Bradbury IR(3).

Author information: 
(1)Bedford Institute of Oceanography, Dartmouth, Nova Scotia, Canada.
(2)Department of Computer Science, Dalhousie University, Halifax, Nova Scotia,
Canada. (3)Northwest Atlantic Fisheries Science Centre, St. John's, Newfoundland,
Canada.

Advances in genetic sequencing technologies and techniques have made large,
genome-wide data sets comprised of hundreds or even thousands of individuals and 
loci the norm rather than the exception even for nonmodel organisms. While such
data present new opportunities for evaluating population structure and
demographic processes, the large size of these genomic data sets brings new
computational challenges for researchers needing to parse, convert and manipulate
data often into a variety of software-specific formats required of genomic
analyses. We developed genepopedit as a flexible tool for the manipulation of
multilocus molecular data sets. Functionality can be divided among diagnostic-,
manipulation-, sampling-, simulation-, and transformation-based tools. Metadata
from large genomic data sets can be efficiently extracted, without the need to
view data in a text-editing program. genepopedit provides tools to manipulate
loci, individual samples and populations included in genomic data sets, in
addition to the ability to convert directly to a variety of software formats.
Functions are compiled as an R package, which can integrate into existing
analysis workflows. Importantly, genepopedit provides a simple yet robust
code-based tool for repeatable genomic data manipulation, which has been proven
to be stable for data sets in excess of 200 000 SNPs. The latest version of the
package and associated documentation are available on Github
(github.com/rystanley/genepopedit).

© 2016 John Wiley & Sons Ltd.

DOI: 10.1111/1755-0998.12569 
PMID: 27434661  [PubMed - in process]


403. J Struct Biol. 2016 Sep;195(3):325-36. doi: 10.1016/j.jsb.2016.07.006. Epub 2016 
Jul 14.

DeepPicker: A deep learning approach for fully automated particle picking in
cryo-EM.

Wang F(1), Gong H(2), Liu G(3), Li M(3), Yan C(4), Xia T(5), Li X(6), Zeng J(7).

Author information: 
(1)School of Electronic Information and Communications, Huazhong University of
Science and Technology, Wuhan 430074, China. (2)Institute for Interdisciplinary
Information Sciences, Tsinghua University, Beijing 100084, China. (3)School of
Life Sciences, Tsinghua University, Beijing 100084, China; Beijing Advanced
Innovation Center for Structure Biology, Tsinghua University, Beijing 100084,
China. (4)School of Life Sciences, Tsinghua University, Beijing 100084, China;
Tsinghua-Peking Joint Center for Life Sciences, Tsinghua University, Beijing
100084, China. (5)School of Electronic Information and Communications, Huazhong
University of Science and Technology, Wuhan 430074, China. Electronic address:
isutian@gmail.com. (6)School of Life Sciences, Tsinghua University, Beijing
100084, China; Beijing Advanced Innovation Center for Structure Biology, Tsinghua
University, Beijing 100084, China; Tsinghua-Peking Joint Center for Life
Sciences, Tsinghua University, Beijing 100084, China. Electronic address:
lixueming@mail.tsinghua.edu.cn. (7)Institute for Interdisciplinary Information
Sciences, Tsinghua University, Beijing 100084, China. Electronic address:
zengjy321@tsinghua.edu.cn.

Particle picking is a time-consuming step in single-particle analysis and often
requires significant interventions from users, which has become a bottleneck for 
future automated electron cryo-microscopy (cryo-EM). Here we report a deep
learning framework, called DeepPicker, to address this problem and fill the
current gaps toward a fully automated cryo-EM pipeline. DeepPicker employs a
novel cross-molecule training strategy to capture common features of particles
from previously-analyzed micrographs, and thus does not require any human
intervention during particle picking. Tests on the recently-published cryo-EM
data of three complexes have demonstrated that our deep learning based scheme can
successfully accomplish the human-level particle picking process and identify a
sufficient number of particles that are comparable to those picked manually by
human experts. These results indicate that DeepPicker can provide a practically
useful tool to significantly reduce the time and manual effort spent in
single-particle analysis and thus greatly facilitate high-resolution cryo-EM
structure determination. DeepPicker is released as an open-source program, which 
can be downloaded from https://github.com/nejyeah/DeepPicker-python.

Copyright © 2016 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.jsb.2016.07.006 
PMID: 27424268  [PubMed - in process]


404. PLoS Comput Biol. 2016 Jul 14;12(7):e1004947. doi: 10.1371/journal.pcbi.1004947. 
eCollection 2016.

Ten Simple Rules for Taking Advantage of Git and GitHub.

Perez-Riverol Y(1), Gatto L(2), Wang R(1), Sachsenberg T(3), Uszkoreit J(4),
Leprevost Fda V(5), Fufezan C(6), Ternent T(1), Eglen SJ(7), Katz DS(8), Pollard 
TJ(9), Konovalov A(10), Flight RM(11), Blin K(12), Vizcaíno JA(1).

Author information: 
(1)European Molecular Biology Laboratory, European Bioinformatics Institute
(EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, Cambridge, United Kingdom.
(2)Computational Proteomics Unit, Cambridge Systems Biology Centre, University of
Cambridge, Cambridge, United Kingdom. (3)Applied Bioinformatics and Department of
Computer Science, University of Tübingen, Tübingen, Germany. (4)Medizinisches
Proteom-Center, Ruhr-Universität Bochum, Bochum, Germany. (5)Department of
Pathology, University of Michigan, Ann Arbor, Michigan, United States of America.
(6)Institute of Plant Biology and Biotechnology, University of Münster, Münster, 
Germany. (7)Centre for Mathematical Sciences, University of Cambridge, Cambridge,
United Kingdom. (8)National Center for Supercomputing Applications and Graduate
School of Library and Information Science, University of Illinois, Urbana,
Illinois, United States of America. (9)MIT Laboratory for Computational
Physiology, Institute for Medical Engineering and Science, Massachusetts
Institute of Technology, Cambridge, Massachusetts, United States of America.
(10)Centre for Interdisciplinary Research in Computational Algebra, University of
St Andrews, St Andrews, United Kingdom. (11)Department of Molecular Biology and
Biochemistry, Markey Cancer Center, Resource Center for Stable Isotope-Resolved
Metabolomics, University of Kentucky, Lexington, Kentucky, United States of
America. (12)The Novo Nordisk Foundation Center for Biosustainability, Technical 
University of Denmark, Hørsholm, Denmark.

DOI: 10.1371/journal.pcbi.1004947 
PMCID: PMC4945047
PMID: 27415786  [PubMed - in process]


405. PLoS One. 2016 Jul 14;11(7):e0159128. doi: 10.1371/journal.pone.0159128.
eCollection 2016.

The Widespread Prevalence and Functional Significance of Silk-Like Structural
Proteins in Metazoan Biological Materials.

McDougall C(1), Woodcroft BJ(2), Degnan BM(1).

Author information: 
(1)School of Biological Sciences, The University of Queensland, Brisbane,
Queensland, Australia. (2)Australian Centre for Ecogenomics, The University of
Queensland, Brisbane, Queensland, Australia.

In nature, numerous mechanisms have evolved by which organisms fabricate
biological structures with an impressive array of physical characteristics. Some 
examples of metazoan biological materials include the highly elastic byssal
threads by which bivalves attach themselves to rocks, biomineralized structures
that form the skeletons of various animals, and spider silks that are renowned
for their exceptional strength and elasticity. The remarkable properties of
silks, which are perhaps the best studied biological materials, are the result of
the highly repetitive, modular, and biased amino acid composition of the proteins
that compose them. Interestingly, similar levels of modularity/repetitiveness and
similar bias in amino acid compositions have been reported in proteins that are
components of structural materials in other organisms, however the exact nature
and extent of this similarity, and its functional and evolutionary relevance, is 
unknown. Here, we investigate this similarity and use sequence features common to
silks and other known structural proteins to develop a bioinformatics-based
method to identify similar proteins from large-scale transcriptome and
whole-genome datasets. We show that a large number of proteins identified using
this method have roles in biological material formation throughout the animal
kingdom. Despite the similarity in sequence characteristics, most of the
silk-like structural proteins (SLSPs) identified in this study appear to have
evolved independently and are restricted to a particular animal lineage. Although
the exact function of many of these SLSPs is unknown, the apparent independent
evolution of proteins with similar sequence characteristics in divergent lineages
suggests that these features are important for the assembly of biological
materials. The identification of these characteristics enable the generation of
testable hypotheses regarding the mechanisms by which these proteins assemble and
direct the construction of biological materials with diverse morphologies. The
SilkSlider predictor software developed here is available at
https://github.com/wwood/SilkSlider.

DOI: 10.1371/journal.pone.0159128 
PMCID: PMC4944945
PMID: 27415783  [PubMed - in process]


406. Bioinformatics. 2016 Nov 15;32(22):3513-3515. Epub 2016 Jul 13.

LAMPLINK: detection of statistically significant SNP combinations from GWAS data.

Terada A(1,)(2,)(3), Yamada R(4), Tsuda K(2,)(3,)(5), Sese J(3,)(6).

Author information: 
(1)PRESTO, Japan Science and Technology Agency, Saitama 332-0012, Japan.
(2)Department of Computational Biology and Medical Science, Graduate School of
Frontier Sciences, The University of Tokyo, Chiba 277-8561, Japan.
(3)Biotechnology Research Institute for Drug Discovery, National Institute of
Advanced Industrial Science and Technology (AIST), Tokyo 135-0064, Japan.
(4)Center for Genomic Medicine, Graduate School of Medicine, Kyoto University,
Kyoto, 606-8507 Japan. (5)Center for Materials Research by Information
Integration, NIMS, Ibaraki, 305-0047 Japan. (6)Artificial Intelligence Research
Center, National Institute of Advanced Industrial Science and Technology (AIST), 
Tokyo 135-0064, Japan.

One of the major issues in genome-wide association studies is to solve the
missing heritability problem. While considering epistatic interactions among
multiple SNPs may contribute to solving this problem, existing software cannot
detect statistically significant high-order interactions. We propose software
named LAMPLINK, which employs a cutting-edge method to enumerate statistically
significant SNP combinations from genome-wide case-control data. LAMPLINK is
implemented as a set of additional functions to PLINK, and hence existing
procedures with PLINK can be applicable. Applied to the 1000 Genomes Project
data, LAMPLINK detected a combination of five SNPs that are statistically
significantly accumulated in the Japanese population.AVAILABILITY AND
IMPLEMENTATION: LAMPLINK is available at http://a-terada.github.io/lamplink/
CONTACT: terada@cbms.k.u-tokyo.ac.jp or sese.jun@aist.go.jpSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw418 
PMCID: PMC5181558
PMID: 27412093  [PubMed - in process]


407. Bioinformatics. 2016 Nov 15;32(22):3519-3521. Epub 2016 Jul 13.

BioPartsDB: a synthetic biology workflow web-application for education and
research.

Stracquadanio G(1), Yang K(1), Boeke JD(2), Bader JS(1).

Author information: 
(1)Department of Biomedical Engineering and High-Throughput Biology Center, Johns
Hopkins University, Baltimore, MD 21218, USA. (2)Institute for Systems Genetics
and Department of Biochemistry and Molecular Pharmacology, NYU Langone Medical
Center, New York, NY 10016, USA.

Synthetic biology has become a widely used technology, and expanding applications
in research, education and industry require progress tracking for team-based DNA 
synthesis projects. Although some vendors are beginning to supply multi-kilobase 
sequence-verified constructs, synthesis workflows starting with short oligos
remain important for cost savings and pedagogical benefit. We developed
BioPartsDB as an open source, extendable workflow management system for synthetic
biology projects with entry points for oligos and larger DNA constructs and
ending with sequence-verified clones.AVAILABILITY AND IMPLEMENTATION: BioPartsDB 
is released under the MIT license and available for download at
https://github.com/baderzone/biopartsdb Additional documentation and video
tutorials are available at https://github.com/baderzone/biopartsdb/wiki An Amazon
Web Services image is available from the AWS Market Place (ami-a01d07c8).
CONTACT: joel.bader@jhu.edu.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw394 
PMCID: PMC5181553
PMID: 27412090  [PubMed - in process]


408. Bioinformatics. 2016 Nov 15;32(22):3498-3500. Epub 2016 Jul 13.

sBWT: memory efficient implementation of the hardware-acceleration-friendly
Schindler transform for the fast biological sequence mapping.

Chang CH(1,)(2), Chou MT(1), Wu YC(3), Hong TW(1), Li YL(1), Yang CH(3), Hung
JH(1,)(2,)(4).

Author information: 
(1)Institute of Bioinformatics and Systems Biology. (2)Institute of Biomedical
Engineering. (3)Department of Electrical Engineering, National Taiwan University,
Taipei, Taiwan. (4)Department of Biological Science and Technology, National
Chiao Tung University, Hsin-Chu, Taiwan.

MOTIVATION: The Full-text index in Minute space (FM-index) derived from the
Burrows-Wheeler transform (BWT) is broadly used for fast string matching in large
genomes or a huge set of sequencing reads. Several graphic processing unit (GPU) 
accelerated aligners based on the FM-index have been proposed recently; however, 
the construction of the index is still handled by central processing unit (CPU), 
only parallelized in data level (e.g. by performing blockwise suffix sorting in
GPU), or not scalable for large genomes.
RESULTS: To fulfill the need for a more practical, hardware-parallelizable
indexing and matching approach, we herein propose sBWT based on a BWT variant
(i.e. Schindler transform) that can be built with highly simplified
hardware-acceleration-friendly algorithms and still suffices accurate and fast
string matching in repetitive references. In our tests, the implementation
achieves significant speedups in indexing and searching compared with other
BWT-based tools and can be applied to a variety of domains.
AVAILABILITY AND IMPLEMENTATION: sBWT is implemented in C ++ with CPU-only and
GPU-accelerated versions. sBWT is open-source software and is available at
http://jhhung.github.io/sBWT/Supplementary information: Supplementary data are
available at Bioinformatics online.
CONTACT: chyee@ntu.edu.tw or jhhung@nctu.edu.tw (also juihunghung@gmail.com).

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw419 
PMID: 27412087  [PubMed - in process]


409. J Proteome Res. 2016 Aug 5;15(8):2749-59. doi: 10.1021/acs.jproteome.6b00290.
Epub 2016 Jul 22.

Dynamic Bayesian Network for Accurate Detection of Peptides from Tandem Mass
Spectra.

Halloran JT(1), Bilmes JA(1), Noble WS(2).

Author information: 
(1)Department of Electrical Engineering, University of Washington , Seattle
98195, Washington, United States. (2)Department of Genome Sciences, University of
Washington , Seattle 98195, Washington, United States.

A central problem in mass spectrometry analysis involves identifying, for each
observed tandem mass spectrum, the corresponding generating peptide. We present a
dynamic Bayesian network (DBN) toolkit that addresses this problem by using a
machine learning approach. At the heart of this toolkit is a DBN for Rapid
Identification (DRIP), which can be trained from collections of high-confidence
peptide-spectrum matches (PSMs). DRIP's score function considers fragment ion
matches using Gaussians rather than fixed fragment-ion tolerances and also finds 
the optimal alignment between the theoretical and observed spectrum by
considering all possible alignments, up to a threshold that is controlled using a
beam-pruning algorithm. This function not only yields state-of-the art database
search accuracy but also can be used to generate features that significantly
boost the performance of the Percolator postprocessor. The DRIP software is built
upon a general purpose DBN toolkit (GMTK), thereby allowing a wide variety of
options for user-specific inference tasks as well as facilitating easy
modifications to the DRIP model in future work. DRIP is implemented in Python and
C++ and is available under Apache license at
http://melodi-lab.github.io/dripToolkit .

DOI: 10.1021/acs.jproteome.6b00290 
PMCID: PMC5116375 [Available on 2017-08-05]
PMID: 27397138  [PubMed - in process]


410. Proc Natl Acad Sci U S A. 2016 Jul 5;113(27):7377-82. doi:
10.1073/pnas.1510497113.

Linear mixed model for heritability estimation that explicitly addresses
environmental variation.

Heckerman D(1), Gurdasani D(2), Kadie C(3), Pomilla C(2), Carstensen T(2), Martin
H(4), Ekoru K(2), Nsubuga RN(5), Ssenyomo G(5), Kamali A(5), Kaleebu P(5), Widmer
C(6), Sandhu MS(2).

Author information: 
(1)Microsoft Research, Los Angeles, CA 90024; heckerma@microsoft.com. (2)Wellcome
Trust Sanger Institute, Hinxton CB10 1SA, United Kingdom; Department of Medicine,
University of Cambridge, Cambridge CB2 0SP, United Kingdom; (3)Microsoft
Research, Redmond, WA 98052; (4)Wellcome Trust Sanger Institute, Hinxton CB10
1SA, United Kingdom; (5)MRC/UVRI Uganda Research Unit on AIDS, Uganda.
(6)Microsoft Research, Los Angeles, CA 90024;

The linear mixed model (LMM) is now routinely used to estimate heritability.
Unfortunately, as we demonstrate, LMM estimates of heritability can be inflated
when using a standard model. To help reduce this inflation, we used a more
general LMM with two random effects-one based on genomic variants and one based
on easily measured spatial location as a proxy for environmental effects. We
investigated this approach with simulated data and with data from a Uganda cohort
of 4,778 individuals for 34 phenotypes including anthropometric indices, blood
factors, glycemic control, blood pressure, lipid tests, and liver function tests.
For the genomic random effect, we used identity-by-descent estimates from
accurately phased genome-wide data. For the environmental random effect, we
constructed a covariance matrix based on a Gaussian radial basis function. Across
the simulated and Ugandan data, narrow-sense heritability estimates were lower
using the more general model. Thus, our approach addresses, in part, the issue of
"missing heritability" in the sense that much of the heritability previously
thought to be missing was fictional. Software is available at
https://github.com/MicrosoftGenomics/FaST-LMM.

DOI: 10.1073/pnas.1510497113 
PMCID: PMC4941438
PMID: 27382152  [PubMed - in process]


411. Front Microbiol. 2016 Jun 17;7:907. doi: 10.3389/fmicb.2016.00907. eCollection
2016.

From DNA to FBA: How to Build Your Own Genome-Scale Metabolic Model.

Cuevas DA(1), Edirisinghe J(2), Henry CS(2), Overbeek R(3), O'Connell TG(4),
Edwards RA(5).

Author information: 
(1)Computational Science Research Center, San Diego State University, San Diego
CA, USA. (2)Mathematics and Computer Science Division, Argonne National
Laboratory, Argonne IL, USA. (3)Fellowship for Interpretation of Genomes, Burr
Ridge IL, USA. (4)Biological and Medical Informatics Research Center, San Diego
State University, San Diego CA, USA. (5)Computational Science Research Center,
San Diego State University, San DiegoCA, USA; Biological and Medical Informatics 
Research Center, San Diego State University, San DiegoCA, USA; Department of
Computer Science, San Diego State University, San DiegoCA, USA; Department of
Biology, San Diego State University, San DiegoCA, USA.

Microbiological studies are increasingly relying on in silico methods to perform 
exploration and rapid analysis of genomic data, and functional genomics studies
are supplemented by the new perspectives that genome-scale metabolic models
offer. A mathematical model consisting of a microbe's entire metabolic map can be
rapidly determined from whole-genome sequencing and annotating the genomic
material encoded in its DNA. Flux-balance analysis (FBA), a linear programming
technique that uses metabolic models to predict the phenotypic responses imposed 
by environmental elements and factors, is the leading method to simulate and
manipulate cellular growth in silico. However, the process of creating an
accurate model to use in FBA consists of a series of steps involving a multitude 
of connections between bioinformatics databases, enzyme resources, and metabolic 
pathways. We present the methodology and procedure to obtain a metabolic model
using PyFBA, an extensible Python-based open-source software package aimed to
provide a platform where functional annotations are used to build metabolic
models (http://linsalrob.github.io/PyFBA). Backed by the Model SEED biochemistry 
database, PyFBA contains methods to reconstruct a microbe's metabolic map, run
FBA upon different media conditions, and gap-fill its metabolism. The
extensibility of PyFBA facilitates novel techniques in creating accurate
genome-scale metabolic models.

DOI: 10.3389/fmicb.2016.00907 
PMCID: PMC4911401
PMID: 27379044  [PubMed]


412. Brief Bioinform. 2016 Jul 3. pii: bbw054. [Epub ahead of print]

BrowseVCF: a web-based application and workflow to quickly prioritize
disease-causative variants in VCF files.

Salatino S, Ramraj V.

Following variant calling and annotation, accurate variant filtering is a crucial
step to extract meaningful information from sequencing data and to investigate
disease aetiology. However, the variant call format (VCF) used to store this
information is not easy to handle for non-bioinformaticians. We present
BrowseVCF, a flexible and intuitive software to enable researchers to browse and 
filter millions of variants in a few seconds. Key features include querying
user-defined gene lists, grouping samples for family or tumour/normal studies and
exporting results in spreadsheet format. BrowseVCF's significant advantages over 
most existing tools include the ability to process data from any DNA sequencing
experiment (exome, whole-genome and amplicons) and to correctly parse files
annotated with Variant Effect Predictor. BrowseVCF can be used either locally on 
personal computers or as part of automated pipelines. Its user interface has been
carefully designed to minimize tunable parameters. BrowseVCF is freely available 
from https://github.com/BSGOxford/BrowseVCF/releases/latest.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bib/bbw054 
PMID: 27373737  [PubMed - as supplied by publisher]


413. BMC Genomics. 2016 Jun 23;17 Suppl 2:396. doi: 10.1186/s12864-016-2723-1.

KinMutRF: a random forest classifier of sequence variants in the human protein
kinase superfamily.

Pons T(1), Vazquez M(1), Matey-Hernandez ML(2), Brunak S(2,)(3), Valencia A(1),
Izarzugaza JM(4).

Author information: 
(1)Structural Biology and BioComputing Programme, Spanish National Cancer
Research Centre (CNIO), Melchor Fernández Almagro, 3, 28029, Madrid, Spain.
(2)Center for Biological Sequence Analysis (CBS), Systems Biology Department,
Technical University of Denmark (DTU), Kemitorvet, Building 208, 2800 Kgs.,
Lyngby, Denmark. (3)Novo Nordisk Foundation Center for Protein Research, Faculty 
of Health Sciences, University of Copenhagen, Blegdamsvej 3A, 2200, Copenhagen,
Denmark. (4)Center for Biological Sequence Analysis (CBS), Systems Biology
Department, Technical University of Denmark (DTU), Kemitorvet, Building 208, 2800
Kgs., Lyngby, Denmark. josemgizarzugaza@cbs.dtu.dk.

BACKGROUND: The association between aberrant signal processing by protein kinases
and human diseases such as cancer was established long time ago. However,
understanding the link between sequence variants in the protein kinase
superfamily and the mechanistic complex traits at the molecular level remains
challenging: cells tolerate most genomic alterations and only a minor fraction
disrupt molecular function sufficiently and drive disease.
RESULTS: KinMutRF is a novel random-forest method to automatically identify
pathogenic variants in human kinases. Twenty six decision trees implemented as a 
random forest ponder a battery of features that characterize the variants: a) at 
the gene level, including membership to a Kinbase group and Gene Ontology terms; 
b) at the PFAM domain level; and c) at the residue level, the types of amino
acids involved, changes in biochemical properties, functional annotations from
UniProt, Phospho.ELM and FireDB. KinMutRF identifies disease-associated variants 
satisfactorily (Acc: 0.88, Prec:0.82, Rec:0.75, F-score:0.78, MCC:0.68) when
trained and cross-validated with the 3689 human kinase variants from UniProt that
have been annotated as neutral or pathogenic. All unclassified variants were
excluded from the training set. Furthermore, KinMutRF is discussed with respect
to two independent kinase-specific sets of mutations no included in the training 
and testing, Kin-Driver (643 variants) and Pon-BTK (1495 variants). Moreover, we 
provide predictions for the 848 protein kinase variants in UniProt that remained 
unclassified. A public implementation of KinMutRF, including documentation and
examples, is available online ( http://kinmut2.bioinfo.cnio.es ). The source code
for local installation is released under a GPL version 3 license, and can be
downloaded from https://github.com/Rbbt-Workflows/KinMut2 .
CONCLUSIONS: KinMutRF is capable of classifying kinase variation with good
performance. Predictions by KinMutRF compare favorably in a benchmark with other 
state-of-the-art methods (i.e. SIFT, Polyphen-2, MutationAssesor, MutationTaster,
LRT, CADD, FATHMM, and VEST). Kinase-specific features rank as the most
elucidatory in terms of information gain and are likely the improvement in
prediction performance. This advocates for the development of family-specific
classifiers able to exploit the discriminatory power of features unique to
individual protein families.

DOI: 10.1186/s12864-016-2723-1 
PMCID: PMC4928150
PMID: 27357839  [PubMed - in process]


414. Bioinformatics. 2016 Oct 15;32(20):3150-3154. Epub 2016 Jun 29.

Estimating and testing high-dimensional mediation effects in epigenetic studies.

Zhang H(1), Zheng Y(2), Zhang Z(2), Gao T(2), Joyce B(2), Yoon G(3), Zhang W(2), 
Schwartz J(4), Just A(5), Colicino E(4), Vokonas P(6), Zhao L(2), Lv J(7),
Baccarelli A(4), Hou L(2), Liu L(2).

Author information: 
(1)Center for Applied Mathematics, Tianjin University, Tianjin 300072, China.
(2)Department of Preventive Medicine. (3)Department of Statistics, Northwestern
University, Chicago, IL 60611, USA. (4)Department of Environmental Health,
Harvard University, Boston, MA 02115, USA. (5)Department of Preventive Medicine, 
Icahn School of Medicine at Mount Sinai, New York, NY 10029, USA. (6)Veterans
Affairs Boston Healthcare System and Boston University School of Medicine, VA
Normative Aging Study, Boston, MA 02118, USA. (7)Data Sciences and Operations
Department, University of Southern California, Los Angeles, CA 90089, USA.

MOTIVATION: High-dimensional DNA methylation markers may mediate pathways linking
environmental exposures with health outcomes. However, there is a lack of
analytical methods to identify significant mediators for high-dimensional
mediation analysis.
RESULTS: Based on sure independent screening and minimax concave penalty
techniques, we use a joint significance test for mediation effect. We demonstrate
its practical performance using Monte Carlo simulation studies and apply this
method to investigate the extent to which DNA methylation markers mediate the
causal pathway from smoking to reduced lung function in the Normative Aging
Study. We identify 2 CpGs with significant mediation effects.
AVAILABILITY AND IMPLEMENTATION: R package, source code, and simulation study are
available at https://github.com/YinanZheng/HIMA CONTACT:
lei.liu@northwestern.edu.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw351 
PMCID: PMC5048064 [Available on 2017-10-15]
PMID: 27357171  [PubMed - in process]


415. Bioinformatics. 2016 Oct 15;32(20):3210-3212. Epub 2016 Jun 26.

CellProfiler Analyst: interactive data exploration, analysis and classification
of large biological image sets.

Dao D(1), Fraser AN(2), Hung J(3), Ljosa V(2), Singh S(2), Carpenter AE(2).

Author information: 
(1)Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, MA 02142, USA
Department of Informatics, Technical University of Munich, Munich, Bavaria 80333,
Germany. (2)Imaging Platform, Broad Institute of Harvard and MIT, Cambridge, MA
02142, USA. (3)Imaging Platform, Broad Institute of Harvard and MIT, Cambridge,
MA 02142, USA Department of Chemical Engineering, Massachusetts Institute of
Technology (MIT), Cambridge, MA 02139, USA.

CellProfiler Analyst allows the exploration and visualization of image-based
data, together with the classification of complex biological phenotypes, via an
interactive user interface designed for biologists and data scientists.
CellProfiler Analyst 2.0, completely rewritten in Python, builds on these
features and adds enhanced supervised machine learning capabilities (Classifier),
as well as visualization tools to overview an experiment (Plate Viewer and Image 
Gallery).AVAILABILITY AND IMPLEMENTATION: CellProfiler Analyst 2.0 is free and
open source, available at http://www.cellprofiler.org and from GitHub
(https://github.com/CellProfiler/CellProfiler-Analyst) under the BSD license. It 
is available as a packaged application for Mac OS X and Microsoft Windows and can
be compiled for Linux. We implemented an automatic build process that supports
nightly updates and regular release cycles for the software.
CONTACT: anne@broadinstitute.orgSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw390 
PMCID: PMC5048071
PMID: 27354701  [PubMed - in process]


416. Bioinformatics. 2016 Oct 15;32(20):3124-3132. Epub 2016 Jun 26.

GeneCodeq: quality score compression and improved genotyping using a Bayesian
framework.

Greenfield DL(1), Stegle O(2), Rrustemi A(1).

Author information: 
(1)PetaGene, Ideaspace, 3 Charles Babbage Rd, Cambridge CB3 0GT, UK. (2)European 
Molecular Biology Laboratory, European Bioinformatics Institute, Wellcome Trust
Genome Campus, Hinxton, Cambridge CB10 1SQ, UK.

MOTIVATION: The exponential reduction in cost of genome sequencing has resulted
in a rapid growth of genomic data. Most of the entropy of short read data lies
not in the sequence of read bases themselves but in their Quality Scores-the
confidence measurement that each base has been sequenced correctly. Lossless
compression methods are now close to their theoretical limits and hence there is 
a need for lossy methods that further reduce the complexity of these data without
impacting downstream analyses.
RESULTS: We here propose GeneCodeq, a Bayesian method inspired by coding theory
for adjusting quality scores to improve the compressibility of quality scores
without adversely impacting genotyping accuracy. Our model leverages a corpus of 
k-mers to reduce the entropy of the quality scores and thereby the
compressibility of these data (in FASTQ or SAM/BAM/CRAM files), resulting in
compression ratios that significantly exceeds those of other methods. Our
approach can also be combined with existing lossy compression schemes to further 
reduce entropy and allows the user to specify a reference panel of expected
sequence variations to improve the model accuracy. In addition to extensive
empirical evaluation, we also derive novel theoretical insights that explain the 
empirical performance and pitfalls of corpus-based quality score compression
schemes in general. Finally, we show that as a positive side effect of
compression, the model can lead to improved genotyping accuracy.
AVAILABILITY AND IMPLEMENTATION: GeneCodeq is available at:
github.com/genecodeq/eval CONTACT: dan@petagene.comSupplementary information:
Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw385 
PMID: 27354700  [PubMed - in process]


417. Bioinformatics. 2016 Oct 15;32(20):3196-3198. Epub 2016 Jun 26.

Conpair: concordance and contamination estimator for matched tumor-normal pairs.

Bergmann EA(1), Chen BJ(1), Arora K(1), Vacic V(1), Zody MC(1).

Author information: 
(1)New York Genome Center, New York, NY 10013, USA.

MOTIVATION: Sequencing of matched tumor and normal samples is the standard study 
design for reliable detection of somatic alterations. However, even very low
levels of cross-sample contamination significantly impact calling of somatic
mutations, because contaminant germline variants can be incorrectly interpreted
as somatic. There are currently no sequence-only based methods that reliably
estimate contamination levels in tumor samples, which frequently display copy
number changes. As a solution, we developed Conpair, a tool for detection of
sample swaps and cross-individual contamination in whole-genome and whole-exome
tumor-normal sequencing experiments.
RESULTS: On a ladder of in silico contaminated samples, we demonstrated that
Conpair reliably measures contamination levels as low as 0.1%, even in presence
of copy number changes. We also estimated contamination levels in glioblastoma
WGS and WXS tumor-normal datasets from TCGA and showed that they strongly
correlate with tumor-normal concordance, as well as with the number of germline
variants called as somatic by several widely-used somatic callers.
AVAILABILITY AND IMPLEMENTATION: The method is available at:
https://github.com/nygenome/conpair CONTACT: egrabowska@gmail.com or
mczody@nygenome.orgSupplementary information: Supplementary data are available at
Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw389 
PMCID: PMC5048070
PMID: 27354699  [PubMed - in process]


418. Bioinformatics. 2016 Oct 15;32(20):3065-3071. Epub 2016 Jun 26.

Inheritance-mode specific pathogenicity prioritization (ISPP) for human protein
coding genes.

Hsu JS(1), Kwan JS(1), Pan Z(1), Garcia-Barcelo MM(2), Sham PC(3), Li M(3).

Author information: 
(1)Department of Psychiatry. (2)Department of Surgery. (3)Department of
Psychiatry Centre for Genomics Science, Li Ka Shing Faculty of Medicine, The
University of Hong Kong, Hong Kong.

MOTIVATION: Exome sequencing studies have facilitated the detection of causal
genetic variants in yet-unsolved Mendelian diseases. However, the identification 
of disease causal genes among a list of candidates in an exome sequencing study
is still not fully settled, and it is often difficult to prioritize candidate
genes for follow-up studies. The inheritance mode provides crucial information
for understanding Mendelian diseases, but none of the existing gene
prioritization tools fully utilize this information.
RESULTS: We examined the characteristics of Mendelian disease genes under
different inheritance modes. The results suggest that Mendelian disease genes
with autosomal dominant (AD) inheritance mode are more haploinsufficiency and de 
novo mutation sensitive, whereas those autosomal recessive (AR) genes have
significantly more non-synonymous variants and regulatory transcript isoforms. In
addition, the X-linked (XL) Mendelian disease genes have fewer non-synonymous and
synonymous variants. As a result, we derived a new scoring system for
prioritizing candidate genes for Mendelian diseases according to the inheritance 
mode. Our scoring system assigned to each annotated protein-coding gene
(N = 18 859) three pathogenic scores according to the inheritance mode (AD, AR
and XL). This inheritance mode-specific framework achieved higher accuracy (area 
under curve  = 0.84) in XL mode.
CONCLUSION: The inheritance-mode specific pathogenicity prioritization (ISPP)
outperformed other well-known methods including Haploinsufficiency, Recessive,
Network centrality, Genic Intolerance, Gene Damage Index and Gene Constraint
scores. This systematic study suggests that genes manifesting disease inheritance
modes tend to have unique characteristics.
AVAILABILITY AND IMPLEMENTATION: ISPP is included in KGGSeq v1.0
(http://grass.cgs.hku.hk/limx/kggseq/), and source code is available from
(https://github.com/jacobhsu35/ISPP.git).
CONTACT: mxli@hku.hkSupplementary information: Supplementary data are available
at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw381 
PMID: 27354691  [PubMed - in process]


419. PLoS Comput Biol. 2016 Jun 23;12(6):e1004728. doi: 10.1371/journal.pcbi.1004728. 
eCollection 2016.

Ensembler: Enabling High-Throughput Molecular Simulations at the Superfamily
Scale.

Parton DL(1), Grinaway PB(2), Hanson SM(1), Beauchamp KA(1), Chodera JD(1).

Author information: 
(1)Computational Biology Program, Sloan Kettering Institute, Memorial Sloan
Kettering Cancer Center, New York, New York, United States of America.
(2)Graduate Program in Physiology, Biophysics, and Systems Biology, Weill Cornell
Medical College, New York, New York, United States of America.

The rapidly expanding body of available genomic and protein structural data
provides a rich resource for understanding protein dynamics with biomolecular
simulation. While computational infrastructure has grown rapidly, simulations on 
an omics scale are not yet widespread, primarily because software infrastructure 
to enable simulations at this scale has not kept pace. It should now be possible 
to study protein dynamics across entire (super)families, exploiting both
available structural biology data and conformational similarities across
homologous proteins. Here, we present a new tool for enabling high-throughput
simulation in the genomics era. Ensembler takes any set of sequences-from a
single sequence to an entire superfamily-and shepherds them through various
stages of modeling and refinement to produce simulation-ready structures. This
includes comparative modeling to all relevant PDB structures (which may span
multiple conformational states of interest), reconstruction of missing loops,
addition of missing atoms, culling of nearly identical structures, assignment of 
appropriate protonation states, solvation in explicit solvent, and refinement and
filtering with molecular simulation to ensure stable simulation. The output of
this pipeline is an ensemble of structures ready for subsequent molecular
simulations using computer clusters, supercomputers, or distributed computing
projects like Folding@home. Ensembler thus automates much of the time-consuming
process of preparing protein models suitable for simulation, while allowing
scalability up to entire superfamilies. A particular advantage of this approach
can be found in the construction of kinetic models of conformational
dynamics-such as Markov state models (MSMs)-which benefit from a diverse array of
initial configurations that span the accessible conformational states to aid
sampling. We demonstrate the power of this approach by constructing models for
all catalytic domains in the human tyrosine kinase family, using all available
kinase catalytic domain structures from any organism as structural templates.
Ensembler is free and open source software licensed under the GNU General Public 
License (GPL) v2. It is compatible with Linux and OS X. The latest release can be
installed via the conda package manager, and the latest source can be downloaded 
from https://github.com/choderalab/ensembler.

DOI: 10.1371/journal.pcbi.1004728 
PMCID: PMC4918922
PMID: 27337644  [PubMed - in process]


420. PLoS Comput Biol. 2016 Jun 23;12(6):e1004809. doi: 10.1371/journal.pcbi.1004809. 
eCollection 2016.

QuIN: A Web Server for Querying and Visualizing Chromatin Interaction Networks.

Thibodeau A(1), Márquez EJ(2), Luo O(2), Ruan Y(2), Menghi F(2), Shin DG(1),
Stitzel ML(2,)(3), Vera-Licona P(3,)(4), Ucar D(2,)(3).

Author information: 
(1)Department of Computer Science, University of Connecticut, Storrs,
Connecticut, United States of America. (2)The Jackson Laboratory for Genomic
Medicine, Farmington, Connecticut, United States of America. (3)Institute of
Systems Genomics, University of Connecticut Health Center, Farmington,
Connecticut, United States of America. (4)Center for Quantitative Medicine,
Department of Cell Biology, University of Connecticut Health Center, Farmington, 
Connecticut, United States of America.

Recent studies of the human genome have indicated that regulatory elements (e.g. 
promoters and enhancers) at distal genomic locations can interact with each other
via chromatin folding and affect gene expression levels. Genomic technologies for
mapping interactions between DNA regions, e.g., ChIA-PET and HiC, can generate
genome-wide maps of interactions between regulatory elements. These interaction
datasets are important resources to infer distal gene targets of non-coding
regulatory elements and to facilitate prioritization of critical loci for
important cellular functions. With the increasing diversity and complexity of
genomic information and public ontologies, making sense of these datasets demands
integrative and easy-to-use software tools. Moreover, network representation of
chromatin interaction maps enables effective data visualization, integration, and
mining. Currently, there is no software that can take full advantage of network
theory approaches for the analysis of chromatin interaction datasets. To fill
this gap, we developed a web-based application, QuIN, which enables: 1) building 
and visualizing chromatin interaction networks, 2) annotating networks with
user-provided private and publicly available functional genomics and interaction 
datasets, 3) querying network components based on gene name or chromosome
location, and 4) utilizing network based measures to identify and prioritize
critical regulatory targets and their direct and indirect
interactions.AVAILABILITY: QuIN's web server is available at http://quin.jax.org 
QuIN is developed in Java and JavaScript, utilizing an Apache Tomcat web server
and MySQL database and the source code is available under the GPLV3 license
available on GitHub: https://github.com/UcarLab/QuIN/.

DOI: 10.1371/journal.pcbi.1004809 
PMCID: PMC4919057
PMID: 27336171  [PubMed - in process]


421. Bioinformatics. 2016 Sep 15;32(18):2776-82. doi: 10.1093/bioinformatics/btw319.
Epub 2016 Jun 9.

Revealing aperiodic aspects of solenoid proteins from sequence information.

Hrabe T(1), Jaroszewski L(1), Godzik A(1).

Author information: 
(1)Department of Bioinformatics and Systems Biology, Sanford Burnham Prebys
Medical Discovery Institute, La Jolla, CA 92037, USA.

MOTIVATION: Repeat proteins, which contain multiple repeats of short sequence
motifs, form a large but seldom-studied group of proteins. Methods focusing on
the analysis of 3D structures of such proteins identified many subtle effects in 
length distribution of individual motifs that are important for their functions. 
However, similar analysis was yet not applied to the vast majority of repeat
proteins with unknown 3D structures, mostly because of the extreme diversity of
the underlying motifs and the resulting difficulty to detect those.
RESULTS: We developed FAIT, a sequence-based algorithm for the precise assignment
of individual repeats in repeat proteins and introduced a framework to classify
and compare aperiodicity patterns for large protein families. FAIT extracts
repeat positions by post-processing FFAS alignment matrices with image processing
methods. On examples of proteins with Leucine Rich Repeat (LRR) domains and other
solenoids like proteins, we show that the automated analysis with FAIT correctly 
identifies exact lengths of individual repeats based entirely on sequence
information.
AVAILABILITY AND IMPLEMENTATION: https://github.com/GodzikLab/FAIT CONTACT:
adam@godziklab.org
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw319 
PMID: 27334472  [PubMed - in process]


422. PeerJ. 2016 Jun 8;4:e2016. doi: 10.7717/peerj.2016. eCollection 2016.

Sparc: a sparsity-based consensus algorithm for long erroneous sequencing reads.

Ye C(1), Ma ZS(2).

Author information: 
(1)Department of Computer Science, University of Maryland , College Park, MD ,
USA. (2)Computational Biology and Medical Ecology Lab, State Key Laboratory of
Genetic Resources and Evolution, Kunming Institute of Zoology, Chinese Academy of
Sciences , Kunming, Yunnan , China.

Motivation. The third generation sequencing (3GS) technology generates long
sequences of thousands of bases. However, its current error rates are estimated
in the range of 15-40%, significantly higher than those of the prevalent next
generation sequencing (NGS) technologies (less than 1%). Fundamental
bioinformatics tasks such as de novo genome assembly and variant calling require 
high-quality sequences that need to be extracted from these long but erroneous
3GS sequences. Results. We describe a versatile and efficient linear complexity
consensus algorithm Sparc to facilitate de novo genome assembly. Sparc builds a
sparse k-mer graph using a collection of sequences from a targeted genomic
region. The heaviest path which approximates the most likely genome sequence is
searched through a sparsity-induced reweighted graph as the consensus sequence.
Sparc supports using NGS and 3GS data together, which leads to significant
improvements in both cost efficiency and computational efficiency. Experiments
with Sparc show that our algorithm can efficiently provide high-quality consensus
sequences using both PacBio and Oxford Nanopore sequencing technologies. With
only 30× PacBio data, Sparc can reach a consensus with error rate <0.5%. With the
more challenging Oxford Nanopore data, Sparc can also achieve similar error rate 
when combined with NGS data. Compared with the existing approaches, Sparc
calculates the consensus with higher accuracy, and uses approximately 80% less
memory and time. Availability. The source code is available for download at
https://github.com/yechengxi/Sparc.

DOI: 10.7717/peerj.2016 
PMCID: PMC4906657
PMID: 27330851  [PubMed]


423. JP J Biostat. 2015 Dec;12(2):99-115. Epub 2016 Jan 1.

DETECTING CONFORMATIONAL DIFFERENCES BETWEEN RNA 3D STRUCTURES.

Rahrig RR(1), Zirbel CL(1).

Author information: 
(1)Department of Mathematics and Statistics, Ohio Northern University, Ada, OH
45810, U. S. A.

A method is described for detecting local conformational differences between two 
3D structures of the same RNA molecule. These could be distinct 3D structures of 
the same molecule from the same organism, or homologous molecules from different 
organisms. In this approach, we detect the variability that exists among the
relative translation and rotation operations that are needed to superimpose local
neighborhoods after an initial rigid-body global superposition. Each translation 
and rotation is represented by a three dimensional vector. Thus, we investigate
the variability within sets of multivariate data. We demonstrate that the method 
is able to identify both small- and large-scale conformational changes.
Matlab/Octave programs to read RNA 3D structure files and compare structures have
been developed and are freely accessible at:
https://github.com/BGSU-RNA/ConformationalChange.

DOI: 10.17654/JPJBDec2015_099_115 
PMCID: PMC4911192
PMID: 27330250  [PubMed]


424. Bioinformatics. 2016 Oct 15;32(20):3089-3097. Epub 2016 Jun 21.

ACE: adaptive cluster expansion for maximum entropy graphical model inference.

Barton JP(1), De Leonardis E(2), Coucke A(3), Cocco S(4).

Author information: 
(1)Departments of Chemical Engineering and Physics, Massachusetts Institute of
Technology, Cambridge, MA 02139, USA Ragon Institute of Massachusetts General
Hospital, Massachusetts Institute of Technology and Harvard, Cambridge, MA 02139,
USA. (2)Laboratoire de Physique Statistique de L'Ecole Normale Supérieure, CNRS, 
Ecole Normale Supérieure & Université P.&M. Curie, Paris, France Computational
and Quantitative Biology, UPMC, UMR 7238, Sorbonne Université, Paris, France.
(3)Computational and Quantitative Biology, UPMC, UMR 7238, Sorbonne Université,
Paris, France Laboratoire de Physique Théorique de L'Ecole Normale Supérieure,
CNRS, Ecole Normale Supérieure & Université P.&M. Curie, Paris, France.
(4)Laboratoire de Physique Statistique de L'Ecole Normale Supérieure, CNRS, Ecole
Normale Supérieure & Université P.&M. Curie, Paris, France.

MOTIVATION: Graphical models are often employed to interpret patterns of
correlations observed in data through a network of interactions between the
variables. Recently, Ising/Potts models, also known as Markov random fields, have
been productively applied to diverse problems in biology, including the
prediction of structural contacts from protein sequence data and the description 
of neural activity patterns. However, inference of such models is a challenging
computational problem that cannot be solved exactly. Here, we describe the
adaptive cluster expansion (ACE) method to quickly and accurately infer Ising or 
Potts models based on correlation data. ACE avoids overfitting by constructing a 
sparse network of interactions sufficient to reproduce the observed correlation
data within the statistical error expected due to finite sampling. When
convergence of the ACE algorithm is slow, we combine it with a Boltzmann Machine 
Learning algorithm (BML). We illustrate this method on a variety of biological
and artificial datasets and compare it to state-of-the-art approximate methods
such as Gaussian and pseudo-likelihood inference.
RESULTS: We show that ACE accurately reproduces the true parameters of the
underlying model when they are known, and yields accurate statistical
descriptions of both biological and artificial data. Models inferred by ACE more 
accurately describe the statistics of the data, including both the constrained
low-order correlations and unconstrained higher-order correlations, compared to
those obtained by faster Gaussian and pseudo-likelihood methods. These
alternative approaches can recover the structure of the interaction network but
typically not the correct strength of interactions, resulting in less accurate
generative models.
AVAILABILITY AND IMPLEMENTATION: The ACE source code, user manual and tutorials
with the example data and filtered correlations described herein are freely
available on GitHub at https://github.com/johnbarton/ACE CONTACTS:
jpbarton@mit.edu, cocco@lps.ens.frSupplementary information: Supplementary data
are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw328 
PMID: 27329863  [PubMed - in process]


425. Sci Rep. 2016 Jun 22;6:28517. doi: 10.1038/srep28517.

PEDLA: predicting enhancers with a deep learning-based algorithmic framework.

Liu F(1), Li H(1), Ren C(1), Bo X(1), Shu W(1).

Author information: 
(1)Department of Biotechnology, Beijing Institute of Radiation Medicine, Beijing 
100850, China.

Transcriptional enhancers are non-coding segments of DNA that play a central role
in the spatiotemporal regulation of gene expression programs. However,
systematically and precisely predicting enhancers remain a major challenge.
Although existing methods have achieved some success in enhancer prediction, they
still suffer from many issues. We developed a deep learning-based algorithmic
framework named PEDLA (https://github.com/wenjiegroup/PEDLA), which can directly 
learn an enhancer predictor from massively heterogeneous data and generalize in
ways that are mostly consistent across various cell types/tissues. We first
trained PEDLA with 1,114-dimensional heterogeneous features in H1 cells, and
demonstrated that PEDLA framework integrates diverse heterogeneous features and
gives state-of-the-art performance relative to five existing methods for enhancer
prediction. We further extended PEDLA to iteratively learn from 22 training cell 
types/tissues. Our results showed that PEDLA manifested superior performance
consistency in both training and independent test sets. On average, PEDLA
achieved 95.0% accuracy and a 96.8% geometric mean (GM) of sensitivity and
specificity across 22 training cell types/tissues, as well as 95.7% accuracy and 
a 96.8% GM across 20 independent test cell types/tissues. Together, our work
illustrates the power of harnessing state-of-the-art deep learning techniques to 
consistently identify regulatory elements at a genome-wide scale from massively
heterogeneous data across diverse cell types/tissues.

DOI: 10.1038/srep28517 
PMCID: PMC4916453
PMID: 27329130  [PubMed - in process]


426. PLoS Comput Biol. 2016 Jun 21;12(6):e1004957. doi: 10.1371/journal.pcbi.1004957. 
eCollection 2016.

MEGAN Community Edition - Interactive Exploration and Analysis of Large-Scale
Microbiome Sequencing Data.

Huson DH(1,)(2), Beier S(1), Flade I(3), Górska A(1,)(4), El-Hadidi M(1), Mitra
S(5), Ruscheweyh HJ(1), Tappu R(1).

Author information: 
(1)Center for Bioinformatics, University of Tübingen, Tübingen, Germany. (2)Life 
Sciences Institute, National University of Singapore, Singapore. (3)CeMeT GmbH,
Tübingen, Germany. (4)IMPRS 'From Molecules to Organisms', MPI for Developmental 
Biology and University of Tübingen, Tübingen, Germany. (5)Norwich Medical School,
University of East Anglia, Norwich, United Kingdom.

There is increasing interest in employing shotgun sequencing, rather than
amplicon sequencing, to analyze microbiome samples. Typical projects may involve 
hundreds of samples and billions of sequencing reads. The comparison of such
samples against a protein reference database generates billions of alignments and
the analysis of such data is computationally challenging. To address this, we
have substantially rewritten and extended our widely-used microbiome analysis
tool MEGAN so as to facilitate the interactive analysis of the taxonomic and
functional content of very large microbiome datasets. Other new features include 
a functional classifier called InterPro2GO, gene-centric read assembly, principal
coordinate analysis of taxonomy and function, and support for metadata. The new
program is called MEGAN Community Edition (CE) and is open source. By integrating
MEGAN CE with our high-throughput DNA-to-protein alignment tool DIAMOND and by
providing a new program MeganServer that allows access to metagenome analysis
files hosted on a server, we provide a straightforward, yet powerful and complete
pipeline for the analysis of metagenome shotgun sequences. We illustrate how to
perform a full-scale computational analysis of a metagenomic sequencing project, 
involving 12 samples and 800 million reads, in less than three days on a single
server. All source code is available here:
https://github.com/danielhuson/megan-ce.

DOI: 10.1371/journal.pcbi.1004957 
PMCID: PMC4915700
PMID: 27327495  [PubMed - in process]


427. Bioinformatics. 2016 Oct 15;32(20):3098-3106. Epub 2016 Jun 20.

RTCR: a pipeline for complete and accurate recovery of T cell repertoires from
high throughput sequencing data.

Gerritsen B(1), Pandit A(1), Andeweg AC(2), de Boer RJ(1).

Author information: 
(1)Theoretical Biology and Bioinformatics, Utrecht University, 3584CH the
Netherlands. (2)Department of Viroscience, Rotterdam, Erasmus MC, 3000CA, the
Netherlands.

MOTIVATION: High Throughput Sequencing (HTS) has enabled researchers to probe the
human T cell receptor (TCR) repertoire, which consists of many rare sequences.
Distinguishing between true but rare TCR sequences and variants generated by
polymerase chain reaction (PCR) and sequencing errors remains a formidable
challenge. The conventional approach to handle errors is to remove low quality
reads, and/or rare TCR sequences. Such filtering discards a large number of true 
and often rare TCR sequences. However, accurate identification and quantification
of rare TCR sequences is essential for repertoire diversity estimation.
RESULTS: We devised a pipeline, called Recover TCR (RTCR), that accurately
recovers TCR sequences, including rare TCR sequences, from HTS data (including
barcoded data) even at low coverage. RTCR employs a data-driven statistical model
to rectify PCR and sequencing errors in an adaptive manner. Using simulations, we
demonstrate that RTCR can easily adapt to the error profiles of different types
of sequencers and exhibits consistently high recall and high precision even at
low coverages where other pipelines perform poorly. Using published real data, we
show that RTCR accurately resolves sequencing errors and outperforms all other
pipelines.
AVAILABILITY AND IMPLEMENTATION: The RTCR pipeline is implemented in Python
(v2.7) and C and is freely available at http://uubram.github.io/RTCR/along with
documentation and examples of typical usage.
CONTACT: b.gerritsen@uu.nl.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw339 
PMCID: PMC5048062
PMID: 27324198  [PubMed - in process]


428. Bioinformatics. 2016 Sep 15;32(18):2809-16. doi: 10.1093/bioinformatics/btw334.
Epub 2016 Jun 20.

Integrated gene set analysis for microRNA studies.

Garcia-Garcia F(1), Panadero J(2), Dopazo J(3), Montaner D(1).

Author information: 
(1)Computational Genomics Department, Centro de Investigacion Principe Felipe
(CIPF), Valencia, Spain. (2)Genometra S.L., Valencia, Spain. (3)Computational
Genomics Department, Centro de Investigacion Principe Felipe (CIPF), Valencia,
Spain Bioinformatics of Rare Diseases (BIER), CIBER de Enfermedades Raras
(CIBERER), Valencia, Spain Functional Genomics Node, (INB) at CIPF, Valencia,
Spain.

MOTIVATION: Functional interpretation of miRNA expression data is currently done 
in a three step procedure: select differentially expressed miRNAs, find their
target genes, and carry out gene set overrepresentation analysis Nevertheless,
major limitations of this approach have already been described at the gene level,
while some newer arise in the miRNA scenario.Here, we propose an enhanced
methodology that builds on the well-established gene set analysis paradigm.
Evidence for differential expression at the miRNA level is transferred to a gene 
differential inhibition score which is easily interpretable in terms of gene sets
or pathways. Such transferred indexes account for the additive effect of several 
miRNAs targeting the same gene, and also incorporate cancellation effects between
cases and controls. Together, these two desirable characteristics allow for more 
accurate modeling of regulatory processes.
RESULTS: We analyze high-throughput sequencing data from 20 different cancer
types and provide exhaustive reports of gene and Gene Ontology-term deregulation 
by miRNA action.
AVAILABILITY AND IMPLEMENTATION: The proposed methodology was implemented in the 
Bioconductor library mdgsa http://bioconductor.org/packages/mdgsa For the purpose
of reproducibility all of the scripts are available at
https://github.com/dmontaner-papers/gsa4mirna
CONTACT: : david.montaner@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw334 
PMCID: PMC5018374
PMID: 27324197  [PubMed - in process]


429. Genome Biol. 2016 Jun 20;17(1):132. doi: 10.1186/s13059-016-0997-x.

Mash: fast genome and metagenome distance estimation using MinHash.

Ondov BD(1), Treangen TJ(1), Melsted P(2), Mallonee AB(1), Bergman NH(1), Koren
S(3), Phillippy AM(4).

Author information: 
(1)National Biodefense Analysis and Countermeasures Center, Frederick, MD, USA.
(2)Faculty of Industrial Engineering, Mechanical Engineering and Computer
Science, University of Iceland, Reykjavik, Iceland. (3)Genome Informatics
Section, Computational and Statistical Genomics Branch, National Human Genome
Research Institute, National Institutes of Health, Bethesda, MD, USA. (4)Genome
Informatics Section, Computational and Statistical Genomics Branch, National
Human Genome Research Institute, National Institutes of Health, Bethesda, MD,
USA. adam.phillippy@nih.gov.

Mash extends the MinHash dimensionality-reduction technique to include a pairwise
mutation distance and P value significance test, enabling the efficient
clustering and search of massive sequence collections. Mash reduces large
sequences and sequence sets to small, representative sketches, from which global 
mutation distances can be rapidly estimated. We demonstrate several use cases,
including the clustering of all 54,118 NCBI RefSeq genomes in 33 CPU h; real-time
database search using assembled or unassembled Illumina, Pacific Biosciences, and
Oxford Nanopore data; and the scalable clustering of hundreds of metagenomic
samples by composition. Mash is freely released under a BSD license (
https://github.com/marbl/mash ).

DOI: 10.1186/s13059-016-0997-x 
PMCID: PMC4915045
PMID: 27323842  [PubMed - in process]


430. Anal Chem. 2016 Jul 19;88(14):7154-62. doi: 10.1021/acs.analchem.6b01260. Epub
2016 Jun 30.

LOBSTAHS: An Adduct-Based Lipidomics Strategy for Discovery and Identification of
Oxidative Stress Biomarkers.

Collins JR(1,)(2), Edwards BR(1,)(2), Fredricks HF(2), Van Mooy BA(2).

Author information: 
(1)Massachusetts Institute of Technology/Woods Hole Oceanographic Institution
Joint Program in Oceanography, Woods Hole, Massachusetts 02543, United States.
(2)Department of Marine Chemistry and Geochemistry, Woods Hole Oceanographic
Institution , Woods Hole, Massachusetts 02543, United States.

Discovery and identification of molecular biomarkers in large LC/MS data sets
requires significant automation without loss of accuracy in the compound
screening and annotation process. Here, we describe a lipidomics workflow and
open-source software package for high-throughput annotation and putative
identification of lipid, oxidized lipid, and oxylipin biomarkers in
high-mass-accuracy HPLC-MS data. Lipid and oxylipin biomarker screening through
adduct hierarchy sequences, or LOBSTAHS, uses orthogonal screening criteria based
on adduct ion formation patterns and other properties to identify thousands of
compounds while providing the user with a confidence score for each assignment.
Assignments are made from one of two customizable databases; the default
databases contain 14 068 unique entries. To demonstrate the software's
functionality, we screened more than 340 000 mass spectral features from an
experiment in which hydrogen peroxide was used to induce oxidative stress in the 
marine diatom Phaeodactylum tricornutum. LOBSTAHS putatively identified 1969
unique parent compounds in 21 869 features that survived the multistage screening
process. While P. tricornutum maintained more than 92% of its core lipidome under
oxidative stress, patterns in biomarker distribution and abundance indicated
remodeling was both subtle and pervasive. Treatment with 150 μM H2O2 promoted
statistically significant carbon-chain elongation across lipid classes, with the 
strongest elongation accompanying oxidation in moieties of
monogalactosyldiacylglycerol, a lipid typically localized to the chloroplast.
Oxidative stress also induced a pronounced reallocation of lipidome peak area to 
triacylglycerols. LOBSTAHS can be used with environmental or experimental data
from a variety of systems and is freely available at
https://github.com/vanmooylipidomics/LOBSTAHS .

DOI: 10.1021/acs.analchem.6b01260 
PMID: 27322848  [PubMed - in process]


431. Bioinformatics. 2016 Oct 1;32(19):3035-7. doi: 10.1093/bioinformatics/btw365.
Epub 2016 Jun 17.

SELAM: simulation of epistasis and local adaptation during admixture with mate
choice.

Corbett-Detig R(1), Jones M(1).

Author information: 
(1)Department of Integrative Biology, University of California Berkeley,
Berkeley, CA, USA.

SELAM is a forward time population genetic simulation program that provides a
flexible framework for simulating admixture between any number of ancestral
populations. The program can be used to simulate complex demographic and
selection models, including dioecious or monoecious populations, autosomal or sex
chromosomes, local adaptation, dominance, epistasis, and mate choice.AVAILABILITY
AND IMPLEMENTATION: The SELAM package (C ++ source code, examples and manuals) is
available via github at https://github.com/russcd/SELAM This package is
distributed under version 3 of the GNU general public license.
CONTACT: russcd@gmail.com.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw365 
PMID: 27318207  [PubMed - in process]


432. Bioinformatics. 2016 Oct 1;32(19):3021-3. doi: 10.1093/bioinformatics/btw369.
Epub 2016 Jun 17.

Assemblytics: a web analytics tool for the detection of variants from an
assembly.

Nattestad M(1), Schatz MC(2).

Author information: 
(1)Cold Spring Harbor Laboratory, Simons Center for Quantitative Biology, Cold
Spring Harbor, NY, USA and. (2)Cold Spring Harbor Laboratory, Simons Center for
Quantitative Biology, Cold Spring Harbor, NY, USA and Department of Computer
Science, Johns Hopkins University, Baltimore, MD, USA.

Assemblytics is a web app for detecting and analyzing variants from a de novo
genome assembly aligned to a reference genome. It incorporates a unique anchor
filtering approach to increase robustness to repetitive elements, and identifies 
six classes of variants based on their distinct alignment signatures.
Assemblytics can be applied both to comparing aberrant genomes, such as human
cancers, to a reference, or to identify differences between related species.
Multiple interactive visualizations enable in-depth explorations of the genomic
distributions of variants.AVAILABILITY AND IMPLEMENTATION:
http://assemblytics.com, https://github.com/marianattestad/assemblytics
CONTACT: mnattest@cshl.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw369 
PMID: 27318204  [PubMed - in process]


433. Bioinformatics. 2016 Oct 1;32(19):2911-9. doi: 10.1093/bioinformatics/btw360.
Epub 2016 Jun 17.

AgIn: measuring the landscape of CpG methylation of individual repetitive
elements.

Suzuki Y(1), Korlach J(2), Turner SW(2), Tsukahara T(3), Taniguchi J(1), Qu W(1),
Ichikawa K(1), Yoshimura J(1), Yurino H(1), Takahashi Y(4), Mitsui J(4), Ishiura 
H(4), Tsuji S(4), Takeda H(3), Morishita S(1).

Author information: 
(1)Department of Computational Biology and Medical Sciences, Graduate School of
Frontier Sciences, The University of Tokyo, Chiba 277-8583, Japan. (2)Pacific
Biosciences, Menlo Park, CA 94025, USA. (3)Department of Biological Sciences,
Graduate School of Science, The University of Tokyo, Tokyo 113-0033, Japan.
(4)Department of Neurology, Graduate School of Medicine, The University of Tokyo,
Tokyo, 113-8655, Japan.

MOTIVATION: Determining the methylation state of regions with high copy numbers
is challenging for second-generation sequencing, because the read length is
insufficient to map reads uniquely, especially when repetitive regions are long
and nearly identical to each other. Single-molecule real-time (SMRT) sequencing
is a promising method for observing such regions, because it is not vulnerable to
GC bias, it produces long read lengths, and its kinetic information is sensitive 
to DNA modifications.
RESULTS: We propose a novel linear-time algorithm that combines the kinetic
information for neighboring CpG sites and increases the confidence in identifying
the methylation states of those sites. Using a practical read coverage of
∼30-fold from an inbred strain medaka (Oryzias latipes), we observed that both
the sensitivity and precision of our method on individual CpG sites were ∼93.7%. 
We also observed a high correlation coefficient (R = 0.884) between our method
and bisulfite sequencing, and for 92.0% of CpG sites, methylation levels ranging 
over [0,1] were in concordance within an acceptable difference 0.25. Using this
method, we characterized the landscape of the methylation status of repetitive
elements, such as LINEs, in the human genome, thereby revealing the strong
correlation between CpG density and hypomethylation and detecting hypomethylation
hot spots of LTRs and LINEs. We uncovered the methylation states for nearly
identical active transposons, two novel LINE insertions of identity ∼99% and
length 6050 base pairs (bp) in the human genome, and 16 Tol2 elements of
identity >99.8% and length 4682 bp in the medaka genome.
AVAILABILITY AND IMPLEMENTATION: AgIn (Aggregate on Intervals) is available at:
https://github.com/hacone/AgIn
CONTACT: ysuzuki@cb.k.u-tokyo.ac.jp or moris@cb.k.u-tokyo.ac.jp
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw360 
PMCID: PMC5039925
PMID: 27318202  [PubMed - in process]


434. Bioinformatics. 2016 Oct 15;32(20):3058-3064. Epub 2016 Jun 17.

Genome puzzle master (GPM): an integrated pipeline for building and editing
pseudomolecules from fragmented sequences.

Zhang J(1), Kudrna D(2), Mu T(3), Li W(3), Copetti D(4), Yu Y(2), Goicoechea
JL(2), Lei Y(3), Wing RA(4).

Author information: 
(1)National Key Laboratory of Crop Genetic Improvement, Huazhong Agricultural
University, Wuhan 430070, China Arizona Genomics Institute and BIO5 Institute,
School of Plant Sciences, University of Arizona, Tucson, AZ 85721, USA.
(2)Arizona Genomics Institute and BIO5 Institute, School of Plant Sciences,
University of Arizona, Tucson, AZ 85721, USA. (3)National Key Laboratory of Crop 
Genetic Improvement, Huazhong Agricultural University, Wuhan 430070, China.
(4)Arizona Genomics Institute and BIO5 Institute, School of Plant Sciences,
University of Arizona, Tucson, AZ 85721, USA International Rice Research
Institute, Genetic Resource Center, Los Baños, Laguna, Philippines.

MOTIVATION: Next generation sequencing technologies have revolutionized our
ability to rapidly and affordably generate vast quantities of sequence data. Once
generated, raw sequences are assembled into contigs or scaffolds. However, these 
assemblies are mostly fragmented and inaccurate at the whole genome scale,
largely due to the inability to integrate additional informative datasets (e.g.
physical, optical and genetic maps). To address this problem, we developed a
semi-automated software tool-Genome Puzzle Master (GPM)-that enables the
integration of additional genomic signposts to edit and build
'new-gen-assemblies' that result in high-quality 'annotation-ready'
pseudomolecules.
RESULTS: With GPM, loaded datasets can be connected to each other via their
logical relationships which accomplishes tasks to 'group,' 'merge,' 'order and
orient' sequences in a draft assembly. Manual editing can also be performed with 
a user-friendly graphical interface. Final pseudomolecules reflect a user's total
data package and are available for long-term project management. GPM is a
web-based pipeline and an important part of a Laboratory Information Management
System (LIMS) which can be easily deployed on local servers for any genome
research laboratory.
AVAILABILITY AND IMPLEMENTATION: The GPM (with LIMS) package is available at
https://github.com/Jianwei-Zhang/LIMS CONTACTS: jzhang@mail.hzau.edu.cn or
rwing@mail.arizona.eduSupplementary information: Supplementary data are available
at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw370 
PMCID: PMC5048067
PMID: 27318200  [PubMed - in process]


435. Bioinformatics. 2016 Oct 15;32(20):3190-3192. Epub 2016 Jun 17.

TADtool: visual parameter identification for TAD-calling algorithms.

Kruse K(1), Hug CB(1), Hernández-Rodríguez B(1), Vaquerizas JM(1).

Author information: 
(1)Max Planck Institute for Molecular Biomedicine, Münster 48149, Germany.

Eukaryotic genomes are hierarchically organized into topologically associating
domains (TADs). The computational identification of these domains and their
associated properties critically depends on the choice of suitable parameters of 
TAD-calling algorithms. To reduce the element of trial-and-error in parameter
selection, we have developed TADtool: an interactive plot to find robust
TAD-calling parameters with immediate visual feedback. TADtool allows the direct 
export of TADs called with a chosen set of parameters for two of the most common 
TAD calling algorithms: directionality and insulation index. It can be used as an
intuitive, standalone application or as a Python package for maximum
flexibility.AVAILABILITY AND IMPLEMENTATION: TADtool is available as a Python
package from GitHub (https://github.com/vaquerizaslab/tadtool) or can be
installed directly via PyPI, the Python package index (tadtool).
CONTACT: kai.kruse@mpi-muenster.mpg.de, jmv@mpi-muenster.mpg.deSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw368 
PMCID: PMC5048066
PMID: 27318199  [PubMed - in process]


436. J Struct Biol. 2016 Aug;195(2):252-8. doi: 10.1016/j.jsb.2016.06.011. Epub 2016
Jun 15.

Defining the limits and reliability of rigid-body fitting in cryo-EM maps using
multi-scale image pyramids.

van Zundert GC(1), Bonvin AM(2).

Author information: 
(1)Bijvoet Center for Biomolecular Research, Faculty of Science - Chemistry,
Utrecht University, Utrecht 3584 CH, The Netherlands. (2)Bijvoet Center for
Biomolecular Research, Faculty of Science - Chemistry, Utrecht University,
Utrecht 3584 CH, The Netherlands. Electronic address: a.m.j.j.bonvin@uu.nl.

Cryo-electron microscopy provides fascinating structural insight into large
macromolecular machines at increasing detail. Despite significant advances in the
field, the resolution of the resulting three-dimensional images is still
typically insufficient for de novo model building. To bridge the resolution gap
and give an atomic interpretation to the data, high-resolution models are
typically placed into the density as rigid bodies. Unfortunately, this is often
done manually using graphics software, a subjective method that can lead to
over-interpretation of the data. A more objective approach is to perform an
exhaustive cross-correlation-based search to fit subunits into the density. Here 
we show, using five experimental ribosome maps ranging in resolution from 5.5 to 
6.9Å, that cross-correlation-based fitting is capable of successfully fitting
subunits correctly in the density for over 90% of the cases. Importantly, we
provide indicators for the reliability and ambiguity of a fit, using the Fisher
z-transformation and its associated confidence intervals, giving a formal
approach to identify over-interpreted regions in the density. In addition, we
quantify the resolution requirement for a successful fit as a function of the
subunit size. For larger subunits the resolution of the data can be down-filtered
to 20Å while still retaining an unambiguous fit. We leverage this information
through the use of multi-scale image pyramids to accelerate the search up to
30-fold on CPUs and 40-fold on GPUs at a negligible loss in success rate. We
implemented this approach in our rigid-body fitting software PowerFit, which can 
be freely downloaded from https://github.com/haddocking/powerfit.

Copyright © 2016 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.jsb.2016.06.011 
PMID: 27318041  [PubMed - in process]


437. BMC Bioinformatics. 2016 Jun 17;17(1):244. doi: 10.1186/s12859-016-1133-3.

PGA: an R/Bioconductor package for identification of novel peptides using a
customized database derived from RNA-Seq.

Wen B(1), Xu S(1), Zhou R(1), Zhang B(2), Wang X(2), Liu X(1), Xu X(1), Liu
S(3,)(4).

Author information: 
(1)BGI-Shenzhen, Shenzhen, 518083, China. (2)Department of Biomedical
Informatics, Vanderbilt University School of Medicine, Nashville, TN, 37232, USA.
(3)BGI-Shenzhen, Shenzhen, 518083, China. siqiliu@genomics.cn. (4)Beijing
Institute of Genomics, Chinese Academy of Sciences, Beijing, 100101, China.
siqiliu@genomics.cn.

BACKGROUND: Peptide identification based upon mass spectrometry (MS) is generally
achieved by comparison of the experimental mass spectra with the theoretically
digested peptides derived from a reference protein database. Obviously, this
strategy could not identify peptide and protein sequences that are absent from a 
reference database. A customized protein database on the basis of RNA-Seq data is
thus proposed to assist with and improve the identification of novel peptides.
Correspondingly, development of a comprehensive pipeline, which provides an
end-to-end solution for novel peptide detection with the customized protein
database, is necessary.
RESULTS: A pipeline with an R package, assigned as a PGA utility, was developed
that enables automated treatment to the tandem mass spectrometry (MS/MS) data
acquired from different MS platforms and construction of customized protein
databases based on RNA-Seq data with or without a reference genome guide. Hence, 
PGA can identify novel peptides and generate an HTML-based report with a
visualized interface. On the basis of a published dataset, PGA was employed to
identify peptides, resulting in 636 novel peptides, including 510 single amino
acid polymorphism (SAP) peptides, 2 INDEL peptides, 49 splice junction peptides, 
and 75 novel transcript-derived peptides. The software is freely available from
http://bioconductor.org/packages/PGA/ , and the example reports are available at 
http://wenbostar.github.io/PGA/ .
CONCLUSIONS: The pipeline of PGA, aimed at being platform-independent and
easy-to-use, was successfully developed and shown to be capable of identifying
novel peptides by searching the customized protein database derived from RNA-Seq 
data.

DOI: 10.1186/s12859-016-1133-3 
PMCID: PMC4912784
PMID: 27316337  [PubMed - in process]


438. BMC Genomics. 2016 Jun 17;17:467. doi: 10.1186/s12864-016-2816-x.

EventPointer: an effective identification of alternative splicing events using
junction arrays.

Romero JP(1,)(2), Muniategui A(1,)(2), De Miguel FJ(3), Aramburu A(1,)(2),
Montuenga L(3,)(4,)(5), Pio R(3,)(5,)(6), Rubio A(7,)(8).

Author information: 
(1)CEIT, Parque Tecnológico de San Sebastián, Paseo Mikeletegi 48, 20009, San
Sebastián, Gipuzkoa, Spain. (2)Tecnun, University of Navarra, P° de Manuel
Lardizabal 13, 20018, Donostia-San Sebastián, Gipuzkoa, Spain. (3)Program in
Solid Tumors and Biomarkers, CIMA, University of Navarra, Avda. Pío XII, 55,
E-31008, Pamplona, Navarra, Spain. (4)Department of Histology and Pathology,
University of Navarra, Pamplona, Spain. (5)IdiSNA, Navarra Institute for Health
Research, Recinto de Complejo Hospitalario de Navarra, C/Irunlarrea 3, 31008,
Pamplona, Navarra, Spain. (6)Department of Biochemistry and Genetics, University 
of Navarra, Pamplona, Spain. (7)CEIT, Parque Tecnológico de San Sebastián, Paseo 
Mikeletegi 48, 20009, San Sebastián, Gipuzkoa, Spain. arubio@ceit.es. (8)Tecnun, 
University of Navarra, P° de Manuel Lardizabal 13, 20018, Donostia-San Sebastián,
Gipuzkoa, Spain. arubio@ceit.es.

BACKGROUND: Alternative splicing (AS) is a major source of variability in the
transcriptome of eukaryotes. There is an increasing interest in its role in
different pathologies. Before sequencing technology appeared, AS was measured
with specific arrays. However, these arrays did not perform well in the detection
of AS events and provided very large false discovery rates (FDR). Recently the
Human Transcriptome Array 2.0 (HTA 2.0) has been deployed. It includes junction
probes. However, the interpretation software provided by its vendor (TAC 3.0)
does not fully exploit its potential (does not study jointly the exons and
junctions involved in a splicing event) and can only be applied to case-control
studies. New statistical algorithms and software must be developed in order to
exploit the HTA 2.0 array for event detection.
RESULTS: We have developed EventPointer, an R package (built under the
aroma.affymetrix framework) to search and analyze Alternative Splicing events
using HTA 2.0 arrays. This software uses a linear model that broadens its
application from plain case-control studies to complex experimental designs.
Given the CEL files and the design and contrast matrices, the software retrieves 
a list of all the detected events indicating: 1) the type of event (exon
cassette, alternative 3', etc.), 2) its fold change and its statistical
significance, and 3) the potential protein domains affected by the AS events and 
the statistical significance of the possible enrichment. Our tests have shown
that EventPointer has an extremely low FDR value (only 1 false positive within
the tested top-200 events). This software is publicly available and it has been
uploaded to GitHub.
CONCLUSIONS: This software empowers the HTA 2.0 arrays for AS event detection as 
an alternative to RNA-seq: simplifying considerably the required analysis,
speeding it up and reducing the required computational power.

DOI: 10.1186/s12864-016-2816-x 
PMCID: PMC4912780
PMID: 27315794  [PubMed - in process]


439. Bioinformatics. 2016 Oct 1;32(19):2981-7. doi: 10.1093/bioinformatics/btw357.
Epub 2016 Jun 16.

@MInter: automated text-mining of microbial interactions.

Lim KM(1), Li C(2), Chng KR(3), Nagarajan N(2).

Author information: 
(1)Computational and Systems Biology, Genome Institute of Singapore, Singapore
138672, Singapore Computational Biology Program, Faculty of Science.
(2)Computational and Systems Biology, Genome Institute of Singapore, Singapore
138672, Singapore Department of Computer Science, National University of
Singapore, Singapore, Singapore. (3)Computational and Systems Biology, Genome
Institute of Singapore, Singapore 138672, Singapore.

MOTIVATION: Microbial consortia are frequently defined by numerous interactions
within the community that are key to understanding their function. While
microbial interactions have been extensively studied experimentally, information 
regarding them is dispersed in the scientific literature. As manual collation is 
an infeasible option, automated data processing tools are needed to make this
information easily accessible.
RESULTS: We present @MInter, an automated information extraction system based on 
Support Vector Machines to analyze paper abstracts and infer microbial
interactions. @MInter was trained and tested on a manually curated gold standard 
dataset of 735 species interactions and 3917 annotated abstracts, constructed as 
part of this study. Cross-validation analysis showed that @MInter was able to
detect abstracts pertaining to one or more microbial interactions with high
specificity (specificity = 95%, AUC = 0.97). Despite challenges in identifying
specific microbial interactions in an abstract (interaction level recall = 95%,
precision = 25%), @MInter was shown to reduce annotator workload 13-fold compared
to alternate approaches. Applying @MInter to 175 bacterial species abundant on
human skin, we identified a network of 357 literature-reported microbial
interactions, demonstrating its utility for the study of microbial communities.
AVAILABILITY AND IMPLEMENTATION: @MInter is freely available at
https://github.com/CSB5/atminter
CONTACT: nagarajann@gis.a-star.edu.sg
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw357 
PMID: 27312413  [PubMed - in process]


440. Bioinformatics. 2016 Oct 1;32(19):3047-8. doi: 10.1093/bioinformatics/btw354.
Epub 2016 Jun 16.

MultiQC: summarize analysis results for multiple tools and samples in a single
report.

Ewels P(1), Magnusson M(2), Lundin S(3), Käller M(3).

Author information: 
(1)Department of Biochemistry and Biophysics, Science for Life Laboratory,
Stockholm University, Stockholm 106 91, Sweden. (2)Department of Molecular
Medicine and Surgery, Science for Life Laboratory, Center for Molecular Medicine,
Karolinska Institutet, Stockholm, Sweden. (3)Science for Life Laboratory, School 
of Biotechnology, Division of Gene Technology, Royal Institute of Technology,
Stockholm, Sweden.

MOTIVATION: Fast and accurate quality control is essential for studies involving 
next-generation sequencing data. Whilst numerous tools exist to quantify QC
metrics, there is no common approach to flexibly integrate these across tools and
large sample sets. Assessing analysis results across an entire project can be
time consuming and error prone; batch effects and outlier samples can easily be
missed in the early stages of analysis.
RESULTS: We present MultiQC, a tool to create a single report visualising output 
from multiple tools across many samples, enabling global trends and biases to be 
quickly identified. MultiQC can plot data from many common bioinformatics tools
and is built to allow easy extension and customization.
AVAILABILITY AND IMPLEMENTATION: MultiQC is available with an GNU GPLv3 license
on GitHub, the Python Package Index and Bioconda. Documentation and example
reports are available at http://multiqc.info
CONTACT: phil.ewels@scilifelab.se.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw354 
PMCID: PMC5039924
PMID: 27312411  [PubMed - in process]


441. Bioinformatics. 2016 Oct 1;32(19):3032-4. doi: 10.1093/bioinformatics/btw355.
Epub 2016 Jun 16.

ARGON: fast, whole-genome simulation of the discrete time Wright-fisher process.

Palamara PF(1).

Author information: 
(1)Department of Epidemiology, Harvard T. H. Chan School of Public Health,
Boston, MA 02115, USA and Program in Medical and Population Genetics, Broad
Institute of Harvard and MIT, Cambridge, MA 02142, USA.

MOTIVATION: Simulation under the coalescent model is ubiquitous in the analysis
of genetic data. The rapid growth of real data sets from multiple human
populations led to increasing interest in simulating very large sample sizes at
whole-chromosome scales. When the sample size is large, the coalescent model
becomes an increasingly inaccurate approximation of the discrete time
Wright-Fisher model (DTWF). Analytical and computational treatment of the DTWF,
however, is generally harder.
RESULTS: We present a simulator (ARGON) for the DTWF process that scales up to
hundreds of thousands of samples and whole-chromosome lengths, with a time/memory
performance comparable or superior to currently available methods for coalescent 
simulation. The simulator supports arbitrary demographic history, migration,
Newick tree output, variable mutation/recombination rates and gene conversion,
and efficiently outputs pairwise identical-by-descent sharing data.
AVAILABILITY: ARGON (version 0.1) is written in Java, open source, and freely
available at https://github.com/pierpal/ARGON CONTACT: ppalama@hsph.harvard.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw355 
PMID: 27312410  [PubMed - in process]


442. PLoS Comput Biol. 2016 Jun 16;12(6):e1004753. doi: 10.1371/journal.pcbi.1004753. 
eCollection 2016.

GRAbB: Selective Assembly of Genomic Regions, a New Niche for Genomic Research.

Brankovics B(1,)(2), Zhang H(3), van Diepeningen AD(1), van der Lee TA(4),
Waalwijk C(4), de Hoog GS(1,)(2).

Author information: 
(1)CBS-KNAW Fungal Biodiversity Centre, Utrecht, the Netherlands. (2)Institute of
Biodiversity and Ecosystem Dynamics, University of Amsterdam, Amsterdam, the
Netherlands. (3)State Key Laboratory for Biology of Plant Diseases and Insect
Pests, Institute of Plant Protection, Chinese Academy of Agriculture Sciences,
Beijing, China. (4)Wageningen University and Research Centre, Wageningen, the
Netherlands.

GRAbB (Genomic Region Assembly by Baiting) is a new program that is dedicated to 
assemble specific genomic regions from NGS data. This approach is especially
useful when dealing with multi copy regions, such as mitochondrial genome and the
rDNA repeat region, parts of the genome that are often neglected or poorly
assembled, although they contain interesting information from phylogenetic or
epidemiologic perspectives, but also single copy regions can be assembled. The
program is capable of targeting multiple regions within a single run.
Furthermore, GRAbB can be used to extract specific loci from NGS data, based on
homology, like sequences that are used for barcoding. To make the assembly
specific, a known part of the region, such as the sequence of a PCR amplicon or a
homologous sequence from a related species must be specified. By assembling only 
the region of interest, the assembly process is computationally much less
demanding and may lead to assemblies of better quality. In this study the
different applications and functionalities of the program are demonstrated such
as: exhaustive assembly (rDNA region and mitochondrial genome), extracting
homologous regions or genes (IGS, RPB1, RPB2 and TEF1a), as well as extracting
multiple regions within a single run. The program is also compared with MITObim, 
which is meant for the exhaustive assembly of a single target based on a similar 
query sequence. GRAbB is shown to be more efficient than MITObim in terms of
speed, memory and disk usage. The other functionalities (handling multiple
targets simultaneously and extracting homologous regions) of the new program are 
not matched by other programs. The program is available with explanatory
documentation at https://github.com/b-brankovics/grabb. GRAbB has been tested on 
Ubuntu (12.04 and 14.04), Fedora (23), CentOS (7.1.1503) and Mac OS X (10.7).
Furthermore, GRAbB is available as a docker repository: brankovics/grabb
(https://hub.docker.com/r/brankovics/grabb/).

DOI: 10.1371/journal.pcbi.1004753 
PMCID: PMC4911045
PMID: 27308864  [PubMed - in process]


443. Bioinformatics. 2016 Jun 15;32(12):i90-i100. doi: 10.1093/bioinformatics/btw247.

Jumping across biomedical contexts using compressive data fusion.

Zitnik M(1), Zupan B(2).

Author information: 
(1)Department of Computer Science, Stanford University, CA 94305, USA Faculty of 
Computer and Information Science, University of Ljubljana, Ljubljana, Slovenia
1000. (2)Faculty of Computer and Information Science, University of Ljubljana,
Ljubljana, Slovenia 1000 Department of Molecular and Human Genetics, Baylor
College of Medicine, TX 77030, USA.

MOTIVATION: The rapid growth of diverse biological data allows us to consider
interactions between a variety of objects, such as genes, chemicals, molecular
signatures, diseases, pathways and environmental exposures. Often, any pair of
objects-such as a gene and a disease-can be related in different ways, for
example, directly via gene-disease associations or indirectly via functional
annotations, chemicals and pathways. Different ways of relating these objects
carry different semantic meanings However, traditional methods disregard these
semantics and thus cannot fully exploit their value in data modeling.
RESULTS: We present Medusa, an approach to detect size-k modules of objects that,
taken together, appear most significant to another set of objects. Medusa
operates on large-scale collections of heterogeneous datasets and explicitly
distinguishes between diverse data semantics. It advances research along two
dimensions: it builds on collective matrix factorization to derive different
semantics, and it formulates the growing of the modules as a submodular
optimization program. Medusa is flexible in choosing or combining semantic
meanings and provides theoretical guarantees about detection quality. In a
systematic study on 310 complex diseases, we show the effectiveness of Medusa in 
associating genes with diseases and detecting disease modules. We demonstrate
that in predicting gene-disease associations Medusa compares favorably to methods
that ignore diverse semantic meanings. We find that the utility of different
semantics depends on disease categories and that, overall, Medusa recovers
disease modules more accurately when combining different semantics.
AVAILABILITY AND IMPLEMENTATION: Source code is at
http://github.com/marinkaz/medusa
CONTACT: marinka@cs.stanford.edu, blaz.zupan@fri.uni-lj.si.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw247 
PMCID: PMC4908331
PMID: 27307649  [PubMed - in process]


444. Bioinformatics. 2016 Jun 15;32(12):i44-i51. doi: 10.1093/bioinformatics/btw251.

PHOCOS: inferring multi-feature phenotypic crosstalk networks.

Deng Y(1), Altschuler SJ(1), Wu LF(1).

Author information: 
(1)Department of Pharmaceutical Chemistry, University of California at San
Francisco, San Francisco, CA 94158, USA.

MOTIVATION: Quantification of cellular changes to perturbations can provide a
powerful approach to infer crosstalk among molecular components in biological
networks. Existing crosstalk inference methods conduct network-structure learning
based on a single phenotypic feature (e.g. abundance) of a biomarker. These
approaches are insufficient for analyzing perturbation data that can contain
information about multiple features (e.g. abundance, activity or localization) of
each biomarker.
RESULTS: We propose a computational framework for inferring phenotypic crosstalk 
(PHOCOS) that is suitable for high-content microscopy or other modalities that
capture multiple phenotypes per biomarker. PHOCOS uses a robust graph-learning
paradigm to predict direct effects from potential indirect effects and identify
errors owing to noise or missing links. The result is a multi-feature, sparse
network that parsimoniously captures direct and strong interactions across
phenotypic attributes of multiple biomarkers. We use simulated and biological
data to demonstrate the ability of PHOCOS to recover multi-attribute crosstalk
networks from cellular perturbation assays.
AVAILABILITY AND IMPLEMENTATION: PHOCOS is available in open source at
https://github.com/AltschulerWu-Lab/PHOCOS CONTACT: steven.altschuler@ucsf.edu or
lani.wu@ucsf.edu.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw251 
PMCID: PMC4908335
PMID: 27307643  [PubMed - in process]


445. Bioinformatics. 2016 Jun 15;32(12):i378-i385. doi: 10.1093/bioinformatics/btw281.

A novel algorithm for calling mRNA m6A peaks by modeling biological variances in 
MeRIP-seq data.

Cui X(1), Meng J(2), Zhang S(3), Chen Y(4), Huang Y(5).

Author information: 
(1)Department of Electrical and Computer Engineering, University of Texas at San 
Antonio, TX 78249, USA. (2)Department of Biological Science, Xi'an
Jiaotong-Liverpool University, Suzhou 215123, China. (3)College of Automation,
Northwestern Polytechnical University, Xi'an 710072, China. (4)Greehey Children's
Cancer Research Institute Department of Epidemiology and Biostatistics,
University of Texas Health Science Center at San Antonio, TX 78229, USA.
(5)Department of Electrical and Computer Engineering, University of Texas at San 
Antonio, TX 78249, USA Department of Epidemiology and Biostatistics, University
of Texas Health Science Center at San Antonio, TX 78229, USA.

MOTIVATION: N(6)-methyl-adenosine (m(6)A) is the most prevalent mRNA methylation 
but precise prediction of its mRNA location is important for understanding its
function. A recent sequencing technology, known as Methylated RNA
Immunoprecipitation Sequencing technology (MeRIP-seq), has been developed for
transcriptome-wide profiling of m(6)A. We previously developed a peak calling
algorithm called exomePeak. However, exomePeak over-simplifies data
characteristics and ignores the reads' variances among replicates or reads
dependency across a site region. To further improve the performance, new model is
needed to address these important issues of MeRIP-seq data.
RESULTS: We propose a novel, graphical model-based peak calling method, MeTPeak, 
for transcriptome-wide detection of m(6)A sites from MeRIP-seq data. MeTPeak
explicitly models read count of an m(6)A site and introduces a hierarchical layer
of Beta variables to capture the variances and a Hidden Markov model to
characterize the reads dependency across a site. In addition, we developed a
constrained Newton's method and designed a log-barrier function to compute
analytically intractable, positively constrained Beta parameters. We applied our 
algorithm to simulated and real biological datasets and demonstrated significant 
improvement in detection performance and robustness over exomePeak. Prediction
results on publicly available MeRIP-seq datasets are also validated and shown to 
be able to recapitulate the known patterns of m(6)A, further validating the
improved performance of MeTPeak.
AVAILABILITY AND IMPLEMENTATION: The package 'MeTPeak' is implemented in R and
C ++, and additional details are available at
https://github.com/compgenomics/MeTPeak
CONTACT: yufei.huang@utsa.edu or xdchoi@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw281 
PMCID: PMC4908365
PMID: 27307641  [PubMed - in process]


446. Bioinformatics. 2016 Jun 15;32(12):i360-i368. doi: 10.1093/bioinformatics/btw265.

RNAiFold2T: Constraint Programming design of thermo-IRES switches.

Garcia-Martin JA(1), Dotu I(2), Fernandez-Chamorro J(3), Lozano G(3), Ramajo
J(3), Martinez-Salas E(3), Clote P(1).

Author information: 
(1)Biology Department, Boston College, Chestnut Hill, MA 02467, USA.
(2)Department of Experimental and Health Sciences, Research Programme on
Biomedical Informatics (GRIB), Universitat Pompeu Fabra. Dr. Aiguader 88,
Barcelona, Spain. (3)Centro de Biologia Molecular Severo Ochoa, Consejo Superior 
de Investigaciones Cientificas-Universidad Autonoma de Madrid, 28049 Madrid,
Spain.

MOTIVATION: RNA thermometers (RNATs) are cis-regulatory elements that change
secondary structure upon temperature shift. Often involved in the regulation of
heat shock, cold shock and virulence genes, RNATs constitute an interesting
potential resource in synthetic biology, where engineered RNATs could prove to be
useful tools in biosensors and conditional gene regulation.
RESULTS: Solving the 2-temperature inverse folding problem is critical for RNAT
engineering. Here we introduce RNAiFold2T, the first Constraint Programming (CP) 
and Large Neighborhood Search (LNS) algorithms to solve this problem.
Benchmarking tests of RNAiFold2T against existent programs (adaptive walk and
genetic algorithm) inverse folding show that our software generates two orders of
magnitude more solutions, thus allowing ample exploration of the space of
solutions. Subsequently, solutions can be prioritized by computing various
measures, including probability of target structure in the ensemble, melting
temperature, etc. Using this strategy, we rationally designed two thermosensor
internal ribosome entry site (thermo-IRES) elements, whose normalized
cap-independent translation efficiency is approximately 50% greater at 42 °C than
30 °C, when tested in reticulocyte lysates. Translation efficiency is lower than 
that of the wild-type IRES element, which on the other hand is fully resistant to
temperature shift-up. This appears to be the first purely computational design of
functional RNA thermoswitches, and certainly the first purely computational
design of functional thermo-IRES elements.
AVAILABILITY: RNAiFold2T is publicly available as part of the new release
RNAiFold3.0 at https://github.com/clotelab/RNAiFold and
http://bioinformatics.bc.edu/clotelab/RNAiFold, which latter has a web server as 
well. The software is written in C ++ and uses OR-Tools CP search engine.
CONTACT: clote@bc.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw265 
PMCID: PMC4908349
PMID: 27307638  [PubMed - in process]


447. Bioinformatics. 2016 Jun 15;32(12):i216-i224. doi: 10.1093/bioinformatics/btw267.

Genome assembly from synthetic long read clouds.

Kuleshov V(1), Snyder MP(2), Batzoglou S(3).

Author information: 
(1)Department of Computer Science, Stanford University Department of Genetics,
Stanford University School of Medicine, Stanford, CA 94305, USA. (2)Department of
Genetics, Stanford University School of Medicine, Stanford, CA 94305, USA.
(3)Department of Computer Science, Stanford University.

MOTIVATION: Despite rapid progress in sequencing technology, assembling de novo
the genomes of new species as well as reconstructing complex metagenomes remains 
major technological challenges. New synthetic long read (SLR) technologies
promise significant advances towards these goals; however, their applicability is
limited by high sequencing requirements and the inability of current assembly
paradigms to cope with combinations of short and long reads.
RESULTS: Here, we introduce Architect, a new de novo scaffolder aimed at SLR
technologies. Unlike previous assembly strategies, Architect does not require a
costly subassembly step; instead it assembles genomes directly from the SLR's
underlying short reads, which we refer to as read clouds This enables a 4- to
20-fold reduction in sequencing requirements and a 5-fold increase in assembly
contiguity on both genomic and metagenomic datasets relative to state-of-the-art 
assembly strategies aimed directly at fully subassembled long reads.
AVAILABILITY AND IMPLEMENTATION: Our source code is freely available at
https://github.com/kuleshov/architect
CONTACT: kuleshov@stanford.edu.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw267 
PMCID: PMC4908351
PMID: 27307620  [PubMed - in process]


448. Bioinformatics. 2016 Jun 15;32(12):i209-i215. doi: 10.1093/bioinformatics/btw258.

phRAIDER: Pattern-Hunter based Rapid Ab Initio Detection of Elementary Repeats.

Schaeffer CE(1), Figueroa ND(1), Liu X(2), Karro JE(3).

Author information: 
(1)Department of Computer Science and Software Engineering. (2)Department of
Cell, Molecular, and Structural Biology. (3)Department of Computer Science and
Software Engineering Department of Cell, Molecular, and Structural Biology
Department of Microbiology Department of Statistics, Miami University, Oxford,
OH, USA.

MOTIVATION: Transposable elements (TEs) and repetitive DNA make up a sizable
fraction of Eukaryotic genomes, and their annotation is crucial to the study of
the structure, organization, and evolution of any newly sequenced genome.
Although RepeatMasker and nHMMER are useful for identifying these repeats, they
require a pre-compiled repeat library-which is not always available. De novo
identification tools such as Recon, RepeatScout or RepeatGluer serve to identify 
TEs purely from sequence content, but are either limited by runtimes that
prohibit whole-genome use or degrade in quality in the presence of substitutions 
that disrupt the sequence patterns.
RESULTS: phRAIDER is a de novo TE identification tool that address the issues of 
excessive runtime without sacrificing sensitivity as compared to competing tools.
The underlying model is a new definition of elementary repeats that incorporates 
the PatternHunter spaced seed model, allowing for greater sensitivity in the
presence of genomic substitutions. As compared with the premier tool in the
literature, RepeatScout, phRAIDER shows an average 10× speedup on any single
human chromosome and has the ability to process the whole human genome in just
over three hours. Here we discuss the tool, the theoretical model underlying the 
tool, and the results demonstrating its effectiveness.
AVAILABILITY AND IMPLEMENTATION: phRAIDER is an open source tool available from
https://github.com/karroje/phRAIDER CONTACT: : karroje@miamiOH.edu or
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw258 
PMCID: PMC4908342
PMID: 27307619  [PubMed - in process]


449. Bioinformatics. 2016 Jun 15;32(12):i201-i208. doi: 10.1093/bioinformatics/btw279.

Compacting de Bruijn graphs from sequencing data quickly and in low memory.

Chikhi R(1), Limasset A(2), Medvedev P(3).

Author information: 
(1)CNRS, CRIStAL, Lille, France. (2)ENS Cachan Brittany, Bruz, France.
(3)Department of Computer Science and Engineering, The Pennsylvania State
University, USA Department of Biochemistry and Molecular Biology, The
Pennsylvania State University, USA Genome Sciences Institute of the Huck, The
Pennsylvania State University, USA.

MOTIVATION: As the quantity of data per sequencing experiment increases, the
challenges of fragment assembly are becoming increasingly computational. The de
Bruijn graph is a widely used data structure in fragment assembly algorithms,
used to represent the information from a set of reads. Compaction is an important
data reduction step in most de Bruijn graph based algorithms where long simple
paths are compacted into single vertices. Compaction has recently become the
bottleneck in assembly pipelines, and improving its running time and memory usage
is an important problem.
RESULTS: We present an algorithm and a tool bcalm 2 for the compaction of de
Bruijn graphs. bcalm 2 is a parallel algorithm that distributes the input based
on a minimizer hashing technique, allowing for good balance of memory usage
throughout its execution. For human sequencing data, bcalm 2 reduces the
computational burden of compacting the de Bruijn graph to roughly an hour and
3 GB of memory. We also applied bcalm 2 to the 22 Gbp loblolly pine and 20 Gbp
white spruce sequencing datasets. Compacted graphs were constructed from raw
reads in less than 2 days and 40 GB of memory on a single machine. Hence, bcalm 2
is at least an order of magnitude more efficient than other available methods.
AVAILABILITY AND IMPLEMENTATION: Source code of bcalm 2 is freely available at:
https://github.com/GATB/bcalm
CONTACT: rayan.chikhi@univ-lille1.fr.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw279 
PMCID: PMC4908363
PMID: 27307618  [PubMed - in process]


450. Bioinformatics. 2016 Jun 15;32(12):i192-i200. doi: 10.1093/bioinformatics/btw277.

RapMap: a rapid, sensitive and accurate tool for mapping RNA-seq reads to
transcriptomes.

Srivastava A(1), Sarkar H(1), Gupta N(1), Patro R(1).

Author information: 
(1)Department of Computer Science, Stony Brook University Stony Brook, New York, 
NY 11794-2424, USA.

MOTIVATION: The alignment of sequencing reads to a transcriptome is a common and 
important step in many RNA-seq analysis tasks. When aligning RNA-seq reads
directly to a transcriptome (as is common in the de novo setting or when a
trusted reference annotation is available), care must be taken to report the
potentially large number of multi-mapping locations per read. This can pose a
substantial computational burden for existing aligners, and can considerably slow
downstream analysis.
RESULTS: We introduce a novel concept, quasi-mapping, and an efficient algorithm 
implementing this approach for mapping sequencing reads to a transcriptome. By
attempting only to report the potential loci of origin of a sequencing read, and 
not the base-to-base alignment by which it derives from the reference, RapMap-our
tool implementing quasi-mapping-is capable of mapping sequencing reads to a
target transcriptome substantially faster than existing alignment tools. The
algorithm we use to implement quasi-mapping uses several efficient data
structures and takes advantage of the special structure of shared sequence
prevalent in transcriptomes to rapidly provide highly-accurate mapping
information. We demonstrate how quasi-mapping can be successfully applied to the 
problems of transcript-level quantification from RNA-seq reads and the clustering
of contigs from de novo assembled transcriptomes into biologically meaningful
groups.
AVAILABILITY AND IMPLEMENTATION: RapMap is implemented in C ++11 and is available
as open-source software, under GPL v3, at https://github.com/COMBINE-lab/RapMap
CONTACT: rob.patro@cs.stonybrook.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw277 
PMCID: PMC4908361
PMID: 27307617  [PubMed - in process]


451. Bioinformatics. 2016 Jun 15;32(12):i174-i182. doi: 10.1093/bioinformatics/btw266.

deBWT: parallel construction of Burrows-Wheeler Transform for large collection of
genomes with de Bruijn-branch encoding.

Liu B(1), Zhu D(1), Wang Y(1).

Author information: 
(1)Center for Bioinformatics, Harbin Institute of Technology, Harbin,
Heilongjiang 150001, China.

MOTIVATION: With the development of high-throughput sequencing, the number of
assembled genomes continues to rise. It is critical to well organize and index
many assembled genomes to promote future genomics studies. Burrows-Wheeler
Transform (BWT) is an important data structure of genome indexing, which has many
fundamental applications; however, it is still non-trivial to construct BWT for
large collection of genomes, especially for highly similar or repetitive genomes.
Moreover, the state-of-the-art approaches cannot well support scalable parallel
computing owing to their incremental nature, which is a bottleneck to use modern 
computers to accelerate BWT construction.
RESULTS: We propose de Bruijn branch-based BWT constructor (deBWT), a novel
parallel BWT construction approach. DeBWT innovatively represents and organizes
the suffixes of input sequence with a novel data structure, de Bruijn branch
encoding. This data structure takes the advantage of de Bruijn graph to
facilitate the comparison between the suffixes with long common prefix, which
breaks the bottleneck of the BWT construction of repetitive genomic sequences.
Meanwhile, deBWT also uses the structure of de Bruijn graph for reducing
unnecessary comparisons between suffixes. The benchmarking suggests that, deBWT
is efficient and scalable to construct BWT for large dataset by parallel
computing. It is well-suited to index many genomes, such as a collection of
individual human genomes, with multiple-core servers or clusters.
AVAILABILITY AND IMPLEMENTATION: deBWT is implemented in C language, the source
code is available at https://github.com/hitbc/deBWT or
https://github.com/DixianZhu/deBWTContact: ydwang@hit.edu.cn
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw266 
PMCID: PMC4908350
PMID: 27307614  [PubMed - in process]


452. Bioinformatics. 2016 Jun 15;32(12):i147-i155. doi: 10.1093/bioinformatics/btw283.

Analysis of differential splicing suggests different modes of short-term splicing
regulation.

Topa H(1), Honkela A(2).

Author information: 
(1)Helsinki Institute for Information Technology HIIT, Department of Computer
Science, Aalto University, Espoo 00076, Finland Helsinki Institute for
Information Technology HIIT, Department of Computer Science, University of
Helsinki, Helsinki 00014, Finland. (2)Helsinki Institute for Information
Technology HIIT, Department of Computer Science, University of Helsinki, Helsinki
00014, Finland.

MOTIVATION: Alternative splicing is an important mechanism in which the regions
of pre-mRNAs are differentially joined in order to form different transcript
isoforms. Alternative splicing is involved in the regulation of normal
physiological functions but also linked to the development of diseases such as
cancer. We analyse differential expression and splicing using RNA-sequencing time
series in three different settings: overall gene expression levels, absolute
transcript expression levels and relative transcript expression levels.
RESULTS: Using estrogen receptor α signaling response as a model system, our
Gaussian process-based test identifies genes with differential splicing and/or
differentially expressed transcripts. We discover genes with consistent changes
in alternative splicing independent of changes in absolute expression and genes
where some transcripts change whereas others stay constant in absolute level. The
results suggest classes of genes with different modes of alternative splicing
regulation during the experiment.
AVAILABILITY AND IMPLEMENTATION: R and Matlab codes implementing the method are
available at https://github.com/PROBIC/diffsplicing An interactive browser for
viewing all model fits is available at
http://users.ics.aalto.fi/hande/splicingGP/ CONTACT: hande.topa@helsinki.fi or
antti.honkela@helsinki.fi
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw283 
PMCID: PMC4908367
PMID: 27307611  [PubMed - in process]


453. Bioinformatics. 2016 Jun 15;32(12):i137-i146. doi: 10.1093/bioinformatics/btw278.

A cross-species bi-clustering approach to identifying conserved co-regulated
genes.

Sun J(1), Jiang Z(2), Tian X(2), Bi J(1).

Author information: 
(1)Department of Computer Science and Engineering. (2)Center for Regenerative
Biology and Department of Animal Science, University of Connecticut, Storrs, CT
06269, USA.

MOTIVATION: A growing number of studies have explored the process of
pre-implantation embryonic development of multiple mammalian species. However,
the conservation and variation among different species in their developmental
programming are poorly defined due to the lack of effective computational methods
for detecting co-regularized genes that are conserved across species. The most
sophisticated method to date for identifying conserved co-regulated genes is a
two-step approach. This approach first identifies gene clusters for each species 
by a cluster analysis of gene expression data, and subsequently computes the
overlaps of clusters identified from different species to reveal common
subgroups. This approach is ineffective to deal with the noise in the expression 
data introduced by the complicated procedures in quantifying gene expression.
Furthermore, due to the sequential nature of the approach, the gene clusters
identified in the first step may have little overlap among different species in
the second step, thus difficult to detect conserved co-regulated genes.
RESULTS: We propose a cross-species bi-clustering approach which first denoises
the gene expression data of each species into a data matrix. The rows of the data
matrices of different species represent the same set of genes that are
characterized by their expression patterns over the developmental stages of each 
species as columns. A novel bi-clustering method is then developed to cluster
genes into subgroups by a joint sparse rank-one factorization of all the data
matrices. This method decomposes a data matrix into a product of a column vector 
and a row vector where the column vector is a consistent indicator across the
matrices (species) to identify the same gene cluster and the row vector specifies
for each species the developmental stages that the clustered genes co-regulate.
Efficient optimization algorithm has been developed with convergence analysis.
This approach was first validated on synthetic data and compared to the two-step 
method and several recent joint clustering methods. We then applied this approach
to two real world datasets of gene expression during the pre-implantation
embryonic development of the human and mouse. Co-regulated genes consistent
between the human and mouse were identified, offering insights into conserved
functions, as well as similarities and differences in genome activation timing
between the human and mouse embryos.
AVAILABILITY AND IMPLEMENTATION: The R package containing the implementation of
the proposed method in C ++ is available at: https://github.com/JavonSun/mvbc.git
and also at the R platform https://www.r-project.org/
CONTACT: jinbo@engr.uconn.edu.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw278 
PMCID: PMC4908362
PMID: 27307610  [PubMed - in process]


454. mSphere. 2016 Jan 13;1(1). pii: e00050-15. doi: 10.1128/mSphere.00050-15.

SSTAR, a Stand-Alone Easy-To-Use Antimicrobial Resistance Gene Predictor.

de Man TJ(1), Limbago BM(1).

Author information: 
(1)Centers for Disease Control and Prevention, Division of Healthcare Quality
Promotion, Atlanta, Georgia, USA.

We present the easy-to-use Sequence Search Tool for Antimicrobial Resistance,
SSTAR. It combines a locally executed BLASTN search against a customizable
database with an intuitive graphical user interface for identifying antimicrobial
resistance (AR) genes from genomic data. Although the database is initially
populated from a public repository of acquired resistance determinants (i.e.,
ARG-ANNOT), it can be customized for particular pathogen groups and resistance
mechanisms. For instance, outer membrane porin sequences associated with
carbapenem resistance phenotypes can be added, and known intrinsic mechanisms can
be included. Unique about this tool is the ability to easily detect putative new 
alleles and truncated versions of existing AR genes. Variants and potential new
alleles are brought to the attention of the user for further investigation. For
instance, SSTAR is able to identify modified or truncated versions of porins,
which may be of great importance in carbapenemase-negative carbapenem-resistant
Enterobacteriaceae. SSTAR is written in Java and is therefore platform
independent and compatible with both Windows and Unix operating systems. SSTAR
and its manual, which includes a simple installation guide, are freely available 
from
https://github.com/tomdeman-bio/Sequence-Search-Tool-for-Antimicrobial-Resistance
-SSTAR-. IMPORTANCE Whole-genome sequencing (WGS) is quickly becoming a routine
method for identifying genes associated with antimicrobial resistance (AR).
However, for many microbiologists, the use and analysis of WGS data present a
substantial challenge. We developed SSTAR, software with a graphical user
interface that enables the identification of known AR genes from WGS and has the 
unique capacity to easily detect new variants of known AR genes, including
truncated protein variants. Current software solutions do not notify the user
when genes are truncated and, therefore, likely nonfunctional, which makes
phenotype predictions less accurate. SSTAR users can apply any AR database of
interest as a reference comparator and can manually add genes that impact
resistance, even if such genes are not resistance determinants per se (e.g.,
porins and efflux pumps).

DOI: 10.1128/mSphere.00050-15 
PMCID: PMC4863618
PMID: 27303709  [PubMed]


455. mSphere. 2016 Feb 10;1(1). pii: e00078-15. doi: 10.1128/mSphere.00078-15.

Infectio: a Generic Framework for Computational Simulation of Virus Transmission 
between Cells.

Yakimovich A(1), Yakimovich Y(1), Schmid M(2), Mercer J(3), Sbalzarini IF(4),
Greber UF(1).

Author information: 
(1)Institute of Molecular Life Sciences, University of Zurich, Zurich,
Switzerland. (2)University of Zurich, Zurich, Switzerland. (3)Medical Research
Council, Laboratory for Molecular Cell Biology, University College London,
London, United Kingdom. (4)Faculty of Computer Science, Technische Universität
Dresden, Dresden, Germany; Center for Systems Biology, Dresden, Germany; Max
Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany.

Viruses spread between cells, tissues, and organisms by cell-free and cell-cell
mechanisms, depending on the cell type, the nature of the virus, or the phase of 
the infection cycle. The mode of viral transmission has a large impact on disease
development, the outcome of antiviral therapies or the efficacy of gene therapy
protocols. The transmission mode of viruses can be addressed in tissue culture
systems using live-cell imaging. Yet even in relatively simple cell cultures, the
mechanisms of viral transmission are difficult to distinguish. Here we present a 
cross-platform software framework called "Infectio," which is capable of
simulating transmission phenotypes in tissue culture of virtually any virus.
Infectio can estimate interdependent biological parameters, for example for
vaccinia virus infection, and differentiate between cell-cell and cell-free virus
spreading. Infectio assists in elucidating virus transmission mechanisms, a
feature useful for designing strategies of perturbing or enhancing viral
transmission. The complexity of the Infectio software is low compared to that of 
other software commonly used to quantitate features of cell biological images,
which yields stable and relatively error-free output from Infectio. The software 
is open source (GPLv3 license), and operates on the major platforms (Windows,
Mac, and Linux). The complete source code can be downloaded from
http://infectio.github.io/index.html. IMPORTANCE Infectio presents a generalized 
platform to analyze virus infection spread between cells. It allows the
simulation of plaque phenotypes from image-based assays. Viral plaques are the
result of virus spreading from primary infected cells to neighboring cells. This 
is a complex process and involves neighborhood effects at cell-cell contact sites
or fluid dynamics in the extracellular medium. Infectio differentiates between
two major modes of virus transmission between cells, allowing in silico testing
of hypotheses about spreading mechanisms of any virus which can be grown in cell 
cultures, based on experimentally measured parameters, such as infection
intensity or cell killing. The results of these tests can be compared with
experimental data and allow interpretations with regard to biophysical
mechanisms. Infectio also facilitates characterizations of the mode of action of 
therapeutic agents, such as oncolytic viruses or other infectious or cytotoxic
agents.

DOI: 10.1128/mSphere.00078-15 
PMCID: PMC4863613
PMID: 27303704  [PubMed]


456. J Proteome Res. 2016 Aug 5;15(8):2863-70. doi: 10.1021/acs.jproteome.6b00274.
Epub 2016 Jun 24.

ProXL (Protein Cross-Linking Database): A Platform for Analysis, Visualization,
and Sharing of Protein Cross-Linking Mass Spectrometry Data.

Riffle M(1,)(2), Jaschob D(1), Zelter A(1), Davis TN(1).

Author information: 
(1)Department of Biochemistry, University of Washington , Seattle, Washington
98195, United States. (2)Department of Genome Sciences, University of Washington 
, Seattle, Washington 98195, United States.

ProXL is a Web application and accompanying database designed for sharing,
visualizing, and analyzing bottom-up protein cross-linking mass spectrometry data
with an emphasis on structural analysis and quality control. ProXL is designed to
be independent of any particular software pipeline. The import process is
simplified by the use of the ProXL XML data format, which shields developers of
data importers from the relative complexity of the relational database schema.
The database and Web interfaces function equally well for any software pipeline
and allow data from disparate pipelines to be merged and contrasted. ProXL
includes robust public and private data sharing capabilities, including a
project-based interface designed to ensure security and facilitate collaboration 
among multiple researchers. ProXL provides multiple interactive and highly
dynamic data visualizations that facilitate structural-based analysis of the
observed cross-links as well as quality control. ProXL is open-source,
well-documented, and freely available at https://github.com/yeastrc/proxl-web-app
.

DOI: 10.1021/acs.jproteome.6b00274 
PMCID: PMC4977572
PMID: 27302480  [PubMed - in process]


457. Nucleic Acids Res. 2016 Sep 19;44(16):e132. doi: 10.1093/nar/gkw538. Epub 2016
Jun 14.

The exon quantification pipeline (EQP): a comprehensive approach to the
quantification of gene, exon and junction expression from RNA-seq data.

Schuierer S(1), Roma G(2).

Author information: 
(1)Novartis Institutes for Biomedical Research, CH-4056 Basel, Switzerland
sven.schuierer@novartis.com. (2)Novartis Institutes for Biomedical Research,
CH-4056 Basel, Switzerland.

The quantification of transcriptomic features is the basis of the analysis of
RNA-seq data. We present an integrated alignment workflow and a simple
counting-based approach to derive estimates for gene, exon and exon-exon junction
expression. In contrast to previous counting-based approaches, EQP takes into
account only reads whose alignment pattern agrees with the splicing pattern of
the features of interest. This leads to improved gene expression estimates as
well as to the generation of exon counts that allow disambiguating reads between 
overlapping exons. Unlike other methods that quantify skipped introns, EQP offers
a novel way to compute junction counts based on the agreement of the read
alignments with the exons on both sides of the junction, thus providing a
uniformly derived set of counts. We evaluated the performance of EQP on both
simulated and real Illumina RNA-seq data and compared it with other
quantification tools. Our results suggest that EQP provides superior gene
expression estimates and we illustrate the advantages of EQP's exon and junction 
counts. The provision of uniformly derived high-quality counts makes EQP an ideal
quantification tool for differential expression and differential splicing
studies. EQP is freely available for download at
https://github.com/Novartis/EQP-cluster.

© The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkw538 
PMCID: PMC5027495
PMID: 27302131  [PubMed - in process]


458. Phys Rev E. 2016 May;93(5):053303. doi: 10.1103/PhysRevE.93.053303. Epub 2016 May
12.

Motion blur filtering: A statistical approach for extracting confinement forces
and diffusivity from a single blurred trajectory.

Calderon CP(1).

Author information: 
(1)Ursa Analytics, Inc., Denver, Colorado 80212, USA.

Single particle tracking (SPT) can aid in understanding a variety of complex
spatiotemporal processes. However, quantifying diffusivity and confinement forces
from individual live cell trajectories is complicated by inter- and
intratrajectory kinetic heterogeneity, thermal fluctuations, and (experimentally 
resolvable) statistical temporal dependence inherent to the underlying molecule's
time correlated confined dynamics experienced in the cell. The problem is further
complicated by experimental artifacts such as localization uncertainty and motion
blur. The latter is caused by the tagged molecule emitting photons at different
spatial positions during the exposure time of a single frame. The aforementioned 
experimental artifacts induce spurious time correlations in measured SPT time
series that obscure the information of interest (e.g., confinement forces and
diffusivity). We develop a maximum likelihood estimation (MLE) technique that
decouples the above noise sources and systematically treats temporal correlation 
via time series methods. This ultimately permits a reliable algorithm for
extracting diffusivity and effective forces in confined or unconfined
environments. We illustrate how our approach avoids complications inherent to
mean square displacement or autocorrelation techniques. Our algorithm modifies
the established Kalman filter (which does not handle motion blur artifacts) to
provide a likelihood based time series estimation procedure. The result extends
A. J. Berglund's motion blur model [Phys. Rev. E 82, 011917
(2010)PLEEE81539-375510.1103/PhysRevE.82.011917] to handle confined dynamics. The
approach can also systematically utilize (possibly time dependent) localization
uncertainty estimates afforded by image analysis if available. This technique,
which explicitly treats confinement and motion blur within a time domain MLE
framework, uses an exact likelihood (time domain methods facilitate analyzing
nonstationary signals). Our estimator is demonstrated to be consistent over a
wide range of exposure times (5 to 100 ms), diffusion coefficients (1×10^{-3} to 
1μm^{2}/s), and confinement widths (100 nm to 2μm). We demonstrate that
neglecting motion blur or confinement can substantially bias estimation of
kinetic parameters of interest to researchers. The technique also permits one to 
check statistical model assumptions against measured individual trajectories
without "ground truth." The ability to reliably and consistently extract motion
parameters in trajectories exhibiting confined and/or non-stationary dynamics,
without exposure time artifacts corrupting estimates, is expected to aid in
directly comparing trajectories obtained from different experiments or imaging
modalities. A Python implementation is provided (open-source code will be
maintained on GitHub; see also the Supplemental Material with this paper).

DOI: 10.1103/PhysRevE.93.053303 
PMID: 27301001  [PubMed - in process]


459. Nucleic Acids Res. 2016 Sep 19;44(16):e133. doi: 10.1093/nar/gkw540. Epub 2016
Jun 13.

Boiler: lossy compression of RNA-seq alignments using coverage vectors.

Pritt J(1), Langmead B(2).

Author information: 
(1)Department of Computer Science, Johns Hopkins University, Baltimore, MD 21218,
USA Center for Computational Biology, Johns Hopkins University, Baltimore, MD
21205, USA jacobpritt@gmail.com. (2)Department of Computer Science, Johns Hopkins
University, Baltimore, MD 21218, USA Center for Computational Biology, Johns
Hopkins University, Baltimore, MD 21205, USA langmea@cs.jhu.edu.

We describe Boiler, a new software tool for compressing and querying large
collections of RNA-seq alignments. Boiler discards most per-read data, keeping
only a genomic coverage vector plus a few empirical distributions summarizing the
alignments. Since most per-read data is discarded, storage footprint is often
much smaller than that achieved by other compression tools. Despite this, the
most relevant per-read data can be recovered; we show that Boiler compression has
only a slight negative impact on results given by downstream tools for isoform
assembly and quantification. Boiler also allows the user to pose fast and useful 
queries without decompressing the entire file. Boiler is free open source
software available from github.com/jpritt/boiler.

© The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkw540 
PMCID: PMC5027496
PMID: 27298258  [PubMed - in process]


460. Mol Ecol Resour. 2017 Jan;17(1):120-128. doi: 10.1111/1755-0998.12558. Epub 2016 
Jul 12.

Developing educational resources for population genetics in R: an open and
collaborative approach.

Kamvar ZN(1), López-Uribe MM(2), Coughlan S(3), Grünwald NJ(1,)(4), Lapp H(5),
Manel S(6).

Author information: 
(1)Department of Botany and Plant Pathology, Oregon State University, Corvallis, 
OR, USA. (2)Department of Entomology and Plant Pathology, North Carolina State
University, Raleigh, NC, 27695, USA. (3)School of Mathematics, Statistics and
Applied Mathematics, National University of Ireland Galway, Galway, Ireland.
(4)Horticultural Crops Research Unit, USDA Agricultural Research Service,
Corvallis, OR, 97330, USA. (5)Center for Genomic and Computational Biology, Duke 
University, Durham, NC, 27708, USA. (6)EPHE, PSL Research University, CNRS, UM,
SupAgro, IRD, INRA, UMR 5175 CEFE, F-34293, Montpellier, France.

The r computing and statistical language community has developed a myriad of
resources for conducting population genetic analyses. However, resources for
learning how to carry out population genetic analyses in r are scattered and
often incomplete, which can make acquiring this skill unnecessarily difficult and
time consuming. To address this gap, we developed an online community resource
with guidance and working demonstrations for conducting population genetic
analyses in r. The resource is freely available at http://popgen.nescent.org and 
includes material for both novices and advanced users of r for population
genetics. To facilitate continued maintenance and growth of this resource, we
developed a toolchain, process and conventions designed to (i) minimize financial
and labour costs of upkeep; (ii) to provide a low barrier to contribution; and
(iii) to ensure strong quality assurance. The toolchain includes automatic
integration testing of every change and rebuilding of the website when new
vignettes or edits are accepted. The process and conventions largely follow a
common, distributed version control-based contribution workflow, which is used to
provide and manage open peer review by designated website editors. The online
resources include detailed documentation of this process, including video
tutorials. We invite the community of population geneticists working in r to
contribute to this resource, whether for a new use case of their own, or as one
of the vignettes from the 'wish list' we maintain, or by improving existing
vignettes.

© 2016 John Wiley & Sons Ltd.

DOI: 10.1111/1755-0998.12558 
PMID: 27297607  [PubMed - in process]


461. BMC Genomics. 2016 Jun 13;17:453. doi: 10.1186/s12864-016-2799-7.

VDJviz: a versatile browser for immunogenomics data.

Bagaev DV(1), Zvyagin IV(1,)(2,)(3), Putintseva EV(1,)(3), Izraelson
M(1,)(2,)(3), Britanova OV(1,)(2,)(3), Chudakov DM(4,)(5,)(6), Shugay M(7,)(8).

Author information: 
(1)Shemyakin-Ovchinnikov Institute of Bioorganic Chemistry RAS, Miklukho-Maklaya 
16/10, 117997, Moscow, Russia. (2)Pirogov Russian National Research Medical
University, Ostrovityanova 1, 117997, Moscow, Russia. (3)Central European
Institute of Technology, Masaryk University, Brno, Czech republic.
(4)Shemyakin-Ovchinnikov Institute of Bioorganic Chemistry RAS, Miklukho-Maklaya 
16/10, 117997, Moscow, Russia. chudakovdm@mail.ru. (5)Pirogov Russian National
Research Medical University, Ostrovityanova 1, 117997, Moscow, Russia.
chudakovdm@mail.ru. (6)Central European Institute of Technology, Masaryk
University, Brno, Czech republic. chudakovdm@mail.ru. (7)Shemyakin-Ovchinnikov
Institute of Bioorganic Chemistry RAS, Miklukho-Maklaya 16/10, 117997, Moscow,
Russia. mikhail.shugay@gmail.com. (8)Pirogov Russian National Research Medical
University, Ostrovityanova 1, 117997, Moscow, Russia. mikhail.shugay@gmail.com.

BACKGROUND: The repertoire of T- and B-cell receptor sequences encodes the
antigen specificity of adaptive immunity system, determines its present state and
guides its ability to mount effective response against encountered antigens in
future. High throughput sequencing of immune repertoires (Rep-Seq) is a promising
technique that allows to profile millions of antigen receptors of an individual
in a single experiment. While a substantial number of tools for mapping and
assembling Rep-Seq data were published recently, the field still lacks an
intuitive and flexible tool that can be used by researchers with little or no
computational background for in-depth analysis of immune repertoire profiles.
RESULTS: Here we report VDJviz, a web tool that can be used to browse, analyze
and perform quality control of Rep-Seq results generated by various
pre-processing software. On a set of real data examples we show that VDJviz can
be used to explore key repertoire characteristics such as spectratype, repertoire
clonality, V-(D)-J recombination patterns and to identify shared clonotypes. We
also demonstrate the utility of VDJviz in detection of critical Rep-Seq biases
such as artificial repertoire diversity and cross-sample contamination.
CONCLUSIONS: VDJviz is a versatile and lightweight tool that can be easily
employed by biologists, immunologists and immunogeneticists for routine analysis 
and quality control of Rep-Seq data. The software is freely available for
non-commercial purposes, and can be downloaded from:
https://github.com/antigenomics/vdjviz .

DOI: 10.1186/s12864-016-2799-7 
PMCID: PMC4907000
PMID: 27297497  [PubMed - in process]


462. Bioinformatics. 2016 Oct 1;32(19):3029-31. doi: 10.1093/bioinformatics/btw349.
Epub 2016 Jun 13.

GSA-Lightning: ultra-fast permutation-based gene set analysis.

Chang BH(1), Tian W(2).

Author information: 
(1)State Key Laboratory of Genetic Engineering and Collaborative Innovation
Center for Genetics and Development, Department of Biostatistics and
Computational Biology, School of Life Sciences, Fudan University, Shanghai
200436, People's Republic of China Jockey Club School of Public Health and
Primary Care, the Chinese University of Hong Kong, Shatin, Hong Kong SAR.
(2)State Key Laboratory of Genetic Engineering and Collaborative Innovation
Center for Genetics and Development, Department of Biostatistics and
Computational Biology, School of Life Sciences, Fudan University, Shanghai
200436, People's Republic of China.

The computational speed of many gene set analysis methods can be slow due to the 
computationally demanding permutation step. This article introduces
GSA-Lightning, a fast implementation of permutation-based gene set analysis.
GSA-Lightning achieves significant speedup compared with existing methods,
particularly when the number of gene sets and permutations are large.AVAILABILITY
AND IMPLEMENTATION: The GSA-Lightning R package is available on Github at
https://github.com/billyhw/GSALightning and on R Bioconductor. The package also
contains a comprehensive user's guide with a step-by-step tutorial vignette.
CONTACT: weidong.tian@fudan.edu.cn
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw349 
PMID: 27296982  [PubMed - in process]


463. Bioinformatics. 2016 Oct 1;32(19):3041-3. doi: 10.1093/bioinformatics/btw332.
Epub 2016 Jun 13.

Web-based network analysis and visualization using CellMaps.

Salavert F(1), García-Alonso L(2), Sánchez R(2), Alonso R(3), Bleda M(4), Medina 
I(5), Dopazo J(6).

Author information: 
(1)Computational Genomics Department, Centro de Investigación Príncipe Felipe
(CIPF), Valencia 46012, Spain Bioinformatics of Rare Diseases (BIER), CIBER de
Enfermedades Raras (CIBERER), Valencia, Spain. (2)Computational Genomics
Department, Centro de Investigación Príncipe Felipe (CIPF), Valencia 46012,
Spain. (3)Computational Genomics Department, Centro de Investigación Príncipe
Felipe (CIPF), Valencia 46012, Spain Bull-CIPF, Computational Genomics Chair,
Valencia 46012, Spain. (4)Department of Medicine, University of Cambridge, School
of Clinical Medicine, Addenbrooke's Hospital, Hills Road, Cambridge CB2 0QQ, UK. 
(5)HPC Service, UIS, University of Cambridge, Cambridge, UK. (6)Computational
Genomics Department, Centro de Investigación Príncipe Felipe (CIPF), Valencia
46012, Spain Bioinformatics of Rare Diseases (BIER), CIBER de Enfermedades Raras 
(CIBERER), Valencia, Spain Functional Genomics Node, (INB, PRB2, ISCIII) at CIPF,
Valencia 46012, Spain.

: CellMaps is an HTML5 open-source web tool that allows displaying, editing,
exploring and analyzing biological networks as well as integrating metadata into 
them. Computations and analyses are remotely executed in high-end servers, and
all the functionalities are available through RESTful web services. CellMaps can 
easily be integrated in any web page by using an available JavaScript
API.AVAILABILITY AND IMPLEMENTATION: The application is available at:
http://cellmaps.babelomics.org/ and the code can be found in:
https://github.com/opencb/cell-maps The client is implemented in JavaScript and
the server in C and Java.
CONTACT: jdopazo@cipf.es
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw332 
PMCID: PMC5039919
PMID: 27296979  [PubMed - in process]


464. IEEE/ACM Trans Comput Biol Bioinform. 2016 May-Jun;13(3):531-40. doi:
10.1109/TCBB.2015.2462344.

Efficient Drug-Pathway Association Analysis via Integrative Penalized Matrix
Decomposition.

Li C, Yang C, Hather G, Liu R, Zhao H.

Traditional drug discovery practice usually follows the "one drug - one target"
approach, seeking to identify drug molecules that act on individual targets,
which ignores the systemic nature of human diseases. Pathway-based drug discovery
recently emerged as an appealing approach to overcome this limitation. An
important first step of such pathway-based drug discovery is to identify
associations between drug molecules and biological pathways. This task has been
made feasible by the accumulating data from high-throughput transcription and
drug sensitivity profiling. In this paper, we developed "iPaD", an integrative
Penalized Matrix Decomposition method to identify drug-pathway associations
through jointly modeling of such high-throughput transcription and drug
sensitivity data. A scalable bi-convex optimization algorithm was implemented and
gave iPaD tremendous advantage in computational efficiency over current
state-of-the-art method, which allows it to handle the ever-growing large-scale
data sets that current method cannot afford to. On two widely used real data
sets, iPaD also significantly outperformed the current method in terms of the
number of validated drug-pathway associations that were identified. The Matlab
code of our algorithm publicly available at http://licong-jason.github.io/iPaD/.

DOI: 10.1109/TCBB.2015.2462344 
PMCID: PMC4951188 [Available on 2017-05-01]
PMID: 27295636  [PubMed - in process]


465. Bioinformatics. 2016 Oct 1;32(19):3012-4. doi: 10.1093/bioinformatics/btw325.
Epub 2016 Jun 10.

GenVisR: Genomic Visualizations in R.

Skidmore ZL(1), Wagner AH(1), Lesurf R(1), Campbell KM(1), Kunisaki J(1),
Griffith OL(2), Griffith M(3).

Author information: 
(1)McDonnell Genome Institute, Washington University School of Medicine, St.
Louis, MO 63108, USA. (2)McDonnell Genome Institute, Washington University School
of Medicine, St. Louis, MO 63108, USA Department of Medicine Siteman Cancer
Center Department of Genetics, Washington University School of Medicine, St.
Louis, MO 63110, USA. (3)McDonnell Genome Institute, Washington University School
of Medicine, St. Louis, MO 63108, USA Siteman Cancer Center Department of
Genetics, Washington University School of Medicine, St. Louis, MO 63110, USA.

Visualizing and summarizing data from genomic studies continues to be a
challenge. Here, we introduce the GenVisR package to addresses this challenge by 
providing highly customizable, publication-quality graphics focused on cohort
level genome analyses. GenVisR provides a rapid and easy-to-use suite of genomic 
visualization tools, while maintaining a high degree of flexibility by leveraging
the abilities of ggplot2 and Bioconductor.AVAILABILITY AND IMPLEMENTATION:
GenVisR is an R package available via Bioconductor
(https://bioconductor.org/packages/GenVisR) under GPLv3. Support is available via
GitHub (https://github.com/griffithlab/GenVisR/issues) and the Bioconductor
support website.
CONTACTS: obigriffith@wustl.edu or mgriffit@wustl.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw325 
PMCID: PMC5039916
PMID: 27288499  [PubMed - in process]


466. Bioinformatics. 2016 Oct 1;32(19):3024-6. doi: 10.1093/bioinformatics/btw338.
Epub 2016 Jun 10.

RTFBSDB: an integrated framework for transcription factor binding site analysis.

Wang Z(1), Martins AL(1), Danko CG(2).

Author information: 
(1)Baker Institute for Animal Health, College of Veterinary Medicine, Cornell
University, Ithaca, NY, USA. (2)Baker Institute for Animal Health, College of
Veterinary Medicine, Cornell University, Ithaca, NY, USA Department of Biomedical
Sciences, College of Veterinary Medicine, Cornell University, Ithaca, NY, USA.

Transcription factors (TFs) regulate complex programs of gene transcription by
binding to short DNA sequence motifs. Here, we introduce rtfbsdb, a unified
framework that integrates a database of more than 65 000 TF binding motifs with
tools to easily and efficiently scan target genome sequences. Rtfbsdb clusters
motifs with similar DNA sequence specificities and integrates RNA-seq or PRO-seq 
data to restrict analyses to motifs recognized by TFs expressed in the cell type 
of interest. Our package allows common analyses to be performed rapidly in an
integrated environment.AVAILABILITY AND IMPLEMENTATION: rtfbsdb available at
(https://github.com/Danko-Lab/rtfbs_db).
CONTACT: dankoc@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw338 
PMCID: PMC5039921 [Available on 2017-10-01]
PMID: 27288497  [PubMed - in process]


467. Bioinformatics. 2016 Oct 1;32(19):2956-64. doi: 10.1093/bioinformatics/btw329.
Epub 2016 Jun 10.

Inferring the perturbation time from biological time course data.

Yang J(1), Penfold CA(2), Grant MR(3), Rattray M(1).

Author information: 
(1)Faculty of Life Sciences, University of Manchester, Manchester, UK. (2)Warwick
Systems Biology Centre, University of Warwick, Coventry, UK. (3)School of
Biosciences, University of Exeter, Exeter, UK.

MOTIVATION: Time course data are often used to study the changes to a biological 
process after perturbation. Statistical methods have been developed to determine 
whether such a perturbation induces changes over time, e.g. comparing a perturbed
and unperturbed time course dataset to uncover differences. However, existing
methods do not provide a principled statistical approach to identify the specific
time when the two time course datasets first begin to diverge after a
perturbation; we call this the perturbation time. Estimation of the perturbation 
time for different variables in a biological process allows us to identify the
sequence of events following a perturbation and therefore provides valuable
insights into likely causal relationships.
RESULTS: We propose a Bayesian method to infer the perturbation time given time
course data from a wild-type and perturbed system. We use a non-parametric
approach based on Gaussian Process regression. We derive a probabilistic model of
noise-corrupted and replicated time course data coming from the same profile
before the perturbation time and diverging after the perturbation time. The
likelihood function can be worked out exactly for this model and the posterior
distribution of the perturbation time is obtained by a simple histogram approach,
without recourse to complex approximate inference algorithms. We validate the
method on simulated data and apply it to study the transcriptional change
occurring in Arabidopsis following inoculation with Pseudomonas syringae pv.
tomato DC3000 versus the disarmed strain DC3000hrpA AVAILABILITY AND
IMPLEMENTATION: : An R package, DEtime, implementing the method is available at
https://github.com/ManchesterBioinference/DEtime along with the data and code
required to reproduce all the results.
CONTACT: Jing.Yang@manchester.ac.uk or Magnus.Rattray@manchester.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw329 
PMCID: PMC5039917
PMID: 27288495  [PubMed - in process]


468. Bioinformatics. 2016 Oct 1;32(19):3049-50. doi: 10.1093/bioinformatics/btw333.
Epub 2016 Jun 10.

bdvis: visualizing biodiversity data in R.

Barve V(1), Otegui J(2).

Author information: 
(1)Florida Museum of Natural History, University of Florida, Gainesville, FL,
USA. (2)University of Colorado Museum of Natural History, Boulder, CO, USA.

Biodiversity studies are relying increasingly on primary biodiversity records
(PBRs) for modelling and analysis. Because biodiversity data are frequently
'harvested'-i.e. not collected by the researcher for that particular study, but
obtained from data aggregators such as the Global Biodiversity Information
Facility-researchers need to be aware of strengths and weaknesses of their data
before they venture into further analysis. R is becoming a lingua franca of data 
exploration and analysis. Here, we describe an R package, bdvis, which
facilitates efforts to understand the gaps and strengths of PBR data with quick
and useful visualization functions.AVAILABILITY AND IMPLEMENTATION: The full code
of the R package bdvis, along with instructions on how to install and use it, is 
available via CRAN - The Comprehensive R Archive Network
(http://cran.r-project.org/web/packages/bdvis/index.html) and in the
corresponding author's main GitHub repository:
http://www.github.com/vijaybarve/bdvis The source code is licensed under CC0
CONTACT: vijay.barve@gmail.com.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw333 
PMID: 27288494  [PubMed - in process]


469. Bioinformatics. 2016 Oct 1;32(19):2896-902. doi: 10.1093/bioinformatics/btw336.
Epub 2016 Jun 10.

Zerone: a ChIP-seq discretizer for multiple replicates with built-in quality
control.

Cuscó P(1), Filion GJ(1).

Author information: 
(1)Genome Architecture, Gene Regulation, Stem Cells and Cancer Programme, Centre 
for Genomic Regulation (CRG), the Barcelona Institute of Science and Technology, 
Barcelona 08003, Spain Universitat Pompeu Fabra (UPF), Barcelona, Spain.

MOTIVATION: Chromatin immunoprecipitation followed by high-throughput sequencing 
(ChIP-seq) is the standard method to investigate chromatin protein composition.
As the number of community-available ChIP-seq profiles increases, it becomes more
common to use data from different sources, which makes joint analysis
challenging. Issues such as lack of reproducibility, heterogeneous quality and
conflicts between replicates become evident when comparing datasets, especially
when they are produced by different laboratories.
RESULTS: Here, we present Zerone, a ChIP-seq discretizer with built-in quality
control. Zerone is powered by a Hidden Markov Model with zero-inflated negative
multinomial emissions, which allows it to merge several replicates into a single 
discretized profile. To identify low quality or irreproducible data, we trained a
Support Vector Machine and integrated it as part of the discretization process.
The result is a classifier reaching 95% accuracy in detecting low quality
profiles. We also introduce a graphical representation to compare discretization 
quality and we show that Zerone achieves outstanding accuracy. Finally, on
current hardware, Zerone discretizes a ChIP-seq experiment on mammalian genomes
in about 5 min using less than 700 MB of memory.
AVAILABILITY AND IMPLEMENTATION: Zerone is available as a command line tool and
as an R package. The C source code and R scripts can be downloaded from
https://github.com/nanakiksc/zerone The information to reproduce the benchmark
and the figures is stored in a public Docker image that can be downloaded from
https://hub.docker.com/r/nanakiksc/zerone/
CONTACT: : guillaume.filion@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw336 
PMCID: PMC5039920
PMID: 27288492  [PubMed - in process]


470. BMC Bioinformatics. 2016 Jun 10;17(1):233. doi: 10.1186/s12859-016-1108-4.

tarSVM: Improving the accuracy of variant calls derived from microfluidic
PCR-based targeted next generation sequencing using a support vector machine.

Gillies CE(1), Otto EA(2), Vega-Warner V(1), Robertson CC(1), Sanna-Cherchi S(3),
Gharavi A(3), Crawford B(1), Bhimma R(4), Winkler C(5); Nephrotic Syndrome Study 
Network (NEPTUNE); C-PROBE InvestigatorGroup of the Michigan Kidney Translational
Core Center, Kang HM(6), Sampson MG(7,)(8).

Author information: 
(1)Department of Pediatrics-Nephrology, University of Michigan School of
Medicine, Ann Arbor, MI, USA. (2)Department of Internal Medicine-Nephrology,
University of Michigan School of Medicine, Ann Arbor, MI, USA. (3)Department of
Medicine, Columbia University College of Physicians and Surgeons, New York, NY,
USA. (4)Department of Paediatrics and Child Health, University of KwaZulu Natal, 
Durban, South Africa. (5)NCI, Frederick National Lab for Cancer Research,
Molecular Genetics Epidemiology Section, Frederick, MD, USA. (6)Department of
Biostatistics, University of Michigan School of Public Health, Ann Arbor, MI,
USA. (7)Department of Pediatrics-Nephrology, University of Michigan School of
Medicine, Ann Arbor, MI, USA. mgsamps@med.umich.edu. (8), 3560B MSRB2, 1150 West 
Medical Center Drive, Ann Arbor, MI, 48109, USA. mgsamps@med.umich.edu.

BACKGROUND: Targeted sequencing of discrete gene sets is a cost effective
strategy to screen subjects for monogenic forms of disease. One method to achieve
this pairs microfluidic PCR with next generation sequencing. The PCR step of this
pipeline creates challenges in accurate variant calling. This includes that most 
reads targeting a specific exon are duplicates that have been amplified from the 
PCR step. To reduce false positive variant calls from these experiments, previous
studies have used threshold-based filtering of alternative allele depth ratio and
manual inspection of the alignments. However even after manual inspection and
filtering, many variants fail to be validated via Sanger sequencing. To improve
the accuracy of variant calling from these experiments, we are challenged to
design a variant filtering strategy that sufficiently models microfluidic
PCR-specific issues.
RESULTS: We developed an open source variant filtering pipeline, targeted
sequencing support vector machine ("tarSVM"), that uses a Support Vector Machine 
(SVM) and a new score the normalized allele dosage test to identify high quality 
variants from microfluidic PCR data. tarSVM maximizes training knowledge by
selecting variants that are likely true and likely false variants by
incorporating knowledge from the 1000 Genomes and the Exome Aggregation
Consortium projects. tarSVM improves on previous approaches by synthesizing
variant features from the Genome Analysis Toolkit and allele dosage information. 
We compared the accuracy of tarSVM versus existing variant quality filtering
strategies on two cohorts (n = 474 and n = 1152), and validated our method on a
third cohort (n = 75). In the first cohort, our method achieved 84.5 % accuracy
of predicting whether or not a variant would be validated with Sanger sequencing 
versus 78.8 % for the second most accurate method. In the second cohort, our
method had an accuracy of 73.3 %, versus 61.5 % for the second best method.
Finally, our method had a false discovery rate of 5 % for the validation cohort.
CONCLUSIONS: tarSVM increases the accuracy of variant calling when using
microfluidic PCR based targeted sequencing approaches. This results in higher
confidence downstream analyses, and ultimately reduces the costs Sanger
validation. Our approach is less labor intensive than existing approaches, and is
available as an open source pipeline for read trimming, aligning, variant
calling, and variant quality filtering on GitHub at
https://github.com/christopher-gillies/TargetSpecificGATKSequencingPipeline .

DOI: 10.1186/s12859-016-1108-4 
PMCID: PMC4902911
PMID: 27287006  [PubMed - in process]


471. Protein Eng Des Sel. 2016 Aug;29(8):291-9. doi: 10.1093/protein/gzw020. Epub 2016
Jun 9.

Exploring the interplay between experimental methods and the performance of
predictors of binding affinity change upon mutations in protein complexes.

Geng C(1), Vangone A(1), Bonvin AM(2).

Author information: 
(1)Computational Structural Biology Group, Bijvoet Center for Biomolecular
Research, Faculty of Science-Chemistry, Utrecht University, Padualaan 8, Utrecht 
3584 CH, The Netherlands. (2)Computational Structural Biology Group, Bijvoet
Center for Biomolecular Research, Faculty of Science-Chemistry, Utrecht
University, Padualaan 8, Utrecht 3584 CH, The Netherlands a.m.j.j.bonvin@uu.nl.

Reliable prediction of binding affinity changes (ΔΔG) upon mutations in protein
complexes relies not only on the performance of computational methods but also on
the availability and quality of experimental data. Binding affinity changes can
be measured by various experimental methods with different accuracies and
limitations. To understand the impact of these on the prediction of binding
affinity change, we present the Database of binding Affinity Change Upon Mutation
(DACUM), a database of 1872 binding affinity changes upon single-point mutations,
a subset of the SKEMPI database (Moal,I.H. and Fernández-Recio,J. Bioinformatics,
2012;28:2600-2607) extended with information on the experimental methods used for
ΔΔG measurements. The ΔΔG data were classified into different data sets based on 
the experimental method used and the position of the mutation (interface and
non-interface). We tested the prediction performance of the original HADDOCK
score, a newly trained version of it and mutation Cutoff Scanning Matrix
(Pires,D.E.V., Ascher,D.B. and Blundell,T.L. Bioinformatics 2014;30:335-342), one
of the best reported ΔΔG predictors so far, on these various data sets. Our
results demonstrate a strong impact of the experimental methods on the
performance of binding affinity change predictors for protein complexes. This
underscores the importance of properly considering and carefully choosing
experimental methods in the development of novel binding affinity change
predictors. The DACUM database is available online at
https://github.com/haddocking/DACUM.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/protein/gzw020 
PMID: 27284087  [PubMed - in process]


472. Bioinformatics. 2016 Sep 15;32(18):2783-90. doi: 10.1093/bioinformatics/btw345.
Epub 2016 Jun 9.

KCMBT: a k-mer Counter based on Multiple Burst Trees.

Mamun AA(1), Pal S(1), Rajasekaran S(1).

Author information: 
(1)Department of Computer Science and Engineering, University of Connecticut,
Storrs, CT 06269, USA.

MOTIVATION: A massive number of bioinformatics applications require counting of
k-length substrings in genetically important long strings. A k-mer counter
generates the frequencies of each k-length substring in genome sequences. Genome 
assembly, repeat detection, multiple sequence alignment, error detection and many
other related applications use a k-mer counter as a building block. Very fast and
efficient algorithms are necessary to count k-mers in large data sets to be
useful in such applications.
RESULTS: We propose a novel trie-based algorithm for this k-mer counting problem.
We compare our devised algorithm k-mer Counter based on Multiple Burst Trees
(KCMBT) with available all well-known algorithms. Our experimental results show
that KCMBT is around 30% faster than the previous best-performing algorithm KMC2 
for human genome dataset. As another example, our algorithm is around six times
faster than Jellyfish2. Overall, KCMBT is 20-30% faster than KMC2 on five
benchmark data sets when both the algorithms were run using multiple threads.
AVAILABILITY AND IMPLEMENTATION: KCMBT is freely available on GitHub:
(https://github.com/abdullah009/kcmbt_mt).
CONTACT: rajasek@engr.uconn.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw345 
PMID: 27283950  [PubMed - in process]


473. Bioinformatics. 2016 Sep 15;32(18):2817-23. doi: 10.1093/bioinformatics/btw327.
Epub 2016 Jun 9.

pong: fast analysis and visualization of latent clusters in population genetic
data.

Behr AA(1), Liu KZ(2), Liu-Fang G(3), Nakka P(4), Ramachandran S(4).

Author information: 
(1)Department of Ecology and Evolutionary Biology Department of Computer Science,
Brown University, Providence, RI, USA. (2)Department of Computer Science, Brown
University, Providence, RI, USA. (3)Computer Science Department, Wellesley
College, Wellesley, MA, USA. (4)Department of Ecology and Evolutionary Biology
Center for Computational Molecular Biology, Brown University, Providence, RI,
USA.

MOTIVATION: A series of methods in population genetics use multilocus genotype
data to assign individuals membership in latent clusters. These methods belong to
a broad class of mixed-membership models, such as latent Dirichlet allocation
used to analyze text corpora. Inference from mixed-membership models can produce 
different output matrices when repeatedly applied to the same inputs, and the
number of latent clusters is a parameter that is often varied in the analysis
pipeline. For these reasons, quantifying, visualizing, and annotating the output 
from mixed-membership models are bottlenecks for investigators across multiple
disciplines from ecology to text data mining.
RESULTS: We introduce pong, a network-graphical approach for analyzing and
visualizing membership in latent clusters with a native interactive D3.js
visualization. pong leverages efficient algorithms for solving the Assignment
Problem to dramatically reduce runtime while increasing accuracy compared with
other methods that process output from mixed-membership models. We apply pong to 
225 705 unlinked genome-wide single-nucleotide variants from 2426 unrelated
individuals in the 1000 Genomes Project, and identify previously overlooked
aspects of global human population structure. We show that pong outpaces current 
solutions by more than an order of magnitude in runtime while providing a
customizable and interactive visualization of population structure that is more
accurate than those produced by current tools.
AVAILABILITY AND IMPLEMENTATION: pong is freely available and can be installed
using the Python package management system pip. pong's source code is available
at https://github.com/abehr/pong
CONTACT: aaron_behr@alumni.brown.edu or sramachandran@brown.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw327 
PMCID: PMC5018373
PMID: 27283948  [PubMed - in process]


474. Med Phys. 2016 Jun;43(6):3104. doi: 10.1118/1.4950883.

Dynamic PET simulator via tomographic emission projection for kinetic modeling
and parametric image studies.

Häggström I(1), Beattie BJ(2), Schmidtlein CR(2).

Author information: 
(1)Department of Medical Physics, Memorial Sloan Kettering Cancer Center, New
York, New York 10065 and Department of Radiation Sciences, Umeå University, Umeå 
90187, Sweden. (2)Department of Medical Physics, Memorial Sloan Kettering Cancer 
Center, New York, New York 10065.

PURPOSE: To develop and evaluate a fast and simple tool called dpetstep (Dynamic 
PET Simulator of Tracers via Emission Projection), for dynamic PET simulations as
an alternative to Monte Carlo (MC), useful for educational purposes and
evaluation of the effects of the clinical environment, postprocessing choices,
etc., on dynamic and parametric images.
METHODS: The tool was developed in matlab using both new and previously reported 
modules of petstep (PET Simulator of Tracers via Emission Projection). Time
activity curves are generated for each voxel of the input parametric image,
whereby effects of imaging system blurring, counting noise, scatters, randoms,
and attenuation are simulated for each frame. Each frame is then reconstructed
into images according to the user specified method, settings, and corrections.
Reconstructed images were compared to MC data, and simple Gaussian noised time
activity curves (GAUSS).
RESULTS: dpetstep was 8000 times faster than MC. Dynamic images from dpetstep had
a root mean square error that was within 4% on average of that of MC images,
whereas the GAUSS images were within 11%. The average bias in dpetstep and MC
images was the same, while GAUSS differed by 3% points. Noise profiles in
dpetstep images conformed well to MC images, confirmed visually by scatter plot
histograms, and statistically by tumor region of interest histogram comparisons
that showed no significant differences (p < 0.01). Compared to GAUSS, dpetstep
images and noise properties agreed better with MC.
CONCLUSIONS: The authors have developed a fast and easy one-stop solution for
simulations of dynamic PET and parametric images, and demonstrated that it
generates both images and subsequent parametric images with very similar noise
properties to those of MC images, in a fraction of the time. They believe
dpetstep to be very useful for generating fast, simple, and realistic results,
however since it uses simple scatter and random models it may not be suitable for
studies investigating these phenomena. dpetstep can be downloaded free of cost
from https://github.com/CRossSchmidtlein/dPETSTEP.

DOI: 10.1118/1.4950883 
PMCID: PMC4884183 [Available on 2017-06-01]
PMID: 27277057  [PubMed - in process]


475. BMC Bioinformatics. 2016 Jun 8;17(1):232. doi: 10.1186/s12859-016-1109-3.

SCOUP: a probabilistic model based on the Ornstein-Uhlenbeck process to analyze
single-cell expression data during differentiation.

Matsumoto H(1,)(2), Kiryu H(3).

Author information: 
(1)Bioinformatics Research Unit, Advanced Center for Computing and Communication,
RIKEN, 2-1 Hirosawa, Wako, Saitama, 351-0198, Japan. hirotaka.matsumoto@riken.jp.
(2)Department of Computational Biology and Medical Sciences, Faculty of Frontier 
Sciences, The University of Tokyo, 5-1-5 Kashiwanoha, Kashiwa, Chiba, 277-8561,
Japan. hirotaka.matsumoto@riken.jp. (3)Department of Computational Biology and
Medical Sciences, Faculty of Frontier Sciences, The University of Tokyo, 5-1-5
Kashiwanoha, Kashiwa, Chiba, 277-8561, Japan.

BACKGROUND: Single-cell technologies make it possible to quantify the
comprehensive states of individual cells, and have the power to shed light on
cellular differentiation in particular. Although several methods have been
developed to fully analyze the single-cell expression data, there is still room
for improvement in the analysis of differentiation.
RESULTS: In this paper, we propose a novel method SCOUP to elucidate
differentiation process. Unlike previous dimension reduction-based approaches,
SCOUP describes the dynamics of gene expression throughout differentiation
directly, including the degree of differentiation of a cell (in pseudo-time) and 
cell fate. SCOUP is superior to previous methods with respect to pseudo-time
estimation, especially for single-cell RNA-seq. SCOUP also successfully estimates
cell lineage more accurately than previous method, especially for cells at an
early stage of bifurcation. In addition, SCOUP can be applied to various
downstream analyses. As an example, we propose a novel correlation calculation
method for elucidating regulatory relationships among genes. We apply this method
to a single-cell RNA-seq data and detect a candidate of key regulator for
differentiation and clusters in a correlation network which are not detected with
conventional correlation analysis.
CONCLUSIONS: We develop a stochastic process-based method SCOUP to analyze
single-cell expression data throughout differentiation. SCOUP can estimate
pseudo-time and cell lineage more accurately than previous methods. We also
propose a novel correlation calculation method based on SCOUP. SCOUP is a
promising approach for further single-cell analysis and available at
https://github.com/hmatsu1226/SCOUP.

DOI: 10.1186/s12859-016-1109-3 
PMCID: PMC4898467
PMID: 27277014  [PubMed - in process]


476. Stat Appl Genet Mol Biol. 2016 Aug 1;15(4):349-61. doi: 10.1515/sagmb-2015-0085.

LandScape: a simple method to aggregate p-values and other stochastic variables
without a priori grouping.

Wiuf C, Schaumburg-Müller Pallesen J, Foldager L, Grove J.

In many areas of science it is custom to perform many, potentially millions, of
tests simultaneously. To gain statistical power it is common to group tests based
on a priori criteria such as predefined regions or by sliding windows. However,
it is not straightforward to choose grouping criteria and the results might
depend on the chosen criteria. Methods that summarize, or aggregate, test
statistics or p-values, without relying on a priori criteria, are therefore
desirable. We present a simple method to aggregate a sequence of stochastic
variables, such as test statistics or p-values, into fewer variables without
assuming a priori defined groups. We provide different ways to evaluate the
significance of the aggregated variables based on theoretical considerations and 
resampling techniques, and show that under certain assumptions the FWER is
controlled in the strong sense. Validity of the method was demonstrated using
simulations and real data analyses. Our method may be a useful supplement to
standard procedures relying on evaluation of test statistics individually.
Moreover, by being agnostic and not relying on predefined selected regions, it
might be a practical alternative to conventionally used methods of aggregation of
p-values over regions. The method is implemented in Python and freely available
online (through GitHub, see the Supplementary information).

DOI: 10.1515/sagmb-2015-0085 
PMID: 27269897  [PubMed - in process]


477. J Proteome Res. 2016 Jul 1;15(7):2198-210. doi: 10.1021/acs.jproteome.6b00171.
Epub 2016 Jun 17.

LaCyTools: A Targeted Liquid Chromatography-Mass Spectrometry Data Processing
Package for Relative Quantitation of Glycopeptides.

Jansen BC(1), Falck D(1), de Haan N(1), Hipgrave Ederveen AL(1), Razdorov G(2),
Lauc G(2), Wuhrer M(1).

Author information: 
(1)Center for Proteomics and Metabolomics, Leiden University Medical Center ,
2300RC Leiden, The Netherlands. (2)Department of Biochemistry and Molecular
Biology, Faculty of Pharmacy and Biochemistry, University of Zagreb , A. Kovačića
1, HR10000 Zagreb, Croatia.

Bottom-up glycoproteomics by liquid chromatography-mass spectrometry (LC-MS) is
an established approach for assessing glycosylation in a protein- and
site-specific manner. Consequently, tools are needed to automatically align,
calibrate, and integrate LC-MS glycoproteomics data. We developed a modular
software package designed to tackle the individual aspects of an LC-MS
experiment, called LaCyTools. Targeted alignment is performed using user defined 
m/z and retention time (tr) combinations. Subsequently, sum spectra are created
for each user defined analyte group. Quantitation is performed on the sum
spectra, where each user defined analyte can have its own tr, minimum, and
maximum charge states. Consequently, LaCyTools deals with multiple charge states,
which gives an output per charge state if desired, and offers various analyte and
spectra quality criteria. We compared throughput and performance of LaCyTools to 
combinations of available tools that deal with individual processing steps.
LaCyTools yielded relative quantitation of equal precision (relative standard
deviation <0.5%) and higher trueness due to the use of MS peak area instead of MS
peak intensity. In conclusion, LaCyTools is an accurate automated data processing
tool for high-throughput analysis of LC-MS glycoproteomics data. Released under
the Apache 2.0 license, it is freely available on GitHub (
https://github.com/Tarskin/LaCyTools ).

DOI: 10.1021/acs.jproteome.6b00171 
PMID: 27267458  [PubMed - in process]


478. Comput Methods Programs Biomed. 2016 Jul;131:63-77. doi:
10.1016/j.cmpb.2016.03.030. Epub 2016 Apr 8.

BIOMedical Search Engine Framework: Lightweight and customized implementation of 
domain-specific biomedical search engines.

Jácome AG(1), Fdez-Riverola F(1), Lourenço A(2).

Author information: 
(1)ESEI-Escuela Superior de Ingeniería Informática, Edificio Politécnico, Campus 
Universitario As Lagoas s/n, Universidad de Vigo, 32004 Ourense, Spain.
(2)ESEI-Escuela Superior de Ingeniería Informática, Edificio Politécnico, Campus 
Universitario As Lagoas s/n, Universidad de Vigo, 32004 Ourense, Spain; Centre of
Biological Engineering, University of Minho, Campus de Gualtar, 4710-057 Braga,
Portugal. Electronic address: agjacome@esei.uvigo.es.

BACKGROUND AND OBJECTIVES: Text mining and semantic analysis approaches can be
applied to the construction of biomedical domain-specific search engines and
provide an attractive alternative to create personalized and enhanced search
experiences. Therefore, this work introduces the new open-source BIOMedical
Search Engine Framework for the fast and lightweight development of
domain-specific search engines. The rationale behind this framework is to
incorporate core features typically available in search engine frameworks with
flexible and extensible technologies to retrieve biomedical documents, annotate
meaningful domain concepts, and develop highly customized Web search interfaces.
METHODS: The BIOMedical Search Engine Framework integrates taggers for major
biomedical concepts, such as diseases, drugs, genes, proteins, compounds and
organisms, and enables the use of domain-specific controlled vocabulary.
Technologies from the Typesafe Reactive Platform, the AngularJS JavaScript
framework and the Bootstrap HTML/CSS framework support the customization of the
domain-oriented search application. Moreover, the RESTful API of the BIOMedical
Search Engine Framework allows the integration of the search engine into existing
systems or a complete web interface personalization.
RESULTS: The construction of the Smart Drug Search is described as
proof-of-concept of the BIOMedical Search Engine Framework. This public search
engine catalogs scientific literature about antimicrobial resistance, microbial
virulence and topics alike. The keyword-based queries of the users are
transformed into concepts and search results are presented and ranked
accordingly. The semantic graph view portraits all the concepts found in the
results, and the researcher may look into the relevance of different concepts,
the strength of direct relations, and non-trivial, indirect relations. The number
of occurrences of the concept shows its importance to the query, and the
frequency of concept co-occurrence is indicative of biological relations
meaningful to that particular scope of research. Conversely, indirect concept
associations, i.e. concepts related by other intermediary concepts, can be useful
to integrate information from different studies and look into non-trivial
relations.
CONCLUSIONS: The BIOMedical Search Engine Framework supports the development of
domain-specific search engines. The key strengths of the framework are modularity
and extensibilityin terms of software design, the use of open-source consolidated
Web technologies, and the ability to integrate any number of biomedical text
mining tools and information resources. Currently, the Smart Drug Search keeps
over 1,186,000 documents, containing more than 11,854,000 annotations for 77,200 
different concepts. The Smart Drug Search is publicly accessible at
http://sing.ei.uvigo.es/sds/. The BIOMedical Search Engine Framework is freely
available for non-commercial use at https://github.com/agjacome/biomsef.

Copyright © 2016 Elsevier Ireland Ltd. All rights reserved.

DOI: 10.1016/j.cmpb.2016.03.030 
PMID: 27265049  [PubMed - in process]


479. Bioinformatics. 2016 Sep 15;32(18):2760-7. doi: 10.1093/bioinformatics/btw312.
Epub 2016 Jun 3.

MetaFast: fast reference-free graph-based comparison of shotgun metagenomic data.

Ulyantsev VI(1), Kazakov SV(1), Dubinkina VB(2), Tyakht AV(2), Alexeev DG(3).

Author information: 
(1)ITMO University, Saint Petersburg, Russian Federation. (2)Federal Research and
Clinical Centre of Physical-Chemical Medicine, Moscow, Russian Federation Moscow 
Institute of Physics and Technology (State University), Dolgoprudny, Russian
Federation. (3)Moscow Institute of Physics and Technology (State University),
Dolgoprudny, Russian Federation.

MOTIVATION: High-throughput metagenomic sequencing has revolutionized our view on
the structure and metabolic potential of microbial communities. However, analysis
of metagenomic composition is often complicated by the high complexity of the
community and the lack of related reference genomic sequences. As a start point
for comparative metagenomic analysis, the researchers require efficient means for
assessing pairwise similarity of the metagenomes (beta-diversity). A number of
approaches were used to address this task, however, most of them have inherent
disadvantages that limit their scope of applicability. For instance, the
reference-based methods poorly perform on metagenomes from previously unstudied
niches, while composition-based methods appear to be too abstract for
straightforward interpretation and do not allow to identify the differentially
abundant features.
RESULTS: We developed MetaFast, an approach that allows to represent a shotgun
metagenome from an arbitrary environment as a modified de Bruijn graph consisting
of simplified components. For multiple metagenomes, the resulting representation 
is used to obtain a pairwise similarity matrix. The dimensional structure of the 
metagenomic components preserved in our algorithm reflects the inherent
subspecies-level diversity of microbiota. The method is computationally efficient
and especially promising for an analysis of metagenomes from novel environmental 
niches.
AVAILABILITY AND IMPLEMENTATION: Source code and binaries are freely available
for download at https://github.com/ctlab/metafast The code is written in Java and
is platform independent (tested on Linux and Windows x86_64).
CONTACT: ulyantsev@rain.ifmo.ru
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw312 
PMID: 27259541  [PubMed - in process]


480. PeerJ. 2016 May 24;4:e2074. doi: 10.7717/peerj.2074. eCollection 2016.

DeepSNVMiner: a sequence analysis tool to detect emergent, rare mutations in
subsets of cell populations.

Andrews TD(1), Jeelall Y(2), Talaulikar D(3), Goodnow CC(4), Field MA(5).

Author information: 
(1)Department of Immunology, John Curtin School of Medical Research, Australian
National University, Canberra ACT, Australia; National Computational
Infrastructure, Canberra ACT, Australia. (2)Department of Immunology, John Curtin
School of Medical Research, Australian National University, Canberra ACT,
Australia; School of Medicine and Pharmacology, University of Western Australia, 
Harry Perkins Institute, Perth, Australia. (3)Department of Immunology, John
Curtin School of Medical Research, Australian National University, Canberra ACT, 
Australia; Haematology Translational Research Unit, Haematology Unit, ACT
Pathology, Canberra ACT, Australia; ANU Medical School, Australian National
University, Canberra ACT, Australia. (4)Department of Immunology, John Curtin
School of Medical Research, Australian National University, Canberra ACT,
Australia; Immunology Division, Garvan Institute of Medical Research, Sydney NSW,
Australia; St Vincent's Clinical School, University of New South Wales,
Darlinghurst NSW, Australia. (5)Department of Immunology, John Curtin School of
Medical Research, Australian National University , Canberra ACT , Australia.

Background. Massively parallel sequencing technology is being used to sequence
highly diverse populations of DNA such as that derived from heterogeneous cell
mixtures containing both wild-type and disease-related states. At the core of
such molecule tagging techniques is the tagging and identification of sequence
reads derived from individual input DNA molecules, which must be first
computationally disambiguated to generate read groups sharing common sequence
tags, with each read group representing a single input DNA molecule. This
disambiguation typically generates huge numbers of reads groups, each of which
requires additional variant detection analysis steps to be run specific to each
read group, thus representing a significant computational challenge. While
sequencing technologies for producing these data are approaching maturity, the
lack of available computational tools for analysing such heterogeneous sequence
data represents an obstacle to the widespread adoption of this technology.
Results. Using synthetic data we successfully detect unique variants at dilution 
levels of 1 in a 1,000,000 molecules, and find DeeepSNVMiner obtains
significantly lower false positive and false negative rates compared to popular
variant callers GATK, SAMTools, FreeBayes and LoFreq, particularly as the variant
concentration levels decrease. In a dilution series with genomic DNA from two
cells lines, we find DeepSNVMiner identifies a known somatic variant when present
at concentrations of only 1 in 1,000 molecules in the input material, the lowest 
concentration amongst all variant callers tested. Conclusions. Here we present
DeepSNVMiner; a tool to disambiguate tagged sequence groups and robustly identify
sequence variants specific to subsets of starting DNA molecules that may indicate
the presence of a disease. DeepSNVMiner is an automated workflow of custom
sequence analysis utilities and open source tools able to differentiate somatic
DNA variants from artefactual sequence variants that likely arose during DNA
amplification. The workflow remains flexible such that it may be customised to
variants of the data production protocol used, and supports reproducible analysis
through detailed logging and reporting of results. DeepSNVMiner is available for 
academic non-commercial research purposes at
https://github.com/mattmattmattmatt/DeepSNVMiner.

DOI: 10.7717/peerj.2074 
PMCID: PMC4888318
PMID: 27257550  [PubMed]


481. Nucleic Acids Res. 2016 Jul 8;44(12):5550-6. doi: 10.1093/nar/gkw477. Epub 2016
Jun 1.

Goldmine integrates information placing genomic ranges into meaningful biological
contexts.

Bhasin JM(1), Ting AH(2).

Author information: 
(1)Department of Molecular Medicine, Cleveland Clinic Lerner College of Medicine,
Case Western Reserve University, Cleveland, OH 44195, USA Genomic Medicine
Institute, Lerner Research Institute, Cleveland Clinic, Cleveland, OH 44195, USA.
(2)Department of Molecular Medicine, Cleveland Clinic Lerner College of Medicine,
Case Western Reserve University, Cleveland, OH 44195, USA Genomic Medicine
Institute, Lerner Research Institute, Cleveland Clinic, Cleveland, OH 44195, USA 
tinga@ccf.org.

Bioinformatic analysis often produces large sets of genomic ranges that can be
difficult to interpret in the absence of genomic context. Goldmine annotates
genomic ranges from any source with gene model and feature contexts to facilitate
global descriptions and candidate loci discovery. We demonstrate the value of
genomic context by using Goldmine to elucidate context dynamics in transcription 
factor binding and to reveal differentially methylated regions (DMRs) with
context-specific functional correlations. The open source R package and
documentation for Goldmine are available at http://jeffbhasin.github.io/goldmine.

© The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkw477 
PMCID: PMC4937336
PMID: 27257071  [PubMed - in process]


482. Bioinformatics. 2016 Sep 15;32(18):2883-5. doi: 10.1093/bioinformatics/btw234.
Epub 2016 Jun 2.

SETH detects and normalizes genetic variants in text.

Thomas P(1), Rocktäschel T(2), Hakenberg J(3), Lichtblau Y(4), Leser U(4).

Author information: 
(1)Language Technology Lab, DFKI Berlin, Germany Knowledge Management in
Bioinformatics, Institute for Computer Science, Humboldt-Universität Zu Berlin,
Unter Den Linden 6, Berlin 10099, Germany. (2)University College London, Gower
Street, LondonWC1E 6BT, UK. (3)Illumina, Inc, 451 El Camino Real, Santa Clara, CA
95050, USA. (4)Knowledge Management in Bioinformatics, Institute for Computer
Science, Humboldt-Universität Zu Berlin, Unter Den Linden 6, Berlin 10099,
Germany.

: Descriptions of genetic variations and their effect are widely spread across
the biomedical literature. However, finding all mentions of a specific variation,
or all mentions of variations in a specific gene, is difficult to achieve due to 
the many ways such variations are described. Here, we describe SETH, a tool for
the recognition of variations from text and their subsequent normalization to
dbSNP or UniProt. SETH achieves high precision and recall on several evaluation
corpora of PubMed abstracts. It is freely available and encompasses stand-alone
scripts for isolated application and evaluation as well as a thorough
documentation for integration into other applications.AVAILABILITY AND
IMPLEMENTATION: SETH is released under the Apache 2.0 license and can be
downloaded from http://rockt.github.io/SETH/ CONTACT:
thomas@informatik.hu-berlin.de or leser@informatik.hu-berlin.de.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw234 
PMID: 27256315  [PubMed - in process]


483. Bioinformatics. 2016 Jun 2. pii: btw290. [Epub ahead of print]

COCACOLA: binning metagenomic contigs using sequence COmposition, read CoverAge, 
CO-alignment and paired-end read LinkAge.

Lu YY(1), Chen T(2), Fuhrman JA(3), Sun F(4).

Author information: 
(1)Molecular and Computational Biology Program, Department of Biological
Sciences, University of Southern California, Los Angeles, CA 90089, USA.
(2)Molecular and Computational Biology Program, Department of Biological
Sciences, University of Southern California, Los Angeles, CA 90089, USA Center
for Synthetic and Systems Biology, TNLIST, Beijing 100084, China. (3)Department
of Biological Sciences and Wrigley Institute for Environmental Studies,
University of Southern California, Los Angeles, CA 90089, USA. (4)Molecular and
Computational Biology Program, Department of Biological Sciences, University of
Southern California, Los Angeles, CA 90089, USA Center for Computational Systems 
Biology, Fudan University, Shanghai 200433, China.

MOTIVATION: The advent of next-generation sequencing technologies enables
researchers to sequence complex microbial communities directly from the
environment. Because assembly typically produces only genome fragments, also
known as contigs, instead of an entire genome, it is crucial to group them into
operational taxonomic units (OTUs) for further taxonomic profiling and
down-streaming functional analysis. OTU clustering is also referred to as
binning. We present COCACOLA, a general framework automatically bin contigs into 
OTUs based on sequence composition and coverage across multiple samples.
RESULTS: The effectiveness of COCACOLA is demonstrated in both simulated and real
datasets in comparison with state-of-art binning approaches such as CONCOCT,
GroopM, MaxBin and MetaBAT. The superior performance of COCACOLA relies on two
aspects. One is using L1 distance instead of Euclidean distance for better
taxonomic identification during initialization. More importantly, COCACOLA takes 
advantage of both hard clustering and soft clustering by sparsity regularization.
In addition, the COCACOLA framework seamlessly embraces customized knowledge to
facilitate binning accuracy. In our study, we have investigated two types of
additional knowledge, the co-alignment to reference genomes and linkage of
contigs provided by paired-end reads, as well as the ensemble of both. We find
that both co-alignment and linkage information further improve binning in the
majority of cases. COCACOLA is scalable and faster than CONCOCT, GroopM, MaxBin
and MetaBAT.
AVAILABILITY AND IMPLEMENTATION: The software is available at
https://github.com/younglululu/COCACOLA CONTACT: fsun@usc.eduSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw290 
PMID: 27256312  [PubMed - as supplied by publisher]


484. Genome Biol. 2016 Jun 1;17(1):118. doi: 10.1186/s13059-016-0973-5.

Vcfanno: fast, flexible annotation of genetic variants.

Pedersen BS(1,)(2,)(3), Layer RM(4,)(5,)(6), Quinlan AR(7,)(8,)(9).

Author information: 
(1)Department of Human Genetics, University of Utah, Salt Lake City, UT, 84105,
USA. bpederse@gmail.com. (2)USTAR Center for Genetic Discovery, University of
Utah, Salt Lake City, UT, 84105, USA. bpederse@gmail.com. (3)Department of
Biomedical Informatics, University of Utah, Salt Lake City, UT, 84105, USA.
bpederse@gmail.com. (4)Department of Human Genetics, University of Utah, Salt
Lake City, UT, 84105, USA. (5)USTAR Center for Genetic Discovery, University of
Utah, Salt Lake City, UT, 84105, USA. (6)Department of Biomedical Informatics,
University of Utah, Salt Lake City, UT, 84105, USA. (7)Department of Human
Genetics, University of Utah, Salt Lake City, UT, 84105, USA.
aquinlan@genetics.utah.edu. (8)USTAR Center for Genetic Discovery, University of 
Utah, Salt Lake City, UT, 84105, USA. aquinlan@genetics.utah.edu. (9)Department
of Biomedical Informatics, University of Utah, Salt Lake City, UT, 84105, USA.
aquinlan@genetics.utah.edu.

The integration of genome annotations is critical to the identification of
genetic variants that are relevant to studies of disease or other traits.
However, comprehensive variant annotation with diverse file formats is difficult 
with existing methods. Here we describe vcfanno, which flexibly extracts and
summarizes attributes from multiple annotation files and integrates the
annotations within the INFO column of the original VCF file. By leveraging a
parallel "chromosome sweeping" algorithm, we demonstrate substantial performance 
gains by annotating ~85,000 variants per second with 50 attributes from 17
commonly used genome annotation resources. Vcfanno is available at
https://github.com/brentp/vcfanno under the MIT license.

DOI: 10.1186/s13059-016-0973-5 
PMCID: PMC4888505
PMID: 27250555  [PubMed - in process]


485. Bioinformatics. 2016 Jun 1;32(11):1618-24. doi: 10.1093/bioinformatics/btw287.

methylFlow: cell-specific methylation pattern reconstruction from high-throughput
bisulfite-converted DNA sequencing.

Dorri F(1), Mendelowitz L(2), Corrada Bravo H(1).

Author information: 
(1)Center for Bioinformatics and Computational Biology Department of Computer
Science. (2)Center for Bioinformatics and Computational Biology Applied
Mathematics, Statistics and Scientific Compoutation Program, University of
Maryland, College Park, MD 20745, USA.

MOTIVATION: DNA methylation aberrations are now known to, almost universally,
accompany the initiation and progression of cancers. In particular, the colon
cancer epigenome contains specific genomic regions that, along with differences
in methylation levels with respect to normal colon tissue, also show increased
epigenetic and gene expression heterogeneity at the population level, i.e. across
tumor samples, in comparison with other regions in the genome. Tumors are highly 
heterogeneous at the clonal level as well, and the relationship between clonal
and population heterogeneity is poorly understood.
RESULTS: We present an approach that uses sequencing reads from high-throughput
sequencing of bisulfite-converted DNA to reconstruct heterogeneous cell
populations by assembling cell-specific methylation patterns. Our methodology is 
based on the solution of a specific class of minimum cost network flow problems. 
We use our methods to analyze the relationship between clonal heterogeneity and
population heterogeneity in high-coverage data from multiple samples of colon
tumor and matched normal tissues.
AVAILABILITY AND IMPLEMENTATION: http://github.com/hcorrada/methylFlow
CONTACT: hcorrada@umiacs.umd.edu
SUPPLEMENTARY INFORMATION: SUPPLEMENTARY INFORMATION is available at
Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw287 
PMCID: PMC4892417 [Available on 2017-06-01]
PMID: 27246923  [PubMed - in process]


486. BMC Genomics. 2016 May 27;17:414. doi: 10.1186/s12864-016-2737-8.

Cogena, a novel tool for co-expressed gene-set enrichment analysis, applied to
drug repositioning and drug mode of action discovery.

Jia Z(1,)(2), Liu Y(3), Guan N(4,)(5), Bo X(6), Luo Z(7,)(8), Barnes MR(9).

Author information: 
(1)Department of Chemistry and Biology, College of Science, National University
of Defense Technology, Changsha, Hunan, 410073, People's Republic of China.
(2)William Harvey Research Institute, Queen Mary University of London,
Charterhouse Square, London, EC1M 6BQ, UK. (3)Hunan Key Laboratory of Medical
Epigenomics, Department of Dermatology, Second Xiangya Hospital, Central South
University, Changsha, Hunan, 410011, People's Republic of China. (4)College of
Computer, National University of Defense Technology, Changsha, 410073, People's
Republic of China. (5)National Laboratory for Parallel and Distributed
Processing, National University of Defense Technology, Changsha, 410073, People's
Republic of China. (6)Beijing Institute of Radiation Medicine, Beijing, 100850,
People's Republic of China. (7)College of Computer, National University of
Defense Technology, Changsha, 410073, People's Republic of China.
zgluo@nudt.edu.cn. (8)National Laboratory for Parallel and Distributed
Processing, National University of Defense Technology, Changsha, 410073, People's
Republic of China. zgluo@nudt.edu.cn. (9)William Harvey Research Institute, Queen
Mary University of London, Charterhouse Square, London, EC1M 6BQ, UK.
m.r.barnes@qmul.ac.uk.

BACKGROUND: Drug repositioning, finding new indications for existing drugs, has
gained much recent attention as a potentially efficient and economical strategy
for accelerating new therapies into the clinic. Although improvement in the
sensitivity of computational drug repositioning methods has identified numerous
credible repositioning opportunities, few have been progressed. Arguably the
"black box" nature of drug action in a new indication is one of the main blocks
to progression, highlighting the need for methods that inform on the broader
target mechanism in the disease context.
RESULTS: We demonstrate that the analysis of co-expressed genes may be a critical
first step towards illumination of both disease pathology and mode of drug
action. We achieve this using a novel framework, co-expressed gene-set enrichment
analysis (cogena) for co-expression analysis of gene expression signatures and
gene set enrichment analysis of co-expressed genes. The cogena framework enables 
simultaneous, pathway driven, disease and drug repositioning analysis. Cogena can
be used to illuminate coordinated changes within disease transcriptomes and
identify drugs acting mechanistically within this framework. We illustrate this
using a psoriatic skin transcriptome, as an exemplar, and recover two widely used
Psoriasis drugs (Methotrexate and Ciclosporin) with distinct modes of action.
Cogena out-performs the results of Connectivity Map and NFFinder webservers in
similar disease transcriptome analyses. Furthermore, we investigated the
literature support for the other top-ranked compounds to treat psoriasis and
showed how the outputs of cogena analysis can contribute new insight to support
the progression of drugs into the clinic. We have made cogena freely available
within Bioconductor or https://github.com/zhilongjia/cogena .
CONCLUSIONS: In conclusion, by targeting co-expressed genes within disease
transcriptomes, cogena offers novel biological insight, which can be effectively 
harnessed for drug discovery and repositioning, allowing the grouping and
prioritisation of drug repositioning candidates on the basis of putative mode of 
action.

DOI: 10.1186/s12864-016-2737-8 
PMCID: PMC4884357
PMID: 27234029  [PubMed - in process]


487. J Chem Theory Comput. 2016 Jul 12;12(7):3416-28. doi: 10.1021/acs.jctc.5b01157.
Epub 2016 Jun 29.

Firefly Algorithm for Structural Search.

Avendaño-Franco G(1), Romero AH(1).

Author information: 
(1)Department of Physics and Astronomy, West Virginia University , Morgantown,
West Virginia 26506, United States.

The problem of computational structure prediction of materials is approached
using the firefly (FF) algorithm. Starting from the chemical composition and
optionally using prior knowledge of similar structures, the FF method is able to 
predict not only known stable structures but also a variety of novel competitive 
metastable structures. This article focuses on the strengths and limitations of
the algorithm as a multimodal global searcher. The algorithm has been implemented
in software package PyChemia ( https://github.com/MaterialsDiscovery/PyChemia ), 
an open source python library for materials analysis. We present applications of 
the method to van der Waals clusters and crystal structures. The FF method is
shown to be competitive when compared to other population-based global searchers.

DOI: 10.1021/acs.jctc.5b01157 
PMID: 27232694  [PubMed - in process]


488. BMC Bioinformatics. 2016 May 26;17(1):223. doi: 10.1186/s12859-016-1089-3.

Crowdsourcing the nodulation gene network discovery environment.

Li Y(1,)(2), Jackson SA(3,)(4).

Author information: 
(1)Center for Applied Genetic Technologies, University of Georgia, 111 Riverbend 
Road, Athens, 30602, GA, USA. (2)Institute of Plant Breeding, Genetics and
Genomics, University of Georgia, 111 Riverbend Road, Athens, 30602, GA, USA.
(3)Center for Applied Genetic Technologies, University of Georgia, 111 Riverbend 
Road, Athens, 30602, GA, USA. sjackson@uga.edu. (4)Institute of Plant Breeding,
Genetics and Genomics, University of Georgia, 111 Riverbend Road, Athens, 30602, 
GA, USA. sjackson@uga.edu.

BACKGROUND: The Legumes (Fabaceae) are an economically and ecologically important
group of plant species with the conspicuous capacity for symbiotic nitrogen
fixation in root nodules, specialized plant organs containing symbiotic microbes.
With the aim of understanding the underlying molecular mechanisms leading to
nodulation, many efforts are underway to identify nodulation-related genes and
determine how these genes interact with each other. In order to accurately and
efficiently reconstruct nodulation gene network, a crowdsourcing platform,
CrowdNodNet, was created.
RESULTS: The platform implements the jQuery and vis.js JavaScript libraries, so
that users are able to interactively visualize and edit the gene network, and
easily access the information about the network, e.g. gene lists, gene
interactions and gene functional annotations. In addition, all the gene
information is written on MediaWiki pages, enabling users to edit and contribute 
to the network curation.
CONCLUSIONS: Utilizing the continuously updated, collaboratively written, and
community-reviewed Wikipedia model, the platform could, in a short time, become a
comprehensive knowledge base of nodulation-related pathways. The platform could
also be used for other biological processes, and thus has great potential for
integrating and advancing our understanding of the functional genomics and
systems biology of any process for any species. The platform is available at
http://crowd.bioops.info/ , and the source code can be openly accessed at
https://github.com/bioops/crowdnodnet under MIT License.

DOI: 10.1186/s12859-016-1089-3 
PMCID: PMC4880984
PMID: 27230384  [PubMed - in process]


489. Invest Ophthalmol Vis Sci. 2016 May 1;57(6):2831-8. doi: 10.1167/iovs.16-19541.

Quantification of Focal Outflow Enhancement Using Differential Canalograms.

Loewen RT(1), Brown EN(2), Scott G(1), Parikh H(3), Schuman JS(4), Loewen NA(1).

Author information: 
(1)Department of Ophthalmology University of Pittsburgh Medical Center,
Pittsburgh, Pennsylvania, United States. (2)Department of Ophthalmology,
Vanderbilt University School of Medicine, Nashville, Tennessee, United States.
(3)Department of Ophthalmology University of Pittsburgh Medical Center,
Pittsburgh, Pennsylvania, United States 3School of Medicine, Rutgers State
University of New Jersey, New Brunswick, New Jersey, United States. (4)Department
of Ophthalmology University of Pittsburgh Medical Center, Pittsburgh,
Pennsylvania, United States 4School of Medicine, New York University, New York,
New York, United States.

PURPOSE: To quantify regional changes of conventional outflow caused by ab
interno trabeculectomy (AIT).
METHODS: Gonioscopic, plasma-mediated AIT was established in enucleated pig eyes.
We developed a program to automatically quantify outflow changes (R, package
eye-canalogram, github.com) using a fluorescent tracer reperfusion technique.
Trabecular meshwork (TM) ablation was demonstrated with fluorescent spheres in
six eyes before formal outflow quantification with two-dye reperfusion
canalograms in six additional eyes. Eyes were perfused with a central,
intracameral needle at 15 mm Hg. Canalograms and histology were correlated for
each eye.
RESULTS: The pig eye provided a model with high similarity to AIT in human
patients. Histology indicated ablation of TM and unroofing of most Schlemm's
canal segments. Spheres highlighted additional circumferential and radial outflow
beyond the immediate area of ablation. Differential canalograms showed that AIT
caused an increase of outflow of 17 ± 5-fold inferonasally, 14 ± 3-fold
superonasally, and also an increase in the opposite quadrants with a 2 ± 1-fold
increase superotemporally, and 3 ± 3 inferotemporally. Perilimbal specific flow
image analysis showed an accelerated nasal filling with an additional perilimbal 
flow direction into adjacent quadrants.
CONCLUSIONS: A quantitative, differential canalography technique was developed
that allows us to quantify supraphysiological outflow enhancement by AIT.

DOI: 10.1167/iovs.16-19541 
PMCID: PMC5113980
PMID: 27227352  [PubMed - in process]


490. J Proteome Res. 2016 Jul 1;15(7):2143-51. doi: 10.1021/acs.jproteome.6b00016.
Epub 2016 Jun 8.

Dinosaur: A Refined Open-Source Peptide MS Feature Detector.

Teleman J(1,)(2), Chawade A(1), Sandin M(1), Levander F(1,)(3), Malmström J(2).

Author information: 
(1)Department of Immunotechnology, Lund University , 223 83 Lund, Sweden.
(2)Department of Clinical Sciences Lund, Lund University , 221 00 Lund, Sweden.
(3)Bioinformatics Infrastructure for Life Sciences (BILS), Lund University , 223 
83 Lund, Sweden.

In bottom-up mass spectrometry (MS)-based proteomics, peptide isotopic and
chromatographic traces (features) are frequently used for label-free
quantification in data-dependent acquisition MS but can also be used for the
improved identification of chimeric spectra or sample complexity
characterization. Feature detection is difficult because of the high complexity
of MS proteomics data from biological samples, which frequently causes features
to intermingle. In addition, existing feature detection algorithms commonly
suffer from compatibility issues, long computation times, or poor performance on 
high-resolution data. Because of these limitations, we developed a new tool,
Dinosaur, with increased speed and versatility. Dinosaur has the functionality to
sample algorithm computations through quality-control plots, which we call a plot
trail. From the evaluation of this plot trail, we introduce several algorithmic
improvements to further improve the robustness and performance of Dinosaur, with 
the detection of features for 98% of MS/MS identifications in a benchmark data
set, and no other algorithm tested in this study passed 96% feature detection. We
finally used Dinosaur to reimplement a published workflow for peptide
identification in chimeric spectra, increasing chimeric identification from 26%
to 32% over the standard workflow. Dinosaur is operating-system-independent and
is freely available as open source on https://github.com/fickludd/dinosaur .

DOI: 10.1021/acs.jproteome.6b00016 
PMCID: PMC4933939
PMID: 27224449  [PubMed - in process]


491. Mol Biol Evol. 2016 Aug;33(8):2135-50. doi: 10.1093/molbev/msw098. Epub 2016 May 
24.

Controlling for Phylogenetic Relatedness and Evolutionary Rates Improves the
Discovery of Associations Between Species' Phenotypic and Genomic Differences.

Prudent X(1), Parra G(1), Schwede P(1), Roscito JG(1), Hiller M(2).

Author information: 
(1)Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany 
Max Planck Institute for the Physics of Complex Systems, Dresden, Germany. (2)Max
Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany Max
Planck Institute for the Physics of Complex Systems, Dresden, Germany
hiller@mpi-cbg.de.

The growing number of sequenced genomes allows us now to address a key question
in genetics and evolutionary biology: which genomic changes underlie particular
phenotypic changes between species? Previously, we developed a computational
framework called Forward Genomics that associates phenotypic to genomic
differences by focusing on phenotypes that are independently lost in different
lineages. However, our previous implementation had three main limitations. Here, 
we present two new Forward Genomics methods that overcome these limitations by
(1) directly controlling for phylogenetic relatedness, (2) controlling for
differences in evolutionary rates, and (3) computing a statistical significance. 
We demonstrate on large-scale simulated data and on real data that both new
methods substantially improve the sensitivity to detect associations between
phenotypic and genomic differences. We applied these new methods to detect
genomic differences involved in the loss of vision in the blind mole rat and the 
cape golden mole, two independent subterranean mammals. Forward Genomics
identified several genes that are enriched in functions related to eye
development and the perception of light, as well as genes involved in the
circadian rhythm. These new Forward Genomics methods represent a significant
advance in our ability to discover the genomic basis underlying phenotypic
differences between species. Source code:
https://github.com/hillerlab/ForwardGenomics/.

© The Author 2016. Published by Oxford University Press on behalf of the Society 
for Molecular Biology and Evolution.

DOI: 10.1093/molbev/msw098 
PMCID: PMC4948712
PMID: 27222536  [PubMed - in process]


492. Nat Methods. 2016 Jul;13(7):581-3. doi: 10.1038/nmeth.3869. Epub 2016 May 23.

DADA2: High-resolution sample inference from Illumina amplicon data.

Callahan BJ(1), McMurdie PJ(2), Rosen MJ(3), Han AW(2), Johnson AJ(2), Holmes
SP(1).

Author information: 
(1)Department of Statistics, Stanford University, Stanford, California, USA.
(2)Second Genome, South San Francisco, California, USA. (3)Department of Applied 
Physics, Stanford University, Stanford, California, USA.

We present the open-source software package DADA2 for modeling and correcting
Illumina-sequenced amplicon errors (https://github.com/benjjneb/dada2). DADA2
infers sample sequences exactly and resolves differences of as little as 1
nucleotide. In several mock communities, DADA2 identified more real variants and 
output fewer spurious sequences than other methods. We applied DADA2 to vaginal
samples from a cohort of pregnant women, revealing a diversity of previously
undetected Lactobacillus crispatus variants.

DOI: 10.1038/nmeth.3869 
PMCID: PMC4927377
PMID: 27214047  [PubMed - in process]


493. Genome Med. 2016 May 19;8(1):56. doi: 10.1186/s13073-016-0302-3.

An adaptive association test for microbiome data.

Wu C(1), Chen J(2), Kim J(1), Pan W(3).

Author information: 
(1)Division of Biostatistics, University of Minnesota, 420 Delaware St. SE,
Minneapolis, 55455, USA. (2)Division of Biomedical Statistics and Informatics,
Department of Health Sciences Research, Mayo Clinic, 200 First St. SW, Rochester,
55905, USA. (3)Division of Biostatistics, University of Minnesota, 420 Delaware
St. SE, Minneapolis, 55455, USA. weip@biostat.umn.edu.

There is increasing interest in investigating how the compositions of microbial
communities are associated with human health and disease. Although existing
methods have identified many associations, a proper choice of a phylogenetic
distance is critical for the power of these methods. To assess an overall
association between the composition of a microbial community and an outcome of
interest, we present a novel multivariate testing method called aMiSPU, that is
joint and highly adaptive over all observed taxa and thus high powered across
various scenarios, alleviating the issue with the choice of a phylogenetic
distance. Our simulations and real-data analyses demonstrated that the aMiSPU
test was often more powerful than several competing methods while correctly
controlling type I error rates. The R package MiSPU is available at
https://github.com/ChongWu-Biostat/MiSPU and CRAN.

DOI: 10.1186/s13073-016-0302-3 
PMCID: PMC4872356
PMID: 27198579  [PubMed - in process]


494. Anal Biochem. 2016 Aug 15;507:1-6. doi: 10.1016/j.ab.2016.05.005. Epub 2016 May
16.

Predicting pupylation sites in prokaryotic proteins using semi-supervised
self-training support vector machine algorithm.

Ju Z(1), Gu H(2).

Author information: 
(1)School of Control Science and Engineering, Dalian University of Technology,
Dalian 116024, People's Republic of China. (2)School of Control Science and
Engineering, Dalian University of Technology, Dalian 116024, People's Republic of
China. Electronic address: guhong@dlut.edu.cn.

As one important post-translational modification of prokaryotic proteins,
pupylation plays a key role in regulating various biological processes. The
accurate identification of pupylation sites is crucial for understanding the
underlying mechanisms of pupylation. Although several computational methods have 
been developed for the identification of pupylation sites, the prediction
accuracy of them is still unsatisfactory. Here, a novel bioinformatics tool named
IMP-PUP is proposed to improve the prediction of pupylation sites. IMP-PUP is
constructed on the composition of k-spaced amino acid pairs and trained with a
modified semi-supervised self-training support vector machine (SVM) algorithm.
The proposed algorithm iteratively trains a series of support vector machine
classifiers on both annotated and non-annotated pupylated proteins. Computational
results show that IMP-PUP achieves the area under receiver operating
characteristic curves of 0.91, 0.73, and 0.75 on our training set, Tung's testing
set, and our testing set, respectively, which are better than those of the
different error costs SVM algorithm and the original self-training SVM algorithm.
Independent tests also show that IMP-PUP significantly outperforms three other
existing pupylation site predictors: GPS-PUP, iPUP, and pbPUP. Therefore, IMP-PUP
can be a useful tool for accurate prediction of pupylation sites. A MATLAB
software package for IMP-PUP is available at https://juzhe1120.github.io/.

Copyright © 2016 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.ab.2016.05.005 
PMID: 27197054  [PubMed - in process]


495. Mol Biol Evol. 2016 Aug;33(8):2163-6. doi: 10.1093/molbev/msw080. Epub 2016 Apr
19.

Phylo.io: Interactive Viewing and Comparison of Large Phylogenetic Trees on the
Web.

Robinson O(1), Dylus D(2), Dessimoz C(3).

Author information: 
(1)Department of Computer Science, University College London, London, United
Kingdom Department of Genetics Evolution and Environment, University College
London, London, United Kingdom. (2)Department of Genetics Evolution and
Environment, University College London, London, United Kingdom Department of
Ecology and Evolution, University of Lausanne, Lausanne, Switzerland Center for
Integrative Genomics, University of Lausanne, Lausanne, Switzerland
david.dylus@unil.ch christophe.dessimoz@unil.ch. (3)Department of Computer
Science, University College London, London, United Kingdom Department of Genetics
Evolution and Environment, University College London, London, United Kingdom
Department of Ecology and Evolution, University of Lausanne, Lausanne,
Switzerland Center for Integrative Genomics, University of Lausanne, Lausanne,
Switzerland Swiss Institute of Bioinformatics, Lausanne, Switzerland
david.dylus@unil.ch christophe.dessimoz@unil.ch.

Phylogenetic trees are pervasively used to depict evolutionary relationships.
Increasingly, researchers need to visualize large trees and compare multiple
large trees inferred for the same set of taxa (reflecting uncertainty in the tree
inference or genuine discordance among the loci analyzed). Existing tree
visualization tools are however not well suited to these tasks. In particular,
side-by-side comparison of trees can prove challenging beyond a few dozen taxa.
Here, we introduce Phylo.io, a web application to visualize and compare
phylogenetic trees side-by-side. Its distinctive features are: highlighting of
similarities and differences between two trees, automatic identification of the
best matching rooting and leaf order, scalability to large trees, high usability,
multiplatform support via standard HTML5 implementation, and possibility to store
and share visualizations. The tool can be freely accessed at http://phylo.io and 
can easily be embedded in other web servers. The code for the associated
JavaScript library is available at https://github.com/DessimozLab/phylo-io under 
an MIT open source license.

© The Author 2016. Published by Oxford University Press on behalf of the Society 
for Molecular Biology and Evolution.

DOI: 10.1093/molbev/msw080 
PMCID: PMC4948708
PMID: 27189561  [PubMed - in process]


496. Mol Biol Evol. 2016 Aug;33(8):2117-34. doi: 10.1093/molbev/msw069. Epub 2016 Apr 
6.

A New Orthology Assessment Method for Phylogenomic Data: Unrooted Phylogenetic
Orthology.

Ballesteros JA(1), Hormiga G(2).

Author information: 
(1)Department of Biological Sciences, The George Washington University
jabac@gwu.edu. (2)Department of Biological Sciences, The George Washington
University.

Erratum in
    Mol Biol Evol. 2016 Sep;33(9):2481.

Current sequencing technologies are making available unprecedented amounts of
genetic data for a large variety of species including nonmodel organisms.
Although many phylogenomic surveys spend considerable time finding orthologs from
the wealth of sequence data, these results do not transcend the original study
and after being processed for specific phylogenetic purposes these orthologs do
not become stable orthology hypotheses. We describe a procedure to detect and
document the phylogenetic distribution of orthologs allowing researchers to use
this information to guide selection of loci best suited to test specific
evolutionary questions. At the core of this pipeline is a new phylogenetic
orthology method that is neither affected by the position of the root nor
requires explicit assignment of outgroups. We discuss the properties of this new 
orthology assessment method and exemplify its utility for phylogenomics using a
small insects dataset. In addition, we exemplify the pipeline to identify and
document stable orthologs for the group of orb-weaving spiders (Araneoidea) using
RNAseq data. The scripts used in this study, along with sample files and
additional documentation, are available at https://github.com/ballesterus/UPhO.

© The Author 2016. Published by Oxford University Press on behalf of the Society 
for Molecular Biology and Evolution. All rights reserved. For permissions, please
e-mail: journals.permissions@oup.com.

DOI: 10.1093/molbev/msw069 
PMID: 27189539  [PubMed - in process]


497. Bioinformatics. 2016 Sep 1;32(17):2590-7. doi: 10.1093/bioinformatics/btw302.
Epub 2016 May 13.

SoFIA: a data integration framework for annotating high-throughput datasets.

Childs LH(1), Mamlouk S(2), Brandt J(1), Sers C(2), Leser U(1).

Author information: 
(1)Wissenmanagement in der Bioinformatik, Humboldt-Universität zu Berlin, Berlin,
Germany. (2)DKTK Deutsches Konsortium Für Translationale Krebsforschung, Partner 
site Charite Berlin, Berlin, Germany.

MOTIVATION: Integrating heterogeneous datasets from several sources is a common
bioinformatics task that often requires implementing a complex workflow
intermixing database access, data filtering, format conversions, identifier
mapping, among further diverse operations. Data integration is especially
important when annotating next generation sequencing data, where a multitude of
diverse tools and heterogeneous databases can be used to provide a large variety 
of annotation for genomic locations, such a single nucleotide variants or genes. 
Each tool and data source is potentially useful for a given project and often
more than one are used in parallel for the same purpose. However, software that
always produces all available data is difficult to maintain and quickly leads to 
an excess of data, creating an information overload rather than the desired
goal-oriented and integrated result.
RESULTS: We present SoFIA, a framework for workflow-driven data integration with 
a focus on genomic annotation. SoFIA conceptualizes workflow templates as
comprehensive workflows that cover as many data integration operations as
possible in a given domain. However, these templates are not intended to be
executed as a whole; instead, when given an integration task consisting of a set 
of input data and a set of desired output data, SoFIA derives a minimal workflow 
that completes the task. These workflows are typically fast and create exactly
the information a user wants without requiring them to do any implementation
work. Using a comprehensive genome annotation template, we highlight the
flexibility, extensibility and power of the framework using real-life case
studies.
AVAILABILITY AND IMPLEMENTATION:
https://github.com/childsish/sofia/releases/latest under the GNU General Public
License
CONTACT: liam.childs@hu-berlin.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw302 
PMID: 27187206  [PubMed - in process]


498. Bioinformatics. 2016 Sep 1;32(17):2604-10. doi: 10.1093/bioinformatics/btw304.
Epub 2016 May 13.

seqlm: an MDL based method for identifying differentially methylated regions in
high density methylation array data.

Kolde R(1), Märtens K(2), Lokk K(3), Laur S(2), Vilo J(2).

Author information: 
(1)Institute of Computer Science, University of Tartu, 50409 Tartu, Estonia
Center for Computational and Integrative Biology, Massachusetts General Hospital,
Boston, MA 02114, USA. (2)Institute of Computer Science, University of Tartu,
50409 Tartu, Estonia. (3)Institute of Molecular and Cell Biology, University of
Tartu, 51010 Tartu, Estonia.

MOTIVATION: One of the main goals of large scale methylation studies is to detect
differentially methylated loci. One way is to approach this problem sitewise,
i.e. to find differentially methylated positions (DMPs). However, it has been
shown that methylation is regulated in longer genomic regions. So it is more
desirable to identify differentially methylated regions (DMRs) instead of DMPs.
The new high coverage arrays, like Illuminas 450k platform, make it possible at a
reasonable cost. Few tools exist for DMR identification from this type of data,
but there is no standard approach.
RESULTS: We propose a novel method for DMR identification that detects the region
boundaries according to the minimum description length (MDL) principle,
essentially solving the problem of model selection. The significance of the
regions is established using linear mixed models. Using both simulated and large 
publicly available methylation datasets, we compare seqlm performance to
alternative approaches. We demonstrate that it is both more sensitive and
specific than competing methods. This is achieved with minimal parameter tuning
and, surprisingly, quickest running time of all the tried methods. Finally, we
show that the regional differential methylation patterns identified on sparse
array data are confirmed by higher resolution sequencing approaches.
AVAILABILITY AND IMPLEMENTATION: The methods have been implemented in R package
seqlm that is available through Github: https://github.com/raivokolde/seqlm
CONTACT: rkolde@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw304 
PMCID: PMC5013909
PMID: 27187204  [PubMed - in process]


499. Bioinformatics. 2016 Sep 1;32(17):2598-603. doi: 10.1093/bioinformatics/btw303.
Epub 2016 May 13.

A simple yet accurate correction for winner's curse can predict signals
discovered in much larger genome scans.

Bigdeli TB(1), Lee D(1), Webb BT(1), Riley BP(1), Vladimirov VI(2), Fanous AH(1),
Kendler KS(1), Bacanu SA(1).

Author information: 
(1)Department of Psychiatry, Virginia Institute for Psychiatric and Behavioral
Genetics. (2)Department of Psychiatry, Virginia Institute for Psychiatric and
Behavioral Genetics Center for Biomarker Research & Personalized Medicine,
Virginia Commonwealth University, Richmond, VA 23298, USA Lieber Institute for
Brain Development, Johns Hopkins University, Baltimore, MD 21205, USA.

MOTIVATION: For genetic studies, statistically significant variants explain far
less trait variance than 'sub-threshold' association signals. To dimension
follow-up studies, researchers need to accurately estimate 'true' effect sizes at
each SNP, e.g. the true mean of odds ratios (ORs)/regression coefficients (RRs)
or Z-score noncentralities. Naïve estimates of effect sizes incur winner's curse 
biases, which are reduced only by laborious winner's curse adjustments (WCAs).
Given that Z-scores estimates can be theoretically translated on other scales, we
propose a simple method to compute WCA for Z-scores, i.e. their true
means/noncentralities.
RESULTS: WCA of Z-scores shrinks these towards zero while, on P-value scale,
multiple testing adjustment (MTA) shrinks P-values toward one, which corresponds 
to the zero Z-score value. Thus, WCA on Z-scores scale is a proxy for MTA on
P-value scale. Therefore, to estimate Z-score noncentralities for all SNPs in
genome scans, we propose F: DR I: nverse Q: uantile T: ransformation (FIQT). It
(i) performs the simpler MTA of P-values using FDR and (ii) obtains
noncentralities by back-transforming MTA P-values on Z-score scale. When compared
to competitors, realistic simulations suggest that FIQT is more (i) accurate and 
(ii) computationally efficient by orders of magnitude. Practical application of
FIQT to Psychiatric Genetic Consortium schizophrenia cohort predicts a
non-trivial fraction of sub-threshold signals which become significant in much
larger supersamples.
CONCLUSIONS: FIQT is a simple, yet accurate, WCA method for Z-scores (and
ORs/RRs, via simple transformations).
AVAILABILITY AND IMPLEMENTATION: A 10 lines R function implementation is
available at https://github.com/bacanusa/FIQT CONTACT: sabacanu@vcu.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw303 
PMCID: PMC5013908
PMID: 27187203  [PubMed - in process]


500. Bioinformatics. 2016 Sep 1;32(17):2611-7. doi: 10.1093/bioinformatics/btw308.
Epub 2016 May 14.

A two-part mixed-effects model for analyzing longitudinal microbiome
compositional data.

Chen EZ(1), Li H(1).

Author information: 
(1)Genomics and Computational Biology Graduate Group Department of Biostatistics 
and Epidemiology, University of Pennsylvania Perelman School of Medicine,
Philadelphia, PA 19104, USA.

MOTIVATION: The human microbial communities are associated with many human
diseases such as obesity, diabetes and inflammatory bowel disease.
High-throughput sequencing technology has been widely used to quantify the
microbial composition in order to understand its impacts on human health.
Longitudinal measurements of microbial communities are commonly obtained in many 
microbiome studies. A key question in such microbiome studies is to identify the 
microbes that are associated with clinical outcomes or environmental factors.
However, microbiome compositional data are highly skewed, bounded in [0,1), and
often sparse with many zeros. In addition, the observations from repeated
measures in longitudinal studies are correlated. A method that takes into account
these features is needed for association analysis in longitudinal microbiome
data.
RESULTS: In this paper, we propose a two-part zero-inflated Beta regression model
with random effects (ZIBR) for testing the association between microbial
abundance and clinical covariates for longitudinal microbiome data. The model
includes a logistic regression component to model presence/absence of a microbe
in the samples and a Beta regression component to model non-zero microbial
abundance, where each component includes a random effect to account for the
correlations among the repeated measurements on the same subject. Both simulation
studies and the application to real microbiome data have shown that ZIBR model
outperformed the previously used methods. The method provides a useful tool for
identifying the relevant taxa based on longitudinal or repeated measures in
microbiome research.
AVAILABILITY AND IMPLEMENTATION: https://github.com/chvlyl/ZIBR CONTACT:
hongzhe@upenn.edu.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw308 
PMID: 27187200  [PubMed - in process]


501. PLoS One. 2016 May 16;11(5):e0155461. doi: 10.1371/journal.pone.0155461.
eCollection 2016.

SparkBWA: Speeding Up the Alignment of High-Throughput DNA Sequencing Data.

Abuín JM(1), Pichel JC(1), Pena TF(1), Amigo J(2,)(3).

Author information: 
(1)Centro de Investigación en Tecnoloxías da Información (CITIUS), Universidade
de Santiago de Compostela, Santiago de Compostela, Spain. (2)Fundación Pública
Galega de Medicina Xenómica (SERGAS), Santiago de Compostela, Spain. (3)Grupo
Medicina Xenómica, Instituto de Investigación Sanitaria de Santiago de
Compostela, Santiago de Compostela, Spain.

Next-generation sequencing (NGS) technologies have led to a huge amount of
genomic data that need to be analyzed and interpreted. This fact has a huge
impact on the DNA sequence alignment process, which nowadays requires the mapping
of billions of small DNA sequences onto a reference genome. In this way, sequence
alignment remains the most time-consuming stage in the sequence analysis
workflow. To deal with this issue, state of the art aligners take advantage of
parallelization strategies. However, the existent solutions show limited
scalability and have a complex implementation. In this work we introduce
SparkBWA, a new tool that exploits the capabilities of a big data technology as
Spark to boost the performance of one of the most widely adopted aligner, the
Burrows-Wheeler Aligner (BWA). The design of SparkBWA uses two independent
software layers in such a way that no modifications to the original BWA source
code are required, which assures its compatibility with any BWA version (future
or legacy). SparkBWA is evaluated in different scenarios showing noticeable
results in terms of performance and scalability. A comparison to other parallel
BWA-based aligners validates the benefits of our approach. Finally, an intuitive 
and flexible API is provided to NGS professionals in order to facilitate the
acceptance and adoption of the new tool. The source code of the software
described in this paper is publicly available at
https://github.com/citiususc/SparkBWA, with a GPL3 license.

DOI: 10.1371/journal.pone.0155461 
PMCID: PMC4868289
PMID: 27182962  [PubMed - in process]


502. Genetics. 2016 Jul;203(3):1105-16. doi: 10.1534/genetics.116.188292. Epub 2016
May 6.

Local Joint Testing Improves Power and Identifies Hidden Heritability in
Association Studies.

Brown BC(1), Price AL(2), Patsopoulos NA(3), Zaitlen N(4).

Author information: 
(1)Department of Computer Science, University of California, Berkeley, California
94720 brielin@berkeley.edu. (2)Harvard T. H. Chan School of Public Health,
Harvard University, Boston, Massachusetts 02115. (3)Department of Neurology,
Brigham & Women's Hospital, Boston, Massachusetts 02115 Division of Genetics,
Department of Medicine, Brigham & Women's Hospital, Boston, Massachusetts 02115
Broad Institute, Cambridge, Massachusetts 02142. (4)Department of Medicine,
University of California, San Francisco, California 94158.

There is mounting evidence that complex human phenotypes are highly polygenic,
with many loci harboring multiple causal variants, yet most genetic association
studies examine each SNP in isolation. While this has led to the discovery of
thousands of disease associations, discovered variants account for only a small
fraction of disease heritability. Alternative multi-SNP methods have been
proposed, but issues such as multiple-testing correction, sensitivity to
genotyping error, and optimization for the underlying genetic architectures
remain. Here we describe a local joint-testing procedure, complete with
multiple-testing correction, that leverages a genetic phenomenon we call linkage 
masking wherein linkage disequilibrium between SNPs hides their signal under
standard association methods. We show that local joint testing on the original
Wellcome Trust Case Control Consortium (WTCCC) data set leads to the discovery of
22 associated loci, 5 more than the marginal approach. These loci were later
found in follow-up studies containing thousands of additional individuals. We
find that these loci significantly increase the heritability explained by
genome-wide significant associations in the WTCCC data set. Furthermore, we show 
that local joint testing in a cis-expression QTL (eQTL) study of the gEUVADIS
data set increases the number of genes containing significant eQTL by 10.7% over 
marginal analyses. Our multiple-hypothesis correction and joint-testing framework
are available in a python software package called Jester, available at
github.com/brielin/Jester.

Copyright © 2016 by the Genetics Society of America.

DOI: 10.1534/genetics.116.188292 
PMCID: PMC4937483 [Available on 2017-07-01]
PMID: 27182951  [PubMed - in process]


503. Nucleic Acids Res. 2016 Jul 27;44(13):e117. doi: 10.1093/nar/gkw430. Epub 2016
May 13.

TSCAN: Pseudo-time reconstruction and evaluation in single-cell RNA-seq analysis.

Ji Z(1), Ji H(2).

Author information: 
(1)Department of Biostatistics, Johns Hopkins University Bloomberg School of
Public Health, 615 North Wolfe Street, Baltimore, MD 21205, USA. (2)Department of
Biostatistics, Johns Hopkins University Bloomberg School of Public Health, 615
North Wolfe Street, Baltimore, MD 21205, USA hji@jhu.edu.

When analyzing single-cell RNA-seq data, constructing a pseudo-temporal path to
order cells based on the gradual transition of their transcriptomes is a useful
way to study gene expression dynamics in a heterogeneous cell population.
Currently, a limited number of computational tools are available for this task,
and quantitative methods for comparing different tools are lacking. Tools for
Single Cell Analysis (TSCAN) is a software tool developed to better support in
silico pseudo-Time reconstruction in Single-Cell RNA-seq ANalysis. TSCAN uses a
cluster-based minimum spanning tree (MST) approach to order cells. Cells are
first grouped into clusters and an MST is then constructed to connect cluster
centers. Pseudo-time is obtained by projecting each cell onto the tree, and the
ordered sequence of cells can be used to study dynamic changes of gene expression
along the pseudo-time. Clustering cells before MST construction reduces the
complexity of the tree space. This often leads to improved cell ordering. It also
allows users to conveniently adjust the ordering based on prior knowledge. TSCAN 
has a graphical user interface (GUI) to support data visualization and user
interaction. Furthermore, quantitative measures are developed to objectively
evaluate and compare different pseudo-time reconstruction methods. TSCAN is
available at https://github.com/zji90/TSCAN and as a Bioconductor package.

© The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkw430 
PMCID: PMC4994863
PMID: 27179027  [PubMed - in process]


504. Phys Rev E. 2016 Apr;93:042307. doi: 10.1103/PhysRevE.93.042307. Epub 2016 Apr
12.

Law of corresponding states for open collaborations.

Gherardi M(1,)(2,)(3), Bassetti F(4), Cosentino Lagomarsino M(1,)(5).

Author information: 
(1)Sorbonne Universités, UPMC Univ Paris 06, UMR 7238, Computational and
Quantitative Biology, 15 rue de l'École de Médecine Paris, France.
(2)Dipartimento di Fisica, Università degli Studi di Milano, via Celoria 16,
20133 Milano, Italy. (3)I.N.F.N. Milano. (4)Dipartimento di Matematica,
Università di Pavia, Pavia, Italy. (5)CNRS, UMR 7238, Paris, France.

We study the relation between number of contributors and product size in
Wikipedia and GitHub. In contrast to traditional production, this is strongly
probabilistic, but is characterized by two quantitative nonlinear laws: a
power-law bound to product size for increasing number of contributors, and the
universal collapse of rescaled distributions. A variant of the random-energy
model shows that both laws are due to the heterogeneity of contributors, and
displays an intriguing finite-size scaling property with no equivalent in
standard systems. The analysis uncovers the right intensive densities, enabling
the comparison of projects with different numbers of contributors on equal
grounds. We use this property to expose the detrimental effects of conflicting
interactions in Wikipedia.

DOI: 10.1103/PhysRevE.93.042307 
PMID: 27176312  [PubMed - in process]


505. J Biomed Semantics. 2016 May 10;7:25. doi: 10.1186/s13326-016-0064-2. eCollection
2016.

OmniSearch: a semantic search system based on the Ontology for MIcroRNA Target
(OMIT) for microRNA-target gene interaction data.

Huang J(1), Gutierrez F(2), Strachan HJ(1), Dou D(2), Huang W(3), Smith B(4),
Blake JA(5), Eilbeck K(6), Natale DA(7), Lin Y(8), Wu B(9), Silva Nd(2), Wang
X(10), Liu Z(11), Borchert GM(12), Tan M(11), Ruttenberg A(13).

Author information: 
(1)School of Computing, University of South Alabama, Mobile, Alabama, 36688-0002 
USA. (2)Computer and Information Science Department, University of Oregon,
Eugene, Oregon, 97403-1202 USA. (3)Miracle Query, Inc., Eugene, Oregon,
97403-1202 USA. (4)Department of Philosophy, University at Buffalo, Buffalo, New 
York, 14260-4150 USA. (5)Genome Informatics, The Jackson Laboratory, Bar Harbor, 
Maine, 04609-1523 USA. (6)Department of Biomedical Informatics, University of
Utah, Salt Lake City, Utah, 84112-5775 USA. (7)Department of Biochemistry and
Molecular and Cellular Biology, Georgetown University Medical Center, Washington 
D.C., 20007-1485 USA. (8)Center for Computational Science, University of Miami,
Miami, Florida, 33146-2960 U.S.A. (9)Department of Microbiology and Immunology,
First Affiliated Hospital, Kunming Medical University, Kunming, Yunnan, 650032
China. (10)Department of Radiation Oncology, Washington University School of
Medicine, St. Louis, Missouri, 63110-0001 USA. (11)Mitchell Cancer Institute,
University of South Alabama, Mobile, Alabama, 36604-1405 USA. (12)Department of
Biology, University of South Alabama, Mobile, Alabama, 36688-0002 USA. (13)School
of Dental Medicine, University at Buffalo, Buffalo, New York, 14214-8006 USA.

As a special class of non-coding RNAs (ncRNAs), microRNAs (miRNAs) perform
important roles in numerous biological and pathological processes. The
realization of miRNA functions depends largely on how miRNAs regulate specific
target genes. It is therefore critical to identify, analyze, and cross-reference 
miRNA-target interactions to better explore and delineate miRNA functions.
Semantic technologies can help in this regard. We previously developed a miRNA
domain-specific application ontology, Ontology for MIcroRNA Target (OMIT), whose 
goal was to serve as a foundation for semantic annotation, data integration, and 
semantic search in the miRNA field. In this paper we describe our continuing
effort to develop the OMIT, and demonstrate its use within a semantic search
system, OmniSearch, designed to facilitate knowledge capture of miRNA-target
interaction data. Important changes in the current version OMIT are summarized
as: (1) following a modularized ontology design (with 2559 terms imported from
the NCRO ontology); (2) encoding all 1884 human miRNAs (vs. 300 in previous
versions); and (3) setting up a GitHub project site along with an issue tracker
for more effective community collaboration on the ontology development. The OMIT 
ontology is free and open to all users, accessible at:
http://purl.obolibrary.org/obo/omit.owl. The OmniSearch system is also free and
open to all users, accessible at:
http://omnisearch.soc.southalabama.edu/index.php/Software.

DOI: 10.1186/s13326-016-0064-2 
PMCID: PMC4863347
PMID: 27175225  [PubMed - in process]


506. Bioinformatics. 2016 Sep 1;32(17):2707-9. doi: 10.1093/bioinformatics/btw298.
Epub 2016 May 11.

SA-SSR: a suffix array-based algorithm for exhaustive and efficient SSR discovery
in large genetic sequences.

Pickett BD(1), Karlinsey SM(1), Penrod CE(1), Cormier MJ(1), Ebbert MT(1),
Shiozawa DK(1), Whipple CJ(1), Ridge PG(1).

Author information: 
(1)Department of Biology, Brigham Young University, Provo, UT 84602, USA.

Simple Sequence Repeats (SSRs) are used to address a variety of research
questions in a variety of fields (e.g. population genetics, phylogenetics,
forensics, etc.), due to their high mutability within and between species. Here, 
we present an innovative algorithm, SA-SSR, based on suffix and longest common
prefix arrays for efficiently detecting SSRs in large sets of sequences. Existing
SSR detection applications are hampered by one or more limitations (i.e. speed,
accuracy, ease-of-use, etc.). Our algorithm addresses these challenges while
being the most comprehensive and correct SSR detection software available. SA-SSR
is 100% accurate and detected >1000 more SSRs than the second best algorithm,
while offering greater control to the user than any existing
software.AVAILABILITY AND IMPLEMENTATION: SA-SSR is freely available at
http://github.com/ridgelab/SA-SSR CONTACT: perry.ridge@byu.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw298 
PMCID: PMC5013907
PMID: 27170037  [PubMed - in process]


507. IEEE/ACM Trans Comput Biol Bioinform. 2016 May 5. [Epub ahead of print]

A Generalized Lattice based Probabilistic Approach for Metagenomic Clustering.

Jha M, Malhotra R, Acharya R.

Metagenomics involves the analysis of genomes of microorganisms sampled directly 
from their environment. Next Generation Sequencing allows a high-throughput
sampling of small segments from genomes in the metagenome to generate reads. To
study the properties and relationships of the microorganisms present, clustering 
can be performed based on the inherent composition of the sampled reads for
unknown species. We propose a two-dimensional lattice based probabilistic model
for clustering metagenomic datasets. The occurrence of a species in the
metagenome is estimated using a lattice of probabilistic distributions over small
sized genomic sequences. The two dimensions denote distributions for different
sizes and groups of words respectively. The lattice structure allows for
additional support for a node from its neighbors when the probabilistic support
for the species using the parameters of the current node is deemed insufficient. 
We also show convergence for our algorithm. We test our algorithm on simulated
metagenomic data containing bacterial species and observe more than 85%
precision. We also evaluate our algorithm on an in vitro-simulated bacterial
metagenome and on human patient data, and show a better clustering than other
algorithms even for short reads and varied abundance. The software and datasets
can be downloaded from https:// github.com/lattclus/lattice-metage.

DOI: 10.1109/TCBB.2016.2563422 
PMID: 27168602  [PubMed - as supplied by publisher]


508. Nucleic Acids Res. 2016 Jun 20;44(11):5022-33. doi: 10.1093/nar/gkw396. Epub 2016
May 10.

Phylogeny-aware identification and correction of taxonomically mislabeled
sequences.

Kozlov AM(1), Zhang J(2), Yilmaz P(3), Glöckner FO(4), Stamatakis A(5).

Author information: 
(1)The Exelixis Lab, Scientific Computing Group, Heidelberg Institute for
Theoretical Studies, Schloss-Wolfsbrunnenweg 35, 69118 Heidelberg, Germany
Alexey.Kozlov@h-its.org. (2)The Exelixis Lab, Scientific Computing Group,
Heidelberg Institute for Theoretical Studies, Schloss-Wolfsbrunnenweg 35, 69118
Heidelberg, Germany. (3)Microbial Genomics and Bioinformatics Research Group, Max
Planck Institute for Marine Microbiology, 28359 Bremen, Germany. (4)Microbial
Genomics and Bioinformatics Research Group, Max Planck Institute for Marine
Microbiology, 28359 Bremen, Germany Jacobs University Bremen gGmbH, Campus Ring
1, 28759 Bremen, Germany. (5)The Exelixis Lab, Scientific Computing Group,
Heidelberg Institute for Theoretical Studies, Schloss-Wolfsbrunnenweg 35, 69118
Heidelberg, Germany Karlsruhe Institute of Technology, Institute for Theoretical 
Informatics, Postfach 6980, 76128 Karlsruhe, Germany.

Molecular sequences in public databases are mostly annotated by the submitting
authors without further validation. This procedure can generate erroneous
taxonomic sequence labels. Mislabeled sequences are hard to identify, and they
can induce downstream errors because new sequences are typically annotated using 
existing ones. Furthermore, taxonomic mislabelings in reference sequence
databases can bias metagenetic studies which rely on the taxonomy. Despite
significant efforts to improve the quality of taxonomic annotations, the curation
rate is low because of the labor-intensive manual curation process. Here, we
present SATIVA, a phylogeny-aware method to automatically identify taxonomically 
mislabeled sequences ('mislabels') using statistical models of evolution. We use 
the Evolutionary Placement Algorithm (EPA) to detect and score sequences whose
taxonomic annotation is not supported by the underlying phylogenetic signal, and 
automatically propose a corrected taxonomic classification for those. Using
simulated data, we show that our method attains high accuracy for identification 
(96.9% sensitivity/91.7% precision) as well as correction (94.9%
sensitivity/89.9% precision) of mislabels. Furthermore, an analysis of four
widely used microbial 16S reference databases (Greengenes, LTP, RDP and SILVA)
indicates that they currently contain between 0.2% and 2.5% mislabels. Finally,
we use SATIVA to perform an in-depth evaluation of alternative taxonomies for
Cyanobacteria. SATIVA is freely available at https://github.com/amkozlov/sativa.

© The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkw396 
PMCID: PMC4914121
PMID: 27166378  [PubMed - in process]


509. Bioinformatics. 2016 Sep 1;32(17):2704-6. doi: 10.1093/bioinformatics/btw286.
Epub 2016 May 10.

SimLoRD: Simulation of Long Read Data.

Stöcker BK(1), Köster J(2), Rahmann S(1).

Author information: 
(1)Genome Informatics, Institute of Human Genetics, University of Duisburg-Essen,
Essen, 45147, Germany. (2)Life Sciences, Centrum Wiskunde & Informatica (CWI),
Amsterdam 1098 XG, The Netherlands Medical Oncology, Dana-Farber Cancer
Institute, Harvard Medical School, Boston, MA 02215, USA.

MOTIVATION: Third generation sequencing methods provide longer reads than second 
generation methods and have distinct error characteristics. While there exist
many read simulators for second generation data, there is a very limited choice
for third generation data.
RESULTS: We analyzed public data from Pacific Biosciences (PacBio) SMRT
sequencing, developed an error model and implemented it in a new read simulator
called SimLoRD. It offers options to choose the read length distribution and to
model error probabilities depending on the number of passes through the
sequencer. The new error model makes SimLoRD the most realistic SMRT read
simulator available.
AVAILABILITY AND IMPLEMENTATION: SimLoRD is available open source at
http://bitbucket.org/genomeinformatics/simlord/ and installable via Bioconda
(http://bioconda.github.io).
CONTACT: Bianca.Stoecker@uni-due.de or Sven.Rahmann@uni-due.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw286 
PMID: 27166244  [PubMed - in process]


510. Bioinformatics. 2016 Sep 1;32(17):2582-9. doi: 10.1093/bioinformatics/btw237.
Epub 2016 May 9.

Evaluation of hybrid and non-hybrid methods for de novo assembly of nanopore
reads.

Sović I(1), Križanović K(2), Skala K(1), Šikić M(3).

Author information: 
(1)Centre for Informatics and Computing, Ruđer Bošković Institute, 10000 Zagreb, 
Croatia. (2)Department of Electronic Systems and Information Processing, Faculty 
of Electrical Engineering and Computing, University of Zagreb, 10000 Zagreb,
Croatia. (3)Department of Electronic Systems and Information Processing, Faculty 
of Electrical Engineering and Computing, University of Zagreb, 10000 Zagreb,
Croatia Bioinformatics Institute, Singapore 138671, Singapore.

MOTIVATION: Recent emergence of nanopore sequencing technology set a challenge
for established assembly methods. In this work, we assessed how existing hybrid
and non-hybrid de novo assembly methods perform on long and error prone nanopore 
reads.
RESULTS: We benchmarked five non-hybrid (in terms of both error correction and
scaffolding) assembly pipelines as well as two hybrid assemblers which use third 
generation sequencing data to scaffold Illumina assemblies. Tests were performed 
on several publicly available MinION and Illumina datasets of Escherichia coli
K-12, using several sequencing coverages of nanopore data (20×, 30×, 40× and
50×). We attempted to assess the assembly quality at each of these coverages, in 
order to estimate the requirements for closed bacterial genome assembly. For the 
purpose of the benchmark, an extensible genome assembly benchmarking framework
was developed. Results show that hybrid methods are highly dependent on the
quality of NGS data, but much less on the quality and coverage of nanopore data
and perform relatively well on lower nanopore coverages. All non-hybrid methods
correctly assemble the E. coli genome when coverage is above 40×, even the
non-hybrid method tailored for Pacific Biosciences reads. While it requires
higher coverage compared to a method designed particularly for nanopore reads,
its running time is significantly lower.
AVAILABILITY AND IMPLEMENTATION: https://github.com/kkrizanovic/NanoMark
CONTACT: mile.sikic@fer.hr
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw237 
PMID: 27162186  [PubMed - in process]


511. BMC Bioinformatics. 2016 May 10;17:208. doi: 10.1186/s12859-016-1069-7.

SeqPurge: highly-sensitive adapter trimming for paired-end NGS data.

Sturm M(1), Schroeder C(2), Bauer P(2).

Author information: 
(1)Institute of Medical Genetics and Applied Genomics, University Hospital
Tübingen, Tübingen, Germany. marc.sturm@med.uni-tuebingen.de. (2)Institute of
Medical Genetics and Applied Genomics, University Hospital Tübingen, Tübingen,
Germany.

BACKGROUND: Trimming of adapter sequences from short read data is a common
preprocessing step during NGS data analysis. When performing paired-end
sequencing, the overlap between forward and reverse read can be used to identify 
excess adapter sequences. This is exploited by several previously published
adapter trimming tools. However, our evaluation on amplicon-based data shows that
most of the current tools are not able to remove all adapter sequences and that
adapter contamination may even lead to spurious variant calls.
RESULTS: Here we present SeqPurge ( https://github.com/imgag/ngs-bits ), a
highly-sensitive adapter trimmer that uses a probabilistic approach to detect the
overlap between forward and reverse reads of Illumina sequencing data. SeqPurge
can detect very short adapter sequences, even if only one base long. Compared to 
other adapter trimmers specifically designed for paired-end data, we found that
SeqPurge achieves a higher sensitivity. The number of remaining adapter bases
after trimming is reduced by up to 90 %, depending on the compared tool. In
simulations with different error rates, we found that SeqPurge is also the most
error-tolerant adapter trimmer in the comparison.
CONCLUSION: SeqPurge achieves a very high sensitivity and a high error-tolerance,
combined with a specificity and runtime that are comparable to other
state-of-the-art adapter trimmers. The very good adapter trimming performance,
complemented with additional features such as quality-based trimming and basic
quality control, makes SeqPurge an excellent choice for the pre-processing of
paired-end NGS data.

DOI: 10.1186/s12859-016-1069-7 
PMCID: PMC4862148
PMID: 27161244  [PubMed - indexed for MEDLINE]


512. J Chem Theory Comput. 2016 Jun 14;12(6):2706-19. doi: 10.1021/acs.jctc.6b00316.
Epub 2016 May 26.

A Practical Guide to Density Matrix Embedding Theory in Quantum Chemistry.

Wouters S(1), Jiménez-Hoyos CA(1), Sun Q(1), Chan GK(1).

Author information: 
(1)Department of Chemistry, Frick Chemistry Laboratory, Princeton University ,
Princeton, New Jersey 08544, United States.

Density matrix embedding theory (DMET) (Knizia, G.; Chan, G. K.-L. Phys. Rev.
Lett. 2012, 109, 186404) provides a theoretical framework to treat finite
fragments in the presence of a surrounding molecular or bulk environment, even
when there is significant correlation or entanglement between the two. In this
work, we give a practically oriented and explicit description of the numerical
and theoretical formulation of DMET. We also describe in detail how to perform
self-consistent DMET optimizations. We explore different embedding strategies
with and without a self-consistency condition in hydrogen rings, beryllium rings,
and a sample SN2 reaction. The source code for the calculations in this work can 
be obtained from https://github.com/sebwouters/qc-dmet .

DOI: 10.1021/acs.jctc.6b00316 
PMID: 27159268  [PubMed - in process]


513. F1000Res. 2016 Apr 13;5:674. doi: 10.12688/f1000research.8288.1. eCollection
2016.

MetaNetVar: Pipeline for applying network analysis tools for genomic variants
analysis.

Moyer E(1), Hagenauer M(2), Lesko M(3), Francis F(4), Rodriguez O(5), Nagarajan
V(6), Huser V(7), Busby B(3).

Author information: 
(1)National Center for Biotechnology Information, Bethesda, USA. (2)Molecular,
Behavioral Neuroscience Institute, University of Michigan, Ann Arbor, USA.
(3)National Center for Biotechnology Information, National Library of Medicine,
Bethesda, USA. (4)Bioinformatics and Systems Biology program, University of
Delaware, Newark, USA. (5)Department of Genetics and Genomic Sciences, Icahn
School of Medicine at Mount Sinai, New York, USA. (6)Bioinformatics and
Computational Biosciences Branch, National Institute of Allergy and Infectious
Diseases, National Institute of Mental Health, Bethesda, USA. (7)Lister Hill
National Center for Biomedical Communications, National Library of Medicine,
National Institute of Mental Health, Bethesda, USA.

Network analysis can make variant analysis better. There are existing tools like 
HotNet2 and dmGWAS that can provide various analytical methods. We developed a
prototype of a pipeline called MetaNetVar that allows execution of multiple
tools. The code is published at https://github.com/NCBI-Hackathons/Network_SNPs. 
A working prototype is published as an Amazon Machine Image - ami-4510312f .

DOI: 10.12688/f1000research.8288.1 
PMCID: PMC4857755
PMID: 27158457  [PubMed]


514. BMC Bioinformatics. 2016 May 6;17(1):203. doi: 10.1186/s12859-016-1067-9.

Parallel computation of genome-scale RNA secondary structure to detect structural
constraints on human genome.

Kawaguchi R(1), Kiryu H(2).

Author information: 
(1)Department of Computational Biology and Medical Sciences, Graduate School of
Frontier Sciences, University of Tokyo, 5-1-5 Kashiwanoha, Kashiwa, Chiba,
277-8561, Japan. kawaguchi-rs@cb.k.u-tokyo.ac.jp. (2)Department of Computational 
Biology and Medical Sciences, Graduate School of Frontier Sciences, University of
Tokyo, 5-1-5 Kashiwanoha, Kashiwa, Chiba, 277-8561, Japan.

BACKGROUND: RNA secondary structure around splice sites is known to assist normal
splicing by promoting spliceosome recognition. However, analyzing the structural 
properties of entire intronic regions or pre-mRNA sequences has been difficult
hitherto, owing to serious experimental and computational limitations, such as
low read coverage and numerical problems.
RESULTS: Our novel software, "ParasoR", is designed to run on a computer cluster 
and enables the exact computation of various structural features of long RNA
sequences under the constraint of maximal base-pairing distance. ParasoR divides 
dynamic programming (DP) matrices into smaller pieces, such that each piece can
be computed by a separate computer node without losing the connectivity
information between the pieces. ParasoR directly computes the ratios of DP
variables to avoid the reduction of numerical precision caused by the
cancellation of a large number of Boltzmann factors. The structural preferences
of mRNAs computed by ParasoR shows a high concordance with those determined by
high-throughput sequencing analyses. Using ParasoR, we investigated the global
structural preferences of transcribed regions in the human genome. A genome-wide 
folding simulation indicated that transcribed regions are significantly more
structural than intergenic regions after removing repeat sequences and k-mer
frequency bias. In particular, we observed a highly significant preference for
base pairing over entire intronic regions as compared to their antisense
sequences, as well as to intergenic regions. A comparison between pre-mRNAs and
mRNAs showed that coding regions become more accessible after splicing,
indicating constraints for translational efficiency. Such changes are correlated 
with gene expression levels, as well as GC content, and are enriched among genes 
associated with cytoskeleton and kinase functions.
CONCLUSIONS: We have shown that ParasoR is very useful for analyzing the
structural properties of long RNA sequences such as mRNAs, pre-mRNAs, and long
non-coding RNAs whose lengths can be more than a million bases in the human
genome. In our analyses, transcribed regions including introns are indicated to
be subject to various types of structural constraints that cannot be explained
from simple sequence composition biases. ParasoR is freely available at
https://github.com/carushi/ParasoR .

DOI: 10.1186/s12859-016-1067-9 
PMCID: PMC4858847
PMID: 27153986  [PubMed - in process]


515. Bioinformatics. 2016 May 1;32(9):1423-6. doi: 10.1093/bioinformatics/btw079. Epub
2016 Feb 15.

RVTESTS: an efficient and comprehensive tool for rare variant association
analysis using sequence data.

Zhan X(1), Hu Y(2), Li B(3), Abecasis GR(4), Liu DJ(5).

Author information: 
(1)Department of Clinical Science, Quantitative Biomedical Research Center,
Center for the Genetics of Host Defense, University of Texas Southwestern Medical
Center, Dallas, TX 75390, USA. (2)A9.Com Inc, Palo Alto, CA 94301, USA.
(3)Department of Molecular Physiology and Biophysics, Vanderbilt University,
Nashville, TN 37240, USA. (4)Center of Statistical Genetics, Department of
Biostatistics, University of Michigan, Ann Arbor, MI 48109, USA. (5)Division of
Biostatistics and Bioinformatics, Department of Public Health Sciences, Penn
State College of Medicine, Hershey, PA 17033, USA and Institute for Personalized 
Medicine, Penn State College of Medicine, Hershey, PA 17033, USA.

MOTIVATION: Next-generation sequencing technologies have enabled the large-scale 
assessment of the impact of rare and low-frequency genetic variants for complex
human diseases. Gene-level association tests are often performed to analyze rare 
variants, where multiple rare variants in a gene region are analyzed jointly.
Applying gene-level association tests to analyze sequence data often requires
integrating multiple heterogeneous sources of information (e.g. annotations,
functional prediction scores, allele frequencies, genotypes and phenotypes) to
determine the optimal analysis unit and prioritize causal variants. Given the
complexity and scale of current sequence datasets and bioinformatics databases,
there is a compelling need for more efficient software tools to facilitate these 
analyses. To answer this challenge, we developed RVTESTS, which implements a
broad set of rare variant association statistics and supports the analysis of
autosomal and X-linked variants for both unrelated and related individuals.
RVTESTS also provides useful companion features for annotating sequence variants,
integrating bioinformatics databases, performing data quality control and sample 
selection. We illustrate the advantages of RVTESTS in functionality and
efficiency using the 1000 Genomes Project data.
AVAILABILITY AND IMPLEMENTATION: RVTESTS is available on Linux, MacOS and
Windows. Source code and executable files can be obtained at
https://github.com/zhanxw/rvtests
CONTACT: zhanxw@gmail.com; goncalo@umich.edu; dajiang.liu@outlook.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw079 
PMCID: PMC4848408
PMID: 27153000  [PubMed - in process]


516. Bioinformatics. 2016 Aug 1;32(15):2382-3. doi: 10.1093/bioinformatics/btw134.
Epub 2016 Mar 9.

GSP: a web-based platform for designing genome-specific primers in polyploids.

Wang Y(1), Tiwari VK(2), Rawat N(2), Gill BS(2), Huo N(3), You FM(4),
Coleman-Derr D(5), Gu YQ(3).

Author information: 
(1)USDA-ARS, Western Regional Research Center, Crop Improvement and Genetics
Research Unit, Albany, CA 94710, USA USDA-ARS, Plant Gene Expression Center,
Albany, CA 94710, USA. (2)Wheat Genetic Resource Center, Department of Plant
Pathology, Kansas State University, Manhattan, KS 66506, USA. (3)USDA-ARS,
Western Regional Research Center, Crop Improvement and Genetics Research Unit,
Albany, CA 94710, USA. (4)Cereal Research Centre, Agriculture and Agri-Food
Canada, Morden, MB R6M 1Y5, Canada. (5)USDA-ARS, Plant Gene Expression Center,
Albany, CA 94710, USA.

MOTIVATION: The sequences among subgenomes in a polyploid species have high
similarity, making it difficult to design genome-specific primers for sequence
analysis.
RESULTS: We present GSP, a web-based platform to design genome-specific primers
that distinguish subgenome sequences in a polyploid genome. GSP uses BLAST to
extract homeologous sequences of the subgenomes in existing databases, performs a
multiple sequence alignment, and design primers based on sequence variants in the
alignment. An interactive primers diagram, a sequence alignment viewer and a
virtual electrophoresis are displayed as parts of the primer design result. GSP
also designs specific primers from multiple sequences uploaded by users.
AVAILABILITY AND IMPLEMENTATION: GSP is a user-friendly and efficient web
platform freely accessible at http://probes.pw.usda.gov/GSP Source code and
command-line application are available at https://github.com/bioinfogenome/GSP
CONTACTS: yong.gu@ars.usda.gov or devin.coleman-derr@ars.usda.gov
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw134 
PMID: 27153733  [PubMed - in process]


517. Bioinformatics. 2016 Jun 1;32(11):1652-61. doi: 10.1093/bioinformatics/btw050.
Epub 2016 Mar 2.

Efficient privacy-preserving string search and an application in genomics.

Shimizu K(1), Nuida K(2), Rätsch G(3).

Author information: 
(1)Biotechnology Research Institute for Drug Discovery, National Institute of
Advanced Industrial Science and Technology, Tokyo 135-0064, Japan, Computational 
Biology, Memorial Sloan Kettering Cancer Center, New York, NY 1275 York, USA.
(2)Information Technology Research Institute, National Institute of Advanced
Industrial Science and Technology, Tokyo 135-0064, Japan and Japan Science and
Technology Agency (JST) PRESTO Researcher, Tokyo, Japan. (3)Computational
Biology, Memorial Sloan Kettering Cancer Center, New York, NY 1275 York, USA.

MOTIVATION: Personal genomes carry inherent privacy risks and protecting privacy 
poses major social and technological challenges. We consider the case where a
user searches for genetic information (e.g. an allele) on a server that stores a 
large genomic database and aims to receive allele-associated information. The
user would like to keep the query and result private and the server the database.
APPROACH: We propose a novel approach that combines efficient string data
structures such as the Burrows-Wheeler transform with cryptographic techniques
based on additive homomorphic encryption. We assume that the sequence data is
searchable in efficient iterative query operations over a large indexed
dictionary, for instance, from large genome collections and employing the
(positional) Burrows-Wheeler transform. We use a technique called oblivious
transfer that is based on additive homomorphic encryption to conceal the sequence
query and the genomic region of interest in positional queries.
RESULTS: We designed and implemented an efficient algorithm for searching
sequences of SNPs in large genome databases. During search, the user can only
identify the longest match while the server does not learn which sequence of SNPs
the user queried. In an experiment based on 2184 aligned haploid genomes from the
1000 Genomes Project, our algorithm was able to perform typical queries within
[Formula: see text] 4.6 s and [Formula: see text] 10.8 s for client and server
side, respectively, on laptop computers. The presented algorithm is at least one 
order of magnitude faster than an exhaustive baseline algorithm.
AVAILABILITY AND IMPLEMENTATION: https://github.com/iskana/PBWT-sec and
https://github.com/ratschlab/PBWT-sec
CONTACTS: shimizu-kana@aist.go.jp or Gunnar.Ratsch@ratschlab.org
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw050 
PMCID: PMC4892414
PMID: 27153731  [PubMed - in process]


518. Bioinformatics. 2016 Aug 1;32(15):2306-12. doi: 10.1093/bioinformatics/btw097.
Epub 2016 Mar 9.

Rapid genotype refinement for whole-genome sequencing data using multi-variate
normal distributions.

Arthur R(1), O'Connell J(1), Schulz-Trieglaff O(1), Cox AJ(1).

Author information: 
(1)Illumina Cambridge Ltd, Chesterford Research Park, Little Chesterford, Essex
CB10 1XL, UK.

MOTIVATION: Whole-genome low-coverage sequencing has been combined with
linkage-disequilibrium (LD)-based genotype refinement to accurately and
cost-effectively infer genotypes in large cohorts of individuals. Most genotype
refinement methods are based on hidden Markov models, which are accurate but
computationally expensive. We introduce an algorithm that models LD using a
simple multivariate Gaussian distribution. The key feature of our algorithm is
its speed.
RESULTS: Our method is hundreds of times faster than other methods on the same
data set and its scaling behaviour is linear in the number of samples. We
demonstrate the performance of the method on both low- and high-coverage samples.
AVAILABILITY AND IMPLEMENTATION: The source code is available at
https://github.com/illumina/marvin
CONTACT: rarthur@illumina.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw097 
PMID: 27153730  [PubMed - in process]


519. Bioinformatics. 2016 Jul 1;32(13):2029-31. doi: 10.1093/bioinformatics/btw111.
Epub 2016 Feb 26.

VariantBam: filtering and profiling of next-generational sequencing data using
region-specific rules.

Wala J(1), Zhang CZ(2), Meyerson M(3), Beroukhim R(3).

Author information: 
(1)The Broad Institute of Harvard and MIT, Cambridge, MA 02142, USA
Bioinformatics and Integrative Genomics, Harvard University, Cambridge, MA 02138,
USA Department of Cancer Biology, Dana-Farber Cancer Institute, Boston, MA 02115,
USA. (2)The Broad Institute of Harvard and MIT, Cambridge, MA 02142, USA. (3)The 
Broad Institute of Harvard and MIT, Cambridge, MA 02142, USA Department of Cancer
Biology, Dana-Farber Cancer Institute, Boston, MA 02115, USA.

We developed VariantBam, a C ++ read filtering and profiling tool for use with
BAM, CRAM and SAM sequencing files. VariantBam provides a flexible framework for 
extracting sequencing reads or read-pairs that satisfy combinations of rules,
defined by any number of genomic intervals or variant sites. We have implemented 
filters based on alignment data, sequence motifs, regional coverage and base
quality. For example, VariantBam achieved a median size reduction ratio of 3.1:1 
when applied to 10 lung cancer whole genome BAMs by removing large tags and
selecting for only high-quality variant-supporting reads and reads matching a
large dictionary of sequence motifs. Thus VariantBam enables efficient storage of
sequencing data while preserving the most relevant information for downstream
analysis.AVAILABILITY AND IMPLEMENTATION: VariantBam and full documentation are
available at github.com/jwalabroad/VariantBam
CONTACT: rameen@broadinstitute.org
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw111 
PMCID: PMC4920121 [Available on 2017-07-01]
PMID: 27153727  [PubMed - in process]


520. Bioinformatics. 2016 Aug 1;32(15):2396-8. doi: 10.1093/bioinformatics/btw120.
Epub 2016 Mar 2.

AlgoRun: a Docker-based packaging system for platform-agnostic implemented
algorithms.

Hosny A(1), Vera-Licona P(2), Laubenbacher R(3), Favre T(4).

Author information: 
(1)Center for Quantitative Medicine. (2)Center for Quantitative Medicine
Department of Cell Biology Institute for Systems Genomics, UConn Health, CT, USA.
(3)Center for Quantitative Medicine Department of Cell Biology Institute for
Systems Genomics, UConn Health, CT, USA Jackson Laboratory for Genomic Medicine, 
CT, USA. (4)Democratech, Paris, France.

MOTIVATION: There is a growing need in bioinformatics for easy-to-use software
implementations of algorithms that are usable across platforms. At the same time,
reproducibility of computational results is critical and often a challenge due to
source code changes over time and dependencies.
RESULTS: The approach introduced in this paper addresses both of these needs with
AlgoRun, a dedicated packaging system for implemented algorithms, using Docker
technology. Implemented algorithms, packaged with AlgoRun, can be executed
through a user-friendly interface directly from a web browser or via a
standardized RESTful web API to allow easy integration into more complex
workflows. The packaged algorithm includes the entire software execution
environment, thereby eliminating the common problem of software dependencies and 
the irreproducibility of computations over time. AlgoRun-packaged algorithms can 
be published on http://algorun.org, a centralized searchable directory to find
existing AlgoRun-packaged algorithms.
AVAILABILITY AND IMPLEMENTATION: AlgoRun is available at http://algorun.org and
the source code under GPL license is available at https://github.com/algorun
CONTACT: laubenbacher@uchc.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw120 
PMID: 27153722  [PubMed - in process]


521. Bioinformatics. 2016 Jul 1;32(13):2044-6. doi: 10.1093/bioinformatics/btw113.
Epub 2016 Feb 26.

FRED 2: an immunoinformatics framework for Python.

Schubert B(1), Walzer M(1), Brachvogel HP(2), Szolek A(1), Mohr C(1), Kohlbacher 
O(3).

Author information: 
(1)Center for Bioinformatics, University of Tübingen, Tübingen 72076, Germany
Department of Computer Science, Applied Bioinformatics, Tübingen 72076, Germany. 
(2)Center for Bioinformatics, University of Tübingen, Tübingen 72076, Germany.
(3)Center for Bioinformatics, University of Tübingen, Tübingen 72076, Germany
Department of Computer Science, Applied Bioinformatics, Tübingen 72076, Germany
Quantitative Biology Center, Tübingen 72076, Germany Faculty of Medicine,
University of Tübingen, Tübingen 72076, Germany Max Planck Institute for
Developmental Biology, Biomolecular Interactions, Tübingen 72076, Germany.

Immunoinformatics approaches are widely used in a variety of applications from
basic immunological to applied biomedical research. Complex data integration is
inevitable in immunological research and usually requires comprehensive pipelines
including multiple tools and data sources. Non-standard input and output formats 
of immunoinformatics tools make the development of such applications difficult.
Here we present FRED 2, an open-source immunoinformatics framework offering easy 
and unified access to methods for epitope prediction and other immunoinformatics 
applications. FRED 2 is implemented in Python and designed to be extendable and
flexible to allow rapid prototyping of complex applications.AVAILABILITY AND
IMPLEMENTATION: FRED 2 is available at http://fred-2.github.io
CONTACT: schubert@informatik.uni-tuebingen.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw113 
PMCID: PMC4920123
PMID: 27153717  [PubMed - in process]


522. Bioinformatics. 2016 Aug 1;32(15):2380-1. doi: 10.1093/bioinformatics/btw126.
Epub 2016 Mar 26.

NSimScan: DNA comparison tool with increased speed, sensitivity and accuracy.

Novichkov V(1), Kaznadzey A(2), Alexandrova N(3), Kaznadzey D(4).

Author information: 
(1)Independent Researcher, Bridgewater, NJ, USA. (2)Institute for Information
Transmission Problems, RAS, Moscow, Russia. (3)Genome Designs, Inc, Walnut Creek,
CA, USA. (4)Thermo-Fisher, South San Francisco, CA, USA.

Nucleotide Similarity Scanner (NSimScan) is specialized for searching massive DNA
databases for distant similarities. Its targeted applications include
phylogenomics, comparative and functional studies of non-coding sequences,
contamination detection, etc. NSimScan outperforms industry standard tools in
combined sensitivity, accuracy and speed, operating at sensitivity similar to
BLAST, accuracy of ssearch and speed of MegaBLAST.AVAILABILITY AND
IMPLEMENTATION: NSimScan is available at https://github.com/abadona/qsimscan as a
part of QSimScan package. It is implemented in C ++, distributed under MIT
license and supported on Linux, OS X and Windows (with cygwin).
CONTACT: dkaznadzey@yahoo.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw126 
PMID: 27153714  [PubMed - in process]


523. Bioinformatics. 2016 Jul 15;32(14):2143-50. doi: 10.1093/bioinformatics/btw154.
Epub 2016 Mar 19.

Detecting critical state before phase transition of complex biological systems by
hidden Markov model.

Chen P(1), Liu R(2), Li Y(1), Chen L(3).

Author information: 
(1)School of Computer Science and Engineering. (2)School of Mathematics, South
China University of Technology, Guangzhou 510640, China. (3)Key Laboratory of
Systems Biology, Innovation Center for Cell Signaling Network, Institute of
Biochemistry and Cell Biology, Shanghai Institutes for Biological Sciences,
Chinese Academy of Sciences, Shanghai 200031, China Collaborative Research Center
for Innovative Mathematical Modelling, Institute of Industrial Science,
University of Tokyo, Tokyo 153-8505, Japan.

MOTIVATION: Identifying the critical state or pre-transition state just before
the occurrence of a phase transition is a challenging task, because the state of 
the system may show little apparent change before this critical transition during
the gradual parameter variations. Such dynamics of phase transition is generally 
composed of three stages, i.e. before-transition state, pre-transition state and 
after-transition state, which can be considered as three different Markov
processes.
RESULTS: By exploring the rich dynamical information provided by high-throughput 
data, we present a novel computational method, i.e. hidden Markov model (HMM)
based approach, to detect the switching point of the two Markov processes from
the before-transition state (a stationary Markov process) to the pre-transition
state (a time-varying Markov process), thereby identifying the pre-transition
state or early-warning signals of the phase transition. To validate the
effectiveness, we apply this method to detect the signals of the imminent phase
transitions of complex systems based on the simulated datasets, and further
identify the pre-transition states as well as their critical modules for three
real datasets, i.e. the acute lung injury triggered by phosgene inhalation, MCF-7
human breast cancer caused by heregulin and HCV-induced dysplasia and
hepatocellular carcinoma. Both functional and pathway enrichment analyses
validate the computational results.
AVAILABILITY AND IMPLEMENTATION: The source code and some supporting files are
available at https://github.com/rabbitpei/HMM_based-method
CONTACTS: lnchen@sibs.ac.cn or liyj@scut.edu.cn
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw154 
PMID: 27153710  [PubMed - in process]


524. Bioinformatics. 2016 Jul 1;32(13):2038-40. doi: 10.1093/bioinformatics/btw099.
Epub 2016 Feb 19.

A web application for sample size and power calculation in case-control
microbiome studies.

Mattiello F(1), Verbist B(2), Faust K(3), Raes J(3), Shannon WD(4), Bijnens L(2),
Thas O(5).

Author information: 
(1)Department of Mathematical Modelling, Statistics and Bioinformatics, Ghent
University, Coupure Links 653, Gent, 9000. (2)Janssen Pharmaceutica,
Turnhoutseweg 30, Beerse, 2340, Belgium. (3)KU Leuven, Laboratory of Molecular
Bacteriology and Department of Microbiology and Immunology, Herestraat 49,
Leuven, 3000, Belgium. (4)BioRankings, 4041 Forest Park Ave, St.Louis, MO 63108, 
USA. (5)Department of Mathematical Modelling, Statistics and Bioinformatics,
Ghent University, Coupure Links 653, Gent, 9000 University of Wollongong,
National Institute for Applied Statistics Research Australia (NIASRA), School of 
Mathematics and Applied Statistics, Australia.

: When designing a case-control study to investigate differences in microbial
composition, it is fundamental to assess the sample sizes needed to detect an
hypothesized difference with sufficient statistical power. Our application
includes power calculation for (i) a recoded version of the two-sample
generalized Wald test of the 'HMP' R-package for comparing community composition,
and (ii) the Wilcoxon-Mann-Whitney test for comparing operational taxonomic
unit-specific abundances between two samples (optional). The simulation-based
power calculations make use of the Dirichlet-Multinomial model to describe and
generate abundances. The web interface allows for easy specification of sample
and effect sizes. As an illustration of our application, we compared the
statistical power of the two tests, with and without stratification of samples.
We observed that statistical power increases considerably when stratification is 
employed, meaning that less samples are needed to detect the same effect size
with the same power.AVAILABILITY AND IMPLEMENTATION: The web interface is written
in R code using Shiny (RStudio Inc., 2016) and it is available at
https://fedematt.shinyapps.io/shinyMB The R code for the recoded generalized Wald
test can be found at https://github.com/mafed/msWaldHMP CONTACT:
Federico.Mattiello@UGent.be.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw099 
PMID: 27153704  [PubMed - in process]


525. Bioinformatics. 2016 Jun 15;32(12):1883-4. doi: 10.1093/bioinformatics/btw088.
Epub 2016 Feb 18.

fqtools: an efficient software suite for modern FASTQ file manipulation.

Droop AP(1).

Author information: 
(1)MRC Medical Bioinformatics Centre, University of Leeds, Clarendon Way, Leeds, 
LS2 9NL, UK.

Many Next Generation Sequencing analyses involve the basic manipulation of input 
sequence data before downstream processing (e.g. searching for specific
sequences, format conversion or basic file statistics). The rapidly increasing
data volumes involved in NGS make any dataset manipulation a time-consuming and
error-prone process. I have developed fqtools; a fast and reliable FASTQ file
manipulation suite that can process the full set of valid FASTQ files, including 
those with multi-line sequences, whilst identifying invalid files. Fqtools is
faster than similar tools, and is designed for use in automatic processing
pipelines.AVAILABILITY AND IMPLEMENTATION: fqtools is open source and is
available at: https://github.com/alastair-droop/fqtools
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.
CONTACT: a.p.droop@leeds.ac.uk.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw088 
PMCID: PMC4908325
PMID: 27153699  [PubMed - in process]


526. Bioinformatics. 2016 Jul 1;32(13):2062-4. doi: 10.1093/bioinformatics/btw071.
Epub 2016 Feb 28.

SASpy: a PyMOL plugin for manipulation and refinement of hybrid models against
small angle X-ray scattering data.

Panjkovich A(1), Svergun DI(1).

Author information: 
(1)European Molecular Biology Laboratory, Hamburg Outstation, EMBL C/O DESY,
Hamburg 22607, Germany.

Complex formation and conformational transitions of biological macromolecules in 
solution can be effectively studied using the information about overall shape and
size provided by small angle X-ray scattering (SAXS). Hybrid modeling is often
applied to integrate high-resolution models into SAXS data analysis. To
facilitate this task, we present SASpy, a PyMOL plugin that provides an
easy-to-use graphical interface for SAXS-based hybrid modeling. Through a few
mouse clicks in SASpy, low-resolution models can be superimposed to
high-resolution structures, theoretical scattering profiles and fits can be
calculated and displayed on-the-fly. Mouse-based manual rearrangements of
complexes are conveniently applied to rapidly check and interactively refine
tentative models. Interfaces to automated rigid-body and flexible refinement of
macromolecular models against the experimental SAXS data are
provided.AVAILABILITY AND IMPLEMENTATION: SASpy is available as open source at:
github.com/emblsaxs/saspy/. Working installations of both PyMOL (www.pymol.org)
and ATSAS (www.embl-hamburg.de/biosaxs/download.html) are required.
CONTACT: apanjkovich@embl-hamburg.de or svergun@embl-hamburg.de.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw071 
PMCID: PMC4920112
PMID: 27153695  [PubMed - in process]


527. Bioinformatics. 2016 Jul 1;32(13):2065-6. doi: 10.1093/bioinformatics/btw096.
Epub 2016 Feb 22.

Reaction Decoder Tool (RDT): extracting features from chemical reactions.

Rahman SA(1), Torrance G(2), Baldacci L(3), Martínez Cuesta S(4), Fenninger F(5),
Gopal N(2), Choudhary S(2), May JW(6), Holliday GL(7), Steinbeck C(2), Thornton
JM(2).

Author information: 
(1)European Molecular Biology Laboratory, European Bioinformatics Institute
EMBL-EBI, Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SD, UK Congenica
Ltd, Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SA, UK. (2)European
Molecular Biology Laboratory, European Bioinformatics Institute EMBL-EBI,
Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SD, UK. (3)European
Molecular Biology Laboratory, European Bioinformatics Institute EMBL-EBI,
Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SD, UK DISI, University of
Bologna, V.Le Risorgimento 2, Bologna, Italy. (4)European Molecular Biology
Laboratory, European Bioinformatics Institute EMBL-EBI, Wellcome Trust Genome
Campus, Hinxton, Cambridge CB10 1SD, UK Cancer Research UK Cambridge Institute,
University of Cambridge, Li Ka Shing Centre, Robinson Way, Cambridge CB2 0RE, UK.
(5)European Molecular Biology Laboratory, European Bioinformatics Institute
EMBL-EBI, Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SD, UK Michael
Smith Laboratories, the University of British Columbia, Vancouver, British
Columbia V6T 1Z4, Canada. (6)European Molecular Biology Laboratory, European
Bioinformatics Institute EMBL-EBI, Wellcome Trust Genome Campus, Hinxton,
Cambridge CB10 1SD, UK Innovation Centre (Unit 23), Cambridge Science Park,
NextMove Software Ltd, Cambridge CB4 0EY, UK. (7)European Molecular Biology
Laboratory, European Bioinformatics Institute EMBL-EBI, Wellcome Trust Genome
Campus, Hinxton, Cambridge CB10 1SD, UK Bioengineering, UCSF School of Pharmacy, 
San Francisco, CA 94158, USA.

Extracting chemical features like Atom-Atom Mapping (AAM), Bond Changes (BCs) and
Reaction Centres from biochemical reactions helps us understand the chemical
composition of enzymatic reactions. Reaction Decoder is a robust command line
tool, which performs this task with high accuracy. It supports standard chemical 
input/output exchange formats i.e. RXN/SMILES, computes AAM, highlights BCs and
creates images of the mapped reaction. This aids in the analysis of metabolic
pathways and the ability to perform comparative studies of chemical reactions
based on these features.AVAILABILITY AND IMPLEMENTATION: This software is
implemented in Java, supported on Windows, Linux and Mac OSX, and freely
available at https://github.com/asad/ReactionDecoder
CONTACT: : asad@ebi.ac.uk or s9asad@gmail.com.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw096 
PMCID: PMC4920114
PMID: 27153692  [PubMed - in process]


528. Bioinformatics. 2016 Jul 15;32(14):2239-41. doi: 10.1093/bioinformatics/btw123.
Epub 2016 Mar 18.

SharpViSu: integrated analysis and segmentation of super-resolution microscopy
data.

Andronov L(1), Lutz Y(1), Vonesch JL(1), Klaholz BP(1).

Author information: 
(1)Centre for Integrative Biology (CBI), Department of Integrated Structural
Biology, IGBMC (Institute of Genetics and of Molecular and Cellular Biology),
Illkirch, France Centre National de la Recherche Scientifique (CNRS) UMR 7104,
Illkirch, France Institut National de la Santé et de la Recherche Médicale
(INSERM) U964, Illkirch, France Université de Strasbourg, Strasbourg, France.

We introduce SharpViSu, an interactive open-source software with a graphical user
interface, which allows performing processing steps for localization data in an
integrated manner. This includes common features and new tools such as correction
of chromatic aberrations, drift correction based on iterative cross-correlation
calculations, selection of localization events, reconstruction of 2D and 3D
datasets in different representations, estimation of resolution by Fourier ring
correlation, clustering analysis based on Voronoi diagrams and Ripley's
functions. SharpViSu is optimized to work with eventlist tables exported from
most popular localization software. We show applications of these on single and
double-labelled super-resolution data.AVAILABILITY AND IMPLEMENTATION: SharpViSu 
is available as open source code and as compiled stand-alone application under
https://github.com/andronovl/SharpViSu
CONTACT: klaholz@igbmc.fr
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw123 
PMCID: PMC4937188
PMID: 27153691  [PubMed - in process]


529. Bioinformatics. 2016 Jul 1;32(13):1981-9. doi: 10.1093/bioinformatics/btw052.
Epub 2016 Feb 19.

metaCCA: summary statistics-based multivariate meta-analysis of genome-wide
association studies using canonical correlation analysis.

Cichonska A(1), Rousu J(2), Marttinen P(2), Kangas AJ(3), Soininen P(4),
Lehtimäki T(5), Raitakari OT(6), Järvelin MR(7), Salomaa V(8), Ala-Korpela M(9), 
Ripatti S(10), Pirinen M(11).

Author information: 
(1)Institute for Molecular Medicine Finland FIMM, University of Helsinki,
Helsinki, Finland, Helsinki Institute for Information Technology HIIT, Department
of Computer Science, Aalto University, Espoo, Finland. (2)Helsinki Institute for 
Information Technology HIIT, Department of Computer Science, Aalto University,
Espoo, Finland. (3)Computational Medicine, University of Oulu, Oulu University
Hospital and Biocenter Oulu, Oulu, Finland. (4)Computational Medicine, University
of Oulu, Oulu University Hospital and Biocenter Oulu, Oulu, Finland, NMR
Metabolomics Laboratory, School of Pharmacy, University of Eastern Finland,
Kuopio, Finland. (5)Department of Clinical Chemistry, Fimlab Laboratories,
University of Tampere School of Medicine, Tampere, Finland. (6)Department of
Clinical Physiology and Nuclear Medicine, University of Turku and Turku
University Hospital, Turku, Finland, Research Centre of Applied and Preventive
Cardiovascular Medicine, University of Turku and Department of Clinical
Physiology and Nuclear Medicine, Turku University Hospital, Turku, Finland.
(7)Department of Epidemiology and Biostatistics, MRC-PHE Centre for Environment &
Health, School of Public Health, Imperial College London, London, UK, Centre for 
Life Course Epidemiology, Faculty of Medicine, University of Oulu, Oulu, Finland,
Biocenter Oulu, University of Oulu, Oulu, Finland, Unit of Primary Care, Oulu
University Hospital, Oulu, Finland. (8)National Institute for Health and Welfare,
Helsinki, Finland. (9)Computational Medicine, University of Oulu, Oulu University
Hospital and Biocenter Oulu, Oulu, Finland, NMR Metabolomics Laboratory, School
of Pharmacy, University of Eastern Finland, Kuopio, Finland, Computational
Medicine, School of Social and Community Medicine and the Medical Research
Council Integrative Epidemiology Unit, University of Bristol, Bristol, UK.
(10)Institute for Molecular Medicine Finland FIMM, University of Helsinki,
Helsinki, Finland, Public Health, University of Helsinki, Helsinki, Finland and
Wellcome Trust Sanger Institute, Wellcome Trust Genome Campus, Hinxton, UK.
(11)Institute for Molecular Medicine Finland FIMM, University of Helsinki,
Helsinki, Finland.

MOTIVATION: A dominant approach to genetic association studies is to perform
univariate tests between genotype-phenotype pairs. However, analyzing related
traits together increases statistical power, and certain complex associations
become detectable only when several variants are tested jointly. Currently,
modest sample sizes of individual cohorts, and restricted availability of
individual-level genotype-phenotype data across the cohorts limit conducting
multivariate tests.
RESULTS: We introduce metaCCA, a computational framework for summary
statistics-based analysis of a single or multiple studies that allows
multivariate representation of both genotype and phenotype. It extends the
statistical technique of canonical correlation analysis to the setting where
original individual-level records are not available, and employs a covariance
shrinkage algorithm to achieve robustness.Multivariate meta-analysis of two
Finnish studies of nuclear magnetic resonance metabolomics by metaCCA, using
standard univariate output from the program SNPTEST, shows an excellent agreement
with the pooled individual-level analysis of original data. Motivated by strong
multivariate signals in the lipid genes tested, we envision that multivariate
association testing using metaCCA has a great potential to provide novel insights
from already published summary statistics from high-throughput phenotyping
technologies.
AVAILABILITY AND IMPLEMENTATION: Code is available at
https://github.com/aalto-ics-kepaco
CONTACTS: anna.cichonska@helsinki.fi or matti.pirinen@helsinki.fi
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw052 
PMCID: PMC4920109
PMID: 27153689  [PubMed - in process]


530. Bioinformatics. 2016 Jul 15;32(14):2176-83. doi: 10.1093/bioinformatics/btw155.
Epub 2016 Mar 21.

MOLGENIS/connect: a system for semi-automatic integration of heterogeneous
phenotype data with applications in biobanks.

Pang C(1), van Enckevort D(2), de Haan M(2), Kelpin F(2), Jetten J(2), Hendriksen
D(2), de Boer T(2), Charbon B(2), Winder E(2), van der Velde KJ(2), Doiron D(3), 
Fortier I(3), Hillege H(4), Swertz MA(1).

Author information: 
(1)Department of Genetics, University Medical Center Groningen, Genomics
Coordination Center, University of Groningen, Groningen, The Netherlands
Department of Epidemiology, University Medical Center Groningen, University of
Groningen, Groningen, The Netherlands. (2)Department of Genetics, University
Medical Center Groningen, Genomics Coordination Center, University of Groningen, 
Groningen, The Netherlands. (3)Research Institute of the McGill University Health
Centre and Department of Medicine, McGill University, Montreal, Canada.
(4)Department of Epidemiology, University Medical Center Groningen, University of
Groningen, Groningen, The Netherlands.

MOTIVATION: While the size and number of biobanks, patient registries and other
data collections are increasing, biomedical researchers still often need to pool 
data for statistical power, a task that requires time-intensive retrospective
integration.
RESULTS: To address this challenge, we developed MOLGENIS/connect, a
semi-automatic system to find, match and pool data from different sources. The
system shortlists relevant source attributes from thousands of candidates using
ontology-based query expansion to overcome variations in terminology. Then it
generates algorithms that transform source attributes to a common target
DataSchema. These include unit conversion, categorical value matching and complex
conversion patterns (e.g. calculation of BMI). In comparison to human-experts,
MOLGENIS/connect was able to auto-generate 27% of the algorithms perfectly, with 
an additional 46% needing only minor editing, representing a reduction in the
human effort and expertise needed to pool data.
AVAILABILITY AND IMPLEMENTATION: Source code, binaries and documentation are
available as open-source under LGPLv3 from http://github.com/molgenis/molgenis
and www.molgenis.org/connect
CONTACT: : m.a.swertz@rug.nl
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw155 
PMCID: PMC4937195
PMID: 27153686  [PubMed - in process]


531. Bioinformatics. 2016 Jun 15;32(12):1901-2. doi: 10.1093/bioinformatics/btw080.
Epub 2016 Feb 15.

solarius: an R interface to SOLAR for variance component analysis in pedigrees.

Ziyatdinov A(1), Brunel H(1), Martinez-Perez A(1), Buil A(2), Perera A(3), Soria 
JM(1).

Author information: 
(1)Unitat De Genòmica De Malalties Complexes, Institut D'investigació Biomèdica
Sant Pau (IIB-Sant Pau), Barcelona, Spain. (2)Department of Genetics Medicine and
Development, University of Geneva Medical School, Geneva, Switzerland. (3)B2SLab,
Department ESAII, Universitat Politècnica De Catalunya, Barcelona, Spain CIBER in
Bioengineering Biomaterials and Nanomedicine, Barcelona, Spain.

: The open source environment R is one of the most widely used software for
statistical computing. It provides a variety of applications including
statistical genetics. Most of the powerful tools for quantitative genetic
analyses are stand-alone free programs developed by researchers in academia.
SOLAR is one of the standard software programs to perform linkage and association
mappings of the quantitative trait loci (QTLs) in pedigrees of arbitrary size and
complexity. solarius allows the user to exploit the variance component methods
implemented in SOLAR. It automates such routine operations as formatting pedigree
and phenotype data. It parses also the model output and contains summary and
plotting functions for exploration of the results. In addition, solarius enables 
parallel computing of the linkage and association analyses that makes the
calculation of genome-wide scans more efficient.AVAILABILITY AND IMPLEMENTATION: 
solarius is available on CRAN and on GitHub https://github.com/ugcd/solarius
CONTACT: : aziyatdinov@santpau.cat.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw080 
PMID: 27153684  [PubMed - in process]


532. Bioinformatics. 2016 Jul 1;32(13):1925-32. doi: 10.1093/bioinformatics/btw064.
Epub 2016 Mar 2.

Assembly scaffolding with PE-contaminated mate-pair libraries.

Sahlin K(1), Chikhi R(2), Arvestad L(3).

Author information: 
(1)Science for Life Laboratory, School of Computer Science and Communication, KTH
Royal Institute of Technology, Solna, Sweden. (2)CNRS, CRIStAL, UMR 9189,
Villeneuve D'ascq 59650, France and. (3)Swedish e-Science Research Centre,
Science for Life Laboratory, and Department of Numerical Analysis and Computer
Science, Stockholm University, Stockholm, Sweden.

MOTIVATION: Scaffolding is often an essential step in a genome assembly process, 
in which contigs are ordered and oriented using read pairs from a combination of 
paired-end libraries and longer-range mate-pair libraries. Although a simple
idea, scaffolding is unfortunately hard to get right in practice. One source of
problems is so-called PE-contamination in mate-pair libraries, in which a
non-negligible fraction of the read pairs get the wrong orientation and a much
smaller insert size than what is expected. This contamination has been discussed 
before, in relation to integrated scaffolders, but solutions rely on the
orientation being observable, e.g. by finding the junction adapter sequence in
the reads. This is not always possible, making orientation and insert size of a
read pair stochastic. To our knowledge, there is neither previous work on
modeling PE-contamination, nor a study on the effect PE-contamination has on
scaffolding quality.
RESULTS: We have addressed PE-contamination in an update to our scaffolder BESST.
We formulate the problem as an integer linear program which is solved using an
efficient heuristic. The new method shows significant improvement over both
integrated and stand-alone scaffolders in our experiments. The impact of modeling
PE-contamination is quantified by comparing with the previous BESST model. We
also show how other scaffolders are vulnerable to PE-contaminated libraries,
resulting in an increased number of misassemblies, more conservative scaffolding 
and inflated assembly sizes.
AVAILABILITY AND IMPLEMENTATION: The model is implemented in BESST. Source code
and usage instructions are found at https://github.com/ksahlin/BESST BESST can
also be downloaded using PyPI.
CONTACT: ksahlin@kth.se
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw064 
PMID: 27153683  [PubMed - in process]


533. Bioinformatics. 2016 Jun 15;32(12):1903-4. doi: 10.1093/bioinformatics/btw098.
Epub 2016 Feb 18.

Coala: an R framework for coalescent simulation.

Staab PR(1), Metzler D(1).

Author information: 
(1)Department of Biology, Ludwig-Maximilians-Universität München,
Planegg-Martinsried 82152, Germany.

Simulation programs based on the coalescent efficiently generate genetic data
according to a given model of evolution. We present coala, an R package for
calling coalescent simulators with a unified syntax. It can execute simulations
with several programs, calculate additional summary statistics and combine
multiple simulations to create biologically more realistic data.AVAILABILITY AND 
IMPLEMENTATION: The package is publicly available on CRAN and on
https://github.com/statgenlmu/coala under the conditions of the MIT license.
CONTACT: metzler@bio.lmu.de.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw098 
PMID: 27153679  [PubMed - in process]


534. Bioinformatics. 2016 Jul 1;32(13):2026-8. doi: 10.1093/bioinformatics/btw106.
Epub 2016 Feb 26.

PhamDB: a web-based application for building Phamerator databases.

Lamine JG(1), DeJong RJ(2), Nelesen SM(1).

Author information: 
(1)Department of Computer Science. (2)Department of Biology, Calvin College,
Grand Rapids, MI, USA.

PhamDB is a web application which creates databases of bacteriophage genes,
grouped by gene similarity. It is backwards compatible with the existing
Phamerator desktop software while providing an improved database creation
workflow. Key features include a graphical user interface, validation of uploaded
GenBank files, and abilities to import phages from existing databases, modify
existing databases and queue multiple jobs.AVAILABILITY AND IMPLEMENTATION:
Source code and installation instructions for Linux, Windows and Mac OSX are
freely available at https://github.com/jglamine/phage PhamDB is also distributed 
as a docker image which can be managed via Kitematic. This docker image contains 
the application and all third party software dependencies as a pre-configured
system, and is freely available via the installation instructions provided.
CONTACT: snelesen@calvin.edu.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw106 
PMID: 27153674  [PubMed - in process]


535. Bioinformatics. 2016 Jul 1;32(13):2047-9. doi: 10.1093/bioinformatics/btw116.
Epub 2016 Mar 7.

Goldilocks: a tool for identifying genomic regions that are 'just right'.

Nicholls SM(1), Clare A(2), Randall JC(3).

Author information: 
(1)Department of Computer Science, Aberystwyth University, Aberystwyth, UK
Department of Human Genetics Informatics, Wellcome Trust Sanger Institute,
Cambridge, UK. (2)Department of Computer Science, Aberystwyth University,
Aberystwyth, UK. (3)Department of Human Genetics Informatics, Wellcome Trust
Sanger Institute, Cambridge, UK.

: We present Goldilocks: a Python package providing functionality for collecting 
summary statistics, identifying shifts in variation, discovering outlier regions 
and locating and extracting interesting regions from one or more arbitrary
genomes for further analysis, for a user-provided definition of
interesting.AVAILABILITY AND IMPLEMENTATION: Goldilocks is freely available
open-source software distributed under the MIT licence. Source code is hosted
publicly at https://github.com/SamStudio8/goldilocks and the package may also be 
installed using pip install goldilocks. Documentation can be found at
https://goldilocks.readthedocs.org
CONTACT: : msn@aber.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw116 
PMCID: PMC4920124
PMID: 27153673  [PubMed - in process]


536. Bioinformatics. 2016 Sep 1;32(17):2702-3. doi: 10.1093/bioinformatics/btw241.
Epub 2016 May 3.

OrfM: a fast open reading frame predictor for metagenomic data.

Woodcroft BJ(1), Boyd JA(1), Tyson GW(1).

Author information: 
(1)Australian Centre for Ecogenomics, School of Chemistry and Molecular
Biosciences, University of Queensland, Brisbane, QLD 4072, Australia.

Finding and translating stretches of DNA lacking stop codons is a task common in 
the analysis of sequence data. However, the computational tools for finding open 
reading frames are sufficiently slow that they are becoming a bottleneck as the
volume of sequence data grows. This computational bottleneck is especially
problematic in metagenomics when searching unassembled reads, or screening
assembled contigs for genes of interest. Here, we present OrfM, a tool to rapidly
identify open reading frames (ORFs) in sequence data by applying the Aho-Corasick
algorithm to find regions uninterrupted by stop codons. Benchmarking revealed
that OrfM finds identical ORFs to similar tools ('GetOrf' and 'Translate') but is
four-five times faster. While OrfM is sequencing platform-agnostic, it is best
suited to large, high quality datasets such as those produced by Illumina
sequencers.AVAILABILITY AND IMPLEMENTATION: Source code and binaries are freely
available for download at http://github.com/wwood/OrfM or through GNU Guix under 
the LGPL 3+ license. OrfM is implemented in C and supported on GNU/Linux and OSX.
CONTACTS: b.woodcroft@uq.edu.au
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw241 
PMCID: PMC5013905
PMID: 27153669  [PubMed - in process]


537. Bioinformatics. 2016 Sep 15;32(18):2863-5. doi: 10.1093/bioinformatics/btw229.
Epub 2016 May 5.

MEANS: python package for Moment Expansion Approximation, iNference and
Simulation.

Fan S(1), Geissmann Q(1), Lakatos E(1), Lukauskas S(1), Ale A(1), Babtie AC(1),
Kirk PD(2), Stumpf MP(1).

Author information: 
(1)Centre for Integrative Systems Biology and Bioinformatics, Department of Life 
Sciences, Imperial College London, London SW7 2AZ, UK. (2)MRC Biostatistics Unit,
Cambridge CB2 0SR, UK.

MOTIVATION: Many biochemical systems require stochastic descriptions.
Unfortunately these can only be solved for the simplest cases and their direct
simulation can become prohibitively expensive, precluding thorough analysis. As
an alternative, moment closure approximation methods generate equations for the
time-evolution of the system's moments and apply a closure ansatz to obtain a
closed set of differential equations; that can become the basis for the
deterministic analysis of the moments of the outputs of stochastic systems.
RESULTS: We present a free, user-friendly tool implementing an efficient moment
expansion approximation with parametric closures that integrates well with the
IPython interactive environment. Our package enables the analysis of complex
stochastic systems without any constraints on the number of species and moments
studied and the type of rate laws in the system. In addition to the approximation
method our package provides numerous tools to help non-expert users in stochastic
analysis.
AVAILABILITY AND IMPLEMENTATION: https://github.com/theosysbio/means
CONTACTS: m.stumpf@imperial.ac.uk or e.lakatos13@imperial.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw229 
PMCID: PMC5018365
PMID: 27153663  [PubMed - in process]


538. Bioinformatics. 2016 Sep 1;32(17):2664-71. doi: 10.1093/bioinformatics/btw228.
Epub 2016 May 5.

Drug repositioning based on comprehensive similarity measures and Bi-Random walk 
algorithm.

Luo H(1), Wang J(2), Li M(2), Luo J(2), Peng X(2), Wu FX(3), Pan Y(4).

Author information: 
(1)School of Information Science and Engineering, Central South University,
ChangSha, 410083, China School of Computer and Information Engineering, Henan
University, KaiFeng 475001, China. (2)School of Information Science and
Engineering, Central South University, ChangSha, 410083, China. (3)Division of
Biomedical Engineering, University of Saskatchewan, Saskatchewan S7N 5A9, Canada.
(4)Department of Computer Science, Georgia State University, Atlanta, GA
30302-3994, USA.

MOTIVATION: Drug repositioning, which aims to identify new indications for
existing drugs, offers a promising alternative to reduce the total time and cost 
of traditional drug development. Many computational strategies for drug
repositioning have been proposed, which are based on similarities among drugs and
diseases. Current studies typically use either only drug-related properties (e.g.
chemical structures) or only disease-related properties (e.g. phenotypes) to
calculate drug or disease similarity, respectively, while not taking into account
the influence of known drug-disease association information on the similarity
measures.
RESULTS: In this article, based on the assumption that similar drugs are normally
associated with similar diseases and vice versa, we propose a novel computational
method named MBiRW, which utilizes some comprehensive similarity measures and
Bi-Random walk (BiRW) algorithm to identify potential novel indications for a
given drug. By integrating drug or disease features information with known
drug-disease associations, the comprehensive similarity measures are firstly
developed to calculate similarity for drugs and diseases. Then drug similarity
network and disease similarity network are constructed, and they are incorporated
into a heterogeneous network with known drug-disease interactions. Based on the
drug-disease heterogeneous network, BiRW algorithm is adopted to predict novel
potential drug-disease associations. Computational experiment results from
various datasets demonstrate that the proposed approach has reliable prediction
performance and outperforms several recent computational drug repositioning
approaches. Moreover, case studies of five selected drugs further confirm the
superior performance of our method to discover potential indications for drugs
practically.
AVAILABILITY AND IMPLEMENTATION: http://github.com//bioinfomaticsCSU/MBiRW
CONTACT: jxwang@mail.csu.edu.cn
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw228 
PMID: 27153662  [PubMed - in process]


539. Bioinformatics. 2016 Jul 15;32(14):2227-9. doi: 10.1093/bioinformatics/btw220.
Epub 2016 May 3.

ASAFE: ancestry-specific allele frequency estimation.

Zhang QS(1), Browning BL(2), Browning SR(3).

Author information: 
(1)Department of Medicine Department of Biostatistics and. (2)Department of
Biostatistics and Division of Medical Genetics, Department of Medicine,
University of Washington, Seattle, WA, USA. (3)Department of Biostatistics and.

In a genome-wide association study (GWAS) of an admixed population, such as
Hispanic Americans, ancestry-specific allele frequencies can inform the design of
a replication GWAS. We derive an EM algorithm to estimate ancestry-specific
allele frequencies for a bi-allelic marker given genotypes and local ancestries
on a 3-way admixed population, when the phase of each admixed individual's
genotype relative to the pair of local ancestries is unknown. We call our
algorithm Ancestry Specific Allele Frequency Estimation (ASAFE). We demonstrate
that ASAFE has low error on simulated data.AVAILABILITY AND IMPLEMENTATION: The R
source code for ASAFE is available for download at
https://github.com/BiostatQian/ASAFE CONTACT: qszhang@uw.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw220 
PMCID: PMC4937201 [Available on 2017-07-15]
PMID: 27153656  [PubMed - in process]


540. Bioinformatics. 2016 Jun 1;32(11):1670-7. doi: 10.1093/bioinformatics/btw217.
Epub 2016 Apr 28.

Informed kmer selection for de novo transcriptome assembly.

Durai DA(1), Schulz MH(1).

Author information: 
(1)Cluster of Excellence on Multimodal Computing and Interaction, Saarland
University, Saarbrücken, 66123, Germany Department for Computational Biology and 
Applied Algorithmics, Max Planck Institute for Informatics, Saarbrücken, 66123,
Germany.

MOTIVATION: De novo transcriptome assembly is an integral part for many RNA-seq
workflows. Common applications include sequencing of non-model organisms, cancer 
or meta transcriptomes. Most de novo transcriptome assemblers use the de Bruijn
graph (DBG) as the underlying data structure. The quality of the assemblies
produced by such assemblers is highly influenced by the exact word length k As
such no single kmer value leads to optimal results. Instead, DBGs over different 
kmer values are built and the assemblies are merged to improve sensitivity.
However, no studies have investigated thoroughly the problem of automatically
learning at which kmer value to stop the assembly. Instead a suboptimal selection
of kmer values is often used in practice.
RESULTS: Here we investigate the contribution of a single kmer value in a
multi-kmer based assembly approach. We find that a comparative clustering of
related assemblies can be used to estimate the importance of an additional kmer
assembly. Using a model fit based algorithm we predict the kmer value at which no
further assemblies are necessary. Our approach is tested with different de novo
assemblers for datasets with different coverage values and read lengths. Further,
we suggest a simple post processing step that significantly improves the quality 
of multi-kmer assemblies.
CONCLUSION: We provide an automatic method for limiting the number of kmer values
without a significant loss in assembly quality but with savings in assembly time.
This is a step forward to making multi-kmer methods more reliable and easier to
use.
AVAILABILITY AND IMPLEMENTATION: A general implementation of our approach can be 
found under: https://github.com/SchulzLab/KREATIONSupplementary information:
Supplementary data are available at Bioinformatics online.
CONTACT: mschulz@mmci.uni-saarland.de.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw217 
PMCID: PMC4892416
PMID: 27153653  [PubMed - in process]


541. Bioinformatics. 2016 Jul 15;32(14):2216-8. doi: 10.1093/bioinformatics/btw215.
Epub 2016 Apr 22.

CaFE: a tool for binding affinity prediction using end-point free energy methods.

Liu H(1), Hou T(1).

Author information: 
(1)College of Pharmaceutical Sciences, Zhejiang University, Hangzhou, Zhejiang
310058, China.

Accurate prediction of binding free energy is of particular importance to
computational biology and structure-based drug design. Among those methods for
binding affinity predictions, the end-point approaches, such as MM/PBSA and LIE, 
have been widely used because they can achieve a good balance between prediction 
accuracy and computational cost. Here we present an easy-to-use pipeline tool
named Calculation of Free Energy (CaFE) to conduct MM/PBSA and LIE calculations. 
Powered by the VMD and NAMD programs, CaFE is able to handle numerous static
coordinate and molecular dynamics trajectory file formats generated by different 
molecular simulation packages and supports various force field
parameters.AVAILABILITY AND IMPLEMENTATION: CaFE source code and documentation
are freely available under the GNU General Public License via GitHub at
https://github.com/huiliucode/cafe_plugin It is a VMD plugin written in Tcl and
the usage is platform-independent.
CONTACT: tingjunhou@zju.edu.cn.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw215 
PMID: 27153651  [PubMed - in process]


542. Bioinformatics. 2016 Jul 15;32(14):2096-102. doi: 10.1093/bioinformatics/btw212. 
Epub 2016 Apr 22.

Estimating IBD tracts from low coverage NGS data.

Vieira FG(1), Albrechtsen A(2), Nielsen R(3).

Author information: 
(1)Centre for GeoGenetics, Natural History Museum of Denmark. (2)Department of
Biology, University of Copenhagen, Copenhagen, Denmark and. (3)Department of
Biology, University of Copenhagen, Copenhagen, Denmark and Department of
Integrative Biology, University of California, Berkeley, USA.

MOTIVATION: The amount of IBD in an individual depends on the relatedness of the 
individual's parents. However, it can also provide information regarding mating
system, past history and effective size of the population from which the
individual has been sampled.
RESULTS: Here, we present a new method for estimating inbreeding IBD tracts from 
low coverage NGS data. Contrary to other methods that use genotype data, the one 
presented here uses genotype likelihoods to take the uncertainty of the data into
account. We benchmark it under a wide range of biologically relevant conditions
and show that the new method provides a marked increase in accuracy even at low
coverage.
AVAILABILITY AND IMPLEMENTATION: The methods presented in this work were
implemented in C/C ++ and are freely available for non-commercial use from
https://github.com/fgvieira/ngsF-HMM CONTACT: fgvieira@snm.ku.dk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw212 
PMID: 27153648  [PubMed - in process]


543. Bioinformatics. 2016 Aug 15;32(16):2524-5. doi: 10.1093/bioinformatics/btw210.
Epub 2016 Apr 22.

TnT: a set of libraries for visualizing trees and track-based annotations for the
web.

Pignatelli M(1).

Author information: 
(1)Centre for Therapeutic Target Validation and European Bioinformatics
Institute, Wellcome Genome Campus, Hinxton, Cambridge CB10 1SD, UK.

There is an increasing need for rich and dynamic biological data visualizations
in bioinformatic web applications. New standards in web technologies, like SVG or
Canvas, are now supported by most modern web browsers allowing the blossoming of 
powerful visualizations in biological data analysis. The exploration of different
ways to visualize genomic data is still challenging due to the lack of flexible
tools to develop them. Here, I present a set of libraries aimed at creating
powerful tree- and track-based visualizations for the web. Its modularity and
rich API facilitate the development of many different visualizations ranging from
simple species trees to complex visualizations comprising per-node data
annotations or even simple genome browsers.AVAILABILITY AND IMPLEMENTATION: The
TnT libraries have been written in Javascript, licensed under the APACHE 2.0
license and hosted at https://github.com/tntvis
CONTACT: mp@ebi.ac.uk.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw210 
PMCID: PMC4978938
PMID: 27153646  [PubMed - in process]


544. Bioinformatics. 2016 Aug 15;32(16):2419-26. doi: 10.1093/bioinformatics/btw209.
Epub 2016 Apr 19.

Romulus: robust multi-state identification of transcription factor binding sites 
from DNase-seq data.

Jankowski A(1), Tiuryn J(2), Prabhakar S(3).

Author information: 
(1)Faculty of Mathematics, Informatics and Mechanics, University of Warsaw,
02-097 Warszawa, Poland Computational and Systems Biology, Genome Institute of
Singapore, Singapore 138672, Singapore. (2)Faculty of Mathematics, Informatics
and Mechanics, University of Warsaw, 02-097 Warszawa, Poland. (3)Computational
and Systems Biology, Genome Institute of Singapore, Singapore 138672, Singapore.

MOTIVATION: Computational prediction of transcription factor (TF) binding sites
in the genome remains a challenging task. Here, we present Romulus, a novel
computational method for identifying individual TF binding sites from genome
sequence information and cell-type-specific experimental data, such as DNase-seq.
It combines the strengths of previous approaches, and improves robustness by
reducing the number of free parameters in the model by an order of magnitude.
RESULTS: We show that Romulus significantly outperforms existing methods across
three sources of DNase-seq data, by assessing the performance of these tools
against ChIP-seq profiles. The difference was particularly significant when
applied to binding site prediction for low-information-content motifs. Our method
is capable of inferring multiple binding modes for a single TF, which differ in
their DNase I cut profile. Finally, using the model learned by Romulus and
ChIP-seq data, we introduce Binding in Closed Chromatin (BCC) as a quantitative
measure of TF pioneer factor activity. Uniquely, our measure quantifies a
defining feature of pioneer factors, namely their ability to bind closed
chromatin.
AVAILABILITY AND IMPLEMENTATION: Romulus is freely available as an R package at
http://github.com/ajank/Romulus
CONTACT: ajank@mimuw.edu.pl
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw209 
PMCID: PMC4978937
PMID: 27153645  [PubMed - in process]


545. Bioinformatics. 2016 Jul 15;32(14):2208-9. doi: 10.1093/bioinformatics/btw205.
Epub 2016 Apr 22.

SAMFIRE: multi-locus variant calling for time-resolved sequence data.

Illingworth CJ(1).

Author information: 
(1)Department of Genetics, University of Cambridge, Cambridge CB2 3AS, UK.

An increasingly common method for studying evolution is the collection of
time-resolved short-read sequence data. Such datasets allow for the direct
observation of rapid evolutionary processes, as might occur in natural microbial 
populations and in evolutionary experiments. In many circumstances, evolutionary 
pressure acting upon single variants can cause genomic changes at multiple nearby
loci. SAMFIRE is an open-access software package for processing and analyzing
sequence reads from time-resolved data, calling important single- and multi-locus
variants over time, identifying alleles potentially affected by selection,
calculating linkage disequilibrium statistics, performing haplotype
reconstruction and exploiting time-resolved information to estimate the extent of
uncertainty in reported genomic data.AVAILABILITY AND IMPLEMENTATION: C ++ code
may be found at https://github.com/cjri/samfire/
CONTACT: chris.illingworth@gen.cam.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw205 
PMCID: PMC4937198 [Available on 2017-07-15]
PMID: 27153641  [PubMed - in process]


546. Bioinformatics. 2016 Jul 15;32(14):2128-35. doi: 10.1093/bioinformatics/btw202.
Epub 2016 Apr 19.

Beta-Poisson model for single-cell RNA-seq data analyses.

Vu TN(1), Wills QF(2), Kalari KR(3), Niu N(4), Wang L(4), Rantalainen M(1),
Pawitan Y(1).

Author information: 
(1)Department of Medical Epidemiology and Biostatistics, Karolinska Institutet,
17177 Stockholm, Sweden. (2)Wellcome Trust Centre for Human Genetics, University 
of Oxford, Oxford OX3 7BN, UK Weatherall Institute of Molecular Medicine,
University of Oxford, Oxford OX3 9DS, UK. (3)Department of Health Sciences
Research, Mayo Clinic, Rochester, MN 55905, USA. (4)Department of Molecular
Pharmacology and Experimental Therapeutics, Mayo Clinic, Rochester, MN 55905,
USA.

MOTIVATION: Single-cell RNA-sequencing technology allows detection of gene
expression at the single-cell level. One typical feature of the data is a
bimodality in the cellular distribution even for highly expressed genes,
primarily caused by a proportion of non-expressing cells. The standard and the
over-dispersed gamma-Poisson models that are commonly used in bulk-cell
RNA-sequencing are not able to capture this property.
RESULTS: We introduce a beta-Poisson mixture model that can capture the
bimodality of the single-cell gene expression distribution. We further integrate 
the model into the generalized linear model framework in order to perform
differential expression analyses. The whole analytical procedure is called BPSC. 
The results from several real single-cell RNA-seq datasets indicate that ∼90% of 
the transcripts are well characterized by the beta-Poisson model; the model-fit
from BPSC is better than the fit of the standard gamma-Poisson model in > 80% of 
the transcripts. Moreover, in differential expression analyses of simulated and
real datasets, BPSC performs well against edgeR, a conventional method widely
used in bulk-cell RNA-sequencing data, and against scde and MAST, two recent
methods specifically designed for single-cell RNA-seq data.
AVAILABILITY AND IMPLEMENTATION: An R package BPSC for model fitting and
differential expression analyses of single-cell RNA-seq data is available under
GPL-3 license at https://github.com/nghiavtr/BPSC CONTACT: yudi.pawitan@ki.se or 
mattias.rantalainen@ki.se
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw202 
PMID: 27153638  [PubMed - in process]


547. Bioinformatics. 2016 Jul 15;32(14):2219-20. doi: 10.1093/bioinformatics/btw201.
Epub 2016 Apr 19.

SCell: integrated analysis of single-cell RNA-seq data.

Diaz A(1), Liu SJ(2), Sandoval C(2), Pollen A(2), Nowakowski TJ(2), Lim DA(3),
Kriegstein A(2).

Author information: 
(1)Department of Neurological Surgery, UCSF Eli and Edythe Broad Center of
Regeneration Medicine and Stem Cell Research. (2)Eli and Edythe Broad Center of
Regeneration Medicine and Stem Cell Research. (3)Department of Neurological
Surgery, UCSF Eli and Edythe Broad Center of Regeneration Medicine and Stem Cell 
Research Eli and Edythe Broad Center of Regeneration Medicine and Stem Cell
Research.

Analysis of the composition of heterogeneous tissue has been greatly enabled by
recent developments in single-cell transcriptomics. We present SCell, an
integrated software tool for quality filtering, normalization, feature selection,
iterative dimensionality reduction, clustering and the estimation of
gene-expression gradients from large ensembles of single-cell RNA-seq datasets.
SCell is open source, and implemented with an intuitive graphical interface.
Scripts and protocols for the high-throughput pre-processing of large ensembles
of single-cell, RNA-seq datasets are provided as an additional
resource.AVAILABILITY AND IMPLEMENTATION: Binary executables for Windows, MacOS
and Linux are available at http://sourceforge.net/projects/scell, source code and
pre-processing scripts are available from
https://github.com/diazlab/SCellSupplementary information: Supplementary data are
available at Bioinformatics online.
CONTACT: aaron.diaz@ucsf.edu.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw201 
PMCID: PMC4937196 [Available on 2017-07-15]
PMID: 27153637  [PubMed - in process]


548. Bioinformatics. 2016 Aug 15;32(16):2562-4. doi: 10.1093/bioinformatics/btw196.
Epub 2016 Apr 13.

Muxstep: an open-source C ++ multiplex HMM library for making inferences on
multiple data types.

Veličković P(1), Liò P(1).

Author information: 
(1)Computer Laboratory, University of Cambridge, Cambridge CB3 0FD, UK.

MOTIVATION: With the development of experimental methods and technology, we are
able to reliably gain access to data in larger quantities, dimensions and types. 
This has great potential for the improvement of machine learning (as the learning
algorithms have access to a larger space of information). However, conventional
machine learning approaches used thus far on single-dimensional data inputs are
unlikely to be expressive enough to accurately model the problem in higher
dimensions; in fact, it should generally be most suitable to represent our
underlying models as some form of complex networksng;nsio with nontrivial
topological features. As the first step in establishing such a trend, we present 
MUXSTEP: , an open-source library utilising multiplex networks for the purposes
of binary classification on multiple data types. The library is designed to be
used out-of-the-box for developing models based on the multiplex network
framework, as well as easily modifiable to suit problem modelling needs that may 
differ significantly from the default approach described.
AVAILABILITY AND IMPLEMENTATION: The full source code is available on GitHub:
https://github.com/PetarV-/muxstep
CONTACT: petar.velickovic@cl.cam.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw196 
PMID: 27153633  [PubMed - in process]


549. Bioinformatics. 2016 Aug 15;32(16):2554-5. doi: 10.1093/bioinformatics/btw195.
Epub 2016 Apr 13.

hotspot: software to support sperm-typing for investigating recombination
hotspots.

Odenthal-Hesse L(1), Dutheil JY(1), Klötzl F(1), Haubold B(1).

Author information: 
(1)Department of Evolutionary Genetics, Max-Planck-Institute for Evolutionary
Biology, Plön, Germany.

MOTIVATION: In many organisms, including humans, recombination clusters within
recombination hotspots. The standard method for de novo detection of recombinants
at hotspots is sperm typing. This relies on allele-specific PCR at single
nucleotide polymorphisms. Designing allele-specific primers by hand is
time-consuming. We have therefore written a package to support hotspot detection 
and analysis.
RESULTS: hotspot consists of four programs: asp looks up SNPs and designs
allele-specific primers; aso constructs allele-specific oligos for mapping
recombinants; xov implements a maximum-likelihood method for estimating the
crossover rate; six, finally, simulates typing data.
AVAILABILITY AND IMPLEMENTATION: hotspot is written in C. Sources are freely
available under the GNU General Public License from
http://github.com/evolbioinf/hotspot/
CONTACT: haubold@evolbio.mpg.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw195 
PMCID: PMC4978934
PMID: 27153632  [PubMed - in process]


550. Bioinformatics. 2016 Aug 15;32(16):2464-72. doi: 10.1093/bioinformatics/btw190.
Epub 2016 Apr 19.

MEMO: multi-experiment mixture model analysis of censored data.

Geissen EM(1), Hasenauer J(2), Heinrich S(3), Hauf S(3), Theis FJ(2), Radde
NE(1).

Author information: 
(1)Institute for Systems Theory and Automatic Control, University of Stuttgart,
Stuttgart 70550, Germany. (2)Institute of Computational Biology, Helmholtz
Zentrum München - German Research Center for Environmental Health, Neuherberg
85764, Germany Department of Mathematics, Technische Universität München,
Garching 85748, Germany. (3)Friedrich Miescher Laboratory of the Max Planck
Society, Tübingen 72076, Germany.

MOTIVATION: The statistical analysis of single-cell data is a challenge in cell
biological studies. Tailored statistical models and computational methods are
required to resolve the subpopulation structure, i.e. to correctly identify and
characterize subpopulations. These approaches also support the unraveling of
sources of cell-to-cell variability. Finite mixture models have shown promise,
but the available approaches are ill suited to the simultaneous consideration of 
data from multiple experimental conditions and to censored data. The prevalence
and relevance of single-cell data and the lack of suitable computational
analytics make automated methods, that are able to deal with the requirements
posed by these data, necessary.
RESULTS: We present MEMO, a flexible mixture modeling framework that enables the 
simultaneous, automated analysis of censored and uncensored data acquired under
multiple experimental conditions. MEMO is based on maximum-likelihood inference
and allows for testing competing hypotheses. MEMO can be applied to a variety of 
different single-cell data types. We demonstrate the advantages of MEMO by
analyzing right and interval censored single-cell microscopy data. Our results
show that an examination of censoring and the simultaneous consideration of
different experimental conditions are necessary to reveal biologically meaningful
subpopulation structures. MEMO allows for a stringent analysis of single-cell
data and enables researchers to avoid misinterpretation of censored data.
Therefore, MEMO is a valuable asset for all fields that infer the characteristics
of populations by looking at single individuals such as cell biology and
medicine.
AVAILABILITY AND IMPLEMENTATION: MEMO is implemented in MATLAB and freely
available via github (https://github.com/MEMO-toolbox/MEMO).
CONTACTS: eva-maria.geissen@ist.uni-stuttgart.de or
nicole.radde@ist.uni-stuttgart.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw190 
PMCID: PMC4978932
PMID: 27153627  [PubMed - in process]


551. Bioinformatics. 2016 Aug 15;32(16):2517-9. doi: 10.1093/bioinformatics/btw180.
Epub 2016 Apr 8.

methyLiftover: cross-platform DNA methylation data integration.

Titus AJ(1), Houseman EA(2), Johnson KC(3), Christensen BC(4).

Author information: 
(1)Department of Epidemiology, Geisel School of Medicine at Dartmouth, Lebanon,
NH, USA. (2)Department of Biostatistics, Oregon State University College of
Public Health and Human Sciences, Corvallis, OR, USA. (3)Department of
Epidemiology, Geisel School of Medicine at Dartmouth, Lebanon, NH, USA Department
of Pharmacology and Toxicology, Geisel School of Medicine at Dartmouth, Lebanon, 
NH, USA. (4)Department of Epidemiology, Geisel School of Medicine at Dartmouth,
Lebanon, NH, USA Department of Pharmacology and Toxicology, Geisel School of
Medicine at Dartmouth, Lebanon, NH, USA Department of Community and Family
Medicine, Geisel School of Medicine at Dartmouth, Lebanon, NH, USA.

: The public availability of high throughput molecular data provides new
opportunities for researchers to advance discovery, replication and validation
efforts. One common challenge in leveraging such data is the diversity of
measurement approaches and platforms and a lack of utilities enabling
cross-platform comparisons among data sources for analysis. We present a method
to map DNA methylation data from bisulfite sequencing approaches to CpG sites
measured with the widely used Illumina methylation bead-array platforms.
Correlations and median absolute deviations support the validity of using
bisulfite sequencing data in combination with Illumina bead-array methylation
data.AVAILABILITY AND IMPLEMENTATION:
https://github.com/Christensen-Lab-Dartmouth/methyLiftover includes source,
documentation and data references.
CONTACT: brock.c.christensen@dartmouth.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw180 
PMCID: PMC5006233 [Available on 2017-08-15]
PMID: 27153617  [PubMed - in process]


552. Bioinformatics. 2016 Jun 1;32(11):1662-9. doi: 10.1093/bioinformatics/btw178.
Epub 2016 Apr 5.

Cell-free DNA fragment-size distribution analysis for non-invasive prenatal CNV
prediction.

Arbabi A(1), Rampášek L(2), Brudno M(3).

Author information: 
(1)Department of Computer Science, University of Toronto, Toronto, ON M5S 2E4,
Canada Centre for Computational Medicine, Hospital for Sick Children, Toronto, ON
M5G 1L7, Canada and. (2)Department of Computer Science, University of Toronto,
Toronto, ON M5S 2E4, Canada Genetics and Genome Biology, Hospital for Sick
Children, Toronto, ON M5G 1L7, Canada. (3)Department of Computer Science,
University of Toronto, Toronto, ON M5S 2E4, Canada Centre for Computational
Medicine, Hospital for Sick Children, Toronto, ON M5G 1L7, Canada and Genetics
and Genome Biology, Hospital for Sick Children, Toronto, ON M5G 1L7, Canada.

BACKGROUND: Non-invasive detection of aneuploidies in a fetal genome through
analysis of cell-free DNA circulating in the maternal plasma is becoming a
routine clinical test. Such tests, which rely on analyzing the read coverage or
the allelic ratios at single-nucleotide polymorphism (SNP) loci, are not
sensitive enough for smaller sub-chromosomal abnormalities due to sequencing
biases and paucity of SNPs in a genome.
RESULTS: We have developed an alternative framework for identifying
sub-chromosomal copy number variations in a fetal genome. This framework relies
on the size distribution of fragments in a sample, as fetal-origin fragments tend
to be smaller than those of maternal origin. By analyzing the local distribution 
of the cell-free DNA fragment sizes in each region, our method allows for the
identification of sub-megabase CNVs, even in the absence of SNP positions. To
evaluate the accuracy of our method, we used a plasma sample with the fetal
fraction of 13%, down-sampled it to samples with coverage of 10X-40X and
simulated samples with CNVs based on it. Our method had a perfect accuracy (both 
specificity and sensitivity) for detecting 5 Mb CNVs, and after reducing the
fetal fraction (to 11%, 9% and 7%), it could correctly identify 98.82-100% of the
5 Mb CNVs and had a true-negative rate of 95.29-99.76%.
AVAILABILITY AND IMPLEMENTATION: Our source code is available on GitHub at
https://github.com/compbio-UofT/FSDA CONTACT: : brudno@cs.toronto.edu.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw178 
PMID: 27153615  [PubMed - in process]


553. Bioinformatics. 2016 Aug 15;32(16):2551-3. doi: 10.1093/bioinformatics/btw177.
Epub 2016 Apr 21.

Rail-dbGaP: analyzing dbGaP-protected data in the cloud with Amazon Elastic
MapReduce.

Nellore A(1), Wilks C(2), Hansen KD(3), Leek JT(3), Langmead B(1).

Author information: 
(1)Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA
Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health,
Baltimore, MD, USA Center for Computational Biology, Johns Hopkins University,
Baltimore, MD, USA. (2)Department of Computer Science, Johns Hopkins University, 
Baltimore, MD, USA Center for Computational Biology, Johns Hopkins University,
Baltimore, MD, USA. (3)Department of Biostatistics, Johns Hopkins Bloomberg
School of Public Health, Baltimore, MD, USA Center for Computational Biology,
Johns Hopkins University, Baltimore, MD, USA.

MOTIVATION: Public archives contain thousands of trillions of bases of valuable
sequencing data. More than 40% of the Sequence Read Archive is human data
protected by provisions such as dbGaP. To analyse dbGaP-protected data,
researchers must typically work with IT administrators and signing officials to
ensure all levels of security are implemented at their institution. This is a
major obstacle, impeding reproducibility and reducing the utility of archived
data.
RESULTS: We present a protocol and software tool for analyzing protected data in 
a commercial cloud. The protocol, Rail-dbGaP, is applicable to any tool running
on Amazon Web Services Elastic MapReduce. The tool, Rail-RNA v0.2, is a spliced
aligner for RNA-seq data, which we demonstrate by running on 9662 samples from
the dbGaP-protected GTEx consortium dataset. The Rail-dbGaP protocol makes
explicit for the first time the steps an investigator must take to develop
Elastic MapReduce pipelines that analyse dbGaP-protected data in a manner
compliant with NIH guidelines. Rail-RNA automates implementation of the protocol,
making it easy for typical biomedical investigators to study protected RNA-seq
data, regardless of their local IT resources or expertise.
AVAILABILITY AND IMPLEMENTATION: Rail-RNA is available from http://rail.bio
Technical details on the Rail-dbGaP protocol as well as an implementation
walkthrough are available at https://github.com/nellore/rail-dbgap Detailed
instructions on running Rail-RNA on dbGaP-protected data using Amazon Web
Services are available at http://docs.rail.bio/dbgap/
CONTACTS: : anellore@gmail.com or langmea@cs.jhu.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw177 
PMCID: PMC4978928
PMID: 27153614  [PubMed - in process]


554. Bioinformatics. 2016 Aug 15;32(16):2511-3. doi: 10.1093/bioinformatics/btw173.
Epub 2016 Apr 8.

CHiCP: a web-based tool for the integrative and interactive visualization of
promoter capture Hi-C datasets.

Schofield EC(1), Carver T(1), Achuthan P(1), Freire-Pritchett P(2), Spivakov
M(2), Todd JA(1), Burren OS(1).

Author information: 
(1)JDRF/Wellcome Trust Diabetes and Inflammation Laboratory, NIHR Cambridge
Biomedical Research Centre, Department of Medical Genetics, Cambridge Institute
for Medical Research, University of Cambridge, Cambridge CB2 0XY, UK. (2)Nuclear 
Dynamics Programme, The Babraham Institute, Cambridge CB22 3AT, UK.

Promoter capture Hi-C (PCHi-C) allows the genome-wide interrogation of physical
interactions between distal DNA regulatory elements and gene promoters in
multiple tissue contexts. Visual integration of the resultant chromosome
interaction maps with other sources of genomic annotations can provide insight
into underlying regulatory mechanisms. We have developed Capture HiC Plotter
(CHiCP), a web-based tool that allows interactive exploration of PCHi-C
interaction maps and integration with both public and user-defined genomic
datasets.AVAILABILITY AND IMPLEMENTATION: CHiCP is freely accessible from
www.chicp.org and supports most major HTML5 compliant web browsers. Full source
code and installation instructions are available from
http://github.com/D-I-L/django-chicp
CONTACT: ob219@cam.ac.uk.

© The Author 2016. Published by Oxford University Press. All rights reserved.

DOI: 10.1093/bioinformatics/btw173 
PMCID: PMC4978926
PMID: 27153610  [PubMed - in process]


555. Bioinformatics. 2016 Aug 1;32(15):2378-9. doi: 10.1093/bioinformatics/btw167.
Epub 2016 Mar 29.

pileup.js: a JavaScript library for interactive and in-browser visualization of
genomic data.

Vanderkam D(1), Aksoy BA(1), Hodes I(1), Perrone J(1), Hammerbacher J(1).

Author information: 
(1)Department of Genetics and Genomic Sciences, Icahn School of Medicine at Mount
Sinai, 1 Gustave L. Levy Pl, New York, NY 10029, USA.

P: ileup.js is a new browser-based genome viewer. It is designed to facilitate
the investigation of evidence for genomic variants within larger web
applications. It takes advantage of recent developments in the JavaScript
ecosystem to provide a modular, reliable and easily embedded library.AVAILABILITY
AND IMPLEMENTATION: The code and documentation for pileup.js is publicly
available at https://github.com/hammerlab/pileup.js under the Apache 2.0 license.
CONTACT: correspondence@hammerlab.org.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw167 
PMCID: PMC4965634
PMID: 27153605  [PubMed - in process]


556. Bioinformatics. 2016 Aug 1;32(15):2352-8. doi: 10.1093/bioinformatics/btw165.
Epub 2016 Mar 25.

Deep models for brain EM image segmentation: novel insights and improved
performance.

Fakhry A(1), Peng H(2), Ji S(3).

Author information: 
(1)Department of Computer Science, Old Dominion University, Norfolk, VA 23529,
USA. (2)Allen Institute for Brain Science, Seattle, WA 98103, USA. (3)School of
Electrical Engineering and Computer Science, Washington State University,
Pullman, WA 99164, USA.

MOTIVATION: Accurate segmentation of brain electron microscopy (EM) images is a
critical step in dense circuit reconstruction. Although deep neural networks
(DNNs) have been widely used in a number of applications in computer vision, most
of these models that proved to be effective on image classification tasks cannot 
be applied directly to EM image segmentation, due to the different objectives of 
these tasks. As a result, it is desirable to develop an optimized architecture
that uses the full power of DNNs and tailored specifically for EM image
segmentation.
RESULTS: In this work, we proposed a novel design of DNNs for this task. We
trained a pixel classifier that operates on raw pixel intensities with no
preprocessing to generate probability values for each pixel being a membrane or
not. Although the use of neural networks in image segmentation is not completely 
new, we developed novel insights and model architectures that allow us to achieve
superior performance on EM image segmentation tasks. Our submission based on
these insights to the 2D EM Image Segmentation Challenge achieved the best
performance consistently across all the three evaluation metrics. This challenge 
is still ongoing and the results in this paper are as of June 5, 2015.
AVAILABILITY AND IMPLEMENTATION: https://github.com/ahmed-fakhry/dive
CONTACT: : sji@eecs.wsu.edu.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw165 
PMID: 27153603  [PubMed - in process]


557. Bioinformatics. 2016 Jul 15;32(14):2083-8. doi: 10.1093/bioinformatics/btw164.
Epub 2016 Mar 24.

Quantitative phosphoproteomics-based molecular network description for
high-resolution kinase-substrate interactome analysis.

Narushima Y(1), Kozuka-Hata H(1), Tsumoto K(2), Inoue J(3), Oyama M(1).

Author information: 
(1)Medical Proteomics Laboratory, The Institute of Medical Science, The
University of Tokyo, Minato-ku, Tokyo 108-8639, Japan. (2)Medical Proteomics
Laboratory, The Institute of Medical Science, The University of Tokyo, Minato-ku,
Tokyo 108-8639, Japan Department of Bioengineering, Graduate School of
Engineering, The University of Tokyo, Bunkyo-ku, Tokyo 113-8656, Japan.
(3)Medical Proteomics Laboratory, The Institute of Medical Science, The
University of Tokyo, Minato-ku, Tokyo 108-8639, Japan Department of Cancer
Biology, The Institute of Medical Science, The University of Tokyo, Minato-ku,
Tokyo 108-8639, Japan.

MOTIVATION: Phosphorylation-dependent cellular signaling is known to play a
diverse role in regulating multiple cellular processes such as proliferation,
differentiation and apoptosis. Recent technological advances in mass
spectrometry-based phosphoproteomics have enabled us to measure network-wide
signaling dynamics in a comprehensive and quantitative manner. As conventional
protein-protein interaction (PPI) information-based network analysis is
insufficient to systematically analyze phosphorylation site-dependent complex
interaction dynamics, here we develop and evaluate a platform to provide a
high-resolution molecular network description for kinase-substrate interactome
analysis.
RESULTS: In this study, we developed a Cytoscape-based bioinformatical platform
named 'Post Translational Modification mapper (PTMapper)' to integrate PPI data
with publicly available kinase-substrate relations at the resolution of
phosphorylated amino acid residues. The previous phosphoproteome data on
EGF-induced cellular signaling in glioblastoma stem cells was applied to evaluate
our platform, leading to discovery of phosphorylation-dependent crucial signaling
modulation in the p70S6K1-related pathway. Our study revealed that
high-resolution cellular network description of phosphorylation-site dependent
kinase-substrate signaling regulation should accelerate phosphoproteomics-based
exploration of novel drug targets in the context of each disease-related
signaling.
AVAILABILITY AND IMPLEMENTATION: PTMapper and the example data for construction
of phosphorylation site-oriented networks are available at
https://github.com/y-narushima/PTMapper
CONTACT: moyama@ims.u-tokyo.ac.jp
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw164 
PMID: 27153602  [PubMed - in process]


558. Bioinformatics. 2016 Aug 1;32(15):2375-7. doi: 10.1093/bioinformatics/btw163.
Epub 2016 Mar 24.

Canvas: versatile and scalable detection of copy number variants.

Roller E(1), Ivakhno S(2), Lee S(1), Royce T(3), Tanner S(1).

Author information: 
(1)Illumina Inc, San Diego, CA 92122, USA. (2)Illumina Cambridge Ltd, Chesterford
Research Park, Little Chesterford, Essex CB10 1XL, UK. (3)Ashion Analytics,
Phoenix, AZ, USA.

MOTIVATION: Versatile and efficient variant calling tools are needed to analyze
large scale sequencing datasets. In particular, identification of copy number
changes remains a challenging task due to their complexity, susceptibility to
sequencing biases, variation in coverage data and dependence on genome-wide
sample properties, such as tumor polyploidy or polyclonality in cancer samples.
RESULTS: We have developed a new tool, Canvas, for identification of copy number 
changes from diverse sequencing experiments including whole-genome matched
tumor-normal and single-sample normal re-sequencing, as well as whole-exome
matched and unmatched tumor-normal studies. In addition to variant calling,
Canvas infers genome-wide parameters such as cancer ploidy, purity and
heterogeneity. It provides fast and easy-to-run workflows that can scale to
thousands of samples and can be easily incorporated into variant calling
pipelines.
AVAILABILITY AND IMPLEMENTATION: Canvas is distributed under an open source
license and can be downloaded from https://github.com/Illumina/canvas
CONTACT: eroller@illumina.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw163 
PMID: 27153601  [PubMed - in process]


559. Bioinformatics. 2016 Aug 1;32(15):2399-401. doi: 10.1093/bioinformatics/btw162.
Epub 2016 Mar 25.

CellMiner Companion: an interactive web application to explore CellMiner NCI-60
data.

Wang S(1), Gribskov M(1), Hazbun TR(2), Pascuzzi PE(3).

Author information: 
(1)Department of Biological Sciences. (2)Department of Medicinal Chemistry and
Molecular Pharmacology Purdue University Center for Cancer Research. (3)Purdue
University Center for Cancer Research Department of Biochemistry Purdue
University Libraries, Purdue University, West Lafayette, IN 47907, USA.

The NCI-60 human tumor cell line panel is an invaluable resource for cancer
researchers, providing drug sensitivity, molecular and phenotypic data for a
range of cancer types. CellMiner is a web resource that provides tools for the
acquisition and analysis of quality-controlled NCI-60 data. CellMiner supports
queries of up to 150 drugs or genes, but the output is an Excel file for each
drug or gene. This output format makes it difficult for researchers to explore
the data from large queries. CellMiner Companion is a web application that
facilitates the exploration and visualization of output from CellMiner, further
increasing the accessibility of NCI-60 data.AVAILABILITY AND IMPLEMENTATION: The 
web application is freely accessible at
https://pul-bioinformatics.shinyapps.io/CellMinerCompanion The R source code can 
be downloaded at https://github.com/pepascuzzi/CellMinerCompanion.git
CONTACT: ppascuzz@purdue.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw162 
PMID: 27153600  [PubMed - in process]


560. Bioinformatics. 2016 Aug 15;32(16):2508-10. doi: 10.1093/bioinformatics/btw159.
Epub 2016 Apr 7.

gEVAL - a web-based browser for evaluating genome assemblies.

Chow W(1), Brugger K(2), Caccamo M(3), Sealy I(1), Torrance J(1), Howe K(1).

Author information: 
(1)Wellcome Trust Sanger Institute, Hinxton, Cambridge CB10 1SA, UK. (2)East
Anglian Medical Genetics Centre, Cambridge University Hospitals, NHS Foundation
Trust, Cambridge CB2 0QQ, UK. (3)National Institute of Agricultural Botany,
Cambridge CB3 0LE, UK.

MOTIVATION: For most research approaches, genome analyses are dependent on the
existence of a high quality genome reference assembly. However, the local
accuracy of an assembly remains difficult to assess and improve. The gEVAL
browser allows the user to interrogate an assembly in any region of the genome by
comparing it to different datasets and evaluating the concordance. These analyses
include: a wide variety of sequence alignments, comparative analyses of multiple 
genome assemblies, and consistency with optical and other physical maps. gEVAL
highlights allelic variations, regions of low complexity, abnormal coverage, and 
potential sequence and assembly errors, and offers strategies for improvement.
Although gEVAL focuses primarily on sequence integrity, it can also display
arbitrary annotation including from Ensembl or TrackHub sources. We provide gEVAL
web sites for many human, mouse, zebrafish and chicken assemblies to support the 
Genome Reference Consortium, and gEVAL is also downloadable to enable its use for
any organism and assembly.
AVAILABILITY AND IMPLEMENTATION: Web Browser: http://geval.sanger.ac.uk, Plugin: 
http://wchow.github.io/wtsi-geval-plugin
CONTACT: kj2@sanger.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw159 
PMCID: PMC4978925
PMID: 27153597  [PubMed - in process]


561. Bioinformatics. 2016 Jul 15;32(14):2103-10. doi: 10.1093/bioinformatics/btw152.
Epub 2016 Mar 19.

Minimap and miniasm: fast mapping and de novo assembly for noisy long sequences.

Li H(1).

Author information: 
(1)Medical Population Genetics, Broad Institute, Cambridge, MA 02142, USA.

MOTIVATION: Single Molecule Real-Time (SMRT) sequencing technology and Oxford
Nanopore technologies (ONT) produce reads over 10 kb in length, which have
enabled high-quality genome assembly at an affordable cost. However, at present, 
long reads have an error rate as high as 10-15%. Complex and computationally
intensive pipelines are required to assemble such reads.
RESULTS: We present a new mapper, minimap and a de novo assembler, miniasm, for
efficiently mapping and assembling SMRT and ONT reads without an error correction
stage. They can often assemble a sequencing run of bacterial data into a single
contig in a few minutes, and assemble 45-fold Caenorhabditis elegans data in
9 min, orders of magnitude faster than the existing pipelines, though the
consensus sequence error rate is as high as raw reads. We also introduce a
pairwise read mapping format and a graphical fragment assembly format, and
demonstrate the interoperability between ours and current tools.
AVAILABILITY AND IMPLEMENTATION: https://github.com/lh3/minimap and
https://github.com/lh3/miniasm
CONTACT: hengli@broadinstitute.org
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw152 
PMCID: PMC4937194 [Available on 2017-07-15]
PMID: 27153593  [PubMed - in process]


562. Bioinformatics. 2016 Jul 15;32(14):2202-4. doi: 10.1093/bioinformatics/btw149.
Epub 2016 Mar 18.

chopBAI: BAM index reduction solves I/O bottlenecks in the joint analysis of
large sequencing cohorts.

Kehr B(1), Melsted P(2).

Author information: 
(1)deCODE Genetics/Amgen, Reykjavík, Iceland. (2)deCODE Genetics/Amgen,
Reykjavík, Iceland Faculty of Industrial Engineering, Mechanical Engineering and 
Computer Science, University of Iceland, Reykjavík, Iceland.

Advances in sequencing capacity have led to the generation of unprecedented
amounts of genomic data. The processing of this data frequently leads to I/O
bottlenecks, e. g. when analyzing a small genomic region across a large number of
samples. The largest I/O burden is, however, often not imposed by the amount of
data needed for the analysis but rather by index files that help retrieving this 
data. We have developed chopBAI, a program that can chop a BAM index (BAI) file
into small pieces. The program outputs a list of BAI files each indexing a
specified genomic interval. The output files are much smaller in size but
maintain compatibility with existing software tools. We show how preprocessing
BAI files with chopBAI can lead to a reduction of I/O by more than 95% during the
analysis of 10 kb genomic regions, eventually enabling the joint analysis of more
than 10 000 individuals.AVAILABILITY AND IMPLEMENTATION: The software is
implemented in C ++, GPL licensed and available at
http://github.com/DecodeGenetics/chopBAIContact:birte.kehr@decode.is.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw149 
PMID: 27153590  [PubMed - in process]


563. Bioinformatics. 2016 Jul 15;32(14):2224-6. doi: 10.1093/bioinformatics/btw147.
Epub 2016 Mar 18.

Ferret: a user-friendly Java tool to extract data from the 1000 Genomes Project.

Limou S(1), Taverner AM(2), Winkler CA(1).

Author information: 
(1)Molecular Genetic Epidemiology Section, Basic Research Laboratory, Basic
Science Program, NCI, Leidos Biomedical Research, Inc., Frederick National
Laboratory, Frederick, MD 21702, USA. (2)Molecular Genetic Epidemiology Section, 
Basic Research Laboratory, Basic Science Program, NCI, Leidos Biomedical
Research, Inc., Frederick National Laboratory, Frederick, MD 21702, USA
Quantitative and Computational Biology program, Princeton University, Princeton, 
NJ 08544, USA.

The 1000 Genomes (1KG) Project provides a near-comprehensive resource on human
genetic variation in worldwide reference populations. 1KG variants can be
accessed through a browser and through the raw and annotated data that are
regularly released on an ftp server. We developed Ferret, a user-friendly Java
tool, to easily extract genetic variation information from these large and
complex data files. From a locus, gene(s) or SNP(s) of interest, Ferret retrieves
genotype data for 1KG SNPs and indels, and computes allelic frequencies for 1KG
populations and optionally, for the Exome Sequencing Project populations. By
converting the 1KG data into files that can be imported into popular pre-existing
tools (e.g. PLINK and HaploView), Ferret offers a straightforward way, even for
non-bioinformatics specialists, to manipulate, explore and merge 1KG data with
the user's dataset, as well as visualize linkage disequilibrium pattern, infer
haplotypes and design tagSNPs.AVAILABILITY AND IMPLEMENTATION: Ferret tool and
source code are publicly available at http://limousophie35.github.io/Ferret/
CONTACT: ferret@nih.gov
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

Published by Oxford University Press 2016. This work is written by US Government 
employees and is in the public domain in the US.

DOI: 10.1093/bioinformatics/btw147 
PMCID: PMC4937191 [Available on 2017-07-15]
PMID: 27153588  [PubMed - in process]


564. Bioinformatics. 2016 Jul 15;32(14):2199-201. doi: 10.1093/bioinformatics/btw144. 
Epub 2016 Mar 15.

MeCorS: Metagenome-enabled error correction of single cell sequencing reads.

Bremges A(1), Singer E(2), Woyke T(2), Sczyrba A(1).

Author information: 
(1)Center for Biotechnology and Faculty of Technology, Bielefeld University,
Bielefeld 33615, Germany U.S. Department of Energy Joint Genome Institute, Walnut
Creek, CA 94598, USA. (2)U.S. Department of Energy Joint Genome Institute, Walnut
Creek, CA 94598, USA.

We present a new tool, MeCorS, to correct chimeric reads and sequencing errors in
Illumina data generated from single amplified genomes (SAGs). It uses sequence
information derived from accompanying metagenome sequencing to accurately correct
errors in SAG reads, even from ultra-low coverage regions. In evaluations on real
data, we show that MeCorS outperforms BayesHammer, the most widely used
state-of-the-art approach. MeCorS performs particularly well in correcting
chimeric reads, which greatly improves both accuracy and contiguity of de novo
SAG assemblies.AVAILABILITY AND IMPLEMENTATION:
https://github.com/metagenomics/MeCorS CONTACT: abremges@cebitec.uni-bielefeld.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw144 
PMCID: PMC4937190
PMID: 27153586  [PubMed - in process]


565. Bioinformatics. 2016 Jul 15;32(14):2196-8. doi: 10.1093/bioinformatics/btw142.
Epub 2016 Mar 15.

LS-GKM: a new gkm-SVM for large-scale datasets.

Lee D(1).

Author information: 
(1)McKusick-Nathans Institute of Genetic Medicine, Johns Hopkins University,
Baltimore, MD 21205, USA.

gkm-SVM is a sequence-based method for predicting and detecting the regulatory
vocabulary encoded in functional DNA elements, and is a commonly used tool for
studying gene regulatory mechanisms. Here we introduce new software, LS-GKM,
which removes several limitations of our previous releases, enabling training on 
much larger scale (LS) datasets. LS-GKM also provides additional advanced gapped 
k-mer based kernel functions. With these improvements, LS-GKM achieves
considerably higher accuracy than the original gkm-SVM.AVAILABILITY AND
IMPLEMENTATION: C/C ++ source codes and related scripts are freely available from
http://github.com/Dongwon-Lee/lsgkm/, and supported on Linux and Mac OS X.
CONTACT: dwlee@jhu.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw142 
PMCID: PMC4937189 [Available on 2017-07-15]
PMID: 27153584  [PubMed - in process]


566. Bioinformatics. 2016 Aug 1;32(15):2248-55. doi: 10.1093/bioinformatics/btw138.
Epub 2016 Mar 11.

D3M: detection of differential distributions of methylation levels.

Matsui Y(1), Mizuta M(2), Ito S(3), Miyano S(3), Shimamura T(1).

Author information: 
(1)Nagoya University Graduate School of Medicine, Nagoya 466-8550, Japan.
(2)Information Initiative Center, Hokkaido University, Sapporo 060-0811, Japan.
(3)Institute of Medical Science, The University of Tokyo, Tokyo 108-8639, Japan.

MOTIVATION: DNA methylation is an important epigenetic modification related to a 
variety of diseases including cancers. We focus on the methylation data from
Illumina's Infinium HumanMethylation450 BeadChip. One of the key issues of
methylation analysis is to detect the differential methylation sites between case
and control groups. Previous approaches describe data with simple summary
statistics or kernel function, and then use statistical tests to determine the
difference. However, a summary statistics-based approach cannot capture
complicated underlying structure, and a kernel function-based approach lacks
interpretability of results.
RESULTS: We propose a novel method D(3)M, for detection of differential
distribution of methylation, based on distribution-valued data. Our method can
detect the differences in high-order moments, such as shapes of underlying
distributions in methylation profiles, based on the Wasserstein metric. We test
the significance of the difference between case and control groups and provide an
interpretable summary of the results. The simulation results show that the
proposed method achieves promising accuracy and shows favorable results compared 
with previous methods. Glioblastoma multiforme and lower grade glioma data from
The Cancer Genome Atlas show that our method supports recent biological advances 
and suggests new insights.
AVAILABILITY AND IMPLEMENTATION: R implemented code is freely available from
https://github.com/ymatts/D3M/ CONTACT: ymatsui@med.nagoya-u.ac.jp or
shimamura@med.nagoya-u.ac.jp
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw138 
PMID: 27153581  [PubMed - in process]


567. Bioinformatics. 2016 Aug 1;32(15):2346-51. doi: 10.1093/bioinformatics/btw136.
Epub 2016 Mar 12.

ARGs-OAP: online analysis pipeline for antibiotic resistance genes detection from
metagenomic data using an integrated structured ARG-database.

Yang Y(1), Jiang X(2), Chai B(3), Ma L(2), Li B(2), Zhang A(2), Cole JR(3),
Tiedje JM(3), Zhang T(2).

Author information: 
(1)Environmental Biotechnology Laboratory, Department of Civil Engineering, The
University of Hong Kong, Hong Kong, China School of Marine Sciences, Sun Yat-Sen 
University, Guangzhou, China. (2)Environmental Biotechnology Laboratory,
Department of Civil Engineering, The University of Hong Kong, Hong Kong, China.
(3)Department of Plant, Soil, and Microbial Sciences, Michigan State University, 
East Lansing, MI, USA.

MOTIVATION: Environmental dissemination of antibiotic resistance genes (ARGs) has
become an increasing concern for public health. Metagenomics approaches can
effectively detect broad profiles of ARGs in environmental samples; however, the 
detection and subsequent classification of ARG-like sequences are time consuming 
and have been severe obstacles in employing metagenomic methods. We sought to
accelerate quantification of ARGs in metagenomic data from environmental samples.
RESULTS: A Structured ARG reference database (SARG) was constructed by
integrating ARDB and CARD, the two most commonly used databases. SARG was curated
to remove redundant sequences and optimized to facilitate query sequence
identification by similarity. A database with a hierarchical structure
(type-subtype-reference sequence) was then constructed to facilitate
classification (assigning ARG-like sequence to type, subtype and reference
sequence) of sequences identified through similarity search. Utilizing SARG and a
previously proposed hybrid functional gene annotation pipeline, we developed an
online pipeline called ARGs-OAP for fast annotation and classification of
ARG-like sequences from metagenomic data. We also evaluated and proposed a set of
criteria important for efficiently conducting metagenomic analysis of ARGs using 
ARGs-OAP.
AVAILABILITY AND IMPLEMENTATION: Perl script for ARGs-OAP can be downloaded from 
https://github.com/biofuture/Ublastx_stageone ARGs-OAP can be accessed through
http://smile.hku.hk/SARGs
CONTACT: zhangt@hku.hk or tiedjej@msu.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw136 
PMID: 27153579  [PubMed - in process]


568. Bioinformatics. 2016 Aug 1;32(15):2321-9. doi: 10.1093/bioinformatics/btw131.
Epub 2016 Mar 8.

Analysis of CFSE time-series data using division-, age- and label-structured
population models.

Hross S(1), Hasenauer J(1).

Author information: 
(1)Helmholtz Zentrum München-German Research Center for Environmental Health,
Institute of Computational Biology, Neuherberg 85764, Germany Department of
Mathematical Modeling of Biological Systems, Center for Mathematics, Technische
Universität München, Garching 85748, Germany.

MOTIVATION: In vitro and in vivo cell proliferation is often studied using the
dye carboxyfluorescein succinimidyl ester (CFSE). The CFSE time-series data
provide information about the proliferation history of populations of cells.
While the experimental procedures are well established and widely used, the
analysis of CFSE time-series data is still challenging. Many available analysis
tools do not account for cell age and employ optimization methods that are
inefficient (or even unreliable).
RESULTS: We present a new model-based analysis method for CFSE time-series data. 
This method uses a flexible description of proliferating cell populations,
namely, a division-, age- and label-structured population model. Efficient
maximum likelihood and Bayesian estimation algorithms are introduced to infer the
model parameters and their uncertainties. These methods exploit the forward
sensitivity equations of the underlying partial differential equation model for
efficient and accurate gradient calculation, thereby improving computational
efficiency and reliability compared with alternative approaches and accelerating 
uncertainty analysis. The performance of the method is assessed by studying a
dataset for immune cell proliferation. This revealed the importance of different 
factors on the proliferation rates of individual cells. Among others, the
predominate effect of cell age on the division rate is found, which was not
revealed by available computational methods.
AVAILABILITY AND IMPLEMENTATION: The MATLAB source code implementing the models
and algorithms is available from
http://janhasenauer.github.io/ShAPE-DALSP/Contact:
jan.hasenauer@helmholtz-muenchen.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw131 
PMID: 27153577  [PubMed - in process]


569. Bioinformatics. 2016 Jul 1;32(13):2050-2. doi: 10.1093/bioinformatics/btw119.
Epub 2016 Mar 7.

Visual Omics Explorer (VOE): a cross-platform portal for interactive data
visualization.

Kim B(1), Ali T(1), Hosmer S(2), Krampis K(3).

Author information: 
(1)Department of Biological Sciences Center for Translational and Basic Research 
and Belfer Research Building, Hunter College of the City University of New York, 
New York, NY, USA. (2)The Graduate Center, City University of New York, New York,
NY, USA. (3)Department of Biological Sciences Center for Translational and Basic 
Research and Belfer Research Building, Hunter College of the City University of
New York, New York, NY, USA The Graduate Center, City University of New York, New
York, NY, USA Department of Physiology and Biophysics, Institute for
Computational Biomedicine, Weil Cornell Medical College, Cornell University, New 
York, NY, USA.

MOTIVATION: Given the abundance of genome sequencing and omics data, an
opprtunity and challenge in bioinformatics relates to data mining and
visualization. The majority of current bioinformatics visualizations are
implemented either as multi-tier web server applications that require significant
maintenance effort, or as client software that presumes technical expertise for
installation. Here we present the Visual Omics Explorer (VOE), a cross-platform
data visualization portal that is implemented using only HTML and Javascript
code. VOE is a standalone software that can be loaded offline on the web browser 
from a local copy of the code, or over the internet without any dependency other 
than distributing the code through a file sharing service. VOE can interactively 
display genomics, transcriptomics, epigenomics and metagenomics data stored
either locally or retrieved from cloud storage services, and runs on both desktop
computers and mobile devices.
AVAILABILITY AND IMPLEMENTATION: VOE is accessible at http://bcil.github.io/VOE/ 
CONTACT: agbiotec@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw119 
PMID: 27153572  [PubMed - in process]


570. Bioinformatics. 2016 Jul 1;32(13):2008-16. doi: 10.1093/bioinformatics/btw107.
Epub 2016 Feb 26.

An algorithm for designing minimal microbial communities with desired metabolic
capacities.

Eng A(1), Borenstein E(2).

Author information: 
(1)Department of Genome Sciences. (2)Department of Genome Sciences Department of 
Computer Science and Engineering, University of Washington, Seattle, WA, USA
Santa Fe Institute, Santa Fe, NM, USA.

MOTIVATION: Recent efforts to manipulate various microbial communities, such as
fecal microbiota transplant and bioreactor systems' optimization, suggest a
promising route for microbial community engineering with numerous medical,
environmental and industrial applications. However, such applications are
currently restricted in scale and often rely on mimicking or enhancing natural
communities, calling for the development of tools for designing synthetic
communities with specific, tailored, desired metabolic capacities.
RESULTS: Here, we present a first step toward this goal, introducing a novel
algorithm for identifying minimal sets of microbial species that collectively
provide the enzymatic capacity required to synthesize a set of desired target
product metabolites from a predefined set of available substrates. Our method
integrates a graph theoretic representation of network flow with the set cover
problem in an integer linear programming (ILP) framework to simultaneously
identify possible metabolic paths from substrates to products while minimizing
the number of species required to catalyze these metabolic reactions. We apply
our algorithm to successfully identify minimal communities both in a set of
simple toy problems and in more complex, realistic settings, and to investigate
metabolic capacities in the gut microbiome. Our framework adds to the growing
toolset for supporting informed microbial community engineering and for
ultimately realizing the full potential of such engineering efforts.
AVAILABILITY AND IMPLEMENTATION: The algorithm source code, compilation, usage
instructions and examples are available under a non-commercial research use only 
license at https://github.com/borenstein-lab/CoMiDA CONTACT: elbo@uw.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw107 
PMCID: PMC4920118 [Available on 2017-07-01]
PMID: 27153571  [PubMed - in process]


571. Bioinformatics. 2016 Jul 1;32(13):1921-4. doi: 10.1093/bioinformatics/btw101.
Epub 2016 Feb 24.

Alpha-CENTAURI: assessing novel centromeric repeat sequence variation with long
read sequencing.

Sevim V(1), Bashir A(2), Chin CS(1), Miga KH(3).

Author information: 
(1)Pacific Biosciences, Inc., Menlo Park, CA 94025, USA. (2)Department of
Genetics and Genomic Sciences, Icahn School of Medicine at Mount Sinai, 1425
Madison Avenue, New York, NY 10029, USA Icahn Institute for Genomics and
Multiscale Biology, Icahn School of Medicine at Mount Sinai, 1425 Madison Avenue,
New York, NY 10029, USA. (3)Center for Biomolecular Science and Engineering,
University of California, Santa Cruz, CA 95064, USA.

MOTIVATION: Long arrays of near-identical tandem repeats are a common feature of 
centromeric and subtelomeric regions in complex genomes. These sequences present 
a source of repeat structure diversity that is commonly ignored by standard
genomic tools. Unlike reads shorter than the underlying repeat structure that
rely on indirect inference methods, e.g. assembly, long reads allow direct
inference of satellite higher order repeat structure. To automate
characterization of local centromeric tandem repeat sequence variation we have
designed Alpha-CENTAURI (ALPHA satellite CENTromeric AUtomated Repeat
Identification), that takes advantage of Pacific Bioscience long-reads from
whole-genome sequencing datasets. By operating on reads prior to assembly, our
approach provides a more comprehensive set of repeat-structure variants and is
not impacted by rearrangements or sequence underrepresentation due to
misassembly.
RESULTS: We demonstrate the utility of Alpha-CENTAURI in characterizing repeat
structure for alpha satellite containing reads in the hydatidiform mole (CHM1,
haploid-like) genome. The pipeline is designed to report local repeat
organization summaries for each read, thereby monitoring rearrangements in repeat
units, shifts in repeat orientation and sites of array transition into
non-satellite DNA, typically defined by transposable element insertion. We
validate the method by showing consistency with existing centromere high order
repeat references. Alpha-CENTAURI can, in principle, run on any sequence data,
offering a method to generate a sequence repeat resolution that could be readily 
performed using consensus sequences available for other satellite families in
genomes without high-quality reference assemblies.
AVAILABILITY AND IMPLEMENTATION: Documentation and source code for Alpha-CENTAURI
are freely available at http://github.com/volkansevim/alpha-CENTAURI CONTACT:
ali.bashir@mssm.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw101 
PMCID: PMC4920115
PMID: 27153570  [PubMed - in process]


572. BMC Bioinformatics. 2016 May 4;17(1):199. doi: 10.1186/s12859-016-1058-x.

TopHat-Recondition: a post-processor for TopHat unmapped reads.

Brueffer C(1), Saal LH(2).

Author information: 
(1)Division of Oncology and Pathology, Department of Clinical Sciences, Lund
University Cancer Center, Lund University, Medicon Village Building 404-B2, Lund,
223 81, Sweden. (2)Division of Oncology and Pathology, Department of Clinical
Sciences, Lund University Cancer Center, Lund University, Medicon Village
Building 404-B2, Lund, 223 81, Sweden. lao.saal@med.lu.se.

BACKGROUND: TopHat is a popular spliced junction mapper for RNA sequencing data, 
and writes files in the BAM format - the binary version of the Sequence
Alignment/Map (SAM) format. BAM is the standard exchange format for aligned
sequencing reads, thus correct format implementation is paramount for software
interoperability and correct analysis. However, TopHat writes its unmapped reads 
in a way that is not compatible with other software that implements the SAM/BAM
format.
RESULTS: We have developed TopHat-Recondition, a post-processor for TopHat
unmapped reads that restores read information in the proper format.
TopHat-Recondition thus enables downstream software to process the plethora of
BAM files written by TopHat.
CONCLUSIONS: TopHat-Recondition can repair unmapped read files written by TopHat 
and is freely available under a 2-clause BSD license on GitHub:
https://github.com/cbrueffer/tophat-recondition .

DOI: 10.1186/s12859-016-1058-x 
PMCID: PMC4855331
PMID: 27142976  [PubMed - in process]


573. Version 2. F1000Res. 2016 Apr 13 [revised 2016 May 9];5:672. doi:
10.12688/f1000research.8382.2. eCollection 2016.

Closing gaps between open software and public data in a hackathon setting:
User-centered software prototyping.

Busby B(1), Lesko M(1); August 2015 and January 2016 Hackathon participants,
Federer L(2).

Author information: 
(1)National Center for Biotechnology Information (NCBI), National Library of
Medicine, National Institutes of Health, Bethesda, MD, USA. (2)NIH Library,
Division of Library Services, Office of Research Services, National Institutes of
Health, Bethesda, MD, USA.

In genomics, bioinformatics and other areas of data science, gaps exist between
extant public datasets and the open-source software tools built by the community 
to analyze similar data types.  The purpose of biological data science hackathons
is to assemble groups of genomics or bioinformatics professionals and software
developers to rapidly prototype software to address these gaps.  The only two
rules for the NCBI-assisted hackathons run so far are that 1) data either must be
housed in public data repositories or be deposited to such repositories shortly
after the hackathon's conclusion, and 2) all software comprising the final
pipeline must be open-source or open-use.  Proposed topics, as well as suggested 
tools and approaches, are distributed to participants at the beginning of each
hackathon and refined during the event.  Software, scripts, and pipelines are
developed and published on GitHub, a web service providing publicly available,
free-usage tiers for collaborative software development. The code resulting from 
each hackathon is published at https://github.com/NCBI-Hackathons/ with separate 
directories or repositories for each team.

DOI: 10.12688/f1000research.8382.2 
PMCID: PMC4837979
PMID: 27134733  [PubMed]


574. Nucleic Acids Res. 2016 Jul 8;44(12):e113. doi: 10.1093/nar/gkw294. Epub 2016 Apr
29.

Redundans: an assembly pipeline for highly heterozygous genomes.

Pryszcz LP(1), Gabaldón T(2).

Author information: 
(1)Centre for Genomic Regulation (CRG), The Barcelona Institute of Science and
Technology, Dr. Aiguader 88, Barcelona 08003, Spain International Institute of
Molecular and Cell Biology, Warsaw, Poland. (2)Centre for Genomic Regulation
(CRG), The Barcelona Institute of Science and Technology, Dr. Aiguader 88,
Barcelona 08003, Spain Universitat Pompeu Fabra (UPF), 08003 Barcelona, Spain
Institució Catalana de Recerca i Estudis Avançats (ICREA), Pg. Lluís Companys 23,
08010 Barcelona, Spain tgabaldon@crg.es.

Many genomes display high levels of heterozygosity (i.e. presence of different
alleles at the same loci in homologous chromosomes), being those of hybrid
organisms an extreme such case. The assembly of highly heterozygous genomes from 
short sequencing reads is a challenging task because it is difficult to
accurately recover the different haplotypes. When confronted with highly
heterozygous genomes, the standard assembly process tends to collapse homozygous 
regions and reports heterozygous regions in alternative contigs. The boundaries
between homozygous and heterozygous regions result in multiple assembly paths
that are hard to resolve, which leads to highly fragmented assemblies with a
total size larger than expected. This, in turn, causes numerous problems in
downstream analyses such as fragmented gene models, wrong gene copy number, or
broken synteny. To circumvent these caveats we have developed a pipeline that
specifically deals with the assembly of heterozygous genomes by introducing a
step to recognise and selectively remove alternative heterozygous contigs. We
tested our pipeline on simulated and naturally-occurring heterozygous genomes and
compared its accuracy to other existing tools. Our method is freely available at 
https://github.com/Gabaldonlab/redundans.

© The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkw294 
PMCID: PMC4937319
PMID: 27131372  [PubMed - in process]


575. Behav Res Methods. 2016 Apr 29. [Epub ahead of print]

SwarmSight: Measuring the temporal progression of animal group activity levels
from natural-scene and laboratory videos.

Birgiolas J(1), Jernigan CM(2), Smith BH(2), Crook SM(2,)(3).

Author information: 
(1)School of Life Sciences, Arizona State University, P.O. Box 874601, Tempe, AZ,
85287-4601, USA. justas@asu.edu. (2)School of Life Sciences, Arizona State
University, P.O. Box 874601, Tempe, AZ, 85287-4601, USA. (3)School of
Mathematical and Statistical Sciences, Arizona State University, Tempe, AZ, USA.

We describe SwarmSight (available at https://github.com/justasb/SwarmSight ), a
novel, open-source, Microsoft Windows software tool for quantitative assessment
of the temporal progression of animal group activity levels from recorded videos.
The tool utilizes a background subtraction machine vision algorithm and provides 
an activity metric that can be used to quantitatively assess and compare animal
group behavior. Here we demonstrate the tool's utility by analyzing defensive bee
behavior as modulated by alarm pheromones, wild-bird feeding onset and
interruption, and cockroach nest-finding activity. Although more sophisticated,
commercial software packages are available, SwarmSight provides a low-cost,
open-source, and easy-to-use alternative that is suitable for a wide range of
users, including minimally trained research technicians and behavioral science
undergraduate students in classroom laboratory settings.

DOI: 10.3758/s13428-016-0732-2 
PMCID: PMC5086309 [Available on 2017-10-29]
PMID: 27130170  [PubMed - as supplied by publisher]


576. BMC Bioinformatics. 2016 Apr 27;17:190. doi: 10.1186/s12859-016-1057-y.

ImiRP: a computational approach to microRNA target site mutation.

Ryan BC(1), Werner TS(1), Howard PL(1,)(2), Chow RL(3).

Author information: 
(1)Department of Biology, University of Victoria, Victoria, BC, V8W 3N5, Canada. 
(2)Department of Biochemistry and Microbiology, University of Victoria, Victoria,
BC, V8W 3N5, Canada. (3)Department of Biology, University of Victoria, Victoria, 
BC, V8W 3N5, Canada. bobchow@uvic.ca.

BACKGROUND: MicroRNAs (miRNAs) are small ~22 nucleotide non-coding RNAs that
function as post-transcriptional regulators of messenger RNA (mRNA) through
base-pairing to 6-8 nucleotide long target sites, usually located within the mRNA
3' untranslated region. A common approach to validate and probe microRNA-mRNA
interactions is to mutate predicted target sites within the mRNA and determine
whether it affects miRNA-mediated activity. The introduction of miRNA target site
mutations, however, is potentially problematic as it may generate new,
"illegitimate sites" target sites for other miRNAs, which may affect the
experimental outcome. While it is possible to manually generate and check single 
miRNA target site mutations, this process can be time consuming, and becomes
particularly onerous and error prone when multiple sites are to be mutated
simultaneously. We have developed a modular Java-based system called ImiRP
(Illegitimate miRNA Predictor) to solve this problem and to facilitate miRNA
target site mutagenesis.
RESULTS: The ImiRP interface allows users to input a sequence of interest,
specify the locations of multiple predicted target sites to mutate, and set
parameters such as species, mutation strategy, and disallowed illegitimate target
site types. As mutant sequences are generated, ImiRP utilizes the miRBase high
confidence miRNA dataset to identify illegitimate target sites in each mutant
sequence by comparing target site predictions between input and mutant sequences.
ImiRP then assembles a final mutant sequence in which all specified target sites 
have been mutated.
CONCLUSIONS: ImiRP is a mutation generator program that enables selective
disruption of specified miRNA target sites while ensuring predicted target sites 
for other miRNAs are not inadvertently created. ImiRP supports mutagenesis of
single and multiple miRNA target sites within a given sequence, including sites
that overlap. This software will be particularly useful for studies looking at
microRNA cooperativity, where mutagenesis of multiple microRNA target sites may
be desired. The software is available at imirp.org and is available open source
for download through GitHub ( https://github.com/imirp ).

DOI: 10.1186/s12859-016-1057-y 
PMCID: PMC4848830
PMID: 27122020  [PubMed - indexed for MEDLINE]


577. Anal Chem. 2016 Jun 7;88(11):5725-32. doi: 10.1021/acs.analchem.5b04858. Epub
2016 May 23.

Automated Glycan Sequencing from Tandem Mass Spectra of N-Linked Glycopeptides.

Yu CY(1), Mayampurath A(2), Zhu R(3), Zacharias L(3), Song E(3), Wang L(1),
Mechref Y(3), Tang H(1).

Author information: 
(1)School of Informatics and Computing, Indiana University , 150 South Woodlawn
Avenue, Bloomington, Indiana 47405, United States. (2)Computation Institute,
University of Chicago , Chicago, Illinois 60637, United States. (3)Department of 
Chemistry and Biochemistry, Texas Tech University , Lubbock, Texas 79409, United 
States.

Mass spectrometry has become a routine experimental tool for proteomic biomarker 
analysis of human blood samples, partly due to the large availability of
informatics tools. As one of the most common protein post-translational
modifications (PTMs) in mammals, protein glycosylation has been observed to alter
in multiple human diseases and thus may potentially be candidate markers of
disease progression. While mass spectrometry instrumentation has seen
advancements in capabilities, discovering glycosylation-related markers using
existing software is currently not straightforward. Complete characterization of 
protein glycosylation requires the identification of intact glycopeptides in
samples, including identification of the modification site as well as the
structure of the attached glycans. In this paper, we present GlycoSeq, an
open-source software tool that implements a heuristic iterated glycan sequencing 
algorithm coupled with prior knowledge for automated elucidation of the glycan
structure within a glycopeptide from its collision-induced dissociation tandem
mass spectrum. GlycoSeq employs rules of glycosidic linkage as defined by glycan 
synthetic pathways to eliminate improbable glycan structures and build reasonable
glycan trees. We tested the tool on two sets of tandem mass spectra of N-linked
glycopeptides cell lines acquired from breast cancer patients. After employing
enzymatic specificity within the N-linked glycan synthetic pathway, the
sequencing results of GlycoSeq were highly consistent with the manually curated
glycan structures. Hence, GlycoSeq is ready to be used for the characterization
of glycan structures in glycopeptides from MS/MS analysis. GlycoSeq is released
as open source software at https://github.com/chpaul/GlycoSeq/ .

DOI: 10.1021/acs.analchem.5b04858 
PMCID: PMC4899231
PMID: 27111718  [PubMed - in process]


578. J Mol Model. 2016 May;22(5):110. doi: 10.1007/s00894-016-2983-3. Epub 2016 Apr
23.

Kudi: A free open-source python library for the analysis of properties along
reaction paths.

Vogt-Geisse S(1,)(2).

Author information: 
(1)Nucleus Millennium Chemical Processes and Catalysis; Laboratorio de Química
Teórica Computacional (QTC), Departamento de Química-Física, Facultad de Química,
Pontificia Universidad Católica de Chile, Av. Vicuña Mackenna 4860, Macul,
Santiago, 9900087, Chile. savogt@uc.cl. (2)Departamento de Fisicoquímica,
Facultad de Ciencias Químicas, Universidad de Concepción, Casilla 160-C,
Concepción, Chile. savogt@uc.cl.

With increasing computational capabilities, an ever growing amount of data is
generated in computational chemistry that contains a vast amount of chemically
relevant information. It is therefore imperative to create new computational
tools in order to process and extract this data in a sensible way. Kudi is an
open source library that aids in the extraction of chemical properties from
reaction paths. The straightforward structure of Kudi makes it easy to use for
users and allows for effortless implementation of new capabilities, and extension
to any quantum chemistry package. A use case for Kudi is shown for the
tautomerization reaction of formic acid. Kudi is available free of charge at
www.github.com/stvogt/kudi.

DOI: 10.1007/s00894-016-2983-3 
PMID: 27107577  [PubMed]


579. Nucleic Acids Res. 2016 Jul 8;44(12):e111. doi: 10.1093/nar/gkw281. Epub 2016 Apr
21.

InPhaDel: integrative shotgun and proximity-ligation sequencing to phase
deletions with single nucleotide polymorphisms.

Patel A(1), Edge P(2), Selvaraj S(3), Bansal V(4), Bafna V(5).

Author information: 
(1)Bioinformatics and Systems Biology Program, University of California, San
Diego 9500 Gilman Drive, La Jolla, CA 92093, USA Department of Computer Science
and Engineering, University of California, San Diego 9500 Gilman Drive, La Jolla,
CA 92093, USA adp002@ucsd.edu. (2)Department of Computer Science and Engineering,
University of California, San Diego 9500 Gilman Drive, La Jolla, CA 92093, USA.
(3)Bioinformatics and Systems Biology Program, University of California, San
Diego 9500 Gilman Drive, La Jolla, CA 92093, USA. (4)Department of Pediatrics,
School of Medicine, University of California, San Diego 9500 Gilman Drive, La
Jolla, CA 92093, USA. (5)Bioinformatics and Systems Biology Program, University
of California, San Diego 9500 Gilman Drive, La Jolla, CA 92093, USA Department of
Computer Science and Engineering, University of California, San Diego 9500 Gilman
Drive, La Jolla, CA 92093, USA.

Phasing of single nucleotide (SNV), and structural variations into
chromosome-wide haplotypes in humans has been challenging, and required either
trio sequencing or restricting phasing to population-based haplotypes. Selvaraj
et al demonstrated single individual SNV phasing is possible with proximity
ligated (HiC) sequencing. Here, we demonstrate HiC can phase structural variants 
into phased scaffolds of SNVs. Since HiC data is noisy, and SV calling is
challenging, we applied a range of supervised classification techniques,
including Support Vector Machines and Random Forest, to phase deletions. Our
approach was demonstrated on deletion calls and phasings on the NA12878 human
genome. We used three NA12878 chromosomes and simulated chromosomes to train
model parameters. The remaining NA12878 chromosomes withheld from training were
used to evaluate phasing accuracy. Random Forest had the highest accuracy and
correctly phased 86% of the deletions with allele-specific read evidence.
Allele-specific read evidence was found for 76% of the deletions. HiC provides
significant read evidence for accurately phasing 33% of the deletions. Also,
eight of eight top ranked deletions phased by only HiC were validated using long 
range polymerase chain reaction and Sanger. Thus, deletions from a single
individual can be accurately phased using a combination of shotgun and proximity 
ligation sequencing. InPhaDel software is available at:
http://l337x911.github.io/inphadel/.

Published by Oxford University Press on behalf of Nucleic Acids Research 2016.
This work is written by (a) US Government employee(s) and is in the public domain
in the US.

DOI: 10.1093/nar/gkw281 
PMCID: PMC4937317
PMID: 27105843  [PubMed - in process]


580. Sci Rep. 2016 Apr 22;6:23901. doi: 10.1038/srep23901.

Clonify: unseeded antibody lineage assignment from next-generation sequencing
data.

Briney B(1,)(2,)(3), Le K(1,)(2,)(3), Zhu J(1,)(2,)(3), Burton DR(1,)(2,)(3,)(4).

Author information: 
(1)Department of Immunology and Microbial Science, The Scripps Research
Institute, La Jolla, CA 92037, USA. (2)International AIDS Vaccine Initiative
Neutralizing Antibody Center, The Scripps Research Institute, La Jolla, CA 92037,
USA. (3)Center for HIV/AIDS Vaccine Immunology and Immunogen Discovery, The
Scripps Research Institute, La Jolla, CA 92037, USA. (4)Ragon Institute of
Massachusetts General Hospital, Massachusetts Institute of Technology, and
Harvard University, Boston, MA 02142, USA.

Defining the dynamics and maturation processes of antibody clonal lineages is
crucial to understanding the humoral response to infection and immunization.
Although individual antibody lineages have been previously analyzed in isolation,
these studies provide only a narrow view of the total antibody response.
Comprehensive study of antibody lineages has been limited by the lack of an
accurate clonal lineage assignment algorithm capable of operating on
next-generation sequencing datasets. To address this shortcoming, we developed
Clonify, which is able to perform unseeded lineage assignment on very large sets 
of antibody sequences. Application of Clonify to IgG+ memory repertoires from
healthy individuals revealed a surprising lack of influence of large extended
lineages on the overall repertoire composition, indicating that this composition 
is driven less by the order and frequency of pathogen encounters than previously 
thought. Clonify is freely available at www.github.com/briney/clonify-python.

DOI: 10.1038/srep23901 
PMCID: PMC4840318
PMID: 27102563  [PubMed - in process]


581. PLoS Comput Biol. 2016 Apr 21;12(4):e1004873. doi: 10.1371/journal.pcbi.1004873. 
eCollection 2016.

CNVkit: Genome-Wide Copy Number Detection and Visualization from Targeted DNA
Sequencing.

Talevich E(1,)(2,)(3), Shain AH(1,)(2,)(3), Botton T(1,)(2,)(3), Bastian
BC(1,)(2,)(3).

Author information: 
(1)Department of Dermatology, University of California, San Francisco, San
Francisco, California, United States of America. (2)Department of Pathology,
University of California, San Francisco, San Francisco, California, United States
of America. (3)Helen Diller Family Comprehensive Cancer Center, University of
California, San Francisco, San Francisco, California, United States of America.

Germline copy number variants (CNVs) and somatic copy number alterations (SCNAs) 
are of significant importance in syndromic conditions and cancer. Massively
parallel sequencing is increasingly used to infer copy number information from
variations in the read depth in sequencing data. However, this approach has
limitations in the case of targeted re-sequencing, which leaves gaps in coverage 
between the regions chosen for enrichment and introduces biases related to the
efficiency of target capture and library preparation. We present a method for
copy number detection, implemented in the software package CNVkit, that uses both
the targeted reads and the nonspecifically captured off-target reads to infer
copy number evenly across the genome. This combination achieves both exon-level
resolution in targeted regions and sufficient resolution in the larger intronic
and intergenic regions to identify copy number changes. In particular, we
successfully inferred copy number at equivalent to 100-kilobase resolution
genome-wide from a platform targeting as few as 293 genes. After normalizing read
counts to a pooled reference, we evaluated and corrected for three sources of
bias that explain most of the extraneous variability in the sequencing read
depth: GC content, target footprint size and spacing, and repetitive sequences.
We compared the performance of CNVkit to copy number changes identified by array 
comparative genomic hybridization. We packaged the components of CNVkit so that
it is straightforward to use and provides visualizations, detailed reporting of
significant features, and export options for integration into existing analysis
pipelines. CNVkit is freely available from https://github.com/etal/cnvkit.

DOI: 10.1371/journal.pcbi.1004873 
PMCID: PMC4839673
PMID: 27100738  [PubMed - indexed for MEDLINE]


582. PLoS Comput Biol. 2016 Apr 20;12(4):e1004879. doi: 10.1371/journal.pcbi.1004879. 
eCollection 2016.

Network-Based Interpretation of Diverse High-Throughput Datasets through the
Omics Integrator Software Package.

Tuncbag N(1), Gosline SJ(1), Kedaigle A(1), Soltis AR(1), Gitter A(1), Fraenkel
E(1).

Author information: 
(1)Department of Biological Engineering, Massachusetts Institute of Technology,
Cambridge, Massachusetts, United States of America.

High-throughput, 'omic' methods provide sensitive measures of biological
responses to perturbations. However, inherent biases in high-throughput assays
make it difficult to interpret experiments in which more than one type of data is
collected. In this work, we introduce Omics Integrator, a software package that
takes a variety of 'omic' data as input and identifies putative underlying
molecular pathways. The approach applies advanced network optimization algorithms
to a network of thousands of molecular interactions to find high-confidence,
interpretable subnetworks that best explain the data. These subnetworks connect
changes observed in gene expression, protein abundance or other global assays to 
proteins that may not have been measured in the screens due to inherent bias or
noise in measurement. This approach reveals unannotated molecular pathways that
would not be detectable by searching pathway databases. Omics Integrator also
provides an elegant framework to incorporate not only positive data, but also
negative evidence. Incorporating negative evidence allows Omics Integrator to
avoid unexpressed genes and avoid being biased toward highly-studied hub
proteins, except when they are strongly implicated by the data. The software is
comprised of two individual tools, Garnet and Forest, that can be run together or
independently to allow a user to perform advanced integration of multiple types
of high-throughput data as well as create condition-specific subnetworks of
protein interactions that best connect the observed changes in various datasets. 
It is available at http://fraenkel.mit.edu/omicsintegrator and on GitHub at
https://github.com/fraenkel-lab/OmicsIntegrator.

DOI: 10.1371/journal.pcbi.1004879 
PMCID: PMC4838263
PMID: 27096930  [PubMed - indexed for MEDLINE]


583. BMC Bioinformatics. 2016 Apr 19;17:172. doi: 10.1186/s12859-016-1016-7.

Growthcurver: an R package for obtaining interpretable metrics from microbial
growth curves.

Sprouffske K(1,)(2), Wagner A(3,)(4,)(5).

Author information: 
(1)Department of Evolutionary Biology and Environmental Studies, University of
Zurich, Winterthurerstrasse 190, Zurich, 8057, Switzerland. (2)Swiss Institute of
Bioinformatics, Quartier Sorge - Batiment Genopode, Lausanne, 1015, Switzerland. 
(3)Department of Evolutionary Biology and Environmental Studies, University of
Zurich, Winterthurerstrasse 190, Zurich, 8057, Switzerland.
andreas.wagner@ieu.uzh.ch. (4)Swiss Institute of Bioinformatics, Quartier Sorge -
Batiment Genopode, Lausanne, 1015, Switzerland. andreas.wagner@ieu.uzh.ch. (5)The
Santa Fe Institute, 1399 Hyde Park Road, Santa Fe, New Mexico, 24105, USA.
andreas.wagner@ieu.uzh.ch.

BACKGROUND: Plate readers can measure the growth curves of many microbial strains
in a high-throughput fashion. The hundreds of absorbance readings collected
simultaneously for hundreds of samples create technical hurdles for data
analysis.
RESULTS: Growthcurver summarizes the growth characteristics of microbial growth
curve experiments conducted in a plate reader. The data are fitted to a standard 
form of the logistic equation, and the parameters have clear interpretations on
population-level characteristics, like doubling time, carrying capacity, and
growth rate.
CONCLUSIONS: Growthcurver is an easy-to-use R package available for installation 
from the Comprehensive R Archive Network (CRAN). The source code is available
under the GNU General Public License and can be obtained from Github (Sprouffske 
K, Growthcurver sourcecode, 2016).

DOI: 10.1186/s12859-016-1016-7 
PMCID: PMC4837600
PMID: 27094401  [PubMed - indexed for MEDLINE]


584. Algorithms Mol Biol. 2016 Apr 14;11:3. doi: 10.1186/s13015-016-0066-8.
eCollection 2016.

Bloom Filter Trie: an alignment-free and reference-free data structure for
pan-genome storage.

Holley G(1), Wittler R(1), Stoye J(1).

Author information: 
(1)Genome Informatics, Faculty of Technology, Bielefeld University, Bielefeld,
Germany ; Center for Biotechnology, Bielefeld University, Bielefeld, Germany ;
International Research Training Group 1906, Bielefeld University, Bielefeld,
Germany.

BACKGROUND: High throughput sequencing technologies have become fast and cheap in
the past years. As a result, large-scale projects started to sequence tens to
several thousands of genomes per species, producing a high number of sequences
sampled from each genome. Such a highly redundant collection of very similar
sequences is called a pan-genome. It can be transformed into a set of sequences
"colored" by the genomes to which they belong. A colored de Bruijn graph (C-DBG) 
extracts from the sequences all colored k-mers, strings of length k, and stores
them in vertices.
RESULTS: In this paper, we present an alignment-free, reference-free and
incremental data structure for storing a pan-genome as a C-DBG: the bloom filter 
trie (BFT). The data structure allows to store and compress a set of colored
k-mers, and also to efficiently traverse the graph. Bloom filter trie was used to
index and query different pangenome datasets. Compared to another
state-of-the-art data structure, BFT was up to two times faster to build while
using about the same amount of main memory. For querying k-mers, BFT was about
52-66 times faster while using about 5.5-14.3 times less memory.
CONCLUSION: We present a novel succinct data structure called the Bloom Filter
Trie for indexing a pan-genome as a colored de Bruijn graph. The trie stores
k-mers and their colors based on a new representation of vertices that compress
and index shared substrings. Vertices use basic data structures for lightweight
substrings storage as well as Bloom filters for efficient trie and graph
traversals. Experimental results prove better performance compared to another
state-of-the-art data structure.
AVAILABILITY: https://www.github.com/GuillaumeHolley/BloomFilterTrie.

DOI: 10.1186/s13015-016-0066-8 
PMCID: PMC4832552
PMID: 27087830  [PubMed]


585. Database (Oxford). 2016 Apr 17;2016. pii: baw051. doi: 10.1093/database/baw051.
Print 2016.

A crowdsourcing workflow for extracting chemical-induced disease relations from
free text.

Li TS(1), Bravo À(2), Furlong LI(2), Good BM(1), Su AI(3).

Author information: 
(1)Department of Molecular and Experimental Medicine, the Scripps Research
Institute, La Jolla, CA 92037, USA. (2)Research Programme on Biomedical
Informatics (GRIB), IMIM, UPF, Barcelona, Spain. (3)Department of Molecular and
Experimental Medicine, the Scripps Research Institute, La Jolla, CA 92037, USA
asu@scripps.edu.

Relations between chemicals and diseases are one of the most queried biomedical
interactions. Although expert manual curation is the standard method for
extracting these relations from the literature, it is expensive and impractical
to apply to large numbers of documents, and therefore alternative methods are
required. We describe here a crowdsourcing workflow for extracting
chemical-induced disease relations from free text as part of the BioCreative V
Chemical Disease Relation challenge. Five non-expert workers on the CrowdFlower
platform were shown each potential chemical-induced disease relation highlighted 
in the original source text and asked to make binary judgments about whether the 
text supported the relation. Worker responses were aggregated through voting, and
relations receiving four or more votes were predicted as true. On the official
evaluation dataset of 500 PubMed abstracts, the crowd attained a 0.505F-score
(0.475 precision, 0.540 recall), with a maximum theoretical recall of 0.751 due
to errors with named entity recognition. The total crowdsourcing cost was
$1290.67 ($2.58 per abstract) and took a total of 7 h. A qualitative error
analysis revealed that 46.66% of sampled errors were due to task limitations and 
gold standard errors, indicating that performance can still be improved. All code
and results are publicly available
athttps://github.com/SuLab/crowd_cid_relexDatabase
URL:https://github.com/SuLab/crowd_cid_relex.

© The Author(s) 2016. Published by Oxford University Press.

DOI: 10.1093/database/baw051 
PMCID: PMC4834205
PMID: 27087308  [PubMed - indexed for MEDLINE]


586. Int J Epidemiol. 2016 Apr;45(2):402-7. doi: 10.1093/ije/dyw047. Epub 2016 Apr 16.

Software Application Profile: RVPedigree: a suite of family-based rare variant
association tests for normally and non-normally distributed quantitative traits.

Oualkacha K(1), Lakhal-Chaieb L(2), Greenwood CM(3).

Author information: 
(1)Départment de mathématiques, Université du Québec à Montréal, QC, Canada
celia.greenwood@mcgill.ca. (2)Département de mathématiques et de statistique,
Université Laval, Québec, QC, Canada. (3)Lady Davis Institute, Jewish General
Hospital, Montréal, QC, Canada Departments of Oncology, Epidemiology,
Biostatistics & Occupational Health, and Human Genetics, McGill University,
Montreal, QC, Canada Ludmer Centre for Neuroinformatics and Mental Health,
Montreal, QC, Canada celia.greenwood@mcgill.ca.

MOTIVATION: RVPedigree (Rare Variant association tests in Pedigrees) implements a
suite of programs facilitating genome-wide analysis of association between a
quantitative trait and autosomal region-based genetic variation. The main
features here are the ability to appropriately test for association of rare
variants with non-normally distributed quantitative traits, and also to
appropriately adjust for related individuals, either from families or from
population structure and cryptic relatedness.
IMPLEMENTATION: RVPedigree is available as an R package.
GENERAL FEATURES: The package includes calculation of kinship matrices, various
options for coping with non-normality, three different ways of estimating
statistical significance incorporating triaging to enable efficient use of the
most computationally-intensive calculations, and a parallelization option for
genome-wide analysis.
AVAILABILITY: The software is available from the Comprehensive R Archive Network 
[CRAN.R-project.org] under the name 'RVPedigree' and at
[https://github.com/GreenwoodLab]. It has been published under General Public
License (GPL) version 3 or newer.

© The Author 2016; all rights reserved. Published by Oxford University Press on
behalf of the International Epidemiological Association.

DOI: 10.1093/ije/dyw047 
PMID: 27085080  [PubMed - in process]


587. Nucleic Acids Res. 2016 Jun 20;44(11):e107. doi: 10.1093/nar/gkw226. Epub 2016
Apr 15.

DanQ: a hybrid convolutional and recurrent deep neural network for quantifying
the function of DNA sequences.

Quang D(1), Xie X(2).

Author information: 
(1)Department of Computer Science University of California, Irvine, CA 92697, USA
Center for Complex Biological Systems University of California, Irvine, CA 92697,
USA. (2)Department of Computer Science University of California, Irvine, CA
92697, USA Center for Complex Biological Systems University of California,
Irvine, CA 92697, USA xhx@uci.edu.

Modeling the properties and functions of DNA sequences is an important, but
challenging task in the broad field of genomics. This task is particularly
difficult for non-coding DNA, the vast majority of which is still poorly
understood in terms of function. A powerful predictive model for the function of 
non-coding DNA can have enormous benefit for both basic science and translational
research because over 98% of the human genome is non-coding and 93% of
disease-associated variants lie in these regions. To address this need, we
propose DanQ, a novel hybrid convolutional and bi-directional long short-term
memory recurrent neural network framework for predicting non-coding function de
novo from sequence. In the DanQ model, the convolution layer captures regulatory 
motifs, while the recurrent layer captures long-term dependencies between the
motifs in order to learn a regulatory 'grammar' to improve predictions. DanQ
improves considerably upon other models across several metrics. For some
regulatory markers, DanQ can achieve over a 50% relative improvement in the area 
under the precision-recall curve metric compared to related models. We have made 
the source code available at the github repository
http://github.com/uci-cbcl/DanQ.

© The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkw226 
PMCID: PMC4914104
PMID: 27084946  [PubMed - in process]


588. Genome Biol. 2016 Apr 15;17:70. doi: 10.1186/s13059-016-0930-3.

Beyond comparisons of means: understanding changes in gene expression at the
single-cell level.

Vallejos CA(1,)(2), Richardson S(3), Marioni JC(4,)(5).

Author information: 
(1)MRC Biostatistics Unit, Cambridge Institute of Public Health, Cambridge, UK.
catalina.vallejos@mrc-bsu.cam.ac.uk. (2)EMBL European Bioinformatics Institute,
Wellcome Trust Genome Campus, Cambridge, UK. catalina.vallejos@mrc-bsu.cam.ac.uk.
(3)MRC Biostatistics Unit, Cambridge Institute of Public Health, Cambridge, UK.
sylvia.richardson@mrc-bsu.cam.ac.uk. (4)EMBL European Bioinformatics Institute,
Wellcome Trust Genome Campus, Cambridge, UK. marioni@ebi.ac.uk. (5)Cancer
Research UK Cambridge Institute, University of Cambridge, Li Ka Shing Centre,
Cambridge, UK. marioni@ebi.ac.uk.

Traditional differential expression tools are limited to detecting changes in
overall expression, and fail to uncover the rich information provided by
single-cell level data sets. We present a Bayesian hierarchical model that builds
upon BASiCS to study changes that lie beyond comparisons of means, incorporating 
built-in normalization and quantifying technical artifacts by borrowing
information from spike-in genes. Using a probabilistic approach, we highlight
genes undergoing changes in cell-to-cell heterogeneity but whose overall
expression remains unchanged. Control experiments validate our method's
performance and a case study suggests that novel biological insights can be
revealed. Our method is implemented in R and available at
https://github.com/catavallejos/BASiCS.

DOI: 10.1186/s13059-016-0930-3 
PMCID: PMC4832562
PMID: 27083558  [PubMed - in process]


589. PLoS One. 2016 Apr 15;11(4):e0153658. doi: 10.1371/journal.pone.0153658.
eCollection 2016.

Infinity: An In-Silico Tool for Genome-Wide Prediction of Specific DNA Matrices
in miRNA Genomic Loci.

Falcone E(1), Grandoni L(2), Garibaldi F(1), Manni I(1), Filligoi G(2), Piaggio
G(1), Gurtner A(1).

Author information: 
(1)Department of Research, Advanced Diagnostics, and Technological Innovation,
Regina Elena National Cancer Institute, Rome, Italy. (2)Department of Information
Engineering, Electronics and Telecommunications (DIET), Faculty of Information
Engineering, Statistics and Informatics, University Sapienza, Rome, Italy.

MOTIVATION: miRNAs are potent regulators of gene expression and modulate multiple
cellular processes in physiology and pathology. Deregulation of miRNAs expression
has been found in various cancer types, thus, miRNAs may be potential targets for
cancer therapy. However, the mechanisms through which miRNAs are regulated in
cancer remain unclear. Therefore, the identification of transcriptional
factor-miRNA crosstalk is one of the most update aspects of the study of miRNAs
regulation.
RESULTS: In the present study we describe the development of a fast and
user-friendly software, named infinity, able to find the presence of DNA
matrices, such as binding sequences for transcriptional factors, on ~65kb
(kilobase) of 939 human miRNA genomic sequences, simultaneously. Of note, the
power of this software has been validated in vivo by performing chromatin
immunoprecipitation assays on a subset of new in silico identified target
sequences (CCAAT) for the transcription factor NF-Y on colon cancer deregulated
miRNA loci. Moreover, for the first time, we have demonstrated that NF-Y, through
its CCAAT binding activity, regulates the expression of miRNA-181a, -181b, -21,
-17, -130b, -301b in colon cancer cells.
CONCLUSIONS: The infinity software that we have developed is a powerful tool to
underscore new TF/miRNA regulatory networks.
AVAILABILITY AND IMPLEMENTATION: Infinity was implemented in pure Java using
Eclipse framework, and runs on Linux and MS Windows machine, with MySQL database.
The software is freely available on the web at
https://github.com/bio-devel/infinity. The website is implemented in JavaScript, 
PHP and HTML with all major browsers supported.

DOI: 10.1371/journal.pone.0153658 
PMCID: PMC4833383
PMID: 27082112  [PubMed - indexed for MEDLINE]


590. Nat Commun. 2016 Apr 15;7:11307. doi: 10.1038/ncomms11307.

Fast and sensitive mapping of nanopore sequencing reads with GraphMap.

Sović I(1,)(2), Šikić M(3,)(4), Wilm A(1), Fenlon SN(1,)(5), Chen S(1,)(6),
Nagarajan N(1).

Author information: 
(1)Computational &Systems Biology, Genome Institute of Singapore, 60 Biopolis
Street, #02-01 Genome, Singapore 138672, Singapore. (2)Centre for Informatics and
Computing, Ruđer Bošković Institute, Bijenička 54, 10000 Zagreb, Croatia.
(3)Faculty of Electrical Engineering and Computing, Department of Electronic
Systems and Information Processing, University of Zagreb, Unska 3, 10000 Zagreb, 
Croatia. (4)Bioinformatics Institute, Singapore 138671, Singapore. (5)Faculty of 
Medicine and Institute for Life Sciences, University of Southampton, Southampton 
SO16 6YD, UK. (6)Division of Infectious Diseases, Department of Medicine, Yong
Loo Lin School of Medicine, National University of Singapore, Singapore 119074,
Singapore.

Realizing the democratic promise of nanopore sequencing requires the development 
of new bioinformatics approaches to deal with its specific error characteristics.
Here we present GraphMap, a mapping algorithm designed to analyse nanopore
sequencing reads, which progressively refines candidate alignments to robustly
handle potentially high-error rates and a fast graph traversal to align long
reads with speed and high precision (>95%). Evaluation on MinION sequencing data 
sets against short- and long-read mappers indicates that GraphMap increases
mapping sensitivity by 10-80% and maps >95% of bases. GraphMap alignments enabled
single-nucleotide variant calling on the human genome with increased sensitivity 
(15%) over the next best mapper, precise detection of structural variants from
length 100 bp to 4 kbp, and species and strain-specific identification of
pathogens using MinION reads. GraphMap is available open source under the MIT
license at https://github.com/isovic/graphmap.

DOI: 10.1038/ncomms11307 
PMCID: PMC4835549
PMID: 27079541  [PubMed - indexed for MEDLINE]


591. BMC Genomics. 2016 Apr 14;17:290. doi: 10.1186/s12864-016-2614-5.

mInDel: a high-throughput and efficient pipeline for genome-wide InDel marker
development.

Lv Y(1), Liu Y(2), Zhao H(3).

Author information: 
(1)Institute of Agricultural Biotechnology, Jiangsu Academy of Agricultural
Sciences, Nanjing, 210014, China. (2)Department of Crop Sciences, University of
Illinois at Urbana-Champaign, Urbana, IL, 61801, USA. (3)Institute of
Agricultural Biotechnology, Jiangsu Academy of Agricultural Sciences, Nanjing,
210014, China. zhaohan@jaas.ac.cn.

BACKGROUND: Rich in genetic information and cost-effective to genotype, the
Insertion-Deletion (InDel) molecular marker system is an important tool for
studies in genetics, genomics and for marker-assisted breeding. Advent of
next-generation sequencing (NGS) revolutionized the speed and throughput of
sequence data generation, and enabled genome-wide identification of insertion and
deletion variation. However, current NGS-based InDel mining tools, such as
Samtools, GATK and Atlas2, all rely on a reference genome for variant calling
which hinders their application on unsequenced organisms and the output of short 
InDels compromised their use on gel-based genotyping platforms. To address these 
issues, an enhanced platform is needed to identify longer InDels and develop
markers in absence of a reference genome.
RESULTS: Here we present mInDel (multiple InDel), a next-generation variant
calling tool specifically designed for InDel marker discovery. By taking in raw
sequence reads and assembling them into contigs de novo, this software identifies
InDel polymorphisms using a sliding window alignment from assembled contigs,
rendering a unique advantage when a reference genome is unavailable. By providing
an option of combining multiple discovered InDels as output, mInDel is amiable to
gel-based genotyping platforms where markers with large polymorphisms are
preferred. We demonstrated the usability and performance of this software through
a case study using a set of maize NGS data, and experimentally validated the
accuracy of markers generated from mInDel.
CONCLUSIONS: mInDel is a novel and practical tool that enables rapid genome-wide 
InDel marker discovery. The features of being independent from a reference genome
and the flexibility with downstream genotyping platforms will allow a broad range
of applications across genetics research and plant breeding. The mInDel pipeline 
is freely available at www.github.com/lyd0527/mInDel .

DOI: 10.1186/s12864-016-2614-5 
PMCID: PMC4832496
PMID: 27079510  [PubMed - indexed for MEDLINE]


592. J Biomed Semantics. 2016 Apr 12;7:18. doi: 10.1186/s13326-016-0060-6. eCollection
2016.

MicrO: an ontology of phenotypic and metabolic characters, assays, and culture
media found in prokaryotic taxonomic descriptions.

Blank CE(1), Cui H(2), Moore LR(3), Walls RL(4).

Author information: 
(1)Department of Geosciences, University of Montana, Missoula, MT 59812 USA.
(2)School of Information, University of Arizona, Tucson, AZ 85719 USA.
(3)Department of Biological Sciences, University of Southern Maine, Portland, ME 
04104 USA. (4)CyVerse, University of Arizona, Tucson, AZ 85721 USA.

BACKGROUND: MicrO is an ontology of microbiological terms, including prokaryotic 
qualities and processes, material entities (such as cell components), chemical
entities (such as microbiological culture media and medium ingredients), and
assays. The ontology was built to support the ongoing development of a natural
language processing algorithm, MicroPIE (or, Microbial Phenomics Information
Extractor). During the MicroPIE design process, we realized there was a need for 
a prokaryotic ontology which would capture the evolutionary diversity of
phenotypes and metabolic processes across the tree of life, capture the diversity
of synonyms and information contained in the taxonomic literature, and relate
microbiological entities and processes to terms in a large number of other
ontologies, most particularly the Gene Ontology (GO), the Phenotypic Quality
Ontology (PATO), and the Chemical Entities of Biological Interest (ChEBI). We
thus constructed MicrO to be rich in logical axioms and synonyms gathered from
the taxonomic literature.
RESULTS: MicrO currently has ~14550 classes (~2550 of which are new, the
remainder being microbiologically-relevant classes imported from other
ontologies), connected by ~24,130 logical axioms (5,446 of which are new), and is
available at (http://purl.obolibrary.org/obo/MicrO.owl) and on the project
website at https://github.com/carrineblank/MicrO. MicrO has been integrated into 
the OBO Foundry Library (http://www.obofoundry.org/ontology/micro.html), so that 
other ontologies can borrow and re-use classes. Term requests and user feedback
can be made using MicrO's Issue Tracker in GitHub. We designed MicrO such that it
can support the ongoing and future development of algorithms that can leverage
the controlled vocabulary and logical inference power provided by the ontology.
CONCLUSIONS: By connecting microbial classes with large numbers of chemical
entities, material entities, biological processes, molecular functions, and
qualities using a dense array of logical axioms, we intend MicrO to be a powerful
new tool to increase the computing power of bioinformatics tools such as the
automated text mining of prokaryotic taxonomic descriptions using natural
language processing. We also intend MicrO to support the development of new
bioinformatics tools that aim to develop new connections between microbial
phenotypes and genotypes (i.e., the gene content in genomes). Future ontology
development will include incorporation of pathogenic phenotypes and prokaryotic
habitats.

DOI: 10.1186/s13326-016-0060-6 
PMCID: PMC4830071
PMID: 27076900  [PubMed - indexed for MEDLINE]


593. BMC Bioinformatics. 2016 Apr 12;17:161. doi: 10.1186/s12859-016-1003-z.

Implementation of a methodology for determining elastic properties of lipid
assemblies from molecular dynamics simulations.

Johner N(1), Harries D(2), Khelashvili G(3).

Author information: 
(1)Swiss Institute of Bioinformatics, Klingelbergstrasse 50/70, Basel,
Switzerland. niklaus.johner@a3.epfl.ch. (2)Institute of Chemistry and the Fritz
Haber Research Center, The Hebrew University, Jerusalem, 91904, Israel.
(3)Department of Physiology and Biophysics, Weill Medical College of Cornell
University, New York, NY, 10065, USA.

Erratum in
    BMC Bioinformatics. 2016;17(1):236.

BACKGROUND: The importance of the material properties of membranes for diverse
cellular processes is well established. Notably, the elastic properties of the
membrane, which depend on its composition, can directly influence membrane
reshaping and fusion processes as well as the organisation and function of
membrane proteins. Determining these properties is therefore key for a
mechanistic understanding of how the cell functions.
RESULTS: We have developed a method to determine the bending rigidity and tilt
modulus, for lipidic assemblies of arbitrary lipid composition and shape, from
molecular dynamics simulations. The method extracts the elastic moduli from the
distributions of microscopic tilts and splays of the lipid components. We present
here an open source implementation of the method as a set of Python modules using
the computational framework OpenStructure. These modules offer diverse algorithms
typically used in the calculatation the elastic moduli, including routines to
align MD trajectories of complex lipidic systems, to determine the water/lipid
interface, to calculate lipid tilts and splays, as well as to fit the
corresponding distributions to extract the elastic properties. We detail the
implementation of the method and give several examples of how to use the modules 
in specific cases.
CONCLUSIONS: The method presented here is, to our knowledge, the only available
computational approach allowing to quantify the elastic properties of lipidic
assemblies of arbitrary shape and composition (including lipid mixtures). The
implementation as python modules offers flexibility, which has already allowed
the method to be applied to diverse lipid assembly types, ranging from bilayers
in the liquid ordered and disordered phases to a study of the inverted-hexagonal 
phase, and with different force-fields (both all-atom and coarse grained
representations). The modules are freely available through GitHub at
https://github.com/njohner/ost_pymodules/ while OpenStructure can be obtained at 
http://www.openstructure.org .

DOI: 10.1186/s12859-016-1003-z 
PMCID: PMC4830014
PMID: 27071656  [PubMed - indexed for MEDLINE]


594. Source Code Biol Med. 2016 Apr 11;11:6. doi: 10.1186/s13029-016-0053-y.
eCollection 2016.

MM2S: personalized diagnosis of medulloblastoma patients and model systems.

Gendoo DM(1), Haibe-Kains B(2).

Author information: 
(1)Bioinformatics and Computational Genomics Laboratory, Princess Margaret Cancer
Center, University Health Network, Toronto, Ontario Canada ; Department of
Medical Biophysics, University of Toronto, Toronto, Ontario Canada.
(2)Bioinformatics and Computational Genomics Laboratory, Princess Margaret Cancer
Center, University Health Network, Toronto, Ontario Canada ; Department of
Medical Biophysics, University of Toronto, Toronto, Ontario Canada ; Department
of Computer Science, University of Toronto, Toronto, Ontario Canada.

BACKGROUND: Medulloblastoma (MB) is a highly malignant and heterogeneous brain
tumour that is the most common cause of cancer-related deaths in children.
Increasing availability of genomic data over the last decade had resulted in
improvement of human subtype classification methods, and the parallel development
of MB mouse models towards identification of subtype-specific disease origins and
signaling pathways. Despite these advances, MB classification schemes remained
inadequate for personalized prediction of MB subtypes for individual patient
samples and across model systems. To address this issue, we developed the
Medullo-Model to Subtypes ( MM2S ) classifier, a new method enabling
classification of individual gene expression profiles from MB samples (patient
samples, mouse models, and cell lines) against well-established molecular
subtypes [Genomics 106:96-106, 2015]. We demonstrated the accuracy and
flexibility of MM2S in the largest meta-analysis of human patients and mouse
models to date. Here, we present a new functional package that provides an
easy-to-use and fully documented implementation of the MM2S method, with
additional functionalities that allow users to obtain graphical and tabular
summaries of MB subtype predictions for single samples and across sample
replicates. The flexibility of the MM2S package promotes incorporation of MB
predictions into large Medulloblastoma-driven analysis pipelines, making this
tool suitable for use by researchers.
RESULTS: The MM2S package is applied in two case studies involving human primary 
patient samples, as well as sample replicates of the GTML mouse model. We
highlight functions that are of use for species-specific MB classification,
across individual samples and sample replicates. We emphasize on the range of
functions that can be used to derive both singular and meta-centric views of MB
predictions, across samples and across MB subtypes.
CONCLUSIONS: Our MM2S package can be used to generate predictions without having 
to rely on an external web server or additional sources. Our open-source package 
facilitates and extends the MM2S algorithm in diverse computational and
bioinformatics contexts. The package is available on CRAN, at the following URL: 
https://cran.r-project.org/web/packages/MM2S/, as well as on Github at the
following URLs: https://github.com/DGendoo and https://github.com/bhklab.

DOI: 10.1186/s13029-016-0053-y 
PMCID: PMC4827218
PMID: 27069505  [PubMed]


595. J Proteome Res. 2016 Jun 3;15(6):1830-41. doi: 10.1021/acs.jproteome.6b00004.
Epub 2016 May 6.

XLSearch: a Probabilistic Database Search Algorithm for Identifying Cross-Linked 
Peptides.

Ji C(1), Li S(1), Reilly JP(1), Radivojac P(1), Tang H(1).

Author information: 
(1)Department of Computer Science and Informatics and ‡Department of Chemistry,
Indiana University , Bloomington, Indiana 47405, United States.

Chemical cross-linking combined with mass spectrometric analysis has become an
important technique for probing protein three-dimensional structure and
protein-protein interactions. A key step in this process is the accurate
identification and validation of cross-linked peptides from tandem mass spectra. 
The identification of cross-linked peptides, however, presents challenges related
to the expanded nature of the search space (all pairs of peptides in a sequence
database) and the fact that some peptide-spectrum matches (PSMs) contain one
correct and one incorrect peptide but often receive scores that are comparable to
those in which both peptides are correctly identified. To address these problems 
and improve detection of cross-linked peptides, we propose a new database search 
algorithm, XLSearch, for identifying cross-linked peptides. Our approach is based
on a data-driven scoring scheme that independently estimates the probability of
correctly identifying each individual peptide in the cross-link given knowledge
of the correct or incorrect identification of the other peptide. These
conditional probabilities are subsequently used to estimate the joint posterior
probability that both peptides are correctly identified. Using the data from two 
previous cross-link studies, we show the effectiveness of this scoring scheme,
particularly in distinguishing between true identifications and those containing 
one incorrect peptide. We also provide evidence that XLSearch achieves more
identifications than two alternative methods at the same false discovery rate
(availability: https://github.com/COL-IU/XLSearch ).

DOI: 10.1021/acs.jproteome.6b00004 
PMID: 27068484  [PubMed - in process]


596. Front Neuroinform. 2016 Mar 29;10:12. doi: 10.3389/fninf.2016.00012. eCollection 
2016.

Neonatal Brain Tissue Classification with Morphological Adaptation and Unified
Segmentation.

Beare RJ(1), Chen J(1), Kelly CE(2), Alexopoulos D(3), Smyser CD(3), Rogers
CE(4), Loh WY(5), Matthews LG(6), Cheong JL(7), Spittle AJ(8), Anderson PJ(9),
Doyle LW(10), Inder TE(11), Seal ML(9), Thompson DK(12).

Author information: 
(1)Murdoch Childrens Research Institute, The Royal Children's HospitalMelbourne, 
VIC, Australia; Department of Medicine, Monash Medical Centre, Monash
UniversityMelbourne, VIC, Australia. (2)Murdoch Childrens Research Institute, The
Royal Children's Hospital Melbourne, VIC, Australia. (3)Department of Neurology, 
Washington University School of Medicine St. Louis, MO, USA. (4)Department of
Psychiatry, Washington University School of Medicine St. Louis, MO, USA.
(5)Murdoch Childrens Research Institute, The Royal Children's HospitalMelbourne, 
VIC, Australia; Florey Institute of Neuroscience and Mental HealthMelbourne, VIC,
Australia. (6)Murdoch Childrens Research Institute, The Royal Children's
HospitalMelbourne, VIC, Australia; Department of Paediatrics, University of
MelbourneMelbourne, VIC, Australia; Royal Women's HospitalMelbourne, VIC,
Australia. (7)Murdoch Childrens Research Institute, The Royal Children's
HospitalMelbourne, VIC, Australia; Royal Women's HospitalMelbourne, VIC,
Australia; Department of Obstetrics and Gynaecology, University of
MelbourneMelbourne, VIC, Australia. (8)Murdoch Childrens Research Institute, The 
Royal Children's HospitalMelbourne, VIC, Australia; Royal Women's
HospitalMelbourne, VIC, Australia; Department of Physiotherapy, University of
MelbourneMelbourne, VIC, Australia. (9)Murdoch Childrens Research Institute, The 
Royal Children's HospitalMelbourne, VIC, Australia; Department of Paediatrics,
University of MelbourneMelbourne, VIC, Australia. (10)Murdoch Childrens Research 
Institute, The Royal Children's HospitalMelbourne, VIC, Australia; Department of 
Paediatrics, University of MelbourneMelbourne, VIC, Australia; Royal Women's
HospitalMelbourne, VIC, Australia; Department of Obstetrics and Gynaecology,
University of MelbourneMelbourne, VIC, Australia. (11)Department of Pediatric
Newborn Medicine, Harvard Medical School, Brigham and Women's Hospital Boston,
MA, USA. (12)Murdoch Childrens Research Institute, The Royal Children's
HospitalMelbourne, VIC, Australia; Florey Institute of Neuroscience and Mental
HealthMelbourne, VIC, Australia; Department of Paediatrics, University of
MelbourneMelbourne, VIC, Australia.

Measuring the distribution of brain tissue types (tissue classification) in
neonates is necessary for studying typical and atypical brain development, such
as that associated with preterm birth, and may provide biomarkers for
neurodevelopmental outcomes. Compared with magnetic resonance images of adults,
neonatal images present specific challenges that require the development of
specialized, population-specific methods. This paper introduces MANTiS
(Morphologically Adaptive Neonatal Tissue Segmentation), which extends the
unified segmentation approach to tissue classification implemented in Statistical
Parametric Mapping (SPM) software to neonates. MANTiS utilizes a combination of
unified segmentation, template adaptation via morphological segmentation tools
and topological filtering, to segment the neonatal brain into eight tissue
classes: cortical gray matter, white matter, deep nuclear gray matter,
cerebellum, brainstem, cerebrospinal fluid (CSF), hippocampus and amygdala. We
evaluated the performance of MANTiS using two independent datasets. The first
dataset, provided by the NeoBrainS12 challenge, consisted of coronal T 2-weighted
images of preterm infants (born ≤30 weeks' gestation) acquired at 30 weeks'
corrected gestational age (n = 5), coronal T 2-weighted images of preterm infants
acquired at 40 weeks' corrected gestational age (n = 5) and axial T 2-weighted
images of preterm infants acquired at 40 weeks' corrected gestational age (n =
5). The second dataset, provided by the Washington University NeuroDevelopmental 
Research (WUNDeR) group, consisted of T 2-weighted images of preterm infants
(born <30 weeks' gestation) acquired shortly after birth (n = 12), preterm
infants acquired at term-equivalent age (n = 12), and healthy term-born infants
(born ≥38 weeks' gestation) acquired within the first 9 days of life (n = 12).
For the NeoBrainS12 dataset, mean Dice scores comparing MANTiS with manual
segmentations were all above 0.7, except for the cortical gray matter for coronal
images acquired at 30 weeks. This demonstrates that MANTiS' performance is
competitive with existing techniques. For the WUNDeR dataset, mean Dice scores
comparing MANTiS with manually edited segmentations demonstrated good agreement, 
where all scores were above 0.75, except for the hippocampus and amygdala. The
results show that MANTiS is able to segment neonatal brain tissues well, even in 
images that have brain abnormalities common in preterm infants. MANTiS is
available for download as an SPM toolbox from
http://developmentalimagingmcri.github.io/mantis.

DOI: 10.3389/fninf.2016.00012 
PMCID: PMC4809890
PMID: 27065840  [PubMed]


597. Database (Oxford). 2016 Apr 6;2016. pii: baw042. doi: 10.1093/database/baw042.
Print 2016.

Chemical-induced disease relation extraction with various linguistic features.

Gu J(1), Qian L(2), Zhou G(1).

Author information: 
(1)Natural Language Processing Lab, School of Computer Science and Technology,
Soochow University, 1 Shizi Street, Suzhou, China, 215006. (2)Natural Language
Processing Lab, School of Computer Science and Technology, Soochow University, 1 
Shizi Street, Suzhou, China, 215006 qianlonghua@suda.edu.cn.

Understanding the relations between chemicals and diseases is crucial in various 
biomedical tasks such as new drug discoveries and new therapy developments. While
manually mining these relations from the biomedical literature is costly and
time-consuming, such a procedure is often difficult to keep up-to-date. To
address these issues, the BioCreative-V community proposed a challenging task of 
automatic extraction of chemical-induced disease (CID) relations in order to
benefit biocuration. This article describes our work on the CID relation
extraction task on the BioCreative-V tasks. We built a machine learning based
system that utilized simple yet effective linguistic features to extract
relations with maximum entropy models. In addition to leveraging various
features, the hypernym relations between entity concepts derived from the Medical
Subject Headings (MeSH)-controlled vocabulary were also employed during both
training and testing stages to obtain more accurate classification models and
better extraction performance, respectively. We demoted relation extraction
between entities in documents to relation extraction between entity mentions. In 
our system, pairs of chemical and disease mentions at both intra- and
inter-sentence levels were first constructed as relation instances for training
and testing, then two classification models at both levels were trained from the 
training examples and applied to the testing examples. Finally, we merged the
classification results from mention level to document level to acquire final
relations between chemicals and diseases. Our system achieved promisingF-scores
of 60.4% on the development dataset and 58.3% on the test dataset using
gold-standard entity annotations, respectively. Database
URL:https://github.com/JHnlp/BC5CIDTask.

© The Author(s) 2016. Published by Oxford University Press.

DOI: 10.1093/database/baw042 
PMCID: PMC4822558
PMID: 27052618  [PubMed - indexed for MEDLINE]


598. Sci Rep. 2016 Apr 6;6:24095. doi: 10.1038/srep24095.

SHEsisPlus, a toolset for genetic studies on polyploid species.

Shen J(1,)(2,)(3), Li Z(1,)(3), Chen J(1,)(3), Song Z(1,)(3), Zhou Z(1,)(4,)(5), 
Shi Y(1,)(2,)(6,)(7).

Author information: 
(1)Bio-X Institutes, Key Laboratory for the Genetics of Developmental and
Neuropsychiatric Disorders (Ministry of Education) and the Collaborative
Innovation Center for Brain Science, Shanghai Jiao Tong University, Shanghai
200030, P.R. China. (2)School of Bio-medical Engineering, Shanghai Jiao Tong
University, Shanghai 200230, P.R. China. (3)Institute of Social Cognitive and
Behavioral Sciences, Shanghai Jiao Tong University, Shanghai 200240, P.R. China. 
(4)Shandong Provincial Key Laboratory of Metabolic Disease, the Affiliated
Hospital of Qingdao University, 16 Jiangsu Road, Qingdao 266003, China.
(5)Institute of Clinical Research, the Affiliated Hospital of Qingdao University,
16 Jiangsu Road, Qingdao 266003, China. (6)Shanghai Changning Mental Health
Center, Shanghai 200042, P.R. China. (7)Department of Psychiatry, the First
Teaching Hospital of Xinjiang Medical University, Urumqi 830054, P.R. China.

Currently, algorithms and softwares for genetic analysis of diploid organisms
with bi-allelic markers are well-established, while those for polyploids are
limited. Here, we present SHEsisPlus, the online algorithm toolset for both
dichotomous and quantitative trait genetic analysis on polyploid species
(compatible with haploids and diploids, too). SHEsisPlus is also optimized for
handling multiple-allele datasets. It's free, open source and also designed to
perform a range of analyses, including haplotype inference, linkage
disequilibrium analysis, epistasis detection, Hardy-Weinberg equilibrium and
single locus association tests. Meanwhile, we developed an accurate and efficient
haplotype inference algorithm for polyploids and proposed an entropy-based
algorithm to detect epistasis in the context of quantitative traits. A study of
both simulated and real datasets showed that our haplotype inference algorithm
was much faster and more accurate than existing ones. Our epistasis detection
algorithm was the first try to apply information theory to characterizing the
gene interactions in quantitative trait datasets. Results showed that its
statistical power was significantly higher than conventional approaches.
SHEsisPlus is freely available on the web at http://shesisplus.bio-x.cn/. Source 
code is freely available for download at
https://github.com/celaoforever/SHEsisPlus.

DOI: 10.1038/srep24095 
PMCID: PMC4822172
PMID: 27048905  [PubMed - in process]


599. Genomics. 2016 May;107(5):163-9. doi: 10.1016/j.ygeno.2016.03.006. Epub 2016 Apr 
2.

Practicability of detecting somatic point mutation from RNA high throughput
sequencing data.

Sheng Q(1), Zhao S(1), Li CI(2), Shyr Y(3), Guo Y(4).

Author information: 
(1)Vanderbilt Ingram Cancer Center, Center for Quantitative Sciences, Nashville, 
TN, USA; Department of Cancer Biology, Vanderbilt University, Nashville, TN, USA.
(2)Department of Statistics, National Cheng Kung University, Taiwan.
(3)Vanderbilt Ingram Cancer Center, Center for Quantitative Sciences, Nashville, 
TN, USA; Department of Cancer Biology, Vanderbilt University, Nashville, TN, USA;
Department of Biostatistics, Vanderbilt University, Nashville, TN, USA.
Electronic address: Yu.shyr@vanderbilt.edu. (4)Vanderbilt Ingram Cancer Center,
Center for Quantitative Sciences, Nashville, TN, USA; Department of Cancer
Biology, Vanderbilt University, Nashville, TN, USA. Electronic address:
Yan.guo@vanderbilt.edu.

Traditionally, somatic mutations are detected by examining DNA sequence. The
maturity of sequencing technology has allowed researchers to screen for somatic
mutations in the whole genome. Increasingly, researchers have become interested
in identifying somatic mutations through RNAseq data. With this motivation, we
evaluated the practicability of detecting somatic mutations from RNAseq data.
Current somatic mutation calling tools were designed for DNA sequencing data. To 
increase performance on RNAseq data, we developed a somatic mutation caller GLMVC
based on bias reduced generalized linear model for both DNA and RNA sequencing
data. Through comparison with MuTect and Varscan we showed that GLMVC performed
better for somatic mutation detection using exome sequencing or RNAseq data.
GLMVC is freely available for download at the following website:
https://github.com/shengqh/GLMVC/wiki.

Copyright © 2015 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.ygeno.2016.03.006 
PMID: 27046520  [PubMed - in process]


600. J Chem Theory Comput. 2016 May 10;12(5):2388-400. doi: 10.1021/acs.jctc.6b00144. 
Epub 2016 Apr 14.

Chemically Realistic Tetrahedral Lattice Models for Polymer Chains: Application
to Polyethylene Oxide.

Dietschreit JC(1), Diestler DJ(1,)(2), Knapp EW(1).

Author information: 
(1)Department of Biology, Chemistry and Pharmacy, Institute of Chemistry and
Biochemistry, Freie Universität Berlin , Fabeckstrasse 36A, D-14195 Berlin,
Germany. (2)University of Nebraska-Lincoln , Lincoln, Nebraska 68583, United
States.

To speed up the generation of an ensemble of poly(ethylene oxide) (PEO) polymer
chains in solution, a tetrahedral lattice model possessing the appropriate bond
angles is used. The distance between noncovalently bonded atoms is maintained at 
realistic values by generating chains with an enhanced degree of self-avoidance
by a very efficient Monte Carlo (MC) algorithm. Potential energy parameters
characterizing this lattice model are adjusted so as to mimic realistic PEO
polymer chains in water simulated by molecular dynamics (MD), which serves as a
benchmark. The MD data show that PEO chains have a fractal dimension of about
two, in contrast to self-avoiding walk lattice models, which exhibit the fractal 
dimension of 1.7. The potential energy accounts for a mild hydrophobic effect
(HYEF) of PEO and for a proper setting of the distribution between trans and
gauche conformers. The potential energy parameters are determined by matching the
Flory radius, the radius of gyration, and the fraction of trans torsion angles in
the chain. A gratifying result is the excellent agreement of the pair
distribution function and the angular correlation for the lattice model with the 
benchmark distribution. The lattice model allows for the precise computation of
the torsional entropy of the chain. The generation of polymer conformations of
the adjusted lattice model is at least 2 orders of magnitude more efficient than 
MD simulations of the PEO chain in explicit water. This method of generating
chain conformations on a tetrahedral lattice can also be applied to other types
of polymers with appropriate adjustment of the potential energy function. The
efficient MC algorithm for generating chain conformations on a tetrahedral
lattice is available for download at https://github.com/Roulattice/Roulattice .

DOI: 10.1021/acs.jctc.6b00144 
PMID: 27045228  [PubMed - in process]


601. J Comput Chem. 2016 Jun 15;37(16):1511-20. doi: 10.1002/jcc.24358. Epub 2016 Apr 
4.

ORBKIT: A modular python toolbox for cross-platform postprocessing of quantum
chemical wavefunction data.

Hermann G(1), Pohl V(1), Tremblay JC(1), Paulus B(1), Hege HC(2), Schild A(3).

Author information: 
(1)Institut für Chemie und Biochemie, Freie Universität Berlin, Takustraße 3,
Berlin, 14195, Germany. (2)Department of Visual Data Analysis, Zuse Institute
Berlin, Takustraße 7, Berlin, 14195, Germany. (3)Max-Planck-Institut für
Mikrostrukturphysik, Weinberg 2, Halle, 06120, Germany.

ORBKIT is a toolbox for postprocessing electronic structure calculations based on
a highly modular and portable Python architecture. The program allows computing a
multitude of electronic properties of molecular systems on arbitrary spatial
grids from the basis set representation of its electronic wavefunction, as well
as several grid-independent properties. The required data can be extracted
directly from the standard output of a large number of quantum chemistry
programs. ORBKIT can be used as a standalone program to determine standard
quantities, for example, the electron density, molecular orbitals, and
derivatives thereof. The cornerstone of ORBKIT is its modular structure. The
existing basic functions can be arranged in an individual way and can be easily
extended by user-written modules to determine any other derived quantity. ORBKIT 
offers multiple output formats that can be processed by common visualization
tools (VMD, Molden, etc.). Additionally, ORBKIT possesses routines to order
molecular orbitals computed at different nuclear configurations according to
their electronic character and to interpolate the wavefunction between these
configurations. The program is open-source under GNU-LGPLv3 license and freely
available at https://github.com/orbkit/orbkit/. This article provides an overview
of ORBKIT with particular focus on its capabilities and applicability, and
includes several example calculations. © 2016 Wiley Periodicals, Inc.

© 2016 Wiley Periodicals, Inc.

DOI: 10.1002/jcc.24358 
PMID: 27043934  [PubMed - in process]


602. Cryobiology. 2016 Jun;72(3):251-7. doi: 10.1016/j.cryobiol.2016.03.010. Epub 2016
Mar 31.

An open source cryostage and software analysis method for detection of antifreeze
activity.

Buch JL(1), Ramløv H(2).

Author information: 
(1)Department of Biology, University of Southern Denmark, Campusvej 55, 5230
Odense M, Denmark. Electronic address: jloerup@gmail.com. (2)Department of
Science and Environment, Roskilde University, Universitetsvej 1, 4000 Roskilde,
Denmark. Electronic address: hr@ruc.dk.

The aim of this study is to provide the reader with a simple setup that can
detect antifreeze proteins (AFP) by inhibition of ice recrystallisation in very
small sample sizes. This includes an open source cryostage, a method for
preparing and loading samples as well as a software analysis method. The entire
setup was tested using hyperactive AFP from the cerambycid beetle, Rhagium
mordax. Samples containing AFP were compared to buffer samples, and the results
are visualised as crystal radius evolution over time and in absolute change over 
30 min. Statistical analysis showed that samples containing AFP could reliably be
told apart from controls after only two minutes of recrystallisation. The goal of
providing a fast, cheap and easy method for detecting antifreeze proteins in
solution was met, and further development of the system can be followed at
https://github.com/pechano/cryostage.

Copyright © 2016 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.cryobiol.2016.03.010 
PMID: 27041219  [PubMed - in process]


603. Stat Anal Data Min. 2016 Feb;9(1):12-42. Epub 2016 Jan 22.

Cross-validation and Peeling Strategies for Survival Bump Hunting using Recursive
Peeling Methods.

Dazard JE(1), Choe M(1), LeBlanc M(2), Rao JS(3).

Author information: 
(1)Center for Proteomics and Bioinformatics, Case Western Reserve University,
Cleveland, OH 44106, USA. (2)Department of Biostatistics, School of Public
Health, University of Washington, Seattle, WA 98195, USA; Public Health Sciences,
Fred Hutchinson Cancer Research Center, Seattle, WA 98109, USA. (3)Division of
Biostatistics, Department of Epidemiology and Public Health, The University of
Miami, Miami, FL 33136, USA.

We introduce a framework to build a survival/risk bump hunting model with a
censored time-to-event response. Our Survival Bump Hunting (SBH) method is based 
on a recursive peeling procedure that uses a specific survival peeling criterion 
derived from non/semi-parametric statistics such as the hazards-ratio, the
log-rank test or the Nelson--Aalen estimator. To optimize the tuning parameter of
the model and validate it, we introduce an objective function based on survival
or prediction-error statistics, such as the log-rank test and the concordance
error rate. We also describe two alternative cross-validation techniques adapted 
to the joint task of decision-rule making by recursive peeling and survival
estimation. Numerical analyses show the importance of replicated cross-validation
and the differences between criteria and techniques in both low and
high-dimensional settings. Although several non-parametric survival models exist,
none addresses the problem of directly identifying local extrema. We show how SBH
efficiently estimates extreme survival/risk subgroups unlike other models. This
provides an insight into the behavior of commonly used models and suggests
alternatives to be adopted in practice. Finally, our SBH framework was applied to
a clinical dataset. In it, we identified subsets of patients characterized by
clinical and demographic covariates with a distinct extreme survival outcome, for
which tailored medical interventions could be made. An R package PRIMsrc (Patient
Rule Induction Method in Survival, Regression and Classification settings) is
available on CRAN (Comprehensive R Archive Network) and GitHub.

DOI: 10.1002/sam.11301 
PMCID: PMC4809437
PMID: 27034730  [PubMed]


604. Sci Rep. 2016 Mar 30;6:23774. doi: 10.1038/srep23774.

VIP: an integrated pipeline for metagenomics of virus identification and
discovery.

Li Y(1,)(2), Wang H(1,)(3), Nie K(1), Zhang C(1), Zhang Y(1), Wang J(1), Niu
P(1), Ma X(1).

Author information: 
(1)Key Laboratory of Medical Virology, Ministry of Health; National Institute for
Viral Disease Control and Prevention, Chinese Center for Disease Control and
Prevention, Beijing, 102206, China. (2)National Engineering Research Center for
Beijing Biochip Technology, Beijing 102206, China. (3)Department of Infectious
Diseases, Institute of Biomedicine, Sahlgrenska Academy, University of
Gothenburg, Gothenburg, 41345, Sweden.

Identification and discovery of viruses using next-generation sequencing
technology is a fast-developing area with potential wide application in clinical 
diagnostics, public health monitoring and novel virus discovery. However,
tremendous sequence data from NGS study has posed great challenge both in
accuracy and velocity for application of NGS study. Here we describe VIP ("Virus 
Identification Pipeline"), a one-touch computational pipeline for virus
identification and discovery from metagenomic NGS data. VIP performs the
following steps to achieve its goal: (i) map and filter out background-related
reads, (ii) extensive classification of reads on the basis of nucleotide and
remote amino acid homology, (iii) multiple k-mer based de novo assembly and
phylogenetic analysis to provide evolutionary insight. We validated the
feasibility and veracity of this pipeline with sequencing results of various
types of clinical samples and public datasets. VIP has also contributed to timely
virus diagnosis (~10 min) in acutely ill patients, demonstrating its potential in
the performance of unbiased NGS-based clinical studies with demand of short
turnaround time. VIP is released under GPLv3 and is available for free download
at: https://github.com/keylabivdc/VIP.

DOI: 10.1038/srep23774 
PMCID: PMC4824449
PMID: 27026381  [PubMed - in process]


605. Proteins. 2016 Sep;84(9):1177-89. doi: 10.1002/prot.25039. Epub 2016 Jun 23.

Molprobity's ultimate rotamer-library distributions for model validation.

Hintze BJ(1), Lewis SM(1), Richardson JS(1), Richardson DC(1).

Author information: 
(1)Department of Biochemistry, Duke University, Durham North Carolina 27710.

Here we describe the updated MolProbity rotamer-library distributions derived
from an order-of-magnitude larger and more stringently quality-filtered dataset
of about 8000 (vs. 500) protein chains, and we explain the resulting changes and 
improvements to model validation as seen by users. To include only side-chains
with satisfactory justification for their given conformation, we added
residue-specific filters for electron-density value and model-to-density fit. The
combined new protocol retains a million residues of data, while cleaning up
false-positive noise in the multi- χ datapoint distributions. It enables
unambiguous characterization of conformational clusters nearly 1000-fold less
frequent than the most common ones. We describe examples of local interactions
that favor these rare conformations, including the role of authentic covalent
bond-angle deviations in enabling presumably strained side-chain conformations.
Further, along with favored and outlier, an allowed category (0.3-2.0% occurrence
in reference data) has been added, analogous to Ramachandran validation
categories. The new rotamer distributions are used for current rotamer validation
in MolProbity and PHENIX, and for rotamer choice in PHENIX model-building and
refinement. The multi-dimensional χ distributions and Top8000 reference dataset
are freely available on GitHub. These rotamers are termed "ultimate" because data
sampling and quality are now fully adequate for this task, and also because we
believe the future of conformational validation should integrate side-chain with 
backbone criteria. Proteins 2016; 84:1177-1189. © 2016 Wiley Periodicals, Inc.

© 2016 Wiley Periodicals, Inc.

DOI: 10.1002/prot.25039 
PMCID: PMC4983197
PMID: 27018641  [PubMed - in process]


606. Nucleic Acids Res. 2016 Jun 20;44(11):e103. doi: 10.1093/nar/gkw210. Epub 2016
Mar 25.

Coding exon-structure aware realigner (CESAR) utilizes genome alignments for
accurate comparative gene annotation.

Sharma V(1), Elghafari A(2), Hiller M(3).

Author information: 
(1)Max Planck Institute of Molecular Cell Biology and Genetics, Pfotenhauerstr.
108, 01307 Dresden, Germany Max Planck Institute for the Physics of Complex
Systems, Nöthnitzer Str. 38, 01187 Dresden, Germany. (2)Max Planck Institute of
Molecular Cell Biology and Genetics, Pfotenhauerstr. 108, 01307 Dresden, Germany 
Max Planck Institute for the Physics of Complex Systems, Nöthnitzer Str. 38,
01187 Dresden, Germany Technical University, 01069 Dresden, Germany. (3)Max
Planck Institute of Molecular Cell Biology and Genetics, Pfotenhauerstr. 108,
01307 Dresden, Germany Max Planck Institute for the Physics of Complex Systems,
Nöthnitzer Str. 38, 01187 Dresden, Germany hiller@mpi-cbg.de.

Identifying coding genes is an essential step in genome annotation. Here, we
utilize existing whole genome alignments to detect conserved coding exons and
then map gene annotations from one genome to many aligned genomes. We show that
genome alignments contain thousands of spurious frameshifts and splice site
mutations in exons that are truly conserved. To overcome these limitations, we
have developed CESAR (Coding Exon-Structure Aware Realigner) that realigns coding
exons, while considering reading frame and splice sites of each exon. CESAR
effectively avoids spurious frameshifts in conserved genes and detects 91% of
shifted splice sites. This results in the identification of thousands of
additional conserved exons and 99% of the exons that lack inactivating mutations 
match real exons. Finally, to demonstrate the potential of using CESAR for
comparative gene annotation, we applied it to 188 788 exons of 19 865 human genes
to annotate human genes in 99 other vertebrates. These comparative gene
annotations are available as a resource (http://bds.mpi-cbg.de/hillerlab/CESAR/).
CESAR (https://github.com/hillerlab/CESAR/) can readily be applied to other
alignments to accurately annotate coding genes in many other vertebrate and
invertebrate genomes.

© The Author(s) 2016. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkw210 
PMCID: PMC4914097
PMID: 27016733  [PubMed - in process]


607. Genome Biol. 2016 Mar 24;17:55. doi: 10.1186/s13059-016-0915-2.

CRISPR library designer (CLD): software for multispecies design of single guide
RNA libraries.

Heigwer F(1), Zhan T(1,)(2), Breinig M(1), Winter J(1), Brügemann D(1), Leible
S(1), Boutros M(3).

Author information: 
(1)Division Signaling and Functional Genomics, German Cancer Research Center
(DKFZ) and Heidelberg University, Im Neuenheimer Feld 580, Heidelberg, 69120,
Germany. (2)Department of Medicine II, University Hospital Mannheim, Medical
Faculty Mannheim, Heidelberg University, Mannheim, Germany. (3)Division Signaling
and Functional Genomics, German Cancer Research Center (DKFZ) and Heidelberg
University, Im Neuenheimer Feld 580, Heidelberg, 69120, Germany.
m.boutros@dkfz.de.

BACKGROUND: Genetic screens using CRISPR/Cas9 are a powerful method for the
functional analysis of genomes.
RESULTS: Here we describe CRISPR library designer (CLD), an integrated
bioinformatics application for the design of custom single guide RNA (sgRNA)
libraries for all organisms with annotated genomes. CLD is suitable for the
design of libraries using modified CRISPR enzymes and targeting non-coding
regions. To demonstrate its utility, we perform a pooled screen for modulators of
the TNF-related apoptosis inducing ligand (TRAIL) pathway using a custom library 
of 12,471 sgRNAs.
CONCLUSION: CLD predicts a high fraction of functional sgRNAs and is publicly
available at https://github.com/boutroslab/cld.

DOI: 10.1186/s13059-016-0915-2 
PMCID: PMC4807595
PMID: 27013184  [PubMed - in process]


608. Methods. 2016 Jun 1;102:3-11. doi: 10.1016/j.ymeth.2016.02.020. Epub 2016 Mar 21.

MEGAHIT v1.0: A fast and scalable metagenome assembler driven by advanced
methodologies and community practices.

Li D(1), Luo R(2), Liu CM(3), Leung CM(1), Ting HF(1), Sadakane K(4), Yamashita
H(4), Lam TW(5).

Author information: 
(1)Department of Computer Science, University of Hong Kong, Hong Kong.
(2)Department of Computer Science, University of Hong Kong, Hong Kong; L3
Bioinformatics Limited, Hong Kong. (3)L3 Bioinformatics Limited, Hong Kong.
(4)Department of Mathematical Informatics, Graduate School of Information Science
and Technology, The University of Tokyo, Japan. (5)Department of Computer
Science, University of Hong Kong, Hong Kong; L3 Bioinformatics Limited, Hong
Kong. Electronic address: twlam@cs.hku.hk.

The study of metagenomics has been much benefited from low-cost and
high-throughput sequencing technologies, yet the tremendous amount of data
generated make analysis like de novo assembly to consume too much computational
resources. In late 2014 we released MEGAHIT v0.1 (together with a brief note of
Li et al. (2015) [1]), which is the first NGS metagenome assembler that can
assemble genome sequences from metagenomic datasets of hundreds of Giga
base-pairs (bp) in a time- and memory-efficient manner on a single server. The
core of MEGAHIT is an efficient parallel algorithm for constructing succinct de
Bruijn Graphs (SdBG), implemented on a graphical processing unit (GPU). The
software has been well received by the assembly community, and there is interest 
in how to adapt the algorithms to integrate popular assembly practices so as to
improve the assembly quality, as well as how to speed up the software using
better CPU-based algorithms (instead of GPU). In this paper we first describe the
details of the core algorithms in MEGAHIT v0.1, and then we show the new modules 
to upgrade MEGAHIT to version v1.0, which gives better assembly quality, runs
faster and uses less memory. For the Iowa Prairie Soil dataset (252Gbp after
quality trimming), the assembly quality of MEGAHIT v1.0, when compared with v0.1,
has a significant improvement, namely, 36% increase in assembly size and 23% in
N50. More interestingly, MEGAHIT v1.0 is no slower than before (even running with
the extra modules). This is primarily due to a new CPU-based algorithm for SdBG
construction that is faster and requires less memory. Using CPU only, MEGAHIT
v1.0 can assemble the Iowa Prairie Soil sample in about 43h, reducing the running
time of v0.1 by at least 25% and memory usage by up to 50%. MEGAHIT v1.0,
exhibiting a smaller memory footprint, can process even larger datasets. The
Kansas Prairie Soil sample (484Gbp), the largest publicly available dataset, can 
now be assembled using no more than 500GB of memory in 7.5days. The assemblies of
these datasets (and other large metgenomic datasets), as well as the software,
are available at the website https://hku-bal.github.io/megabox.

Copyright © 2016 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.ymeth.2016.02.020 
PMID: 27012178  [PubMed - in process]


609. PLoS One. 2016 Mar 24;11(3):e0151826. doi: 10.1371/journal.pone.0151826.
eCollection 2016.

A Bayesian Assignment Method for Ambiguous Bisulfite Short Reads.

Tran H(1), Wu X(2), Tithi S(1), Sun MA(3), Xie H(3,)(4), Zhang L(1).

Author information: 
(1)Department of Computer Science, Virginia Polytechnic Institute and State
University (Virginia Tech), Blacksburg, Virginia, United States of America.
(2)Department of Statistics, Virginia Polytechnic Institute and State University 
(Virginia Tech), Blacksburg, Virginia, United States of America. (3)Virginia
Bioinformatics Institute, Virginia Polytechnic Institute and State University
(Virginia Tech), Blacksburg, Virginia, United States of America. (4)Department of
Biological Sciences, Virginia Polytechnic Institute and State University(Virginia
Tech), Blacksburg, Virginia, United States of America.

DNA methylation is an epigenetic modification critical for normal development and
diseases. The determination of genome-wide DNA methylation at single-nucleotide
resolution is made possible by sequencing bisulfite treated DNA with next
generation high-throughput sequencing. However, aligning bisulfite short reads to
a reference genome remains challenging as only a limited proportion of them
(around 50-70%) can be aligned uniquely; a significant proportion, known as
multireads, are mapped to multiple locations and thus discarded from downstream
analyses, causing financial waste and biased methylation inference. To address
this issue, we develop a Bayesian model that assigns multireads to their most
likely locations based on the posterior probability derived from information
hidden in uniquely aligned reads. Analyses of both simulated data and real
hairpin bisulfite sequencing data show that our method can effectively assign
approximately 70% of the multireads to their best locations with up to 90%
accuracy, leading to a significant increase in the overall mapping efficiency.
Moreover, the assignment model shows robust performance with low coverage depth, 
making it particularly attractive considering the prohibitive cost of bisulfite
sequencing. Additionally, results show that longer reads help improve the
performance of the assignment model. The assignment model is also robust to
varying degrees of methylation and varying sequencing error rates. Finally,
incorporating prior knowledge on mutation rate and context specific methylation
level into the assignment model increases inference accuracy. The assignment
model is implemented in the BAM-ABS package and freely available at
https://github.com/zhanglabvt/BAM_ABS.

DOI: 10.1371/journal.pone.0151826 
PMCID: PMC4806927
PMID: 27011215  [PubMed - indexed for MEDLINE]


610. Mol Biol Evol. 2016 Jul;33(7):1875-86. doi: 10.1093/molbev/msw056. Epub 2016 Mar 
23.

BaitFisher: A Software Package for Multispecies Target DNA Enrichment Probe
Design.

Mayer C(1), Sann M(2), Donath A(1), Meixner M(3), Podsiadlowski L(4), Peters
RS(5), Petersen M(1), Meusemann K(6), Liere K(3), Wägele JW(7), Misof B(1),
Bleidorn C(8), Ohl M(9), Niehuis O(10).

Author information: 
(1)Center for Molecular Biodiversity Research, Zoological Research Museum
Alexander Koenig, Bonn, Germany. (2)Center for Molecular Biodiversity Research,
Zoological Research Museum Alexander Koenig, Bonn, Germany Museum für Naturkunde,
Leibniz Institute for Evolution and Biodiversity Science, Berlin, Germany.
(3)Services in Molecular Biology GmbH, Rüdersdorf, Germany. (4)University of
Bonn, Institute of Evolutionary Biology and Ecology, Bonn, Germany. (5)Department
Arthropoda, Zoological Research Museum Alexander Koenig, Bonn, Germany. (6)Center
for Molecular Biodiversity Research, Zoological Research Museum Alexander Koenig,
Bonn, Germany Australian National Insect Collection, CSIRO National Research
Collections Australia, Acton, Canberra, ACT, Australia. (7)Zoological Research
Museum Alexander Koenig, Bonn, Germany. (8)Molecular Evolution and Systematics of
Animals, Institute for Biology, University of Leipzig, Leipzig, Germany German
Centre for Integrative Biodiversity Research (iDiv) Halle-Jena-Leipzig, Leipzig, 
Germany Museo Nacional de Ciencias Naturales, Spanish National Research Council
(CSIC), Madrid, Spain. (9)Museum für Naturkunde, Leibniz Institute for Evolution 
and Biodiversity Science, Berlin, Germany o.niehuis@zfmk.de
michael.ohl@mfn-berlin.de. (10)Center for Molecular Biodiversity Research,
Zoological Research Museum Alexander Koenig, Bonn, Germany o.niehuis@zfmk.de
michael.ohl@mfn-berlin.de.

Target DNA enrichment combined with high-throughput sequencing technologies is a 
powerful approach to probing a large number of loci in genomes of interest.
However, software algorithms that explicitly consider nucleotide sequence
information of target loci in multiple reference species for optimizing design of
target enrichment baits to be applicable across a wide range of species have not 
been developed. Here we present an algorithm that infers target DNA enrichment
baits from multiple nucleotide sequence alignments. By applying clustering
methods and the combinatorial 1-center sequence optimization to bait design, we
are able to minimize the total number of baits required to efficiently probe
target loci in multiple species. Consequently, more loci can be probed across
species with a given number of baits. Using transcript sequences of 24 apoid
wasps (Hymenoptera: Crabronidae, Sphecidae) from the 1KITE project and the gene
models of Nasonia vitripennis, we inferred 57,650, 120-bp-long baits for
capturing 378 coding sequence sections of 282 genes in apoid wasps. Illumina
reduced-representation library sequencing confirmed successful enrichment of the 
target DNA when applying these baits to DNA of various apoid wasps. The designed 
baits furthermore enriched a major fraction of the target DNA in distantly
related Hymenoptera, such as Formicidae and Chalcidoidea, highlighting the baits'
broad taxonomic applicability. The availability of baits with broad taxonomic
applicability is of major interest in numerous disciplines, ranging from
phylogenetics to biodiversity monitoring. We implemented our new approach in a
software package, called BaitFisher, which is open source and freely available at
https://github.com/cmayer/BaitFisher-package.git.

© The Author 2016. Published by Oxford University Press on behalf of the Society 
for Molecular Biology and Evolution. All rights reserved. For permissions, please
e-mail: journals.permissions@oup.com.

DOI: 10.1093/molbev/msw056 
PMID: 27009209  [PubMed - in process]


611. Comput Methods Programs Biomed. 2016 Apr;127:83-93. doi:
10.1016/j.cmpb.2016.01.013. Epub 2016 Feb 17.

A diagnostic tool for population models using non-compartmental analysis: The
ncappc package for R.

Acharya C(1), Hooker AC(2), Türkyılmaz GY(3), Jönsson S(2), Karlsson MO(2).

Author information: 
(1)Department of Pharmaceutical Biosciences, Uppsala University, P.O. Box 591,
SE-751 24 Uppsala, Sweden. Electronic address: chayan.acharya@farmbio.uu.se.
(2)Department of Pharmaceutical Biosciences, Uppsala University, P.O. Box 591,
SE-751 24 Uppsala, Sweden. (3)Department of Pharmaceutical Biosciences, Uppsala
University, P.O. Box 591, SE-751 24 Uppsala, Sweden; Ege University, Faculty of
Pharmacy, Department of Biopharmaceutics and Pharmacokinetics, 35100 İzmir,
Turkey.

BACKGROUND AND OBJECTIVE: Non-compartmental analysis (NCA) calculates
pharmacokinetic (PK) metrics related to the systemic exposure to a drug following
administration, e.g. area under the concentration-time curve and peak
concentration. We developed a new package in R, called ncappc, to perform (i) a
NCA and (ii) simulation-based posterior predictive checks (ppc) for a population 
PK (PopPK) model using NCA metrics.
METHODS: The nca feature of ncappc package estimates the NCA metrics by NCA. The 
ppc feature of ncappc estimates the NCA metrics from multiple sets of simulated
concentration-time data and compares them with those estimated from the observed 
data. The diagnostic analysis is performed at the population as well as the
individual level. The distribution of the simulated population means of each NCA 
metric is compared with the corresponding observed population mean. The
individual level comparison is performed based on the deviation of the mean of
any NCA metric based on simulations for an individual from the corresponding NCA 
metric obtained from the observed data. The ncappc package also reports the
normalized prediction distribution error (NPDE) of the simulated NCA metrics for 
each individual and their distribution within a population.
RESULTS: The ncappc produces two default outputs depending on the type of
analysis performed, i.e., NCA and PopPK diagnosis. The PopPK diagnosis feature of
ncappc produces 8 sets of graphical outputs to assess the ability of a population
model to simulate the concentration-time profile of a drug and thereby evaluate
model adequacy. In addition, tabular outputs are generated showing the values of 
the NCA metrics estimated from the observed and the simulated data, along with
the deviation, NPDE, regression parameters used to estimate the elimination rate 
constant and the related population statistics.
CONCLUSIONS: The ncappc package is a versatile and flexible tool-set written in R
that successfully estimates NCA metrics from concentration-time data and produces
a comprehensive set of graphical and tabular output to summarize the diagnostic
results including the model specific outliers. The output is easy to interpret
and to use in evaluation of a population PK model. ncappc is freely available on 
CRAN (http://cran.r-project.org/web/packages/ncappc/index.html/) and GitHub
(https://github.com/cacha0227/ncappc/).

Copyright © 2016 The Authors. Published by Elsevier Ireland Ltd.. All rights
reserved.

DOI: 10.1016/j.cmpb.2016.01.013 
PMID: 27000291  [PubMed - indexed for MEDLINE]


612. Prenat Diagn. 2016 Jul;36(7):614-21. doi: 10.1002/pd.4816. Epub 2016 May 20.

Calculating the fetal fraction for noninvasive prenatal testing based on
genome-wide nucleosome profiles.

Straver R(1), Oudejans CB(2), Sistermans EA(1), Reinders MJ(1,)(3).

Author information: 
(1)Department of Clinical Genetics, VU University Medical Center Amsterdam,
Amsterdam, The Netherlands. (2)Department of Clinical Chemistry, VU University
Medical Center Amsterdam, Amsterdam, The Netherlands. (3)Delft Bioinformatics
Lab, Delft University of Technology, Delft, The Netherlands.

OBJECTIVE: While large fetal copy number aberrations can generally be detected
through sequencing of DNA in maternal blood, the reliability of tests depends on 
the fraction of DNA that originates from the fetus. Existing methods to determine
this fetal fraction require additional work or are limited to male fetuses. We
aimed to create a sex-independent approach without additional work.
METHODS: DNA fragments used for noninvasive prenatal testing are cut only by
natural processes; thus, influences on cutting by the packaging of DNA in
nucleosomes will be preserved in sequencing. As cuts are expected to be made
preferentially in linker regions, the shorter fetal fragments should be enriched 
for reads starting in nucleosome covered positions.
RESULTS: We generated genome-wide nucleosome profiles based on single end
sequencing of cell-free DNA. We found a difference between DNA digestion of fetal
cell-free DNA and maternal cell-free DNA and used this to calculate the fraction 
of fetal DNA in maternal plasma for both male and female fetuses.
CONCLUSION: Our method facilitates cost-effective noninvasive prenatal testing,
as the fetal DNA fraction can be estimated without the need for expensive
paired-end sequencing or additional tests. The methodology is implemented as a
tool, which we called SANEFALCON (Single reAds Nucleosome-basEd FetAL fraCtiON). 
It is available for academic and non-profit purposes under Creative Commons
Attribution-NonCommercial-ShareAlike 4.0 International Public License.
github.com/rstraver/sanefalcon. © 2016 The Authors. Prenatal Diagnosis published 
by John Wiley & Sons, Ltd.

© 2016 The Authors. Prenatal Diagnosis published by John Wiley & Sons, Ltd.

DOI: 10.1002/pd.4816 
PMCID: PMC5111749
PMID: 26996738  [PubMed - in process]


613. J Anim Breed Genet. 2016 Apr;133(2):85-91. doi: 10.1111/jbg.12200. Epub 2016 Jan 
6.

A combined coalescence gene-dropping tool for evaluating genomic selection in
complex scenarios (ms2gs).

Pérez-Enciso M(1,)(2), Legarra A(3).

Author information: 
(1)Centre for Research in Agricultural Genomics (CRAG), CSIC-IRTA-UAB-UB
Consortium, Bellaterra, Spain. (2)Institut Català de Recerca i Estudis Avançats
(ICREA), Carrer de Lluís Companys, Barcelona, Spain. (3)UMR 1388 GENPHYSE,
Génétique, Physiologie et Systèmes d'Elevage, INRA, Castanet-Tolosan, France.

We present ms2gs, a combined coalescence - gene dropping (i.e. backward-forward) 
simulator for complex traits. It therefore aims at combining the advantages of
both approaches. It is primarily conceived for very short term, recent scenarios 
such as those that are of interest in animal and plant breeding. It is very
flexible in terms of defining QTL architecture and SNP ascertainment bias, and it
allows for easy modelling of alternative markers such as RADs. It can use real
sequence or chip data or generate molecular polymorphisms via the coalescence. It
can generate QTL conditional on extant molecular information, such as low-density
genotyping. It models (simplistically) sequence, imputation or genotyping errors.
It requires as input both genotypic data in plink or ms formats, and a pedigree
that is used to perform the gene dropping. By default, it compares accuracy for
BLUP, SNP ascertained data, sequence, and causal SNPs. It employs VanRaden's
linear (GBLUP) and nonlinear method for incorporating molecular information. To
illustrate the program, we present a small application in a half-sib population
and a multiparental (MAGIC) cross. The program, manual and examples are available
at https://github.com/mperezenciso/ms2gs.

© 2016 Blackwell Verlag GmbH.

DOI: 10.1111/jbg.12200 
PMID: 26995218  [PubMed - indexed for MEDLINE]


614. PeerJ. 2016 Mar 14;4:e1750. doi: 10.7717/peerj.1750. eCollection 2016.

Computational inference of H3K4me3 and H3K27ac domain length.

Zubek J(1), Stitzel ML(2), Ucar D(2), Plewczynski DM(3).

Author information: 
(1)Centre of New Technologies, University of Warsaw, Warsaw, Mazovia, Poland;
Institute of Computer Science, Warsaw, Mazovia, Poland. (2)Institute for Systems 
Genomics, Univeristy of Connecticut, Farmington, CT, United States of America;
The Jackson Laboratory for Genomic Medicine, Farmington, CT, United States of
America. (3)Centre of New Technologies, University of Warsaw, Warsaw, Mazovia,
Poland; Faculty of Pharmacy, Medical University of Warsaw, Warsaw, Poland.

Background. Recent epigenomic studies have shown that the length of a DNA region 
covered by an epigenetic mark is not just a byproduct of the assaying
technologies and has functional implications for that locus. For example,
expanded regions of DNA sequences that are marked by enhancer-specific histone
modifications, such as acetylation of histone H3 lysine 27 (H3K27ac) domains
coincide with cell-specific enhancers, known as super or stretch enhancers.
Similarly, promoters of genes critical for cell-specific functions are marked by 
expanded H3K4me3 domains in the cognate cell type, and these can span DNA regions
from 4-5kb up to 40-50kb in length. These expanded H3K4me3 domains are known as
buffer domains or super promoters. Methods. To ask what correlates with-and
potentially regulates-the length of loci marked with these two important histone 
marks, H3K4me3 and H3K27ac, we built Random Forest regression models. With these 
models, we computationally identified genomic and epigenomic patterns that are
predictive for the length of these marks in seven ENCODE cell lines. Results. We 
found that certain epigenetic marks and transcription factors explain the
variability of the length of H3K4me3 and H3K27ac marks across different cell
types, which implies that the lengths of these two epigenetic marks are tightly
regulated in a given cell type. Our source code for the regression models and
data can be found at our GitHub page: https://github.com/zubekj/broad_peaks.
Discussion. Our Random Forest based regression models enabled us to estimate the 
individual contribution of different epigenetic marks and protein binding
patterns to the length of H3K4me3 and H3K27ac deposition patterns, therefore
potentially revealing genomic signatures at cell specific regulatory elements.

DOI: 10.7717/peerj.1750 
PMCID: PMC4793332
PMID: 26989607  [PubMed]


615. PLoS One. 2016 Mar 15;11(3):e0150719. doi: 10.1371/journal.pone.0150719.
eCollection 2016.

REPdenovo: Inferring De Novo Repeat Motifs from Short Sequence Reads.

Chu C(1), Nielsen R(2), Wu Y(1).

Author information: 
(1)Department of Computer Science and Engineering, University of Connecticut,
Storrs, CT 06269, United States of America. (2)Department of Integrative Biology,
University of California, Berkeley, CA 94720, United States of America.

Repeat elements are important components of eukaryotic genomes. One limitation in
our understanding of repeat elements is that most analyses rely on reference
genomes that are incomplete and often contain missing data in highly repetitive
regions that are difficult to assemble. To overcome this problem we develop a new
method, REPdenovo, which assembles repeat sequences directly from raw shotgun
sequencing data. REPdenovo can construct various types of repeats that are highly
repetitive and have low sequence divergence within copies. We show that REPdenovo
is substantially better than existing methods both in terms of the number and the
completeness of the repeat sequences that it recovers. The key advantage of
REPdenovo is that it can reconstruct long repeats from sequence reads. We apply
the method to human data and discover a number of potentially new repeats
sequences that have been missed by previous repeat annotations. Many of these
sequences are incorporated into various parasite genomes, possibly because the
filtering process for host DNA involved in the sequencing of the parasite genomes
failed to exclude the host derived repeat sequences. REPdenovo is a new powerful 
computational tool for annotating genomes and for addressing questions regarding 
the evolution of repeat families. The software tool, REPdenovo, is available for 
download at https://github.com/Reedwarbler/REPdenovo.

DOI: 10.1371/journal.pone.0150719 
PMCID: PMC4792456
PMID: 26977803  [PubMed - indexed for MEDLINE]


616. Sci Rep. 2016 Mar 14;6:23035. doi: 10.1038/srep23035.

Differential network analysis reveals the genome-wide landscape of estrogen
receptor modulation in hormonal cancers.

Hsiao TH(1,)(2), Chiu YC(1,)(3), Hsu PY(4), Lu TP(5), Lai LC(6,)(7), Tsai
MH(7,)(8), Huang TH(4), Chuang EY(3,)(7), Chen Y(1,)(9).

Author information: 
(1)Greehey Children's Cancer Research Institute, University of Texas Health
Science Center at San Antonio, San Antonio, TX, United States of America.
(2)Department of Medical Research, Taichung Veterans General Hospital, Taichung, 
Taiwan. (3)Graduate Institute of Biomedical Electronics and Bioinformatics,
National Taiwan University, Taipei, Taiwan. (4)Department of Molecular
Medicine/Institute of Biotechnology, University of Texas Health Science Center at
San Antonio, San Antonio, TX, United States of America. (5)Institute of
Epidemiology and Preventive Medicine, National Taiwan University, Taipei, Taiwan.
(6)Graduate Institute of Physiology, National Taiwan University, Taipei, Taiwan. 
(7)Bioinformatics and Biostatistics Core, Center of Genomic Medicine, National
Taiwan University, Taipei, Taiwan. (8)Institute of Biotechnology, National Taiwan
University, Taipei, Taiwan. (9)Department of Epidemiology and Biostatistics,
University of Texas Health Science Center at San Antonio, San Antonio, TX, United
States of America.

Several mutual information (MI)-based algorithms have been developed to identify 
dynamic gene-gene and function-function interactions governed by key modulators
(genes, proteins, etc.). Due to intensive computation, however, these methods
rely heavily on prior knowledge and are limited in genome-wide analysis. We
present the modulated gene/gene set interaction (MAGIC) analysis to
systematically identify genome-wide modulation of interaction networks. Based on 
a novel statistical test employing conjugate Fisher transformations of
correlation coefficients, MAGIC features fast computation and adaption to
variations of clinical cohorts. In simulated datasets MAGIC achieved greatly
improved computation efficiency and overall superior performance than the
MI-based method. We applied MAGIC to construct the estrogen receptor (ER)
modulated gene and gene set (representing biological function) interaction
networks in breast cancer. Several novel interaction hubs and functional
interactions were discovered. ER+ dependent interaction between TGFβ and NFκB was
further shown to be associated with patient survival. The findings were verified 
in independent datasets. Using MAGIC, we also assessed the essential roles of ER 
modulation in another hormonal cancer, ovarian cancer. Overall, MAGIC is a
systematic framework for comprehensively identifying and constructing the
modulated interaction networks in a whole-genome landscape. MATLAB implementation
of MAGIC is available for academic uses at https://github.com/chiuyc/MAGIC.

DOI: 10.1038/srep23035 
PMCID: PMC4789788
PMID: 26972162  [PubMed - indexed for MEDLINE]


617. Comput Biol Chem. 2016 Aug;63:62-72. doi: 10.1016/j.compbiolchem.2016.01.014.
Epub 2016 Feb 13.

MOCCS: Clarifying DNA-binding motif ambiguity using ChIP-Seq data.

Ozaki H(1), Iwasaki W(2).

Author information: 
(1)Department of Computational Biology, Graduate School of Frontier Sciences, The
University of Tokyo, Kashiwanoha 5-1-5, Kashiwa, 277-8568 Chiba, Japan.
Electronic address: haruka.ozaki@riken.jp. (2)Department of Computational
Biology, Graduate School of Frontier Sciences, The University of Tokyo,
Kashiwanoha 5-1-5, Kashiwa, 277-8568 Chiba, Japan; Department of Biological
Sciences, Graduate School of Science, The University of Tokyo, Hongo 7-3-1,
Bunkyo-ku, 113-0032 Tokyo, Japan; Atmosphere and Ocean Research Institute, The
University of Tokyo, Kashiwanoha 5-1-5, Kashiwa, 277-8564 Chiba, Japan.
Electronic address: iwasaki@bs.s.u-tokyo.ac.jp.

BACKGROUND: As a key mechanism of gene regulation, transcription factors (TFs)
bind to DNA by recognizing specific short sequence patterns that are called
DNA-binding motifs. A single TF can accept ambiguity within its DNA-binding
motifs, which comprise both canonical (typical) and non-canonical motifs.
Clarification of such DNA-binding motif ambiguity is crucial for revealing gene
regulatory networks and evaluating mutations in cis-regulatory elements. Although
chromatin immunoprecipitation sequencing (ChIP-seq) now provides abundant data on
the genomic sequences to which a given TF binds, existing motif discovery methods
are unable to directly answer whether a given TF can bind to a specific
DNA-binding motif.
RESULTS: Here, we report a method for clarifying the DNA-binding motif ambiguity,
MOCCS. Given ChIP-Seq data of any TF, MOCCS comprehensively analyzes and
describes every k-mer to which that TF binds. Analysis of simulated datasets
revealed that MOCCS is applicable to various ChIP-Seq datasets, requiring only a 
few minutes per dataset. Application to the ENCODE ChIP-Seq datasets proved that 
MOCCS directly evaluates whether a given TF binds to each DNA-binding motif, even
if known position weight matrix models do not provide sufficient information on
DNA-binding motif ambiguity. Furthermore, users are not required to provide
numerous parameters or background genomic sequence models that are typically
unavailable. MOCCS is implemented in Perl and R and is freely available via
https://github.com/yuifu/moccs.
CONCLUSIONS: By complementing existing motif-discovery software, MOCCS will
contribute to the basic understanding of how the genome controls diverse cellular
processes via DNA-protein interactions.

Copyright © 2016 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.compbiolchem.2016.01.014 
PMID: 26971251  [PubMed - in process]


618. Semin Oncol. 2016 Feb;43(1):13-8. doi: 10.1053/j.seminoncol.2016.01.002. Epub
2016 Jan 18.

The Bayesian basket design for genomic variant-driven phase II trials.

Simon R(1), Geyer S(2), Subramanian J(3), Roychowdhury S(4).

Author information: 
(1)Division of Cancer Treatment & Diagnosis, National Cancer Institute, 9609
Medical Center Dr, Rockville, MD 20892-9735, USA. Electronic address:
rsimon@nih.gov. (2)Department of Pediatrics, University of South Florida, Tampa, 
FL, USA. (3)Emmes Corporation, Rockville, MD, USA. (4)Department of Internal
Medicine, The James Cancer Center, Ohio State University, Columbus, OH, USA.

Basket clinical trials are a new category of early clinical trials in which a
treatment is evaluated in a population of patients with tumors of various
histologic types and primary sites selected for containing specific genomic
abnormalities. The objective of such studies is generally to discover histologic 
types in which the treatment is active. Basket trials are early discovery trials 
whose results should be confirmed in expanded histology specific cohorts. In this
report, we develop a design for planning, monitoring, and analyzing basket
trials. A website for using the new design is available at
https://brbnci.shinyapps.io/BasketTrials/ and the software is available at GitHub
in the "Basket Trials" repository of account brbnci.

Copyright © 2016 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1053/j.seminoncol.2016.01.002 
PMID: 26970120  [PubMed - indexed for MEDLINE]


619. BMC Syst Biol. 2016 Mar 11;10:26. doi: 10.1186/s12918-016-0271-6.

Systems biology of the structural proteome.

Brunk E(1,)(2), Mih N(3), Monk J(1), Zhang Z(1), O'Brien EJ(1), Bliven SE(3,)(4),
Chen K(1), Chang RL(5), Bourne PE(6), Palsson BO(7).

Author information: 
(1)Department of Bioengineering, University of California, La Jolla, San Diego,
CA, 92093, USA. (2)Joint BioEnergy Institute, Emeryville, CA, 94608, USA.
(3)Bioinformatics and Systems Biology Program, University of California, La
Jolla, San Diego, CA, 92093, USA. (4)National Center for Biotechnology
Information, National Library of Medicine, National Institutes of Health,
Bethesda, MD, 20894, USA. (5)Department of Systems Biology, Harvard Medical
School, Boston, MA, 02115, USA. (6)Office of the Director, National Institutes of
Health, Bethesda, MD, 20894, USA. (7)Department of Bioengineering, University of 
California, La Jolla, San Diego, CA, 92093, USA. palsson@eng.ucsd.edu.

BACKGROUND: The success of genome-scale models (GEMs) can be attributed to the
high-quality, bottom-up reconstructions of metabolic, protein synthesis, and
transcriptional regulatory networks on an organism-specific basis. Such
reconstructions are biochemically, genetically, and genomically structured
knowledge bases that can be converted into a mathematical format to enable a
myriad of computational biological studies. In recent years, genome-scale
reconstructions have been extended to include protein structural information,
which has opened up new vistas in systems biology research and empowered
applications in structural systems biology and systems pharmacology.
RESULTS: Here, we present the generation, application, and dissemination of
genome-scale models with protein structures (GEM-PRO) for Escherichia coli and
Thermotoga maritima. We show the utility of integrating molecular scale analyses 
with systems biology approaches by discussing several comparative analyses on the
temperature dependence of growth, the distribution of protein fold families,
substrate specificity, and characteristic features of whole cell proteomes.
Finally, to aid in the grand challenge of big data to knowledge, we provide
several explicit tutorials of how protein-related information can be linked to
genome-scale models in a public GitHub repository (
https://github.com/SBRG/GEMPro/tree/master/GEMPro_recon/).
CONCLUSIONS: Translating genome-scale, protein-related information to structured 
data in the format of a GEM provides a direct mapping of gene to gene-product to 
protein structure to biochemical reaction to network states to phenotypic
function. Integration of molecular-level details of individual proteins, such as 
their physical, chemical, and structural properties, further expands the
description of biochemical network-level properties, and can ultimately influence
how to model and predict whole cell phenotypes as well as perform comparative
systems biology approaches to study differences between organisms. GEM-PRO offers
insight into the physical embodiment of an organism's genotype, and its use in
this comparative framework enables exploration of adaptive strategies for these
organisms, opening the door to many new lines of research. With these provided
tools, tutorials, and background, the reader will be in a position to run GEM-PRO
for their own purposes.

DOI: 10.1186/s12918-016-0271-6 
PMCID: PMC4787049
PMID: 26969117  [PubMed - in process]


620. Stat Appl Genet Mol Biol. 2016 Apr;15(2):123-38. doi: 10.1515/sagmb-2014-0081.

Resistant multiple sparse canonical correlation.

Coleman J, Replogle J, Chandler G, Hardin J.

Canonical correlation analysis (CCA) is a multivariate technique that takes two
datasets and forms the most highly correlated possible pairs of linear
combinations between them. Each subsequent pair of linear combinations is
orthogonal to the preceding pair, meaning that new information is gleaned from
each pair. By looking at the magnitude of coefficient values, we can find out
which variables can be grouped together, thus better understanding multiple
interactions that are otherwise difficult to compute or grasp intuitively. CCA
appears to have quite powerful applications to high-throughput data, as we can
use it to discover, for example, relationships between gene expression and gene
copy number variation. One of the biggest problems of CCA is that the number of
variables (often upwards of 10,000) makes biological interpretation of linear
combinations nearly impossible. To limit variable output, we have employed a
method known as sparse canonical correlation analysis (SCCA), while adding
estimation which is resistant to extreme observations or other types of deviant
data. In this paper, we have demonstrated the success of resistant estimation in 
variable selection using SCCA. Additionally, we have used SCCA to find multiple
canonical pairs for extended knowledge about the datasets at hand. Again, using
resistant estimators provided more accurate estimates than standard estimators in
the multiple canonical correlation setting. R code is available and documented at
https://github.com/hardin47/rmscca.

DOI: 10.1515/sagmb-2014-0081 
PMID: 26963062  [PubMed - indexed for MEDLINE]


621. BMC Bioinformatics. 2016 Mar 2;17 Suppl 4:83. doi: 10.1186/s12859-016-0912-1.

Multiplex methods provide effective integration of multi-omic data in
genome-scale models.

Angione C(1), Conway M(2), Lió P(3).

Author information: 
(1)School of Computing - Teesside University, Middlesbrough, UK.
c.angione@tees.ac.uk. (2)Computer Laboratory - University of Cambridge,
Cambridge, UK. max.conway@cl.cam.ac.uk. (3)Computer Laboratory - University of
Cambridge, Cambridge, UK. pietro.lio@cl.cam.ac.uk.

BACKGROUND: Genomic, transcriptomic, and metabolic variations shape the complex
adaptation landscape of bacteria to varying environmental conditions. Elucidating
the genotype-phenotype relation paves the way for the prediction of such effects,
but methods for characterizing the relationship between multiple environmental
factors are still lacking. Here, we tackle the problem of extracting
network-level information from collections of environmental conditions, by
integrating the multiple omic levels at which the bacterial response is measured.
RESULTS: To this end, we model a large compendium of growth conditions as a
multiplex network consisting of transcriptomic and fluxomic layers, and we
propose a multi-omic network approach to infer similarity of growth conditions by
integrating layers of the multiplex network. Each node of the network represents 
a single condition, while edges are similarities between conditions, as measured 
by phenotypic and transcriptomic properties on different layers of the network.
We then fuse these layers into one network, therefore capturing a global network 
of conditions and the associated similarities across two omic levels. We apply
this multi-omic fusion to an updated genome-scale reconstruction of Escherichia
coli that includes underground metabolism and new gene-protein-reaction
associations.
CONCLUSIONS: Our method can be readily used to evaluate and cross-compare
different collections of conditions among different species. Acquiring multi-omic
information on the topology of the space of experimental conditions makes it
possible to infer the position and to build condition-specific models of untested
or incomplete profiles for which experimental data is not available. Our weighted
network fusion method for genome-scale models is freely available at
https://github.com/maxconway/SNFtool .

DOI: 10.1186/s12859-016-0912-1 
PMCID: PMC4896256
PMID: 26961692  [PubMed - indexed for MEDLINE]


622. J Comput Biol. 2016 Apr;23(4):229-38. doi: 10.1089/cmb.2015.0214. Epub 2016 Mar
7.

bioOTU: An Improved Method for Simultaneous Taxonomic Assignments and Operational
Taxonomic Units Clustering of 16s rRNA Gene Sequences.

Chen SY(1), Deng F(1), Huang Y(2), Jia X(1), Liu YP(1), Lai SJ(1).

Author information: 
(1)1 Farm Animal Genetic Resources Exploration and Innovation Key Laboratory of
Sichuan Province, Chengdu, China . (2)2 College of Veterinary Medicine, Sichuan
Agricultural University , Chengdu, China .

Clustering of 16s rRNA amplicon sequences into operational taxonomic units (OTUs)
is the most common bioinformatics pipeline for investigating microbial community 
by high-throughput sequencing technologies. However, the existing algorithms of
OTUs clustering still remain to be improved at reliability. Here we propose an
improved method (bioOTU) that first assigns taxonomy to unique tags at genus
level for separating the error-free sequences of known species in reference
database from artifacts, and then cluster them into OTUs by different strategies.
The remaining tags, which fail to be clustered in the previous step, are further 
subjected to independent OTUs clustering by the optimized algorithm of heuristic 
clustering. The performance tests on both mock and real communities revealed that
bioOTU is powerful for recovering the underlying profiles at both microbial
composition and abundance, and it also produces comparable or less number of OTUs
in comparison with the prevailing tools of Mothur and UPARSE. The bioOTU is
implemented in C and Python languages with source codes freely available on the
GitHub repository.

DOI: 10.1089/cmb.2015.0214 
PMID: 26950196  [PubMed - indexed for MEDLINE]


623. Ultramicroscopy. 2016 May;164:51-61. doi: 10.1016/j.ultramic.2016.02.004. Epub
2016 Mar 2.

A numerical model for multiple detector energy dispersive X-ray spectroscopy in
the transmission electron microscope.

Xu W(1), Dycus JH(1), Sang X(1), LeBeau JM(2).

Author information: 
(1)Department of Materials Science and Engineering, North Carolina State
University, Raleigh, NC 27695, USA. (2)Department of Materials Science and
Engineering, North Carolina State University, Raleigh, NC 27695, USA. Electronic 
address: jmlebeau@ncsu.edu.

Here we report a numerical approach to model a four quadrant energy dispersive
X-ray spectrometer in the transmission electron microscope. The model includes
detector geometries, specimen position and absorption, shadowing by the holder,
and filtering by the Be carrier. We show that this comprehensive model accurately
predicts absolute counts and intensity ratios as a function of specimen tilt and 
position. We directly compare the model to experimental results acquired with a
FEI Super-X EDS four quadrant detector. The contribution from each detector to
the sum is investigated. The program and source code can be downloaded from
https://github.com/subangstrom/superAngle.

Copyright © 2016 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.ultramic.2016.02.004 
PMID: 26948674  [PubMed]


624. BMC Bioinformatics. 2016 Mar 2;17:114. doi: 10.1186/s12859-016-0970-4.

MetICA: independent component analysis for high-resolution mass-spectrometry
based non-targeted metabolomics.

Liu Y(1,)(2), Smirnov K(3), Lucio M(4), Gougeon RD(5), Alexandre H(6),
Schmitt-Kopplin P(7,)(8).

Author information: 
(1)Research Unit Analytical BioGeoChemistry, Department of Environmental
Sciences, Helmholtz Zentrum München, Ingolstädter Landstr.1, 85758, Neuherberg,
Germany. youzhong.liu@u-bourgogne.fr. (2)UMR PAM Université de Bourgogne/Agrosup 
Dijon, Institut Universitaire de la Vigne et du Vin, Jules Guyot, Rue Claude
Ladrey, BP 27877, Dijon, Cedex, France. youzhong.liu@u-bourgogne.fr. (3)Research 
Unit Analytical BioGeoChemistry, Department of Environmental Sciences, Helmholtz 
Zentrum München, Ingolstädter Landstr.1, 85758, Neuherberg, Germany.
kirill.smirnov@helmholtz-muenchen.de. (4)Research Unit Analytical
BioGeoChemistry, Department of Environmental Sciences, Helmholtz Zentrum München,
Ingolstädter Landstr.1, 85758, Neuherberg, Germany.
marianna.lucio@helmholtz-muenchen.de. (5)UMR PAM Université de Bourgogne/Agrosup 
Dijon, Institut Universitaire de la Vigne et du Vin, Jules Guyot, Rue Claude
Ladrey, BP 27877, Dijon, Cedex, France. regis.gougeon@u-bourgogne.fr. (6)UMR PAM 
Université de Bourgogne/Agrosup Dijon, Institut Universitaire de la Vigne et du
Vin, Jules Guyot, Rue Claude Ladrey, BP 27877, Dijon, Cedex, France.
rvalex@u-bourgogne.fr. (7)Research Unit Analytical BioGeoChemistry, Department of
Environmental Sciences, Helmholtz Zentrum München, Ingolstädter Landstr.1, 85758,
Neuherberg, Germany. schmitt-kopplin@helmholtz-muenchen.de. (8)Technische
Universität München, Chair of Analytical Food Chemistry, Alte Akademie 1085354,
Freising-Weihenstephan, Germany. schmitt-kopplin@helmholtz-muenchen.de.

BACKGROUND: Interpreting non-targeted metabolomics data remains a challenging
task. Signals from non-targeted metabolomics studies stem from a combination of
biological causes, complex interactions between them and experimental bias/noise.
The resulting data matrix usually contain huge number of variables and only few
samples, and classical techniques using nonlinear mapping could result in
computational complexity and overfitting. Independent Component Analysis (ICA) as
a linear method could potentially bring more meaningful results than Principal
Component Analysis (PCA). However, a major problem with most ICA algorithms is
the output variations between different runs and the result of a single ICA run
should be interpreted with reserve.
RESULTS: ICA was applied to simulated and experimental mass spectrometry
(MS)-based non-targeted metabolomics data, under the hypothesis that underlying
sources are mutually independent. Inspired from the Icasso algorithm, a new ICA
method, MetICA was developed to handle the instability of ICA on complex
datasets. Like the original Icasso algorithm, MetICA evaluated the algorithmic
and statistical reliability of ICA runs. In addition, MetICA suggests two ways to
select the optimal number of model components and gives an order of
interpretation for the components obtained.
CONCLUSIONS: Correlating the components obtained with prior biological knowledge 
allows understanding how non-targeted metabolomics data reflect biological nature
and technical phenomena. We could also extract mass signals related to this
information. This novel approach provides meaningful components due to their
independent nature. Furthermore, it provides an innovative concept on which to
base model selection: that of optimizing the number of reliable components
instead of trying to fit the data. The current version of MetICA is available at 
https://github.com/daniellyz/MetICA.

DOI: 10.1186/s12859-016-0970-4 
PMCID: PMC4776428
PMID: 26936354  [PubMed - indexed for MEDLINE]


625. BMC Bioinformatics. 2016 Mar 3;17:115. doi: 10.1186/s12859-016-0969-x.

MaGuS: a tool for quality assessment and scaffolding of genome assemblies with
Whole Genome Profiling™ Data.

Madoui MA(1), Dossat C(2), d'Agata L(3), van Oeveren J(4), van der Vossen E(5),
Aury JM(6).

Author information: 
(1)CEA, DSV, Institut de Génomique, Genoscope, 2 rue Gaston Crémieux, CP5706,
91057, Evry, France. amadoui@genoscope.cns.fr. (2)CEA, DSV, Institut de
Génomique, Genoscope, 2 rue Gaston Crémieux, CP5706, 91057, Evry, France.
cdossat@genoscope.cns.fr. (3)CEA, DSV, Institut de Génomique, Genoscope, 2 rue
Gaston Crémieux, CP5706, 91057, Evry, France. ldataga@genoscope.cns.fr.
(4)Keygene NV, Agro Business Park 90, 6708 PW, Wageningen, The Netherlands.
jan.van-oeveren@keygene.com. (5)Keygene NV, Agro Business Park 90, 6708 PW,
Wageningen, The Netherlands. edwin.van-der-vossen@keygene.com. (6)CEA, DSV,
Institut de Génomique, Genoscope, 2 rue Gaston Crémieux, CP5706, 91057, Evry,
France. jmaury@genoscope.cns.fr.

BACKGROUND: Scaffolding is an essential step in the genome assembly process.
Current methods based on large fragment paired-end reads or long reads allow an
increase in contiguity but often lack consistency in repetitive regions,
resulting in fragmented assemblies. Here, we describe a novel tool to link
assemblies to a genome map to aid complex genome reconstruction by detecting
assembly errors and allowing scaffold ordering and anchoring.
RESULTS: We present MaGuS (map-guided scaffolding), a modular tool that uses a
draft genome assembly, a Whole Genome Profiling™ (WGP) map, and high-throughput
paired-end sequencing data to estimate the quality and to enhance the contiguity 
of an assembly. We generated several assemblies of the Arabidopsis genome using
different scaffolding programs and applied MaGuS to select the best assembly
using quality metrics. Then, we used MaGuS to perform map-guided scaffolding to
increase contiguity by creating new scaffold links in low-covered and highly
repetitive regions where other commonly used scaffolding methods lack
consistency.
CONCLUSIONS: MaGuS is a powerful reference-free evaluator of assembly quality and
a WGP map-guided scaffolder that is freely available at
https://github.com/institut-de-genomique/MaGuS. Its use can be extended to other 
high-throughput sequencing data (e.g., long-read data) and also to other map data
(e.g., genetic maps) to improve the quality and the contiguity of large and
complex genome assemblies.

DOI: 10.1186/s12859-016-0969-x 
PMCID: PMC4776351
PMID: 26936254  [PubMed - indexed for MEDLINE]


626. Anal Bioanal Chem. 2016 Apr;408(11):2975-83. doi: 10.1007/s00216-015-9299-5. Epub
2016 Mar 2.

PEPR: pipelines for evaluating prokaryotic references.

Olson ND(1), Zook JM(2), Samarov DV(3), Jackson SA(2), Salit ML(2,)(4).

Author information: 
(1)Biosystems and Biomaterials Division, Material Measurement Laboratory,
National Institute of Standards and Technology, Gaithersburg, MD, USA.
nolson@nist.gov. (2)Biosystems and Biomaterials Division, Material Measurement
Laboratory, National Institute of Standards and Technology, Gaithersburg, MD,
USA. (3)Statistical Engineering Division, Information Technology Laboratory,
National Institute of Standards and Technology, Gaithersburg, MD, USA.
(4)Department of Bioengineering, Stanford University, Stanford, CA, USA.

The rapid adoption of microbial whole genome sequencing in public health,
clinical testing, and forensic laboratories requires the use of validated
measurement processes. Well-characterized, homogeneous, and stable microbial
genomic reference materials can be used to evaluate measurement processes,
improving confidence in microbial whole genome sequencing results. We have
developed a reproducible and transparent bioinformatics tool, PEPR, Pipelines for
Evaluating Prokaryotic References, for characterizing the reference genome of
prokaryotic genomic materials. PEPR evaluates the quality, purity, and
homogeneity of the reference material genome, and purity of the genomic material.
The quality of the genome is evaluated using high coverage paired-end sequence
data; coverage, paired-end read size and direction, as well as soft-clipping
rates, are used to identify mis-assemblies. The homogeneity and purity of the
material relative to the reference genome are characterized by comparing base
calls from replicate datasets generated using multiple sequencing technologies.
Genomic purity of the material is assessed by checking for DNA contaminants. We
demonstrate the tool and its output using sequencing data while developing a
Staphylococcus aureus candidate genomic reference material. PEPR is open source
and available at https://github.com/usnistgov/pepr .

DOI: 10.1007/s00216-015-9299-5 
PMCID: PMC4819933
PMID: 26935931  [PubMed - indexed for MEDLINE]


627. PLoS One. 2016 Mar 2;11(3):e0148538. doi: 10.1371/journal.pone.0148538.
eCollection 2016.

Bio-SCoRes: A Smorgasbord Architecture for Coreference Resolution in Biomedical
Text.

Kilicoglu H(1), Demner-Fushman D(1).

Author information: 
(1)Lister Hill National Center for Biomedical Communications, National Library of
Medicine, National Institutes of Health, Bethesda, MD, United States of America.

Coreference resolution is one of the fundamental and challenging tasks in natural
language processing. Resolving coreference successfully can have a significant
positive effect on downstream natural language processing tasks, such as
information extraction and question answering. The importance of coreference
resolution for biomedical text analysis applications has increasingly been
acknowledged. One of the difficulties in coreference resolution stems from the
fact that distinct types of coreference (e.g., anaphora, appositive) are
expressed with a variety of lexical and syntactic means (e.g., personal pronouns,
definite noun phrases), and that resolution of each combination often requires a 
different approach. In the biomedical domain, it is common for coreference
annotation and resolution efforts to focus on specific subcategories of
coreference deemed important for the downstream task. In the current work, we aim
to address some of these concerns regarding coreference resolution in biomedical 
text. We propose a general, modular framework underpinned by a smorgasbord
architecture (Bio-SCoRes), which incorporates a variety of coreference types,
their mentions and allows fine-grained specification of resolution strategies to 
resolve coreference of distinct coreference type-mention pairs. For development
and evaluation, we used a corpus of structured drug labels annotated with
fine-grained coreference information. In addition, we evaluated our approach on
two other corpora (i2b2/VA discharge summaries and protein coreference dataset)
to investigate its generality and ease of adaptation to other biomedical text
types. Our results demonstrate the usefulness of our novel smorgasbord
architecture. The specific pipelines based on the architecture perform
successfully in linking coreferential mention pairs, while we find that
recognition of full mention clusters is more challenging. The corpus of
structured drug labels (SPL) as well as the components of Bio-SCoRes and some of 
the pipelines based on it are publicly available at
https://github.com/kilicogluh/Bio-SCoRes. We believe that Bio-SCoRes can serve as
a strong and extensible baseline system for coreference resolution of biomedical 
text.

DOI: 10.1371/journal.pone.0148538 
PMCID: PMC4774913
PMID: 26934708  [PubMed - indexed for MEDLINE]


628. J Cheminform. 2016 Mar 1;8:11. doi: 10.1186/s13321-016-0123-9. eCollection 2016.

libChEBI: an API for accessing the ChEBI database.

Swainston N(1), Hastings J(2), Dekker A(2), Muthukrishnan V(2), May J(3),
Steinbeck C(2), Mendes P(4).

Author information: 
(1)Manchester Centre for Synthetic Biology of Fine and Specialty Chemicals
(SYNBIOCHEM), Manchester Institute of Biotechnology, University of Manchester,
Manchester, M1 7DN UK ; European Bioinformatics Institute, Hinxton, Cambridge,
CB10 1SD UK. (2)European Bioinformatics Institute, Hinxton, Cambridge, CB10 1SD
UK. (3)European Bioinformatics Institute, Hinxton, Cambridge, CB10 1SD UK ;
NextMove Software Ltd., Innovation Centre, Science Park, Milton Road, Cambridge, 
CB4 0EY UK. (4)Manchester Centre for Synthetic Biology of Fine and Specialty
Chemicals (SYNBIOCHEM), Manchester Institute of Biotechnology, University of
Manchester, Manchester, M1 7DN UK ; School of Computer Science, University of
Manchester, Manchester, M13 9PL UK ; Center for Quantitative Medicine, UConn
Health, Farmington, CT 06030 USA.

BACKGROUND: ChEBI is a database and ontology of chemical entities of biological
interest. It is widely used as a source of identifiers to facilitate unambiguous 
reference to chemical entities within biological models, databases, ontologies
and literature. ChEBI contains a wealth of chemical data, covering over 46,500
distinct chemical entities, and related data such as chemical formula, charge,
molecular mass, structure, synonyms and links to external databases. Furthermore,
ChEBI is an ontology, and thus provides meaningful links between chemical
entities. Unlike many other resources, ChEBI is fully human-curated, providing a 
reliable, non-redundant collection of chemical entities and related data. While
ChEBI is supported by a web service for programmatic access and a number of
download files, it does not have an API library to facilitate the use of ChEBI
and its data in cheminformatics software.
RESULTS: To provide this missing functionality, libChEBI, a comprehensive API
library for accessing ChEBI data, is introduced. libChEBI is available in Java,
Python and MATLAB versions from http://github.com/libChEBI, and provides full
programmatic access to all data held within the ChEBI database through a simple
and documented API. libChEBI is reliant upon the (automated) download and regular
update of flat files that are held locally. As such, libChEBI can be embedded in 
both on- and off-line software applications.
CONCLUSIONS: libChEBI allows better support of ChEBI and its data in the
development of new cheminformatics software. Covering three key programming
languages, it allows for the entirety of the ChEBI database to be accessed easily
and quickly through a simple API. All code is open access and freely available.

DOI: 10.1186/s13321-016-0123-9 
PMCID: PMC4772646
PMID: 26933452  [PubMed]


629. PLoS One. 2016 Mar 1;11(3):e0150465. doi: 10.1371/journal.pone.0150465.
eCollection 2016.

RED: A Java-MySQL Software for Identifying and Visualizing RNA Editing Sites
Using Rule-Based and Statistical Filters.

Sun Y(1), Li X(1), Wu D(1), Pan Q(2), Ji Y(1), Ren H(2), Ding K(2).

Author information: 
(1)School of Information and Communication Engineering, Beijing University of
Posts & Telecommunications, Beijing, P. R. China. (2)Key Laboratory of Molecular 
Biology for Infectious Diseases (Ministry of Education), Institute for Viral
Hepatitis, Department of Infectious Diseases, The Second Affiliated Hospital,
Chongqing Medical University, Chongqing, China.

RNA editing is one of the post- or co-transcriptional processes that can lead to 
amino acid substitutions in protein sequences, alternative pre-mRNA splicing, and
changes in gene expression levels. Although several methods have been suggested
to identify RNA editing sites, there remains challenges to be addressed in
distinguishing true RNA editing sites from its counterparts on genome and
technical artifacts. In addition, there lacks a software framework to identify
and visualize potential RNA editing sites. Here, we presented a software - 'RED' 
(RNA Editing sites Detector) - for the identification of RNA editing sites by
integrating multiple rule-based and statistical filters. The potential RNA
editing sites can be visualized at the genome and the site levels by graphical
user interface (GUI). To improve performance, we used MySQL database management
system (DBMS) for high-throughput data storage and query. We demonstrated the
validity and utility of RED by identifying the presence and absence of C→U
RNA-editing sites experimentally validated, in comparison with REDItools, a
command line tool to perform high-throughput investigation of RNA editing. In an 
analysis of a sample data-set with 28 experimentally validated C→U RNA editing
sites, RED had sensitivity and specificity of 0.64 and 0.5. In comparison,
REDItools had a better sensitivity (0.75) but similar specificity (0.5). RED is
an easy-to-use, platform-independent Java-based software, and can be applied to
RNA-seq data without or with DNA sequencing data. The package is freely available
under the GPLv3 license at http://github.com/REDetector/RED or
https://sourceforge.net/projects/redetector.

DOI: 10.1371/journal.pone.0150465 
PMCID: PMC4773184
PMID: 26930599  [PubMed - indexed for MEDLINE]


630. Biodivers Data J. 2016 Feb 4;(4):e7606. doi: 10.3897/BDJ.4.e7606. eCollection
2016.

The Meristogram: a neglected tool for acanthocephalan systematics.

Wayland MT(1).

Author information: 
(1)Department of Zoology, University of Cambridge, Cambridge, United Kingdom.

BACKGROUND: The hooks of the acanthocephalan proboscis exhibit serial variation
in size and shape. The Meristogram was developed by Huffman and Bullock (1975) to
provide a graphical representation of this positional variation in hook
morphology. Initial studies demonstrated the ability of the Meristogram to
discriminate species within the genera Echinorhynchus and Pomphorhynchus (Huffman
and Bullock 1975, Huffman and Nickol 1978, Gleason and Huffman 1981). However,
the reliability of the method for taxonomic work was questioned by Shostak et al.
(1986) after they found intra-specific variation in two Echinorhynchus species.
Uncertainty about the usefulness of the Meristogram and the absence of a readily 
available software implementation of the algorithm, might explain why this
abstract proboscis character has yet to be adopted by acanthocephalan
systematists.
NEW INFORMATION: The Meristogram algorithm was implemented in the R language and 
a simple graphical user interface created to facilitate ease of use (the software
is freely available from https://github.com/WaylandM/meristogram). The accuracy
of the algorithm's formula for calculating hook cross-sectional area was
validated by data collected using a digitizing tablet. Meristograms were created 
from data in public respositories for eight Echinorhynchus taxa: E. bothniensis, 
E. 'bothniensis', E. gadi spp. A, B and I, E. brayi, E. salmonis and E. truttae. 
In this preliminary analysis, the meristogram differentiated E. bothniensis, E.
brayi, E. gadi sp. B, E. salmonis and E. truttae from each other, and from the
remaining taxa in this study, but independent data will be required for
validation. Sample sizes for E. 'bothniensis' and E. gadi spp. A and I were too
small to identify diagnostic features with any degree of confidence. Meristogram 
differences among the sibling species of the E. gadi and E. bothniensis groups
suggest that the 'intra-specfic' variation in meristogram previously reported for
some Echinorhynchus taxa, may have actually represented morphological divergence 
between unrecognized cryptic species. Hierarchical clustering of taxa based on
Meristogram data yielded dendrograms that were largely concordant with
phylogenetic relationships inferred from DNA sequence data, indicating the
presence of a strong phylogenetic signal.

DOI: 10.3897/BDJ.4.e7606 
PMCID: PMC4759448
PMID: 26929718  [PubMed]


631. Front Genet. 2016 Feb 19;7:18. doi: 10.3389/fgene.2016.00018. eCollection 2016.

ROMA: Representation and Quantification of Module Activity from Target Expression
Data.

Martignetti L(1), Calzone L(1), Bonnet E(1), Barillot E(1), Zinovyev A(1).

Author information: 
(1)Computational and Systems Biology of Cancer, Institut CurieParis, France; PSL 
Research UniversityParis, France; Institut National de la Santé et de la
Recherche Médicale U900Paris, France; Mines ParisTechParis, France.

In many analyses of high-throughput data in systems biology, there is a need to
quantify the activity of a set of genes in individual samples. A typical example 
is the case where it is necessary to estimate the activity of a transcription
factor (which is often not directly measurable) from the expression of its target
genes. We present here ROMA (Representation and quantification Of Module
Activities) Java software, designed for fast and robust computation of the
activity of gene sets (or modules) with coordinated expression. ROMA activity
quantification is based on the simplest uni-factor linear model of gene
regulation that approximates the expression data of a gene set by its first
principal component. The proposed algorithm implements novel functionalities: it 
provides several method modifications for principal components computation,
including weighted, robust and centered methods; it distinguishes overdispersed
modules (based on the variance explained by the first principal component) and
coordinated modules (based on the significance of the spectral gap); finally, it 
computes statistical significance of the estimated module overdispersion or
coordination. ROMA can be applied in many contexts, from estimating differential 
activities of transcriptional factors to finding overdispersed pathways in
single-cell transcriptomics data. We describe here the principles of ROMA
providing several practical examples of its use. ROMA source code is available at
https://github.com/sysbio-curie/Roma.

DOI: 10.3389/fgene.2016.00018 
PMCID: PMC4760130
PMID: 26925094  [PubMed]


632. BMC Res Notes. 2016 Feb 27;9:130. doi: 10.1186/s13104-016-1938-1.

blastjs: a BLAST+ wrapper for Node.js.

Page M(1), MacLean D(2), Schudoma C(3,)(4).

Author information: 
(1)Bioinformatics Group, The Sainsbury Laboratory, Norwich Research Park,
Norwich, NR4 7UH, UK. martin.page@tsl.ac.uk. (2)Bioinformatics Group, The
Sainsbury Laboratory, Norwich Research Park, Norwich, NR4 7UH, UK.
dan.maclean@tsl.ac.uk. (3)Bioinformatics Group, The Sainsbury Laboratory, Norwich
Research Park, Norwich, NR4 7UH, UK. christian.schudoma@tsl.ac.uk. (4)Triticeae
Genomics Group, The Genome Analysis Centre, Norwich Research Park, Norwich, NR4
7UH, UK. christian.schudoma@tsl.ac.uk.

BACKGROUND: To cope with the ever-increasing amount of sequence data generated in
the field of genomics, the demand for efficient and fast database searches that
drive functional and structural annotation in both large- and small-scale genome 
projects is on the rise. The tools of the BLAST+ suite are the most widely
employed bioinformatic method for these database searches. Recent trends in
bioinformatics application development show an increasing number of JavaScript
apps that are based on modern frameworks such as Node.js. Until now, there is no 
way of using database searches with the BLAST+ suite from a Node.js codebase.
RESULTS: We developed blastjs, a Node.js library that wraps the search tools of
the BLAST+ suite and thus allows to easily add significant functionality to any
Node.js-based application.
CONCLUSION: blastjs is a library that allows the incorporation of BLAST+
functionality into bioinformatics applications based on JavaScript and Node.js.
The library was designed to be as user-friendly as possible and therefore
requires only a minimal amount of code in the client application. The library is 
freely available under the MIT license at https://github.com/teammaclean/blastjs.

DOI: 10.1186/s13104-016-1938-1 
PMCID: PMC4769840
PMID: 26922376  [PubMed - indexed for MEDLINE]


633. BMC Bioinformatics. 2016 Feb 27;17:107. doi: 10.1186/s12859-016-0966-0.

HPG pore: an efficient and scalable framework for nanopore sequencing data.

Tarraga J(1), Gallego A(2), Arnau V(3), Medina I(4), Dopazo J(5,)(6,)(7).

Author information: 
(1)Computational Genomics Department, Centro de Investigación Príncipe Felipe
(CIPF), Valencia, 46012, Spain. jtarraga@cipf.es. (2)Computational Genomics
Department, Centro de Investigación Príncipe Felipe (CIPF), Valencia, 46012,
Spain. agallego@cipf.es. (3)Departamento de Informática, ETSE, Universidad de
Valencia, Valencia, Spain. Vicente.Arnau@uv.es. (4)HPC Service, University
Information Services, University of Cambridge, Cambridge, UK. im411@cam.ac.uk.
(5)Computational Genomics Department, Centro de Investigación Príncipe Felipe
(CIPF), Valencia, 46012, Spain. jdopazo@cipf.es. (6)Bioinformatics of Rare
Diseases (BIER), CIBER de Enfermedades Raras (CIBERER), Valencia, Spain.
jdopazo@cipf.es. (7)Functional Genomics Node, (INB) at CIPF, Valencia, 46012,
Spain. jdopazo@cipf.es.

BACKGROUND: The use of nanopore technologies is expected to spread in the future 
because they are portable and can sequence long fragments of DNA molecules
without prior amplification. The first nanopore sequencer available, the MinION™ 
from Oxford Nanopore Technologies, is a USB-connected, portable device that
allows real-time DNA analysis. In addition, other new instruments are expected to
be released soon, which promise to outperform the current short-read technologies
in terms of throughput. Despite the flood of data expected from this technology, 
the data analysis solutions currently available are only designed to manage small
projects and are not scalable.
RESULTS: Here we present HPG Pore, a toolkit for exploring and analysing nanopore
sequencing data. HPG Pore can run on both individual computers and in the Hadoop 
distributed computing framework, which allows easy scale-up to manage the large
amounts of data expected to result from extensive use of nanopore technologies in
the future.
CONCLUSIONS: HPG Pore allows for virtually unlimited sequencing data scalability,
thus guaranteeing its continued management in near future scenarios. HPG Pore is 
available in GitHub at http://github.com/opencb/hpg-pore.

DOI: 10.1186/s12859-016-0966-0 
PMCID: PMC4769497
PMID: 26921234  [PubMed - indexed for MEDLINE]


634. BMC Bioinformatics. 2016 Feb 27;17:106. doi: 10.1186/s12859-016-0946-4.

CUDAMPF: a multi-tiered parallel framework for accelerating protein sequence
search in HMMER on CUDA-enabled GPU.

Jiang H(1), Ganesan N(2).

Author information: 
(1)Department of Elec. and Comp. Engg, Stevens Institute of Technology, Hoboken, 
NJ, 07030, USA. hjiang5@stevens.edu. (2)Department of Elec. and Comp. Engg,
Stevens Institute of Technology, Hoboken, NJ, 07030, USA. nganesan@stevens.edu.

BACKGROUND: HMMER software suite is widely used for analysis of homologous
protein and nucleotide sequences with high sensitivity. The latest version of
hmmsearch in HMMER 3.x, utilizes heuristic-pipeline which consists of MSV/SSV
(Multiple/Single ungapped Segment Viterbi) stage, P7Viterbi stage and the Forward
scoring stage to accelerate homology detection. Since the latest version is
highly optimized for performance on modern multi-core CPUs with SSE capabilities,
only a few acceleration attempts report speedup. However, the most compute
intensive tasks within the pipeline (viz., MSV/SSV and P7Viterbi stages) still
stand to benefit from the computational capabilities of massively parallel
processors.
RESULTS: A Multi-Tiered Parallel Framework (CUDAMPF) implemented on CUDA-enabled 
GPUs presented here, offers a finer-grained parallelism for MSV/SSV and Viterbi
algorithms. We couple SIMT (Single Instruction Multiple Threads) mechanism with
SIMD (Single Instructions Multiple Data) video instructions with warp-synchronism
to achieve high-throughput processing and eliminate thread idling. We also
propose a hardware-aware optimal allocation scheme of scarce resources like
on-chip memory and caches in order to boost performance and scalability of
CUDAMPF. In addition, runtime compilation via NVRTC available with CUDA 7.0 is
incorporated into the presented framework that not only helps unroll innermost
loop to yield upto 2 to 3-fold speedup than static compilation but also enables
dynamic loading and switching of kernels depending on the query model size, in
order to achieve optimal performance.
CONCLUSIONS: CUDAMPF is designed as a hardware-aware parallel framework for
accelerating computational hotspots within the hmmsearch pipeline as well as
other sequence alignment applications. It achieves significant speedup by
exploiting hierarchical parallelism on single GPU and takes full advantage of
limited resources based on their own performance features. In addition to
exceeding performance of other acceleration attempts, comprehensive evaluations
against high-end CPUs (Intel i5, i7 and Xeon) shows that CUDAMPF yields upto 440 
GCUPS for SSV, 277 GCUPS for MSV and 14.3 GCUPS for P7Viterbi all with 100 %
accuracy, which translates to a maximum speedup of 37.5, 23.1 and 11.6-fold for
MSV, SSV and P7Viterbi respectively. The source code is available at
https://github.com/Super-Hippo/CUDAMPF.

DOI: 10.1186/s12859-016-0946-4 
PMCID: PMC4769571
PMID: 26920848  [PubMed - indexed for MEDLINE]


635. Gigascience. 2016 Feb 23;5:10. doi: 10.1186/s13742-016-0115-8. eCollection 2016.

Galaxy-M: a Galaxy workflow for processing and analyzing direct infusion and
liquid chromatography mass spectrometry-based metabolomics data.

Davidson RL(1), Weber RJ(2), Liu H(2), Sharma-Oates A(2), Viant MR(2).

Author information: 
(1)GigaScience, BGI-Hong Kong Co. Ltd, Tai Po Industrial Estate, 16 Dai Fu
Street, Tai Po, NT Hong Kong ; School of Biosciences, University of Birmingham,
Birmingham, B15 2TT UK. (2)School of Biosciences, University of Birmingham,
Birmingham, B15 2TT UK.

BACKGROUND: Metabolomics is increasingly recognized as an invaluable tool in the 
biological, medical and environmental sciences yet lags behind the methodological
maturity of other omics fields. To achieve its full potential, including the
integration of multiple omics modalities, the accessibility, standardization and 
reproducibility of computational metabolomics tools must be improved
significantly.
RESULTS: Here we present our end-to-end mass spectrometry metabolomics workflow
in the widely used platform, Galaxy. Named Galaxy-M, our workflow has been
developed for both direct infusion mass spectrometry (DIMS) and liquid
chromatography mass spectrometry (LC-MS) metabolomics. The range of tools
presented spans from processing of raw data, e.g. peak picking and alignment,
through data cleansing, e.g. missing value imputation, to preparation for
statistical analysis, e.g. normalization and scaling, and principal components
analysis (PCA) with associated statistical evaluation. We demonstrate the ease of
using these Galaxy workflows via the analysis of DIMS and LC-MS datasets, and
provide PCA scores and associated statistics to help other users to ensure that
they can accurately repeat the processing and analysis of these two datasets.
Galaxy and data are all provided pre-installed in a virtual machine (VM) that can
be downloaded from the GigaDB repository. Additionally, source code, executables 
and installation instructions are available from GitHub.
CONCLUSIONS: The Galaxy platform has enabled us to produce an easily accessible
and reproducible computational metabolomics workflow. More tools could be added
by the community to expand its functionality. We recommend that Galaxy-M workflow
files are included within the supplementary information of publications, enabling
metabolomics studies to achieve greater reproducibility.

DOI: 10.1186/s13742-016-0115-8 
PMCID: PMC4765054
PMID: 26913198  [PubMed - indexed for MEDLINE]


636. F1000Res. 2015 Dec 30;4. pii: ISCB Comm J-1520. doi:
10.12688/f1000research.7647.1. eCollection 2015.

CausalTrail: Testing hypothesis using causal Bayesian networks.

Stöckel D(1), Schmidt F(2), Trampert P(1), Lenhof HP(1).

Author information: 
(1)Centre for Bioinformatics, Saarland University, Saarbrücken, 66123, Germany.
(2)Centre for Bioinformatics, Saarland University, Saarbrücken, 66123, Germany;
Cluster of Excellence 'Multimodal Computing and Interaction', Computer Science,
Saarland University, Saarbrücken, 66123, Germany.

Summary Causal Bayesian Networks are a special class of Bayesian networks in
which the hierarchy directly encodes the causal relationships between the
variables. This allows to compute the effect of interventions, which are external
changes to the system, caused by e.g. gene knockouts or an administered drug.
Whereas numerous packages for constructing causal Bayesian networks are
available, hardly any program targeted at downstream analysis exists. In this
paper we present CausalTrail, a tool for performing reasoning on causal Bayesian 
networks using the do-calculus. CausalTrail's features include multiple data
import methods, a flexible query language for formulating hypotheses, as well as 
an intuitive graphical user interface. The program is able to account for missing
data and thus can be readily applied in multi-omics settings where it is common
that not all measurements are performed for all samples. Availability and
Implementation CausalTrail is implemented in C++ using the Boost and Qt5
libraries. It can be obtained from https://github.com/dstoeckel/causaltrail.

DOI: 10.12688/f1000research.7647.1 
PMCID: PMC4743151
PMID: 26913195  [PubMed]


637. Genome Biol. 2016 Feb 24;17:33. doi: 10.1186/s13059-016-0895-2.

Modelling local gene networks increases power to detect trans-acting genetic
effects on gene expression.

Rakitsch B(1), Stegle O(2).

Author information: 
(1)European Molecular Biology Laboratory, European Bioinformatics Institute,
Wellcome Trust Genome Campus, Hinxton, Cambridge, UK. rakitsch@ebi.ac.uk.
(2)European Molecular Biology Laboratory, European Bioinformatics Institute,
Wellcome Trust Genome Campus, Hinxton, Cambridge, UK. stegle@ebi.ac.uk.

Expression quantitative trait loci (eQTL) mapping is a widely used tool to study 
the genetics of gene expression. Confounding factors and the burden of multiple
testing limit the ability to map distal trans eQTLs, which is important to
understand downstream genetic effects on genes and pathways. We propose a
two-stage linear mixed model that first learns local directed gene-regulatory
networks to then condition on the expression levels of selected genes. We show
that this covariate selection approach controls for confounding factors and
regulatory context, thereby increasing eQTL detection power and improving the
consistency between studies. GNet-LMM is available at:
https://github.com/PMBio/GNetLMM.

DOI: 10.1186/s13059-016-0895-2 
PMCID: PMC4765046
PMID: 26911988  [PubMed - indexed for MEDLINE]


638. J Theor Biol. 2016 May 21;397:145-50. doi: 10.1016/j.jtbi.2016.02.020. Epub 2016 
Feb 22.

Predicting lysine phosphoglycerylation with fuzzy SVM by incorporating k-spaced
amino acid pairs into Chou׳s general PseAAC.

Ju Z(1), Cao JZ(2), Gu H(3).

Author information: 
(1)School of Control Science and Engineering, Dalian University of Technology, #2
Ling-gong Road, Dalian 116024, People׳s Republic of China. Electronic address:
juzhe1120@hotmail.com. (2)School of Control Science and Engineering, Dalian
University of Technology, #2 Ling-gong Road, Dalian 116024, People׳s Republic of 
China. Electronic address: caojunzhe@dlut.edu.cn. (3)School of Control Science
and Engineering, Dalian University of Technology, #2 Ling-gong Road, Dalian
116024, People׳s Republic of China. Electronic address: guhong@dlut.edu.cn.

As a new type of post-translational modification, lysine phosphoglycerylation
plays a key role in regulating glycolytic process and metabolism in cells. Due to
the traditional experimental methods are time-consuming and labor-intensive, it
is important to develop computational methods to identify the potential
phosphoglycerylation sites. However, the prediction performance of the existing
phosphoglycerylation site predictor is not satisfactory. In this study, a novel
predictor named CKSAAP_PhoglySite is developed to predict phosphoglycerylation
sites by using composition of k-spaced amino acid pairs and fuzzy support vector 
machine. On the one hand, after many aspects of assessments, we find the
composition of k-spaced amino acid pairs is more suitable for representing the
protein sequence around the phosphoglycerylation sites than other encoding
schemes. On the other hand, the proposed fuzzy support vector machine algorithm
can effectively handle the imbalanced and noisy problem in phosphoglycerylation
sites training dataset. Experimental results indicate that CKSAAP_PhoglySite
outperforms the existing phosphoglycerylation site predictor Phogly-PseAAC
significantly. A matlab software package for CKSAAP_PhoglySite can be freely
downloaded from
https://github.com/juzhe1120/Matlab_Software/blob/master/CKSAAP_PhoglySite_Matlab
_Software.zip.

Copyright © 2016 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.jtbi.2016.02.020 
PMID: 26908349  [PubMed - indexed for MEDLINE]


639. Microbiome. 2016 Feb 24;4:11. doi: 10.1186/s40168-016-0153-6.

Ghost-tree: creating hybrid-gene phylogenetic trees for diversity analyses.

Fouquier J(1), Rideout JR(2), Bolyen E(3), Chase J(4), Shiffer A(5,)(6), McDonald
D(7), Knight R(8), Caporaso JG(9,)(10), Kelley ST(11,)(12,)(13).

Author information: 
(1)Graduate Program in Bioinformatics and Medical Informatics, San Diego State
University, San Diego, CA, USA. jennietf@gmail.com. (2)Center for Microbial
Genetics and Genomics, Northern Arizona University, Flagstaff, AZ, USA.
jai.rideout@gmail.com. (3)Center for Microbial Genetics and Genomics, Northern
Arizona University, Flagstaff, AZ, USA. ebolyen@gmail.com. (4)Center for
Microbial Genetics and Genomics, Northern Arizona University, Flagstaff, AZ, USA.
chasejohnh@gmail.com. (5)Center for Microbial Genetics and Genomics, Northern
Arizona University, Flagstaff, AZ, USA. shiffy35@gmail.com. (6)Department of
Biological Sciences, Northern Arizona University, Flagstaff, AZ, USA.
shiffy35@gmail.com. (7)Institute for Systems Biology, Seattle, WA, USA.
wasade@gmail.com. (8)Department of Pediatrics, and Department of Computer Science
and Engineering, University of California San Diego, San Diego, CA, USA.
robknight@ucsd.edu. (9)Center for Microbial Genetics and Genomics, Northern
Arizona University, Flagstaff, AZ, USA. greg.caporaso@gmail.com. (10)Department
of Biological Sciences, Northern Arizona University, Flagstaff, AZ, USA.
greg.caporaso@gmail.com. (11)Graduate Program in Bioinformatics and Medical
Informatics, San Diego State University, San Diego, CA, USA.
skelley@mail.sdsu.edu. (12)Department of Biology, San Diego State University, San
Diego, CA, USA. skelley@mail.sdsu.edu. (13)San Diego State University, 5500
Campanile Drive, San Diego, CA, 92182-4614, USA. skelley@mail.sdsu.edu.

BACKGROUND: Fungi play critical roles in many ecosystems, cause serious diseases 
in plants and animals, and pose significant threats to human health and
structural integrity problems in built environments. While most fungal diversity 
remains unknown, the development of PCR primers for the internal transcribed
spacer (ITS) combined with next-generation sequencing has substantially improved 
our ability to profile fungal microbial diversity. Although the high sequence
variability in the ITS region facilitates more accurate species identification,
it also makes multiple sequence alignment and phylogenetic analysis unreliable
across evolutionarily distant fungi because the sequences are hard to align
accurately. To address this issue, we created ghost-tree, a bioinformatics tool
that integrates sequence data from two genetic markers into a single phylogenetic
tree that can be used for diversity analyses. Our approach starts with a
"foundation" phylogeny based on one genetic marker whose sequences can be aligned
across organisms spanning divergent taxonomic groups (e.g., fungal families).
Then, "extension" phylogenies are built for more closely related organisms (e.g.,
fungal species or strains) using a second more rapidly evolving genetic marker.
These smaller phylogenies are then grafted onto the foundation tree by mapping
taxonomic names such that each corresponding foundation-tree tip would branch
into its new "extension tree" child.
RESULTS: We applied ghost-tree to graft fungal extension phylogenies derived from
ITS sequences onto a foundation phylogeny derived from fungal 18S sequences. Our 
analysis of simulated and real fungal ITS data sets found that phylogenetic
distances between fungal communities computed using ghost-tree phylogenies
explained significantly more variance than non-phylogenetic distances. The
phylogenetic metrics also improved our ability to distinguish small differences
(effect sizes) between microbial communities, though results were similar to
non-phylogenetic methods for larger effect sizes.
CONCLUSIONS: The Silva/UNITE-based ghost tree presented here can be easily
integrated into existing fungal analysis pipelines to enhance the resolution of
fungal community differences and improve understanding of these communities in
built environments. The ghost-tree software package can also be used to develop
phylogenetic trees for other marker gene sets that afford different taxonomic
resolution, or for bridging genome trees with amplicon trees.
AVAILABILITY: ghost-tree is pip-installable. All source code, documentation, and 
test code are available under the BSD license at
https://github.com/JTFouquier/ghost-tree .

DOI: 10.1186/s40168-016-0153-6 
PMCID: PMC4765138
PMID: 26905735  [PubMed - indexed for MEDLINE]


640. BMC Res Notes. 2016 Feb 17;9:106. doi: 10.1186/s13104-016-1927-4.

Seqotron: a user-friendly sequence editor for Mac OS X.

Fourment M(1,)(2), Holmes EC(3).

Author information: 
(1)The ithree institute, University of Technology Sydney, Sydney, Australia.
mathieu.fourment@uts.edu.au. (2)Marie Bashir Institute for Infectious Diseases
and Biosecurity, Charles Perkins Centre, School of Biological Sciences and Sydney
Medical School, The University of Sydney, Sydney, Australia.
mathieu.fourment@uts.edu.au. (3)Marie Bashir Institute for Infectious Diseases
and Biosecurity, Charles Perkins Centre, School of Biological Sciences and Sydney
Medical School, The University of Sydney, Sydney, Australia.
edward.holmes@sydney.edu.au.

BACKGROUND: Accurate multiple sequence alignment is central to bioinformatics and
molecular evolutionary analyses. Although sophisticated sequence alignment
programs are available, manual adjustments are often required to improve
alignment quality. Unfortunately, few programs offer a simple and intuitive way
to edit sequence alignments.
RESULTS: We present Seqotron, a sequence editor that reads and writes files in a 
wide variety of sequence formats. Sequences can be easily aligned and manually
edited using the mouse and keyboard. The program also allows the user to estimate
both phylogenetic trees and distance matrices.
CONCLUSIONS: Seqotron will benefit researchers who need to manipulate and align
complex sequence data. Seqotron is a Mac OS X compatible open source project and 
is available from Github https://github.com/4ment/seqotron/.

DOI: 10.1186/s13104-016-1927-4 
PMCID: PMC4756450
PMID: 26887850  [PubMed - indexed for MEDLINE]


641. Genome Med. 2016 Feb 17;8(1):19. doi: 10.1186/s13073-016-0270-7.

SpoTyping: fast and accurate in silico Mycobacterium spoligotyping from sequence 
reads.

Xia E(1), Teo YY(2,)(3,)(4,)(5,)(6), Ong RT(7).

Author information: 
(1)NUS Graduate School for Integrative Sciences and Engineering, National
University of Singapore, Singapore, Singapore. xiaeryu@u.nus.edu. (2)NUS Graduate
School for Integrative Sciences and Engineering, National University of
Singapore, Singapore, Singapore. statyy@nus.edu.sg. (3)Centre for Infectious
Disease Epidemiology and Research, Saw Swee Hock School of Public Health,
National University of Singapore, Singapore, Singapore. statyy@nus.edu.sg.
(4)Department of Statistics and Applied Probability, National University of
Singapore, Singapore, Singapore. statyy@nus.edu.sg. (5)Life Sciences Institute,
National University of Singapore, Singapore, Singapore. statyy@nus.edu.sg.
(6)Genome Institute of Singapore, Singapore, Singapore. statyy@nus.edu.sg.
(7)Centre for Infectious Disease Epidemiology and Research, Saw Swee Hock School 
of Public Health, National University of Singapore, Singapore, Singapore.
twee_hee_ong@nuhs.edu.sg.

SpoTyping is a fast and accurate program for in silico spoligotyping of
Mycobacterium tuberculosis isolates from next-generation sequencing reads. This
novel method achieves high accuracy for reads of both uniform and varying
lengths, and is about 20 to 40 times faster than SpolPred. SpoTyping also
integrates the function of producing a report summarizing associated
epidemiological data from a global database of all isolates having the same
spoligotype. SpoTyping is freely available at:
https://github.com/xiaeryu/SpoTyping-v2.0 .

DOI: 10.1186/s13073-016-0270-7 
PMCID: PMC4756441
PMID: 26883915  [PubMed - indexed for MEDLINE]


642. Bioinformatics. 2016 Jun 15;32(12):1832-9. doi: 10.1093/bioinformatics/btw074.
Epub 2016 Feb 11.

Gene expression inference with deep learning.

Chen Y(1), Li Y(2), Narayan R(3), Subramanian A(3), Xie X(4).

Author information: 
(1)Department of Computer Science, University of California, Irvine, CA 92697,
USA Baidu Research-Big Data Lab, Beijing, 100085, China. (2)Department of
Computer Science, University of California, Irvine, CA 92697, USA. (3)Broad
Institute of MIT And Harvard, Cambridge, MA 02142, USA. (4)Department of Computer
Science, University of California, Irvine, CA 92697, USA Center for Complex
Biological Systems, University of California, Irvine, CA 92697, USA.

MOTIVATION: Large-scale gene expression profiling has been widely used to
characterize cellular states in response to various disease conditions, genetic
perturbations, etc. Although the cost of whole-genome expression profiles has
been dropping steadily, generating a compendium of expression profiling over
thousands of samples is still very expensive. Recognizing that gene expressions
are often highly correlated, researchers from the NIH LINCS program have
developed a cost-effective strategy of profiling only ∼1000 carefully selected
landmark genes and relying on computational methods to infer the expression of
remaining target genes. However, the computational approach adopted by the LINCS 
program is currently based on linear regression (LR), limiting its accuracy since
it does not capture complex nonlinear relationship between expressions of genes.
RESULTS: We present a deep learning method (abbreviated as D-GEX) to infer the
expression of target genes from the expression of landmark genes. We used the
microarray-based Gene Expression Omnibus dataset, consisting of 111K expression
profiles, to train our model and compare its performance to those from other
methods. In terms of mean absolute error averaged across all genes, deep learning
significantly outperforms LR with 15.33% relative improvement. A gene-wise
comparative analysis shows that deep learning achieves lower error than LR in
99.97% of the target genes. We also tested the performance of our learned model
on an independent RNA-Seq-based GTEx dataset, which consists of 2921 expression
profiles. Deep learning still outperforms LR with 6.57% relative improvement, and
achieves lower error in 81.31% of the target genes.
AVAILABILITY AND IMPLEMENTATION: D-GEX is available at
https://github.com/uci-cbcl/D-GEX CONTACT: xhx@ics.uci.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw074 
PMCID: PMC4908320 [Available on 2017-06-15]
PMID: 26873929  [PubMed - in process]


643. Bioinformatics. 2016 Jun 15;32(12):1840-7. doi: 10.1093/bioinformatics/btw076.
Epub 2016 Feb 11.

SplAdder: identification, quantification and testing of alternative splicing
events from RNA-Seq data.

Kahles A(1), Ong CS(2), Zhong Y(1), Rätsch G(1).

Author information: 
(1)Memorial Sloan Kettering Cancer Center, New York, NY 10065, USA and.
(2)Canberra Research Laboratory, NICTA, Canberra, ACT 2601, Australia.

MOTIVATION: Understanding the occurrence and regulation of alternative splicing
(AS) is a key task towards explaining the regulatory processes that shape the
complex transcriptomes of higher eukaryotes. With the advent of high-throughput
sequencing of RNA (RNA-Seq), the diversity of AS transcripts could be measured at
an unprecedented depth. Although the catalog of known AS events has grown ever
since, novel transcripts are commonly observed when working with less well
annotated organisms, in the context of disease, or within large populations.
Whereas an identification of complete transcripts is technically challenging and 
computationally expensive, focusing on single splicing events as a proxy for
transcriptome characteristics is fruitful and sufficient for a wide range of
analyses.
RESULTS: We present SplAdder, an alternative splicing toolbox, that takes RNA-Seq
alignments and an annotation file as input to (i) augment the annotation based on
RNA-Seq evidence, (ii) identify alternative splicing events present in the
augmented annotation graph, (iii) quantify and confirm these events based on the 
RNA-Seq data and (iv) test for significant quantitative differences between
samples. Thereby, our main focus lies on performance, accuracy and usability.
AVAILABILITY: Source code and documentation are available for download at
http://github.com/ratschlab/spladder Example data, introductory information and a
small tutorial are accessible via http://bioweb.me/spladder
CONTACTS: : andre.kahles@ratschlab.org or gunnar.ratsch@ratschlab.org
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw076 
PMCID: PMC4908322
PMID: 26873928  [PubMed - in process]


644. PLoS One. 2016 Feb 12;11(2):e0148655. doi: 10.1371/journal.pone.0148655.
eCollection 2016.

Kernel Manifold Alignment for Domain Adaptation.

Tuia D(1), Camps-Valls G(2).

Author information: 
(1)MultiModal Remote Sensing, University of Zurich, Zurich, Switzerland. (2)Image
Processing Laboratory, Universitat of València, València, Spain.

The wealth of sensory data coming from different modalities has opened numerous
opportunities for data analysis. The data are of increasing volume, complexity
and dimensionality, thus calling for new methodological innovations towards
multimodal data processing. However, multimodal architectures must rely on models
able to adapt to changes in the data distribution. Differences in the density
functions can be due to changes in acquisition conditions (pose, illumination),
sensors characteristics (number of channels, resolution) or different views (e.g.
street level vs. aerial views of a same building). We call these different
acquisition modes domains, and refer to the adaptation problem as domain
adaptation. In this paper, instead of adapting the trained models themselves, we 
alternatively focus on finding mappings of the data sources into a common,
semantically meaningful, representation domain. This field of manifold alignment 
extends traditional techniques in statistics such as canonical correlation
analysis (CCA) to deal with nonlinear adaptation and possibly non-corresponding
data pairs between the domains. We introduce a kernel method for manifold
alignment (KEMA) that can match an arbitrary number of data sources without
needing corresponding pairs, just few labeled examples in all domains. KEMA has
interesting properties: 1) it generalizes other manifold alignment methods, 2) it
can align manifolds of very different complexities, performing a discriminative
alignment preserving each manifold inner structure, 3) it can define a
domain-specific metric to cope with multimodal specificities, 4) it can align
data spaces of different dimensionality, 5) it is robust to strong nonlinear
feature deformations, and 6) it is closed-form invertible, which allows transfer 
across-domains and data synthesis. To authors' knowledge this is the first method
addressing all these important issues at once. We also present a reduced-rank
version of KEMA for computational efficiency, and discuss the generalization
performance of KEMA under Rademacher principles of stability. Aligning multimodal
data with KEMA reports outstanding benefits when used as a data pre-conditioner
step in the standard data analysis processing chain. KEMA exhibits very good
performance over competing methods in synthetic controlled examples, visual
object recognition and recognition of facial expressions tasks. KEMA is
especially well-suited to deal with high-dimensional problems, such as images and
videos, and under complicated distortions, twists and warpings of the data
manifolds. A fully functional toolbox is available at
https://github.com/dtuia/KEMA.git.

DOI: 10.1371/journal.pone.0148655 
PMCID: PMC4752280
PMID: 26872269  [PubMed - indexed for MEDLINE]


645. PeerJ. 2016 Feb 8;4:e1603. doi: 10.7717/peerj.1603. eCollection 2016.

PhyloPythiaS+: a self-training method for the rapid reconstruction of low-ranking
taxonomic bins from metagenomes.

Gregor I(1), Dröge J(1), Schirmer M(2), Quince C(3), McHardy AC(1).

Author information: 
(1)Max-Planck Research Group for Computational Genomics and Epidemiology,
Max-Planck Institute for Informatics, Saarbrücken, Germany; Department of
Algorithmic Bioinformatics, Heinrich-Heine-University Düsseldorf, Düsseldorf,
Germany; Computational Biology of Infection Research, Helmholtz Center for
Infection Research, Braunschweig, Germany. (2)The Broad Institute of MIT and
Harvard , Cambridge, MA , United States. (3)School of Engineering, University of 
Glasgow , Glasgow , United Kingdom.

Background. Metagenomics is an approach for characterizing environmental
microbial communities in situ, it allows their functional and taxonomic
characterization and to recover sequences from uncultured taxa. This is often
achieved by a combination of sequence assembly and binning, where sequences are
grouped into 'bins' representing taxa of the underlying microbial community.
Assignment to low-ranking taxonomic bins is an important challenge for binning
methods as is scalability to Gb-sized datasets generated with deep sequencing
techniques. One of the best available methods for species bins recovery from
deep-branching phyla is the expert-trained PhyloPythiaS package, where a human
expert decides on the taxa to incorporate in the model and identifies 'training' 
sequences based on marker genes directly from the sample. Due to the manual
effort involved, this approach does not scale to multiple metagenome samples and 
requires substantial expertise, which researchers who are new to the area do not 
have. Results. We have developed PhyloPythiaS+, a successor to our PhyloPythia(S)
software. The new (+) component performs the work previously done by the human
expert. PhyloPythiaS+ also includes a new k-mer counting algorithm, which
accelerated the simultaneous counting of 4-6-mers used for taxonomic binning
100-fold and reduced the overall execution time of the software by a factor of
three. Our software allows to analyze Gb-sized metagenomes with inexpensive
hardware, and to recover species or genera-level bins with low error rates in a
fully automated fashion. PhyloPythiaS+ was compared to MEGAN, taxator-tk, Kraken 
and the generic PhyloPythiaS model. The results showed that PhyloPythiaS+
performs especially well for samples originating from novel environments in
comparison to the other methods. Availability. PhyloPythiaS+ in a virtual machine
is available for installation under Windows, Unix systems or OS X on:
https://github.com/algbioi/ppsp/wiki.

DOI: 10.7717/peerj.1603 
PMCID: PMC4748697
PMID: 26870609  [PubMed]


646. Brief Bioinform. 2017 Jan;18(1):1-8. doi: 10.1093/bib/bbw003. Epub 2016 Feb 10.

Iterative error correction of long sequencing reads maximizes accuracy and
improves contig assembly.

Sameith K, Roscito JG, Hiller M.

Next-generation sequencers such as Illumina can now produce reads up to 300 bp
with high throughput, which is attractive for genome assembly. A first step in
genome assembly is to computationally correct sequencing errors. However,
correcting all errors in these longer reads is challenging. Here, we show that
reads with remaining errors after correction often overlap repeats, where short
erroneous k-mers occur in other copies of the repeat. We developed an iterative
error correction pipeline that runs the previously published String Graph
Assembler (SGA) in multiple rounds of k-mer-based correction with an increasing
k-mer size, followed by a final round of overlap-based correction. By combining
the advantages of small and large k-mers, this approach corrects more errors in
repeats and minimizes the total amount of erroneous reads. We show that higher
read accuracy increases contig lengths two to three times. We provide
SGA-Iteratively Correcting Errors
(https://github.com/hillerlab/IterativeErrorCorrection/) that implements
iterative error correction by using modules from SGA.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bib/bbw003 
PMCID: PMC5221426
PMID: 26868358  [PubMed - in process]


647. Genetics. 2016 Apr;202(4):1289-97. doi: 10.1534/genetics.115.179846. Epub 2016
Feb 10.

A Novel Test for Detecting SNP-SNP Interactions in Case-Only Trio Studies.

Balliu B(1), Zaitlen N(2).

Author information: 
(1)Department of Pathology, Stanford University School of Medicine, California
94305 bballiu@stanford.edu. (2)Department of Medicine, University of California, 
San Francisco, California 94158.

Epistasis plays a significant role in the genetic architecture of many complex
phenotypes in model organisms. To date, there have been very few interactions
replicated in human studies due in part to the multiple-hypothesis burden
implicit in genome-wide tests of epistasis. Therefore, it is of paramount
importance to develop the most powerful tests possible for detecting
interactions. In this work we develop a new SNP-SNP interaction test for use in
case-only trio studies called the trio correlation (TC) test. The TC test
computes the expected joint distribution of marker pairs in offspring conditional
on parental genotypes. This distribution is then incorporated into a standard 1
d.f. correlation test of interaction. We show via extensive simulations under a
variety of disease models that our test substantially outperforms existing tests 
of interaction in case-only trio studies. We also demonstrate a bias in a
previous case-only trio interaction test and identify its origin. Finally, we
show that a previously proposed permutation scheme in trio studies mitigates the 
known biases of case-only tests in the presence of population stratification. We 
conclude that the TC test shows improved power to identify interactions in
existing, as well as emerging, trio association studies. The method is publicly
available at www.github.com/BrunildaBalliu/TrioEpi.

Copyright © 2016 by the Genetics Society of America.

DOI: 10.1534/genetics.115.179846 
PMCID: PMC4905548 [Available on 2017-04-01]
PMID: 26865367  [PubMed - in process]


648. BMC Bioinformatics. 2016 Feb 10;17:81. doi: 10.1186/s12859-016-0930-z.

Parasail: SIMD C library for global, semi-global, and local pairwise sequence
alignments.

Daily J(1).

Author information: 
(1)Pacific Northwest National Laboratory, High Performance Computing Group, 902
Battelle Boulevard, P.O. Box 999, MSIN J4-30, Richland, 99352, WA, USA.
jeff.daily@pnnl.gov.

BACKGROUND: Sequence alignment algorithms are a key component of many
bioinformatics applications. Though various fast Smith-Waterman local sequence
alignment implementations have been developed for x86 CPUs, most are embedded
into larger database search tools. In addition, fast implementations of
Needleman-Wunsch global sequence alignment and its semi-global variants are not
as widespread. This article presents the first software library for local,
global, and semi-global pairwise intra-sequence alignments and improves the
performance of previous intra-sequence implementations.
RESULTS: A faster intra-sequence local pairwise alignment implementation is
described and benchmarked, including new global and semi-global variants. Using a
375 residue query sequence a speed of 136 billion cell updates per second (GCUPS)
was achieved on a dual Intel Xeon E5-2670 24-core processor system, the highest
reported for an implementation based on Farrar's 'striped' approach. Rognes's
SWIPE optimal database search application is still generally the fastest
available at 1.2 to at best 2.4 times faster than Parasail for sequences shorter 
than 500 amino acids. However, Parasail was faster for longer sequences. For
global alignments, Parasail's prefix scan implementation is generally the
fastest, faster even than Farrar's 'striped' approach, however the opal library
is faster for single-threaded applications. The software library is designed for 
64 bit Linux, OS X, or Windows on processors with SSE2, SSE41, or AVX2. Source
code is available from https://github.com/jeffdaily/parasail under the Battelle
BSD-style license.
CONCLUSIONS: Applications that require optimal alignment scores could benefit
from the improved performance. For the first time, SIMD global, semi-global, and 
local alignments are available in a stand-alone C library.

DOI: 10.1186/s12859-016-0930-z 
PMCID: PMC4748600
PMID: 26864881  [PubMed - indexed for MEDLINE]


649. Bioinformatics. 2016 Jun 15;32(12):1905-6. doi: 10.1093/bioinformatics/btw056.
Epub 2016 Feb 9.

MOCCASIN: converting MATLAB ODE models to SBML.

Gómez HF(1), Hucka M(2), Keating SM(3), Nudelman G(4), Iber D(1), Sealfon SC(4).

Author information: 
(1)Department of Biosystems Science and Engineering, ETH Zürich, Basel CH 4058,
Switzerland. (2)Computing and Mathematical Sciences, California Institute of
Technology, Pasadena, CA 91125, USA. (3)European Molecular Biology Laboratory,
European Bioinformatics Institute (EMBL-EBI), Hinxton, Cambridge CB10 1SD, UK
and. (4)Department of Neurology, Icahn School of Medicine at Mount Sinai, Mount
Sinai Medical Center and School of Medicine, New York, NY 10029, USA.

MATLAB is popular in biological research for creating and simulating models that 
use ordinary differential equations (ODEs). However, sharing or using these
models outside of MATLAB is often problematic. A community standard such as
Systems Biology Markup Language (SBML) can serve as a neutral exchange format,
but translating models from MATLAB to SBML can be challenging-especially for
legacy models not written with translation in mind. We developed MOCCASIN (Model 
ODE Converter for Creating Automated SBML INteroperability) to help. MOCCASIN can
convert ODE-based MATLAB models of biochemical reaction networks into the SBML
format.AVAILABILITY AND IMPLEMENTATION: MOCCASIN is available under the terms of 
the LGPL 2.1 license (http://www.gnu.org/licenses/lgpl-2.1.html). Source code,
binaries and test cases can be freely obtained from
https://github.com/sbmlteam/moccasin
CONTACT: : mhucka@caltech.edu
SUPPLEMENTARY INFORMATION: More information is available at
https://github.com/sbmlteam/moccasin.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw056 
PMCID: PMC4908318
PMID: 26861819  [PubMed - in process]


650. BMC Bioinformatics. 2016 Feb 9;17:78. doi: 10.1186/s12859-016-0931-y.

ksRepo: a generalized platform for computational drug repositioning.

Brown AS(1), Kong SW(2), Kohane IS(3), Patel CJ(4).

Author information: 
(1)Department of Biomedical Informatics, Harvard Medical School, Boston, MA,
02115, USA. adambrown@fas.harvard.edu. (2)Boston Children's Hospital, Boston, MA,
02115, USA. sekwon.kong@childrens.harvard.edu. (3)Department of Biomedical
Informatics, Harvard Medical School, Boston, MA, 02115, USA.
isaac_kohane@harvard.edu. (4)Department of Biomedical Informatics, Harvard
Medical School, Boston, MA, 02115, USA. Chirag_Patel@hms.harvard.edu.

BACKGROUND: Repositioning approved drug and small molecules in novel therapeutic 
areas is of key interest to the pharmaceutical industry. A number of promising
computational techniques have been developed to aid in repositioning, however,
the majority of available methodologies require highly specific data inputs that 
preclude the use of many datasets and databases. There is a clear unmet need for 
a generalized methodology that enables the integration of multiple types of both 
gene expression data and database schema.
RESULTS: ksRepo eliminates the need for a single microarray platform as input and
allows for the use of a variety of drug and chemical exposure databases. We
tested ksRepo's performance on a set of five prostate cancer datasets using the
Comparative Toxicogenomics Database (CTD) as our database of gene-compound
interactions. ksRepo successfully predicted significance for five frontline
prostate cancer therapies, representing a significant enrichment from over 7000
CTD compounds, and achieved specificity similar to other repositioning methods.
CONCLUSIONS: We present ksRepo, which enables investigators to use any data
inputs for computational drug repositioning. ksRepo is implemented in a series of
four functions in the R statistical environment under a BSD3 license. Source code
is freely available at http://github.com/adam-sam-brown/ksRepo. A vignette is
provided to aid users in performing ksRepo analysis.

DOI: 10.1186/s12859-016-0931-y 
PMCID: PMC4746802
PMID: 26860211  [PubMed - indexed for MEDLINE]


651. Mob DNA. 2016 Feb 5;7:3. doi: 10.1186/s13100-016-0061-0. eCollection 2016.

Genome ARTIST: a robust, high-accuracy aligner tool for mapping transposon
insertions and self-insertions.

Ecovoiu AA(1), Ghionoiu IC(2), Ciuca AM(2), Ratiu AC(1).

Author information: 
(1)Department of Genetics, Faculty of Biology, University of Bucharest,
Bucharest, Romania. (2)Exenne Technologies, Pitesti, Romania.

BACKGROUND: A critical topic of insertional mutagenesis experiments performed on 
model organisms is mapping the hits of artificial transposons (ATs) at nucleotide
level accuracy. Mapping errors may occur when sequencing artifacts or mutations
as single nucleotide polymorphisms (SNPs) and small indels are present very close
to the junction between a genomic sequence and a transposon inverted repeat
(TIR). Another particular item of insertional mutagenesis is mapping of the
transposon self-insertions and, to our best knowledge, there is no publicly
available mapping tool designed to analyze such molecular events.
RESULTS: We developed Genome ARTIST, a pairwise gapped aligner tool which works
out both issues by means of an original, robust mapping strategy. Genome ARTIST
is not designed to use next-generation sequencing (NGS) data but to analyze ATs
insertions obtained in small to medium-scale mutagenesis experiments. Genome
ARTIST employs a heuristic approach to find DNA sequence similarities and
harnesses a multi-step implementation of a Smith-Waterman adapted algorithm to
compute the mapping alignments. The experience is enhanced by easily customizable
parameters and a user-friendly interface that describes the genomic landscape
surrounding the insertion. Genome ARTIST is functional with many genomes of
bacteria and eukaryotes available in Ensembl and GenBank repositories. Our tool
specifically harnesses the sequence annotation data provided by FlyBase for
Drosophila melanogaster (the fruit fly), which enables mapping of insertions
relative to various genomic features such as natural transposons. Genome ARTIST
was tested against other alignment tools using relevant query sequences derived
from the D. melanogaster and Mus musculus (mouse) genomes. Real and simulated
query sequences were also comparatively inquired, revealing that Genome ARTIST is
a very robust solution for mapping transposon insertions.
CONCLUSIONS: Genome ARTIST is a stand-alone user-friendly application, designed
for high-accuracy mapping of transposon insertions and self-insertions. The tool 
is also useful for routine aligning assessments like detection of SNPs or
checking the specificity of primers and probes. Genome ARTIST is an open source
software and is available for download at www.genomeartist.ro and at GitHub
(https://github.com/genomeartist/genomeartist ).

DOI: 10.1186/s13100-016-0061-0 
PMCID: PMC4744444
PMID: 26855675  [PubMed]


652. Nat Methods. 2016 Apr;13(4):322-4. doi: 10.1038/nmeth.3763. Epub 2016 Feb 8.

epiGBS: reference-free reduced representation bisulfite sequencing.

van Gurp TP(1), Wagemaker NC(2), Wouters B(1), Vergeer P(3), Ouborg JN(2),
Verhoeven KJ(1).

Author information: 
(1)Department of Terrestrial Ecology, Netherlands Institute of Ecology
(NIOO-KNAW), Wageningen, the Netherlands. (2)Department of Experimental Plant
Ecology, Radboud University, Nijmegen, the Netherlands. (3)Plant Ecology and
Nature Conservation Group, Wageningen University, Wageningen, the Netherlands.

We describe epiGBS, a reduced representation bisulfite sequencing method for
cost-effective exploration and comparative analysis of DNA methylation and
genetic variation in hundreds of samples de novo. This method uses genotyping by 
sequencing of bisulfite-converted DNA followed by reliable de novo reference
construction, mapping, variant calling, and distinction of single-nucleotide
polymorphisms (SNPs) versus methylation variation (software is available at
https://github.com/thomasvangurp/epiGBS). The output can be loaded directly into 
a genome browser for visualization and into RnBeads for analysis of differential 
methylation.

DOI: 10.1038/nmeth.3763 
PMID: 26855363  [PubMed - indexed for MEDLINE]


653. Biochim Biophys Acta. 2016 May;1864(5):435-40. doi: 10.1016/j.bbapap.2016.02.005.
Epub 2016 Feb 5.

GprotPRED: Annotation of Gα, Gβ and Gγ subunits of G-proteins using profile
Hidden Markov Models (pHMMs) and application to proteomes.

Kostiou VD(1), Theodoropoulou MC(1), Hamodrakas SJ(2).

Author information: 
(1)Department of Cell Biology and Biophysics, Faculty of Biology, University of
Athens, Athens 157 01, Greece. (2)Department of Cell Biology and Biophysics,
Faculty of Biology, University of Athens, Athens 157 01, Greece. Electronic
address: shamodr@biol.uoa.gr.

Heterotrimeric G-proteins form a major protein family, which participates in
signal transduction. They are composed of three subunits, Gα, Gβ and Gγ. The Gα
subunit is further divided in four distinct families Gs, Gi/o, Gq/11 and G12/13. 
The goal of this work was to detect and classify members of the four distinct
families, plus the Gβ and the Gγ subunits of G-proteins from sequence alone. To
achieve this purpose, six specific profile Hidden Markov Models (pHMMs) were
built and checked for their credibility. These models were then applied to ten
(10) proteomes and were able to identify all known G-protein and classify them
into the distinct families. In a separate case study, the models were applied to 
twenty seven (27) arthropod proteomes and were able to give more credible
classification in proteins with uncertain annotation and in some cases to detect 
novel proteins. An online tool, GprotPRED, was developed that uses these six
pHMMs. The sensitivity and specificity for all pHMMs were equal to 100% with the 
exception of the Gβ case, where sensitivity equals to 100%, while specificity is 
99.993%. In contrast to Pfam's pHMM which detects Gα subunits in general, our
method not only detects Gα subunits but also classifies them into the appropriate
Gα-protein family and thus could become a useful tool for the annotation of
G-proteins in newly discovered proteomes. GprotPRED online tool is publicly
available for non-commercial use at http://bioinformatics.biol.uoa.gr/GprotPRED
and, also, a standalone version of the tool at
https://github.com/vkostiou/GprotPRED.

Copyright © 2016 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.bbapap.2016.02.005 
PMID: 26854601  [PubMed - indexed for MEDLINE]


654. Sci Rep. 2016 Feb 8;6:20631. doi: 10.1038/srep20631.

PrimerMapper: high throughput primer design and graphical assembly for PCR and
SNP detection.

O'Halloran DM(1,)(2).

Author information: 
(1)Department of Biological Sciences, The George Washington University, Science
and Engineering Hall 6000, 800 22nd St. N.W. Washington DC 20052, USA.
(2)Institute for Neuroscience, The George Washington University, 636 Ross Hall,
2300 I St. N.W. Washington DC 20052, USA.

Primer design represents a widely employed gambit in diverse molecular
applications including PCR, sequencing, and probe hybridization. Variations of
PCR, including primer walking, allele-specific PCR, and nested PCR provide
specialized validation and detection protocols for molecular analyses that often 
require screening large numbers of DNA fragments. In these cases, automated
sequence retrieval and processing become important features, and furthermore, a
graphic that provides the user with a visual guide to the distribution of
designed primers across targets is most helpful in quickly ascertaining primer
coverage. To this end, I describe here, PrimerMapper, which provides a
comprehensive graphical user interface that designs robust primers from any
number of inputted sequences while providing the user with both, graphical maps
of primer distribution for each inputted sequence, and also a global assembled
map of all inputted sequences with designed primers. PrimerMapper also enables
the visualization of graphical maps within a browser and allows the user to draw 
new primers directly onto the webpage. Other features of PrimerMapper include
allele-specific design features for SNP genotyping, a remote BLAST window to NCBI
databases, and remote sequence retrieval from GenBank and dbSNP. PrimerMapper is 
hosted at GitHub and freely available without restriction.

DOI: 10.1038/srep20631 
PMCID: PMC4745053
PMID: 26853558  [PubMed - indexed for MEDLINE]


655. Anal Biochem. 2016 Apr 15;499:15-23. doi: 10.1016/j.ab.2016.01.014. Epub 2016 Feb
4.

DRME: Count-based differential RNA methylation analysis at small sample size
scenario.

Liu L(1), Zhang SW(2), Gao F(3), Zhang Y(4), Huang Y(5), Chen R(6), Meng J(7).

Author information: 
(1)Key Laboratory of Information Fusion Technology of Ministry of Education,
School of Automation, Northwestern Polytechnical University, Xi'an 710072, China.
(2)Key Laboratory of Information Fusion Technology of Ministry of Education,
School of Automation, Northwestern Polytechnical University, Xi'an 710072, China.
Electronic address: zhangsw@nwpu.edu.cn. (3)Picower Institute for Learning and
Memory, Department of Brain and Cognitive Science, Massachusetts Institute of
Technology, Cambridge, MA 02139, USA. (4)Suzhou Urban and Environmental Research 
Institute, Huai'an Research Institute of New-type Urbanization, Department of
Environmental Sciences, Xi'an Jiaotong-Liverpool University, Suzhou 215123,
China. (5)Department of Electrical and Computer Engineering, University of Texas 
at San Antonio, San Antonio, TX 78230, USA. (6)Key Laboratory of Information
Fusion Technology of Ministry of Education, School of Automation, Northwestern
Polytechnical University, Xi'an 710072, China; Institute of Biophysics, Chinese
Academy of Sciences, Beijing 100101, China. (7)Department of Biological Sciences,
Xi'an Jiaotong-Liverpool University, Suzhou 215123, China. Electronic address:
jia.meng@xjtlu.edu.cn.

Differential methylation, which concerns difference in the degree of epigenetic
regulation via methylation between two conditions, has been formulated as a beta 
or beta-binomial distribution to address the within-group biological variability 
in sequencing data. However, a beta or beta-binomial model is usually difficult
to infer at small sample size scenario with discrete reads count in sequencing
data. On the other hand, as an emerging research field, RNA methylation has drawn
more and more attention recently, and the differential analysis of RNA
methylation is significantly different from that of DNA methylation due to the
impact of transcriptional regulation. We developed DRME to better address the
differential RNA methylation problem. The proposed model can effectively describe
within-group biological variability at small sample size scenario and handles the
impact of transcriptional regulation on RNA methylation. We tested the newly
developed DRME algorithm on simulated and 4 MeRIP-Seq case-control studies and
compared it with Fisher's exact test. It is in principle widely applicable to
several other RNA-related data types as well, including RNA Bisulfite sequencing 
and PAR-CLIP. The code together with an MeRIP-Seq dataset is available online
(https://github.com/lzcyzm/DRME) for evaluation and reproduction of the figures
shown in this article.

Copyright © 2016 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.ab.2016.01.014 
PMID: 26851340  [PubMed - indexed for MEDLINE]


656. Mol Ecol Resour. 2017 Jan;17(1):27-32. doi: 10.1111/1755-0998.12509. Epub 2016
Feb 26.

pophelper: an R package and web app to analyse and visualize population
structure.

Francis RM(1).

Author information: 
(1)Evolutionary Biology Centre, Uppsala University, Norbyvägen 18D, 75236,
Uppsala, Sweden.

The pophelper r package and web app are software tools to aid in population
structure analyses. They can be used for the analyses and visualization of output
generated from population assignment programs such as admixture, structure and
tess. Some of the functions include parsing output run files to tabulate data,
estimating K using the Evanno method, generating files for clumpp and
functionality to create barplots. These functions can be streamlined into
standard r analysis workflows. The latest version of the package is available on 
github (https://github.com/royfrancis/pophelper). An interactive web version of
the pophelper package is available which covers the same functionalities as the r
package version with features such as interactive plots, cluster alignment during
plotting, sorting individuals and ordering of population groups. The interactive 
version is available at http://pophelper.com/.

© 2016 John Wiley & Sons Ltd.

DOI: 10.1111/1755-0998.12509 
PMID: 26850166  [PubMed - in process]


657. Analyst. 2016 Mar 21;141(6):1973-80. doi: 10.1039/c5an02243f.

Calibration transfer via an extreme learning machine auto-encoder.

Chen WR(1), Bin J(2), Lu HM(1), Zhang ZM(1), Liang YZ(1).

Author information: 
(1)College of Chemistry and Chemical Engineering, Central South University,
Changsha 410083, China. (2)College of Bioscience and Biotechnology, Hunan
Agriculture University, Changsha 410128, China. zmzhang@csu.edu.cn
yizeng_liang@263.net.

In order to solve the spectra standardization problem in near-infrared (NIR)
spectroscopy, a Transfer via Extreme learning machine Auto-encoder Method (TEAM) 
has been proposed in this study. A comparative study among TEAM, piecewise direct
standardization (PDS), generalized least squares (GLS) and calibration transfer
methods based on canonical correlation analysis (CCA) was conducted, and the
performances of these algorithms were benchmarked with three spectral datasets:
corn, tobacco and pharmaceutical tablet spectra. The results show that TEAM is a 
stable method and can significantly reduce prediction errors compared with PDS,
GLS and CCA. TEAM can also achieve the best RMSEPs in most cases with a small
number of calibration sets. TEAM is implemented in Python language and available 
as an open source package at https://github.com/zmzhang/TEAM.

DOI: 10.1039/c5an02243f 
PMID: 26846329  [PubMed]


658. Plant Physiol. 2016 Apr;170(4):1929-34. doi: 10.1104/pp.15.01327. Epub 2016 Feb
3.

GIPS: A Software Guide to Sequencing-Based Direct Gene Cloning in Forward
Genetics Studies.

Hu H(1), Wang W(1), Zhu Z(1), Zhu J(1), Tan D(1), Zhou Z(1), Mao C(2), Chen X(2).

Author information: 
(1)State Key Laboratory of Plant Physiology and Biochemistry (H.H., C.M., X.C.)
and Institute of Plant Sciences (D.T., Zhi.Z.. C.M.), College of Life Sciences,
and Institute of Biochemistry, College of Pharmaceutical Sciences (W.W., Zho.Z., 
J.Z., X.C.), Zhejiang University, Hangzhou 310058, People's Republic of
China;Agricultural Experiment Station, Zhejiang University, Changxing 310058,
People's Republic of China (H.H.); andJoint Institute for Genetics and Genome
Medicine between Zhejiang University and University of Toronto, Zhejiang
University, Hangzhou 310058, People's Republic of China (X.C.). (2)State Key
Laboratory of Plant Physiology and Biochemistry (H.H., C.M., X.C.) and Institute 
of Plant Sciences (D.T., Zhi.Z.. C.M.), College of Life Sciences, and Institute
of Biochemistry, College of Pharmaceutical Sciences (W.W., Zho.Z., J.Z., X.C.),
Zhejiang University, Hangzhou 310058, People's Republic of China;Agricultural
Experiment Station, Zhejiang University, Changxing 310058, People's Republic of
China (H.H.); andJoint Institute for Genetics and Genome Medicine between
Zhejiang University and University of Toronto, Zhejiang University, Hangzhou
310058, People's Republic of China (X.C.) mcz@zju.edu.cn xinchen@zju.edu.cn.

The Gene Identification via Phenotype Sequencing (GIPS) software considers a
range of experimental and analysis choices in sequencing-based forward genetics
studies within an integrated probabilistic framework, which enables direct gene
cloning from the sequencing of several unrelated mutants of the same phenotype
without the need to create segregation populations. GIPS estimates four
measurements to help optimize an analysis procedure as follows: (1) the chance of
reporting the true phenotype-associated gene; (2) the expected number of random
genes that may be reported; (3) the significance of each candidate gene's
association with the phenotype; and (4) the significance of violating the
Mendelian assumption if no gene is reported or if all candidate genes have failed
validation. The usage of GIPS is illustrated with the identification of a rice
(Oryza sativa) gene that epistatically suppresses the phenotype of the phosphate2
mutant from sequencing three unrelated ethyl methanesulfonate mutants. GIPS is
available at https://github.com/synergy-zju/gips/wiki with the user manual and an
analysis example.

© 2016 American Society of Plant Biologists. All Rights Reserved.

DOI: 10.1104/pp.15.01327 
PMCID: PMC4825123 [Available on 2017-04-01]
PMID: 26842621  [PubMed - in process]


659. IEEE/ACM Trans Comput Biol Bioinform. 2015 Dec 23. [Epub ahead of print]

A graph-theoretical approach for motif discovery in protein sequences.

Czeizler E, Hirvola T, Karhu K.

Motif recognition is a challenging problem in bioinformatics due to the diversity
of protein motifs. Many existing algorithms identify motifs of a given length,
thus being either not applicable or not efficient when searching simultaneously
for motifs of various lengths. Searching for gapped motifs, although very
important, is a highly time-consuming task due to the combinatorial explosion of 
possible combinations implied by the consideration of long gaps. We introduce a
new graph theoretical approach to identify motifs of various lengths, both with
and without gaps. We compare our approach with two widely used methods: MEME and 
GLAM2 analyzing both the quality of the results and the required computational
time. Our method provides results of a slightly higher level of quality than MEME
but at a much faster rate, i.e., one eighth of MEME's query time. By using
similarity indexing, we drop the query times down to an average of approximately 
one sixth of the ones required by GLAM2, while achieving a slightly higher level 
of quality of the results. More precisely, for sequence collections smaller than 
50000 bytes GLAM2 is 13 times slower, while being at least as fast as our method 
on larger ones. The source code of our C++ implementation is freely available in 
GitHub: https://github.com/hirvolt1/debruijn-motif.

DOI: 10.1109/TCBB.2015.2511750 
PMID: 26841406  [PubMed - as supplied by publisher]


660. PLoS One. 2016 Feb 3;11(2):e0147221. doi: 10.1371/journal.pone.0147221.
eCollection 2016.

Comprehensive Annotation of the Parastagonospora nodorum Reference Genome Using
Next-Generation Genomics, Transcriptomics and Proteogenomics.

Syme RA(1), Tan KC(1), Hane JK(1,)(2), Dodhia K(1), Stoll T(3), Hastie M(3),
Furuki E(1), Ellwood SR(1), Williams AH(1), Tan YF(4), Testa AC(1), Gorman JJ(3),
Oliver RP(1).

Author information: 
(1)Centre for Crop & Disease Management, Department of Environment and
Agriculture, Curtin University, Bentley, WA, Australia. (2)Curtin Institute for
Computation, Curtin University, Bentley, WA, Australia. (3)Protein Discovery
Centre, QIMR Berghofer Medical Research Institute, Herston, Qld, Australia.
(4)Telethon Kids Institute, Subiaco, WA, Australia.

Parastagonospora nodorum, the causal agent of Septoria nodorum blotch (SNB), is
an economically important pathogen of wheat (Triticum spp.), and a model for the 
study of necrotrophic pathology and genome evolution. The reference P. nodorum
strain SN15 was the first Dothideomycete with a published genome sequence, and
has been used as the basis for comparison within and between species. Here we
present an updated reference genome assembly with corrections of SNP and indel
errors in the underlying genome assembly from deep resequencing data as well as
extensive manual annotation of gene models using transcriptomic and proteomic
sources of evidence (https://github.com/robsyme/Parastagonospora_nodorum_SN15).
The updated assembly and annotation includes 8,366 genes with modified protein
sequence and 866 new genes. This study shows the benefits of using a wide variety
of experimental methods allied to expert curation to generate a reliable set of
gene models.

DOI: 10.1371/journal.pone.0147221 
PMCID: PMC4739733
PMID: 26840125  [PubMed - indexed for MEDLINE]


661. PeerJ. 2016 Jan 28;4:e1660. doi: 10.7717/peerj.1660. eCollection 2016.

AMAS: a fast tool for alignment manipulation and computing of summary statistics.

Borowiec ML(1).

Author information: 
(1)Department of Entomology and Nematology, UC Davis , Davis , United States.

The amount of data used in phylogenetics has grown explosively in the recent
years and many phylogenies are inferred with hundreds or even thousands of loci
and many taxa. These modern phylogenomic studies often entail separate analyses
of each of the loci in addition to multiple analyses of subsets of genes or
concatenated sequences. Computationally efficient tools for handling and
computing properties of thousands of single-locus or large concatenated
alignments are needed. Here I present AMAS (Alignment Manipulation And Summary), 
a tool that can be used either as a stand-alone command-line utility or as a
Python package. AMAS works on amino acid and nucleotide alignments and combines
capabilities of sequence manipulation with a function that calculates basic
statistics. The manipulation functions include conversions among popular formats,
concatenation, extracting sites and splitting according to a pre-defined
partitioning scheme, creation of replicate data sets, and removal of taxa. The
statistics calculated include the number of taxa, alignment length, total count
of matrix cells, overall number of undetermined characters, percent of missing
data, AT and GC contents (for DNA alignments), count and proportion of variable
sites, count and proportion of parsimony informative sites, and counts of all
characters relevant for a nucleotide or amino acid alphabet. AMAS is particularly
suitable for very large alignments with hundreds of taxa and thousands of loci.
It is computationally efficient, utilizes parallel processing, and performs
better at concatenation than other popular tools. AMAS is a Python 3 program that
relies solely on Python's core modules and needs no additional dependencies. AMAS
source code and manual can be downloaded from
http://github.com/marekborowiec/AMAS/ under GNU General Public License.

DOI: 10.7717/peerj.1660 
PMCID: PMC4734057
PMID: 26835189  [PubMed]


662. J Cheminform. 2016 Jan 29;8:3. doi: 10.1186/s13321-016-0115-9. eCollection 2016.

MetFrag relaunched: incorporating strategies beyond in silico fragmentation.

Ruttkies C(1), Schymanski EL(2), Wolf S(3), Hollender J(4), Neumann S(1).

Author information: 
(1)Leibniz Institute of Plant Biochemistry, Department of Stress and
Developmental Biology, Weinberg 3, 06120 Halle, Germany. (2)Eawag: Swiss Federal 
Institute for Aquatic Science and Technology, Überlandstrasse 133, 8600
Dübendorf, Switzerland. (3)Leibniz Institute of Plant Biochemistry, Department of
Stress and Developmental Biology, Weinberg 3, 06120 Halle, Germany ; R&D NMR
Software, Bruker BioSpin GmbH, Silberstreifen, 76287 Rheinstetten, Germany.
(4)Eawag: Swiss Federal Institute for Aquatic Science and Technology,
Überlandstrasse 133, 8600 Dübendorf, Switzerland ; Institute of Biogeochemistry
and Pollutant Dynamics, ETH Zürich, 8092 Zürich, Switzerland.

BACKGROUND: The in silico fragmenter MetFrag, launched in 2010, was one of the
first approaches combining compound database searching and fragmentation
prediction for small molecule identification from tandem mass spectrometry data. 
Since then many new approaches have evolved, as has MetFrag itself. This article 
details the latest developments to MetFrag and its use in small molecule
identification since the original publication.
RESULTS: MetFrag has gone through algorithmic and scoring refinements. New
features include the retrieval of reference, data source and patent information
via ChemSpider and PubChem web services, as well as InChIKey filtering to reduce 
candidate redundancy due to stereoisomerism. Candidates can be filtered or scored
differently based on criteria like occurence of certain elements and/or
substructures prior to fragmentation, or presence in so-called "suspect lists".
Retention time information can now be calculated either within MetFrag with a
sufficient amount of user-provided retention times, or incorporated separately as
"user-defined scores" to be included in candidate ranking. The changes to MetFrag
were evaluated on the original dataset as well as a dataset of 473 merged high
resolution tandem mass spectra (HR-MS/MS) and compared with another open source
in silico fragmenter, CFM-ID. Using HR-MS/MS information only, MetFrag2.2 and
CFM-ID had 30 and 43 Top 1 ranks, respectively, using PubChem as a database.
Including reference and retention information in MetFrag2.2 improved this to 420 
and 336 Top 1 ranks with ChemSpider and PubChem (89 and 71 %), respectively, and 
even up to 343 Top 1 ranks (PubChem) when combining with CFM-ID. The optimal
parameters and weights were verified using three additional datasets of 824
merged HR-MS/MS spectra in total. Further examples are given to demonstrate
flexibility of the enhanced features.
CONCLUSIONS: In many cases additional information is available from the
experimental context to add to small molecule identification, which is especially
useful where the mass spectrum alone is not sufficient for candidate selection
from a large number of candidates. The results achieved with MetFrag2.2 clearly
show the benefit of considering this additional information. The new functions
greatly enhance the chance of identification success and have been incorporated
into a command line interface in a flexible way designed to be integrated into
high throughput workflows. Feedback on the command line version of MetFrag2.2
available at http://c-ruttkies.github.io/MetFrag/ is welcome.

DOI: 10.1186/s13321-016-0115-9 
PMCID: PMC4732001
PMID: 26834843  [PubMed]


663. Bioinformatics. 2016 Jun 1;32(11):1701-8. doi: 10.1093/bioinformatics/btw061.
Epub 2016 Feb 1.

A zero-inflated Poisson model for insertion tolerance analysis of genes based on 
Tn-seq data.

Liu F(1), Wang C(2), Wu Z(3), Zhang Q(3), Liu P(1).

Author information: 
(1)Department of Statistics, Iowa State University. (2)Department of Statistics, 
Iowa State University, Department of Veterinary Diagnostic and Production Animal 
Medicine and. (3)Department of Veterinary Microbiology and Preventive Medicine,
Iowa State University, Ames, IA 50010, USA.

MOTIVATION: Transposon insertion sequencing (Tn-seq) is an emerging technology
that combines transposon mutagenesis with next-generation sequencing technologies
for the identification of genes related to bacterial survival. The resulting data
from Tn-seq experiments consist of sequence reads mapped to millions of potential
transposon insertion sites and a large portion of insertion sites have zero
mapped reads. Novel statistical method for Tn-seq data analysis is needed to
infer functions of genes on bacterial growth.
RESULTS: In this article, we propose a zero-inflated Poisson model for analyzing 
the Tn-seq data that are high-dimensional and with an excess of zeros. Maximum
likelihood estimates of model parameters are obtained using an
expectation-maximization (EM) algorithm, and pseudogenes are utilized to
construct appropriate statistical tests for the transposon insertion tolerance of
normal genes of interest. We propose a multiple testing procedure that
categorizes genes into each of the three states, hypo-tolerant, tolerant and
hyper-tolerant, while controlling the false discovery rate. We evaluate the
proposed method with simulation studies and apply the proposed method to a real
Tn-seq data from an experiment that studied the bacterial pathogen, Campylobacter
jejuniAvailability and implementation: We provide R code for implementing our
proposed method at http://github.com/ffliu/TnSeq A user's guide with example data
analysis is also available there.
CONTACT: pliu@iastate.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw061 
PMID: 26833344  [PubMed - in process]


664. Bioinformatics. 2016 Jun 15;32(12):1788-96. doi: 10.1093/bioinformatics/btw053.
Epub 2016 Feb 1.

Sprites: detection of deletions from sequencing data by re-aligning split reads.

Zhang Z(1), Wang J(2), Luo J(2), Ding X(2), Zhong J(2), Wang J(3), Wu FX(4), Pan 
Y(5).

Author information: 
(1)School of Information Science and Engineering, Central South University,
Changsha, 410083, China, College of Information and Communication Engineering,
Hunan Institute of Science and Technology, Yueyang, 414006, China. (2)School of
Information Science and Engineering, Central South University, Changsha, 410083, 
China. (3)Department of Molecular Physiology & Biophysics, Baylor College of
Medicine, Houston, TX 77030, USA. (4)Department of Mechanical Engineering and
Division of Biomedical Engineering, University of Saskatchewan, Saskatoon, SK S7N
5A9, Canada and. (5)Department of Computer Science, Georgia State University,
Atlanta, GA 30302-4110, USA.

MOTIVATION: Advances of next generation sequencing technologies and availability 
of short read data enable the detection of structural variations (SVs).
Deletions, an important type of SVs, have been suggested in association with
genetic diseases. There are three types of deletions: blunt deletions, deletions 
with microhomologies and deletions with microsinsertions. The last two types are 
very common in the human genome, but they pose difficulty for the detection.
Furthermore, finding deletions from sequencing data remains challenging. It is
highly appealing to develop sensitive and accurate methods to detect deletions
from sequencing data, especially deletions with microhomology and deletions with 
microinsertion.
RESULTS: We present a novel method called Sprites (SPlit Read re-alIgnment To
dEtect Structural variants) which finds deletions from sequencing data. It aligns
a whole soft-clipping read rather than its clipped part to the target sequence, a
segment of the reference which is determined by spanning reads, in order to find 
the longest prefix or suffix of the read that has a match in the target sequence.
This alignment aims to solve the problem of deletions with microhomologies and
deletions with microinsertions. Using both simulated and real data we show that
Sprites performs better on detecting deletions compared with other current
methods in terms of F-score.
AVAILABILITY AND IMPLEMENTATION: Sprites is open source software and freely
available at https://github.com/zhangzhen/sprites
CONTACT: jxwang@mail.csu.edu.cnSupplementary data: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw053 
PMID: 26833342  [PubMed - in process]


665. Bioinformatics. 2016 Jun 1;32(11):1755-7. doi: 10.1093/bioinformatics/btw057.
Epub 2016 Feb 1.

The geospatial data quality REST API for primary biodiversity data.

Otegui J(1), Guralnick RP(1).

Author information: 
(1)Florida Museum of Natural History, University of Florida, Gainesville, FL,
USA.

We present a REST web service to assess the geospatial quality of primary
biodiversity data. It enables access to basic and advanced functions to detect
completeness and consistency issues as well as general errors in the provided
record or set of records. The API uses JSON for data interchange and efficient
parallelization techniques for fast assessments of large datasets.AVAILABILITY
AND IMPLEMENTATION: The Geospatial Data Quality API is part of the VertNet set of
APIs. It can be accessed at
http://api-geospatial.vertnet-portal.appspot.com/geospatial and is already
implemented in the VertNet data portal for quality reporting. Source code is
freely available under GPL license from
http://www.github.com/vertnet/api-geospatial
CONTACT: javier.otegui@gmail.com or rguralnick@flmnh.ufl.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw057 
PMCID: PMC4892415
PMID: 26833340  [PubMed - in process]


666. BMC Bioinformatics. 2016 Feb 1;17:53. doi: 10.1186/s12859-016-0902-3.

NEAT: a framework for building fully automated NGS pipelines and analyses.

Schorderet P(1,)(2).

Author information: 
(1)Department of Molecular Biology, Massachusetts General Hospital, Boston, MA,
02114, USA. patrick.schorderet@molbio.mgh.harvard.edu. (2)Department of Genetics,
Harvard Medical School, Boston, MA, 02115, USA.
patrick.schorderet@molbio.mgh.harvard.edu.

BACKGROUND: The analysis of next generation sequencing (NGS) has become a
standard task for many laboratories in the life sciences. Though there exists
several tools to support users in the manipulation of such datasets on various
levels, few are built on the basis of vertical integration. Here, we present the 
NExt generation Analysis Toolbox (NEAT) that allows non-expert users including
wet-lab scientists to comprehensively build, run and analyze NGS data through
double-clickable executables without the need of any programming experience.
RESULTS: In comparison to many publicly available tools including Galaxy, NEAT
provides three main advantages: (1) Through the development of double-clickable
executables, NEAT is efficient (completes within <24 hours), easy to implement
and intuitive; (2) Storage space, maximum number of job submissions, wall time
and cluster-specific parameters can be customized as NEAT is run on the
institution's cluster; (3) NEAT allows users to visualize and summarize NGS data 
rapidly and efficiently using various built-in exploratory data analysis tools
including metagenomic and differentially expressed gene analysis. To simplify the
control of the workflow, NEAT projects are built around a unique and centralized 
file containing sample names, replicates, conditions, antibodies, alignment-,
filtering- and peak calling parameters as well as cluster-specific paths and
settings. Moreover, the small-sized files produced by NEAT allow users to easily 
manipulate, consolidate and share datasets from different users and institutions.
CONCLUSIONS: NEAT provides biologists and bioinformaticians with a robust,
efficient and comprehensive tool for the analysis of massive NGS datasets.
Frameworks such as NEAT not only allow novice users to overcome the increasing
number of technical hurdles due to the complexity of manipulating large datasets,
but provide more advance users with tools that ensure high reproducibility
standards in the NGS era. NEAT is publically available at
https://github.com/pschorderet/NEAT.

DOI: 10.1186/s12859-016-0902-3 
PMCID: PMC4736651
PMID: 26830846  [PubMed - indexed for MEDLINE]


667. Bioinformatics. 2016 Jun 1;32(11):1749-51. doi: 10.1093/bioinformatics/btw044.
Epub 2016 Jan 30.

BCFtools/RoH: a hidden Markov model approach for detecting autozygosity from
next-generation sequencing data.

Narasimhan V(1), Danecek P(1), Scally A(2), Xue Y(1), Tyler-Smith C(1), Durbin
R(1).

Author information: 
(1)Wellcome Trust Sanger Institute, Hinxton and. (2)Department of Genetics,
University of Cambridge, Cambridge, UK.

Runs of homozygosity (RoHs) are genomic stretches of a diploid genome that show
identical alleles on both chromosomes. Longer RoHs are unlikely to have arisen by
chance but are likely to denote autozygosity, whereby both copies of the genome
descend from the same recent ancestor. Early tools to detect RoH used genotype
array data, but substantially more information is available from sequencing data.
Here, we present and evaluate BCFtools/RoH, an extension to the BCFtools software
package, that detects regions of autozygosity in sequencing data, in particular
exome data, using a hidden Markov model. By applying it to simulated data and
real data from the 1000 Genomes Project we estimate its accuracy and show that it
has higher sensitivity and specificity than existing methods under a range of
sequencing error rates and levels of autozygosity.AVAILABILITY AND
IMPLEMENTATION: BCFtools/RoH and its associated binary/source files are freely
available from https://github.com/samtools/BCFtools
CONTACT: vn2@sanger.ac.uk or pd3@sanger.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw044 
PMCID: PMC4892413
PMID: 26826718  [PubMed - in process]


668. Genome Med. 2016 Jan 29;8(1):11. doi: 10.1186/s13073-016-0264-5.

pVAC-Seq: A genome-guided in silico approach to identifying tumor neoantigens.

Hundal J(1), Carreno BM(2), Petti AA(3), Linette GP(4), Griffith
OL(5,)(6,)(7,)(8), Mardis ER(9,)(10,)(11,)(12,)(13), Griffith M(14,)(15,)(16).

Author information: 
(1)McDonnell Genome Institute, Washington University School of Medicine, St.
Louis, MO, USA. jhundal@genome.wustl.edu. (2)Department of Medicine, Division of 
Oncology, Washington University School of Medicine, St. Louis, MO, USA.
bcarreno@DOM.wustl.edu. (3)McDonnell Genome Institute, Washington University
School of Medicine, St. Louis, MO, USA. apetti@genome.wustl.edu. (4)Department of
Medicine, Division of Oncology, Washington University School of Medicine, St.
Louis, MO, USA. glinette@DOM.wustl.edu. (5)McDonnell Genome Institute, Washington
University School of Medicine, St. Louis, MO, USA. ogriffit@genome.wustl.edu.
(6)Department of Medicine, Division of Oncology, Washington University School of 
Medicine, St. Louis, MO, USA. ogriffit@genome.wustl.edu. (7)Department of
Genetics, Washington University School of Medicine, St. Louis, MO, USA.
ogriffit@genome.wustl.edu. (8)Siteman Cancer Center, Washington University School
of Medicine, St. Louis, MO, USA. ogriffit@genome.wustl.edu. (9)McDonnell Genome
Institute, Washington University School of Medicine, St. Louis, MO, USA.
emardis@wustl.edu. (10)Department of Medicine, Division of Genomics and
Bioinformatics, Washington University School of Medicine, St. Louis, MO, USA.
emardis@wustl.edu. (11)Department of Genetics, Washington University School of
Medicine, St. Louis, MO, USA. emardis@wustl.edu. (12)Siteman Cancer Center,
Washington University School of Medicine, St. Louis, MO, USA. emardis@wustl.edu. 
(13)Department of Molecular Microbiology, Washington University School of
Medicine, St. Louis, MO, USA. emardis@wustl.edu. (14)McDonnell Genome Institute, 
Washington University School of Medicine, St. Louis, MO, USA.
mgriffit@genome.wustl.edu. (15)Department of Genetics, Washington University
School of Medicine, St. Louis, MO, USA. mgriffit@genome.wustl.edu. (16)Siteman
Cancer Center, Washington University School of Medicine, St. Louis, MO, USA.
mgriffit@genome.wustl.edu.

Cancer immunotherapy has gained significant momentum from recent clinical
successes of checkpoint blockade inhibition. Massively parallel sequence analysis
suggests a connection between mutational load and response to this class of
therapy. Methods to identify which tumor-specific mutant peptides (neoantigens)
can elicit anti-tumor T cell immunity are needed to improve predictions of
checkpoint therapy response and to identify targets for vaccines and adoptive T
cell therapies. Here, we present a flexible, streamlined computational workflow
for identification of personalized Variant Antigens by Cancer Sequencing
(pVAC-Seq) that integrates tumor mutation and expression data (DNA- and RNA-Seq).
pVAC-Seq is available at https://github.com/griffithlab/pVAC-Seq .

DOI: 10.1186/s13073-016-0264-5 
PMCID: PMC4733280
PMID: 26825632  [PubMed - indexed for MEDLINE]


669. Bioinformatics. 2016 Jun 1;32(11):1743-5. doi: 10.1093/bioinformatics/btw042.
Epub 2016 Jan 27.

Galaxy Portal: interacting with the galaxy platform through mobile devices.

Børnich C(1), Grytten I(1), Hovig E(2), Paulsen J(1), Čech M(3), Sandve GK(1).

Author information: 
(1)Biomedicial Informatics, Department of Informatics, University of Oslo, Oslo, 
Norway. (2)Biomedicial Informatics, Department of Informatics, University of
Oslo, Oslo, Norway, Department of Tumor Biology, Institute of Cancer Research,
Oslo, Norway, Department of Cancer Genetics and Informatics, Radium Hospital,
Part of Oslo University Hospital, Oslo, Norway and. (3)Department of Biochemistry
and Molecular Biology, Penn State University, University Park, Pennsylvania
16802, USA.

: We present Galaxy Portal app, an open source interface to the Galaxy system
through smart phones and tablets. The Galaxy Portal provides convenient and
efficient monitoring of job completion, as well as opportunities for inspection
of results and execution history. In addition to being useful to the Galaxy
community, we believe that the app also exemplifies a useful way of exploiting
mobile interfaces for research/high-performance computing resources in
general.AVAILABILITY AND IMPLEMENTATION: The source is freely available under a
GPL license on GitHub, along with user documentation and pre-compiled binaries
and instructions for several platforms:
https://github.com/Tarostar/QMLGalaxyPortal It is available for iOS version 7
(and newer) through the Apple App Store, and for Android through Google Play for 
version 4.1 (API 16) or newer.
CONTACT: geirksa@ifi.uio.no.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw042 
PMCID: PMC4892412
PMID: 26819474  [PubMed - in process]


670. Bioinformatics. 2016 May 15;32(10):1592-4. doi: 10.1093/bioinformatics/btw046.
Epub 2016 Jan 27.

FILTUS: a desktop GUI for fast and efficient detection of disease-causing
variants, including a novel autozygosity detector.

Vigeland MD(1), Gjøtterud KS(2), Selmer KK(1).

Author information: 
(1)Department of Medical Genetics, Oslo University Hospital and University of
Oslo, Oslo N-0424. (2)Department of Research, Cancer Registry of Norway, Oslo
N-0304, Norway.

FILTUS is a stand-alone tool for working with annotated variant files, e.g. when 
searching for variants causing Mendelian disease. Very flexible in terms of input
file formats, FILTUS offers efficient filtering and a range of downstream
utilities, including statistical analysis of gene sharing patterns, detection of 
de novo mutations in trios, quality control plots and autozygosity mapping. The
autozygosity mapping is based on a hidden Markov model and enables accurate
detection of autozygous regions directly from exome-scale variant
files.AVAILABILITY AND IMPLEMENTATION: FILTUS is written in Python and runs on
Windows, Mac and Linux. Binaries and source code are freely available at
http://folk.uio.no/magnusv/filtus.html and on GitHub:
https://github.com/magnusdv/filtus Automatic installation is available via PyPI
(e.g. pip install filtus).
CONTACT: magnusdv@medisin.uio.no
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw046 
PMCID: PMC4866527
PMID: 26819469  [PubMed - in process]


671. Biochim Biophys Acta. 2016 Oct;1858(10):2512-28. doi:
10.1016/j.bbamem.2016.01.019. Epub 2016 Jan 22.

Atomistic resolution structure and dynamics of lipid bilayers in simulations and 
experiments.

Ollila OH(1), Pabst G(2).

Author information: 
(1)Department of Neuroscience and Biomedical Engineering, Aalto University,
Finland. Electronic address: samuli.ollila@aalto.fi. (2)University of Graz,
Institute of Molecular Biosciences, Biophysics Division, NAWI Graz, Humboldtstr. 
50/III, Graz, Austria; BioTechMed-Graz, Graz, Austria.

Accurate details on the sampled atomistic resolution structures of lipid bilayers
can be experimentally obtained by measuring C-H bond order parameters, spin
relaxation rates and scattering form factors. These parameters can be also
directly calculated from the classical atomistic resolution molecular dynamics
simulations (MD) and compared to the experimentally achieved results. This
comparison measures the simulation model quality with respect to 'reality'. If
agreement is sufficient, the simulation model gives an atomistic structural
interpretation of the acquired experimental data. Significant advance of MD
models is made by jointly interpreting different experiments using the same
structural model. Here we focus on phosphatidylcholine lipid bilayers, which out 
of all model membranes have been studied mostly by experiments and simulations,
leading to the largest available dataset. From the applied comparisons we
conclude that the acyl chain region structure and rotational dynamics are
generally well described in simulation models. Also changes with temperature,
dehydration and cholesterol concentration are qualitatively correctly reproduced.
However, the quality of the underlying atomistic resolution structural changes is
uncertain. Even worse, when focusing on the lipid bilayer properties at the
interfacial region, e.g. glycerol backbone and choline structures, and cation
binding, many simulation models produce an inaccurate description of experimental
data. Thus extreme care must be applied when simulations are applied to
understand phenomena where the interfacial region plays a significant role. This 
work is done by the NMRlipids Open Collaboration project running at
https://nmrlipids.blogspot.fi and https://github.com/NMRLipids. This article is
part of a Special Issue entitled: Biosimulations edited by Ilpo Vattulainen and
Tomasz Róg.

Copyright © 2016 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.bbamem.2016.01.019 
PMID: 26809025  [PubMed - in process]


672. PLoS One. 2016 Jan 25;11(1):e0146732. doi: 10.1371/journal.pone.0146732.
eCollection 2016.

CERENA: ChEmical REaction Network Analyzer--A Toolbox for the Simulation and
Analysis of Stochastic Chemical Kinetics.

Kazeroonian A(1,)(2), Fröhlich F(1,)(2), Raue A(3), Theis FJ(1,)(2), Hasenauer
J(1,)(2).

Author information: 
(1)Institute of Computational Biology, Helmholtz Zentrum München-German Research 
Center for Environmental Health, Neuherberg, Germany. (2)Department of
Mathematics, Chair of Mathematical Modeling of Biological Systems, Technische
Universität München, Garching, Germany. (3)Merrimack Pharmaceuticals Inc.,
Discovery Devision, Cambridge, MA 02139, United States of America.

Gene expression, signal transduction and many other cellular processes are
subject to stochastic fluctuations. The analysis of these stochastic chemical
kinetics is important for understanding cell-to-cell variability and its
functional implications, but it is also challenging. A multitude of exact and
approximate descriptions of stochastic chemical kinetics have been developed,
however, tools to automatically generate the descriptions and compare their
accuracy and computational efficiency are missing. In this manuscript we
introduced CERENA, a toolbox for the analysis of stochastic chemical kinetics
using Approximations of the Chemical Master Equation solution statistics. CERENA 
implements stochastic simulation algorithms and the finite state projection for
microscopic descriptions of processes, the system size expansion and moment
equations for meso- and macroscopic descriptions, as well as the novel
conditional moment equations for a hybrid description. This unique collection of 
descriptions in a single toolbox facilitates the selection of appropriate
modeling approaches. Unlike other software packages, the implementation of CERENA
is completely general and allows, e.g., for time-dependent propensities and
non-mass action kinetics. By providing SBML import, symbolic model generation and
simulation using MEX-files, CERENA is user-friendly and computationally
efficient. The availability of forward and adjoint sensitivity analyses allows
for further studies such as parameter estimation and uncertainty analysis. The
MATLAB code implementing CERENA is freely available from
http://cerenadevelopers.github.io/CERENA/.

DOI: 10.1371/journal.pone.0146732 
PMCID: PMC4726759
PMID: 26807911  [PubMed - indexed for MEDLINE]


673. Bioinformatics. 2016 May 15;32(10):1598-600. doi: 10.1093/bioinformatics/btw043. 
Epub 2016 Jan 23.

BISQUE: locus- and variant-specific conversion of genomic, transcriptomic and
proteomic database identifiers.

Meyer MJ(1), Geske P(2), Yu H(2).

Author information: 
(1)Department of Biological Statistics and Computational Biology, Weill Institute
for Cell and Molecular Biology, Cornell University, Ithaca, NY 14853, USA and
Tri-Institutional Training Program in Computational Biology and Medicine, New
York, NY 10065, USA. (2)Department of Biological Statistics and Computational
Biology, Weill Institute for Cell and Molecular Biology, Cornell University,
Ithaca, NY 14853, USA and.

Biological sequence databases are integral to efforts to characterize and
understand biological molecules and share biological data. However, when
analyzing these data, scientists are often left holding disparate biological
currency-molecular identifiers from different databases. For downstream
applications that require converting the identifiers themselves, there are many
resources available, but analyzing associated loci and variants can be cumbersome
if data is not given in a form amenable to particular analyses. Here we present
BISQUE, a web server and customizable command-line tool for converting molecular 
identifiers and their contained loci and variants between different database
conventions. BISQUE uses a graph traversal algorithm to generalize the conversion
process for residues in the human genome, genes, transcripts and proteins,
allowing for conversion across classes of molecules and in all directions through
an intuitive web interface and a URL-based web service.AVAILABILITY AND
IMPLEMENTATION: BISQUE is freely available via the web using any major web
browser (http://bisque.yulab.org/). Source code is available in a public GitHub
repository (https://github.com/hyulab/BISQUE).
CONTACT: haiyuan.yu@cornell.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw043 
PMID: 26803163  [PubMed - in process]


674. Bioinformatics. 2016 May 15;32(10):1557-8. doi: 10.1093/bioinformatics/btw028.
Epub 2016 Jan 23.

MuCor: mutation aggregation and correlation.

Kroll KW(1), Eisfeld AK(2), Lozanski G(3), Bloomfield CD(4), Byrd JC(4), Blachly 
JS(4).

Author information: 
(1)Division of Hematology, Department of Internal Medicine. (2)Department of
Human Cancer Genetics and Molecular Virology. (3)Department of Pathology, The
Ohio State University, Columbus, OH 43210 and. (4)Division of Hematology,
Department of Internal Medicine, The Ohio State University James Comprehensive
Cancer Center, Columbus, OH 43210, USA.

MOTIVATION: There are many tools for variant calling and effect prediction, but
little to tie together large sample groups. Aggregating, sorting and summarizing 
variants and effects across a cohort is often done with ad hoc scripts that must 
be re-written for every new project. In response, we have written MuCor, a tool
to gather variants from a variety of input formats (including multiple files per 
sample), perform database lookups and frequency calculations, and write many
types of reports. In addition to use in large studies with numerous samples,
MuCor can also be employed to directly compare variant calls from the same sample
across two or more platforms, parameters or pipelines. A companion utility,
DepthGauge, measures coverage at regions of interest to increase confidence in
calls.
AVAILABILITY AND IMPLEMENTATION: Source code is freely available at
https://github.com/blachlylab/mucor and a Docker image is available at
https://hub.docker.com/r/blachlylab/mucor/
CONTACT: james.blachly@osumc.eduSupplementary data: Supplementary data are
available at Bioinformatics online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw028 
PMCID: PMC4866525
PMID: 26803155  [PubMed - in process]


675. Bioinformatics. 2016 May 15;32(10):1518-26. doi: 10.1093/bioinformatics/btw023.
Epub 2016 Jan 21.

MS-REDUCE: an ultrafast technique for reduction of big mass spectrometry data for
high-throughput processing.

Awan MG(1), Saeed F(2).

Author information: 
(1)Department of Electrical and Computer Engineering and. (2)Department of
Electrical and Computer Engineering and Department of Computer Science, Western
Michigan University, Kalamazoo, MI 49008, USA.

MOTIVATION: Modern proteomics studies utilize high-throughput mass spectrometers 
which can produce data at an astonishing rate. These big mass spectrometry (MS)
datasets can easily reach peta-scale level creating storage and analytic problems
for large-scale systems biology studies. Each spectrum consists of thousands of
peaks which have to be processed to deduce the peptide. However, only a small
percentage of peaks in a spectrum are useful for peptide deduction as most of the
peaks are either noise or not useful for a given spectrum. This redundant
processing of non-useful peaks is a bottleneck for streaming high-throughput
processing of big MS data. One way to reduce the amount of computation required
in a high-throughput environment is to eliminate non-useful peaks. Existing noise
removing algorithms are limited in their data-reduction capability and are
compute intensive making them unsuitable for big data and high-throughput
environments. In this paper we introduce a novel low-complexity technique based
on classification, quantization and sampling of MS peaks.
RESULTS: We present a novel data-reductive strategy for analysis of Big MS data. 
Our algorithm, called MS-REDUCE, is capable of eliminating noisy peaks as well as
peaks that do not contribute to peptide deduction before any peptide deduction is
attempted. Our experiments have shown up to 100× speed up over existing state of 
the art noise elimination algorithms while maintaining comparable high quality
matches. Using our approach we were able to process a million spectra in just
under an hour on a moderate server.
AVAILABILITY AND IMPLEMENTATION: The developed tool and strategy has been made
available to wider proteomics and parallel computing community and the code can
be found at https://github.com/pcdslab/MSREDUCE CONTACT: : fahad.saeed@wmich.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw023 
PMID: 26801958  [PubMed - in process]


676. Proc Am Stat Assoc. 2015 Aug;2015:650-664.

R package PRIMsrc: Bump Hunting by Patient Rule Induction Method for Survival,
Regression and Classification.

Dazard JE(1), Choe M(1), LeBlanc M(2), Rao JS(3).

Author information: 
(1)Division of Bioinformatics, Center for Proteomics and Bioinformatics, Case
Western Reserve University. Cleveland, OH 44106, USA. (2)Department of
Biostatistics, School of Public Health, University of Washington, Seattle, WA
98195, USA; Public Health Sciences, Fred Hutchinson Cancer Research Center,
Seattle, WA 98109. (3)Division of Biostatistics, Dept. of Epidemiology and Public
Health, The University of Miami. Miami, FL 33136, USA.

PRIMsrc is a novel implementation of a non-parametric bump hunting procedure,
based on the Patient Rule Induction Method (PRIM), offering a unified treatment
of outcome variables, including censored time-to-event (Survival), continuous
(Regression) and discrete (Classification) responses. To fit the model, it uses a
recursive peeling procedure with specific peeling criteria and stopping rules
depending on the response. To validate the model, it provides an objective
function based on prediction-error or other specific statistic, as well as two
alternative cross-validation techniques, adapted to the task of decision-rule
making and estimation in the three types of settings. PRIMsrc comes as an open
source R package, including at this point: (i) a main function for fitting a
Survival Bump Hunting model with various options allowing cross-validated model
selection to control model size (#covariates) and model complexity (#peeling
steps) and generation of cross-validated end-point estimates; (ii) parallel
computing; (iii) various S3-generic and specific plotting functions for data
visualization, diagnostic, prediction, summary and display of results. It is
available on CRAN and GitHub.


PMCID: PMC4718587
PMID: 26798326  [PubMed]


677. PLoS One. 2016 Jan 21;11(1):e0147078. doi: 10.1371/journal.pone.0147078.
eCollection 2016.

An Algorithm to Automatically Generate the Combinatorial Orbit Counting
Equations.

Melckenbeeck I(1), Audenaert P(1), Michoel T(2), Colle D(1), Pickavet M(1).

Author information: 
(1)Department of Information Technology (INTEC), Ghent University-iMinds, Ghent, 
Belgium. (2)The Roslin Institute, University of Edinburgh, Easter Bush,
Midlothian, Scotland, United Kingdom.

Graphlets are small subgraphs, usually containing up to five vertices, that can
be found in a larger graph. Identification of the graphlets that a vertex in an
explored graph touches can provide useful information about the local structure
of the graph around that vertex. Actually finding all graphlets in a large graph 
can be time-consuming, however. As the graphlets grow in size, more different
graphlets emerge and the time needed to find each graphlet also scales up. If it 
is not needed to find each instance of each graphlet, but knowing the number of
graphlets touching each node of the graph suffices, the problem is less hard.
Previous research shows a way to simplify counting the graphlets: instead of
looking for the graphlets needed, smaller graphlets are searched, as well as the 
number of common neighbors of vertices. Solving a system of equations then gives 
the number of times a vertex is part of each graphlet of the desired size.
However, until now, equations only exist to count graphlets with 4 or 5 nodes. In
this paper, two new techniques are presented. The first allows to generate the
equations needed in an automatic way. This eliminates the tedious work needed to 
do so manually each time an extra node is added to the graphlets. The technique
is independent on the number of nodes in the graphlets and can thus be used to
count larger graphlets than previously possible. The second technique gives all
graphlets a unique ordering which is easily extended to name graphlets of any
size. Both techniques were used to generate equations to count graphlets with 4, 
5 and 6 vertices, which extends all previous results. Code can be found at
https://github.com/IneMelckenbeeck/equation-generator and
https://github.com/IneMelckenbeeck/graphlet-naming.

DOI: 10.1371/journal.pone.0147078 
PMCID: PMC4721873
PMID: 26797021  [PubMed - indexed for MEDLINE]


678. Bioinformatics. 2016 Apr 1;32(7):1109-11. doi: 10.1093/bioinformatics/btw022.
Epub 2016 Jan 21.

The TraDIS toolkit: sequencing and analysis for dense transposon mutant
libraries.

Barquist L(1), Mayho M(2), Cummins C(2), Cain AK(2), Boinett CJ(2), Page AJ(2),
Langridge GC(2), Quail MA(2), Keane JA(2), Parkhill J(2).

Author information: 
(1)Wellcome Trust Sanger Institute, Hinxton, Cambridge CB10 1SA, UK and Institute
for Molecular Infection Biology, University of Würzburg, Würzburg D-97080,
Germany. (2)Wellcome Trust Sanger Institute, Hinxton, Cambridge CB10 1SA, UK and.

Transposon insertion sequencing is a high-throughput technique for assaying large
libraries of otherwise isogenic transposon mutants providing insight into gene
essentiality, gene function and genetic interactions. We previously developed the
Transposon Directed Insertion Sequencing (TraDIS) protocol for this purpose,
which utilizes shearing of genomic DNA followed by specific PCR amplification of 
transposon-containing fragments and Illumina sequencing. Here we describe an
optimized high-yield library preparation and sequencing protocol for TraDIS
experiments and a novel software pipeline for analysis of the resulting data. The
Bio-Tradis analysis pipeline is implemented as an extensible Perl library which
can either be used as is, or as a basis for the development of more advanced
analysis tools. This article can serve as a general reference for the application
of the TraDIS methodology.AVAILABILITY AND IMPLEMENTATION: The optimized
sequencing protocol is included as supplementary information. The Bio-Tradis
analysis pipeline is available under a GPL license at
https://github.com/sanger-pathogens/Bio-Tradis
CONTACT: parkhill@sanger.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw022 
PMCID: PMC4896371
PMID: 26794317  [PubMed - in process]


679. Proteomics. 2016 Mar;16(6):920-4. doi: 10.1002/pmic.201500420.

Morpheus Spectral Counter: A computational tool for label-free quantitative mass 
spectrometry using the Morpheus search engine.

Gemperline DC(1), Scalf M(2), Smith LM(2), Vierstra RD(1,)(3).

Author information: 
(1)Department of Genetics, University of Wisconsin, Madison, Wisconsin, USA.
(2)Department of Chemistry, University of Wisconsin, Madison, Wisconsin, USA.
(3)Department of Biology, Washington University in St. Louis, St. Louis,
Missouri, USA.

Label-free quantitative MS based on the Normalized Spectral Abundance Factor
(NSAF) has emerged as a straightforward and robust method to determine the
relative abundance of individual proteins within complex mixtures. Here, we
present Morpheus Spectral Counter (MSpC) as the first computational tool that
directly calculates NSAF values from output obtained from Morpheus, a fast,
open-source, peptide-MS/MS matching engine compatible with high-resolution
accurate-mass instruments. NSAF has distinct advantages over other MS-based
quantification methods, including a greater dynamic range as compared to isobaric
tags, no requirement to align and re-extract MS1 peaks, and increased speed. MSpC
features an easy-to-use graphic user interface that additionally calculates both 
distributed and unique NSAF values to permit analyses of both protein families
and isoforms/proteoforms. MSpC determinations of protein concentration were
linear over several orders of magnitude based on the analysis of several
high-mass accuracy datasets either obtained from PRIDE or generated with total
cell extracts spiked with purified Arabidopsis 20S proteasomes. The MSpC software
was developed in C# and is open sourced under a permissive license with the code 
made available at http://dcgemperline.github.io/Morpheus_SpC/.

© 2016 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim.

DOI: 10.1002/pmic.201500420 
PMCID: PMC5089804 [Available on 2017-03-01]
PMID: 26791624  [PubMed - indexed for MEDLINE]


680. Glob Chang Biol. 2016 May;22(5):1690-709. doi: 10.1111/gcb.13226.

Carbon dynamics of mature and regrowth tropical forests derived from a
pantropical database (TropForC-db).

Anderson-Teixeira KJ(1,)(2), Wang MM(1), McGarvey JC(1), LeBauer DS(3).

Author information: 
(1)Conservation Ecology Center, Smithsonian Conservation Biology Institute,
National Zoological Park, 1500 Remount Rd., Front Royal, VA, 22630, USA.
(2)Center for Tropical Forest Science-Forest Global Earth Observatory,
Smithsonian Tropical Research Institute, Apartado 0843-03092, Panamá, Republic of
Panamá (3)Carl Woese Institute for Genomic Biology, University of Illinois, 1206 
W Gregory Dr, Urbana, IL, 61801, USA.

Tropical forests play a critical role in the global carbon (C) cycle, storing
~45% of terrestrial C and constituting the largest component of the terrestrial C
sink. Despite their central importance to the global C cycle, their
ecosystem-level C cycles are not as well-characterized as those of extra-tropical
forests, and knowledge gaps hamper efforts to quantify C budgets across the
tropics and to model tropical forest-climate interactions. To advance
understanding of C dynamics of pantropical forests, we compiled a new database,
the Tropical Forest C database (TropForC-db), which contains data on ground-based
measurements of ecosystem-level C stocks and annual fluxes along with disturbance
history. This database currently contains 3568 records from 845 plots in 178
geographically distinct areas, making it the largest and most comprehensive
database of its type. Using TropForC-db, we characterized C stocks and fluxes for
young, intermediate-aged, and mature forests. Relative to existing C budgets of
extra-tropical forests, mature tropical broadleaf evergreen forests had
substantially higher gross primary productivity (GPP) and ecosystem respiration
(Reco), their autotropic respiration (Ra) consumed a larger proportion (~67%) of 
GPP, and their woody stem growth (ANPPstem) represented a smaller proportion of
net primary productivity (NPP, ~32%) or GPP (~9%). In regrowth stands,
aboveground biomass increased rapidly during the first 20 years following
stand-clearing disturbance, with slower accumulation following agriculture and in
deciduous forests, and continued to accumulate at a slower pace in forests aged
20-100 years. Most other C stocks likewise increased with stand age, while
potential to describe age trends in C fluxes was generally data-limited. We
expect that TropForC-db will prove useful for model evaluation and for
quantifying the contribution of forests to the global C cycle. The database
version associated with this publication is archived in Dryad (DOI:
10.5061/dryad.t516f) and a dynamic version is maintained at
https://github.com/forc-db.

Published 2016. This article is a U.S. Government work and is in the public
domain in the USA.

DOI: 10.1111/gcb.13226 
PMID: 26790568  [PubMed - indexed for MEDLINE]


681. Springerplus. 2016 Jan 12;5:27. doi: 10.1186/s40064-015-1609-z. eCollection 2016.

Structural homology guided alignment of cysteine rich proteins.

Shafee TM(1), Robinson AJ(2), van der Weerden N(1), Anderson MA(1).

Author information: 
(1)Department of Biochemistry, La Trobe Institute of Molecular Sciences, La Trobe
University, Melbourne, 3086 Australia. (2)College of Science, Health and
Engineering, La Trobe University, Melbourne, 3086 Australia ; Life Sciences
Computation Centre, Victorian Life Sciences Computation Initiative, Melbourne,
3053 Australia.

BACKGROUND: Cysteine rich protein families are notoriously difficult to align due
to low sequence identity and frequent insertions and deletions.
RESULTS: Here we present an alignment method that ensures homologous cysteines
align by assigning a unique 10 amino acid barcode to those identified as
structurally homologous by the DALI webserver. The free inter-cysteine regions of
the barcoded sequences can then be aligned using any standard algorithm. Finally 
the barcodes are replaced with the original columns to yield an alignment which
requires the minimum of manual refinement.
CONCLUSIONS: Using structural homology information to constrain sequence
alignments allows the alignment of highly divergent, repetitive sequences that
are poorly dealt with by existing algorithms. Tools are provided to perform this 
method online using the CysBar web-tool (http://CysBar.science.latrobe.edu.au)
and offline (python script available from http://github.com/ts404/CysBar).

DOI: 10.1186/s40064-015-1609-z 
PMCID: PMC4709342
PMID: 26788439  [PubMed]


682. Bioinformatics. 2016 May 15;32(10):1527-35. doi: 10.1093/bioinformatics/btw003.
Epub 2016 Jan 18.

Orthogonal matrix factorization enables integrative analysis of multiple RNA
binding proteins.

Stražar M(1), Žitnik M(1), Zupan B(2), Ule J(3), Curk T(1).

Author information: 
(1)University of Ljubljana, Faculty of Computer and Information Science,
Ljubljana, SI 1000, Slovenia. (2)University of Ljubljana, Faculty of Computer and
Information Science, Ljubljana, SI 1000, Slovenia Department of Molecular and
Human Genetics, Baylor College of Medicine, Houston, TX 77030, USA. (3)Department
of Molecular Neuroscience, UCL Institute of Neurology, Queen Square, London WC1N 
3BG, UK.

MOTIVATION: RNA binding proteins (RBPs) play important roles in
post-transcriptional control of gene expression, including splicing, transport,
polyadenylation and RNA stability. To model protein-RNA interactions by
considering all available sources of information, it is necessary to integrate
the rapidly growing RBP experimental data with the latest genome annotation, gene
function, RNA sequence and structure. Such integration is possible by matrix
factorization, where current approaches have an undesired tendency to identify
only a small number of the strongest patterns with overlapping features. Because 
protein-RNA interactions are orchestrated by multiple factors, methods that
identify discriminative patterns of varying strengths are needed.
RESULTS: We have developed an integrative orthogonality-regularized nonnegative
matrix factorization (iONMF) to integrate multiple data sources and discover
non-overlapping, class-specific RNA binding patterns of varying strengths. The
orthogonality constraint halves the effective size of the factor model and
outperforms other NMF models in predicting RBP interaction sites on RNA. We have 
integrated the largest data compendium to date, which includes 31 CLIP
experiments on 19 RBPs involved in splicing (such as hnRNPs, U2AF2, ELAVL1,
TDP-43 and FUS) and processing of 3'UTR (Ago, IGF2BP). We show that the
integration of multiple data sources improves the predictive accuracy of
retrieval of RNA binding sites. In our study the key predictive factors of
protein-RNA interactions were the position of RNA structure and sequence motifs, 
RBP co-binding and gene region type. We report on a number of protein-specific
patterns, many of which are consistent with experimentally determined properties 
of RBPs.
AVAILABILITY AND IMPLEMENTATION: The iONMF implementation and example datasets
are available at https://github.com/mstrazar/ionmf
CONTACT: : tomaz.curk@fri.uni-lj.si
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw003 
PMCID: PMC4894278
PMID: 26787667  [PubMed - in process]


683. Bioinformatics. 2016 May 15;32(10):1559-61. doi: 10.1093/bioinformatics/btw015.
Epub 2016 Jan 18.

GeneValidator: identify problems with protein-coding gene predictions.

Drăgan MA(1), Moghul I(2), Priyam A(2), Bustos C(3), Wurm Y(2).

Author information: 
(1)Department of Computer Science, ETH Zürich, Zürich, Switzerland. (2)School of 
Biological and Chemical Sciences, Queen Mary University of London, London, UK
and. (3)Departamento de Psiquiatría y Salud Mental, University of Concepción,
Concepción, Chile.

: Genomes of emerging model organisms are now being sequenced at very low cost.
However, obtaining accurate gene predictions remains challenging: even the best
gene prediction algorithms make substantial errors and can jeopardize subsequent 
analyses. Therefore, many predicted genes must be time-consumingly visually
inspected and manually curated. We developed GeneValidator (GV) to automatically 
identify problematic gene predictions and to aid manual curation. For each gene, 
GV performs multiple analyses based on comparisons to gene sequences from large
databases. The resulting report identifies problematic gene predictions and
includes extensive statistics and graphs for each prediction to guide manual
curation efforts. GV thus accelerates and enhances the work of biocurators and
researchers who need accurate gene predictions from newly sequenced
genomes.AVAILABILITY AND IMPLEMENTATION: GV can be used through a web interface
or in the command-line. GV is open-source (AGPL), available at
https://wurmlab.github.io/tools/genevalidator
CONTACT: : y.wurm@qmul.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw015 
PMCID: PMC4866521
PMID: 26787666  [PubMed - in process]


684. Bioinformatics. 2016 May 15;32(10):1486-92. doi: 10.1093/bioinformatics/btv753.
Epub 2016 Jan 18.

MultiGeMS: detection of SNVs from multiple samples using model selection on
high-throughput sequencing data.

Murillo GH(1), You N(2), Su X(3), Cui W(1), Reilly MP(4), Li M(5), Ning K(6), Cui
X(7).

Author information: 
(1)Department of Statistics, University of California, Riverside, CA 92521, USA. 
(2)Department of Statistical Science, School of Mathematics and Computational
Science, Sun Yat-Sen University, Guangzhou, Guangdong 510275, China. (3)Qingdao
Institute of BioEnergy and Bioprocess Technology, Chinese Academy of Sciences,
Qingdao, Shandong 266101, China. (4)Cardiovascular Institute. (5)Department of
Biostatistics and Epidemiology, University of Pennsylvania Perelman School of
Medicine, Philadelphia, PA 19104, USA. (6)Key Laboratory of Molecular Biophysics 
of the Ministry of Education, College of Life Science and Technology, Huazhong
University of Science and Technology, Wuhan, Hubei 430074, China and.
(7)Department of Statistics, University of California, Riverside, CA 92521, USA, 
Center for Plant Cell Biology, Institute for Integrative Genome Biology,
University of California, Riverside, CA 92521, USA.

MOTIVATION: Single nucleotide variant (SNV) detection procedures are being
utilized as never before to analyze the recent abundance of high-throughput DNA
sequencing data, both on single and multiple sample datasets. Building on
previously published work with the single sample SNV caller genotype model
selection (GeMS), a multiple sample version of GeMS (MultiGeMS) is introduced.
Unlike other popular multiple sample SNV callers, the MultiGeMS statistical model
accounts for enzymatic substitution sequencing errors. It also addresses the
multiple testing problem endemic to multiple sample SNV calling and utilizes high
performance computing (HPC) techniques.
RESULTS: A simulation study demonstrates that MultiGeMS ranks highest in
precision among a selection of popular multiple sample SNV callers, while showing
exceptional recall in calling common SNVs. Further, both simulation studies and
real data analyses indicate that MultiGeMS is robust to low-quality data. We also
demonstrate that accounting for enzymatic substitution sequencing errors not only
improves SNV call precision at low mapping quality regions, but also improves
recall at reference allele-dominated sites with high mapping quality.
AVAILABILITY AND IMPLEMENTATION: The MultiGeMS package can be downloaded from
https://github.com/cui-lab/multigems
CONTACT: xinping.cui@ucr.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv753 
PMID: 26787661  [PubMed - in process]


685. BMC Bioinformatics. 2016 Jan 19;17:41. doi: 10.1186/s12859-016-0892-1.

4Pipe4--A 454 data analysis pipeline for SNP detection in datasets with no
reference sequence or strain information.

Pina-Martins F(1,)(2), Vieira BM(3,)(4), Seabra SG(3), Batista D(3,)(5), Paulo
OS(3).

Author information: 
(1)Departamento de Biologia Animal, Faculdade de Ciências, Computational Biology 
and Population Genomics Group, cE3c - Centre for Ecology, Evolution and
Environmental Changes, Universidade de Lisboa, Campo Grande, 1749-016, Lisboa,
Portugal. f.pinamartins@gmail.com. (2)Departamento de Biologia e CESAM, Univ. de 
Aveiro, Aveiro, Portugal. f.pinamartins@gmail.com. (3)Departamento de Biologia
Animal, Faculdade de Ciências, Computational Biology and Population Genomics
Group, cE3c - Centre for Ecology, Evolution and Environmental Changes,
Universidade de Lisboa, Campo Grande, 1749-016, Lisboa, Portugal. (4)Wurm Lab,
School of Biological & Chemical Sciences, Queen Mary University of London, Mile
End Road, E1 4NS, London, UK. (5)Centro de Investigação das Ferrugens do Cafeeiro
(CIFC), Instituto Superior de Agronomia (ISA), Universidade de Lisboa, Quinta do 
Marquês, 2784-505, Oeiras, Portugal.

BACKGROUND: Next-generation sequencing datasets are becoming more frequent, and
their use in population studies is becoming widespread. For non-model species,
without a reference genome, it is possible from a panel of individuals to
identify a set of SNPs that can be used for further population genotyping.
However the lack of a reference genome to which the sequenced data could be
compared makes the finding of SNPs more troublesome. Additionally when the data
sources (strains) are not identified (e.g. in datasets of pooled individuals),
the problem of finding reliable variation in these datasets can become much more 
difficult due to the lack of specialized software for this specific task.
RESULTS: Here we describe 4Pipe4, a 454 data analysis pipeline particularly
focused on SNP detection when no reference or strain information is available. It
uses a command line interface to automatically call other programs, parse their
outputs and summarize the results. The variation detection routine is built-in in
the program itself. Despite being optimized for SNP mining in 454 EST data, it is
flexible enough to automate the analysis of genomic data or even data from other 
NGS technologies. 4Pipe4 will output several HTML formatted reports with metrics 
on many of the most common assembly values, as well as on all the variation
found. There is also a module available for finding putative SSRs in the analysed
datasets.
CONCLUSIONS: This program can be especially useful for researchers that have 454 
datasets of a panel of pooled individuals and want to discover and characterize
SNPs for subsequent individual genotyping with customized genotyping arrays. In
comparison with other SNP detection approaches, 4Pipe4 showed the best validation
ratio, retrieving a smaller number of SNPs but with a considerably lower false
positive rate than other methods. 4Pipe4's source code is available at
https://github.com/StuntsPT/4Pipe4.

DOI: 10.1186/s12859-016-0892-1 
PMCID: PMC4719533
PMID: 26787189  [PubMed - indexed for MEDLINE]


686. PLoS Comput Biol. 2016 Jan 19;12(1):e1004668. doi: 10.1371/journal.pcbi.1004668. 
eCollection 2016.

A Quick Introduction to Version Control with Git and GitHub.

Blischak JD(1), Davenport ER(2), Wilson G(3).

Author information: 
(1)Committee on Genetics, Genomics, and Systems Biology, University of Chicago,
Chicago, Illinois, United States of America. (2)Department of Molecular Biology
and Genetics, Cornell University, Ithaca, New York, United States of America.
(3)Software Carpentry Foundation, Toronto, Ontario, Canada.

DOI: 10.1371/journal.pcbi.1004668 
PMCID: PMC4718703
PMID: 26785377  [PubMed - indexed for MEDLINE]


687. J Comput Neurosci. 2016 Feb;40(1):103-11. doi: 10.1007/s10827-015-0586-0. Epub
2016 Jan 18.

Reliability of signal transmission in stochastic nerve axon equations.

Sauer M(1,)(2), Stannat W(3,)(4).

Author information: 
(1)Institut für Mathematik, Technische Universität Berlin, Straße des 17, Juni
136, 10623, Berlin, Germany. (2)Bernstein Center for Computational Neuroscience, 
Philippstr. 13, 10115, Berlin, Germany. (3)Institut für Mathematik, Technische
Universität Berlin, Straße des 17, Juni 136, 10623, Berlin, Germany.
stannat@math.tu-berlin.de. (4)Bernstein Center for Computational Neuroscience,
Philippstr. 13, 10115, Berlin, Germany. stannat@math.tu-berlin.de.

We introduce a method for computing probabilities for spontaneous activity and
propagation failure of the action potential in spatially extended,
conductance-based neuronal models subject to noise, based on statistical
properties of the membrane potential. We compare different estimators with
respect to the quality of detection, computational costs and robustness and
propose the integral of the membrane potential along the axon as an appropriate
estimator to detect both spontaneous activity and propagation failure. Performing
a model reduction we achieve a simplified analytical expression based on the
linearization at the resting potential (resp. the traveling action potential).
This allows to approximate the probabilities for spontaneous activity and
propagation failure in terms of (classical) hitting probabilities of
one-dimensional linear stochastic differential equations. The quality of the
approximation with respect to the noise amplitude is discussed and illustrated
with numerical results for the spatially extended Hodgkin-Huxley equations.
Python simulation code is supplied on GitHub under the link
https://github.com/deristnochda/Hodgkin-Huxley-SPDE.

DOI: 10.1007/s10827-015-0586-0 
PMID: 26781640  [PubMed - indexed for MEDLINE]


688. BMC Genomics. 2016 Jan 14;17:54. doi: 10.1186/s12864-015-2349-8.

FRAMA: from RNA-seq data to annotated mRNA assemblies.

Bens M(1), Sahm A(2), Groth M(3), Jahn N(4), Morhart M(5), Holtze S(6),
Hildebrandt TB(7), Platzer M(8), Szafranski K(9).

Author information: 
(1)Leibniz Institute on Ageing - Fritz Lipmann Institute, Beutenbergstr. 11,
07745, Jena, Germany. mbens@fli-leibniz.de. (2)Leibniz Institute on Ageing -
Fritz Lipmann Institute, Beutenbergstr. 11, 07745, Jena, Germany.
asahm@fli-leibniz.de. (3)Leibniz Institute on Ageing - Fritz Lipmann Institute,
Beutenbergstr. 11, 07745, Jena, Germany. mgroth@fli-leibniz.de. (4)Leibniz
Institute on Ageing - Fritz Lipmann Institute, Beutenbergstr. 11, 07745, Jena,
Germany. nielsj@fli-leibniz.de. (5)Leibniz Institute for Zoo and Wildlife
Research, Alfred-Kowalke-Straße 17, 10315, Berlin, Germany.
morhart@izw-berlin.de. (6)Leibniz Institute for Zoo and Wildlife Research,
Alfred-Kowalke-Straße 17, 10315, Berlin, Germany. holtze@izw-berlin.de.
(7)Leibniz Institute for Zoo and Wildlife Research, Alfred-Kowalke-Straße 17,
10315, Berlin, Germany. hildebrandt@izw-berlin.de. (8)Leibniz Institute on Ageing
- Fritz Lipmann Institute, Beutenbergstr. 11, 07745, Jena, Germany.
mplatzer@fli-leibniz.de. (9)Leibniz Institute on Ageing - Fritz Lipmann
Institute, Beutenbergstr. 11, 07745, Jena, Germany. szafrans@fli-leibniz.de.

BACKGROUND: Advances in second-generation sequencing of RNA made a near-complete 
characterization of transcriptomes affordable. However, the reconstruction of
full-length mRNAs via de novo RNA-seq assembly is still difficult due to the
complexity of eukaryote transcriptomes with highly similar paralogs and multiple 
alternative splice variants. Here, we present FRAMA, a genome-independent
annotation tool for de novo mRNA assemblies that addresses several post-assembly 
tasks, such as reduction of contig redundancy, ortholog assignment, correction of
misassembled transcripts, scaffolding of fragmented transcripts and coding
sequence identification.
RESULTS: We applied FRAMA to assemble and annotate the transcriptome of the naked
mole-rat and assess the quality of the obtained compilation of transcripts with
the aid of publicy available naked mole-rat gene annotations. Based on a de novo 
transcriptome assembly (Trinity), FRAMA annotated 21,984 naked mole-rat mRNAs
(12,100 full-length CDSs), corresponding to 16,887 genes. The scaffolding of 3488
genes increased the median sequence information 1.27-fold. In total, FRAMA
detected and corrected 4774 misassembled genes, which were predominantly caused
by fusion of genes. A comparison with three different sources of naked mole-rat
transcripts reveals that FRAMA's gene models are better supported by RNA-seq data
than any other transcript set. Further, our results demonstrate the
competitiveness of FRAMA to state of the art genome-based transcript
reconstruction approaches.
CONCLUSION: FRAMA realizes the de novo construction of a low-redundant transcript
catalog for eukaryotes, including the extension and refinement of transcripts.
Thereby, results delivered by FRAMA provide the basis for comprehensive
downstream analyses like gene expression studies or comparative transcriptomics. 
FRAMA is available at https://github.com/gengit/FRAMA .

DOI: 10.1186/s12864-015-2349-8 
PMCID: PMC4712544
PMID: 26763976  [PubMed - indexed for MEDLINE]


689. Bioinformatics. 2016 May 1;32(9):1301-7. doi: 10.1093/bioinformatics/btw011. Epub
2016 Jan 10.

Integration of string and de Bruijn graphs for genome assembly.

Huang YT(1), Liao CF(1).

Author information: 
(1)Department of Computer Science and Information Engineering, National Chung
Cheng University, Chiayi, Taiwan.

MOTIVATION: String and de Bruijn graphs are two graph models used by most genome 
assemblers. At present, none of the existing assemblers clearly outperforms the
others across all datasets. We found that although a string graph can make use of
entire reads for resolving repeats, de Bruijn graphs can naturally assemble
through regions that are error-prone due to sequencing bias.
RESULTS: We developed a novel assembler called StriDe that has advantages of both
string and de Bruijn graphs. First, the reads are decomposed adaptively only in
error-prone regions. Second, each paired-end read is extended into a long read
directly using an FM-index. The decomposed and extended reads are used to build
an assembly graph. In addition, several essential components of an assembler were
designed or improved. The resulting assembler was fully parallelized, tested and 
compared with state-of-the-art assemblers using benchmark datasets. The results
indicate that contiguity of StriDe is comparable with top assemblers on both
short-read and long-read datasets, and the assembly accuracy is high in
comparison with the others.
AVAILABILITY AND IMPLEMENTATION: https://github.com/ythuang0522/StriDe
CONTACT: : ythuang@cs.ccu.edu.tw
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw011 
PMID: 26755626  [PubMed - in process]


690. Bioinformatics. 2016 May 1;32(9):1395-401. doi: 10.1093/bioinformatics/btw013.
Epub 2016 Jan 10.

Collaborative analysis of multi-gigapixel imaging data using Cytomine.

Marée R(1), Rollus L(2), Stévens B(2), Hoyoux R(2), Louppe G(2), Vandaele R(2),
Begon JM(2), Kainz P(3), Geurts P(2), Wehenkel L(2).

Author information: 
(1)Systems and Modeling, Department of Electrical Engineering and Computer
Science and GIGA-Research, University of Liège, Liège, Belgium Bioimage Analysis 
Unit, Institut Pasteur, Paris, France. (2)Systems and Modeling, Department of
Electrical Engineering and Computer Science and GIGA-Research, University of
Liège, Liège, Belgium. (3)Institute of Biophysics, Medical University of Graz,
Graz, Austria.

MOTIVATION: Collaborative analysis of massive imaging datasets is essential to
enable scientific discoveries.
RESULTS: We developed Cytomine to foster active and distributed collaboration of 
multidisciplinary teams for large-scale image-based studies. It uses web
development methodologies and machine learning in order to readily organize,
explore, share and analyze (semantically and quantitatively) multi-gigapixel
imaging data over the internet. We illustrate how it has been used in several
biomedical applications.
AVAILABILITY AND IMPLEMENTATION: Cytomine (http://www.cytomine.be/) is freely
available under an open-source license from http://github.com/cytomine/ A
documentation wiki (http://doc.cytomine.be) and a demo server
(http://demo.cytomine.be) are also available.
CONTACT: info@cytomine.be
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw013 
PMCID: PMC4848407
PMID: 26755625  [PubMed - in process]


691. Sci Rep. 2016 Jan 12;6:19119. doi: 10.1038/srep19119.

Systematic Analysis of Sex-Linked Molecular Alterations and Therapies in Cancer.

Ma J(1,)(2), Malladi S(1,)(2), Beck AH(2).

Author information: 
(1)The Harker School, CA 95128. (2)Department of Pathology, Beth Israel Deaconess
Medical Center and Harvard Medical School, MA.

Though patient sex influences response to cancer treatments, little is known of
the molecular causes, and cancer therapies are generally given irrespective of
patient sex. We assessed transcriptomic differences in tumors from men and women 
spanning 17 cancer types, and we assessed differential expression between tumor
and normal samples stratified by sex across 7 cancers. We used the LincsCloud
platform to perform Connectivity Map analyses to link transcriptomic signatures
identified in male and female tumors with chemical and genetic perturbagens, and 
we performed permutation testing to identify perturbagens that showed
significantly differential connectivity with male and female tumors. Our analyses
predicted that females are sensitive and males are resistant to tamoxifen
treatment of lung adenocarcinoma, a finding which is consistent with known
male-female differences in lung cancer. We made several novel predictions,
including that CDK1 and PTPN1 knockdown would be more effective in males with
hepatocellular carcinoma, and SMAD3 and HSPA4 knockdown would be more effective
in females with head and neck squamous cell carcinoma. Our results provide a new 
resource for researchers studying male-female biological and treatment response
differences in human cancer. The complete results of our analyses are provided at
the website accompanying this manuscript (http://becklab.github.io/SexLinked).

DOI: 10.1038/srep19119 
PMCID: PMC4709570
PMID: 26755347  [PubMed - indexed for MEDLINE]


692. BMC Bioinformatics. 2016 Jan 12;17:25. doi: 10.1186/s12859-015-0862-z.

BayesFlow: latent modeling of flow cytometry cell populations.

Johnsson K(1), Wallin J(2), Fontes M(3,)(4).

Author information: 
(1)Centre for Mathematical Sciences, Lund University, Box 118, Lund, S-221 00,
Sweden. johnsson@maths.lth.se. (2)Mathematical Sciences, Chalmers and University 
of Gothenburg, Gothenburg, S-412 58, Sweden. jonwal@chalmers.se. (3)Centre for
Mathematical Sciences, Lund University, Box 118, Lund, S-221 00, Sweden.
fontes@maths.lth.se. (4)International Group for Data Analysis, Institut Pasteur, 
25 Rue du Docteur Roux, Paris, 75015, France. fontes@maths.lth.se.

Erratum in
    BMC Bioinformatics. 2016;17:149.

BACKGROUND: Flow cytometry is a widespread single-cell measurement technology
with a multitude of clinical and research applications. Interpretation of flow
cytometry data is hard; the instrumentation is delicate and can not render
absolute measurements, hence samples can only be interpreted in relation to each 
other while at the same time comparisons are confounded by inter-sample
variation. Despite this, most automated flow cytometry data analysis methods
either treat samples individually or ignore the variation by for example pooling 
the data. A key requirement for models that include multiple samples is the
ability to visualize and assess inferred variation, since what could be technical
variation in one setting would be different phenotypes in another.
RESULTS: We introduce BayesFlow, a pipeline for latent modeling of flow cytometry
cell populations built upon a Bayesian hierarchical model. The model systematizes
variation in location as well as shape. Expert knowledge can be incorporated
through informative priors and the results can be supervised through compact and 
comprehensive visualizations. BayesFlow is applied to two synthetic and two real 
flow cytometry data sets. For the first real data set, taken from the FlowCAP I
challenge, BayesFlow does not only give a gating which would place it among the
top performers in FlowCAP I for this dataset, it also gives a more consistent
treatment of different samples than either manual gating or other automated
gating methods. The second real data set contains replicated flow cytometry
measurements of samples from healthy individuals. BayesFlow gives here cell
populations with clear expression patterns and small technical intra-donor
variation as compared to biological inter-donor variation.
CONCLUSIONS: Modeling latent relations between samples through BayesFlow enables 
a systematic analysis of inter-sample variation. As opposed to other joint gating
methods, effort is put at ensuring that the obtained partition of the data
corresponds to actual cell populations, and the result is therefore directly
biologically interpretable. BayesFlow is freely available at GitHub.

DOI: 10.1186/s12859-015-0862-z 
PMCID: PMC4709953
PMID: 26755197  [PubMed - indexed for MEDLINE]


693. BMC Bioinformatics. 2016 Jan 12;17:29. doi: 10.1186/s12859-016-0879-y.

GBS-SNP-CROP: a reference-optional pipeline for SNP discovery and plant germplasm
characterization using variable length, paired-end genotyping-by-sequencing data.

Melo AT(1), Bartaula R(2), Hale I(3).

Author information: 
(1)College of Life Sciences and Agriculture, Department of Biological Sciences,
University of New Hampshire, Durham, NH, USA. (2)College of Life Sciences and
Agriculture, Genetics Graduate Program, University of New Hampshire, Durham, NH, 
USA. (3)College of Life Sciences and Agriculture, Department of Biological
Sciences, University of New Hampshire, Durham, NH, USA. iago.hale@unh.edu.

BACKGROUND: With its simple library preparation and robust approach to genome
reduction, genotyping-by-sequencing (GBS) is a flexible and cost-effective
strategy for SNP discovery and genotyping, provided an appropriate reference
genome is available. For resource-limited curation, research, and breeding
programs of underutilized plant genetic resources, however, even low-depth
references may not be within reach, despite declining sequencing costs. Such
programs would find value in an open-source bioinformatics pipeline that can
maximize GBS data usage and perform high-density SNP genotyping in the absence of
a reference.
RESULTS: The GBS SNP-Calling Reference Optional Pipeline (GBS-SNP-CROP) developed
and presented here adopts a clustering strategy to build a population-tailored
"Mock Reference" from the same GBS data used for downstream SNP calling and
genotyping. Designed for libraries of paired-end (PE) reads, GBS-SNP-CROP
maximizes data usage by eliminating unnecessary data culling due to imposed
read-length uniformity requirements. Using 150 bp PE reads from a GBS library of 
48 accessions of tetraploid kiwiberry (Actinidia arguta), GBS-SNP-CROP yielded on
average three times as many SNPs as TASSEL-GBS analyses (32 and 64 bp tag
lengths) and over 18 times as many as TASSEL-UNEAK, with fewer genotyping errors 
in all cases, as evidenced by comparing the genotypic characterizations of
biological replicates. Using the published reference genome of a related diploid 
species (A. chinensis), the reference-based version of GBS-SNP-CROP behaved
similarly to TASSEL-GBS in terms of the number of SNPs called but had an improved
read depth distribution and fewer genotyping errors. Our results also indicate
that the sets of SNPs detected by the different pipelines above are largely
orthogonal to one another; thus GBS-SNP-CROP may be used to augment the results
of alternative analyses, whether or not a reference is available.
CONCLUSIONS: By achieving high-density SNP genotyping in populations for which no
reference genome is available, GBS-SNP-CROP is worth consideration by curators,
researchers, and breeders of under-researched plant genetic resources. In cases
where a reference is available, especially if from a related species or when the 
target population is particularly diverse, GBS-SNP-CROP may complement other
reference-based pipelines by extracting more information per sequencing dollar
spent. The current version of GBS-SNP-CROP is available at
https://github.com/halelab/GBS-SNP-CROP.git.

DOI: 10.1186/s12859-016-0879-y 
PMCID: PMC4709900
PMID: 26754002  [PubMed - indexed for MEDLINE]


694. PLoS Comput Biol. 2016 Jan 11;12(1):e1004409. doi: 10.1371/journal.pcbi.1004409. 
eCollection 2016.

Consistency of VDJ Rearrangement and Substitution Parameters Enables Accurate B
Cell Receptor Sequence Annotation.

Ralph DK(1), Matsen FA 4th(1).

Author information: 
(1)Fred Hutchinson Cancer Research Center, Seattle, Washington, United States of 
America.

VDJ rearrangement and somatic hypermutation work together to produce
antibody-coding B cell receptor (BCR) sequences for a remarkable diversity of
antigens. It is now possible to sequence these BCRs in high throughput; analysis 
of these sequences is bringing new insight into how antibodies develop, in
particular for broadly-neutralizing antibodies against HIV and influenza. A
fundamental step in such sequence analysis is to annotate each base as coming
from a specific one of the V, D, or J genes, or from an N-addition (a.k.a.
non-templated insertion). Previous work has used simple parametric distributions 
to model transitions from state to state in a hidden Markov model (HMM) of VDJ
recombination, and assumed that mutations occur via the same process across
sites. However, codon frame and other effects have been observed to violate these
parametric assumptions for such coding sequences, suggesting that a
non-parametric approach to modeling the recombination process could be useful. In
our paper, we find that indeed large modern data sets suggest a model using
parameter-rich per-allele categorical distributions for HMM transition
probabilities and per-allele-per-position mutation probabilities, and that using 
such a model for inference leads to significantly improved results. We present an
accurate and efficient BCR sequence annotation software package using a novel HMM
"factorization" strategy. This package, called partis
(https://github.com/psathyrella/partis/), is built on a new general-purpose HMM
compiler that can perform efficient inference given a simple text description of 
an HMM.

DOI: 10.1371/journal.pcbi.1004409 
PMCID: PMC4709141
PMID: 26751373  [PubMed - indexed for MEDLINE]


695. Bioinformatics. 2016 May 1;32(9):1281-5. doi: 10.1093/bioinformatics/btw005. Epub
2016 Jan 6.

Estimating the number and assignment of clock models in analyses of multigene
datasets.

Duchêne S(1), Foster CS(2), Ho SY(2).

Author information: 
(1)School of Life and Environmental Sciences Sydney Medical School, University of
Sydney, Sydney, NSW 2006, Australia. (2)School of Life and Environmental
Sciences.

MOTIVATION: Molecular-clock methods can be used to estimate evolutionary rates
and timescales from DNA sequence data. However, different genes can display
different patterns of rate variation across lineages, calling for the employment 
of multiple clock models. Selecting the optimal clock-partitioning scheme for a
multigene dataset can be computationally demanding, but clustering methods
provide a feasible alternative. We investigated the performance of different
clustering methods using data from chloroplast genomes and data generated by
simulation.
RESULTS: Our results show that mixture models provide a useful alternative to
traditional partitioning algorithms. We found only a small number of distinct
patterns of among-lineage rate variation among chloroplast genes, which were
consistent across taxonomic scales. This suggests that the evolution of
chloroplast genes has been governed by a small number of genomic pacemakers. Our 
study also demonstrates that clustering methods provide an efficient means of
identifying clock-partitioning schemes for genome-scale datasets.
AVAILABILITY AND IMPLEMENTATION: The code and data sets used in this study are
available online at
https://github.com/sebastianduchene/pacemaker_clustering_methods
CONTACT: sebastian.duchene@sydney.edu.au
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw005 
PMID: 26743512  [PubMed - in process]


696. Bioinformatics. 2016 May 1;32(9):1323-30. doi: 10.1093/bioinformatics/btw006.
Epub 2016 Jan 6.

MMseqs software suite for fast and deep clustering and searching of large protein
sequence sets.

Hauser M(1), Steinegger M(2), Söding J(3).

Author information: 
(1)Gene Center, Ludwig-Maximilians-Universität München, Munich 81377, Germany.
(2)Gene Center, Ludwig-Maximilians-Universität München, Munich 81377, Germany,
Computational Biology, Max Planck Institute for Biophysical Chemistry, Göttingen 
37077, Germany and TUM, Department of Informatics, Bioinformatics & Computational
Biology-I12, Garching 85748, Germany. (3)Gene Center,
Ludwig-Maximilians-Universität München, Munich 81377, Germany, Computational
Biology, Max Planck Institute for Biophysical Chemistry, Göttingen 37077, Germany
and.

MOTIVATION: Sequence databases are growing fast, challenging existing analysis
pipelines. Reducing the redundancy of sequence databases by similarity clustering
improves speed and sensitivity of iterative searches. But existing tools cannot
efficiently cluster databases of the size of UniProt to 50% maximum pairwise
sequence identity or below. Furthermore, in metagenomics experiments typically
large fractions of reads cannot be matched to any known sequence anymore because 
searching with sensitive but relatively slow tools (e.g. BLAST or HMMER3) through
comprehensive databases such as UniProt is becoming too costly.
RESULTS: MMseqs (Many-against-Many sequence searching) is a software suite for
fast and deep clustering and searching of large datasets, such as UniProt, or
6-frame translated metagenomics sequencing reads. MMseqs contains three core
modules: a fast and sensitive prefiltering module that sums up the scores of
similar k-mers between query and target sequences, an SSE2- and
multi-core-parallelized local alignment module, and a clustering module.In our
homology detection benchmarks, MMseqs is much more sensitive and 4-30 times
faster than UBLAST and RAPsearch, respectively, although it does not reach BLAST 
sensitivity yet. Using its cascaded clustering workflow, MMseqs can cluster large
databases down to ∼30% sequence identity at hundreds of times the speed of
BLASTclust and much deeper than CD-HIT and USEARCH. MMseqs can also update a
database clustering in linear instead of quadratic time. Its much improved
sensitivity-speed trade-off should make MMseqs attractive for a wide range of
large-scale sequence analysis tasks.
AVAILABILITY AND IMPLEMENTATION: MMseqs is open-source software available under
GPL at https://github.com/soedinglab/MMseqs
CONTACT: martin.steinegger@mpibpc.mpg.de, soeding@mpibpc.mpg.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btw006 
PMID: 26743509  [PubMed - in process]


697. Bioinformatics. 2016 May 1;32(9):1408-10. doi: 10.1093/bioinformatics/btw004.
Epub 2016 Jan 6.

OEFinder: a user interface to identify and visualize ordering effects in
single-cell RNA-seq data.

Leng N(1), Choi J(2), Chu LF(1), Thomson JA(1), Kendziorski C(3), Stewart R(1).

Author information: 
(1)Morgridge Institute for Research. (2)Department of Statistics, University of
Wisconsin and. (3)Department of Biostatistics and Medical Informatics, University
of Wisconsin, Madison, WI, USA.

A recent article identified an artifact in multiple single-cell RNA-seq
(scRNA-seq) datasets generated by the Fluidigm C1 platform. Specifically, Leng et
al. showed significantly increased gene expression in cells captured from sites
with small or large plate output IDs. We refer to this artifact as an ordering
effect (OE). Including OE genes in downstream analyses could lead to biased
results. To address this problem, we developed a statistical method and software 
called OEFinder to identify a sorted list of OE genes. OEFinder is available as
an R package along with user-friendly graphical interface implementations which
allows users to check for potential artifacts in scRNA-seq data generated by the 
Fluidigm C1 platform.AVAILABILITY AND IMPLEMENTATION: OEFinder is freely
available at https://github.com/lengning/OEFinder
CONTACT: rstewart@morgridge.org or lengning1@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btw004 
PMCID: PMC4848403
PMID: 26743507  [PubMed - in process]


698. Bioinformatics. 2016 Apr 1;32(7):984-92. doi: 10.1093/bioinformatics/btv751. Epub
2016 Jan 6.

SV-Bay: structural variant detection in cancer genomes using a Bayesian approach 
with correction for GC-content and read mappability.

Iakovishina D(1), Janoueix-Lerosey I(2), Barillot E(3), Regnier M(1), Boeva V(3).

Author information: 
(1)INRIA Projet AMIB, Ecole Polytechnique, Palaiseau, France. (2)Institut Curie, 
Centre De Recherche, Paris Inserm, U830, Department Genetics and Biology of
Cancers, Paris, France. (3)Institut Curie, Centre De Recherche, Paris Inserm,
Department of Bioinformatics, Biostatistics, Epidemiology and Computational
Systems Biology of Cancer, U900, Paris, France Mines ParisTech, Centre for
Computational Biology, Fontainebleau, France PSL Research University, Paris,
France.

MOTIVATION: Whole genome sequencing of paired-end reads can be applied to
characterize the landscape of large somatic rearrangements of cancer genomes.
Several methods for detecting structural variants with whole genome sequencing
data have been developed. So far, none of these methods has combined information 
about abnormally mapped read pairs connecting rearranged regions and associated
global copy number changes automatically inferred from the same sequencing data
file. Our aim was to create a computational method that could use both types of
information, i.e. normal and abnormal reads, and demonstrate that by doing so we 
can highly improve both sensitivity and specificity rates of structural variant
prediction.
RESULTS: We developed a computational method, SV-Bay, to detect structural
variants from whole genome sequencing mate-pair or paired-end data using a
probabilistic Bayesian approach. This approach takes into account depth of
coverage by normal reads and abnormalities in read pair mappings. To estimate the
model likelihood, SV-Bay considers GC-content and read mappability of the genome,
thus making important corrections to the expected read count. For the detection
of somatic variants, SV-Bay makes use of a matched normal sample when it is
available. We validated SV-Bay on simulated datasets and an experimental
mate-pair dataset for the CLB-GA neuroblastoma cell line. The comparison of
SV-Bay with several other methods for structural variant detection demonstrated
that SV-Bay has better prediction accuracy both in terms of sensitivity and
false-positive detection rate.
AVAILABILITY AND IMPLEMENTATION: https://github.com/InstitutCurie/SV-Bay
CONTACT: valentina.boeva@inserm.fr
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv751 
PMCID: PMC4896370
PMID: 26740523  [PubMed - in process]


699. Sci Rep. 2016 Jan 7;6:18854. doi: 10.1038/srep18854.

GeNN: a code generation framework for accelerated brain simulations.

Yavuz E(1), Turner J(1), Nowotny T(1).

Author information: 
(1)Centre for Computational Neuroscience and Robotics, School of Engineering and 
Informatics, University of Sussex, Brighton, BN1 9QJ, UK.

Large-scale numerical simulations of detailed brain circuit models are important 
for identifying hypotheses on brain functions and testing their consistency and
plausibility. An ongoing challenge for simulating realistic models is, however,
computational speed. In this paper, we present the GeNN (GPU-enhanced Neuronal
Networks) framework, which aims to facilitate the use of graphics accelerators
for computational models of large-scale neuronal networks to address this
challenge. GeNN is an open source library that generates code to accelerate the
execution of network simulations on NVIDIA GPUs, through a flexible and
extensible interface, which does not require in-depth technical knowledge from
the users. We present performance benchmarks showing that 200-fold speedup
compared to a single core of a CPU can be achieved for a network of one million
conductance based Hodgkin-Huxley neurons but that for other models the speedup
can differ. GeNN is available for Linux, Mac OS X and Windows platforms. The
source code, user manual, tutorials, Wiki, in-depth example projects and all
other related information can be found on the project website
http://genn-team.github.io/genn/.

DOI: 10.1038/srep18854 
PMCID: PMC4703976
PMID: 26740369  [PubMed - indexed for MEDLINE]


700. Bioinformatics. 2016 May 1;32(9):1331-7. doi: 10.1093/bioinformatics/btv768. Epub
2016 Jan 5.

Prediction of missing sequences and branch lengths in phylogenomic data.

Darriba D(1), Weiß M(2), Stamatakis A(3).

Author information: 
(1)Scientific Computing Group, Heidelberg Institute for Theoretical Studies,
Schloss-Wolfsbrunnenweg 35, Heidelberg 69118, Germany. (2)Department of Biology, 
University of Tübingen, Auf Der Morgenstelle 1, Tübingen 72076, Germany,
Steinbeis Innovation Center, Organismal Mycology and Microbiology, Vor dem
Kreuzberg 17, 72070 Tübingen, Germany and. (3)Scientific Computing Group,
Heidelberg Institute for Theoretical Studies, Schloss-Wolfsbrunnenweg 35,
Heidelberg 69118, Germany, Institute of Theoretical Informatics, Karlsruhe
Institute of Technology, Karlsruhe 76131, Germany.

MOTIVATION: The presence of missing data in large-scale phylogenomic datasets has
negative effects on the phylogenetic inference process. One effect that is caused
by alignments with missing per-gene or per-partition sequences is that the
inferred phylogenies may exhibit extremely long branch lengths. We investigate if
statistically predicting missing sequences for organisms by using information
from genes/partitions that have data for these organisms alleviates the problem
and improves phylogenetic accuracy.
RESULTS: We present several algorithms for correcting excessively long branch
lengths induced by missing data. We also present methods for predicting/imputing 
missing sequence data. We evaluate our algorithms by systematically removing
sequence data from three empirical and 100 simulated alignments. We then compare 
the Maximum Likelihood trees inferred from the gappy alignments and on the
alignments with predicted sequence data to the trees inferred from the original, 
complete datasets. The datasets with predicted sequences showed one to two orders
of magnitude more accurate branch lengths compared to the branch lengths of the
trees inferred from the alignments with missing data. However, prediction did not
affect the RF distances between the trees.
AVAILABILITY AND IMPLEMENTATION: https://github.com/ddarriba/ForeSeqs
CONTACT: : diego.darriba@h-its.org
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv768 
PMID: 26733454  [PubMed - in process]


701. Bioinformatics. 2016 May 1;32(9):1411-3. doi: 10.1093/bioinformatics/btv767. Epub
2016 Jan 5.

ProQ2: estimation of model accuracy implemented in Rosetta.

Uziela K(1), Wallner B(2).

Author information: 
(1)Science for Life Laboratory, Department of Biochemistry and Biophysics,
Stockholm University, Stockholm, Sweden. (2)Division of Bioinformatics,
Department of Physics, Chemistry and Biology, Linköping University, SE-581 83,
Linköping, Sweden and Swedish e-Science Research Center, Linköping, Sweden.

MOTIVATION: Model quality assessment programs are used to predict the quality of 
modeled protein structures. They can be divided into two groups depending on the 
information they are using: ensemble methods using consensus of many alternative 
models and methods only using a single model to do its prediction. The consensus 
methods excel in achieving high correlations between prediction and true quality 
measures. However, they frequently fail to pick out the best possible model, nor 
can they be used to generate and score new structures. Single-model methods on
the other hand do not have these inherent shortcomings and can be used both to
sample new structures and to improve existing consensus methods.
RESULTS: Here, we present an implementation of the ProQ2 program to estimate both
local and global model accuracy as part of the Rosetta modeling suite. The
current implementation does not only make it possible to run large batch runs
locally, but it also opens up a whole new arena for conformational sampling using
machine learned scoring functions and to incorporate model accuracy estimation in
to various existing modeling schemes. ProQ2 participated in CASP11 and results
from CASP11 are used to benchmark the current implementation. Based on results
from CASP11 and CAMEO-QE, a continuous benchmark of quality estimation methods,
it is clear that ProQ2 is the single-model method that performs best in both
local and global model accuracy.
AVAILABILITY AND IMPLEMENTATION: https://github.com/bjornwallner/ProQ_scripts
CONTACT: bjornw@ifm.liu.se
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2016. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv767 
PMCID: PMC4848402
PMID: 26733453  [PubMed - in process]


702. Front Microbiol. 2015 Dec 18;6:1451. doi: 10.3389/fmicb.2015.01451. eCollection
2015.

gbtools: Interactive Visualization of Metagenome Bins in R.

Seah BK(1), Gruber-Vodicka HR(1).

Author information: 
(1)Department of Symbiosis, Max Planck Institute for Marine Microbiology Bremen, 
Germany.

Improvements in DNA sequencing technology have increased the amount and quality
of sequences that can be obtained from metagenomic samples, making it practical
to extract individual microbial genomes from metagenomic assemblies ("binning"). 
However, while many tools and methods exist for unsupervised binning with various
statistical algorithms, there are few options for visualizing the results, even
though visualization is vital to exploratory data analysis. We have developed
gbtools, a software package that allows users to visualize metagenomic assemblies
by plotting coverage (sequencing depth) and GC values of contigs, and also to
annotate the plots with taxonomic information. Different sets of annotations,
including taxonomic assignments from conserved marker genes or SSU rRNA genes,
can be imported simultaneously; users can choose which annotations to plot. Bins 
can be manually defined from plots, or be imported from third-party binning tools
and overlaid onto plots, such that results from different methods can be compared
side-by-side. gbtools reports summary statistics of bins including marker gene
completeness, and allows the user to add or subtract bins with each other. We
illustrate some of the functions available in gbtools with two examples: the
metagenome of Olavius algarvensis, a marine oligochaete worm that has up to five 
bacterial symbionts, and the metagenome of a synthetic mock community comprising 
64 bacterial and archaeal strains. We show how instances of poor automated
binning, sequencer GC% bias, and variation between samples can be quickly
diagnosed by visualization, and demonstrate how the results from different
binning tools can be combined and refined to yield manually curated bins with
higher completeness. gbtools is open-source and written in R. The software
package, documentation, and example data are available freely online at
https://github.com/kbseah/genome-bin-tools.

DOI: 10.3389/fmicb.2015.01451 
PMCID: PMC4683177
PMID: 26732662  [PubMed]


703. Mol Cell Proteomics. 2016 Apr;15(4):1467-78. doi: 10.1074/mcp.O115.055475. Epub
2016 Jan 4.

DeMix-Q: Quantification-Centered Data Processing Workflow.

Zhang B(1), Käll L(2), Zubarev RA(3).

Author information: 
(1)From the ‡ Department of Medical Biochemistry and Biophysics, Karolinska
Institutet, Scheeles väg 2, SE-17177 Solna, Sweden. (2)§ Science for Life
Laboratory, School of Biotechnology, Royal Institute of Technology-KTH, 17165
Solna, Sweden. (3)From the ‡ Department of Medical Biochemistry and Biophysics,
Karolinska Institutet, Scheeles väg 2, SE-17177 Solna, Sweden.
roman.zubarev@ki.se.

For historical reasons, most proteomics workflows focus on MS/MS identification
but consider quantification as the end point of a comparative study. The
stochastic data-dependent MS/MS acquisition (DDA) gives low reproducibility of
peptide identifications from one run to another, which inevitably results in
problems with missing values when quantifying the same peptide across a series of
label-free experiments. However, the signal from the molecular ion is almost
always present among the MS(1)spectra. Contrary to what is frequently claimed,
missing values do not have to be an intrinsic problem of DDA approaches that
perform quantification at the MS(1)level. The challenge is to perform sound
peptide identity propagation across multiple high-resolution LC-MS/MS
experiments, from runs with MS/MS-based identifications to runs where such
information is absent. Here, we present a new analytical workflow DeMix-Q
(https://github.com/userbz/DeMix-Q), which performs such propagation that
recovers missing values reliably by using a novel scoring scheme for quality
control. Compared with traditional workflows for DDA as well as previous DIA
studies, DeMix-Q achieves deeper proteome coverage, fewer missing values, and
lower quantification variance on a benchmark dataset. This
quantification-centered workflow also enables flexible and robust proteome
characterization based on covariation of peptide abundances.

© 2016 by The American Society for Biochemistry and Molecular Biology, Inc.

DOI: 10.1074/mcp.O115.055475 
PMCID: PMC4824868 [Available on 2017-04-01]
PMID: 26729709  [PubMed - indexed for MEDLINE]


704. BMC Bioinformatics. 2016 Jan 5;17:17. doi: 10.1186/s12859-015-0864-x.

ChainRank, a chain prioritisation method for contextualisation of biological
networks.

Tényi Á(1,)(2), de Atauri P(3,)(4), Gomez-Cabrero D(5), Cano I(6,)(7), Clarke
K(8), Falciani F(9), Cascante M(10,)(11), Roca J(12,)(13), Maier D(14).

Author information: 
(1)Hospital Clínic-Institut d'Investigacions Biomediques August Pi i Sunyer
(IDIBAPS), Research Institute, Universitat de Barcelona, C/Villarroel 170, 08036,
Barcelona, Spain. tenyi.akos@ub.edu. (2)Centro de Investigación en Red de
Enfermedades Respiratorias (CibeRes), 07110, Palma de Mallorca, Spain.
tenyi.akos@ub.edu. (3)Hospital Clínic-Institut d'Investigacions Biomediques
August Pi i Sunyer (IDIBAPS), Research Institute, Universitat de Barcelona,
C/Villarroel 170, 08036, Barcelona, Spain. pde_atauri@ub.edu. (4)Departament de
Bioquimica i Biologia Molecular, Facultat de Biologia-IBUB, Universitat de
Barcelona, 08028, Barcelona, Spain. pde_atauri@ub.edu. (5)Unit of computational
Medicine, Center for Molecular Medicine, Department of Medicine, Karolinska
Institute and Karolinska University Hospital, SE-171 76, Stockholm, Sweden.
david.gomezcabrero@ki.se. (6)Hospital Clínic-Institut d'Investigacions
Biomediques August Pi i Sunyer (IDIBAPS), Research Institute, Universitat de
Barcelona, C/Villarroel 170, 08036, Barcelona, Spain. iscano@clinic.ub.es.
(7)Centro de Investigación en Red de Enfermedades Respiratorias (CibeRes), 07110,
Palma de Mallorca, Spain. iscano@clinic.ub.es. (8)Integrative Systems Biology,
University of Liverpool, L69 3BX, Liverpool, UK. kim.clarke@liverpool.ac.uk.
(9)Integrative Systems Biology, University of Liverpool, L69 3BX, Liverpool, UK. 
f.falciani@liverpool.ac.uk. (10)Hospital Clínic-Institut d'Investigacions
Biomediques August Pi i Sunyer (IDIBAPS), Research Institute, Universitat de
Barcelona, C/Villarroel 170, 08036, Barcelona, Spain. martacascante@ub.edu.
(11)Departament de Bioquimica i Biologia Molecular, Facultat de Biologia-IBUB,
Universitat de Barcelona, 08028, Barcelona, Spain. martacascante@ub.edu.
(12)Hospital Clínic-Institut d'Investigacions Biomediques August Pi i Sunyer
(IDIBAPS), Research Institute, Universitat de Barcelona, C/Villarroel 170, 08036,
Barcelona, Spain. jroca@clinic.ub.es. (13)Centro de Investigación en Red de
Enfermedades Respiratorias (CibeRes), 07110, Palma de Mallorca, Spain.
jroca@clinic.ub.es. (14)Biomax Informatics AG, D-82152, Planegg, Germany.
dieter.maier@biomax.com.

BACKGROUND: Advances in high throughput technologies and growth of biomedical
knowledge have contributed to an exponential increase in associative data. These 
data can be represented in the form of complex networks of biological
associations, which are suitable for systems analyses. However, these networks
usually lack both, context specificity in time and space as well as the
distinctive borders, which are usually assigned in the classical pathway view of 
molecular events (e.g. signal transduction). This complexity and high
interconnectedness call for automated techniques that can identify smaller
targeted subnetworks specific to a given research context (e.g. a disease
scenario).
RESULTS: Our method, named ChainRank, finds relevant subnetworks by identifying
and scoring chains of interactions that link specific network components. Scores 
can be generated from integrating multiple general and context specific measures 
(e.g. experimental molecular data from expression to proteomics and metabolomics,
literature evidence, network topology). The performance of the novel ChainRank
method was evaluated on recreating selected signalling pathways from a human
protein interaction network. Specifically, we recreated skeletal muscle specific 
signaling networks in healthy and chronic obstructive pulmonary disease (COPD)
contexts. The analysis showed that ChainRank can identify main mediators of
context specific molecular signalling. An improvement of up to factor 2.5 was
shown in the precision of finding proteins of the recreated pathways compared to 
random simulation.
CONCLUSIONS: ChainRank provides a framework, which can integrate several
user-defined scores and evaluate their combined effect on ranking interaction
chains linking input data sets. It can be used to contextualise networks,
identify signaling and regulatory path amongst targeted genes or to analyse
synthetic lethality in the context of anticancer therapy. ChainRank is
implemented in R programming language and freely available at
https://github.com/atenyi/ChainRank.

DOI: 10.1186/s12859-015-0864-x 
PMCID: PMC4700624
PMID: 26729273  [PubMed - indexed for MEDLINE]


705. Genetics. 2016 Feb;202(2):487-95. doi: 10.1534/genetics.115.182071. Epub 2015 Dec
29.

Imputing Genotypes in Biallelic Populations from Low-Coverage Sequence Data.

Fragoso CA(1), Heffelfinger C(2), Zhao H(3), Dellaporta SL(4).

Author information: 
(1)Program of Computational Biology and Bioinformatics, Yale University, New
Haven, Connecticut 06520 Department of Molecular, Cellular and Developmental
Biology, Yale University, New Haven, Connecticut 06520. (2)Department of
Molecular, Cellular and Developmental Biology, Yale University, New Haven,
Connecticut 06520. (3)Program of Computational Biology and Bioinformatics, Yale
University, New Haven, Connecticut 06520 Department of Biostatistics, Yale School
of Public Health, Yale University, New Haven, Connecticut 06520. (4)Department of
Molecular, Cellular and Developmental Biology, Yale University, New Haven,
Connecticut 06520 stephen.dellaporta@yale.edu.

Low-coverage next-generation sequencing methodologies are routinely employed to
genotype large populations. Missing data in these populations manifest both as
missing markers and markers with incomplete allele recovery. False homozygous
calls at heterozygous sites resulting from incomplete allele recovery confound
many existing imputation algorithms. These types of systematic errors can be
minimized by incorporating depth-of-sequencing read coverage into the imputation 
algorithm. Accordingly, we developed Low-Coverage Biallelic Impute (LB-Impute) to
resolve missing data issues. LB-Impute uses a hidden Markov model that
incorporates marker read coverage to determine variable emission probabilities.
Robust, highly accurate imputation results were reliably obtained with LB-Impute,
even at extremely low (<1×) average per-marker coverage. This finding will have
implications for the design of genotype imputation algorithms in the future.
LB-Impute is publicly available on GitHub at
https://github.com/dellaporta-laboratory/LB-Impute.

Copyright © 2016 by the Genetics Society of America.

DOI: 10.1534/genetics.115.182071 
PMCID: PMC4788230
PMID: 26715670  [PubMed - indexed for MEDLINE]


706. Genome Biol. 2015 Dec 29;16:294. doi: 10.1186/s13059-015-0849-0.

Circlator: automated circularization of genome assemblies using long sequencing
reads.

Hunt M(1), Silva ND(2), Otto TD(2), Parkhill J(2), Keane JA(2), Harris SR(3).

Author information: 
(1)Wellcome Trust Sanger Institute, Wellcome Trust Genome Campus, Cambridge, CB10
1SA, UK. mh12@sanger.ac.uk. (2)Wellcome Trust Sanger Institute, Wellcome Trust
Genome Campus, Cambridge, CB10 1SA, UK. (3)Wellcome Trust Sanger Institute,
Wellcome Trust Genome Campus, Cambridge, CB10 1SA, UK. sh16@sanger.ac.uk.

The assembly of DNA sequence data is undergoing a renaissance thanks to emerging 
technologies capable of producing reads tens of kilobases long. Assembling
complete bacterial and small eukaryotic genomes is now possible, but the final
step of circularizing sequences remains unsolved. Here we present Circlator, the 
first tool to automate assembly circularization and produce accurate linear
representations of circular sequences. Using Pacific Biosciences and Oxford
Nanopore data, Circlator correctly circularized 26 of 27 circularizable
sequences, comprising 11 chromosomes and 12 plasmids from bacteria, the
apicoplast and mitochondrion of Plasmodium falciparum and a human mitochondrion. 
Circlator is available at http://sanger-pathogens.github.io/circlator/ .

DOI: 10.1186/s13059-015-0849-0 
PMCID: PMC4699355
PMID: 26714481  [PubMed - indexed for MEDLINE]


707. PeerJ. 2015 Dec 22;3:e1525. doi: 10.7717/peerj.1525. eCollection 2015.

Identifying communities from multiplex biological networks.

Didier G(1), Brun C(2), Baudot A(1).

Author information: 
(1)Aix Marseille Université, CNRS, Centrale Marseille, I2M UMR 7373 , Marseille ,
France. (2)Aix Marseille Université, Inserm, TAGC UMR_S1090 , Marseille , France 
; CNRS , Marseille , France.

Various biological networks can be constructed, each featuring gene/protein
relationships of different meanings (e.g., protein interactions or gene
co-expression). However, this diversity is classically not considered and the
different interaction categories are usually aggregated in a single network. The 
multiplex framework, where biological relationships are represented by different 
network layers reflecting the various nature of interactions, is expected to
retain more information. Here we assessed aggregation, consensus and
multiplex-modularity approaches to detect communities from multiple network
sources. By simulating random networks, we demonstrated that the
multiplex-modularity method outperforms the aggregation and consensus approaches 
when network layers are incomplete or heterogeneous in density. Application to a 
multiplex biological network containing 4 layers of physical or functional
interactions allowed recovering communities more accurately annotated than their 
aggregated counterparts. Overall, taking into account the multiplexity of
biological networks leads to better-defined functional modules. A user-friendly
graphical software to detect communities from multiplex networks, and
corresponding C source codes, are available at GitHub
(https://github.com/gilles-didier/MolTi).

DOI: 10.7717/peerj.1525 
PMCID: PMC4690346
PMID: 26713261  [PubMed]


708. Leukemia. 2016 May;30(5):1094-102. doi: 10.1038/leu.2015.361. Epub 2015 Dec 29.

Single-cell analysis of targeted transcriptome predicts drug sensitivity of
single cells within human myeloma tumors.

Mitra AK(1), Mukherjee UK(2), Harding T(1), Jang JS(3), Stessman H(1), Li Y(4),
Abyzov A(4), Jen J(3), Kumar S(5), Rajkumar V(5), Van Ness B(1).

Author information: 
(1)Department of Genetics, Cell Biology and Development, University of Minnesota,
Minneapolis, MN, USA. (2)School of Statistics, University of Minnesota,
Minneapolis, MN, USA. (3)Medical Genome Facility Genome Analysis Core, Mayo
Clinic, Rochester, MN, USA. (4)Department of Health Science Research, Mayo
Clinic, Rochester, MN, USA. (5)Division of Hematology, Department of Internal
Medicine, Mayo Clinic, Rochester, MN, USA.

Multiple myeloma (MM) is characterized by significant genetic diversity at
subclonal levels that have a defining role in the heterogeneity of tumor
progression, clinical aggressiveness and drug sensitivity. Although genome
profiling studies have demonstrated heterogeneity in subclonal architecture that 
may ultimately lead to relapse, a gene expression-based prediction program that
can identify, distinguish and quantify drug response in sub-populations within a 
bulk population of myeloma cells is lacking. In this study, we performed targeted
transcriptome analysis on 528 pre-treatment single cells from 11 myeloma cell
lines and 418 single cells from 8 drug-naïve MM patients, followed by intensive
bioinformatics and statistical analysis for prediction of proteasome inhibitor
sensitivity in individual cells. Using our previously reported drug response gene
expression profile signature at the single-cell level, we developed an R
Statistical analysis package available at https://github.com/bvnlabSCATTome,
SCATTome (single-cell analysis of targeted transcriptome), that restructures the 
data obtained from Fluidigm single-cell quantitative real-time-PCR analysis run, 
filters missing data, performs scaling of filtered data, builds classification
models and predicts drug response of individual cells based on targeted
transcriptome using an assortment of machine learning methods. Application of
SCATT should contribute to clinically relevant analysis of intratumor
heterogeneity, and better inform drug choices based on subclonal cellular
responses.

DOI: 10.1038/leu.2015.361 
PMID: 26710886  [PubMed - in process]


709. Bioinformatics. 2016 May 1;32(9):1402-4. doi: 10.1093/bioinformatics/btv718. Epub
2015 Dec 26.

rCGH: a comprehensive array-based genomic profile platform for precision
medicine.

Commo F(1), Guinney J(2), Ferté C(1), Bot B(2), Lefebvre C(3), Soria JC(4), André
F(4).

Author information: 
(1)INSERM U981, Gustave Roussy, University Paris-Sud, Villejuif 94805, France,
Sage Bionetworks, Seattle, WA 98109, USA and. (2)Sage Bionetworks, Seattle, WA
98109, USA and. (3)INSERM U981, Gustave Roussy, University Paris-Sud, Villejuif
94805, France. (4)INSERM U981, Gustave Roussy, University Paris-Sud, Villejuif
94805, France, Department of Medical Oncology, Gustave Roussy, Villejuif 94805,
France.

We present rCGH, a comprehensive array-based comparative genomic hybridization
analysis workflow, integrating computational improvements and functionalities
specifically designed for precision medicine. rCGH supports the major microarray 
platforms, ensures a full traceability and facilitates profiles interpretation
and decision-making through sharable interactive visualizations.AVAILABILITY AND 
IMPLEMENTATION: The rCGH R package is available on bioconductor (under
Artistic-2.0). The aCGH-viewer is available at
https://fredcommo.shinyapps.io/aCGH_viewer, and the application implementation is
freely available for installation at https://github.com/fredcommo/aCGH_viewer
CONTACT: frederic.commo@gustaveroussy.fr
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv718 
PMCID: PMC4848396
PMID: 26708336  [PubMed - in process]


710. Bioinformatics. 2016 Apr 15;32(8):1253-5. doi: 10.1093/bioinformatics/btv739.
Epub 2015 Dec 26.

HitWalker2: visual analytics for precision medicine and beyond.

Bottomly D(1), McWeeney SK(2), Wilmot B(2).

Author information: 
(1)Knight Cancer Institute, Oregon Clinical and Translational Research Institute 
and. (2)Knight Cancer Institute, Oregon Clinical and Translational Research
Institute and Division of Bioinformatics and Computational Biology, Department of
Medical Informatics and Clinical Epidemiology, Oregon Health and Science
University, Portland OR 97239, USA.

The lack of visualization frameworks to guide interpretation and facilitate
discovery is a potential bottleneck for precision medicine, systems genetics and 
other studies. To address this we have developed an interactive, reproducible,
web-based prioritization approach that builds on our earlier work. HitWalker2 is 
highly flexible and can utilize many data types and prioritization methods based 
upon available data and desired questions, allowing it to be utilized in a
diverse range of studies such as cancer, infectious disease and psychiatric
disorders.AVAILABILITY AND IMPLEMENTATION: Source code is freely available at
https://github.com/biodev/HitWalker2 and implemented using Python/Django, Neo4j
and Javascript (D3.js and jQuery). We support major open source browsers (e.g.
Firefox and Chromium/Chrome).
CONTACT: wilmotb@ohsu.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online. Additional information/instructions are available at
https://github.com/biodev/HitWalker2/wiki.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv739 
PMCID: PMC4824131
PMID: 26708334  [PubMed - in process]


711. Nucleic Acids Res. 2016 Jan 4;44(D1):D710-6. doi: 10.1093/nar/gkv1157. Epub 2015 
Dec 19.

Ensembl 2016.

Yates A(1), Akanni W(1), Amode MR(1), Barrell D(2), Billis K(1), Carvalho-Silva
D(1), Cummins C(1), Clapham P(3), Fitzgerald S(1), Gil L(1), Girón CG(1), Gordon 
L(1), Hourlier T(1), Hunt SE(1), Janacek SH(1), Johnson N(1), Juettemann T(1),
Keenan S(1), Lavidas I(1), Martin FJ(1), Maurel T(1), McLaren W(1), Murphy DN(1),
Nag R(1), Nuhn M(1), Parker A(1), Patricio M(1), Pignatelli M(1), Rahtz M(3),
Riat HS(1), Sheppard D(1), Taylor K(1), Thormann A(1), Vullo A(1), Wilder SP(1), 
Zadissa A(1), Birney E(1), Harrow J(3), Muffato M(1), Perry E(1), Ruffier M(1),
Spudich G(1), Trevanion SJ(1), Cunningham F(1), Aken BL(1), Zerbino DR(1), Flicek
P(4).

Author information: 
(1)European Molecular Biology Laboratory, European Bioinformatics Institute,
Wellcome Genome Campus, Hinxton, Cambridge CB10 1SD, UK. (2)European Molecular
Biology Laboratory, European Bioinformatics Institute, Wellcome Genome Campus,
Hinxton, Cambridge CB10 1SD, UK Wellcome Trust Sanger Institute, Wellcome Genome 
Campus, Hinxton, Cambridge, CB10 1SA, UK. (3)Wellcome Trust Sanger Institute,
Wellcome Genome Campus, Hinxton, Cambridge, CB10 1SA, UK. (4)European Molecular
Biology Laboratory, European Bioinformatics Institute, Wellcome Genome Campus,
Hinxton, Cambridge CB10 1SD, UK Wellcome Trust Sanger Institute, Wellcome Genome 
Campus, Hinxton, Cambridge, CB10 1SA, UK flicek@ebi.ac.uk.

The Ensembl project (http://www.ensembl.org) is a system for genome annotation,
analysis, storage and dissemination designed to facilitate the access of genomic 
annotation from chordates and key model organisms. It provides access to data
from 87 species across our main and early access Pre! websites. This year we
introduced three newly annotated species and released numerous updates across our
supported species with a concentration on data for the latest genome assemblies
of human, mouse, zebrafish and rat. We also provided two data updates for the
previous human assembly, GRCh37, through a dedicated website
(http://grch37.ensembl.org). Our tools, in particular the VEP, have been improved
significantly through integration of additional third party data. REST is now
capable of larger-scale analysis and our regulatory data BioMart can deliver
faster results. The website is now capable of displaying long-range interactions 
such as those found in cis-regulated datasets. Finally we have launched a website
optimized for mobile devices providing views of genes, variants and phenotypes.
Our data is made available without restriction and all code is available from our
GitHub organization site (http://github.com/Ensembl) under an Apache 2.0 license.

© The Author(s) 2015. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkv1157 
PMCID: PMC4702834
PMID: 26687719  [PubMed - indexed for MEDLINE]


712. Bioinformatics. 2016 Apr 15;32(8):1121-9. doi: 10.1093/bioinformatics/btv736.
Epub 2015 Dec 17.

Hierarchical block matrices as efficient representations of chromosome topologies
and their application for 3C data integration.

Shavit Y(1), Walker BJ(2), Lio' P(1).

Author information: 
(1)Computer Laboratory, University of Cambridge, Cambridge CB3 0FD, UK.
(2)University of Cambridge, Cambridge CB3 0FD, UK and Department of Life
Sciences, Imperial College London, London SW7 2AZ, UK.

MOTIVATION: Recent advancements in molecular methods have made it possible to
capture physical contacts between multiple chromatin fragments. The resulting
association matrices provide a noisy estimate for average spatial proximity that 
can be used to gain insights into the genome organization inside the nucleus.
However, extracting topological information from these data is challenging and
their integration across resolutions is still poorly addressed. Recent findings
suggest that a hierarchical approach could be advantageous for addressing these
challenges.
RESULTS: We present an algorithmic framework, which is based on hierarchical
block matrices (HBMs), for topological analysis and integration of chromosome
conformation capture (3C) data. We first describe chromoHBM, an algorithm that
compresses high-throughput 3C (HiT-3C) data into topological features that are
efficiently summarized with an HBM representation. We suggest that instead of
directly combining HiT-3C datasets across resolutions, which is a difficult task,
we can integrate their HBM representations, and describe chromoHBM-3C, an
algorithm which merges HBMs. Since three-dimensional (3D) reconstruction can also
benefit from topological information, we further present chromoHBM-3D, an
algorithm which exploits the HBM representation in order to gradually introduce
topological constraints to the reconstruction process. We evaluate our approach
in light of previous image microscopy findings and epigenetic data, and show that
it can relate multiple spatial scales and provide a more complete view of the 3D 
genome architecture.
AVAILABILITY AND IMPLEMENTATION: The presented algorithms are available from:
https://github.com/yolish/hbm
CONTACT: ys388@cam.ac.uk or pl219@cam.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv736 
PMID: 26685310  [PubMed - in process]


713. Bioinformatics. 2016 Apr 15;32(8):1269-71. doi: 10.1093/bioinformatics/btv745.
Epub 2015 Dec 17.

MSAcquisitionSimulator: data-dependent acquisition simulator for LC-MS shotgun
proteomics.

Goldfarb D(1), Wang W(2), Major MB(3).

Author information: 
(1)Department of Computer Science, University of North Carolina at Chapel Hill,
Chapel Hill, NC, USA. (2)Department of Computer Science, University of
California, Los Angeles, CA, USA and. (3)Department of Computer Science,
University of North Carolina at Chapel Hill, Chapel Hill, NC, USA, Department of 
Cell Biology and Physiology, Lineberger Comprehensive Cancer Center, University
of North Carolina at Chapel Hill, Chapel Hill, NC, USA.

Data-dependent acquisition (DDA) is the most common method used to control the
acquisition process of shotgun proteomics experiments. While novel DDA approaches
have been proposed, their evaluation is made difficult by the need of
programmatic control of a mass spectrometer. An alternative is in silico
analysis, for which suitable software has been unavailable. To meet this need, we
have developed MSAcquisitionSimulator-a collection of C ++ programs for
simulating ground truth LC-MS data and the subsequent application of custom DDA
algorithms. It provides an opportunity for researchers to test, refine and
evaluate novel DDA algorithms prior to implementation on a mass
spectrometer.AVAILABILITY AND IMPLEMENTATION: The software is freely available
from its Github repository
http://www.github.com/DennisGoldfarb/MSAcquisitionSimulator/ which contains
further documentation and usage instructions.
CONTACT: weiwang@cs.ucla.edu or ben_major@med.unc.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv745 
PMCID: PMC4894284 [Available on 2017-04-15]
PMID: 26685308  [PubMed - in process]


714. G3 (Bethesda). 2015 Dec 18;6(2):281-6. doi: 10.1534/g3.115.023739.

argyle: An R Package for Analysis of Illumina Genotyping Arrays.

Morgan AP(1).

Author information: 
(1)Department of Genetics, University of North Carolina, Chapel Hill, North
Carolina 27599-7264 apm@email.unc.edu.

Genotyping microarrays are an important and widely-used tool in genetics. I
present argyle, an R package for analysis of genotyping array data tailored to
Illumina arrays. The goal of the argyle package is to provide simple, expressive 
tools for nonexpert users to perform quality checks and exploratory analyses of
genotyping data. To these ends, the package consists of a suite of
quality-control functions, normalization procedures, and utilities for visually
and statistically summarizing such data. Format-conversion tools allow
interoperability with popular software packages for analysis of genetic data
including PLINK, R/qtl and DOQTL. Detailed vignettes demonstrating common use
cases are included as supporting information. argyle bridges the gap between the 
low-level tasks of quality control and high-level tasks of genetic analysis. It
is freely available at https://github.com/andrewparkermorgan/argyle and has been 
submitted to Bioconductor.

Copyright © 2016 Morgan.

DOI: 10.1534/g3.115.023739 
PMCID: PMC4751548
PMID: 26684930  [PubMed - indexed for MEDLINE]


715. BMC Genomics. 2015;16 Suppl 12:S11. doi: 10.1186/1471-2164-16-S12-S11. Epub 2015 
Dec 9.

MethGo: a comprehensive tool for analyzing whole-genome bisulfite sequencing
data.

Liao WW, Yen MR, Ju E, Hsu FM, Lam L, Chen PY.

BACKGROUND: DNA methylation is a major epigenetic modification regulating several
biological processes. A standard approach to measure DNA methylation is bisulfite
sequencing (BS-Seq). BS-Seq couples bisulfite conversion of DNA with
next-generation sequencing to profile genome-wide DNA methylation at single base 
resolution. The analysis of BS-Seq data involves the use of customized aligners
for mapping bisulfite converted reads and the bioinformatic pipelines for
downstream data analysis.
RESULTS: Here we developed MethGo, a software tool designed for the analysis of
data from whole-genome bisulfite sequencing (WGBS) and reduced representation
bisulfite sequencing (RRBS). MethGo provides both genomic and epigenomic analyses
including: 1) coverage distribution of each cytosine; 2) global cytosine
methylation level; 3) cytosine methylation level distribution; 4) cytosine
methylation level of genomic elements; 5) chromosome-wide cytosine methylation
level distribution; 6) Gene-centric cytosine methylation level; 7) cytosine
methylation levels at transcription factor binding sites (TFBSs); 8) single
nucleotide polymorphism (SNP) calling, and 9) copy number variation (CNV)
calling.
CONCLUSIONS: MethGo is a simple and effective tool for the analysis of BS-Seq
data including both WGBS and RRBS. It contains 9 analyses in 5 major modules to
profile (epi)genome. It profiles genome-wide DNA methylation in global and in
gene level scale. It can also analyze the methylation pattern around the
transcription factor binding sites, and assess genetic variations such as SNPs
and CNVs. MethGo is coded in Python and is publically available at
http://paoyangchen-laboratory.github.io/methgo/.

DOI: 10.1186/1471-2164-16-S12-S11 
PMCID: PMC4682368
PMID: 26680022  [PubMed - indexed for MEDLINE]


716. BMC Syst Biol. 2015;9 Suppl 6:S5. doi: 10.1186/1752-0509-9-S6-S5. Epub 2015 Dec
9.

Constructing a molecular interaction network for thyroid cancer via large-scale
text mining of gene and pathway events.

Wu C, Schwartz JM, Brabant G, Peng SL, Nenadic G.

BACKGROUND: Biomedical studies need assistance from automated tools and easily
accessible data to address the problem of the rapidly accumulating literature.
Text-mining tools and curated databases have been developed to address such needs
and they can be applied to improve the understanding of molecular pathogenesis of
complex diseases like thyroid cancer.
RESULTS: We have developed a system, PWTEES, which extracts pathway interactions 
from the literature utilizing an existing event extraction tool (TEES) and
pathway named entity recognition (PathNER). We then applied the system on a
thyroid cancer corpus and systematically extracted molecular interactions
involving either genes or pathways. With the extracted information, we
constructed a molecular interaction network taking genes and pathways as nodes.
Using curated pathway information and network topological analyses, we highlight 
key genes and pathways involved in thyroid carcinogenesis.
CONCLUSIONS: Mining events involving genes and pathways from the literature and
integrating curated pathway knowledge can help improve the understanding of
molecular interactions of complex diseases. The system developed for this study
can be applied in studies other than thyroid cancer. The source code is freely
available online at https://github.com/chengkun-wu/PWTEES.

DOI: 10.1186/1752-0509-9-S6-S5 
PMCID: PMC4674859
PMID: 26679379  [PubMed - indexed for MEDLINE]


717. PLoS One. 2015 Dec 17;10(12):e0144820. doi: 10.1371/journal.pone.0144820.
eCollection 2015.

CloudForest: A Scalable and Efficient Random Forest Implementation for Biological
Data.

Bressler R(1), Kreisberg RB(1), Bernard B(1), Niederhuber JE(2), Vockley
JG(2,)(3), Shmulevich I(1), Knijnenburg TA(1).

Author information: 
(1)Institute for Systems Biology, Seattle, WA, United States of America. (2)Inova
Translational Medicine Institute, Inova Health System and Inova Fairfax Medical
Center, Falls Church, VA, United States of America. (3)Virginia Commonwealth
University, School of Medicine, Richmond, VA, United States of America.

Random Forest has become a standard data analysis tool in computational biology. 
However, extensions to existing implementations are often necessary to handle the
complexity of biological datasets and their associated research questions. The
growing size of these datasets requires high performance implementations. We
describe CloudForest, a Random Forest package written in Go, which is
particularly well suited for large, heterogeneous, genetic and biomedical
datasets. CloudForest includes several extensions, such as dealing with
unbalanced classes and missing values. Its flexible design enables users to
easily implement additional extensions. CloudForest achieves fast running times
by effective use of the CPU cache, optimizing for different classes of features
and efficiently multi-threading. https://github.com/ilyalab/CloudForest.

DOI: 10.1371/journal.pone.0144820 
PMCID: PMC4692062
PMID: 26679347  [PubMed - indexed for MEDLINE]


718. BMC Bioinformatics. 2015;16 Suppl 17:S10. doi: 10.1186/1471-2105-16-S17-S10. Epub
2015 Dec 7.

SpliceJumper: a classification-based approach for calling splicing junctions from
RNA-seq data.

Chu C, Li X, Wu Y.

BACKGROUND: Next-generation RNA sequencing technologies have been widely applied 
in transcriptome profiling. This facilitates further studies of gene structure
and expression on the genome wide scale. It is an important step to align reads
to the reference genome and call out splicing junctions for the following
analysis, such as the analysis of alternative splicing and isoform construction. 
However, because of the existence of introns, when RNA-seq reads are aligned to
the reference genome, reads can not be fully mapped at splicing sites. Thus, it
is challenging to align reads and call out splicing junctions accurately.
RESULTS: In this paper, we present a classification based approach for calling
splicing junctions from RNA-seq data, which is implemented in the program
SpliceJumper. SpliceJumper uses a machine learning approach which combines
multiple features extracted from RNA-seq data. We compare SpliceJumper with two
existing RNA-seq analysis approaches, TopHat2 and MapSplice2, on both simulated
and real data. Our results show that SpliceJumper outperforms TopHat2 and
MapSplice2 in accuracy. The program SpliceJumper can be downloaded at
https://github.com/Reedwarbler/SpliceJumper.

DOI: 10.1186/1471-2105-16-S17-S10 
PMCID: PMC4674845
PMID: 26678515  [PubMed - indexed for MEDLINE]


719. BMC Genomics. 2015;16 Suppl 12:S9. doi: 10.1186/1471-2164-16-S12-S9. Epub 2015
Dec 9.

Subset selection of high-depth next generation sequencing reads for de novo
genome assembly using MapReduce framework.

Fang CH, Chang YJ, Chung WC, Hsieh PH, Lin CY, Ho JM.

BACKGROUND: Recent progress in next-generation sequencing technology has afforded
several improvements such as ultra-high throughput at low cost, very high read
quality, and substantially increased sequencing depth. State-of-the-art
high-throughput sequencers, such as the Illumina MiSeq system, can generate ~15
Gbp sequencing data per run, with >80% bases above Q30 and a sequencing depth of 
up to several 1000x for small genomes. Illumina HiSeq 2500 is capable of
generating up to 1 Tbp per run, with >80% bases above Q30 and often >100x
sequencing depth for large genomes. To speed up otherwise time-consuming genome
assembly and/or to obtain a skeleton of the assembly quickly for scaffolding or
progressive assembly, methods for noise removal and reduction of redundancy in
the original data, with almost equal or better assembly results, are worth
studying.
RESULTS: We developed two subset selection methods for single-end reads and a
method for paired-end reads based on base quality scores and other read analytic 
tools using the MapReduce framework. We proposed two strategies to select reads: 
MinimalQ and ProductQ. MinimalQ selects reads with minimal base-quality above a
threshold. ProductQ selects reads with probability of no incorrect base above a
threshold. In the single-end experiments, we used Escherichia coli and Bacillus
cereus datasets of MiSeq, Velvet assembler for genome assembly, and GAGE
benchmark tools for result evaluation. In the paired-end experiments, we used the
giant grouper (Epinephelus lanceolatus) dataset of HiSeq, ALLPATHS-LG genome
assembler, and QUAST quality assessment tool for comparing genome assemblies of
the original set and the subset. The results show that subset selection not only 
can speed up the genome assembly but also can produce substantially longer
scaffolds.
AVAILABILITY: The software is freely available at
https://github.com/moneycat/QReadSelector.

DOI: 10.1186/1471-2164-16-S12-S9 
PMCID: PMC4682372
PMID: 26678408  [PubMed - indexed for MEDLINE]


720. F1000Res. 2015 Aug 5;4:477. doi: 10.12688/f1000research.6773.1. eCollection 2015.

SLiMScape 3.x: a Cytoscape 3 app for discovery of Short Linear Motifs in protein 
interaction networks.

Olorin E(1), O'Brien KT(2), Palopoli N(3), Pérez-Bercoff Å(1), Shields DC(2),
Edwards RJ(4).

Author information: 
(1)School of Biotechnology and Biomolecular Sciences, University of New South
Wales, Sydney, Australia. (2)UCD Conway Institute of Biomolecular and Biomedical 
Research, School of Medicine, University College Dublin, Dublin, Ireland.
(3)Centre for Biological Sciences, University of Southampton, Southampton, UK ;
Departamento de Ciencia y Tecnología, Universidad Nacional de Quilmes, Bernal,
Argentina ; Fundación Instituto Leloir, Buenos Aires, Argentina. (4)School of
Biotechnology and Biomolecular Sciences, University of New South Wales, Sydney,
Australia ; Centre for Biological Sciences, University of Southampton,
Southampton, UK.

Short linear motifs (SLiMs) are small protein sequence patterns that mediate a
large number of critical protein-protein interactions, involved in processes
such as complex formation, signal transduction, localisation and stabilisation.
SLiMs show rapid evolutionary dynamics and are frequently the targets of
molecular mimicry by pathogens. Identifying enriched sequence patterns due to
convergent evolution in non-homologous proteins has proven to be a successful
strategy for computational SLiM prediction. Tools of the SLiMSuite package use
this strategy, using a statistical model to identify SLiM enrichment based on the
evolutionary relationships, amino acid composition and predicted disorder of the 
input proteins. The quality of input data is critical for successful SLiM
prediction. Cytoscape provides a user-friendly, interactive environment to
explore interaction networks and select proteins based on common features, such
as shared interaction partners. SLiMScape embeds tools of the SLiMSuite package
for de novo SLiM discovery (SLiMFinder and QSLiMFinder) and identifying
occurrences/enrichment of known SLiMs (SLiMProb) within this interactive
framework. SLiMScape makes it easier to (1) generate high quality
hypothesis-driven datasets for these tools, and (2) visualise predicted SLiM
occurrences within the context of the network. To generate new predictions, users
can select nodes from a protein network or provide a set of Uniprot identifiers. 
SLiMProb also requires additional query motif input. Jobs are then run remotely
on the SLiMSuite server ( http://rest.slimsuite.unsw.edu.au) for subsequent
retrieval and visualisation. SLiMScape can also be used to retrieve and visualise
results from jobs run directly on the server. SLiMScape and SLiMSuite are open
source and freely available via GitHub under GNU licenses.

DOI: 10.12688/f1000research.6773.1 
PMCID: PMC4670012
PMID: 26674271  [PubMed]


721. Nucleic Acids Res. 2016 Jan 8;44(1):106-16. doi: 10.1093/nar/gkv1461. Epub 2015
Dec 15.

MethylAction: detecting differentially methylated regions that distinguish
biological subtypes.

Bhasin JM(1), Hu B(2), Ting AH(3).

Author information: 
(1)Department of Molecular Medicine, Cleveland Clinic Lerner College of Medicine,
Case Western Reserve University, Cleveland, OH 44195, USA Genomic Medicine
Institute, Lerner Research Institute, Cleveland Clinic, Cleveland, OH 44195, USA.
(2)Quantitative Health Sciences, Lerner Research Institute, Cleveland Clinic,
Cleveland, OH 44195, USA. (3)Department of Molecular Medicine, Cleveland Clinic
Lerner College of Medicine, Case Western Reserve University, Cleveland, OH 44195,
USA Genomic Medicine Institute, Lerner Research Institute, Cleveland Clinic,
Cleveland, OH 44195, USA tinga@ccf.org.

DNA methylation differences capture substantial information about the molecular
and gene-regulatory states among biological subtypes. Enrichment-based next
generation sequencing methods such as MBD-isolated genome sequencing (MiGS) and
MeDIP-seq are appealing for studying DNA methylation genome-wide in order to
distinguish between biological subtypes. However, current analytic tools do not
provide optimal features for analyzing three-group or larger study designs.
MethylAction addresses this need by detecting all possible patterns of
statistically significant hyper- and hypo- methylation in comparisons involving
any number of groups. Crucially, significance is established at the level of
differentially methylated regions (DMRs), and bootstrapping determines false
discovery rates (FDRs) associated with each pattern. We demonstrate this
functionality in a four-group comparison among benign prostate and three clinical
subtypes of prostate cancer and show that the bootstrap FDRs are highly useful in
selecting the most robust patterns of DMRs. Compared to existing tools that are
limited to two-group comparisons, MethylAction detects more DMRs with strong
differential methylation measurements confirmed by whole genome bisulfite
sequencing and offers a better balance between precision and recall in
cross-cohort comparisons. MethylAction is available as an R package at
http://jeffbhasin.github.io/methylaction.

© The Author(s) 2015. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkv1461 
PMCID: PMC4705678
PMID: 26673711  [PubMed - indexed for MEDLINE]


722. Bioinformatics. 2016 Apr 15;32(8):1211-3. doi: 10.1093/bioinformatics/btv735.
Epub 2015 Dec 14.

DNAshapeR: an R/Bioconductor package for DNA shape prediction and feature
encoding.

Chiu TP(1), Comoglio F(2), Zhou T(1), Yang L(1), Paro R(3), Rohs R(1).

Author information: 
(1)Molecular and Computational Biology Program, Departments of Biological
Sciences, Chemistry, Physics, and Computer Science, University of Southern
California, Los Angeles, CA 90089, USA. (2)Department of Biosystems Science and
Engineering, ETH Zürich, Mattenstrasse 26, 4058 Basel, Switzerland and.
(3)Department of Biosystems Science and Engineering, ETH Zürich, Mattenstrasse
26, 4058 Basel, Switzerland and Faculty of Science, University of Basel,
Klingelbergstrasse 50, 4056 Basel, Switzerland.

DNAshapeR predicts DNA shape features in an ultra-fast, high-throughput manner
from genomic sequencing data. The package takes either nucleotide sequence or
genomic coordinates as input and generates various graphical representations for 
visualization and further analysis. DNAshapeR further encodes DNA sequence and
shape features as user-defined combinations of k-mer and DNA shape features. The 
resulting feature matrices can be readily used as input of various machine
learning software packages for further modeling studies.AVAILABILITY AND
IMPLEMENTATION: The DNAshapeR software package was implemented in the statistical
programming language R and is freely available through the Bioconductor project
at https://www.bioconductor.org/packages/devel/bioc/html/DNAshapeR.html and at
the GitHub developer site, http://tsupeichiu.github.io/DNAshapeR/ CONTACT:
rohs@usc.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv735 
PMCID: PMC4824130
PMID: 26668005  [PubMed - in process]


723. Bioinformatics. 2016 Apr 1;32(7):1065-73. doi: 10.1093/bioinformatics/btv734.
Epub 2015 Dec 14.

Positive and negative forms of replicability in gene network analysis.

Verleyen W(1), Ballouz S(1), Gillis J(1).

Author information: 
(1)Stanley Institute for Cognitive Genomics, Cold Spring Harbor Laboratory, 500
Sunnyside Boulevard Woodbury, NY 11797, USA.

MOTIVATION: Gene networks have become a central tool in the analysis of genomic
data but are widely regarded as hard to interpret. This has motivated a great
deal of comparative evaluation and research into best practices. We explore the
possibility that this may lead to overfitting in the field as a whole.
RESULTS: We construct a model of 'research communities' sampling from real gene
network data and machine learning methods to characterize performance trends. Our
analysis reveals an important principle limiting the value of replication, namely
that targeting it directly causes 'easy' or uninformative replication to dominate
analyses. We find that when sampling across network data and algorithms with
similar variability, the relationship between replicability and accuracy is
positive (Spearman's correlation, rs ∼0.33) but where no such constraint is
imposed, the relationship becomes negative for a given gene function (rs ∼
-0.13). We predict factors driving replicability in some prior analyses of gene
networks and show that they are unconnected with the correctness of the original 
result, instead reflecting replicable biases. Without these biases, the original 
results also vanish replicably. We show these effects can occur quite far
upstream in network data and that there is a strong tendency within
protein-protein interaction data for highly replicable interactions to be
associated with poor quality control.
AVAILABILITY AND IMPLEMENTATION: Algorithms, network data and a guide to the code
available at: https://github.com/wimverleyen/AggregateGeneFunctionPrediction
CONTACT: jgillis@cshl.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv734 
PMID: 26668004  [PubMed - in process]


724. Bioinformatics. 2016 Apr 15;32(8):1275-7. doi: 10.1093/bioinformatics/btv724.
Epub 2015 Dec 12.

Sequence database versioning for command line and Galaxy bioinformatics servers.

Dooley DM(1), Petkau AJ(2), Van Domselaar G(2), Hsiao WW(3).

Author information: 
(1)Department of Pathology, University of British Columbia, Vancouver, BC,
Canada. (2)National Microbiology Laboratory, Public Health Agency of Canada,
Winnipeg, MB, Canada. (3)Department of Pathology, University of British Columbia,
Vancouver, BC, Canada BC Public Health Microbiology and Reference Laboratory,
Vancouver, BC, Canada.

MOTIVATION: There are various reasons for rerunning bioinformatics tools and
pipelines on sequencing data, including reproducing a past result, validation of 
a new tool or workflow using a known dataset, or tracking the impact of database 
changes. For identical results to be achieved, regularly updated reference
sequence databases must be versioned and archived. Database administrators have
tried to fill the requirements by supplying users with one-off versions of
databases, but these are time consuming to set up and are inconsistent across
resources. Disk storage and data backup performance has also discouraged
maintaining multiple versions of databases since databases such as NCBI nr can
consume 50 Gb or more disk space per version, with growth rates that parallel
Moore's law.
RESULTS: Our end-to-end solution combines our own Kipper software package-a
simple key-value large file versioning system-with BioMAJ (software for
downloading sequence databases), and Galaxy (a web-based bioinformatics data
processing platform). Available versions of databases can be recalled and used by
command-line and Galaxy users. The Kipper data store format makes publishing
curated FASTA databases convenient since in most cases it can store a range of
versions into a file marginally larger than the size of the latest version.
AVAILABILITY AND IMPLEMENTATION: Kipper v1.0.0 and the Galaxy Versioned Data tool
are written in Python and released as free and open source software available at 
https://github.com/Public-Health-Bioinformatics/kipper and
https://github.com/Public-Health-Bioinformatics/versioned_data, respectively;
detailed setup instructions can be found at
https://github.com/Public-Health-Bioinformatics/versioned_data/blob/master/doc/se
tup.md
CONTACT: : Damion.Dooley@Bccdc.Ca or William.Hsiao@Bccdc.CaSupplementary
information: Supplementary data are available at Bioinformatics online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv724 
PMCID: PMC4824126
PMID: 26656932  [PubMed - in process]


725. Bioinformatics. 2016 Apr 15;32(8):1226-8. doi: 10.1093/bioinformatics/btv721.
Epub 2015 Dec 10.

FuMa: reporting overlap in RNA-seq detected fusion genes.

Hoogstrate Y(1), Böttcher R(2), Hiltemann S(1), van der Spek PJ(3), Jenster G(2),
Stubbs AP(3).

Author information: 
(1)Department of Urology and Department of Bioinformatics, Erasmus University
Medical Center, Rotterdam, 3000 CA, The Netherlands. (2)Department of Urology
and. (3)Department of Bioinformatics, Erasmus University Medical Center,
Rotterdam, 3000 CA, The Netherlands.

A new generation of tools that identify fusion genes in RNA-seq data is limited
in either sensitivity and or specificity. To allow further downstream analysis
and to estimate performance, predicted fusion genes from different tools have to 
be compared. However, the transcriptomic context complicates genomic
location-based matching. FusionMatcher (FuMa) is a program that reports identical
fusion genes based on gene-name annotations. FuMa automatically compares and
summarizes all combinations of two or more datasets in a single run, without
additional programming necessary. FuMa uses one gene annotation, avoiding
mismatches caused by tool-specific gene annotations. FuMa matches 10% more fusion
genes compared with exact gene matching due to overlapping genes and accepts
intermediate output files that allow a stepwise analysis of corresponding
tools.AVAILABILITY AND IMPLEMENTATION: The code is available at:
https://github.com/ErasmusMC-Bioinformatics/fuma and available for Galaxy in the 
tool sheds and directly accessible at
https://bioinf-galaxian.erasmusmc.nl/galaxy/
CONTACT: y.hoogstrate@erasmusmc.nl or a.stubbs@erasmusmc.nl
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv721 
PMID: 26656567  [PubMed - in process]


726. PLoS One. 2015 Dec 11;10(12):e0144610. doi: 10.1371/journal.pone.0144610.
eCollection 2015.

pyAudioAnalysis: An Open-Source Python Library for Audio Signal Analysis.

Giannakopoulos T(1).

Author information: 
(1)Computational Intelligence Laboratory, Institute of Informatics and
Telecommunications, NCSR Demokritos, Patriarchou Grigoriou and Neapoleos St,
Aghia Paraskevi, Athens, 15310, Greece.

Audio information plays a rather important role in the increasing digital content
that is available today, resulting in a need for methodologies that automatically
analyze such content: audio event recognition for home automations and
surveillance systems, speech recognition, music information retrieval, multimodal
analysis (e.g. audio-visual analysis of online videos for content-based
recommendation), etc. This paper presents pyAudioAnalysis, an open-source Python 
library that provides a wide range of audio analysis procedures including:
feature extraction, classification of audio signals, supervised and unsupervised 
segmentation and content visualization. pyAudioAnalysis is licensed under the
Apache License and is available at GitHub
(https://github.com/tyiannak/pyAudioAnalysis/). Here we present the theoretical
background behind the wide range of the implemented methodologies, along with
evaluation metrics for some of the methods. pyAudioAnalysis has been already used
in several audio analysis research applications: smart-home functionalities
through audio event detection, speech emotion recognition, depression
classification based on audio-visual features, music segmentation, multimodal
content-based movie recommendation and health applications (e.g. monitoring
eating habits). The feedback provided from all these particular audio
applications has led to practical enhancement of the library.

DOI: 10.1371/journal.pone.0144610 
PMCID: PMC4676707
PMID: 26656189  [PubMed - indexed for MEDLINE]


727. Bioinformatics. 2016 Apr 15;32(8):1244-6. doi: 10.1093/bioinformatics/btv723.
Epub 2015 Dec 9.

PharmacoGx: an R package for analysis of large pharmacogenomic datasets.

Smirnov P(1), Safikhani Z(2), El-Hachem N(3), Wang D(1), She A(1), Olsen C(4),
Freeman M(1), Selby H(5), Gendoo DM(2), Grossmann P(6), Beck AH(7), Aerts HJ(6), 
Lupien M(8), Goldenberg A(9), Haibe-Kains B(2).

Author information: 
(1)Princess Margaret Cancer Centre, University Health Network, Toronto, ON,
Canada. (2)Princess Margaret Cancer Centre, University Health Network, Toronto,
ON, Canada, Department of Medical Biophysics, University of Toronto, Toronto, ON,
Canada. (3)Institut De Recherches Cliniques De Montréal, Montreal, QC, Canada.
(4)Princess Margaret Cancer Centre, University Health Network, Toronto, ON,
Canada, Interuniversity Institute of Bioinformatics in Brussels (IB)2, Brussels, 
Belgium, Department of Medical Biophysics, University of Toronto, Toronto, ON,
Canada. (5)Dana-Farber Cancer Institute, Harvard Medical School, Boston, MA, USA,
Department of Bioinformatics, Boston University, Boston, MA, USA. (6)Dana-Farber 
Cancer Institute, Harvard Medical School, Boston, MA, USA. (7)Beth Israel
Deaconess Medical Center, Boston, MA, USA. (8)Princess Margaret Cancer Centre,
University Health Network, Toronto, ON, Canada, Machine Learning Group (MLG),
Department d'Informatique, Université libre de Bruxelles (ULB), Brussels,
Belgium, Ontario Institute of Cancer Research, Toronto, ON, Canada. (9)Hospital
for Sick Children, Toronto, ON, Canada and Department of Computer Science,
University of Toronto, Toronto, ON, Canada.

Pharmacogenomics holds great promise for the development of biomarkers of drug
response and the design of new therapeutic options, which are key challenges in
precision medicine. However, such data are scattered and lack standards for
efficient access and analysis, consequently preventing the realization of the
full potential of pharmacogenomics. To address these issues, we implemented
PharmacoGx, an easy-to-use, open source package for integrative analysis of
multiple pharmacogenomic datasets. We demonstrate the utility of our package in
comparing large drug sensitivity datasets, such as the Genomics of Drug
Sensitivity in Cancer and the Cancer Cell Line Encyclopedia. Moreover, we show
how to use our package to easily perform Connectivity Map analysis. With
increasing availability of drug-related data, our package will open new avenues
of research for meta-analysis of pharmacogenomic data.AVAILABILITY AND
IMPLEMENTATION: PharmacoGx is implemented in R and can be easily installed on any
system. The package is available from CRAN and its source code is available from 
GitHub.
CONTACT: bhaibeka@uhnresearch.ca or benjamin.haibe.kains@utoronto.ca
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv723 
PMID: 26656004  [PubMed - in process]


728. Genome Biol. 2015 Dec 10;16:278. doi: 10.1186/s13059-015-0844-5.

MAST: a flexible statistical framework for assessing transcriptional changes and 
characterizing heterogeneity in single-cell RNA sequencing data.

Finak G(1), McDavid A(2), Yajima M(3), Deng J(4), Gersuk V(5), Shalek
AK(6,)(7,)(8,)(9), Slichter CK(10), Miller HW(11), McElrath MJ(12), Prlic M(13), 
Linsley PS(14), Gottardo R(15,)(16).

Author information: 
(1)Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Research
Center, Seattle, WA, 98109, USA. gfinak@fredhutch.org. (2)Vaccine and Infectious 
Disease Division, Fred Hutchinson Cancer Research Center, Seattle, WA, 98109,
USA. amcdavid@fredhutch.org. (3)Vaccine and Infectious Disease Division, Fred
Hutchinson Cancer Research Center, Seattle, WA, 98109, USA.
myajima@fredhutch.org. (4)Vaccine and Infectious Disease Division, Fred
Hutchinson Cancer Research Center, Seattle, WA, 98109, USA. jdeng@fredhutch.org. 
(5)Benaroya Research Institute at Virginia Mason, Seattle, WA, 98101, USA.
vgersuk@benaroyaresearch.org. (6)Institute for Medical Engineering & Science,
MIT, Boston, MA, 01239-4307, USA. shalek@mit.edu. (7)Department of Chemistry,
MIT, Boston, MA, 01239-4307, USA. shalek@mit.edu. (8)Ragon Institute of MGH, MIT,
& Harvard, Boston, MA, 02139-3583, USA. shalek@mit.edu. (9)Broad Institute of MIT
& Harvard, Boston, MA, 01242, USA. shalek@mit.edu. (10)Vaccine and Infectious
Disease Division, Fred Hutchinson Cancer Research Center, Seattle, WA, 98109,
USA. cslichte@fredhutch.org. (11)Vaccine and Infectious Disease Division, Fred
Hutchinson Cancer Research Center, Seattle, WA, 98109, USA.
hwmiller@fredhutch.org. (12)Vaccine and Infectious Disease Division, Fred
Hutchinson Cancer Research Center, Seattle, WA, 98109, USA.
jmcelrat@fredhutch.org. (13)Vaccine and Infectious Disease Division, Fred
Hutchinson Cancer Research Center, Seattle, WA, 98109, USA. mprlic@fredhutch.org.
(14)Benaroya Research Institute at Virginia Mason, Seattle, WA, 98101, USA.
plinsley@benaroyaresearch.org. (15)Vaccine and Infectious Disease Division, Fred 
Hutchinson Cancer Research Center, Seattle, WA, 98109, USA.
rgottard@fredhutch.org. (16)Public Health Sciences Division, Fred Hutchinson
Cancer Research Center, Seattle, WA, 98109, USA. rgottard@fredhutch.org.

Single-cell transcriptomics reveals gene expression heterogeneity but suffers
from stochastic dropout and characteristic bimodal expression distributions in
which expression is either strongly non-zero or non-detectable. We propose a
two-part, generalized linear model for such bimodal data that parameterizes both 
of these features. We argue that the cellular detection rate, the fraction of
genes expressed in a cell, should be adjusted for as a source of nuisance
variation. Our model provides gene set enrichment analysis tailored to
single-cell data. It provides insights into how networks of co-expressed genes
evolve across an experimental treatment. MAST is available at
https://github.com/RGLab/MAST .

DOI: 10.1186/s13059-015-0844-5 
PMCID: PMC4676162
PMID: 26653891  [PubMed - indexed for MEDLINE]


729. J Proteome Res. 2016 Mar 4;15(3):713-20. doi: 10.1021/acs.jproteome.5b00749. Epub
2016 Jan 12.

MaRaCluster: A Fragment Rarity Metric for Clustering Fragment Spectra in Shotgun 
Proteomics.

The M(1), Käll L(1).

Author information: 
(1)Science for Life Laboratory, School of Biotechnology, Royal Institute of
Technology - KTH , Box 1031, 17121 Solna, Sweden.

Shotgun proteomics experiments generate large amounts of fragment spectra as
primary data, normally with high redundancy between and within experiments. Here,
we have devised a clustering technique to identify fragment spectra stemming from
the same species of peptide. This is a powerful alternative method to traditional
search engines for analyzing spectra, specifically useful for larger scale mass
spectrometry studies. As an aid in this process, we propose a distance
calculation relying on the rarity of experimental fragment peaks, following the
intuition that peaks shared by only a few spectra offer more evidence than peaks 
shared by a large number of spectra. We used this distance calculation and a
complete-linkage scheme to cluster data from a recent large-scale mass
spectrometry-based study. The clusterings produced by our method have up to 40%
more identified peptides for their consensus spectra compared to those produced
by the previous state-of-the-art method. We see that our method would advance the
construction of spectral libraries as well as serve as a tool for mining large
sets of fragment spectra. The source code and Ubuntu binary packages are
available at https://github.com/statisticalbiotechnology/maracluster (under an
Apache 2.0 license).

DOI: 10.1021/acs.jproteome.5b00749 
PMID: 26653874  [PubMed - in process]


730. J Proteome Res. 2016 Mar 4;15(3):777-87. doi: 10.1021/acs.jproteome.5b00780. Epub
2015 Dec 28.

Proteomics Quality Control: Quality Control Software for MaxQuant Results.

Bielow C(1,)(2), Mastrobuoni G(1), Kempa S(1,)(2).

Author information: 
(1)Max-Delbrück-Centrum for Molecular Medicine Berlin , Robert-Rössle-Straße 10, 
13125 Berlin, Germany. (2)Berlin Institute of Health , Kapelle-Ufer 2, 10117
Berlin, Germany.

Mass spectrometry-based proteomics coupled to liquid chromatography has matured
into an automatized, high-throughput technology, producing data on the scale of
multiple gigabytes per instrument per day. Consequently, an automated quality
control (QC) and quality analysis (QA) capable of detecting measurement bias,
verifying consistency, and avoiding propagation of error is paramount for
instrument operators and scientists in charge of downstream analysis. We have
developed an R-based QC pipeline called Proteomics Quality Control (PTXQC) for
bottom-up LC-MS data generated by the MaxQuant software pipeline. PTXQC creates a
QC report containing a comprehensive and powerful set of QC metrics, augmented
with automated scoring functions. The automated scores are collated to create an 
overview heatmap at the beginning of the report, giving valuable guidance also to
nonspecialists. Our software supports a wide range of experimental designs,
including stable isotope labeling by amino acids in cell culture (SILAC), tandem 
mass tags (TMT), and label-free data. Furthermore, we introduce new metrics to
score MaxQuant's Match-between-runs (MBR) functionality by which peptide
identifications can be transferred across Raw files based on accurate retention
time and m/z. Last but not least, PTXQC is easy to install and use and represents
the first QC software capable of processing MaxQuant result tables. PTXQC is
freely available at https://github.com/cbielow/PTXQC .

DOI: 10.1021/acs.jproteome.5b00780 
PMID: 26653327  [PubMed - in process]


731. Evol Bioinform Online. 2015 Nov 30;11:263-6. doi: 10.4137/EBO.S35384. eCollection
2015.

SUMAC: Constructing Phylogenetic Supermatrices and Assessing Partially Decisive
Taxon Coverage.

Freyman WA(1).

Author information: 
(1)Department of Integrative Biology, University of California, Berkeley,
Berkeley, CA, USA.

The amount of phylogenetically informative sequence data in GenBank is growing at
an exponential rate, and large phylogenetic trees are increasingly used in
research. Tools are needed to construct phylogenetic sequence matrices from
GenBank data and evaluate the effect of missing data. Supermatrix Constructor
(SUMAC) is a tool to data-mine GenBank, construct phylogenetic supermatrices, and
assess the phylogenetic decisiveness of a matrix given the pattern of missing
sequence data. SUMAC calculates a novel metric, Missing Sequence Decisiveness
Scores (MSDS), which measures how much each individual missing sequence
contributes to the decisiveness of the matrix. MSDS can be used to compare
supermatrices and prioritize the acquisition of new sequence data. SUMAC
constructs supermatrices either through an exploratory clustering of all GenBank 
sequences within a taxonomic group or by using guide sequences to build
homologous clusters in a more targeted manner. SUMAC assembles supermatrices for 
any taxonomic group recognized in GenBank and is optimized to run on multicore
computer systems by parallelizing multiple stages of operation. SUMAC is
implemented as a Python package that can run as a stand-alone command-line
program, or its modules and objects can be incorporated within other programs.
SUMAC is released under the open source GPLv3 license and is available at
https://github.com/wf8/sumac.

DOI: 10.4137/EBO.S35384 
PMCID: PMC4666519
PMID: 26648681  [PubMed]


732. Bioinformatics. 2016 Apr 15;32(8):1220-2. doi: 10.1093/bioinformatics/btv710.
Epub 2015 Dec 8.

Manta: rapid detection of structural variants and indels for germline and cancer 
sequencing applications.

Chen X(1), Schulz-Trieglaff O(2), Shaw R(2), Barnes B(1), Schlesinger F(1),
Källberg M(2), Cox AJ(2), Kruglyak S(1), Saunders CT(1).

Author information: 
(1)Illumina, Inc, 5200 Illumina Way, San Diego, CA 92122, USA and. (2)Illumina
Cambridge Ltd, Chesterford Research Park, Little Chesterford, Essex CB10 1XL, UK.

: We describe Manta, a method to discover structural variants and indels from
next generation sequencing data. Manta is optimized for rapid germline and
somatic analysis, calling structural variants, medium-sized indels and large
insertions on standard compute hardware in less than a tenth of the time that
comparable methods require to identify only subsets of these variant types: for
example NA12878 at 50× genomic coverage is analyzed in less than 20 min. Manta
can discover and score variants based on supporting paired and split-read
evidence, with scoring models optimized for germline analysis of diploid
individuals and somatic analysis of tumor-normal sample pairs. Call quality is
similar to or better than comparable methods, as determined by pedigree
consistency of germline calls and comparison of somatic calls to COSMIC database 
variants. Manta consistently assembles a higher fraction of its calls to
base-pair resolution, allowing for improved downstream annotation and analysis of
clinical significance. We provide Manta as a community resource to facilitate
practical and routine structural variant analysis in clinical and research
sequencing scenarios.AVAILABILITY AND IMPLEMENTATION: Manta is released under the
open-source GPLv3 license. Source code, documentation and Linux binaries are
available from https://github.com/Illumina/manta.
CONTACT: csaunders@illumina.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv710 
PMID: 26647377  [PubMed - in process]


733. PeerJ. 2015 Nov 26;3:e1444. doi: 10.7717/peerj.1444. eCollection 2015.

Ranking, selecting, and prioritising genes with desirability functions.

Lazic SE(1).

Author information: 
(1)In Silico Lead Discovery, Novartis Institutes for Biomedical Research , Basel 
, Switzerland.

In functional genomics experiments, researchers often select genes to follow-up
or validate from a long list of differentially expressed genes. Typically, sharp 
thresholds are used to bin genes into groups such as significant/non-significant 
or fold change above/below a cut-off value, and ad hoc criteria are also used
such as favouring well-known genes. Binning, however, is inefficient and does not
take the uncertainty of the measurements into account. Furthermore, p-values,
fold-changes, and other outcomes are treated as equally important, and relevant
genes may be overlooked with such an approach. Desirability functions are
proposed as a way to integrate multiple selection criteria for ranking,
selecting, and prioritising genes. These functions map any variable to a
continuous 0-1 scale, where one is maximally desirable and zero is unacceptable. 
Multiple selection criteria are then combined to provide an overall desirability 
that is used to rank genes. In addition to p-values and fold-changes, further
experimental results and information contained in databases can be easily
included as criteria. The approach is demonstrated with a breast cancer
microarray data set. The functions and an example data set can be found in the
desiR package on CRAN (https://cran.r-project.org/web/packages/desiR/) and the
development version is available on GitHub (https://github.com/stanlazic/desiR).

DOI: 10.7717/peerj.1444 
PMCID: PMC4671156
PMID: 26644980  [PubMed]


734. Bioinformatics. 2016 Apr 1;32(7):1048-56. doi: 10.1093/bioinformatics/btv716.
Epub 2015 Dec 7.

Sampling ARG of multiple populations under complex configurations of subdivision 
and admixture.

Carrieri AP(1), Utro F(2), Parida L(2).

Author information: 
(1)Dipartimento Di Informatica Sistemistica E Comunicazione, Università Degli
Studi Di Milano-Bicocca, Viale Sarca 336, Milano, Italy and. (2)Computational
Genomics, IBM T. J. Watson Research, Yorktown Heights, NY 10598, USA.

MOTIVATION: Simulating complex evolution scenarios of multiple populations is an 
important task for answering many basic questions relating to population
genomics. Apart from the population samples, the underlying Ancestral
Recombinations Graph (ARG) is an additional important means in hypothesis
checking and reconstruction studies. Furthermore, complex simulations require a
plethora of interdependent parameters making even the scenario-specification
highly non-trivial.
RESULTS: We present an algorithm SimRA that simulates generic multiple population
evolution model with admixture. It is based on random graphs that improve
dramatically in time and space requirements of the classical algorithm of single 
populations.Using the underlying random graphs model, we also derive closed forms
of expected values of the ARG characteristics i.e., height of the graph, number
of recombinations, number of mutations and population diversity in terms of its
defining parameters. This is crucial in aiding the user to specify meaningful
parameters for the complex scenario simulations, not through trial-and-error
based on raw compute power but intelligent parameter estimation. To the best of
our knowledge this is the first time closed form expressions have been computed
for the ARG properties. We show that the expected values closely match the
empirical values through simulations.Finally, we demonstrate that SimRA produces 
the ARG in compact forms without compromising any accuracy. We demonstrate the
compactness and accuracy through extensive experiments.
AVAILABILITY AND IMPLEMENTATION: SimRA (Simulation based on Random graph
Algorithms) source, executable, user manual and sample input-output sets are
available for downloading at: https://github.com/ComputationalGenomics/SimRA
CONTACT: : parida@us.ibm.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv716 
PMID: 26644417  [PubMed - in process]


735. Bioinformatics. 2016 Apr 15;32(8):1130-7. doi: 10.1093/bioinformatics/btv707.
Epub 2015 Dec 7.

Joint detection of copy number variations in parent-offspring trios.

Liu Y(1), Liu J(1), Lu J(1), Peng J(1), Juan L(1), Zhu X(2), Li B(3), Wang Y(1).

Author information: 
(1)School of Computer Science and Technology, Harbin Institute of Technology,
Harbin 150001, China. (2)Institute for Genomic Medicine, Columbia University, New
York, NY 10032, University Program in Genetics and Genomics, Duke University
Medical School, Durham, NC 27708. (3)Department of Molecular Physiology and
Biophysics, Vanderbilt University, Nashville, TN 37235 and Center for
Quantitative Sciences, Vanderbilt University, Nashville, TN 37235, USA.

MOTIVATION: Whole genome sequencing (WGS) of parent-offspring trios is a powerful
approach for identifying disease-associated genes via detecting copy number
variations (CNVs). Existing approaches, which detect CNVs for each individual in 
a trio independently, usually yield low-detection accuracy. Joint modeling
approaches leveraging Mendelian transmission within the parent-offspring trio can
be an efficient strategy to improve CNV detection accuracy.
RESULTS: In this study, we developed TrioCNV, a novel approach for jointly
detecting CNVs in parent-offspring trios from WGS data. Using negative binomial
regression, we modeled the read depth signal while considering both GC content
bias and mappability bias. Moreover, we incorporated the family relationship and 
used a hidden Markov model to jointly infer CNVs for three samples of a
parent-offspring trio. Through application to both simulated data and a trio from
1000 Genomes Project, we showed that TrioCNV achieved superior performance than
existing approaches.
AVAILABILITY AND IMPLEMENTATION: The software TrioCNV implemented using a
combination of Java and R is freely available from the website at
https://github.com/yongzhuang/TrioCNV CONTACT: ydwang@hit.edu.cn
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv707 
PMCID: PMC4907378 [Available on 2017-04-15]
PMID: 26644415  [PubMed - in process]


736. J Am Med Inform Assoc. 2016 May;23(3):596-600. doi: 10.1093/jamia/ocv153. Epub
2015 Dec 7.

OpenFDA: an innovative platform providing access to a wealth of FDA's publicly
available data.

Kass-Hout TA(1), Xu Z(2), Mohebbi M(3), Nelsen H(3), Baker A(3), Levine J(1),
Johanson E(1), Bright RA(1).

Author information: 
(1)U.S. Food and Drug Administration, Silver Spring, MD, USA. (2)U.S. Food and
Drug Administration, Silver Spring, MD, USA zhiheng.xu@fda.hhs.gov. (3)Iodine,
Inc. 34 Clyde Street, San Francisco, CA 94107, USA.

OBJECTIVE: The objective of openFDA is to facilitate access and use of big
important Food and Drug Administration public datasets by developers,
researchers, and the public through harmonization of data across disparate FDA
datasets provided via application programming interfaces (APIs).
MATERIALS AND METHODS: Using cutting-edge technologies deployed on FDA's new
public cloud computing infrastructure, openFDA provides open data for easier,
faster (over 300 requests per second per process), and better access to FDA
datasets; open source code and documentation shared on GitHub for open community 
contributions of examples, apps and ideas; and infrastructure that can be adopted
for other public health big data challenges.
RESULTS: Since its launch on June 2, 2014, openFDA has developed four APIs for
drug and device adverse events, recall information for all FDA-regulated
products, and drug labeling. There have been more than 20 million API calls (more
than half from outside the United States), 6000 registered users, 20,000
connected Internet Protocol addresses, and dozens of new software (mobile or web)
apps developed. A case study demonstrates a use of openFDA data to understand an 
apparent association of a drug with an adverse event.
CONCLUSION: With easier and faster access to these datasets, consumers worldwide 
can learn more about FDA-regulated products.

© The Author 2015. Published by Oxford University Press on behalf of the American
Medical Informatics Association. All rights reserved.

DOI: 10.1093/jamia/ocv153 
PMCID: PMC4901374 [Available on 2017-05-01]
PMID: 26644398  [PubMed - in process]


737. Genome Med. 2015 Dec 7;7:127. doi: 10.1186/s13073-015-0251-2.

ScanIndel: a hybrid framework for indel detection via gapped alignment, split
reads and de novo assembly.

Yang R(1), Nelson AC(2), Henzler C(3), Thyagarajan B(4), Silverstein KA(5).

Author information: 
(1)Supercomputing Institute for Advanced Computational Research, University of
Minnesota, 117 Pleasant St. SE, RM 541, Minneapolis, MN, 55455, USA.
yang4414@umn.edu. (2)Department of Laboratory Medicine and Pathology, University 
of Minnesota, Minneapolis, MN, 55455, USA. nels2055@umn.edu. (3)Supercomputing
Institute for Advanced Computational Research, University of Minnesota, 117
Pleasant St. SE, RM 541, Minneapolis, MN, 55455, USA. chenzler@umn.edu.
(4)Department of Laboratory Medicine and Pathology, University of Minnesota,
Minneapolis, MN, 55455, USA. thya0003@umn.edu. (5)Supercomputing Institute for
Advanced Computational Research, University of Minnesota, 117 Pleasant St. SE, RM
541, Minneapolis, MN, 55455, USA. kats@umn.edu.

Comprehensive identification of insertions/deletions (indels) across the full
size spectrum from second generation sequencing is challenging due to the
relatively short read length inherent in the technology. Different indel calling 
methods exist but are limited in detection to specific sizes with varying
accuracy and resolution. We present ScanIndel, an integrated framework for
detecting indels with multiple heuristics including gapped alignment, split reads
and de novo assembly. Using simulation data, we demonstrate ScanIndel's superior 
sensitivity and specificity relative to several state-of-the-art indel callers
across various coverage levels and indel sizes. ScanIndel yields higher
predictive accuracy with lower computational cost compared with existing tools
for both targeted resequencing data from tumor specimens and high coverage
whole-genome sequencing data from the human NIST standard NA12878. Thus, we
anticipate ScanIndel will improve indel analysis in both clinical and research
settings. ScanIndel is implemented in Python, and is freely available for
academic use at https://github.com/cauyrd/ScanIndel.

DOI: 10.1186/s13073-015-0251-2 
PMCID: PMC4671222
PMID: 26643039  [PubMed - indexed for MEDLINE]


738. PLoS One. 2015 Dec 7;10(12):e0144163. doi: 10.1371/journal.pone.0144163.
eCollection 2015.

Detecting Protein Complexes in Protein Interaction Networks Modeled as Gene
Expression Biclusters.

Hanna EM(1), Zaki N(1), Amin A(2,)(3).

Author information: 
(1)Intelligent Systems, College of Info. Tech., UAEU, Al Ain 17551, UAE.
(2)Department of Biology, College of Science, UAEU, Al Ain 15551, UAE. (3)Faculty
of Science, Cairo University, Cairo, Egypt.

Developing suitable methods for the detection of protein complexes in protein
interaction networks continues to be an intriguing area of research. The
importance of this objective originates from the fact that protein complexes are 
key players in most cellular processes. The more complexes we identify, the
better we can understand normal as well as abnormal molecular events. Up till
now, various computational methods were designed for this purpose. However,
despite their notable performance, questions arise regarding potential ways to
improve them, in addition to ameliorative guidelines to introduce novel
approaches. A close interpretation leads to the assent that the way in which
protein interaction networks are initially viewed should be adjusted. These
networks are dynamic in reality and it is necessary to consider this fact to
enhance the detection of protein complexes. In this paper, we present
"DyCluster", a framework to model the dynamic aspect of protein interaction
networks by incorporating gene expression data, through biclustering techniques, 
prior to applying complex-detection algorithms. The experimental results show
that DyCluster leads to higher numbers of correctly-detected complexes with
better evaluation scores. The high accuracy achieved by DyCluster in detecting
protein complexes is a valid argument in favor of the proposed method. DyCluster 
is also able to detect biologically meaningful protein groups. The code and
datasets used in the study are downloadable from
https://github.com/emhanna/DyCluster.

DOI: 10.1371/journal.pone.0144163 
PMCID: PMC4671556
PMID: 26641660  [PubMed - indexed for MEDLINE]


739. Evol Bioinform Online. 2015 Nov 25;11:253-61. doi: 10.4137/EBO.S27693.
eCollection 2015.

Segmenting the Human Genome into Isochores.

Cozzi P(1), Milanesi L(2), Bernardi G(3).

Author information: 
(1)National Research Council, Institute for Biomedical Technologies, Segrate,
Milan, Italy. ; Parco Tecnologico Padano, Lodi, Italy. (2)National Research
Council, Institute for Biomedical Technologies, Segrate, Milan, Italy.
(3)National Research Council, Institute for Biomedical Technologies, Segrate,
Milan, Italy. ; Science Department, Rome 3 University, Rome, Italy.

The human genome is a mosaic of isochores, which are long (>200 kb) DNA sequences
that are fairly homogeneous in base composition and can be assigned to five
families comprising 33%-59% of GC composition. Although the compartmentalized
organization of the mammalian genome has been investigated for more than 40
years, no satisfactory automatic procedure for segmenting the genome into
isochores is available so far. We present a critical discussion of the currently 
available methods and a new approach called isoSegmenter which allows segmenting 
the genome into isochores in a fast and completely automatic manner. This
approach relies on two types of experimentally defined parameters, the
compositional boundaries of isochore families and an optimal window size of 100
kb. The approach represents an improvement over the existing methods, is ideally 
suited for investigating long-range features of sequenced and assembled genomes, 
and is publicly available at https://github.com/bunop/isoSegmenter.

DOI: 10.4137/EBO.S27693 
PMCID: PMC4662427
PMID: 26640363  [PubMed]


740. Anal Chem. 2016 Jan 5;88(1):621-8. doi: 10.1021/acs.analchem.5b03628. Epub 2015
Dec 18.

geoRge: A Computational Tool To Detect the Presence of Stable Isotope Labeling in
LC/MS-Based Untargeted Metabolomics.

Capellades J(1,)(2,)(3), Navarro M(1,)(3), Samino S(1,)(3), Garcia-Ramirez
M(3,)(4), Hernandez C(3,)(4), Simo R(3,)(4), Vinaixa M(1,)(5,)(3), Yanes
O(1,)(5,)(3).

Author information: 
(1)Centre for Omic Sciences, Universitat Rovira i Virgili , Avinguda Universitat 
1, 43204 Reus, Spain. (2)Institut d'Investigacio Sanitaria Pere i Virgili
(IISPV), Avinguda Universitat 1, 43204 Reus, Spain. (3)Spanish Biomedical
Research Center in Diabetes and Associated Metabolic Disorders (CIBERDEM) ,
Monforte de Lemos 3-5, 28029 Madrid, Spain. (4)Diabetes and Metabolism Research
Unit, Institut de Recerca Hospital Universitari Vall d'Hebron (VHIR) , Passeig
Vall d'Hebron 119-129, 08035 Barcelona, Spain. (5)Department of Electronic
Engineering, Universitat Rovira i Virgili , Avinguda Paisos Catalans 26, 43007
Tarragona, Spain.

Studying the flow of chemical moieties through the complex set of metabolic
reactions that happen in the cell is essential to understanding the alterations
in homeostasis that occur in disease. Recently, LC/MS-based untargeted
metabolomics and isotopically labeled metabolites have been used to facilitate
the unbiased mapping of labeled moieties through metabolic pathways. However, due
to the complexity of the resulting experimental data sets few computational tools
are available for data analysis. Here we introduce geoRge, a novel computational 
approach capable of analyzing untargeted LC/MS data from stable isotope-labeling 
experiments. geoRge is written in the open language R and runs on the output
structure of the XCMS package, which is in widespread use. As opposed to the few 
existing tools, which use labeled samples to track stable isotopes by iterating
over all MS signals using the theoretical mass difference between the light and
heavy isotopes, geoRge uses unlabeled and labeled biologically equivalent samples
to compare isotopic distributions in the mass spectra. Isotopically enriched
compounds change their isotopic distribution as compared to unlabeled compounds. 
This is directly reflected in a number of new m/z peaks and higher intensity
peaks in the mass spectra of labeled samples relative to the unlabeled
equivalents. The automated untargeted isotope annotation and relative
quantification capabilities of geoRge are demonstrated by the analysis of LC/MS
data from a human retinal pigment epithelium cell line (ARPE-19) grown on normal 
and high glucose concentrations mimicking diabetic retinopathy conditions in
vitro. In addition, we compared the results of geoRge with the outcome of
X(13)CMS, since both approaches rely entirely on XCMS parameters for feature
selection, namely m/z and retention time values. To ensure data traceability and 
reproducibility, and enabling for comparison with other existing and future
approaches, raw LC/MS files have been deposited in MetaboLights (MTBLS213) and
geoRge is available as an R script at https://github.com/jcapelladesto/geoRge.

DOI: 10.1021/acs.analchem.5b03628 
PMID: 26639619  [PubMed - indexed for MEDLINE]


741. Bioinformatics. 2016 Apr 1;32(7):1016-22. doi: 10.1093/bioinformatics/btv711.
Epub 2015 Dec 3.

Maligner: a fast ordered restriction map aligner.

Mendelowitz LM(1), Schwartz DC(2), Pop M(3).

Author information: 
(1)Center for Bioinformatics and Computational Biology, Applied Math &
Statistics, and Scientific Computation. (2)Laboratory for Molecular and
Computational Genomics, Department of Chemistry, Laboratory of Genetics, USA and 
the UW-Biotechnology Center, University of Wisconsin-Madison, WI 53706, USA.
(3)Center for Bioinformatics and Computational Biology, Applied Math &
Statistics, and Scientific Computation, Department of Computer Science,
University of Maryland, College Park, MD 20742, USA and.

MOTIVATION: The Optical Mapping System discovers structural variants and
potentiates sequence assembly of genomes via scaffolding and comparisons that
globally validate or correct sequence assemblies. Despite its utility, there are 
few publicly available tools for aligning optical mapping datasets.
RESULTS: Here we present software, named 'Maligner', for the alignment of both
single molecule restriction maps (Rmaps) and in silico restriction maps of
sequence contigs to a reference. Maligner provides two modes of alignment: an
efficient, sensitive dynamic programming implementation that scales to large
eukaryotic genomes, and a faster indexed based implementation for finding
alignments with unmatched sites in the reference but not the query. We compare
our software to other publicly available tools on Rmap datasets and show that
Maligner finds more correct alignments in comparable runtime. Lastly, we
introduce the M-Score statistic for normalizing alignment scores across
restriction maps and demonstrate its utility for selecting high quality
alignments.
AVAILABILITY AND IMPLEMENTATION: The Maligner software is written in C ++ and is 
available at https://github.com/LeeMendelowitz/maligner under the GNU General
Public License.
CONTACT: mpop@umiacs.umd.edu.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv711 
PMCID: PMC4907389 [Available on 2017-04-01]
PMID: 26637292  [PubMed - in process]


742. Front Microbiol. 2015 Nov 24;6:1267. doi: 10.3389/fmicb.2015.01267. eCollection
2015.

Hunting Down Frame Shifts: Ecological Analysis of Diverse Functional Gene
Sequences.

Strejcek M(1), Wang Q(2), Ridl J(3), Uhlik O(1).

Author information: 
(1)Department of Biochemistry and Microbiology, Faculty of Food and Biochemical
Technology, University of Chemistry and Technology, Prague Prague, Czech
Republic. (2)Center for Microbial Ecology, Michigan State University East
Lansing, MI, USA. (3)Department of Genomics and Bioinformatics, Institute of
Molecular Genetics, Academy of Sciences of the Czech Republic Prague, Czech
Republic.

Functional gene ecological analyses using amplicon sequencing can be challenging 
as translated sequences are often burdened with shifted reading frames. The aim
of this work was to evaluate several bioinformatics tools designed to correct
errors which arise during sequencing in an effort to reduce the number of
frameshifts (FS). Genes encoding for alpha subunits of biphenyl (bphA) and
benzoate (benA) dioxygenases were used as model sequences. FrameBot, a FS
correction tool, was able to reduce the number of detected FS to zero. However,
up to 44% of sequences were discarded by FrameBot as non-specific targets.
Therefore, we proposed a de novo mode of FrameBot for FS correction, which works 
on a similar basis as common chimera identifying platforms and is not dependent
on reference sequences. By nature of FrameBot de novo design, it is crucial to
provide it with data as error free as possible. We tested the ability of several 
publicly available correction tools to decrease the number of errors in the data 
sets. The combination of maximum expected error filtering and single linkage
pre-clustering proved to be the most efficient read processing approach. Applying
FrameBot de novo on the processed data enabled analysis of BphA sequences with
minimal losses of potentially functional sequences not homologous to those
previously known. This experiment also demonstrated the extensive diversity of
dioxygenases in soil. A script which performs FrameBot de novo is presented in
the supplementary material to the study or available at
https://github.com/strejcem/FBdenovo. The tool was also implemented into FunGene 
Pipeline available at http://fungene.cme.msu.edu/FunGenePipeline/.

DOI: 10.3389/fmicb.2015.01267 
PMCID: PMC4656815
PMID: 26635739  [PubMed]


743. Bioinformatics. 2016 Apr 15;32(8):1267-8. doi: 10.1093/bioinformatics/btv698.
Epub 2015 Dec 3.

qsubsec: a lightweight template system for defining sun grid engine workflows.

Droop AP(1).

Author information: 
(1)MRC Medical Bioinformatics Centre, University of Leeds, Clarendon Way, Leeds
LS2 9NL, UK.

The Sun Grid Engine (SGE) high-performance computing batch queueing system is
commonly used in bioinformatics analysis. Creating re-usable scripts for the SGE 
is a common challenge. The qsubsec template language and interpreter described
here allow researchers to easily create generic template definitions that
encapsulate a particular computational job, effectively separating the process
logic from the specific run details. At submission time, the generic template is 
filled in with specific values. This system provides an intermediate level
between simple scripting and complete workflow management tools.AVAILABILITY AND 
IMPLEMENTATION: Qsubsec is open-source and is available at
https://github.com/alastair-droop/qsubsec
CONTACT: a.p.droop@leeds.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv698 
PMCID: PMC4824124
PMID: 26635140  [PubMed - in process]


744. PLoS Genet. 2015 Dec 2;11(12):e1005657. doi: 10.1371/journal.pgen.1005657.
eCollection 2015.

A Simple Model-Based Approach to Inferring and Visualizing Cancer Mutation
Signatures.

Shiraishi Y(1), Tremmel G(1), Miyano S(1), Stephens M(2,)(3).

Author information: 
(1)Laboratory of DNA Information Analysis, Human Genome Center, Institute of
Medical Science, The University of Tokyo, Tokyo, Japan. (2)Department of Human
Genetics, University of Chicago, Chicago, Illinois, United States of America.
(3)Department of Statistics, University of Chicago, Chicago, Illinois, United
States of America.

Recent advances in sequencing technologies have enabled the production of massive
amounts of data on somatic mutations from cancer genomes. These data have led to 
the detection of characteristic patterns of somatic mutations or "mutation
signatures" at an unprecedented resolution, with the potential for new insights
into the causes and mechanisms of tumorigenesis. Here we present new methods for 
modelling, identifying and visualizing such mutation signatures. Our methods
greatly simplify mutation signature models compared with existing approaches,
reducing the number of parameters by orders of magnitude even while increasing
the contextual factors (e.g. the number of flanking bases) that are accounted
for. This improves both sensitivity and robustness of inferred signatures. We
also provide a new intuitive way to visualize the signatures, analogous to the
use of sequence logos to visualize transcription factor binding sites. We
illustrate our new method on somatic mutation data from urothelial carcinoma of
the upper urinary tract, and a larger dataset from 30 diverse cancer types. The
results illustrate several important features of our methods, including the
ability of our new visualization tool to clearly highlight the key features of
each signature, the improved robustness of signature inferences from small sample
sizes, and more detailed inference of signature characteristics such as strand
biases and sequence context effects at the base two positions 5' to the mutated
site. The overall framework of our work is based on probabilistic models that are
closely connected with "mixed-membership models" which are widely used in
population genetic admixture analysis, and in machine learning for document
clustering. We argue that recognizing these relationships should help improve
understanding of mutation signature extraction problems, and suggests ways to
further improve the statistical methods. Our methods are implemented in an R
package pmsignature (https://github.com/friend1ws/pmsignature) and a web
application available at https://friend1ws.shinyapps.io/pmsignature_shiny/.

DOI: 10.1371/journal.pgen.1005657 
PMCID: PMC4667891
PMID: 26630308  [PubMed - indexed for MEDLINE]


745. J Proteome Res. 2016 Jan 4;15(1):144-51. doi: 10.1021/acs.jproteome.5b00610. Epub
2015 Dec 17.

SpectroGene: A Tool for Proteogenomic Annotations Using Top-Down Spectra.

Kolmogorov M(1), Liu X(2), Pevzner PA(1).

Author information: 
(1)Department of Computer Science and Engineering, UCSD , 9500 Gilman Drive, La
Jolla, California, United States. (2)Department of BioHealth Informatics, IUPUI ,
719 Indiana Avenue, Suite 304, Indianapolis, Indiana, United States.

In the past decade, proteogenomics has emerged as a valuable technique that
contributes to the state-of-the-art in genome annotation; however, previous
proteogenomic studies were limited to bottom-up mass spectrometry and did not
take advantage of top-down approaches. We show that top-down proteogenomics
allows one to address the problems that remained beyond the reach of traditional 
bottom-up proteogenomics. In particular, we show that top-down proteogenomics
leads to the discovery of previously unannotated genes even in extensively
studied bacterial genomes and present SpectroGene, a software tool for genome
annotation using top-down tandem mass spectra. We further show that top-down
proteogenomics searches (against the six-frame translation of a genome) identify 
nearly all proteoforms found in traditional top-down proteomics searches (against
the annotated proteome). SpectroGene is freely available at
http://github.com/fenderglass/SpectroGene .

DOI: 10.1021/acs.jproteome.5b00610 
PMID: 26629978  [PubMed - indexed for MEDLINE]


746. Epigenetics Chromatin. 2015 Dec 1;8:51. doi: 10.1186/s13072-015-0045-1.
eCollection 2015.

ADMIRE: analysis and visualization of differential methylation in genomic regions
using the Infinium HumanMethylation450 Assay.

Preussner J(1), Bayer J(1), Kuenne C(1), Looso M(1).

Author information: 
(1)Bioinformatics Group, Max Planck Institute for Heart and Lung Research,
Ludwigstrasse 43, 61231 Bad Nauheim, Germany.

BACKGROUND: DNA methylation at cytosine nucleotides constitutes epigenetic gene
regulation impacting cellular development and a wide range of diseases. Cytosine 
bases of the DNA are converted to 5-methylcytosine by the methyltransferase
enzyme, acting as a reversible regulator of gene expression. Due to its
outstanding importance in the epigenetic field, a number of lab techniques were
developed to interrogate DNA methylation on a global range. Besides whole-genome 
bisulfite sequencing, the Infinium HumanMethylation450 Assay represents a
versatile and cost-effective tool to investigate genome-wide changes of
methylation patterns.
RESULTS: Analysis of DNA Methylation In genomic REgions (ADMIRE) is an open
source, semi-automatic analysis pipeline and visualization tool for Infinium
HumanMethylation450 Assays with a special focus on ease of use. It features
flexible experimental settings, quality control, automatic filtering,
normalization, multiple testing, and differential analyses on arbitrary genomic
regions. Publication-ready graphics, genome browser tracks, and table outputs
include summary data and statistics, permitting instant comparison of methylation
profiles between sample groups and the exploration of methylation patterns along 
the whole genome. ADMIREs statistical approach permits simultaneous large-scale
analyses of hundreds of assays with little impact on algorithm runtimes.
CONCLUSIONS: The web-based version of ADMIRE provides a simple interface to
researchers with limited programming skills, whereas the offline version is
suitable for integration into custom pipelines. ADMIRE may be used via our freely
available web service at https://bioinformatics.mpi-bn.mpg.de without any
limitations concerning the size of a project. An offline version for local
execution is available from our website or GitHub
(https://github.molgen.mpg.de/loosolab/admire).

DOI: 10.1186/s13072-015-0045-1 
PMCID: PMC4666223
PMID: 26628921  [PubMed]


747. Bioinformatics. 2016 Feb 1;32(3):424-31. doi: 10.1093/bioinformatics/btv699. Epub
2015 Dec 1.

IKAP: A heuristic framework for inference of kinase activities from
Phosphoproteomics data.

Mischnik M(1), Sacco F(2), Cox J(2), Schneider HC(1), Schäfer M(1), Hendlich
M(1), Crowther D(1), Mann M(2), Klabunde T(1).

Author information: 
(1)Sanofi-Aventis Deutschland GmbH, Frankfurt, Germany and. (2)Department of
Proteomics and Signal Transduction, Max-Planck-Institute for Biochemistry,
Martinsried, Germany.

MOTIVATION: Phosphoproteomics measurements are widely applied in cellular biology
to detect changes in signalling dynamics. However, due to the inherent complexity
of phosphorylation patterns and the lack of knowledge on how phosphorylations are
related to functions, it is often not possible to directly deduce protein
activities from those measurements. Here, we present a heuristic machine learning
algorithm that infers the activities of kinases from Phosphoproteomics data using
kinase-target information from the PhosphoSitePlus database. By comparing the
estimated kinase activity profiles to the measured phosphosite profiles, it is
furthermore possible to derive the kinases that are most likely to phosphorylate 
the respective phosphosite.
RESULTS: We apply our approach to published datasets of the human cell cycle
generated from HeLaS3 cells, and insulin signalling dynamics in mouse
hepatocytes. In the first case, we estimate the activities of 118 at six cell
cycle stages and derive 94 new kinase-phosphosite links that can be validated
through either database or motif information. In the second case, the activities 
of 143 kinases at eight time points are estimated and 49 new kinase-target links 
are derived.
AVAILABILITY AND IMPLEMENTATION: The algorithm is implemented in Matlab and be
downloaded from github. It makes use of the Optimization and Statistics
toolboxes. https://github.com/marcel-mischnik/IKAP.git.
CONTACT: marcel.mischnik@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv699 
PMID: 26628587  [PubMed - indexed for MEDLINE]


748. Bioinformatics. 2016 Apr 1;32(7):1091-3. doi: 10.1093/bioinformatics/btv705. Epub
2015 Dec 1.

LedPred: an R/bioconductor package to predict regulatory sequences using support 
vector machines.

Seyres D(1), Darbo E(2), Perrin L(3), Herrmann C(4), González A(1).

Author information: 
(1)INSERM, UMR1090 TAGC, Marseille, F-13288 France, Aix-Marseille Université,
UMR1090 TAGC, Marseille, F-13288 France. (2)Cancer Research UK, London Research
Institute, London WC2A 3LY, UK. (3)INSERM, UMR1090 TAGC, Marseille, F-13288
France, Aix-Marseille Université, UMR1090 TAGC, Marseille, F-13288 France, CNRS, 
Marseille, France and. (4)IPMB, Universität Heidelberg and Department of
Theoretical Bioinformatics, DKFZ, Heidelberg 69120, Germany.

Supervised classification based on support vector machines (SVMs) has
successfully been used for the prediction of cis-regulatory modules (CRMs).
However, no integrated tool using such heterogeneous data as position-specific
scoring matrices, ChIP-seq data or conservation scores is currently available.
Here, we present LedPred, a flexible SVM workflow that predicts new regulatory
sequences based on the annotation of known CRMs, which are associated to a large 
variety of feature types. LedPred is provided as an R/Bioconductor package
connected to an online server to avoid installation of non-R software. Due to the
heterogeneous CRM feature integration, LedPred excels at the prediction of
regulatory sequences in Drosophila and mouse datasets compared with similar
SVM-based software.AVAILABILITY AND IMPLEMENTATION: LedPred is available on
GitHub: https://github.com/aitgon/LedPred and Bioconductor:
http://bioconductor.org/packages/release/bioc/html/LedPred.html under the MIT
license.
CONTACT: aitor.gonzalez@univ-amu.fr
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv705 
PMID: 26628586  [PubMed - in process]


749. Bioinformatics. 2016 Apr 1;32(7):1112-4. doi: 10.1093/bioinformatics/btv706. Epub
2015 Dec 1.

An automated workflow for parallel processing of large multiview SPIM recordings.

Schmied C(1), Steinbach P(1), Pietzsch T(1), Preibisch S(2), Tomancak P(1).

Author information: 
(1)Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany.
(2)Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany,
HHMI Janelia Research Campus, Ashburn, VA, USA and Max Delbrück Center for
Molecular Medicine, Berlin Institute for Medical Systems Biology, Berlin,
Germany.

Selective Plane Illumination Microscopy (SPIM) allows to image developing
organisms in 3D at unprecedented temporal resolution over long periods of time.
The resulting massive amounts of raw image data requires extensive processing
interactively via dedicated graphical user interface (GUI) applications. The
consecutive processing steps can be easily automated and the individual time
points can be processed independently, which lends itself to trivial
parallelization on a high performance computing (HPC) cluster. Here, we introduce
an automated workflow for processing large multiview, multichannel,
multiillumination time-lapse SPIM data on a single workstation or in parallel on 
a HPC cluster. The pipeline relies on snakemake to resolve dependencies among
consecutive processing steps and can be easily adapted to any cluster environment
for processing SPIM data in a fraction of the time required to collect
it.AVAILABILITY AND IMPLEMENTATION: The code is distributed free and open source 
under the MIT license http://opensource.org/licenses/MIT The source code can be
downloaded from github: https://github.com/mpicbg-scicomp/snakemake-workflows
Documentation can be found here:
http://fiji.sc/Automated_workflow_for_parallel_Multiview_Reconstruction
CONTACT: : schmied@mpi-cbg.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv706 
PMCID: PMC4896369
PMID: 26628585  [PubMed - in process]


750. PLoS Comput Biol. 2015 Dec 1;11(12):e1004572. doi: 10.1371/journal.pcbi.1004572. 
eCollection 2015.

Wham: Identifying Structural Variants of Biological Consequence.

Kronenberg ZN(1), Osborne EJ(1,)(2), Cone KR(1), Kennedy BJ(1,)(2), Domyan ET(3),
Shapiro MD(3), Elde NC(1), Yandell M(1,)(2).

Author information: 
(1)Department of Human Genetics, Eccles Institute of Human Genetics, University
of Utah, Salt Lake City, Utah, United States of America. (2)Utah Center for
Genetic Discovery, University of Utah, Salt Lake City, Utah, United States of
America. (3)Department of Biology, University of Utah, Salt Lake City, Utah,
United States of America.

Existing methods for identifying structural variants (SVs) from short read
datasets are inaccurate. This complicates disease-gene identification and efforts
to understand the consequences of genetic variation. In response, we have created
Wham (Whole-genome Alignment Metrics) to provide a single, integrated framework
for both structural variant calling and association testing, thereby bypassing
many of the difficulties that currently frustrate attempts to employ SVs in
association testing. Here we describe Wham, benchmark it against three other
widely used SV identification tools-Lumpy, Delly and SoftSearch-and demonstrate
Wham's ability to identify and associate SVs with phenotypes using data from
humans, domestic pigeons, and vaccinia virus. Wham and all associated software
are covered under the MIT License and can be freely downloaded from github
(https://github.com/zeeev/wham), with documentation on a wiki
(http://zeeev.github.io/wham/). For community support please post questions to
https://www.biostars.org/.

DOI: 10.1371/journal.pcbi.1004572 
PMCID: PMC4666669
PMID: 26625158  [PubMed - indexed for MEDLINE]


751. Genome Biol. 2015 Dec 1;16:259. doi: 10.1186/s13059-015-0831-x.

HiC-Pro: an optimized and flexible pipeline for Hi-C data processing.

Servant N(1,)(2,)(3), Varoquaux N(4,)(5,)(6), Lajoie BR(7), Viara E(8), Chen
CJ(9,)(10,)(11,)(12,)(13,)(14), Vert JP(15,)(16,)(17), Heard E(18,)(19,)(20),
Dekker J(21), Barillot E(22,)(23,)(24).

Author information: 
(1)Institut Curie, Paris, France. nicolas.servant@curie.fr. (2)INSERM, U900,
Paris, France. nicolas.servant@curie.fr. (3)Mines ParisTech, PSL-Research
University, CBIO-Centre for Computational Biology, Fontainebleau, France.
nicolas.servant@curie.fr. (4)Institut Curie, Paris, France.
nelle.varoquaux@ensmp.fr. (5)INSERM, U900, Paris, France.
nelle.varoquaux@ensmp.fr. (6)Mines ParisTech, PSL-Research University,
CBIO-Centre for Computational Biology, Fontainebleau, France.
nelle.varoquaux@ensmp.fr. (7)Program in Systems Biology, Department of
Biochemistry and Molecular Pharmacology, University of Massachusetts Medical
School, Worcester, MA, USA. Bryan.Lajoie@umassmed.edu. (8)Sysra, Yerres, France. 
viara@sysra.com. (9)Institut Curie, Paris, France. cchen@annoroad.com.
(10)INSERM, U900, Paris, France. cchen@annoroad.com. (11)Mines ParisTech,
PSL-Research University, CBIO-Centre for Computational Biology, Fontainebleau,
France. cchen@annoroad.com. (12)CNRS UMR3215, Paris, France. cchen@annoroad.com. 
(13)INSERM U934, Paris, France. cchen@annoroad.com. (14)Annoroad Gene Technology 
Co., Ltd, Beijing, China. cchen@annoroad.com. (15)Institut Curie, Paris, France. 
Jean-Philippe.Vert@mines.org. (16)INSERM, U900, Paris, France.
Jean-Philippe.Vert@mines.org. (17)Mines ParisTech, PSL-Research University,
CBIO-Centre for Computational Biology, Fontainebleau, France.
Jean-Philippe.Vert@mines.org. (18)Institut Curie, Paris, France.
edith.heard@curie.fr. (19)CNRS UMR3215, Paris, France. edith.heard@curie.fr.
(20)INSERM U934, Paris, France. edith.heard@curie.fr. (21)Howard Hughes Medical
Institute, Program in Systems Biology, Department of Biochemistry and Molecular
Pharmacology, University of Massachusetts Medical School, Worcester, MA, USA.
job.dekker@umassmed.edu. (22)Institut Curie, Paris, France.
emmanuel.barillot@curie.fr. (23)INSERM, U900, Paris, France.
emmanuel.barillot@curie.fr. (24)Mines ParisTech, PSL-Research University,
CBIO-Centre for Computational Biology, Fontainebleau, France.
emmanuel.barillot@curie.fr.

HiC-Pro is an optimized and flexible pipeline for processing Hi-C data from raw
reads to normalized contact maps. HiC-Pro maps reads, detects valid ligation
products, performs quality controls and generates intra- and inter-chromosomal
contact maps. It includes a fast implementation of the iterative correction
method and is based on a memory-efficient data format for Hi-C contact maps. In
addition, HiC-Pro can use phased genotype data to build allele-specific contact
maps. We applied HiC-Pro to different Hi-C datasets, demonstrating its ability to
easily process large data in a reasonable time. Source code and documentation are
available at http://github.com/nservant/HiC-Pro .

DOI: 10.1186/s13059-015-0831-x 
PMCID: PMC4665391
PMID: 26619908  [PubMed - indexed for MEDLINE]


752. Bioinformatics. 2016 Apr 1;32(7):1103-5. doi: 10.1093/bioinformatics/btv700. Epub
2015 Nov 28.

Admix'em: a flexible framework for forward-time simulations of hybrid populations
with selection and mate choice.

Cui R(1), Schumer M(2), Rosenthal GG(3).

Author information: 
(1)Department of Biology, Texas A&M University, College Station, TX 77843, USA,
Centro De Investigaciones Científicas De Las Huastecas "Aguazarca", Calnali,
Mexico and Max Planck Institute for the Biology of Aging, Cologne, Germany.
(2)Centro De Investigaciones Científicas De Las Huastecas "Aguazarca", Calnali,
Mexico and. (3)Department of Biology, Texas A&M University, College Station, TX
77843, USA, Centro De Investigaciones Científicas De Las Huastecas "Aguazarca",
Calnali, Mexico and.

We introduce a new forward-time simulator, Admix'em, that allows for rapid and
realistic simulations of admixed populations with selection. Complex selection
can be achieved through user-defined fitness and mating-preference probability
functions. Users can specify realistic genomic landscapes and model neutral SNPs 
in addition to sites under selection. Admix'em is designed to simulate selection 
in admixed populations but can also be used as a general population simulator.
Usage and examples are in the supplement.AVAILABILITY AND IMPLEMENTATION: C ++
and OpenMP, supports 64-bit Linux/Unix-like platforms.
https://github.com/melop/admixem
CONTACT: rcui@age.mpg.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv700 
PMID: 26615212  [PubMed - in process]


753. Comput Biol Chem. 2015 Dec;59 Pt B:15-31. doi:
10.1016/j.compbiolchem.2015.08.010. Epub 2015 Oct 19.

Network regularised Cox regression and multiplex network models to predict
disease comorbidities and survival of cancer.

Xu H(1), Moni MA(2), Liò P(3).

Author information: 
(1)Computer Laboratory, University of Cambridge, Cambridge CB3 0FD, UK.
Electronic address: hx228@cam.ac.uk. (2)Computer Laboratory, University of
Cambridge, Cambridge CB3 0FD, UK; Bone Biology, Garvan Institute of Medical
Research, Australia. Electronic address: m.moni@garvan.org.au. (3)Computer
Laboratory, University of Cambridge, Cambridge CB3 0FD, UK. Electronic address:
pl219@cam.ac.uk.

In cancer genomics, gene expression levels provide important molecular signatures
for all types of cancer, and this could be very useful for predicting the
survival of cancer patients. However, the main challenge of gene expression data 
analysis is high dimensionality, and microarray is characterised by few number of
samples with large number of genes. To overcome this problem, a variety of
penalised Cox proportional hazard models have been proposed. We introduce a novel
network regularised Cox proportional hazard model and a novel multiplex network
model to measure the disease comorbidities and to predict survival of the cancer 
patient. Our methods are applied to analyse seven microarray cancer gene
expression datasets: breast cancer, ovarian cancer, lung cancer, liver cancer,
renal cancer and osteosarcoma. Firstly, we applied a principal component analysis
to reduce the dimensionality of original gene expression data. Secondly, we
applied a network regularised Cox regression model on the reduced gene expression
datasets. By using normalised mutual information method and multiplex network
model, we predict the comorbidities for the liver cancer based on the integration
of diverse set of omics and clinical data, and we find the diseasome associations
(disease-gene association) among different cancers based on the identified common
significant genes. Finally, we evaluated the precision of the approach with
respect to the accuracy of survival prediction using ROC curves. We report that
colon cancer, liver cancer and renal cancer share the CXCL5 gene, and breast
cancer, ovarian cancer and renal cancer share the CCND2 gene. Our methods are
useful to predict survival of the patient and disease comorbidities more
accurately and helpful for improvement of the care of patients with comorbidity. 
Software in Matlab and R is available on our GitHub page:
https://github.com/ssnhcom/NetworkRegularisedCox.git.

Copyright © 2015. Published by Elsevier Ltd.

DOI: 10.1016/j.compbiolchem.2015.08.010 
PMID: 26611766  [PubMed - indexed for MEDLINE]


754. Bioinformatics. 2016 Apr 1;32(7):1097-9. doi: 10.1093/bioinformatics/btv693. Epub
2015 Nov 24.

Genefu: an R/Bioconductor package for computation of gene expression-based
signatures in breast cancer.

Gendoo DM(1), Ratanasirigulchai N(2), Schröder MS(3), Paré L(4), Parker JS(5),
Prat A(6), Haibe-Kains B(1).

Author information: 
(1)Bioinformatics and Computational Laboratory, Princess Margaret Cancer Centre, 
University Health Network and Department of Medical Biophysics, University of
Toronto, Toronto, ON, Canada. (2)Bioinformatics and Computational Laboratory,
Princess Margaret Cancer Centre, University Health Network and. (3)UCD School of 
Biomolecular and Biomedical Science, Conway Institute, University College Dublin,
Dublin, UK. (4)Translational Genomics and Targeted Therapeutics in Solid Tumors, 
August Pi i Sunyer Biomedical Research Institute (IDIBAPS), 08036 Barcelona,
Spain. (5)Lineberger Comprehensive Cancer Center, University of North Carolina,
Chapel Hill, NC 27599, USA. (6)Translational Genomics and Targeted Therapeutics
in Solid Tumors, August Pi i Sunyer Biomedical Research Institute (IDIBAPS),
08036 Barcelona, Spain, Translational Genomics Group, Vall d'Hebron Institute of 
Oncology (VHIO), 08035 Barcelona, Spain and Department of Medical Oncology,
Hospital Clínic of Barcelona, 08036 Barcelona, Spain.

Breast cancer is one of the most frequent cancers among women. Extensive studies 
into the molecular heterogeneity of breast cancer have produced a plethora of
molecular subtype classification and prognosis prediction algorithms, as well as 
numerous gene expression signatures. However, reimplementation of these
algorithms is a tedious but important task to enable comparison of existing
signatures and classification models between each other and with new models.
Here, we present the genefu R/Bioconductor package, a multi-tiered compendium of 
bioinformatics algorithms and gene signatures for molecular subtyping and
prognostication in breast cancer.AVAILABILITY AND IMPLEMENTATION: The genefu
package is available from Bioconductor.
http://www.bioconductor.org/packages/devel/bioc/html/genefu.html Source code is
also available on Github https://github.com/bhklab/genefu
CONTACT: bhaibeka@uhnresearch.ca
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv693 
PMID: 26607490  [PubMed - in process]


755. PLoS Comput Biol. 2015 Nov 25;11(11):e1004503. doi: 10.1371/journal.pcbi.1004503.
eCollection 2015.

VDJtools: Unifying Post-analysis of T Cell Receptor Repertoires.

Shugay M(1,)(2), Bagaev DV(1), Turchaninova MA(1,)(2), Bolotin DA(1,)(2),
Britanova OV(1,)(2,)(3), Putintseva EV(1,)(2,)(3), Pogorelyy MV(1), Nazarov
VI(1,)(4), Zvyagin IV(1,)(2,)(3), Kirgizova VI(1), Kirgizov KI(5), Skorobogatova 
EV(5), Chudakov DM(1,)(2,)(3).

Author information: 
(1)Shemyakin-Ovchinnikov Institute of bioorganic chemistry RAS, Moscow, Russia.
(2)Pirogov Russian National Research Medical University, Moscow, Russia.
(3)Central European Institute of Technology, Masaryk University, Brno, Czech
Republic. (4)National Research University Higher School of Economics, Moscow,
Russia. (5)Russian Children's Hospital, Moscow, Russia.

Despite the growing number of immune repertoire sequencing studies, the field
still lacks software for analysis and comprehension of this high-dimensional
data. Here we report VDJtools, a complementary software suite that solves a wide 
range of T cell receptor (TCR) repertoires post-analysis tasks, provides a
detailed tabular output and publication-ready graphics, and is built on top of a 
flexible API. Using TCR datasets for a large cohort of unrelated healthy donors, 
twins, and multiple sclerosis patients we demonstrate that VDJtools greatly
facilitates the analysis and leads to sound biological conclusions. VDJtools
software and documentation are available at https://github.com/mikessh/vdjtools.

DOI: 10.1371/journal.pcbi.1004503 
PMCID: PMC4659587
PMID: 26606115  [PubMed - indexed for MEDLINE]


756. Biomed Res Int. 2015;2015:563674. doi: 10.1155/2015/563674. Epub 2015 Oct 28.

Efficient Multicriteria Protein Structure Comparison on Modern Processor
Architectures.

Sharma A(1), Manolakos ES(1).

Author information: 
(1)Department of Informatics and Telecommunications, University of Athens,
Athens, Greece.

Fast increasing computational demand for all-to-all protein structures comparison
(PSC) is a result of three confounding factors: rapidly expanding structural
proteomics databases, high computational complexity of pairwise protein
comparison algorithms, and the trend in the domain towards using multiple
criteria for protein structures comparison (MCPSC) and combining results. We have
developed a software framework that exploits many-core and multicore CPUs to
implement efficient parallel MCPSC in modern processors based on three popular
PSC methods, namely, TMalign, CE, and USM. We evaluate and compare the
performance and efficiency of the two parallel MCPSC implementations using
Intel's experimental many-core Single-Chip Cloud Computer (SCC) as well as
Intel's Core i7 multicore processor. We show that the 48-core SCC is more
efficient than the latest generation Core i7, achieving a speedup factor of 42
(efficiency of 0.9), making many-core processors an exciting emerging technology 
for large-scale structural proteomics. We compare and contrast the performance of
the two processors on several datasets and also show that MCPSC outperforms its
component methods in grouping related domains, achieving a high F-measure of 0.91
on the benchmark CK34 dataset. The software implementation for protein structure 
comparison using the three methods and combined MCPSC, along with the developed
underlying rckskel algorithmic skeletons library, is available via GitHub.

DOI: 10.1155/2015/563674 
PMCID: PMC4641208
PMID: 26605332  [PubMed - indexed for MEDLINE]


757. BMC Bioinformatics. 2015 Nov 19;16:391. doi: 10.1186/s12859-015-0822-7.

An heuristic filtering tool to identify phenotype-associated genetic variants
applied to human intellectual disability and canine coat colors.

Broeckx BJ(1), Coopman F(2), Verhoeven G(3), Bosmans T(4), Gielen I(5),
Dingemanse W(6), Saunders JH(7), Deforce D(8), Van Nieuwerburgh F(9).

Author information: 
(1)Laboratory of Pharmaceutical Biotechnology, Faculty of Pharmaceutical
Sciences, Ghent University, 9000, Ghent, Belgium. Bart.broeckx@ugent.be.
(2)Department of Applied Biosciences, Faculty of Bioscience Engineering, Ghent
University, 9000, Ghent, Belgium. Frank.coopman@ugent.be. (3)Department of
Medical Imaging and Small Animal Orthopaedics, Faculty of Veterinary Medicine,
Ghent University, 9820, Merelbeke, Belgium. Geertverhoeven@hotmail.com.
(4)Department of Medicine and Clinical Biology of Small Animals, Faculty of
Veterinary Medicine, Ghent University, 9820, Merelbeke, Belgium.
Tim.Bosmans@ugent.be. (5)Department of Medical Imaging and Small Animal
Orthopaedics, Faculty of Veterinary Medicine, Ghent University, 9820, Merelbeke, 
Belgium. Ingrid.Gielen@ugent.be. (6)Department of Medical Imaging and Small
Animal Orthopaedics, Faculty of Veterinary Medicine, Ghent University, 9820,
Merelbeke, Belgium. Walter.Dingemanse@ugent.be. (7)Department of Medical Imaging 
and Small Animal Orthopaedics, Faculty of Veterinary Medicine, Ghent University, 
9820, Merelbeke, Belgium. Jimmy.Saunders@ugent.be. (8)Laboratory of
Pharmaceutical Biotechnology, Faculty of Pharmaceutical Sciences, Ghent
University, 9000, Ghent, Belgium. Dieter.Deforce@ugent.be. (9)Laboratory of
Pharmaceutical Biotechnology, Faculty of Pharmaceutical Sciences, Ghent
University, 9000, Ghent, Belgium. Filip.VanNieuwerburgh@UGent.be.

BACKGROUND: Identification of one or several disease causing variant(s) from the 
large collection of variants present in an individual is often achieved by the
sequential use of heuristic filters. The recent development of whole exome
sequencing enrichment designs for several non-model species created the need for 
a species-independent, fast and versatile analysis tool, capable of tackling a
wide variety of standard and more complex inheritance models. With this aim, we
developed "Mendelian", an R-package that can be used for heuristic variant
filtering.
RESULTS: The R-package Mendelian offers fast and convenient filters to analyze
putative variants for both recessive and dominant models of inheritance, with
variable degrees of penetrance and detectance. Analysis of trios is supported.
Filtering against variant databases and annotation of variants is also included. 
This package is not species specific and supports parallel computation. We
validated this package by reanalyzing data from a whole exome sequencing
experiment on intellectual disability in humans. In a second example, we
identified the mutations responsible for coat color in the dog. This is the first
example of whole exome sequencing without prior mapping in the dog.
CONCLUSION: We developed an R-package that enables the identification of
disease-causing variants from the long list of variants called in sequencing
experiments. The software and a detailed manual are available at
https://github.com/BartBroeckx/Mendelian.

DOI: 10.1186/s12859-015-0822-7 
PMCID: PMC4656174
PMID: 26597515  [PubMed - indexed for MEDLINE]


758. Phys Med. 2016 Jan;32(1):255-9. doi: 10.1016/j.ejmp.2015.11.002. Epub 2015 Nov
18.

Spline modelling electron insert factors using routine measurements.

Biggs S(1), Sobolewski M(2), Murry R(3), Kenny J(4).

Author information: 
(1)Riverina Cancer Care Centre, Wagga Wagga, New South Wales 2650, Australia.
Electronic address: mail@simonbiggs.net. (2)Riverina Cancer Care Centre, Wagga
Wagga, New South Wales 2650, Australia. (3)Radiation Oncology Queensland,
Rockville, Queensland 4350, Australia. (4)Epworth Radiation Oncology, Epworth
HealthCare, Richmond, Victoria 3121, Australia.

There are many methods available to predict electron output factors; however,
many centres still measure the factors for each irregular electron field.
Creating an electron output factor prediction model that approaches measurement
accuracy--but uses already available data and is simple to implement--would be
advantageous in the clinical setting. This work presents an empirical spline
model for output factor prediction that requires only the measured factors for
arbitrary insert shapes. Equivalent ellipses of the insert shapes are determined 
and then parameterised by width and ratio of perimeter to area. This takes into
account changes in lateral scatter, bremsstrahlung produced in the insert
material, and scatter from the edge of the insert. Agreement between prediction
and measurement for the 12 MeV validation data had an uncertainty of 0.4% (1SD). 
The maximum recorded deviation between measurement and prediction over the range 
of energies was 1.0%. The validation methodology showed that one may expect an
approximate uncertainty of 0.5% (1SD) when as little as eight data points are
used. The level of accuracy combined with the ease with which this model can be
generated demonstrates its suitability for clinical use. Implementation of this
method is freely available for download at
https://github.com/SimonBiggs/electronfactors.

Copyright © 2015 Associazione Italiana di Fisica Medica. Published by Elsevier
Ltd. All rights reserved.

DOI: 10.1016/j.ejmp.2015.11.002 
PMID: 26596874  [PubMed - indexed for MEDLINE]


759. Bioinformatics. 2016 Feb 15;32(4):599-601. doi: 10.1093/bioinformatics/btv691.
Epub 2015 Nov 20.

ParTIES: a toolbox for Paramecium interspersed DNA elimination studies.

Denby Wilkes C(1), Arnaiz O(1), Sperling L(1).

Author information: 
(1)Institute for Integrative Biology of the Cell (I2BC), CEA, CNRS, Univ.
Paris-Sud, Université Paris-Saclay, 91198, Gif-sur-Yvette cedex, France.

MOTIVATION: Developmental DNA elimination occurs in a wide variety of
multicellular organisms, but ciliates are the only single-celled eukaryotes in
which this phenomenon has been reported. Despite considerable interest in
ciliates as models for DNA elimination, no standard methods for identification
and characterization of the eliminated sequences are currently available.
RESULTS: We present the Paramecium Toolbox for Interspersed DNA Elimination
Studies (ParTIES), designed for Paramecium species, that (i) identifies
eliminated sequences, (ii) measures their presence in a sequencing sample and
(iii) detects rare elimination polymorphisms.
AVAILABILITY AND IMPLEMENTATION: ParTIES is multi-threaded Perl software
available at https://github.com/oarnaiz/ParTIES. ParTIES is distributed under the
GNU General Public Licence v3.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv691 
PMID: 26589276  [PubMed - indexed for MEDLINE]


760. Bioinformatics. 2016 Mar 15;32(6):958-60. doi: 10.1093/bioinformatics/btv687.
Epub 2015 Nov 20.

FoCuS-point: software for STED fluorescence correlation and time-gated single
photon counting.

Waithe D(1), Clausen MP(2), Sezgin E(2), Eggeling C(3).

Author information: 
(1)Wolfson Imaging Centre and. (2)MRC Human Immunology Unit, Weatherall Institute
of Molecular Medicine, University of Oxford, Headley Way, Oxford, OX3 9DS, UK.
(3)Wolfson Imaging Centre and MRC Human Immunology Unit, Weatherall Institute of 
Molecular Medicine, University of Oxford, Headley Way, Oxford, OX3 9DS, UK.

MOTIVATION: Fluorescence Correlation Spectroscopy (FCS) is a popular tool for
measuring molecular mobility and how mobility relates to molecular interaction
dynamics and bioactivity in living cells. The FCS technique has been
significantly advanced by its combination with super-resolution STED microscopy
(STED-FCS). Specifically, the use of gated detection has shown great potential
for enhancing STED-FCS, but has also created a demand for software which is
efficient and also implements the latest algorithms. Prior to this study, no open
software has been available which would allow practical time-gating and
correlation of point data derived from STED-FCS experiments.
RESULTS: The product of this study is a piece of stand-alone software called
FoCuS-point. FoCuS-point utilizes advanced time-correlated single-photon counting
(TCSPC) correlation algorithms along with time-gated filtering and innovative
data visualization. The software has been designed to be highly user-friendly and
is tailored to handle batches of data with tools designed to process files in
bulk. FoCuS-point also includes advanced fitting algorithms which allow the
parameters of the correlation curves and thus the kinetics of diffusion to be
established quickly and efficiently.
AVAILABILITY AND IMPLEMENTATION: FoCuS-point is written in python and is
available through the github repository:
https://github.com/dwaithe/FCS_point_correlator Furthermore, compiled versions of
the code are available as executables which can be run directly in Linux, Windows
and Mac OSX operating systems.
CONTACT: dominic.waithe@imm.ox.ac.uk.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv687 
PMID: 26589275  [PubMed - in process]


761. Bioinformatics. 2016 Mar 15;32(6):949-51. doi: 10.1093/bioinformatics/btv690.
Epub 2015 Nov 20.

LocusExplorer: a user-friendly tool for integrated visualization of human genetic
association data and biological annotations.

Dadaev T(1), Leongamornlert DA(1), Saunders EJ(1), Eeles R(2), Kote-Jarai Z(1).

Author information: 
(1)The Institute of Cancer Research, London, UK and. (2)The Institute of Cancer
Research, London, UK and Royal Marsden NHS Foundation Trust, London, UK.

: In this article, we present LocusExplorer, a data visualization and exploration
tool for genetic association data. LocusExplorer is written in R using the Shiny 
library, providing access to powerful R-based functions through a simple user
interface. LocusExplorer allows users to simultaneously display genetic,
statistical and biological data for humans in a single image and allows dynamic
zooming and customization of the plot features. Publication quality plots may
then be produced in a variety of file formats.AVAILABILITY AND IMPLEMENTATION:
LocusExplorer is open source and runs through R and a web browser. It is
available at www.oncogenetics.icr.ac.uk/LocusExplorer/ or can be installed
locally and the source code accessed from
https://github.com/oncogenetics/LocusExplorer
CONTACT: tokhir.dadaev@icr.ac.uk.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv690 
PMID: 26589274  [PubMed - in process]


762. Source Code Biol Med. 2015 Nov 19;10:14. doi: 10.1186/s13029-015-0042-6.
eCollection 2015.

PyPedia: using the wiki paradigm as crowd sourcing environment for bioinformatics
protocols.

Kanterakis A(1), Kuiper J(2), Potamias G(3), Swertz MA(2).

Author information: 
(1)University of Groningen, University Medical Center Groningen, Genomics
Coordination Center, Postbus 30 001, Groningen, 9700 RB The Netherlands ;
Institute of Computer Science, Foundation for Research and Technology Hellas
(FORTH), Nikolaou Plastira 100, Heraklion, 71110 Greece. (2)University of
Groningen, University Medical Center Groningen, Genomics Coordination Center,
Postbus 30 001, Groningen, 9700 RB The Netherlands. (3)Institute of Computer
Science, Foundation for Research and Technology Hellas (FORTH), Nikolaou Plastira
100, Heraklion, 71110 Greece.

BACKGROUND: Today researchers can choose from many bioinformatics protocols for
all types of life sciences research, computational environments and coding
languages. Although the majority of these are open source, few of them possess
all virtues to maximize reuse and promote reproducible science. Wikipedia has
proven a great tool to disseminate information and enhance collaboration between 
users with varying expertise and background to author qualitative content via
crowdsourcing. However, it remains an open question whether the wiki paradigm can
be applied to bioinformatics protocols.
RESULTS: We piloted PyPedia, a wiki where each article is both implementation and
documentation of a bioinformatics computational protocol in the python language. 
Hyperlinks within the wiki can be used to compose complex workflows and induce
reuse. A RESTful API enables code execution outside the wiki. Initial content of 
PyPedia contains articles for population statistics, bioinformatics format
conversions and genotype imputation. Use of the easy to learn wiki syntax
effectively lowers the barriers to bring expert programmers and less computer
savvy researchers on the same page.
CONCLUSIONS: PyPedia demonstrates how wiki can provide a collaborative
development, sharing and even execution environment for biologists and
bioinformaticians that complement existing resources, useful for local and
multi-center research teams.
AVAILABILITY: PyPedia is available online at: http://www.pypedia.com. The source 
code and installation instructions are available at:
https://github.com/kantale/PyPedia_server. The PyPedia python library is
available at: https://github.com/kantale/pypedia. PyPedia is open-source,
available under the BSD 2-Clause License.

DOI: 10.1186/s13029-015-0042-6 
PMCID: PMC4652372
PMID: 26587054  [PubMed]


763. Bioinformatics. 2016 Mar 15;32(6):893-900. doi: 10.1093/bioinformatics/btv680.
Epub 2015 Nov 17.

Analyzing synergistic and non-synergistic interactions in signalling pathways
using Boolean Nested Effect Models.

Pirkl M(1), Hand E(2), Kube D(2), Spang R(1).

Author information: 
(1)Statistical Bioinformatics Department, Institute of Functional Genomics,
University of Regensburg, 93053 Regensburg and. (2)Department of Haematology and 
Oncology, University Medical Centre of the Georg-August University of Göttingen, 
37073 Göttingen.

MOTIVATION: Understanding the structure and interplay of cellular signalling
pathways is one of the great challenges in molecular biology. Boolean Networks
can infer signalling networks from observations of protein activation. In
situations where it is difficult to assess protein activation directly, Nested
Effect Models are an alternative. They derive the network structure indirectly
from downstream effects of pathway perturbations. To date, Nested Effect Models
cannot resolve signalling details like the formation of signalling complexes or
the activation of proteins by multiple alternative input signals. Here we
introduce Boolean Nested Effect Models (B-NEM). B-NEMs combine the use of
downstream effects with the higher resolution of signalling pathway structures in
Boolean Networks.
RESULTS: We show that B-NEMs accurately reconstruct signal flows in simulated
data. Using B-NEM we then resolve BCR signalling via PI3K and TAK1 kinases in BL2
lymphoma cell lines.
AVAILABILITY AND IMPLEMENTATION: R code is available at
https://github.com/MartinFXP/B-NEM (github). The BCR signalling dataset is
available at the GEO database (http://www.ncbi.nlm.nih.gov/geo/) through
accession number GSE68761.
CONTACT: martin-franz-xaver.pirkl@ukr.de, Rainer.Spang@ukr.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv680 
PMID: 26581413  [PubMed - in process]


764. Source Code Biol Med. 2015 Nov 16;10:12. doi: 10.1186/s13029-015-0044-4.
eCollection 2015.

MOtoNMS: A MATLAB toolbox to process motion data for neuromusculoskeletal
modeling and simulation.

Mantoan A(1), Pizzolato C(2), Sartori M(3), Sawacha Z(4), Cobelli C(4), Reggiani 
M(1).

Author information: 
(1)Department of Management and Engineering, University of Padova, Stradella San 
Nicola, 3, Vicenza, 36100 Italy. (2)Centre for Musculoskeletal Research, Griffith
University, Gold Coast campus, Gold Coast QLD, 4222 Australia. (3)Department of
Neurorehabilitation Engineering, University Medical Center Goettingen,
Georg-August University, Von-Siebold-Str., 6, Goettingen, 37075 Germany.
(4)Department of Information Engineering, University of Padova, Via Gradenigo,
6/b, Padova, 35131 Italy.

BACKGROUND: Neuromusculoskeletal modeling and simulation enable investigation of 
the neuromusculoskeletal system and its role in human movement dynamics. These
methods are progressively introduced into daily clinical practice. However, a
major factor limiting this translation is the lack of robust tools for the
pre-processing of experimental movement data for their use in
neuromusculoskeletal modeling software.
RESULTS: This paper presents MOtoNMS (matlab MOtion data elaboration TOolbox for 
NeuroMusculoSkeletal applications), a toolbox freely available to the community, 
that aims to fill this lack. MOtoNMS processes experimental data from different
motion analysis devices and generates input data for neuromusculoskeletal
modeling and simulation software, such as OpenSim and CEINMS (Calibrated
EMG-Informed NMS Modelling Toolbox). MOtoNMS implements commonly required
processing steps and its generic architecture simplifies the integration of new
user-defined processing components. MOtoNMS allows users to setup their
laboratory configurations and processing procedures through user-friendly
graphical interfaces, without requiring advanced computer skills. Finally,
configuration choices can be stored enabling the full reproduction of the
processing steps. MOtoNMS is released under GNU General Public License and it is 
available at the SimTK website and from the GitHub repository. Motion data
collected at four institutions demonstrate that, despite differences in
laboratory instrumentation and procedures, MOtoNMS succeeds in processing data
and producing consistent inputs for OpenSim and CEINMS.
CONCLUSIONS: MOtoNMS fills the gap between motion analysis and
neuromusculoskeletal modeling and simulation. Its support to several devices, a
complete implementation of the pre-processing procedures, its simple
extensibility, the available user interfaces, and its free availability can boost
the translation of neuromusculoskeletal methods in daily and clinical practice.

DOI: 10.1186/s13029-015-0044-4 
PMCID: PMC4647340
PMID: 26579208  [PubMed]


765. Bioinformatics. 2016 Mar 15;32(6):926-8. doi: 10.1093/bioinformatics/btv676. Epub
2015 Nov 16.

Global copy number profiling of cancer genomes.

Wang X(1), Chen M(2), Yu X(3), Pornputtapong N(4), Chen H(5), Zhang NR(6), Powers
RS(7), Krauthammer M(4).

Author information: 
(1)Department of Family, Population & Preventive Medicine, Stony Brook
University, Stony Brook, NY 11794, USA, Department of Pathology, Yale School of
Medicine, New Haven, CT 06520, USA. (2)Departments of Biostatistics and Genetics,
University of North Carolina, Chapel Hill, NC 27599, USA. (3)Department of
Biostatistics. (4)Program in Computational Biology and Bioinformatics, Yale
University, New Haven, CT 06520, Department of Pathology, Yale School of
Medicine, New Haven, CT 06520, USA. (5)Department of Statistics, University of
California, Davis, CA 9516, USA. (6)Department of Statistics, The Wharton School,
University of Pennsylvania, PA 19104, USA and. (7)Department of Pathology, Stony 
Brook University, Stony Brook, NY 11794, USA.

In this article, we introduce a robust and efficient strategy for deriving global
and allele-specific copy number alternations (CNA) from cancer whole exome
sequencing data based on Log R ratios and B-allele frequencies. Applying the
approach to the analysis of over 200 skin cancer samples, we demonstrate its
utility for discovering distinct CNA events and for deriving ancillary
information such as tumor purity.AVAILABILITY AND IMPLEMENTATION:
https://github.com/xfwang/CLOSE CONTACT: xuefeng.wang@stonybrook.edu or
michael.krauthammer@yale.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv676 
PMCID: PMC4907391 [Available on 2017-03-15]
PMID: 26576652  [PubMed - in process]


766. J Chem Theory Comput. 2015 Oct 13;11(10):4770-9. doi: 10.1021/acs.jctc.5b00662.
Epub 2015 Sep 17.

Grid-based backbone correction to the ff12SB protein force field for
implicit-solvent simulations.

Perez A, MacCallum JL(1), Brini E, Simmerling C, Dill KA.

Author information: 
(1)Department of Chemistry, University of Calgary , Calgary, AB T2N 1N4, Canada.

Force fields, such as Amber's ff12SB, can be fairly accurate models of the
physical forces in proteins and other biomolecules. When coupled with accurate
solvation models, force fields are able to bring insight into the conformational 
preferences, transitions, pathways, and free energies for these biomolecules.
When computational speed/cost matters, implicit solvent is often used but at the 
cost of accuracy. We present an empirical grid-like correction term, in the
spirit of cMAPs, to the combination of the ff12SB protein force field and the
GBneck2 implicit-solvent model. Ff12SB-cMAP is parametrized on experimental
helicity data. We provide validation on a set of peptides and proteins.
Ff12SB-cMAP successfully improves the secondary structure biases observed in
ff12SB + Gbneck2. Ff12SB-cMAP can be downloaded (
https://github.com/laufercenter/Amap.git ) and used within the Amber package. It 
can improve the agreement of force fields + implicit solvent with experiments.

DOI: 10.1021/acs.jctc.5b00662 
PMCID: PMC4813323
PMID: 26574266  [PubMed - indexed for MEDLINE]


767. BMC Bioinformatics. 2015 Nov 16;16:386. doi: 10.1186/s12859-015-0818-3.

misFinder: identify mis-assemblies in an unbiased manner using reference and
paired-end reads.

Zhu X(1,)(2), Leung HC(3), Wang R(4), Chin FY(5), Yiu SM(6), Quan G(7), Li Y(8), 
Zhang R(9), Jiang Q(10), Liu B(11), Dong Y(12), Zhou G(13), Wang Y(14).

Author information: 
(1)College of Computer Sciences and Information Engineering, Harbin Normal
University, Harbin, Heilongjiang, China. zhuxiao.hit@gmail.com. (2)Center for
Bioinformatics, School of Computer Sciences and Technology, Harbin Institute of
Technology, Harbin, Heilongjiang, China. zhuxiao.hit@gmail.com. (3)Department of 
Computer Science, University of Hong Kong, Pokfulam Road, Hong Kong, China.
cmleung2@cs.hku.hk. (4)Center for Bioinformatics, School of Computer Sciences and
Technology, Harbin Institute of Technology, Harbin, Heilongjiang, China.
rjwang.hit@gmail.com. (5)Department of Computer Science, University of Hong Kong,
Pokfulam Road, Hong Kong, China. chin@cs.hku.hk. (6)Department of Computer
Science, University of Hong Kong, Pokfulam Road, Hong Kong, China.
smyiu@cs.hku.hk. (7)Center for Bioinformatics, School of Computer Sciences and
Technology, Harbin Institute of Technology, Harbin, Heilongjiang, China.
grquan@hit.edu.cn. (8)The Fourth Affiliated Hospital of Harbin Medical
University, Harbin, Heilongjiang, China. 148077246@qq.com. (9)The Fourth
Affiliated Hospital of Harbin Medical University, Harbin, Heilongjiang, China.
282661708@qq.com. (10)School of Life Science and Technology, Harbin Institute of 
Technology, Harbin, Heilongjiang, China. qhjiang@hit.edu.cn. (11)Center for
Bioinformatics, School of Computer Sciences and Technology, Harbin Institute of
Technology, Harbin, Heilongjiang, China. bo.liu@hit.edu.cn. (12)Department of
Immunology, Harbin Medical University, Harbin, Heilongjiang, China.
dongyucui521@yeah.net. (13)College of Computer Sciences and Information
Engineering, Harbin Normal University, Harbin, Heilongjiang, China.
zhou_ghui@163.com. (14)Center for Bioinformatics, School of Computer Sciences and
Technology, Harbin Institute of Technology, Harbin, Heilongjiang, China.
ydwang@hit.edu.cn.

BACKGROUND: Because of the short read length of high throughput sequencing data, 
assembly errors are introduced in genome assembly, which may have adverse impact 
to the downstream data analysis. Several tools have been developed to eliminate
these errors by either 1) comparing the assembled sequences with some similar
reference genome, or 2) analyzing paired-end reads aligned to the assembled
sequences and determining inconsistent features alone mis-assembled sequences.
However, the former approach cannot distinguish real structural variations
between the target genome and the reference genome while the latter approach
could have many false positive detections (correctly assembled sequence being
considered as mis-assembled sequence).
RESULTS: We present misFinder, a tool that aims to identify the assembly errors
with high accuracy in an unbiased way and correct these errors at their
mis-assembled positions to improve the assembly accuracy for downstream analysis.
It combines the information of reference (or close related reference) genome and 
aligned paired-end reads to the assembled sequence. Assembly errors and correct
assemblies corresponding to structural variations can be detected by comparing
the genome reference and assembled sequence. Different types of assembly errors
can then be distinguished from the mis-assembled sequence by analyzing the
aligned paired-end reads using multiple features derived from coverage and
consistence of insert distance to obtain high confident error calls.
CONCLUSIONS: We tested the performance of misFinder on both simulated and real
paired-end reads data, and misFinder gave accurate error calls with only very few
miscalls. And, we further compared misFinder with QUAST and REAPR. misFinder
outperformed QUAST and REAPR by 1) identified more true positive mis-assemblies
with very few false positives and false negatives, and 2) distinguished the
correct assemblies corresponding to structural variations from mis-assembled
sequence. misFinder can be freely downloaded from
https://github.com/hitbio/misFinder.

DOI: 10.1186/s12859-015-0818-3 
PMCID: PMC4647709
PMID: 26573684  [PubMed - indexed for MEDLINE]


768. Clin Trials. 2016 Apr;13(2):188-98. doi: 10.1177/1740774515614542. Epub 2015 Nov 
15.

Sample size under the additive hazards model.

McDaniel LS(1), Yu M(2), Chappell R(3).

Author information: 
(1)Biostatistics Program, School of Public Health, Louisiana State University
Health Sciences Center, New Orleans, LA, USA lmcda4@lsuhsc.edu. (2)Department of 
Biostatistics & Medical Informatics, University of Wisconsin-Madison, Madison,
WI, USA. (3)Department of Biostatistics & Medical Informatics, University of
Wisconsin-Madison, Madison, WI, USA Department of Statistics, University of
Wisconsin-Madison, Madison, WI, USA.

BACKGROUND: The additive hazards model can be easier to interpret and in some
cases fits better than the proportional hazards model. However, sample size
formulas for clinical trials with time to event outcomes are currently based on
either the proportional hazards assumption or an assumption of constant hazards.
AIMS: The goal is to provide sample size formulas for superiority and
non-inferiority trials assuming an additive hazards model but no specific
distribution, along with evaluations of the performance of the formulas.
METHODS: Formulas are presented that determine the required sample size for a
given scenario under the additive hazards model. Simulations are conducted to
ensure that the formulas attain the desired power. For illustration, the
non-inferiority sample size formula is applied to the calculations in the SPORTIF
III trial of stroke prevention in atrial fibrillation.
CONCLUSION: Simulation results show that the sample size calculations lead to the
correct power. Sample size is easily calculated using a tool that is available on
the web at http://leemcdaniel.github.io/samplesize.html.

© The Author(s) 2015.

DOI: 10.1177/1740774515614542 
PMCID: PMC4785046 [Available on 2017-04-01]
PMID: 26572562  [PubMed - indexed for MEDLINE]


769. Bioinformatics. 2016 Mar 15;32(6):937-9. doi: 10.1093/bioinformatics/btv664. Epub
2015 Nov 14.

BioPartsBuilder: a synthetic biology tool for combinatorial assembly of
biological parts.

Yang K(1), Stracquadanio G(1), Luo J(2), Boeke JD(2), Bader JS(1).

Author information: 
(1)Department of Biomedical Engineering, Johns Hopkins University, 3400 N.
Charles Street, Baltimore, MD 21218, USA and. (2)Institute for Systems Genetics
and Department of Biochemistry and Molecular Pharmacology, NYU Langone Medical
Center, New York, NY 10016, USA.

Combinatorial assembly of DNA elements is an efficient method for building
large-scale synthetic pathways from standardized, reusable components. These
methods are particularly useful because they enable assembly of multiple DNA
fragments in one reaction, at the cost of requiring that each fragment satisfies 
design constraints. We developed BioPartsBuilder as a biologist-friendly web tool
to design biological parts that are compatible with DNA combinatorial assembly
methods, such as Golden Gate and related methods. It retrieves biological
sequences, enforces compliance with assembly design standards and provides a
fabrication plan for each fragment.AVAILABILITY AND IMPLEMENTATION:
BioPartsBuilder is accessible at http://public.biopartsbuilder.org and an Amazon 
Web Services image is available from the AWS Market Place (AMI ID: ami-508acf38).
Source code is released under the MIT license, and available for download at
https://github.com/baderzone/biopartsbuilder
CONTACT: joel.bader@jhu.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv664 
PMCID: PMC4803390
PMID: 26568632  [PubMed - in process]


770. Bioinformatics. 2016 Mar 15;32(6):821-7. doi: 10.1093/bioinformatics/btv674. Epub
2015 Nov 14.

Accurate estimation of isoelectric point of protein and peptide based on amino
acid sequences.

Audain E(1), Ramos Y(2), Hermjakob H(3), Flower DR(4), Perez-Riverol Y(3).

Author information: 
(1)Department of Proteomics, Center of Molecular Immunology. (2)Department of
Proteomics, Center for Genetic Engineering and Biotechnology, Ciudad de la
Habana, Cuba. (3)Department European Molecular Biology Laboratory, European
Bioinformatics Institute (EMBL-EBI), Wellcome Trust Genome Campus, Hinxton,
Cambridge, CB10 1SD, UK and. (4)School of Life and Health Sciences, Aston
University, Aston Triangle, Birmingham, B4 7ET, UK.

MOTIVATION: In any macromolecular polyprotic system-for example protein, DNA or
RNA-the isoelectric point-commonly referred to as the pI-can be defined as the
point of singularity in a titration curve, corresponding to the solution pH value
at which the net overall surface charge-and thus the electrophoretic mobility-of 
the ampholyte sums to zero. Different modern analytical biochemistry and
proteomics methods depend on the isoelectric point as a principal feature for
protein and peptide characterization. Protein separation by isoelectric point is 
a critical part of 2-D gel electrophoresis, a key precursor of proteomics, where 
discrete spots can be digested in-gel, and proteins subsequently identified by
analytical mass spectrometry. Peptide fractionation according to their pI is also
widely used in current proteomics sample preparation procedures previous to the
LC-MS/MS analysis. Therefore accurate theoretical prediction of pI would expedite
such analysis. While such pI calculation is widely used, it remains largely
untested, motivating our efforts to benchmark pI prediction methods.
RESULTS: Using data from the database PIP-DB and one publically available dataset
as our reference gold standard, we have undertaken the benchmarking of pI
calculation methods. We find that methods vary in their accuracy and are highly
sensitive to the choice of basis set. The machine-learning algorithms, especially
the SVM-based algorithm, showed a superior performance when studying peptide
mixtures. In general, learning-based pI prediction methods (such as Cofactor, SVM
and Branca) require a large training dataset and their resulting performance will
strongly depend of the quality of that data. In contrast with Iterative methods, 
machine-learning algorithms have the advantage of being able to add new features 
to improve the accuracy of prediction.
CONTACT: yperez@ebi.ac.uk
AVAILABILITY AND IMPLEMENTATION: The software and data are freely available at
https://github.com/ypriverol/pIRSupplementary information: Supplementary data are
available at Bioinformatics online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv674 
PMID: 26568629  [PubMed - in process]


771. Bioinformatics. 2016 Jun 1;32(11):1625-31. doi: 10.1093/bioinformatics/btv662.
Epub 2015 Nov 14.

rHAT: fast alignment of noisy long reads with regional hashing.

Liu B(1), Guan D(1), Teng M(1), Wang Y(1).

Author information: 
(1)Center for Bioinformatics, Harbin Institute of Technology, Harbin,
Heilongjiang 150001, China.

MOTIVATION: Single Molecule Real-Time (SMRT) sequencing has been widely applied
in cutting-edge genomic studies. However, it is still an expensive task to align 
the noisy long SMRT reads to reference genome by state-of-the-art aligners, which
is becoming a bottleneck in applications with SMRT sequencing. Novel approach is 
on demand for improving the efficiency and effectiveness of SMRT read alignment.
RESULTS: We propose Regional Hashing-based Alignment Tool (rHAT), a
seed-and-extension-based read alignment approach specifically designed for noisy 
long reads. rHAT indexes reference genome by regional hash table (RHT), a hash
table-based index which describes the short tokens within local windows of
reference genome. In the seeding phase, rHAT utilizes RHT for efficiently
calculating the occurrences of short token matches between partial read and local
genomic windows to find highly possible candidate sites. In the extension phase, 
a sparse dynamic programming-based heuristic approach is used for reducing the
cost of aligning read to the candidate sites. By benchmarking on the real and
simulated datasets from various prokaryote and eukaryote genomes, we demonstrated
that rHAT can effectively align SMRT reads with outstanding throughput.
AVAILABILITY AND IMPLEMENTATION: rHAT is implemented in C++; the source code is
available at https://github.com/HIT-Bioinformatics/rHAT CONTACT:
ydwang@hit.edu.cn
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv662 
PMID: 26568628  [PubMed - in process]


772. Bioinformatics. 2016 Jun 1;32(11):1632-42. doi: 10.1093/bioinformatics/btv670.
Epub 2015 Nov 14.

Optimal seed solver: optimizing seed selection in read mapping.

Xin H(1), Nahar S(1), Zhu R(1), Emmons J(2), Pekhimenko G(1), Kingsford C(3),
Alkan C(4), Mutlu O(5).

Author information: 
(1)Computer Science Department. (2)Department of Computer Science and
Engineering, Washington University, St. Louis, MO 63130, USA. (3)Computational
Biology Department, Carnegie Mellon University, Pittsburgh, PA 15213, USA.
(4)Department of Computer Engineering, Bilkent University, Bilkent, Ankara 06800,
Turkey and. (5)Computer Science Department, Department of Electrical and Computer
Engineering.

MOTIVATION: Optimizing seed selection is an important problem in read mapping.
The number of non-overlapping seeds a mapper selects determines the sensitivity
of the mapper while the total frequency of all selected seeds determines the
speed of the mapper. Modern seed-and-extend mappers usually select seeds with
either an equal and fixed-length scheme or with an inflexible placement scheme,
both of which limit the ability of the mapper in selecting less frequent seeds to
speed up the mapping process. Therefore, it is crucial to develop a new algorithm
that can adjust both the individual seed length and the seed placement, as well
as derive less frequent seeds.
RESULTS: We present the Optimal Seed Solver (OSS), a dynamic programming
algorithm that discovers the least frequently-occurring set of x seeds in an
L-base-pair read in [Formula: see text] operations on average and in [Formula:
see text] operations in the worst case, while generating a maximum of [Formula:
see text] seed frequency database lookups. We compare OSS against four
state-of-the-art seed selection schemes and observe that OSS provides a 3-fold
reduction in average seed frequency over the best previous seed selection
optimizations.
AVAILABILITY AND IMPLEMENTATION: We provide an implementation of the Optimal Seed
Solver in C++ at: https://github.com/CMU-SAFARI/Optimal-Seed-Solver
CONTACT: hxin@cmu.edu, calkan@cs.bilkent.edu.tr or onur@cmu.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv670 
PMID: 26568624  [PubMed - in process]


773. J Proteome Res. 2015 Dec 4;14(12):5088-98. doi: 10.1021/acs.jproteome.5b00658.
Epub 2015 Nov 13.

MassyTools: A High-Throughput Targeted Data Processing Tool for Relative
Quantitation and Quality Control Developed for Glycomic and Glycoproteomic
MALDI-MS.

Jansen BC(1), Reiding KR(1), Bondt A(1,)(2), Hipgrave Ederveen AL(1), Palmblad
M(1), Falck D(1), Wuhrer M(1,)(3).

Author information: 
(1)Center for Proteomics and Metabolomics, Leiden University Medical Center ,
2300 RC Leiden, The Netherlands. (2)Department of Rheumatology, Erasmus
University Medical Center , 3000 CA Rotterdam, The Netherlands. (3)Division of
BioAnalytical Chemistry, VU University Amsterdam , 1081 HV Amsterdam, The
Netherlands.

The study of N-linked glycosylation has long been complicated by a lack of
bioinformatics tools. In particular, there is still a lack of fast and robust
data processing tools for targeted (relative) quantitation. We have developed
modular, high-throughput data processing software, MassyTools, that is capable of
calibrating spectra, extracting data, and performing quality control calculations
based on a user-defined list of glycan or glycopeptide compositions. Typical
examples of output include relative areas after background subtraction, isotopic 
pattern-based quality scores, spectral quality scores, and signal-to-noise
ratios. We demonstrated MassyTools' performance on MALDI-TOF-MS glycan and
glycopeptide data from different samples. MassyTools yielded better calibration
than the commercial software flexAnalysis, generally showing 2-fold better ppm
errors after internal calibration. Relative quantitation using MassyTools and
flexAnalysis gave similar results, yielding a relative standard deviation (RSD)
of the main glycan of ~6%. However, MassyTools yielded 2- to 5-fold lower RSD
values for low-abundant analytes than flexAnalysis. Additionally, feature
curation based on the computed quality criteria improved the data quality. In
conclusion, we show that MassyTools is a robust automated data processing tool
for high-throughput, high-performance glycosylation analysis. The package is
released under the Apache 2.0 license and is freely available on GitHub (
https://github.com/Tarskin/MassyTools ).

DOI: 10.1021/acs.jproteome.5b00658 
PMID: 26565759  [PubMed - indexed for MEDLINE]


774. PLoS One. 2015 Nov 11;10(11):e0142614. doi: 10.1371/journal.pone.0142614.
eCollection 2015.

Efficient In Silico Identification of a Common Insertion in the MAK Gene which
Causes Retinitis Pigmentosa.

Bujakowska KM(1), White J(1), Place E(1), Consugar M(1), Comander J(1).

Author information: 
(1)Ocular Genomics Institute, Massachusetts Eye and Ear Infirmary, Harvard
Medical School, Boston, Massachusetts, United States of America.

BACKGROUND: Next generation sequencing (NGS) offers a rapid and comprehensive
method of screening for mutations associated with retinitis pigmentosa and
related disorders. However, certain sequence alterations such as large insertions
or deletions may remain undetected using standard NGS pipelines. One such
mutation is a recently-identified Alu insertion into the Male Germ
Cell-Associated Kinase (MAK) gene, which is missed by standard NGS-based variant 
callers. Here, we developed an in silico method of searching NGS raw sequence
reads to detect this mutation, without the need to recalculate sequence
alignments or to screen every sample by PCR.
METHODS: The Linux program grep was used to search for a 23 bp "probe" sequence
containing the known junction sequence of the insert. A corresponding search was 
performed with the wildtype sequence. The matching reads were counted and further
compared to the known sequences of the full wildtype and mutant genomic loci.
(See https://github.com/MEEIBioinformaticsCenter/grepsearch.).
RESULTS: In a test sample set consisting of eleven previously published
homozygous mutants, detection of the MAK-Alu insertion was validated with 100%
sensitivity and specificity. As a discovery cohort, raw NGS reads from 1,847
samples (including custom and whole exome selective capture) were searched in ~1 
hour on a local computer cluster, yielding an additional five samples with
MAK-Alu insertions and solving two previously unsolved pedigrees. Of these, one
patient was homozygous for the insertion, one compound heterozygous with a
missense change on the other allele (c. 46G>A; p.Gly16Arg), and three were
heterozygous carriers.
CONCLUSIONS: Using the MAK-Alu grep program proved to be a rapid and effective
method of finding a known, disease-causing Alu insertion in a large cohort of
patients with NGS data. This simple approach avoids wet-lab assays or
computationally expensive algorithms, and could also be used for other known
disease-causing insertions and deletions.

DOI: 10.1371/journal.pone.0142614 
PMCID: PMC4641726
PMID: 26558903  [PubMed - indexed for MEDLINE]


775. J Chem Inf Model. 2015 Nov 23;55(11):2475-84. doi: 10.1021/acs.jcim.5b00544. Epub
2015 Nov 11.

Molecular Rift: Virtual Reality for Drug Designers.

Norrby M(1), Grebner C(1), Eriksson J, Boström J(1).

Author information: 
(1)Department of Medicinal Chemistry, CVMD iMed, AstraZeneca , S-43183 Mölndal,
Sweden.

Recent advances in interaction design have created new ways to use computers. One
example is the ability to create enhanced 3D environments that simulate physical 
presence in the real world--a virtual reality. This is relevant to drug discovery
since molecular models are frequently used to obtain deeper understandings of,
say, ligand-protein complexes. We have developed a tool (Molecular Rift), which
creates a virtual reality environment steered with hand movements. Oculus Rift, a
head-mounted display, is used to create the virtual settings. The program is
controlled by gesture-recognition, using the gaming sensor MS Kinect v2,
eliminating the need for standard input devices. The Open Babel toolkit was
integrated to provide access to powerful cheminformatics functions. Molecular
Rift was developed with a focus on usability, including iterative test-group
evaluations. We conclude with reflections on virtual reality's future
capabilities in chemistry and education. Molecular Rift is open source and can be
downloaded from GitHub.

DOI: 10.1021/acs.jcim.5b00544 
PMID: 26558887  [PubMed - indexed for MEDLINE]


776. BMC Bioinformatics. 2015 Nov 11;16:381. doi: 10.1186/s12859-015-0792-9.

A large scale prediction of bacteriocin gene blocks suggests a wide functional
spectrum for bacteriocins.

Morton JT(1,)(2), Freed SD(3,)(4), Lee SW(5), Friedberg I(6,)(7,)(8).

Author information: 
(1)Department of Computer Science and Software engineering, Miami University,
Oxford, OH, USA. jamietmorton@gmail.com. (2)Department of Computer Science and
Engineering, University of California San Diego, La Jolla, CA USA.
jamietmorton@gmail.com. (3)Eck Institute for Global Health, Department of
Biological Sciences, University of Notre Dame, South Bend, IN, USA.
stefan_freed@nd.edu. (4)Chemistry Biochemistry Biology Interface Program,
University of Notre Dame, South Bend, IN, USA. stefan_freed@nd.edu. (5)Eck
Institute for Global Health, Department of Biological Sciences, University of
Notre Dame, South Bend, IN, USA. shaun_lee@nd.edu. (6)Department of Computer
Science and Software engineering, Miami University, Oxford, OH, USA.
idoerg@iastate.edu. (7)Department of Microbiology, Miami University, Oxford, OH, 
USA. idoerg@iastate.edu. (8)Department of Veterinary Microbiology and Preventive 
Medicine, Iowa State University, Ames, IA, USA. idoerg@iastate.edu.

BACKGROUND: Bacteriocins are peptide-derived molecules produced by bacteria,
whose recently-discovered functions include virulence factors and signaling
molecules as well as their better known roles as antibiotics. To date, close to
five hundred bacteriocins have been identified and classified. Recent discoveries
have shown that bacteriocins are highly diverse and widely distributed among
bacterial species. Given the heterogeneity of bacteriocin compounds, many tools
struggle with identifying novel bacteriocins due to their vast sequence and
structural diversity. Many bacteriocins undergo post-translational processing or 
modifications necessary for the biosynthesis of the final mature form. Enzymatic 
modification of bacteriocins as well as their export is achieved by proteins
whose genes are often located in a discrete gene cluster proximal to the
bacteriocin precursor gene, referred to as context genes in this study. Although 
bacteriocins themselves are structurally diverse, context genes have been shown
to be largely conserved across unrelated species.
METHODS: Using this knowledge, we set out to identify new candidates for context 
genes which may clarify how bacteriocins are synthesized, and identify new
candidates for bacteriocins that bear no sequence similarity to known toxins. To 
achieve these goals, we have developed a software tool, Bacteriocin Operon and
gene block Associator (BOA) that can identify homologous bacteriocin associated
gene blocks and predict novel ones. BOA generates profile Hidden Markov Models
from the clusters of bacteriocin context genes, and uses them to identify novel
bacteriocin gene blocks and operons.
RESULTS AND CONCLUSIONS: We provide a novel dataset of predicted bacteriocins and
context genes. We also discover that several phyla have a strong preference for
bacteriocin genes, suggesting distinct functions for this group of molecules.
SOFTWARE AVAILABILITY: https://github.com/idoerg/BOA.

DOI: 10.1186/s12859-015-0792-9 
PMCID: PMC4642626
PMID: 26558535  [PubMed - indexed for MEDLINE]


777. Bioinformatics. 2016 Apr 1;32(7):1094-6. doi: 10.1093/bioinformatics/btv656. Epub
2015 Nov 9.

Specific identification and quantification of circular RNAs from sequencing data.

Cheng J(1), Metge F(1), Dieterich C(1).

Author information: 
(1)Max Planck Institute for Biology of Ageing, Joseph-Stelzmann-Strasse 9B, 50931
Cologne, Germany.

MOTIVATION: Circular RNAs (circRNAs) are a poorly characterized class of
molecules that have been identified decades ago. Emerging high-throughput
sequencing methods as well as first reports on confirmed functions have sparked
new interest in this RNA species. However, the computational detection and
quantification tools are still limited.
RESULTS: We developed the software tandem, DCC and CircTest DCC uses output from 
the STAR read mapper to systematically detect back-splice junctions in
next-generation sequencing data. DCC applies a series of filters and integrates
data across replicate sets to arrive at a precise list of circRNA candidates. We 
assessed the detection performance of DCC on a newly generated mouse brain data
set and publicly available sequencing data. Our software achieves a much higher
precision than state-of-the-art competitors at similar sensitivity levels.
Moreover, DCC estimates circRNA versus host gene expression from counting
junction and non-junction reads. These read counts are finally used to test for
host gene-independence of circRNA expression across different experimental
conditions by our R package CircTest We demonstrate the benefits of this approach
on previously reported age-dependent circRNAs in the fruit fly.
AVAILABILITY AND IMPLEMENTATION: The source code of DCC and CircTest is licensed 
under the GNU General Public Licence (GPL) version 3 and available from
https://github.com/dieterich-lab/[DCC or CircTest].
CONTACT: christoph.dieterich@age.mpg.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv656 
PMID: 26556385  [PubMed - in process]


778. Bioinformatics. 2016 Mar 1;32(5):764-6. doi: 10.1093/bioinformatics/btv658. Epub 
2015 Nov 10.

Realtime analysis and visualization of MinION sequencing data with npReader.

Cao MD(1), Ganesamoorthy D(1), Cooper MA(1), Coin LJ(2).

Author information: 
(1)Institute for Molecular Bioscience, The University of Queensland, Brisbane,
QLD, Australia and. (2)Institute for Molecular Bioscience, The University of
Queensland, Brisbane, QLD, Australia and Department of Genomics of Common
Disease, Imperial College London, London W12 0NN, UK.

MOTIVATION: The recently released Oxford Nanopore MinION sequencing platform
presents many innovative features opening up potential for a range of
applications not previously possible. Among these features, the ability to
sequence in real-time provides a unique opportunity for many time-critical
applications. While many software packages have been developed to analyze its
data, there is still a lack of toolkits that support the streaming and real-time 
analysis of MinION sequencing data.
RESULTS: We developed npReader, an open-source software package to facilitate
real-time analysis of MinION sequencing data. npReader can simultaneously extract
sequence reads and stream them to downstream analysis pipelines while the samples
are being sequenced on the MinION device. It provides a command line interface
for easy integration into a bioinformatics work flow, as well as a graphical user
interface which concurrently displays the statistics of the run. It also provides
an application programming interface for development of streaming algorithms in
order to fully utilize the extent of nanopore sequencing potential.
AVAILABILITY AND IMPLEMENTATION: npReader is written in Java and is freely
available at https://github.com/mdcao/npReader
CONTACT: m.cao1@uq.edu.au or l.coin@imb.uq.edu.au.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv658 
PMID: 26556383  [PubMed - in process]


779. PLoS One. 2015 Nov 10;10(11):e0137859. doi: 10.1371/journal.pone.0137859.
eCollection 2015.

RNA Thermodynamic Structural Entropy.

Garcia-Martin JA(1), Clote P(1).

Author information: 
(1)Department of Biology, Boston College, Chestnut Hill, MA 02467, United States 
of America.

Conformational entropy for atomic-level, three dimensional biomolecules is known 
experimentally to play an important role in protein-ligand discrimination, yet
reliable computation of entropy remains a difficult problem. Here we describe the
first two accurate and efficient algorithms to compute the conformational entropy
for RNA secondary structures, with respect to the Turner energy model, where free
energy parameters are determined from UV absorption experiments. An algorithm to 
compute the derivational entropy for RNA secondary structures had previously been
introduced, using stochastic context free grammars (SCFGs). However, the
numerical value of derivational entropy depends heavily on the chosen context
free grammar and on the training set used to estimate rule probabilities. Using
data from the Rfam database, we determine that both of our thermodynamic methods,
which agree in numerical value, are substantially faster than the SCFG method.
Thermodynamic structural entropy is much smaller than derivational entropy, and
the correlation between length-normalized thermodynamic entropy and derivational 
entropy is moderately weak to poor. In applications, we plot the structural
entropy as a function of temperature for known thermoswitches, such as the
repression of heat shock gene expression (ROSE) element, we determine that the
correlation between hammerhead ribozyme cleavage activity and total free energy
is improved by including an additional free energy term arising from
conformational entropy, and we plot the structural entropy of windows of the
HIV-1 genome. Our software RNAentropy can compute structural entropy for any
user-specified temperature, and supports both the Turner'99 and Turner'04 energy 
parameters. It follows that RNAentropy is state-of-the-art software to compute
RNA secondary structure conformational entropy. Source code is available at
https://github.com/clotelab/RNAentropy/; a full web server is available at
http://bioinformatics.bc.edu/clotelab/RNAentropy, including source code and
ancillary programs.

DOI: 10.1371/journal.pone.0137859 
PMCID: PMC4640541
PMID: 26555444  [PubMed - indexed for MEDLINE]


780. BMC Bioinformatics. 2015 Nov 9;16:374. doi: 10.1186/s12859-015-0795-6.

TOGGLE: toolbox for generic NGS analyses.

Monat C(1), Tranchant-Dubreuil C(2), Kougbeadjo A(3), Farcy C(4), Ortega-Abboud
E(5), Amanzougarene S(6), Ravel S(7), Agbessi M(8), Orjuela-Bouniol J(9), Summo
M(10), Sabot F(11).

Author information: 
(1)UMR DIADE IRD/UM, 911 Avenue Agropolis, Montpellier Cedex 5, F-34934, France. 
cecile.monat@ird.fr. (2)UMR DIADE IRD/UM, 911 Avenue Agropolis, Montpellier Cedex
5, F-34934, France. christine.tranchant@ird.fr. (3)UMR AGAP CIRAD/INRA/SupAgro,
TA A-108/03 - Avenue Agropolis, Montpellier Cedex 5, F-34398, France.
ayite.kougbeadjo@cirad.fr. (4)UMR AGAP CIRAD/INRA/SupAgro, TA A-108/03 - Avenue
Agropolis, Montpellier Cedex 5, F-34398, France. cedric.farcy@cirad.fr. (5)UMR
AGAP CIRAD/INRA/SupAgro, TA A-108/03 - Avenue Agropolis, Montpellier Cedex 5,
F-34398, France. enrique.ortega-abboud@cirad.fr. (6)UMR DIADE IRD/UM, 911 Avenue 
Agropolis, Montpellier Cedex 5, F-34934, France. souhila.amanzougarene@ird.fr.
(7)UMR-BGPI CIRAD TA A-54/K, Campus International de Baillarguet, Montpellier
Cedex 5, F-34398, France. sebastien.ravel@cirad.fr. (8)UMR DIADE IRD/UM, 911
Avenue Agropolis, Montpellier Cedex 5, F-34934, France. mawusse.agbessi@ird.fr.
(9)ADNid, Cap Alpha, Avenue de l'Europe, Clapiers, F-34830, France.
julie.orjuela@adnid.fr. (10)UMR AGAP CIRAD/INRA/SupAgro, TA A-108/03 - Avenue
Agropolis, Montpellier Cedex 5, F-34398, France. maryline.summo@cirad.fr. (11)UMR
DIADE IRD/UM, 911 Avenue Agropolis, Montpellier Cedex 5, F-34934, France.
francois.sabot@ird.fr.

BACKGROUND: The explosion of NGS (Next Generation Sequencing) sequence data
requires a huge effort in Bioinformatics methods and analyses. The creation of
dedicated, robust and reliable pipelines able to handle dozens of samples from
raw FASTQ data to relevant biological data is a time-consuming task in all
projects relying on NGS. To address this, we created a generic and modular
toolbox for developing such pipelines.
RESULTS: TOGGLE (TOolbox for Generic nGs anaLysEs) is a suite of tools able to
design pipelines that manage large sets of NGS softwares and utilities. Moreover,
TOGGLE offers an easy way to manipulate the various options of the different
softwares through the pipelines in using a single basic configuration file, which
can be changed for each assay without having to change the code itself. We also
describe one implementation of TOGGLE in a complete analysis pipeline designed
for SNP discovery for large sets of genomic data, ready to use in different
environments (from a single machine to HPC clusters).
CONCLUSION: TOGGLE speeds up the creation of robust pipelines with reliable log
tracking and data flow, for a large range of analyses. Moreover, it enables
Biologists to concentrate on the biological relevance of results, and change the 
experimental conditions easily. The whole code and test data are available at
https://github.com/SouthGreenPlatform/TOGGLE .

DOI: 10.1186/s12859-015-0795-6 
PMCID: PMC4640241
PMID: 26552596  [PubMed - indexed for MEDLINE]


781. Nat Methods. 2016 Jan;13(1):63-5. doi: 10.1038/nmeth.3654. Epub 2015 Nov 9.

Efficient genotype compression and analysis of large genetic-variation data sets.

Layer RM(1), Kindlon N(1), Karczewski KJ(2); Exome Aggregation Consortium,
Quinlan AR(1,)(3,)(4).

Author information: 
(1)Department of Human Genetics, University of Utah, Salt Lake City, Utah, USA.
(2)Analytical and Translational Genetics Unit, Harvard Medical School, Boston,
Massachusetts, USA. (3)Department of Biomedical Informatics, University of Utah, 
Salt Lake City, Utah, USA. (4)USTAR Center for Genetic Discovery, University of
Utah, Salt Lake City, Utah, USA.

Genotype Query Tools (GQT) is an indexing strategy that expedites analyses of
genome-variation data sets in Variant Call Format based on sample genotypes,
phenotypes and relationships. GQT's compressed genotype index minimizes
decompression for analysis, and its performance relative to that of existing
methods improves with cohort size. We show substantial (up to 443-fold) gains in 
performance over existing methods and demonstrate GQT's utility for exploring
massive data sets involving thousands to millions of genomes. GQT can be accessed
at https://github.com/ryanlayer/gqt.

DOI: 10.1038/nmeth.3654 
PMCID: PMC4697868
PMID: 26550772  [PubMed - indexed for MEDLINE]


782. J Chem Inf Model. 2015 Dec 28;55(12):2519-27. doi: 10.1021/acs.jcim.5b00376. Epub
2015 Dec 10.

Mining Discriminative Patterns from Graph Data with Multiple Labels and Its
Application to Quantitative Structure-Activity Relationship (QSAR) Models.

Shao Z(1), Hirayama Y(1), Yamanishi Y(2,)(3), Saigo H(1).

Author information: 
(1)Department of Bioscience and Bioinformatics, Kyushu Institute of Technology , 
Iizuka, Fukuoka 820-8502, Japan. (2)Division of System Cohort, Multi-Scale
Research Center for Medical Science, Medical Institute of Bioregulation, Kyushu
University , 3-1-1 Maidashi, Higashi-ku, Fukuoka 812-8582, Japan. (3)Institute
for Advanced Study, Kyushu University , 6-10-1 Hakozaki, Higashi-ku, Fukuoka
812-8581, Japan.

Graph data are becoming increasingly common in machine learning and data mining, 
and its application field pervades to bioinformatics and cheminformatics.
Accordingly, as a method to extract patterns from graph data, graph mining
recently has been studied and developed rapidly. Since the number of patterns in 
graph data is huge, a central issue is how to efficiently collect informative
patterns suitable for subsequent tasks such as classification or regression. In
this paper, we consider mining discriminative subgraphs from graph data with
multiple labels. The resulting task has important applications in
cheminformatics, such as finding common functional groups that trigger multiple
drug side effects, or identifying ligand functional groups that hit multiple
targets. In computational experiments, we first verify the effectiveness of the
proposed approach in synthetic data, then we apply it to drug adverse effect
prediction problem. In the latter dataset, we compared the proposed method with
L1-norm logistic regression in combination with the PubChem/Open Babel
fingerprint, in that the proposed method showed superior performance with a much 
smaller number of subgraph patterns. Software is available from
https://github.com/axot/GLP.

DOI: 10.1021/acs.jcim.5b00376 
PMID: 26549421  [PubMed - indexed for MEDLINE]


783. Anal Chim Acta. 2015 Oct 29;899:1-12. doi: 10.1016/j.aca.2015.06.042. Epub 2015
Aug 7.

Regularized MANOVA (rMANOVA) in untargeted metabolomics.

Engel J(1), Blanchet L(2), Bloemen B(3), van den Heuvel LP(4), Engelke UH(4),
Wevers RA(4), Buydens LM(5).

Author information: 
(1)Radboud University Nijmegen, Institute for Molecules and Materials,
Heyendaalseweg 135, Nijmegen, The Netherlands; Translational Metabolic Laboratory
at the Department of Laboratory Medicine, Radboud University Medical Centre,
Geert Grooteplein 10, Nijmegen, The Netherlands. (2)Radboud University Nijmegen, 
Institute for Molecules and Materials, Heyendaalseweg 135, Nijmegen, The
Netherlands; Department of Biochemistry, Nijmegen Centre for Molecular Life
Sciences, Radboud University Medical Centre, Geert Grooteplein 10, Nijmegen, The 
Netherlands. (3)Radboud University Nijmegen, Institute for Molecules and
Materials, Heyendaalseweg 135, Nijmegen, The Netherlands. (4)Translational
Metabolic Laboratory at the Department of Laboratory Medicine, Radboud University
Medical Centre, Geert Grooteplein 10, Nijmegen, The Netherlands. (5)Radboud
University Nijmegen, Institute for Molecules and Materials, Heyendaalseweg 135,
Nijmegen, The Netherlands. Electronic address: l.buydens@science.ru.nl.

Many advanced metabolomics experiments currently lead to data where a large
number of response variables were measured while one or several factors were
changed. Often the number of response variables vastly exceeds the sample size
and well-established techniques such as multivariate analysis of variance
(MANOVA) cannot be used to analyze the data. ANOVA simultaneous component
analysis (ASCA) is an alternative to MANOVA for analysis of metabolomics data
from an experimental design. In this paper, we show that ASCA assumes that none
of the metabolites are correlated and that they all have the same variance.
Because of these assumptions, ASCA may relate the wrong variables to a factor.
This reduces the power of the method and hampers interpretation. We propose an
improved model that is essentially a weighted average of the ASCA and MANOVA
models. The optimal weight is determined in a data-driven fashion. Compared to
ASCA, this method assumes that variables can correlate, leading to a more
realistic view of the data. Compared to MANOVA, the model is also applicable when
the number of samples is (much) smaller than the number of variables. These
advantages are demonstrated by means of simulated and real data examples. The
source code of the method is available from the first author upon request, and at
the following github repository: https://github.com/JasperE/regularized-MANOVA.

Copyright © 2015 Elsevier B.V. All rights reserved.

DOI: 10.1016/j.aca.2015.06.042 
PMID: 26547490  [PubMed - indexed for MEDLINE]


784. BMC Bioinformatics. 2015 Nov 6;16:372. doi: 10.1186/s12859-015-0808-5.

Practical impacts of genomic data "cleaning" on biological discovery using
surrogate variable analysis.

Jaffe AE(1,)(2), Hyde T(3,)(4,)(5), Kleinman J(6,)(7), Weinbergern
DR(8,)(9,)(10,)(11,)(12), Chenoweth JG(13), McKay RD(14), Leek JT(15), Colantuoni
C(16,)(17,)(18).

Author information: 
(1)Lieber Institute for Brain Development, 855 N Wolfe St, Ste 300, Baltimore,
MD, 21205, USA. andrew.jaffe@libd.org. (2)Department of Biostatistics, Johns
Hopkins Bloomberg School of Public Health, 615 N Wolfe St, Baltimore, MD, 21205, 
USA. andrew.jaffe@libd.org. (3)Lieber Institute for Brain Development, 855 N
Wolfe St, Ste 300, Baltimore, MD, 21205, USA. Thomas.Hyde@libd.org. (4)Department
of Neurology, Johns Hopkins School of Medicine, Baltimore, MD, 21205, USA.
Thomas.Hyde@libd.org. (5)Department of Psychiatry, Johns Hopkins School of
Medicine, Baltimor, MD, 21205, USA. Thomas.Hyde@libd.org. (6)Lieber Institute for
Brain Development, 855 N Wolfe St, Ste 300, Baltimore, MD, 21205, USA.
Joel.Kleinman@libd.org. (7)Department of Neurology, Johns Hopkins School of
Medicine, Baltimore, MD, 21205, USA. Joel.Kleinman@libd.org. (8)Lieber Institute 
for Brain Development, 855 N Wolfe St, Ste 300, Baltimore, MD, 21205, USA.
drweinberger@libd.org. (9)Department of Neurology, Johns Hopkins School of
Medicine, Baltimore, MD, 21205, USA. drweinberger@libd.org. (10)Department of
Psychiatry, Johns Hopkins School of Medicine, Baltimor, MD, 21205, USA.
drweinberger@libd.org. (11)Department of Neuroscience, Johns Hopkins School of
Medicine, Baltimore, Maryland, 21205, USA. drweinberger@libd.org.
(12)McKusick-Nathans Institute of Genetic Medicine, Johns Hopkins School of
Medicine, Baltimore, Maryland, 21205, USA. drweinberger@libd.org. (13)Lieber
Institute for Brain Development, 855 N Wolfe St, Ste 300, Baltimore, MD, 21205,
USA. josh.chenoweth@libd.org. (14)Lieber Institute for Brain Development, 855 N
Wolfe St, Ste 300, Baltimore, MD, 21205, USA. ronald.mckay@libd.org.
(15)Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health,
615 N Wolfe St, Baltimore, MD, 21205, USA. ljeek@jhsph.edu. (16)Lieber Institute 
for Brain Development, 855 N Wolfe St, Ste 300, Baltimore, MD, 21205, USA.
carlo.colantuoni@libd.org. (17)Department of Neurology, Johns Hopkins School of
Medicine, Baltimore, MD, 21205, USA. carlo.colantuoni@libd.org. (18)Department of
Neuroscience, Johns Hopkins School of Medicine, Baltimore, Maryland, 21205, USA. 
carlo.colantuoni@libd.org.

Erratum in
    BMC Bioinformatics. 2016;17:302.

BACKGROUND: Genomic data production is at its highest level and continues to
increase, making available novel primary data and existing public data to
researchers for exploration. Here we explore the consequences of "batch"
correction for biological discovery in two publicly available expression
datasets. We consider this to include the estimation of and adjustment for
wide-spread systematic heterogeneity in genomic measurements that is unrelated to
the effects under study, whether it be technical or biological in nature.
METHODS: We present three illustrative data analyses using surrogate variable
analysis (SVA) and describe how to perform artifact discovery in light of natural
heterogeneity within biological groups, secondary biological questions of
interest, and non-linear treatment effects in a dataset profiling differentiating
pluripotent cells (GSE32923) and another from human brain tissue (GSE30272).
RESULTS: Careful specification of biological effects of interest is very
important to factor-based approaches like SVA. We demonstrate greatly sharpened
global and gene-specific differential expression across treatment groups in stem 
cell systems. Similarly, we demonstrate how to preserve major non-linear effects 
of age across the lifespan in the brain dataset. However, the gains in precisely 
defining known effects of interest come at the cost of much other information in 
the "cleaned" data, including sex, common copy number effects and sample or cell 
line-specific molecular behavior.
CONCLUSIONS: Our analyses indicate that data "cleaning" can be an important
component of high-throughput genomic data analysis when interrogating explicitly 
defined effects in the context of data affected by robust technical artifacts.
However, caution should be exercised to avoid removing biological signal of
interest. It is also important to note that open data exploration is not possible
after such supervised "cleaning", because effects beyond those stipulated by the 
researcher may have been removed. With the goal of making these statistical
algorithms more powerful and transparent to researchers in the biological
sciences, we provide exploratory plots and accompanying R code for identifying
and guiding "cleaning" process (https://github.com/andrewejaffe/StemCellSVA). The
impact of these methods is significant enough that we have made newly processed
data available for the brain data set at http://braincloud.jhmi.edu/plots/ and
GSE30272.

DOI: 10.1186/s12859-015-0808-5 
PMCID: PMC4636836
PMID: 26545828  [PubMed - indexed for MEDLINE]


785. Bioinformatics. 2016 Mar 1;32(5):738-46. doi: 10.1093/bioinformatics/btv653. Epub
2015 Nov 5.

Evaluation of hierarchical models for integrative genomic analyses.

Denis M(1), Tadesse MG(2).

Author information: 
(1)UMR AGAP, CIRAD, Montpellier, France, Department of Epidemiology, Harvard
School of Public Health, Boston, MA, USA and. (2)Department of Mathematics and
Statistics, Georgetown University, Washington, DC, USA.

MOTIVATION: Advances in high-throughput technologies have led to the acquisition 
of various types of -omic data on the same biological samples. Each data type
gives independent and complementary information that can explain the biological
mechanisms of interest. While several studies performing independent analyses of 
each dataset have led to significant results, a better understanding of complex
biological mechanisms requires an integrative analysis of different sources of
data.
RESULTS: Flexible modeling approaches, based on penalized likelihood methods and 
expectation-maximization (EM) algorithms, are studied and tested under various
biological relationship scenarios between the different molecular features and
their effects on a clinical outcome. The models are applied to genomic datasets
from two cancer types in the Cancer Genome Atlas project: glioblastoma multiforme
and ovarian serous cystadenocarcinoma. The integrative models lead to improved
model fit and predictive performance. They also provide a better understanding of
the biological mechanisms underlying patients' survival.
AVAILABILITY AND IMPLEMENTATION: Source code implementing the integrative models 
is freely available at https://github.com/mgt000/IntegrativeAnalysis along with
example datasets and sample R script applying the models to these data. The TCGA 
datasets used for analysis are publicly available at
https://tcga-data.nci.nih.gov/tcga/tcgaDownload.jsp
CONTACT: marie.denis@cirad.fr or mgt26@georgetown.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv653 
PMID: 26545823  [PubMed - in process]


786. Bioinformatics. 2016 Mar 1;32(5):657-63. doi: 10.1093/bioinformatics/btv654. Epub
2015 Nov 5.

Comparison of genetic variants in matched samples using thesaurus annotation.

Konopka T(1), Nijman SM(1).

Author information: 
(1)Ludwig Institute for Cancer Research, University of Oxford, Oxford, UK.

MOTIVATION: Calling changes in DNA, e.g. as a result of somatic events in cancer,
requires analysis of multiple matched sequenced samples. Events in
low-mappability regions of the human genome are difficult to encode in variant
call files and have been under-reported as a result. However, they can be
described accurately through thesaurus annotation-a technique that links multiple
genomic loci together to explicate a single variant.
RESULTS: We here describe software and benchmarks for using thesaurus annotation 
to detect point changes in DNA from matched samples. In benchmarks on matched
normal/tumor samples we show that the technique can recover between five and ten 
percent more true events than conventional approaches, while strictly limiting
false discovery and being fully consistent with popular variant analysis
workflows. We also demonstrate the utility of the approach for analysis of de
novo mutations in parents/child families.
AVAILABILITY AND IMPLEMENTATION: Software performing thesaurus annotation is
implemented in java; available in source code on github at GeneticThesaurus
(https://github.com/tkonopka/GeneticThesaurus) and as an executable on
sourceforge at geneticthesaurus
(https://sourceforge.net/projects/geneticthesaurus). Mutation calling is
implemented in an R package available on github at RGeneticThesaurus
(https://github.com/tkonopka/RGeneticThesaurus).
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.
CONTACT: tomasz.konopka@ludwig.ox.ac.uk.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv654 
PMCID: PMC4795618
PMID: 26545822  [PubMed - in process]


787. Bioinformatics. 2016 Mar 1;32(5):641-9. doi: 10.1093/bioinformatics/btv643. Epub 
2015 Nov 5.

De novo identification of replication-timing domains in the human genome by deep 
learning.

Liu F(1), Ren C(1), Li H(1), Zhou P(2), Bo X(1), Shu W(1).

Author information: 
(1)Department of Biotechnology, Beijing Institute of Radiation Medicine and.
(2)Department of Radiation Toxicology and Oncology, Beijing Institute of
Radiation Medicine, Beijing 100850, China.

MOTIVATION: The de novo identification of the initiation and termination
zones-regions that replicate earlier or later than their upstream and downstream 
neighbours, respectively-remains a key challenge in DNA replication.
RESULTS: Building on advances in deep learning, we developed a novel hybrid
architecture combining a pre-trained, deep neural network and a hidden Markov
model (DNN-HMM) for the de novo identification of replication domains using
replication timing profiles. Our results demonstrate that DNN-HMM can
significantly outperform strong, discriminatively trained Gaussian mixture
model-HMM (GMM-HMM) systems and other six reported methods that can be applied to
this challenge. We applied our trained DNN-HMM to identify distinct replication
domain types, namely the early replication domain (ERD), the down transition zone
(DTZ), the late replication domain (LRD) and the up transition zone (UTZ), using 
newly replicated DNA sequencing (Repli-Seq) data across 15 human cells. A
subsequent integrative analysis revealed that these replication domains harbour
unique genomic and epigenetic patterns, transcriptional activity and higher-order
chromosomal structure. Our findings support the 'replication-domain' model, which
states (1) that ERDs and LRDs, connected by UTZs and DTZs, are spatially
compartmentalized structural and functional units of higher-order chromosomal
structure, (2) that the adjacent DTZ-UTZ pairs form chromatin loops and (3) that 
intra-interactions within ERDs and LRDs tend to be short-range and long-range,
respectively. Our model reveals an important chromatin organizational principle
of the human genome and represents a critical step towards understanding the
mechanisms regulating replication timing.
AVAILABILITY AND IMPLEMENTATION: Our DNN-HMM method and three additional
algorithms can be freely accessed at https://github.com/wenjiegroup/DNN-HMM The
replication domain regions identified in this study are available in GEO under
the accession ID GSE53984.
CONTACT: shuwj@bmi.ac.cn or boxc@bmi.ac.cn
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv643 
PMCID: PMC4795613
PMID: 26545821  [PubMed - in process]


788. Mol Cell Proteomics. 2016 Jan;15(1):305-17. doi: 10.1074/mcp.O115.050229. Epub
2015 Nov 6.

PRIDE Inspector Toolsuite: Moving Toward a Universal Visualization Tool for
Proteomics Data Standard Formats and Quality Assessment of ProteomeXchange
Datasets.

Perez-Riverol Y(1), Xu QW(1), Wang R(1), Uszkoreit J(2), Griss J(3), Sanchez
A(4), Reisinger F(1), Csordas A(1), Ternent T(1), Del-Toro N(1), Dianes JA(1),
Eisenacher M(2), Hermjakob H(1), Vizcaíno JA(5).

Author information: 
(1)From the ‡European Molecular Biology Laboratory, European Bioinformatics
Institute (EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1SD,
UK; (2)§Ruhr-Universität Bochum, Medizinisches Proteom-Zenter, Medical
Bioinformatics, ZKF, E.142, Universitätsstr. 150, D-44801 Bochum, Germany;
(3)From the ‡European Molecular Biology Laboratory, European Bioinformatics
Institute (EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1SD,
UK; ¶Division of Immunology, Allergy and Infectious Diseases, Department of
Dermatology, Medical University of Vienna, Austria; (4)‖Department of Proteomics,
Center for Genetic Engineering and Biotechnology, Ciudad de la Habana, Cuba.
(5)From the ‡European Molecular Biology Laboratory, European Bioinformatics
Institute (EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1SD,
UK; juan@ebi.ac.uk.

The original PRIDE Inspector tool was developed as an open source standalone tool
to enable the visualization and validation of mass-spectrometry (MS)-based
proteomics data before data submission or already publicly available in the
Proteomics Identifications (PRIDE) database. The initial implementation of the
tool focused on visualizing PRIDE data by supporting the PRIDE XML format and a
direct access to private (password protected) and public experiments in PRIDE.The
ProteomeXchange (PX) Consortium has been set up to enable a better integration of
existing public proteomics repositories, maximizing its benefit to the scientific
community through the implementation of standard submission and dissemination
pipelines. Within the Consortium, PRIDE is focused on supporting submissions of
tandem MS data. The increasing use and popularity of the new Proteomics Standards
Initiative (PSI) data standards such as mzIdentML and mzTab, and the diversity of
workflows supported by the PX resources, prompted us to design and implement a
new suite of algorithms and libraries that would build upon the success of the
original PRIDE Inspector and would enable users to visualize and validate PX
"complete" submissions. The PRIDE Inspector Toolsuite supports the handling and
visualization of different experimental output files, ranging from spectra (mzML,
mzXML, and the most popular peak lists formats) and peptide and protein
identification results (mzIdentML, PRIDE XML, mzTab) to quantification data
(mzTab, PRIDE XML), using a modular and extensible set of open-source,
cross-platform libraries. We believe that the PRIDE Inspector Toolsuite
represents a milestone in the visualization and quality assessment of proteomics 
data. It is freely available at http://github.com/PRIDE-Toolsuite/.

© 2016 by The American Society for Biochemistry and Molecular Biology, Inc.

DOI: 10.1074/mcp.O115.050229 
PMCID: PMC4762524
PMID: 26545397  [PubMed - indexed for MEDLINE]


789. Bioinformatics. 2016 Mar 1;32(5):755-63. doi: 10.1093/bioinformatics/btv648. Epub
2015 Nov 4.

Shape component analysis: structure-preserving dimension reduction on biological 
shape spaces.

Lee HC(1), Liao T(2), Zhang YJ(3), Yang G(4).

Author information: 
(1)Department of Biomedical Engineering. (2)Department of Mechanical Engineering,
and. (3)Department of Biomedical Engineering, Department of Mechanical
Engineering, and. (4)Department of Biomedical Engineering, Department of
Computational Biology, Carnegie Mellon University, Pittsburgh, PA 15213, USA.

MOTIVATION: Quantitative shape analysis is required by a wide range of biological
studies across diverse scales, ranging from molecules to cells and organisms. In 
particular, high-throughput and systems-level studies of biological structures
and functions have started to produce large volumes of complex high-dimensional
shape data. Analysis and understanding of high-dimensional biological shape data 
require dimension-reduction techniques.
RESULTS: We have developed a technique for non-linear dimension reduction of 2D
and 3D biological shape representations on their Riemannian spaces. A key feature
of this technique is that it preserves distances between different shapes in an
embedded low-dimensional shape space. We demonstrate an application of this
technique by combining it with non-linear mean-shift clustering on the Riemannian
spaces for unsupervised clustering of shapes of cellular organelles and proteins.
AVAILABILITY AND IMPLEMENTATION: Source code and data for reproducing results of 
this article are freely available at
https://github.com/ccdlcmu/shape_component_analysis_Matlab The implementation was
made in MATLAB and supported on MS Windows, Linux and Mac OS.
CONTACT: geyang@andrew.cmu.edu.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv648 
PMID: 26543176  [PubMed - in process]


790. Bioinformatics. 2016 Mar 1;32(5):730-7. doi: 10.1093/bioinformatics/btv649. Epub 
2015 Nov 4.

Exact quantification of cellular robustness in genome-scale metabolic networks.

Gerstl MP(1), Klamt S(2), Jungreuthmayer C(1), Zanghellini J(1).

Author information: 
(1)Austrian Centre of Industrial Biotechnology, Vienna, Austria, Department of
Biotechnology, University of Natural Resources and Life Sciences, Vienna,
Austria, and. (2)Max Planck Institute for Dynamics of Complex Technical Systems, 
Magdeburg, Germany.

MOTIVATION: Robustness, the ability of biological networks to uphold their
functionality in spite of perturbations, is a key characteristic of all living
systems. Although several theoretical approaches have been developed to formalize
robustness, it still eludes an exact quantification. Here, we present a rigorous 
and quantitative approach for the structural robustness of metabolic networks by 
measuring their ability to tolerate random reaction (or gene) knockouts.
RESULTS: In analogy to reliability theory, based on an explicit consideration of 
all possible knockout sets, we exactly quantify the probability of failure for a 
given network function (e.g. growth). This measure can be computed if the
network's minimal cut sets (MSCs) are known. We show that even in genome-scale
metabolic networks the probability of (network) failure can be reliably estimated
from MSCs with lowest cardinalities. We demonstrate the applicability of our
theory by analyzing the structural robustness of multiple Enterobacteriaceae and 
Blattibacteriaceae and show a dramatically low structural robustness for the
latter. We find that structural robustness develops from the ability to
proliferate in multiple growth environments consistent with experimentally found 
knowledge.
CONCLUSION: The probability of (network) failure provides thus a reliable and
easily computable measure of structural robustness and redundancy in
(genome-scale) metabolic networks.
AVAILABILITY AND IMPLEMENTATION: Source code is available under the GNU General
Public License at https://github.com/mpgerstl/networkRobustnessToolbox
CONTACT: juergen.zanghellini@boku.ac.at
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv649 
PMCID: PMC4795620
PMID: 26543173  [PubMed - in process]


791. BMC Bioinformatics. 2015 Nov 5;16:370. doi: 10.1186/s12859-015-0798-3.

miRA: adaptable novel miRNA identification in plants using small RNA sequencing
data.

Evers M(1), Huttner M(2), Dueck A(3), Meister G(3), Engelmann JC(2).

Author information: 
(1)Institute of Functional Genomics, University of Regensburg, Regensburg,
Germany. maurits.evers@anu.edu.au. (2)Institute of Functional Genomics,
University of Regensburg, Regensburg, Germany. (3)Biochemistry Center Regensburg 
(BZR), Laboratory for RNA Biology, University of Regensburg, Regensburg, Germany.

BACKGROUND: MicroRNAs (miRNAs) are short regulatory RNAs derived from longer
precursor RNAs. miRNA biogenesis has been studied in animals and plants, recently
elucidating more complex aspects, such as non-conserved, species-specific, and
heterogeneous miRNA precursor populations. Small RNA sequencing data can help in 
computationally identifying genomic loci of miRNA precursors. The challenge is to
predict a valid miRNA precursor from inhomogeneous read coverage from a complex
RNA library: while the mature miRNA typically produces many sequence reads, the
remaining part of the precursor is covered very sparsely. As recent results
suggest, alternative miRNA biogenesis pathways may lead to a more diverse miRNA
precursor population than previously assumed. In plants, the latter manifests
itself in e.g. complex secondary structures and expression from multiple loci
within precursors. Current miRNA identification algorithms often depend on
already existing gene annotation, and/or make use of specific miRNA precursor
features such as precursor lengths, secondary structures etc. Consequently and in
view of the emerging new understanding of a more complex miRNA biogenesis in
plants, current tools may fail to characterise organism-specific and
heterogeneous miRNA populations.
RESULTS: miRA is a new tool to identify miRNA precursors in plants, allowing for 
heterogeneous and complex precursor populations. miRA requires small RNA
sequencing data and a corresponding reference genome, and evaluates precursor
secondary structures and precursor processing accuracy; key parameters can be
adapted based on the specific organism under investigation. We show that miRA
outperforms the currently best plant miRNA prediction tools both in sensitivity
and specificity, for data involving Arabidopsis thaliana and the Volvocine algae 
Chlamydomonas reinhardtii; the latter organism has been shown to exhibit a
heterogeneous and complex precursor population with little cross-species miRNA
sequence conservation, and therefore constitutes an ideal model organism.
Furthermore we identify novel miRNAs in the Chlamydomonas-related organism Volvox
carteri.
CONCLUSIONS: We propose miRA, a new plant miRNA identification tool that is well 
adapted to complex precursor populations. miRA is particularly suited for
organisms with no existing miRNA annotation, or without a known related organism 
with well characterized miRNAs. Moreover, miRA has proven its ability to identify
species-specific miRNAs. miRA is flexible in its parameter settings, and produces
user-friendly output files in various formats (pdf, csv, genome-browser-suitable 
annotation files, etc.). It is freely available at
https://github.com/mhuttner/miRA.

DOI: 10.1186/s12859-015-0798-3 
PMCID: PMC4635600
PMID: 26542525  [PubMed - indexed for MEDLINE]


792. BMC Bioinformatics. 2015 Nov 4;16:358. doi: 10.1186/s12859-015-0793-8.

Fizzy: feature subset selection for metagenomics.

Ditzler G(1), Morrison JC(2), Lan Y(3), Rosen GL(4).

Author information: 
(1)Department of Electrical & Computer Engineering, The University of Arizona,
1230 E Speedway Blvd., ECE Bldg., Tucson, 85721, AZ, USA.
gregory.ditzler@gmail.com. (2)Department of Electrical & Computer Engineering,
Drexel University, 3141 Chestnut St., Philadelphia, 19104, PA, USA.
mutantturkey@gmail.com. (3)School of Biomedical Engineering, Science and Health, 
Drexel University, 3141 Chestnut St., Philadelphia, 19104, PA, USA.
yeminlan@gmail.com. (4)Department of Electrical & Computer Engineering, Drexel
University, 3141 Chestnut St., Philadelphia, 19104, PA, USA.
gailr@ece.drexel.edu.

BACKGROUND: Some of the current software tools for comparative metagenomics
provide ecologists with the ability to investigate and explore bacterial
communities using α- & β-diversity. Feature subset selection--a sub-field of
machine learning--can also provide a unique insight into the differences between 
metagenomic or 16S phenotypes. In particular, feature subset selection methods
can obtain the operational taxonomic units (OTUs), or functional features, that
have a high-level of influence on the condition being studied. For example, in a 
previous study we have used information-theoretic feature selection to understand
the differences between protein family abundances that best discriminate between 
age groups in the human gut microbiome.
RESULTS: We have developed a new Python command line tool, which is compatible
with the widely adopted BIOM format, for microbial ecologists that implements
information-theoretic subset selection methods for biological data formats. We
demonstrate the software tools capabilities on publicly available datasets.
CONCLUSIONS: We have made the software implementation of Fizzy available to the
public under the GNU GPL license. The standalone implementation can be found at
http://github.com/EESI/Fizzy.

DOI: 10.1186/s12859-015-0793-8 
PMCID: PMC4634798
PMID: 26538306  [PubMed - indexed for MEDLINE]


793. Genome Biol Evol. 2015 Nov 3;7(12):3207-25. doi: 10.1093/gbe/evv210.

Predicting RAD-seq Marker Numbers across the Eukaryotic Tree of Life.

Herrera S(1), Reyes-Herrera PH(2), Shank TM(3).

Author information: 
(1)Biology Department, Woods Hole Oceanographic Institution Biology Department,
Massachusetts Institute of Technology sherrera@alum.mit.edu. (2)Colombian
Corporation for Agricultural Research (CORPOICA), Bogotá, Colombia. (3)Biology
Department, Woods Hole Oceanographic Institution.

High-throughput sequencing of reduced representation libraries obtained through
digestion with restriction enzymes--generically known as restriction site
associated DNA sequencing (RAD-seq)--is a common strategy to generate genome-wide
genotypic and sequence data from eukaryotes. A critical design element of any
RAD-seq study is knowledge of the approximate number of genetic markers that can 
be obtained for a taxon using different restriction enzymes, as this number
determines the scope of a project, and ultimately defines its success. This
number can only be directly determined if a reference genome sequence is
available, or it can be estimated if the genome size and restriction recognition 
sequence probabilities are known. However, both scenarios are uncommon for
nonmodel species. Here, we performed systematic in silico surveys of recognition 
sequences, for diverse and commonly used type II restriction enzymes across the
eukaryotic tree of life. Our observations reveal that recognition sequence
frequencies for a given restriction enzyme are strikingly variable among broad
eukaryotic taxonomic groups, being largely determined by phylogenetic
relatedness. We demonstrate that genome sizes can be predicted from cleavage
frequency data obtained with restriction enzymes targeting "neutral" elements.
Models based on genomic compositions are also effective tools to accurately
calculate probabilities of recognition sequences across taxa, and can be applied 
to species for which reduced representation data are available (including
transcriptomes and neutral RAD-seq data sets). The analytical pipeline developed 
in this study, PredRAD (https://github.com/phrh/PredRAD), and the resulting
databases constitute valuable resources that will help guide the design of any
study using RAD-seq or related methods.

© The Author(s) 2015. Published by Oxford University Press on behalf of the
Society for Molecular Biology and Evolution.

DOI: 10.1093/gbe/evv210 
PMCID: PMC4700943
PMID: 26537225  [PubMed - indexed for MEDLINE]


794. BMC Bioinformatics. 2015 Nov 4;16:357. doi: 10.1186/s12859-015-0810-y.

Estimation of evolutionary parameters using short, random and partial sequences
from mixed samples of anonymous individuals.

Wu SH(1,)(2), Rodrigo AG(3,)(4).

Author information: 
(1)Biodesign Institute, Arizona State University, Tempe, AZ, 85287, USA.
stevenwu@asu.edu. (2)Department of Biology, Duke University, Box 90338, Durham,
NC, 27708, USA. stevenwu@asu.edu. (3)Department of Biology, Duke University, Box 
90338, Durham, NC, 27708, USA. a.rodrigo@nescent.org. (4)The National
Evolutionary Synthesis Center, Durham, NC, 27705, USA. a.rodrigo@nescent.org.

BACKGROUND: Over the last decade, next generation sequencing (NGS) has become
widely available, and is now the sequencing technology of choice for most
researchers. Nonetheless, NGS presents a challenge for the evolutionary
biologists who wish to estimate evolutionary genetic parameters from a mixed
sample of unlabelled or untagged individuals, especially when the reconstruction 
of full length haplotypes can be unreliable. We propose two novel approaches,
least squares estimation (LS) and Approximate Bayesian Computation Markov chain
Monte Carlo estimation (ABC-MCMC), to infer evolutionary genetic parameters from 
a collection of short-read sequences obtained from a mixed sample of anonymous
DNA using the frequencies of nucleotides at each site only without reconstructing
the full-length alignment nor the phylogeny.
RESULTS: We used simulations to evaluate the performance of these algorithms, and
our results demonstrate that LS performs poorly because bootstrap 95% Confidence 
Intervals (CIs) tend to under- or over-estimate the true values of the
parameters. In contrast, ABC-MCMC 95% Highest Posterior Density (HPD) intervals
recovered from ABC-MCMC enclosed the true parameter values with a rate
approximately equivalent to that obtained using BEAST, a program that implements 
a Bayesian MCMC estimation of evolutionary parameters using full-length
sequences. Because there is a loss of information with the use of sitewise
nucleotide frequencies alone, the ABC-MCMC 95% HPDs are larger than those
obtained by BEAST.
CONCLUSION: We propose two novel algorithms to estimate evolutionary genetic
parameters based on the proportion of each nucleotide. The LS method cannot be
recommended as a standalone method for evolutionary parameter estimation. On the 
other hand, parameters recovered by ABC-MCMC are comparable to those obtained
using BEAST, but with larger 95% HPDs. One major advantage of ABC-MCMC is that
computational time scales linearly with the number of short-read sequences, and
is independent of the number of full-length sequences in the original data. This 
allows us to perform the analysis on NGS datasets with large numbers of short
read fragments. The source code for ABC-MCMC is available at
https://github.com/stevenhwu/SF-ABC.

DOI: 10.1186/s12859-015-0810-y 
PMCID: PMC4634753
PMID: 26536860  [PubMed - indexed for MEDLINE]


795. F1000Res. 2015 Sep 25;4:900. doi: 10.12688/f1000research.6924.1. eCollection
2015.

The khmer software package: enabling efficient nucleotide sequence analysis.

Crusoe MR(1), Alameldin HF(2), Awad S(3), Boucher E(4), Caldwell A(5), Cartwright
R(6), Charbonneau A(7), Constantinides B(8), Edvenson G(9), Fay S(10), Fenton
J(11), Fenzl T(12), Fish J(11), Garcia-Gutierrez L(13), Garland P(14), Gluck
J(15), González I(16), Guermond S(17), Guo J(18), Gupta A(1), Herr JR(1), Howe
A(19), Hyer A(20), Härpfer A(21), Irber L(11), Kidd R(22), Lin D(23), Lippi
J(24), Mansour T(25), McA'Nulty P(26), McDonald E(11), Mizzi J(27), Murray
KD(28), Nahum JR(29), Nanlohy K(30), Nederbragt AJ(31), Ortiz-Zuazaga H(32), Ory 
J(33), Pell J(11), Pepe-Ranney C(34), Russ ZN(35), Schwarz E(36), Scott C(11),
Seaman J(37), Sievert S(38), Simpson J(39), Skennerton CT(40), Spencer J(41),
Srinivasan R(42), Standage D(43), Stapleton JA(44), Steinman SR(45), Stein J(46),
Taylor B(11), Trimble W(47), Wiencko HL(48), Wright M(11), Wyss B(11), Zhang
Q(11), Zyme E(49), Brown CT(50).

Author information: 
(1)Microbiology and Molecular Genetics, Michigan State University, East Lansing, 
MI, USA. (2)Department of Plant, Soil and Microbial Sciences, Michigan State
University, East Lansing, MI, USA. (3)Population Health and Reproduction,
University of California, Davis, Davis, CA, USA. (4)Department of Biomedical
Engineering, Oregon Health and Science University, Portland, OR, USA. (5)Biology 
Department, San Jose State University, San Jose, CA, USA. (6)School of Life
Sciences and The Biodesign Institute, Arizona State University, Tempe, AZ, USA.
(7)Genetics, Michigan State University, East Lansing, MI, USA. (8)Computational
and Evolutionary Biology, Faculty of Life Sciences, University of Manchester,
Manchester, UK. (9)Micron Technology, Seattle, WA, USA. (10)Invitae, San
Francisco, CA, USA. (11)Computer Science and Engineering, Michigan State
University, East Lansing, MI, USA. (12)Independent Researcher, Munich, Germany.
(13)Mathematics Institute, University of Warwick, Warwick, UK. (14)Eastlake Data,
Seattle, WA, USA. (15)Graduate Program, University of Maryland, College Park, MD,
USA. (16)Athinoula A. Martinos Center for Biomedical Imaging, Department of
Radiology, Massachusetts General Hospital, Charlestown, MA, USA. (17)Independent 
Researcher, Seattle, WA, USA. (18)Center for Microbial Ecology, Michigan State
University, East Lansing, MI, USA. (19)Department of Agricultural and Biosystems 
Engineering, Iowa State University, Ames, IA, USA. (20)Department of Biology,
University of Utah, Salt Lake City, UT, USA. (21)ConSol Software GmbH, Munchen,
Germany. (22)Independent Researcher, Sydney, Australia. (23)Verdematics, Fremont,
CA, USA. (24)Independent Researcher, San Francisco, CA, USA. (25)Population
Health and Reproduction, University of California, Davis, Davis, CA, USA ;
Clinical Pathology, Mansoura University, Mansoura, Egypt. (26)Addgene, Cambridge,
MA, USA. (27)Biochemistry and Molecular Biology, Michigan State University, East 
Lansing, MI, USA. (28)ARC Centre of Excellence in Plant Energy Biology, The
Australian National University, Canberra, ACT, Australia. (29)BEACON Center,
Michigan State University, East Lansing, MI, USA. (30)Independent Researcher, New
Orleans, LA, USA. (31)Centre for Ecological and Evolutionary Synthesis, Dept. of 
Biosciences, University of Oslo, Oslo, Norway. (32)Department of Computer
Science, Rio Piedras Campus, University of Puerto Rico, San Juan, Puerto Rico.
(33)Biochemistry, St. Louis College of Pharmacy, St. Louis, MO, USA. (34)Crop and
Soil Sciences, Cornell University, Ithaca, NY, USA. (35)Department of
Bioengineering, UC Berkeley, Berkeley, CA, USA. (36)Department of Molecular
Biology and Genetics, Cornell University, Ithaca, NY, USA. (37)Data
Visualization, Newline Technical Innovations, Windsor, CO, USA. (38)Electrical
and Computer Engineering, University of Minnesota, Minneapolis, MN, USA.
(39)Ontario Institute for Cancer Research, Toronto, ON, Canada ; Computer
Science, University of Toronto, Toronto, ON, Canada. (40)Division of Geological
and Planetary Sciences, California Institute of Technology, Pasadena, CA, USA.
(41)Dept of Physics and Dept of Materials, Imperial College London, London, UK.
(42)Genetics and Genomic Sciences, Icahn School of Medicine at Mount Sinai, New
York, NY, USA. (43)Department of Biology, Indiana University, Bloomington, IN,
USA ; Bioinformatics and Computational Biology Graduate Program, Iowa State
University, Ames, IA, USA. (44)Chemical Engineering & Materials Science, Michigan
State University, East Lansing, MIS, USA. (45)The New York Eye and Ear Infirmary 
of Mount Sinai, New York, NY, USA. (46)Independent Researcher, Providence, RI,
USA. (47)Mathematics and Computer Science Division, Argonne National Laboratory, 
Lemont, IL, USA. (48)Department of Genetics, Smurfit Institute, Trinity College
Dublin, Dublin, Ireland. (49)Independent Researcher, Boston, MA, USA.
(50)Microbiology and Molecular Genetics, Michigan State University, East Lansing,
MI, USA ; Population Health and Reproduction, University of California, Davis,
Davis, CA, USA ; Computer Science and Engineering, Michigan State University,
East Lansing, MI, USA.

The khmer package is a freely available software library for working
efficiently with fixed length DNA words, or k-mers. khmer provides
implementations of a probabilistic k-mer counting data structure, a compressible 
De Bruijn graph representation, De Bruijn graph partitioning, and digital
normalization. khmer is implemented in C++ and Python, and is freely available
under the BSD license at  https://github.com/dib-lab/khmer/.

DOI: 10.12688/f1000research.6924.1 
PMCID: PMC4608353
PMID: 26535114  [PubMed]


796. Bioinformatics. 2016 Mar 1;32(5):786-8. doi: 10.1093/bioinformatics/btv646. Epub 
2015 Nov 2.

PHYLUCE is a software package for the analysis of conserved genomic loci.

Faircloth BC(1).

Author information: 
(1)Department of Biological Sciences and Museum of Natural Science, Louisiana
State University, Baton Rouge, LA 70803, USA.

Targeted enrichment of conserved and ultraconserved genomic elements allows
universal collection of phylogenomic data from hundreds of species at multiple
time scales (<5 Ma to > 300 Ma). Prior to downstream inference, data from these
types of targeted enrichment studies must undergo preprocessing to assemble
contigs from sequence data; identify targeted, enriched loci from the off-target 
background data; align enriched contigs representing conserved loci to one
another; and prepare and manipulate these alignments for subsequent phylogenomic 
inference. PHYLUCE is an efficient and easy-to-install software package that
accomplishes these tasks across hundreds of taxa and thousands of enriched
loci.AVAILABILITY AND IMPLEMENTATION: PHYLUCE is written for Python 2.7. PHYLUCE 
is supported on OSX and Linux (RedHat/CentOS) operating systems. PHYLUCE source
code is distributed under a BSD-style license from
https://www.github.com/faircloth-lab/phyluce/ PHYLUCE is also available as a
package (https://binstar.org/faircloth-lab/phyluce) for the Anaconda Python
distribution that installs all dependencies, and users can request a PHYLUCE
instance on iPlant Atmosphere (tag: phyluce). The software manual and a tutorial 
are available from http://phyluce.readthedocs.org/en/latest/ and test data are
available from doi: 10.6084/m9.figshare.1284521.
CONTACT: brant@faircloth-lab.org
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv646 
PMID: 26530724  [PubMed - in process]


797. Bioinformatics. 2016 Mar 1;32(5):779-81. doi: 10.1093/bioinformatics/btv645. Epub
2015 Nov 2.

No Promoter Left Behind (NPLB): learn de novo promoter architectures from
genome-wide transcription start sites.

Mitra S(1), Narlikar L(1).

Author information: 
(1)Chemical Engineering Division, CSIR-National Chemical Laboratory, Pune 411008,
India.

Promoters have diverse regulatory architectures and thus activate genes
differently. For example, some have a TATA-box, many others do not. Even the ones
with it can differ in its position relative to the transcription start site
(TSS). No Promoter Left Behind (NPLB) is an efficient, organism-independent
method for characterizing such diverse architectures directly from experimentally
identified genome-wide TSSs, without relying on known promoter elements. As a
test case, we show its application in identifying novel architectures in the fly 
genome.AVAILABILITY AND IMPLEMENTATION: Web-server at http://nplb.ncl.res.in
Standalone also at https://github.com/computationalBiology/NPLB/ (Mac OSX/Linux).
CONTACT: l.narlikar@ncl.res.in
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv645 
PMCID: PMC4795619
PMID: 26530723  [PubMed - in process]


798. Bioinformatics. 2016 Mar 1;32(5):673-81. doi: 10.1093/bioinformatics/btv632. Epub
2015 Nov 2.

Specific small-RNA signatures in the amygdala at premotor and motor stages of
Parkinson's disease revealed by deep sequencing analysis.

Pantano L(1), Friedländer MR(2), Escaramís G(2), Lizano E(2), Pallarès-Albanell
J(2), Ferrer I(3), Estivill X(2), Martí E(2).

Author information: 
(1)Genomics and Disease Group, Bioinformatics and Genomics Programme, Centre for 
Genomic Regulation (CRG), Barcelona Institute of Science and Technology,
Barcelona 08003, Spain, Universitat Pompeu Fabra (UPF), Barcelona 08003, Spain,
IMIM, Hospital del Mar Medical Research Institute, Barcelona 08003, Spain, CIBER 
de Epidemiología y Salud Pública (CIBERESP), CRG, Instituto Carlos III Barcelona 
08003, Spain, Universitat Autonoma de Barcelona, Institut de Biotecnologia i de
Biomedicina, Bellaterra (Cerdanyola del Valles), Barcelona, Spain and.
(2)Genomics and Disease Group, Bioinformatics and Genomics Programme, Centre for 
Genomic Regulation (CRG), Barcelona Institute of Science and Technology,
Barcelona 08003, Spain, Universitat Pompeu Fabra (UPF), Barcelona 08003, Spain,
IMIM, Hospital del Mar Medical Research Institute, Barcelona 08003, Spain, CIBER 
de Epidemiología y Salud Pública (CIBERESP), CRG, Instituto Carlos III Barcelona 
08003, Spain. (3)Institut Neuropatologia, Servei Anatomia Patològica,
IDIBELL-Hospital Universitari de Bellvitge, Universitat de Barcelona, Spain and
CIBER de Enfermedades Neurodegenerativas (CIBERNED), Instituto Carlos III,
Barcelona, Spain.

MOTIVATION: Most computational tools for small non-coding RNAs (sRNA) sequencing 
data analysis focus in microRNAs (miRNAs), overlooking other types of sRNAs that 
show multi-mapping hits. Here, we have developed a pipeline to non-redundantly
quantify all types of sRNAs, and extract patterns of expression in biologically
defined groups. We have used our tool to characterize and profile sRNAs in
post-mortem brain samples of control individuals and Parkinson's disease (PD)
cases at early-premotor and late-symptomatic stages.
RESULTS: Clusters of co-expressed sRNAs mapping onto tRNAs significantly
separated premotor and motor cases from controls. A similar result was obtained
using a matrix of miRNAs slightly varying in sequence (isomiRs). The present
framework revealed sRNA alterations at premotor stages of PD, which might reflect
initial pathogenic perturbations. This tool may be useful to discover sRNA
expression patterns linked to different biological conditions.
AVAILABILITY AND IMPLEMENTATION: The full code is available at
http://github.com/lpantano/seqbuster
CONTACT: lpantano@hsph.harvard.edu or eulalia.marti@crg.eu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv632 
PMID: 26530722  [PubMed - in process]


799. IEEE Trans Nanobioscience. 2015 Dec;14(8):882-93. doi: 10.1109/TNB.2015.2491303. 
Epub 2015 Oct 27.

PETs: A Stable and Accurate Predictor of Protein-Protein Interacting Sites Based 
on Extremely-Randomized Trees.

Xia B, Zhang H, Li Q, Li T.

Protein-protein interaction (PPI) plays crucial roles in the performance of
various biological processes. A variety of methods are dedicated to identify
whether proteins have interaction residues, but it is often more crucial to
recognize each amino acid. In practical applications, the stability of a
prediction model is as important as its accuracy. However, random sampling, which
is widely used in previous prediction models, often brings large difference
between each training model. In this paper, a Predictor of protein-protein
interaction sites based on Extremely-randomized Trees (PETs) is proposed to
improve the prediction accuracy while maintaining the prediction stability. In
PETs, a cluster-based sampling strategy is proposed to ensure the model
stability: first, the training dataset is divided into subsets using specific
features; second, the subsets are clustered using K-means; and finally the
samples are selected from each cluster. Using the proposed sampling strategy,
samples which have different types of significant features could be selected
independently from different clusters. The evaluation shows that PETs is able to 
achieve better accuracy while maintaining a good stability. The source code and
toolkit are available at https://github.com/BinXia/PETs.

DOI: 10.1109/TNB.2015.2491303 
PMID: 26529772  [PubMed - indexed for MEDLINE]


800. Bioinformation. 2015 Sep 30;11(9):422-5. doi: 10.6026/97320630011422. eCollection
2015.

SynRio: R and Shiny based application platform for cyanobacterial genome
analysis.

Lakshmanan K(1), Peter AP(1), Mohandass S(1), Varadharaj S(1), Lakshmanan U(1),
Dharmar P(1).

Author information: 
(1)National Facility for Marine Cyanobacteria ,Sub-Distributed Bioinformatics
Center, Department of Marine Biotechnology, School of Marine Sciences,
Bharathidasan University, Tiruchirappalli, Tamil Nadu, India.

SynRio is a Shiny and R based web analysis portal for viewing Synechocystis PCC
6803 genome, a cyanobacterial genome with data analysis capabilities. The web
based user interface is created using R programming language powered by Shiny
package. This web interface helps in creating interactive genome visualization
based on user provided data selection along with selective data download
options.AVAILABILITY: SinRio is available to download freely from Github -
https://github.com/NFMC/SynRio or from http://www.nfmc.res.in/synrio/. In
addition an online version of the platform is also hosted at nfmc.res.in/synrio, 
using shiny server (open source edition) installation.

DOI: 10.6026/97320630011422 
PMCID: PMC4620618
PMID: 26527850  [PubMed]


801. Syst Biol. 2016 Mar;65(2):334-44. doi: 10.1093/sysbio/syv082. Epub 2015 Nov 1.

SimPhy: Phylogenomic Simulation of Gene, Locus, and Species Trees.

Mallo D(1), De Oliveira Martins L(2), Posada D(2).

Author information: 
(1)Department of Biochemistry, Genetics and Immunology, University of Vigo, Vigo 
36310, Spain dmallo@uvigo.es. (2)Department of Biochemistry, Genetics and
Immunology, University of Vigo, Vigo 36310, Spain.

We present a fast and flexible software package--SimPhy--for the simulation of
multiple gene families evolving under incomplete lineage sorting, gene
duplication and loss, horizontal gene transfer--all three potentially leading to 
species tree/gene tree discordance--and gene conversion. SimPhy implements a
hierarchical phylogenetic model in which the evolution of species, locus, and
gene trees is governed by global and local parameters (e.g., genome-wide,
species-specific, locus-specific), that can be fixed or be sampled from a priori 
statistical distributions. SimPhy also incorporates comprehensive models of
substitution rate variation among lineages (uncorrelated relaxed clocks) and the 
capability of simulating partitioned nucleotide, codon, and protein multilocus
sequence alignments under a plethora of substitution models using the program
INDELible. We validate SimPhy's output using theoretical expectations and other
programs, and show that it scales extremely well with complex models and/or large
trees, being an order of magnitude faster than the most similar program
(DLCoal-Sim). In addition, we demonstrate how SimPhy can be useful to understand 
interactions among different evolutionary processes, conducting a simulation
study to characterize the systematic overestimation of the duplication time when 
using standard reconciliation methods. SimPhy is available at
https://github.com/adamallo/SimPhy, where users can find the source code,
precompiled executables, a detailed manual and example cases.

© The Author(s) 2015. Published by Oxford University Press, on behalf of the
Society of Systematic Biologists.

DOI: 10.1093/sysbio/syv082 
PMCID: PMC4748750
PMID: 26526427  [PubMed - indexed for MEDLINE]


802. Bioinformatics. 2016 Mar 1;32(5):690-6. doi: 10.1093/bioinformatics/btv633. Epub 
2015 Oct 31.

The discordant method: a novel approach for differential correlation.

Siska C(1), Bowler R(2), Kechris K(3).

Author information: 
(1)Computational Bioscience Program, Department of Pharmacology, University of
Colorado Denver. (2)Department of Medicine, National Jewish, Denver, CO and.
(3)Department of Biostatistics and Informatics, University of Colorado Denver,
Denver, CO, USA.

MOTIVATION: Current differential correlation methods are designed to determine
molecular feature pairs that have the largest magnitude of difference between
correlation coefficients. These methods do not easily capture molecular feature
pairs that experience no correlation in one group but correlation in another,
which may reflect certain types of biological interactions. We have developed a
tool, the Discordant method, which categorizes the correlation types for each
group to make this possible.
RESULTS: We compare the Discordant method to existing approaches using
simulations and two biological datasets with different types of -omics data. In
contrast to other methods, Discordant identifies phenotype-related features at a 
similar or higher rate while maintaining reasonable computational tractability
and usability.
AVAILABILITY AND IMPLEMENTATION: R code and sample data are available at
https://github.com/siskac/discordant
CONTACT: katerina.kechris@ucdenver.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv633 
PMCID: PMC5006287 [Available on 2017-03-01]
PMID: 26520855  [PubMed - in process]


803. Bioinformatics. 2016 Mar 1;32(5):770-2. doi: 10.1093/bioinformatics/btv624. Epub 
2015 Oct 30.

MMR: a tool for read multi-mapper resolution.

Kahles A(1), Behr J(1), Rätsch G(1).

Author information: 
(1)Memorial Sloan Kettering Cancer Center, Computational Biology Center, 1275
York Avenue, New York, NY 10065, USA.

MOTIVATION: Mapping high-throughput sequencing data to a reference genome is an
essential step for most analysis pipelines aiming at the computational analysis
of genome and transcriptome sequencing data. Breaking ties between equally well
mapping locations poses a severe problem not only during the alignment phase but 
also has significant impact on the results of downstream analyses. We present the
multi-mapper resolution (MMR) tool that infers optimal mapping locations from the
coverage density of other mapped reads.
RESULTS: Filtering alignments with MMR can significantly improve the performance 
of downstream analyses like transcript quantitation and differential testing. We 
illustrate that the accuracy (Spearman correlation) of transcript quantification 
increases by 15% when using reads of length 51. In addition, MMR decreases the
alignment file sizes by more than 50%, and this leads to a reduced running time
of the quantification tool. Our efficient implementation of the MMR algorithm is 
easily applicable as a post-processing step to existing alignment files in BAM
format. Its complexity scales linearly with the number of alignments and requires
no further inputs.
AVAILABILITY AND IMPLEMENTATION: Open source code and documentation are available
for download at http://github.com/ratschlab/mmr Comprehensive testing results and
further information can be found at http://bioweb.me/mmr.
CONTACT: andre.kahles@ratschlab.org or gunnar.ratsch@ratschlab.org
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv624 
PMCID: PMC4795617
PMID: 26519503  [PubMed - in process]


804. Bioinformatics. 2016 Mar 1;32(5):682-9. doi: 10.1093/bioinformatics/btv631. Epub 
2015 Oct 30.

Bayesian inference with historical data-based informative priors improves
detection of differentially expressed genes.

Li B(1), Sun Z(2), He Q(1), Zhu Y(2), Qin ZS(3).

Author information: 
(1)Department of Biostatistics and Bioinformatics, Rollins School of Public
Health, Emory University, Atlanta, GA 30322, USA. (2)Department of Statistics,
Purdue University, West Lafayette, IN 47906, USA and. (3)Department of
Biostatistics and Bioinformatics, Rollins School of Public Health, Emory
University, Atlanta, GA 30322, USA, Department of Biomedical Informatics, Emory
University School of Medicine, Atlanta, GA 30322, USA.

MOTIVATION: Modern high-throughput biotechnologies such as microarray are capable
of producing a massive amount of information for each sample. However, in a
typical high-throughput experiment, only limited number of samples were assayed, 
thus the classical 'large p, small n' problem. On the other hand, rapid
propagation of these high-throughput technologies has resulted in a substantial
collection of data, often carried out on the same platform and using the same
protocol. It is highly desirable to utilize the existing data when performing
analysis and inference on a new dataset.
RESULTS: Utilizing existing data can be carried out in a straightforward fashion 
under the Bayesian framework in which the repository of historical data can be
exploited to build informative priors and used in new data analysis. In this
work, using microarray data, we investigate the feasibility and effectiveness of 
deriving informative priors from historical data and using them in the problem of
detecting differentially expressed genes. Through simulation and real data
analysis, we show that the proposed strategy significantly outperforms existing
methods including the popular and state-of-the-art Bayesian hierarchical
model-based approaches. Our work illustrates the feasibility and benefits of
exploiting the increasingly available genomics big data in statistical inference 
and presents a promising practical strategy for dealing with the 'large p, small 
n' problem.
AVAILABILITY AND IMPLEMENTATION: Our method is implemented in R package IPBT,
which is freely available from https://github.com/benliemory/IPBT CONTACT:
yuzhu@purdue.edu; zhaohui.qin@emory.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv631 
PMCID: PMC4907396 [Available on 2017-03-01]
PMID: 26519502  [PubMed - in process]


805. PLoS One. 2015 Oct 30;10(10):e0141551. doi: 10.1371/journal.pone.0141551.
eCollection 2015.

DisPredict: A Predictor of Disordered Protein Using Optimized RBF Kernel.

Iqbal S(1), Hoque MT(1).

Author information: 
(1)Department of Computer Science, University of New Orleans, New Orleans, LA,
United States of America.

Intrinsically disordered proteins or, regions perform important biological
functions through their dynamic conformations during binding. Thus accurate
identification of these disordered regions have significant implications in
proper annotation of function, induced fold prediction and drug design to combat 
critical diseases. We introduce DisPredict, a disorder predictor that employs a
single support vector machine with RBF kernel and novel features for reliable
characterization of protein structure. DisPredict yields effective performance.
In addition to 10-fold cross validation, training and testing of DisPredict was
conducted with independent test datasets. The results were consistent with both
the training and test error minimal. The use of multiple data sources, makes the 
predictor generic. The datasets used in developing the model include disordered
regions of various length which are categorized as short and long having
different compositions, different types of disorder, ranging from fully to
partially disordered regions as well as completely ordered regions. Through
comparison with other state of the art approaches and case studies, DisPredict is
found to be a useful tool with competitive performance. DisPredict is available
at https://github.com/tamjidul/DisPredict_v1.0.

DOI: 10.1371/journal.pone.0141551 
PMCID: PMC4627842
PMID: 26517719  [PubMed - indexed for MEDLINE]


806. Bioinformatics. 2016 Feb 15;32(4):602-4. doi: 10.1093/bioinformatics/btv605. Epub
2015 Oct 29.

Protael: protein data visualization library for the web.

Sedova M(1), Jaroszewski L(1), Godzik A(1).

Author information: 
(1)Bioinformatics and Systems Biology Program, Sanford Burnham Prebys Medical
Discovery Institute, La Jolla, CA 92307, USA and Center for Structural Genomics
of Infectious Diseases (CSGID), Chicago, IL 60611, USA.

Protael is a JavaScript library for creating interactive visualizations of
biological sequences and various associated data. It allows users to generate
high-quality vector graphics (SVG) and integrate it into web pages.AVAILABILITY
AND IMPLEMENTATION: Protael distribution, documentation and examples are freely
available at http://protael.org; source code is hosted at
https://github.com/sanshu/protaeljs.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv605 
PMID: 26515826  [PubMed - indexed for MEDLINE]


807. Bioinformatics. 2016 Feb 15;32(4):627-8. doi: 10.1093/bioinformatics/btv636. Epub
2015 Oct 29.

tcsBU: a tool to extend TCS network layout and visualization.

Múrias dos Santos A(1), Cabezas MP(2), Tavares AI(1), Xavier R(3), Branco M(2).

Author information: 
(1)Faculdade de Ciências da Universidade do Porto, 4169-007 Porto, Portugal
CIBIO, Centro de Investigação em Biodiversidade e Recursos Genéticos, Campus
Agrário de Vairão, 4485-661 Vairão, Portugal and. (2)CIBIO, Centro de
Investigação em Biodiversidade e Recursos Genéticos, Campus Agrário de Vairão,
4485-661 Vairão, Portugal and. (3)CIBIO, Centro de Investigação em Biodiversidade
e Recursos Genéticos, Campus Agrário de Vairão, 4485-661 Vairão, Portugal and
School of Biological Sciences, Cardiff University, Cardiff, CF10 3AX, UK.

MOTIVATION: TCS is a widely used haplotype network reconstruction software, but
lacks the capability of overlapping genetic with geographic structure, which is
often a first step in phylogeographic analysis.
RESULTS: tcsBU is a web-based program that extends the capabilities of TCS, by
implementing haplotype classification into an arbitrary user-defined scheme,
which is displayed as pie-chart like graphs embedded into the network. Taking
advantage of modern graphic libraries, tcsBU also improves the speed at which the
final network layout is reached. Networks can be saved as a Scalable Vector
Graphics format.
AVAILABILITY AND IMPLEMENTATION: tcsBU is available on-line at
http://cibio.up.pt/software/tcsBU/. The source code is freely available from
https://github.com/sairum/tcsbu/ under a standard MIT license.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv636 
PMID: 26515821  [PubMed - indexed for MEDLINE]


808. Bioinformatics. 2016 Feb 15;32(4):632-4. doi: 10.1093/bioinformatics/btv617. Epub
2015 Oct 27.

caRpools: an R package for exploratory data analysis and documentation of pooled 
CRISPR/Cas9 screens.

Winter J(1), Breinig M(1), Heigwer F(1), Brügemann D(1), Leible S(1), Pelz O(1), 
Zhan T(2), Boutros M(1).

Author information: 
(1)German Cancer Research Center (DKFZ), Division Signaling and Functional
Genomics and Heidelberg University, Heidelberg, Germany and. (2)German Cancer
Research Center (DKFZ), Division Signaling and Functional Genomics and Heidelberg
University, Heidelberg, Germany and Department of Medicine II, University
Hospital Mannheim, Medical Faculty Mannheim, Heidelberg University, Mannheim,
Germany.

MOTIVATION: Genetic screens by CRISPR/Cas9-mediated genome engineering have
become a powerful tool for functional genomics. However, there is currently a
lack of end-to-end software pipelines to analyze CRISPR/Cas9 screens based on
next generation sequencing.
RESULTS: The CRISPR-AnalyzeR for pooled screens (caRpools) is an R package for
exploratory data analysis that provides a complete workflow to analyze
CRISPR/Cas9 screens. To further support the analysis of large-scale screens,
caRpools integrates screening documentation and generation of standardized
analysis reports.
AVAILABILITY AND IMPLEMENTATION: caRpools, manuals and an open virtual appliance 
are available at http://github.com/boutroslab/caRpools.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv617 
PMID: 26508755  [PubMed - indexed for MEDLINE]


809. Magn Reson Med. 2016 Oct;76(4):1196-209. doi: 10.1002/mrm.26032. Epub 2015 Oct
28.

Coil compression in simultaneous multislice functional MRI with concentric ring
slice-GRAPPA and SENSE.

Chu A(1), Noll DC(2).

Author information: 
(1)Department of Biomedical Engineering, University of Michigan, Ann Arbor,
Michigan, USA. alanchu@umich.edu. (2)Department of Biomedical Engineering,
University of Michigan, Ann Arbor, Michigan, USA.

PURPOSE: Simultaneous multislice (SMS) imaging is a useful way to accelerate
functional magnetic resonance imaging (fMRI). As acceleration becomes more
aggressive, an increasingly larger number of receive coils are required to
separate the slices, which significantly increases the computational burden. We
propose a coil compression method that works with concentric ring non-Cartesian
SMS imaging and should work with Cartesian SMS as well. We evaluate the method on
fMRI scans of several subjects and compare it to standard coil compression
methods.
METHODS: The proposed method uses a slice-separation k-space kernel to
simultaneously compress coil data into a set of virtual coils. Five subjects were
scanned using both non-SMS fMRI and SMS fMRI with three simultaneous slices. The 
SMS fMRI scans were processed using the proposed method, along with other
conventional methods. Code is available at https://github.com/alcu/sms.
RESULTS: The proposed method maintained functional activation with a fewer number
of virtual coils than standard SMS coil compression methods. Compression of
non-SMS fMRI maintained activation with a slightly lower number of virtual coils 
than the proposed method, but does not have the acceleration advantages of SMS
fMRI.
CONCLUSION: The proposed method is a practical way to compress and reconstruct
concentric ring SMS data and improves the preservation of functional activation
over standard coil compression methods in fMRI. Magn Reson Med 76:1196-1209,
2016. © 2015 Wiley Periodicals, Inc.

© 2015 Wiley Periodicals, Inc.

DOI: 10.1002/mrm.26032 
PMCID: PMC4867294 [Available on 2017-10-01]
PMID: 26507705  [PubMed - in process]


810. Database (Oxford). 2015 Oct 27;2015. pii: bav104. doi: 10.1093/database/bav104.
Print 2015.

PhenoMiner: from text to a database of phenotypes associated with OMIM diseases.

Collier N(1), Groza T(2), Smedley D(3), Robinson PN(4), Oellrich A(3),
Rebholz-Schuhmann D(5).

Author information: 
(1)The University of Cambridge, Cambridge, CB3 9DB, UK, European Bioinformatics
Institute (EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, Cambridge, UK,
nhc30@cam.ac.uk. (2)Garvan Institute of Medical Research, Darlinghurst, Sydney,
NSW 2010, Australia, School of ITEE, The University of Queensland, St. Lucia, QLD
4072, Australia. (3)Mouse Informatics Group, Wellcome Trust Sanger Institute,
Wellcome Trust Genome Campus, Hinxton CB10 1SA, UK. (4)Institute for Medical
Genetics and Human Genetics, Charité-Universitatsmedizin Berlin, 13353 Berlin,
Germany and. (5)The Insight Centre for Data Analytics, National University of
Ireland, Galway, Ireland.

Analysis of scientific and clinical phenotypes reported in the experimental
literature has been curated manually to build high-quality databases such as the 
Online Mendelian Inheritance in Man (OMIM). However, the identification and
harmonization of phenotype descriptions struggles with the diversity of human
expressivity. We introduce a novel automated extraction approach called
PhenoMiner that exploits full parsing and conceptual analysis. Apriori
association mining is then used to identify relationships to human diseases. We
applied PhenoMiner to the BMC open access collection and identified 13,636
phenotype candidates. We identified 28,155 phenotype-disorder hypotheses covering
4898 phenotypes and 1659 Mendelian disorders. Analysis showed: (i) the semantic
distribution of the extracted terms against linked ontologies; (ii) a comparison 
of term overlap with the Human Phenotype Ontology (HP); (iii) moderate support
for phenotype-disorder pairs in both OMIM and the literature; (iv) strong
associations of phenotype-disorder pairs to known disease-genes pairs using
PhenoDigm. The full list of PhenoMiner phenotypes (S1), phenotype-disorder
associations (S2), association-filtered linked data (S3) and user database
documentation (S5) is available as supplementary data and can be downloaded at
http://github.com/nhcollier/PhenoMiner under a Creative Commons Attribution 4.0
license. Database URL: phenominer.mml.cam.ac.uk.

© The Author(s) 2015. Published by Oxford University Press.

DOI: 10.1093/database/bav104 
PMCID: PMC4622021
PMID: 26507285  [PubMed - indexed for MEDLINE]


811. Bioinformatics. 2016 Feb 15;32(4):629-31. doi: 10.1093/bioinformatics/btv596.
Epub 2015 Oct 26.

Pycellerator: an arrow-based reaction-like modelling language for biological
simulations.

Shapiro BE(1), Mjolsness E(2).

Author information: 
(1)Department of Mathematics, California State University, Northridge, CA 91330, 
USA and. (2)Department of Computer Science, University of California, Irvine, CA 
92697, USA.

MOTIVATION: We introduce Pycellerator, a Python library for reading Cellerator
arrow notation from standard text files, conversion to differential equations,
generating stand-alone Python solvers, and optionally running and plotting the
solutions. All of the original Cellerator arrows, which represent reactions
ranging from mass action, Michales-Menten-Henri (MMH) and Gene-Regulation (GRN)
to Monod-Wyman-Changeaux (MWC), user defined reactions and enzymatic expansions
(KMech), were previously represented with the Mathematica extended character set.
These are now typed as reaction-like commands in ASCII text files that are read
by Pycellerator, which includes a Python command line interface (CLI), a Python
application programming interface (API) and an iPython notebook interface.
RESULTS: Cellerator reaction arrows are now input in text files. The arrows are
parsed by Pycellerator and translated into differential equations in Python, and 
Python code is automatically generated to solve the system. Time courses are
produced by executing the auto-generated Python code. Users have full freedom to 
modify the solver and utilize the complete set of standard Python tools. The new 
libraries are completely independent of the old Cellerator software and do not
require Mathematica.
AVAILABILITY AND IMPLEMENTATION: All software is available (GPL) from the github 
repository at https://github.com/biomathman/pycellerator/releases. Details,
including installation instructions and a glossary of acronyms and terms, are
given in the Supplementary information.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv596 
PMID: 26504142  [PubMed - indexed for MEDLINE]


812. PLoS One. 2015 Oct 26;10(10):e0141541. doi: 10.1371/journal.pone.0141541.
eCollection 2015.

Extending Protein Domain Boundary Predictors to Detect Discontinuous Domains.

Xue Z(1), Jang R(2), Govindarajoo B(3), Huang Y(1), Wang Y(4).

Author information: 
(1)School of Software Engineering, Huazhong University of Science and Technology,
Wuhan, Hubei, 430074, China. (2)School of Software Engineering, Huazhong
University of Science and Technology, Wuhan, Hubei, 430074, China; Department of 
Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI,
48109, United States of America. (3)Department of Computational Medicine and
Bioinformatics, University of Michigan, Ann Arbor, MI, 48109, United States of
America. (4)School of Life Science and Technology, Huazhong University of Science
and Technology, Wuhan, Hubei, 430074, China.

A variety of protein domain predictors were developed to predict protein domain
boundaries in recent years, but most of them cannot predict discontinuous
domains. Considering nearly 40% of multidomain proteins contain one or more
discontinuous domains, we have developed DomEx to enable domain boundary
predictors to detect discontinuous domains by assembling the continuous domain
segments. Discontinuous domains are predicted by matching the sequence profile of
concatenated continuous domain segments with the profiles from a single-domain
library derived from SCOP and CATH, and Pfam. Then the matches are filtered by
similarity to library templates, a symmetric index score and a profile-profile
alignment score. DomEx recalled 32.3% discontinuous domains with 86.5% precision 
when tested on 97 non-homologous protein chains containing 58 continuous and 99
discontinuous domains, in which the predicted domain segments are within ±20
residues of the boundary definitions in CATH 3.5. Compared with our recently
developed predictor, ThreaDom, which is the state-of-the-art tool to detect
discontinuous-domains, DomEx recalled 26.7% discontinuous domains with 72.7%
precision in a benchmark with 29 discontinuous-domain chains, where ThreaDom
failed to predict any discontinuous domains. Furthermore, combined with ThreaDom,
the method ranked number one among 10 predictors. The source code and datasets
are available at https://github.com/xuezhidong/DomEx.

DOI: 10.1371/journal.pone.0141541 
PMCID: PMC4621036
PMID: 26502173  [PubMed - indexed for MEDLINE]


813. Gigascience. 2015 Oct 19;4:48. doi: 10.1186/s13742-015-0089-y. eCollection 2015.

Rcorrector: efficient and accurate error correction for Illumina RNA-seq reads.

Song L(1), Florea L(2).

Author information: 
(1)Department of Computer Science, Johns Hopkins University, Baltimore, 21218
USA. (2)Department of Computer Science, Johns Hopkins University, Baltimore,
21218 USA ; McKusick-Nathans Institute of Genetic Medicine, Johns Hopkins
University School of Medicine, Baltimore, 21205 USA.

BACKGROUND: Next-generation sequencing of cellular RNA (RNA-seq) is rapidly
becoming the cornerstone of transcriptomic analysis. However, sequencing errors
in the already short RNA-seq reads complicate bioinformatics analyses, in
particular alignment and assembly. Error correction methods have been highly
effective for whole-genome sequencing (WGS) reads, but are unsuitable for RNA-seq
reads, owing to the variation in gene expression levels and alternative splicing.
FINDINGS: We developed a k-mer based method, Rcorrector, to correct random
sequencing errors in Illumina RNA-seq reads. Rcorrector uses a De Bruijn graph to
compactly represent all trusted k-mers in the input reads. Unlike WGS read
correctors, which use a global threshold to determine trusted k-mers, Rcorrector 
computes a local threshold at every position in a read.
CONCLUSIONS: Rcorrector has an accuracy higher than or comparable to existing
methods, including the only other method (SEECER) designed for RNA-seq reads, and
is more time and memory efficient. With a 5 GB memory footprint for 100 million
reads, it can be run on virtually any desktop or server. The software is
available free of charge under the GNU General Public License from
https://github.com/mourisl/Rcorrector/.

DOI: 10.1186/s13742-015-0089-y 
PMCID: PMC4615873
PMID: 26500767  [PubMed - indexed for MEDLINE]


814. J Cheminform. 2015 Oct 24;7:51. doi: 10.1186/s13321-015-0098-y. eCollection 2015.

Target prediction utilising negative bioactivity data covering large chemical
space.

Mervin LH(1), Afzal AM(1), Drakakis G(1), Lewis R(1), Engkvist O(2), Bender A(1).

Author information: 
(1)Department of Chemistry, Centre for Molecular Informatics, University of
Cambridge, Lensfield Road, Cambridge, CB2 1EW UK. (2)Discovery Sciences,
Chemistry Innovation Centre, AstraZeneca R&D, 43183 Mölndal, Sweden.

BACKGROUND: In silico analyses are increasingly being used to support
mode-of-action investigations; however many such approaches do not utilise the
large amounts of inactive data held in chemogenomic repositories. The objective
of this work is concerned with the integration of such bioactivity data in the
target prediction of orphan compounds to produce the probability of activity and 
inactivity for a range of targets. To this end, a novel human bioactivity data
set was constructed through the assimilation of over 195 million bioactivity data
points deposited in the ChEMBL and PubChem repositories, and the subsequent
application of a sphere-exclusion selection algorithm to oversample presumed
inactive compounds.
RESULTS: A Bernoulli Naïve Bayes algorithm was trained using the data and
evaluated using fivefold cross-validation, achieving a mean recall and precision 
of 67.7 and 63.8 % for active compounds and 99.6 and 99.7 % for inactive
compounds, respectively. We show the performances of the models are considerably 
influenced by the underlying intraclass training similarity, the size of a given 
class of compounds, and the degree of additional oversampling. The method was
also validated using compounds extracted from WOMBAT producing average
precision-recall AUC and BEDROC scores of 0.56 and 0.85, respectively. Inactive
data points used for this test are based on presumed inactivity, producing an
approximated indication of the true extrapolative ability of the models. A
distance-based applicability domain analysis was also conducted; indicating an
average Tanimoto Coefficient distance of 0.3 or greater between a test and
training set can be used to give a global measure of confidence in model
predictions. A final comparison to a method trained solely on active data from
ChEMBL performed with precision-recall AUC and BEDROC scores of 0.45 and 0.76.
CONCLUSIONS: The inclusion of inactive data for model training produces models
with superior AUC and improved early recognition capabilities, although the
results from internal and external validation of the models show differing
performance between the breadth of models. The realised target prediction
protocol is available at https://github.com/lhm30/PIDGIN.Graphical abstractThe
inclusion of large scale negative training data for in silico target prediction
improves the precision and recall AUC and BEDROC scores for target models.

DOI: 10.1186/s13321-015-0098-y 
PMCID: PMC4619454
PMID: 26500705  [PubMed]


815. Bioinformatics. 2016 Feb 15;32(4):590-2. doi: 10.1093/bioinformatics/btv613. Epub
2015 Oct 24.

BGT: efficient and flexible genotype query across many samples.

Li H(1).

Author information: 
(1)Medical Population Genetics Program, Broad Institute, Cambridge, MA 02142,
USA.

BGT is a compact format, a fast command line tool and a simple web application
for efficient and convenient query of whole-genome genotypes and frequencies
across tens to hundreds of thousands of samples. On real data, it encodes the
haplotypes of 32 488 samples across 39.2 million SNPs into a 7.4 GB database and 
decodes up to 420 million genotypes per CPU second. The high performance enables 
real-time responses to complex queries.AVAILABILITY AND IMPLEMENTATION:
https://github.com/lh3/bgt.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv613 
PMID: 26500154  [PubMed - indexed for MEDLINE]


816. Bioinformatics. 2016 Feb 15;32(4):593-5. doi: 10.1093/bioinformatics/btv615. Epub
2015 Oct 24.

funtooNorm: an R package for normalization of DNA methylation data when there are
multiple cell or tissue types.

Oros Klein K(1), Grinek S(1), Bernatsky S(2), Bouchard L(3), Ciampi A(4),
Colmegna I(5), Fortin JP(6), Gao L(4), Hivert MF(7), Hudson M(8), Kobor MS(9),
Labbe A(4), MacIsaac JL(10), Meaney MJ(11), Morin AM(10), O'Donnell KJ(12),
Pastinen T(13), Van Ijzendoorn MH(14), Voisin G(1), Greenwood CM(15).

Author information: 
(1)Lady Davis Institute, Jewish General Hospital, Montreal, QC H3T 1E2, Canada,
Ludmer Center for Neuroinformatics and Mental Health. (2)Divisions of
Rheumatology and Clinical Epidemiology, McGill University Health Centre, McGill
University, Montreal, QC H4A 3J1, Canada. (3)ECOGENE-21, Centre intégré
universitaire de santé et de service sociaux du Saguenay-Lac-Saint-Jean, QC G8H
3P7, Canada, Department of Biochemistry, Université de Sherbrooke, QC J1K 2R1,
Canada. (4)Department of Epidemiology, Biostatistics and Occupational Health,
McGill University, Montreal, QC H3A 1A2, Canada. (5)Division of Experimental
Medicine, McGill University Health Centre, McGill University, Montreal, QC H3A
1A3, Canada. (6)Department of Biostatistics, Johns Hopkins University, Baltimore,
MD 21218, USA. (7)Department of Population Medicine, Harvard Medical School,
Harvard Pilgrim Health Care Institute, Boston, MA 02215, USA, Department of
Medicine, Division of Endocrinology, Université de Sherbrooke, Sherbrooke, QC J1K
2R1, Canada. (8)Lady Davis Institute, Jewish General Hospital, Montreal, QC H3T
1E2, Canada, Department of Medicine, McGill University Health Center, Montreal,
QC H4A 3J1, Canada. (9)Canadian Institute for Advanced Research, Child, and Brain
Development Program, Toronto, ON M5G 1Z8, Canada, Centre for Molecular Medicine
and Therapeutics, Child and Family Research Institute, Vancouver, BC V5Z 4H4,
Canada, Department of Medical Genetics, University of British Columbia,
Vancouver, BC V6H 3N1, Canada. (10)Centre for Molecular Medicine and
Therapeutics, Child and Family Research Institute, Vancouver, BC V5Z 4H4, Canada,
Department of Medical Genetics, University of British Columbia, Vancouver, BC V6H
3N1, Canada. (11)Ludmer Center for Neuroinformatics and Mental Health, Canadian
Institute for Advanced Research, Child, and Brain Development Program, Toronto,
ON M5G 1Z8, Canada, Centre for Molecular Medicine and Therapeutics, Child and
Family Research Institute, Vancouver, BC V5Z 4H4, Canada, Douglas Mental Health
University Institute, McGill University, Montreal, QC H4H 1R3, Canada,
Departments of Psychiatry, McGill University, Montreal, QC, Canada H3A 1A1,
Department of Neurology and Neurosurgery, McGill University, Montreal, QC H3A
2B4, Canada. (12)Douglas Mental Health University Institute, McGill University,
Montreal, QC H4H 1R3, Canada. (13)Department of Human Genetics, McGill
University, Montreal, QC H3A 1B1, Canada and. (14)Centre for Child and Family
Studies, Leiden University, Leiden 2300 RB, The Netherlands. (15)Lady Davis
Institute, Jewish General Hospital, Montreal, QC H3T 1E2, Canada, Department of
Biochemistry, Université de Sherbrooke, QC J1K 2R1, Canada, Department of
Epidemiology, Biostatistics and Occupational Health, McGill University, Montreal,
QC H3A 1A2, Canada, Department of Human Genetics, McGill University, Montreal, QC
H3A 1B1, Canada and.

MOTIVATION: DNA methylation patterns are well known to vary substantially across 
cell types or tissues. Hence, existing normalization methods may not be optimal
if they do not take this into account. We therefore present a new R package for
normalization of data from the Illumina Infinium Human Methylation450 BeadChip
(Illumina 450 K) built on the concepts in the recently published funNorm method, 
and introducing cell-type or tissue-type flexibility.
RESULTS: funtooNorm is relevant for data sets containing samples from two or more
cell or tissue types. A visual display of cross-validated errors informs the
choice of the optimal number of components in the normalization. Benefits of cell
(tissue)-specific normalization are demonstrated in three data sets. Improvement 
can be substantial; it is strikingly better on chromosome X, where methylation
patterns have unique inter-tissue variability.
AVAILABILITY AND IMPLEMENTATION: An R package is available at
https://github.com/GreenwoodLab/funtooNorm, and has been submitted to
Bioconductor at http://bioconductor.org.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv615 
PMCID: PMC4743629
PMID: 26500152  [PubMed - indexed for MEDLINE]


817. PLoS One. 2015 Oct 23;10(10):e0141105. doi: 10.1371/journal.pone.0141105.
eCollection 2015.

Virtual Pharmacist: A Platform for Pharmacogenomics.

Cheng R(1), Leung RK(2), Chen Y(1), Pan Y(1), Tong Y(1), Li Z(1), Ning L(1), Ling
XB(3), He J(1).

Author information: 
(1)Department of Biology, South University of Science and Technology of China,
Shenzhen, China. (2)Division of Genomics and Bioinformatics, The Chinese
University of Hong Kong, Hong Kong, China. (3)Departments of Surgery, Stanford
University, Stanford, California, United States of America.

We present Virtual Pharmacist, a web-based platform that takes common types of
high-throughput data, namely microarray SNP genotyping data, FASTQ and Variant
Call Format (VCF) files as inputs, and reports potential drug responses in terms 
of efficacy, dosage and toxicity at one glance. Batch submission facilitates
multivariate analysis or data mining of targeted groups. Individual analysis
consists of a report that is readily comprehensible to patients and practioners
who have basic knowledge in pharmacology, a table that summarizes variants and
potential affected drug response according to the US Food and Drug Administration
pharmacogenomic biomarker labeled drug list and PharmGKB, and visualization of a 
gene-drug-target network. Group analysis provides the distribution of the
variants and potential affected drug response of a target group, a sample-gene
variant count table, and a sample-drug count table. Our analysis of genomes from 
the 1000 Genome Project underlines the potentially differential drug responses
among different human populations. Even within the same population, the findings 
from Watson's genome highlight the importance of personalized medicine. Virtual
Pharmacist can be accessed freely at http://www.sustc-genome.org.cn/vp or
installed as a local web server. The codes and documentation are available at the
GitHub repository (https://github.com/VirtualPharmacist/vp). Administrators can
download the source codes to customize access settings for further development.

DOI: 10.1371/journal.pone.0141105 
PMCID: PMC4619711
PMID: 26496198  [PubMed - indexed for MEDLINE]


818. PLoS One. 2015 Oct 23;10(10):e0140644. doi: 10.1371/journal.pone.0140644.
eCollection 2015.

ARK: Aggregation of Reads by K-Means for Estimation of Bacterial Community
Composition.

Koslicki D(1), Chatterjee S(2), Shahrivar D(2), Walker AW(3), Francis SC(4),
Fraser LJ(5), Vehkaperä M(6), Lan Y(7), Corander J(8).

Author information: 
(1)Dept of Mathematics, Oregon State University, Corvallis, United States of
America. (2)Dept of Communication Theory, KTH Royal Institute of Technology,
Stockholm, Sweden. (3)Microbiology Group, Rowett Institute of Nutrition and
Health, University of Aberdeen, Aberdeen, United Kingdom. (4)MRC Tropical
Epidemiology Group, London School of Hygiene and Tropical Medicine, London,
United Kingdom. (5)Illumina Cambridge Ltd., Chesterford Research Park, Essex,
United Kingdom. (6)Dept of Electronic and Electrical Engineering, University of
Sheffield, Sheffield, United Kingdom. (7)Dept of Physics, Tsinghua University,
Beijing, China. (8)Dept of Mathematics and Statistics, University of Helsinki,
Helsinki, Finland.

MOTIVATION: Estimation of bacterial community composition from high-throughput
sequenced 16S rRNA gene amplicons is a key task in microbial ecology. Since the
sequence data from each sample typically consist of a large number of reads and
are adversely impacted by different levels of biological and technical noise,
accurate analysis of such large datasets is challenging.
RESULTS: There has been a recent surge of interest in using compressed sensing
inspired and convex-optimization based methods to solve the estimation problem
for bacterial community composition. These methods typically rely on summarizing 
the sequence data by frequencies of low-order k-mers and matching this
information statistically with a taxonomically structured database. Here we show 
that the accuracy of the resulting community composition estimates can be
substantially improved by aggregating the reads from a sample with an
unsupervised machine learning approach prior to the estimation phase. The
aggregation of reads is a pre-processing approach where we use a standard K-means
clustering algorithm that partitions a large set of reads into subsets with
reasonable computational cost to provide several vectors of first order
statistics instead of only single statistical summarization in terms of k-mer
frequencies. The output of the clustering is then processed further to obtain the
final estimate for each sample. The resulting method is called Aggregation of
Reads by K-means (ARK), and it is based on a statistical argument via mixture
density formulation. ARK is found to improve the fidelity and robustness of
several recently introduced methods, with only a modest increase in computational
complexity.
AVAILABILITY: An open source, platform-independent implementation of the method
in the Julia programming language is freely available at
https://github.com/dkoslicki/ARK. A Matlab implementation is available at
http://www.ee.kth.se/ctsoftware.

DOI: 10.1371/journal.pone.0140644 
PMCID: PMC4619776
PMID: 26496191  [PubMed - indexed for MEDLINE]


819. J Comput Biol. 2016 Jan;23(1):1-9. doi: 10.1089/cmb.2015.0137. Epub 2015 Oct 20.

dbHT-Trans: An Efficient Tool for Filtering the Protein-Encoding Transcripts
Assembled by RNA-Seq According to Search for Homologous Proteins.

Deng F(1), Chen SY(1).

Author information: 
(1)Farm Animal Genetic Resources Exploration and Innovation Key Laboratory of
Sichuan Province, Sichuan Agricultural University , Chengdu, China .

In RNA-Seq studies, there are still many challenges for reliably assembling
transcripts. Both genome-guided and de novo methods always produce too many false
transcripts because of known and unknown factors. Therefore, the postassembly
quality filtering is necessary before performing downstream analyses. Here, we
present an automatic and efficient tool of dbHT-Trans for filtering the
protein-encoding transcripts assembled by RNA-Seq. For each candidate transcript,
we first deduced all potential open reading frames and translated them into amino
acid sequences. By searching against the reference protein database, a transcript
would be predicted a false one when it has no homologous sequence. Using this
method, it is expected to filter out the falsely assembled transcripts of
protein-encoding genes. Application of dbHT-Trans to the annotated transcriptome 
of mouse revealed that the sensitivity was almost 90% for recalling
protein-encoding transcripts. After this quality filtering, the numbers of
assembled genes became more consistent between Cufflinks and Trinity tools. To
significantly decrease the data storage, we transformed all intermediate data
into descriptive metadata and stored by the MySQL database, which will be
utilized by downstream analyses in a real-time style. The source codes, example
data, and manual of dbHT-Trans are freely available on the GitHub repository.

DOI: 10.1089/cmb.2015.0137 
PMID: 26484655  [PubMed - indexed for MEDLINE]


820. Bioinformatics. 2016 Feb 1;32(3):417-23. doi: 10.1093/bioinformatics/btv594. Epub
2015 Oct 17.

Scalable clustering algorithms for continuous environmental flow cytometry.

Hyrkas J(1), Clayton S(2), Ribalet F(2), Halperin D(3), Armbrust EV(4), Howe
B(3).

Author information: 
(1)Department of Computer Science and Engineering. (2)School of Oceanography and.
(3)Department of Computer Science and Engineering, eScience Institute, University
of Washington, Seattle, WA 98195, USA. (4)School of Oceanography and eScience
Institute, University of Washington, Seattle, WA 98195, USA.

MOTIVATION: Recent technological innovations in flow cytometry now allow
oceanographers to collect high-frequency flow cytometry data from particles in
aquatic environments on a scale far surpassing conventional flow cytometers. The 
SeaFlow cytometer continuously profiles microbial phytoplankton populations
across thousands of kilometers of the surface ocean. The data streams produced by
instruments such as SeaFlow challenge the traditional sample-by-sample approach
in cytometric analysis and highlight the need for scalable clustering algorithms 
to extract population information from these large-scale, high-frequency flow
cytometers.
RESULTS: We explore how available algorithms commonly used for medical
applications perform at classification of such a large-scale, environmental flow 
cytometry data. We apply large-scale Gaussian mixture models to massive datasets 
using Hadoop. This approach outperforms current state-of-the-art cytometry
classification algorithms in accuracy and can be coupled with manual or automatic
partitioning of data into homogeneous sections for further classification gains. 
We propose the Gaussian mixture model with partitioning approach for
classification of large-scale, high-frequency flow cytometry data.
AVAILABILITY AND IMPLEMENTATION: Source code available for download at
https://github.com/jhyrkas/seaflow_cluster, implemented in Java for use with
Hadoop.
CONTACT: hyrkas@cs.washington.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv594 
PMID: 26476780  [PubMed - indexed for MEDLINE]


821. BMC Bioinformatics. 2015 Oct 16;16:332. doi: 10.1186/s12859-015-0750-6.

Improving RNA-Seq expression estimation by modeling isoform- and exon-specific
read sequencing rate.

Liu X(1), Shi X(2), Chen C(3), Zhang L(4).

Author information: 
(1)College of Computer Science and Technology, Nanjing University of Aeronautics 
and Astronautics, 29 Jiangjun Rd., Nanjing, 211106, China.
xuejun.liu@nuaa.edu.cn. (2)College of Computer Science and Technology, Nanjing
University of Aeronautics and Astronautics, 29 Jiangjun Rd., Nanjing, 211106,
China. shixinxin61@126.com. (3)College of Computer Science and Technology,
Nanjing University of Aeronautics and Astronautics, 29 Jiangjun Rd., Nanjing,
211106, China. 524126860@qq.com. (4)College of Computer Science and Technology,
Nanjing University of Aeronautics and Astronautics, 29 Jiangjun Rd., Nanjing,
211106, China. leo.zhang@nuaa.edu.cn.

BACKGROUND: The high-throughput sequencing technology, RNA-Seq, has been widely
used to quantify gene and isoform expression in the study of transcriptome in
recent years. Accurate expression measurement from the millions or billions of
short generated reads is obstructed by difficulties. One is ambiguous mapping of 
reads to reference transcriptome caused by alternative splicing. This increases
the uncertainty in estimating isoform expression. The other is non-uniformity of 
read distribution along the reference transcriptome due to positional,
sequencing, mappability and other undiscovered sources of biases. This violates
the uniform assumption of read distribution for many expression calculation
approaches, such as the direct RPKM calculation and Poisson-based models. Many
methods have been proposed to address these difficulties. Some approaches employ 
latent variable models to discover the underlying pattern of read sequencing.
However, most of these methods make bias correction based on surrounding sequence
contents and share the bias models by all genes. They therefore cannot estimate
gene- and isoform-specific biases as revealed by recent studies.
RESULTS: We propose a latent variable model, NLDMseq, to estimate gene and
isoform expression. Our method adopts latent variables to model the unknown
isoforms, from which reads originate, and the underlying percentage of multiple
spliced variants. The isoform- and exon-specific read sequencing biases are
modeled to account for the non-uniformity of read distribution, and are
identified by utilizing the replicate information of multiple lanes of a single
library run. We employ simulation and real data to verify the performance of our 
method in terms of accuracy in the calculation of gene and isoform expression.
Results show that NLDMseq obtains competitive gene and isoform expression
compared to popular alternatives. Finally, the proposed method is applied to the 
detection of differential expression (DE) to show its usefulness in the
downstream analysis.
CONCLUSIONS: The proposed NLDMseq method provides an approach to accurately
estimate gene and isoform expression from RNA-Seq data by modeling the isoform-
and exon-specific read sequencing biases. It makes use of a latent variable model
to discover the hidden pattern of read sequencing. We have shown that it works
well in both simulations and real datasets, and has competitive performance
compared to popular methods. The method has been implemented as a freely
available software which can be found at https://github.com/PUGEA/NLDMseq.

DOI: 10.1186/s12859-015-0750-6 
PMCID: PMC4609108
PMID: 26475308  [PubMed - indexed for MEDLINE]


822. Appl Environ Microbiol. 2015 Oct 16;82(1):157-66. doi: 10.1128/AEM.02772-15.

Microbial Community Analysis with Ribosomal Gene Fragments from Shotgun
Metagenomes.

Guo J(1), Cole JR(1), Zhang Q(2), Brown CT(3), Tiedje JM(4).

Author information: 
(1)Center for Microbial Ecology, Michigan State University, East Lansing,
Michigan, USA. (2)Department of Computer Science and Engineering, Michigan State 
University, East Lansing, Michigan, USA. (3)Department of Computer Science and
Engineering, Michigan State University, East Lansing, Michigan, USA Department of
Population Health and Reproduction, University of California, Davis, Davis,
California, USA. (4)Center for Microbial Ecology, Michigan State University, East
Lansing, Michigan, USA tiedjej@msu.edu.

Shotgun metagenomic sequencing does not depend on gene-targeted primers or PCR
amplification; thus, it is not affected by primer bias or chimeras. However,
searching rRNA genes from large shotgun Illumina data sets is computationally
expensive, and no approach exists for unsupervised community analysis of
small-subunit (SSU) rRNA gene fragments retrieved from shotgun data. We present a
pipeline, SSUsearch, to achieve the faster identification of short-subunit rRNA
gene fragments and enabled unsupervised community analysis with shotgun data. It 
also includes classification and copy number correction, and the output can be
used by traditional amplicon analysis platforms. Shotgun metagenome data using
this pipeline yielded higher diversity estimates than amplicon data but retained 
the grouping of samples in ordination analyses. We applied this pipeline to soil 
samples with paired shotgun and amplicon data and confirmed bias against
Verrucomicrobia in a commonly used V6-V8 primer set, as well as discovering
likely bias against Actinobacteria and for Verrucomicrobia in a commonly used V4 
primer set. This pipeline can utilize all variable regions in SSU rRNA and also
can be applied to large-subunit (LSU) rRNA genes for confirmation of community
structure. The pipeline can scale to handle large amounts of soil metagenomic
data (5 Gb memory and 5 central processing unit hours to process 38 Gb [1 lane]
of trimmed Illumina HiSeq2500 data) and is freely available at
https://github.com/dib-lab/SSUsearch under a BSD license.

Copyright © 2015, American Society for Microbiology. All Rights Reserved.

DOI: 10.1128/AEM.02772-15 
PMCID: PMC4702641
PMID: 26475107  [PubMed - indexed for MEDLINE]


823. J Bioinform Comput Biol. 2015 Dec;13(6):1542002. doi: 10.1142/S0219720015420020. 
Epub 2015 Sep 9.

MeSHSim: An R/Bioconductor package for measuring semantic similarity over MeSH
headings and MEDLINE documents.

Zhou J(1,)(2), Shui Y(1,)(2), Peng S(1,)(2), Li X(3), Mamitsuka H(4), Zhu
S(1,)(2).

Author information: 
(1)* School of Computer Science, Fudan University, Shanghai 200433, P. R. China. 
(2)† Shanghai Key Laboratory of Intelligent Information Processing, Fudan
University, Shanghai 200433, P. R. China. (3)‡ School of Information Management, 
Wuhan University, Wuhan 430072, P. R. China. (4)§ Bioinformatics Center,
Institute for Chemical Research, Kyoto University, Kyoto 611-0011, Japan.

Currently, all MEDLINE documents are indexed by medical subject headings (MeSH). 
Computing semantic similarity between two MeSH headings as well as two documents 
has become very important for many biomedical text mining applications. We
develop an R package, MeSHSim, which can compute nine similarity measures between
MeSH nodes, by which similarity between MeSH headings as well as MEDLINE
documents can be easily computed. Also, MeSHSim supports querying hierarchy
information of a MeSH heading and retrieving MeSH headings of a query document,
and can be easily integrated into pipelines for any biomedical text analysis
tasks. MeSHSim is released under general public license (GPL), and available
through Bioconductor and from Github at https://github.com/JingZhou2015/MeSHSim.

DOI: 10.1142/S0219720015420020 
PMID: 26471719  [PubMed - indexed for MEDLINE]


824. Nucleic Acids Res. 2016 Feb 29;44(4):e32. doi: 10.1093/nar/gkv1025. Epub 2015 Oct
13.

A deep learning framework for modeling structural features of RNA-binding protein
targets.

Zhang S(1), Zhou J(2), Hu H(2), Gong H(3), Chen L(2), Cheng C(4), Zeng J(5).

Author information: 
(1)Institute for Interdisciplinary Information Sciences, Tsinghua University,
Beijing 100084, China. (2)Department of Pharmacology and Pharmaceutical Sciences,
School of Medicine, Tsinghua University, Beijing 100084, China. (3)School of Life
Sciences, Tsinghua University, Beijing 100084, China MOE Key Laboratory of
Bioinformatics, Tsinghua University, Beijing 100084, China. (4)Department of
Genetics, Institute for Quantitative Biomedical Sciences, Norris Cotton Cancer
Center, Geisel School of Medicine at Dartmouth, Hanover, NH 03755, USA
chao.cheng@dartmouth.edu. (5)Institute for Interdisciplinary Information
Sciences, Tsinghua University, Beijing 100084, China MOE Key Laboratory of
Bioinformatics, Tsinghua University, Beijing 100084, China
zengjy321@tsinghua.edu.cn.

RNA-binding proteins (RBPs) play important roles in the post-transcriptional
control of RNAs. Identifying RBP binding sites and characterizing RBP binding
preferences are key steps toward understanding the basic mechanisms of the
post-transcriptional gene regulation. Though numerous computational methods have 
been developed for modeling RBP binding preferences, discovering a complete
structural representation of the RBP targets by integrating their available
structural features in all three dimensions is still a challenging task. In this 
paper, we develop a general and flexible deep learning framework for modeling
structural binding preferences and predicting binding sites of RBPs, which takes 
(predicted) RNA tertiary structural information into account for the first time. 
Our framework constructs a unified representation that characterizes the
structural specificities of RBP targets in all three dimensions, which can be
further used to predict novel candidate binding sites and discover potential
binding motifs. Through testing on the real CLIP-seq datasets, we have
demonstrated that our deep learning framework can automatically extract effective
hidden structural features from the encoded raw sequence and structural profiles,
and predict accurate RBP binding sites. In addition, we have conducted the first 
study to show that integrating the additional RNA tertiary structural features
can improve the model performance in predicting RBP binding sites, especially for
the polypyrimidine tract-binding protein (PTB), which also provides a new
evidence to support the view that RBPs may own specific tertiary structural
binding preferences. In particular, the tests on the internal ribosome entry site
(IRES) segments yield satisfiable results with experimental support from the
literature and further demonstrate the necessity of incorporating RNA tertiary
structural information into the prediction model. The source code of our approach
can be found in https://github.com/thucombio/deepnet-rbp.

© The Author(s) 2015. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkv1025 
PMCID: PMC4770198
PMID: 26467480  [PubMed - indexed for MEDLINE]


825. BMC Genomics. 2015 Oct 13;16:774. doi: 10.1186/s12864-015-1976-4.

Gene duplications are extensive and contribute significantly to the toxic
proteome of nematocysts isolated from Acropora digitifera (Cnidaria: Anthozoa:
Scleractinia).

Gacesa R(1), Chung R(2), Dunn SR(3), Weston AJ(4), Jaimes-Becerra A(5), Marques
AC(5,)(6), Morandini AC(5), Hranueli D(7), Starcevic A(7), Ward M(2), Long
PF(8,)(9,)(10,)(11).

Author information: 
(1)Institute of Pharmaceutical Science, King's College London, 150 Stamford
Street, London, SE1 9NH, UK. (2)Proteomics Facility, Institute of Psychiatry,
Psychology & Neuroscience, King's College London, 16 De Crespigny Park, London,
SE5 8AF, UK. (3)Coral Reefs Ecosystems Laboratory, School of Biological Sciences,
The University of Queensland, St. Lucia, QLD, 4072, Australia. (4)Mass
Spectrometry Laboratory, UCL School of Pharmacy, 29/39 Brunswick Square, London, 
WC1N 1AX, UK. (5)Departamento de Zoologia, Instituto de Biociências, Universidade
de São Paulo, Rua Matao, Trav. 14, 101, 05508-090, São Paulo, SP, Brazil.
(6)Centro de Biologia Marinha, Universidade de São Paulo, Rodovia Manoel Hypólito
do Rego, km. 131,5, 11600-000, São Sebastião, Brazil. (7)Section for
Bioinformatics, Department of Biochemical Engineering, Faculty of Food Technology
and Biotechnology, University of Zagreb, Pierottijeva 6, 10000, Zagreb, Croatia. 
(8)Institute of Pharmaceutical Science, King's College London, 150 Stamford
Street, London, SE1 9NH, UK. paul.long@kcl.ac.uk. (9)Department of Chemistry,
King's College London, Strand, London, WC2R 2LS, UK. paul.long@kcl.ac.uk.
(10)Brazil Institute, King's College London, Strand, London, WC2R 2LS, UK.
paul.long@kcl.ac.uk. (11)Faculdade de Ciências Farmacêuticas, Universidade de São
Paulo, Av. Prof. Lineu Prestes, 580, B16, 05508-000, São Paulo, SP, Brazil.
paul.long@kcl.ac.uk.

BACKGROUND: Gene duplication followed by adaptive selection is a well-accepted
process leading to toxin diversification in venoms. However, emergent genomic,
transcriptomic and proteomic evidence now challenges this role to be at best
equivocal to other processess . Cnidaria are arguably the most ancient phylum of 
the extant metazoa that are venomous and such provide a definitive ancestral
anchor to examine the evolution of this trait.
METHODS: Here we compare predicted toxins from the translated genome of the coral
Acropora digitifera to putative toxins revealed by proteomic analysis of soluble 
proteins discharged from nematocysts, to determine the extent to which gene
duplications contribute to venom innovation in this reef-building coral species. 
A new bioinformatics tool called HHCompare was developed to detect potential gene
duplications in the genomic data, which is made freely available (
https://github.com/rgacesa/HHCompare ).
RESULTS: A total of 55 potential toxin encoding genes could be predicted from the
A. digitifera genome, of which 36 (65 %) had likely arisen by gene duplication as
evinced using the HHCompare tool and verified using two standard phylogeny
methods. Surprisingly, only 22 % (12/55) of the potential toxin repertoire could 
be detected following rigorous proteomic analysis, for which only half (6/12) of 
the toxin proteome could be accounted for as peptides encoded by the gene
duplicates. Biological activities of these toxins are dominatedby putative
phospholipases and toxic peptidases.
CONCLUSIONS: Gene expansions in A. digitifera venom are the most extensive yet
described in any venomous animal, and gene duplication plays a significant role
leading to toxin diversification in this coral species. Since such low numbers of
toxins were detected in the proteome, it is unlikely that the venom is evolving
rapidly by prey-driven positive natural selection. Rather we contend that the
venom has a defensive role deterring predation or harm from interspecific
competition and overgrowth by fouling organisms. Factors influencing translation 
of toxin encoding genes perhaps warrants more profound experimental
consideration.

DOI: 10.1186/s12864-015-1976-4 
PMCID: PMC4604070
PMID: 26464356  [PubMed - indexed for MEDLINE]


826. PLoS One. 2015 Oct 13;10(10):e0139868. doi: 10.1371/journal.pone.0139868.
eCollection 2015.

NGS-QCbox and Raspberry for Parallel, Automated and Rapid Quality Control
Analysis of Large-Scale Next Generation Sequencing (Illumina) Data.

Katta MA(1), Khan AW(1), Doddamani D(1), Thudi M(1), Varshney RK(2).

Author information: 
(1)International Crops Research Institute for the Semi-Arid Tropics (ICRISAT),
Hyderabad, India. (2)International Crops Research Institute for the Semi-Arid
Tropics (ICRISAT), Hyderabad, India; School of Plant Biology and Institute of
Agriculture, The University of Western Australia, Crawley, Australia.

Rapid popularity and adaptation of next generation sequencing (NGS) approaches
have generated huge volumes of data. High throughput platforms like Illumina
HiSeq produce terabytes of raw data that requires quick processing. Quality
control of the data is an important component prior to the downstream analyses.
To address these issues, we have developed a quality control pipeline, NGS-QCbox 
that scales up to process hundreds or thousands of samples. Raspberry is an
in-house tool, developed in C language utilizing HTSlib (v1.2.1)
(http://htslib.org), for computing read/base level statistics. It can be used as 
stand-alone application and can process both compressed and uncompressed FASTQ
format files. NGS-QCbox integrates Raspberry with other open-source tools for
alignment (Bowtie2), SNP calling (SAMtools) and other utilities (bedtools)
towards analyzing raw NGS data at higher efficiency and in high-throughput
manner. The pipeline implements batch processing of jobs using Bpipe
(https://github.com/ssadedin/bpipe) in parallel and internally, a fine grained
task parallelization utilizing OpenMP. It reports read and base statistics along 
with genome coverage and variants in a user friendly format. The pipeline
developed presents a simple menu driven interface and can be used in either quick
or complete mode. In addition, the pipeline in quick mode outperforms in speed
against other similar existing QC pipeline/tools. The NGS-QCbox pipeline,
Raspberry tool and associated scripts are made available at the URL
https://github.com/CEG-ICRISAT/NGS-QCbox and
https://github.com/CEG-ICRISAT/Raspberry for rapid quality control analysis of
large-scale next generation sequencing (Illumina) data.

DOI: 10.1371/journal.pone.0139868 
PMCID: PMC4604202
PMID: 26460497  [PubMed - indexed for MEDLINE]


827. Bioinformatics. 2016 Feb 1;32(3):453-5. doi: 10.1093/bioinformatics/btv587. Epub 
2015 Oct 9.

CSSSCL: a python package that uses combined sequence similarity scores for
accurate taxonomic classification of long and short sequence reads.

Borozan I(1), Ferretti V(1).

Author information: 
(1)Informatics and Bio-computing, Ontario Institute for Cancer Research, MaRS
Centre, 661 University Avenue, Suite 510, Toronto, Ontario, Canada.

SUMMARY: Sequence comparison of genetic material between known and unknown
organisms plays a crucial role in genomics, metagenomics and phylogenetic
analysis. The emerging long-read sequencing technologies can now produce reads of
tens of kilobases in length that promise a more accurate assessment of their
origin. To facilitate the classification of long and short DNA sequences, we have
developed a Python package that implements a new sequence classification model
that we have demonstrated to improve the classification accuracy when compared
with other state of the art classification methods. For the purpose of
validation, and to demonstrate its usefulness, we test the combined sequence
similarity score classifier (CSSSCL) using three different datasets, including a 
metagenomic dataset composed of short reads.
AVAILABILITY AND IMPLEMENTATION: Package's source code and test datasets are
available under the GPLv3 license at https://github.com/oicr-ibc/cssscl.
CONTACT: ivan.borozan@oicr.on.ca
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv587 
PMCID: PMC4734043
PMID: 26454281  [PubMed - indexed for MEDLINE]


828. Bioinformatics. 2016 Feb 1;32(3):338-44. doi: 10.1093/bioinformatics/btv538. Epub
2015 Oct 10.

Rapid and enhanced remote homology detection by cascading hidden Markov model
searches in sequence space.

Kaushik S(1), Nair AG(1), Mutt E(1), Subramanian HP(1), Sowdhamini R(1).

Author information: 
(1)National Centre for Biological Sciences, Tata Institute of Fundamental
Research, GKVK Campus, Bangalore 560065, India.

MOTIVATION: In the post-genomic era, automatic annotation of protein sequences
using computational homology-based methods is highly desirable. However, often
protein sequences diverge to an extent where detection of homology and automatic 
annotation transfer is not straightforward. Sophisticated approaches to detect
such distant relationships are needed. We propose a new approach to identify deep
evolutionary relationships of proteins to overcome shortcomings of the available 
methods.
RESULTS: We have developed a method to identify remote homologues more
effectively from any protein sequence database by using several cascading events 
with Hidden Markov Models (C-HMM). We have implemented clustering of hits and
profile generation of hit clusters to effectively reduce the computational
timings of the cascaded sequence searches. Our C-HMM approach could cover 94, 83 
and 40% coverage at family, superfamily and fold levels, respectively, when
applied on diverse protein folds. We have compared C-HMM with various remote
homology detection methods and discuss the trade-offs between coverage and false 
positives.
AVAILABILITY AND IMPLEMENTATION: A standalone package implemented in Java along
with a detailed documentation can be downloaded from
https://github.com/RSLabNCBS/C-HMM SUPPLEMENTARY INFORMATION: Supplementary data 
are available at Bioinformatics online.
CONTACT: mini@ncbs.res.in.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv538 
PMID: 26454276  [PubMed - indexed for MEDLINE]


829. Bioinformatics. 2016 Feb 1;32(3):441-3. doi: 10.1093/bioinformatics/btv551. Epub 
2015 Oct 7.

HapFlow: visualizing haplotypes in sequencing data.

Sullivan MJ(1), Bachmann NL(1), Timms P(1), Polkinghorne A(1).

Author information: 
(1)Faculty of Science, Health, Education and Engineering, University of the
Sunshine Coast, Sippy Downs, Australia.

SUMMARY: HapFlow is a python application for visualizing haplotypes present in
sequencing data. It identifies variant profiles present and reads and creates an 
abstract visual representation of these profiles to make haplotypes easier to
identify.
AVAILABILITY AND IMPLEMENTATION: HapFlow is freely available (under a GPL
license) for download (for Mac OS X, Unix and Microsoft Windows) from github
(http://mjsull.github.io/HapFlow).
CONTACT: apolking@usc.edu.au.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv551 
PMID: 26449930  [PubMed - indexed for MEDLINE]


830. BMC Genomics. 2015;16 Suppl 10:S3. doi: 10.1186/1471-2164-16-S10-S3. Epub 2015
Oct 2.

ASTRID: Accurate Species TRees from Internode Distances.

Vachaspati P, Warnow T.

BACKGROUND: Incomplete lineage sorting (ILS), modelled by the multi-species
coalescent (MSC), is known to create discordance between gene trees and species
trees, and lead to inaccurate species tree estimations unless appropriate methods
are used to estimate the species tree. While many statistically consistent
methods have been developed to estimate the species tree in the presence of ILS, 
only ASTRAL-2 and NJst have been shown to have good accuracy on large datasets.
Yet, NJst is generally slower and less accurate than ASTRAL-2, and cannot run on 
some datasets.
RESULTS: We have redesigned NJst to enable it to run on all datasets, and we have
expanded its design space so that it can be used with different distance-based
tree estimation methods. The resultant method, ASTRID, is statistically
consistent under the MSC model, and has accuracy that is competitive with
ASTRAL-2. Furthermore, ASTRID is much faster than ASTRAL-2, completing in minutes
on some datasets for which ASTRAL-2 used hours.
CONCLUSIONS: ASTRID is a new coalescent-based method for species tree estimation 
that is competitive with the best current method in terms of accuracy, while
being much faster. ASTRID is available in open source form on github.

DOI: 10.1186/1471-2164-16-S10-S3 
PMCID: PMC4602181
PMID: 26449326  [PubMed - indexed for MEDLINE]


831. PLoS Comput Biol. 2015 Oct 8;11(10):e1004401. doi: 10.1371/journal.pcbi.1004401. 
eCollection 2015.

TRANSIT--A Software Tool for Himar1 TnSeq Analysis.

DeJesus MA(1), Ambadipudi C(1), Baker R(2), Sassetti C(2), Ioerger TR(1).

Author information: 
(1)Department of Computer Science, Texas A&M University, College Station, Texas, 
United States of America. (2)Department of Microbiology and Physiological
Systems, University of Massachusetts Medical School, Worcester, Massachusetts,
United States of America.

TnSeq has become a popular technique for determining the essentiality of genomic 
regions in bacterial organisms. Several methods have been developed to analyze
the wealth of data that has been obtained through TnSeq experiments. We developed
a tool for analyzing Himar1 TnSeq data called TRANSIT. TRANSIT provides a
graphical interface to three different statistical methods for analyzing TnSeq
data. These methods cover a variety of approaches capable of identifying
essential genes in individual datasets as well as comparative analysis between
conditions. We demonstrate the utility of this software by analyzing TnSeq
datasets of M. tuberculosis grown on glycerol and cholesterol. We show that
TRANSIT can be used to discover genes which have been previously implicated for
growth on these carbon sources. TRANSIT is written in Python, and thus can be run
on Windows, OSX and Linux platforms. The source code is distributed under the GNU
GPL v3 license and can be obtained from the following GitHub repository:
https://github.com/mad-lab/transit.

DOI: 10.1371/journal.pcbi.1004401 
PMCID: PMC4598096
PMID: 26447887  [PubMed - indexed for MEDLINE]


832. Bioinformatics. 2016 Feb 1;32(3):444-6. doi: 10.1093/bioinformatics/btv573. Epub 
2015 Oct 6.

Rust-Bio: a fast and safe bioinformatics library.

Köster J(1).

Author information: 
(1)Center for Functional Cancer Epigenetics, Dana-Farber Cancer Institute,
Department of Biostatistics and Computational Biology, Dana-Farber Cancer
Institute, Harvard School of Public Health and Department of Medical Oncology,
Dana-Farber Cancer Institute, Harvard Medical School, MA02215, Boston, USA.

SUMMARY: We present Rust-Bio, the first general purpose bioinformatics library
for the innovative Rust programming language. Rust-Bio leverages the unique
combination of speed, memory safety and high-level syntax offered by Rust to
provide a fast and safe set of bioinformatics algorithms and data structures with
a focus on sequence analysis.
AVAILABILITY AND IMPLEMENTATION: Rust-Bio is available open source under the MIT 
license at https://rust-bio.github.io.
CONTACT: koester@jimmy.harvard.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv573 
PMID: 26446134  [PubMed - indexed for MEDLINE]


833. Brief Funct Genomics. 2016 Jul;15(4):298-304. doi: 10.1093/bfgp/elv037. Epub 2015
Oct 5.

Quality control, imputation and analysis of genome-wide genotyping data from the 
Illumina HumanCoreExome microarray.

Coleman JR, Euesden J, Patel H, Folarin AA, Newhouse S, Breen G.

The decreasing cost of performing genome-wide association studies has made
genomics widely accessible. However, there is a paucity of guidance for best
practice in conducting such analyses. For the results of a study to be valid and 
replicable, multiple biases must be addressed in the course of data preparation
and analysis. In addition, standardizing methods across small, independent
studies would increase comparability and the potential for effective
meta-analysis. This article provides a discussion of important aspects of quality
control, imputation and analysis of genome-wide data from a low-coverage
microarray, as well as a straight-forward guide to performing a genome-wide
association study. A detailed protocol is provided online, with example scripts
available at https://github.com/JoniColeman/gwas_scripts.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bfgp/elv037 
PMID: 26443613  [PubMed - in process]


834. Hum Mutat. 2016 Jan;37(1):36-42. doi: 10.1002/humu.22914. Epub 2015 Oct 20.

wKinMut-2: Identification and Interpretation of Pathogenic Variants in Human
Protein Kinases.

Vazquez M(1), Pons T(1), Brunak S(2,)(3), Valencia A(1), Izarzugaza JM(3).

Author information: 
(1)Structural Biology and BioComputing Programme, Spanish National Cancer
Research Centre (CNIO), Madrid, 28029, Spain. (2)Novo Nordisk Foundation Center
for Protein Research, Faculty of Health Sciences, University of Copenhagen,
Copenhagen 2200, Denmark. (3)Center for Biological Sequence Analysis (CBS),
Systems Biology Department, Technical University of Denmark (DTU), Kongens Lyngby
2800, Denmark.

Most genomic alterations are tolerated while only a minor fraction disrupts
molecular function sufficiently to drive disease. Protein kinases play a central 
biological function and the functional consequences of their variants are
abundantly characterized. However, this heterogeneous information is often
scattered across different sources, which makes the integrative analysis complex 
and laborious. wKinMut-2 constitutes a solution to facilitate the interpretation 
of the consequences of human protein kinase variation. Nine methods predict their
pathogenicity, including a kinase-specific random forest approach. To understand 
the biological mechanisms causative of human diseases and cancer, information
from pertinent reference knowledge bases and the literature is automatically
mined, digested, and homogenized. Variants are visualized in their structural
contexts and residues affecting catalytic and drug binding are identified. Known 
protein-protein interactions are reported. Altogether, this information is
intended to assist the generation of new working hypothesis to be corroborated
with ulterior experimental work. The wKinMut-2 system, along with a user manual
and examples, is freely accessible at http://kinmut2.bioinfo.cnio.es, the code
for local installations can be downloaded from
https://github.com/Rbbt-Workflows/KinMut2.

© 2015 WILEY PERIODICALS, INC.

DOI: 10.1002/humu.22914 
PMID: 26443060  [PubMed - indexed for MEDLINE]


835. BMC Genomics. 2015 Oct 5;16:745. doi: 10.1186/s12864-015-1944-z.

Identifying binary protein-protein interactions from affinity purification mass
spectrometry data.

Zhang XF(1), Ou-Yang L(2), Hu X(3,)(4), Dai DQ(5).

Author information: 
(1)School of Mathematics and Statistics, Central China Normal University, Luoyu
Road, Wuhan, 430079, China. zhangxf@mail.ccnu.edu.cn. (2)Intelligent Data Center 
and Department of Mathematics, Sun Yat-Sen University, Xingang West Road,
Guangzhou, 510275, China. ouyangle@mail2.sysu.edu.cn. (3)School of Computer,
Central China Normal University, 774 Luoyu Road, Wuhan, 430079, China.
xh29@drexel.edu. (4)College of Information Science and Technology, Drexel
University, Chestnut Street, Philadelphia, 19104, USA. xh29@drexel.edu.
(5)Intelligent Data Center and Department of Mathematics, Sun Yat-Sen University,
Xingang West Road, Guangzhou, 510275, China. stsddq@mail.sysu.edu.cn.

BACKGROUND: The identification of protein-protein interactions contributes
greatly to the understanding of functional organization within cells. With the
development of affinity purification-mass spectrometry (AP-MS) techniques,
several computational scoring methods have been proposed to detect protein
interactions from AP-MS data. However, most of the current methods focus on the
detection of co-complex interactions and do not discriminate between direct
physical interactions and indirect interactions. Consequently, less is known
about the precise physical wiring diagram within cells.
RESULTS: In this paper, we develop a Binary Interaction Network Model (BINM) to
computationally identify direct physical interactions from co-complex
interactions which can be inferred from purification data using previous scoring 
methods. This model provides a mathematical framework for capturing topological
relationships between direct physical interactions and observed co-complex
interactions. It reassigns a confidence score to each observed interaction to
indicate its propensity to be a direct physical interaction. Then observed
interactions with high confidence scores are predicted as direct physical
interactions. We run our model on two yeast co-complex interaction networks which
are constructed by two different scoring methods on a same combined AP-MS data.
The direct physical interactions identified by various methods are
comprehensively benchmarked against different reference sets that provide both
direct and indirect evidence for physical contacts. Experiment results show that 
our model has a competitive performance over the state-of-the-art methods.
CONCLUSIONS: According to the results obtained in this study, BINM is a powerful 
scoring method that can solely use network topology to predict direct physical
interactions from AP-MS data. This study provides us an alternative approach to
explore the information inherent in AP-MS data. The software can be downloaded
from https://github.com/Zhangxf-ccnu/BINM.

DOI: 10.1186/s12864-015-1944-z 
PMCID: PMC4595009
PMID: 26438428  [PubMed - indexed for MEDLINE]


836. PLoS One. 2015 Oct 5;10(10):e0139656. doi: 10.1371/journal.pone.0139656.
eCollection 2015.

Prioritizing Clinically Relevant Copy Number Variation from Genetic Interactions 
and Gene Function Data.

Foong J(1), Girdea M(1), Stavropoulos J(2), Brudno M(1).

Author information: 
(1)Department of Computer Science, University of Toronto, Toronto, Ontario,
Canada; Hospital of Sick Children, Toronto, Ontario, Canada. (2)Hospital of Sick 
Children, Toronto, Ontario, Canada.

It is becoming increasingly necessary to develop computerized methods for
identifying the few disease-causing variants from hundreds discovered in each
individual patient. This problem is especially relevant for Copy Number Variants 
(CNVs), which can be cheaply interrogated via low-cost hybridization arrays
commonly used in clinical practice. We present a method to predict the disease
relevance of CNVs that combines functional context and clinical phenotype to
discover clinically harmful CNVs (and likely causative genes) in patients with a 
variety of phenotypes. We compare several feature and gene weighing systems for
classifying both genes and CNVs. We combined the best performing methodologies
and parameters on over 2,500 Agilent CGH 180k Microarray CNVs derived from 140
patients. Our method achieved an F-score of 91.59%, with 87.08% precision and
97.00% recall. Our methods are freely available at
https://github.com/compbio-UofT/cnv-prioritization. Our dataset is included with 
the supplementary information.

DOI: 10.1371/journal.pone.0139656 
PMCID: PMC4593641
PMID: 26437450  [PubMed - indexed for MEDLINE]


837. Microbiome. 2015 Oct 5;3:43. doi: 10.1186/s40168-015-0105-6.

Improved OTU-picking using long-read 16S rRNA gene amplicon sequencing and
generic hierarchical clustering.

Franzén O(1), Hu J(2), Bao X(3), Itzkowitz SH(4), Peter I(5), Bashir A(6).

Author information: 
(1)Department of Genetics and Genomic Sciences, Icahn School of Medicine at Mount
Sinai, New York, NY, USA. p.oscar.franzen@gmail.com. (2)Department of Genetics
and Genomic Sciences, Icahn School of Medicine at Mount Sinai, New York, NY, USA.
jianzhong.hu@mssm.edu. (3)Division of Gastroenterology, Department of Medicine,
Icahn School of Medicine at Mount Sinai, New York, NY, USA.
xiuliang.bao@mssm.edu. (4)Division of Gastroenterology, Department of Medicine,
Icahn School of Medicine at Mount Sinai, New York, NY, USA.
steven.itzkowitz@mountsinai.org. (5)Department of Genetics and Genomic Sciences, 
Icahn School of Medicine at Mount Sinai, New York, NY, USA. inga.peter@mssm.edu. 
(6)Department of Genetics and Genomic Sciences, Icahn School of Medicine at Mount
Sinai, New York, NY, USA. ali.bashir@mssm.edu.

Erratum in
    Microbiome. 2015;3:57.

BACKGROUND: High-throughput bacterial 16S rRNA gene sequencing followed by
clustering of short sequences into operational taxonomic units (OTUs) is widely
used for microbiome profiling. However, clustering of short 16S rRNA gene reads
into biologically meaningful OTUs is challenging, in part because nucleotide
variation along the 16S rRNA gene is only partially captured by short reads. The 
recent emergence of long-read platforms, such as single-molecule real-time (SMRT)
sequencing from Pacific Biosciences, offers the potential for improved taxonomic 
and phylogenetic profiling. Here, we evaluate the performance of long- and
short-read 16S rRNA gene sequencing using simulated and experimental data,
followed by OTU inference using computational pipelines based on heuristic and
complete-linkage hierarchical clustering.
RESULTS: In simulated data, long-read sequencing was shown to improve OTU quality
and decrease variance. We then profiled 40 human gut microbiome samples using a
combination of Illumina MiSeq and Blautia-specific SMRT sequencing, further
supporting the notion that long reads can identify additional OTUs. We
implemented a complete-linkage hierarchical clustering strategy using a flexible 
computational pipeline, tailored specifically for PacBio circular consensus
sequencing (CCS) data that outperforms heuristic methods in most settings:
https://github.com/oscar-franzen/oclust/ .
CONCLUSION: Our data demonstrate that long reads can improve OTU inference;
however, the choice of clustering algorithm and associated clustering thresholds 
has significant impact on performance.

DOI: 10.1186/s40168-015-0105-6 
PMCID: PMC4593230
PMID: 26434730  [PubMed - indexed for MEDLINE]


838. Behav Res Methods. 2016 Sep;48(3):1062-9. doi: 10.3758/s13428-015-0630-z.

The what, why, and how of born-open data.

Rouder JN(1).

Author information: 
(1)University of Missouri, Columbia, MO, 65211, USA. rouderj@missouri.edu.

Although many researchers agree that scientific data should be open to scrutiny
to ferret out poor analyses and outright fraud, most raw data sets are not
available on demand. There are many reasons researchers do not open their data,
and one is technical. It is often time consuming to prepare and archive data. In 
response, my laboratory has automated the process such that our data are archived
the night they are created without any human approval or action. All data are
versioned, logged, time stamped, and uploaded including aborted runs and data
from pilot subjects. The archive is GitHub, github.com, the world's largest
collection of open-source materials. Data archived in this manner are called born
open. In this paper, I discuss the benefits of born-open data and provide a brief
technical overview of the process. I also address some of the common concerns
about opening data before publication.

DOI: 10.3758/s13428-015-0630-z 
PMID: 26428912  [PubMed - in process]


839. Bioinformatics. 2016 Jan 15;32(2):276-82. doi: 10.1093/bioinformatics/btv570.
Epub 2015 Oct 1.

Cell line name recognition in support of the identification of synthetic
lethality in cancer from text.

Kaewphan S(1), Van Landeghem S(2), Ohta T(3), Van de Peer Y(4), Ginter F(5),
Pyysalo S(6).

Author information: 
(1)Turku Centre for Computer Science (TUCS), 20520 Turku, Finland, Department of 
Information Technology, University of Turku, 20014, Finland, University of Turku 
Graduate School (UTUGS), University of Turku, 20014, Finland. (2)Department of
Plant Systems Biology, VIB, Ghent 9000, Belgium, Department of Plant
Biotechnology and Bioinformatics, Ghent University, Ghent 9052, Belgium.
(3)Textimi, Tokyo, Japan. (4)Department of Plant Systems Biology, VIB, Ghent
9000, Belgium, Department of Plant Biotechnology and Bioinformatics, Ghent
University, Ghent 9052, Belgium, Bioinformatics Institute Ghent, Ghent
University, Ghent, Belgium, Genomics Research Institute, University of Pretoria, 
Pretoria, South Africa and. (5)Department of Information Technology, University
of Turku, 20014, Finland. (6)Department of Information Technology, University of 
Turku, 20014, Finland, Language Technology Lab (LTL), University of Cambridge,
Cambridge CB3 9DA, United Kingdom.

MOTIVATION: The recognition and normalization of cell line names in text is an
important task in biomedical text mining research, facilitating for instance the 
identification of synthetically lethal genes from the literature. While several
tools have previously been developed to address cell line recognition, it is
unclear whether available systems can perform sufficiently well in realistic and 
broad-coverage applications such as extracting synthetically lethal genes from
the cancer literature. In this study, we revisit the cell line name recognition
task, evaluating both available systems and newly introduced methods on various
resources to obtain a reliable tagger not tied to any specific subdomain. In
support of this task, we introduce two text collections manually annotated for
cell line names: the broad-coverage corpus Gellus and CLL, a focused target
domain corpus.
RESULTS: We find that the best performance is achieved using NERsuite, a machine 
learning system based on Conditional Random Fields, trained on the Gellus corpus 
and supported with a dictionary of cell line names. The system achieves an
F-score of 88.46% on the test set of Gellus and 85.98% on the independently
annotated CLL corpus. It was further applied at large scale to 24 302 102
unannotated articles, resulting in the identification of 5 181 342 cell line
mentions, normalized to 11 755 unique cell line database identifiers.
AVAILABILITY AND IMPLEMENTATION: The manually annotated datasets, the cell line
dictionary, derived corpora, NERsuite models and the results of the large-scale
run on unannotated texts are available under open licenses at
http://turkunlp.github.io/Cell-line-recognition/.
CONTACT: sukaew@utu.fi.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv570 
PMCID: PMC4708107
PMID: 26428294  [PubMed - indexed for MEDLINE]


840. Bioinformatics. 2016 Jan 15;32(2):295-7. doi: 10.1093/bioinformatics/btv567. Epub
2015 Oct 1.

JEPEGMIX: gene-level joint analysis of functional SNPs in cosmopolitan cohorts.

Lee D(1), Williamson VS(1), Bigdeli TB(1), Riley BP(1), Webb BT(1), Fanous AH(1),
Kendler KS(1), Vladimirov VI(1), Bacanu SA(1).

Author information: 
(1)Department of Psychiatry, Virginia Commonwealth University, Richmond, VA
23298, USA.

MOTIVATION: To increase detection power, gene level analysis methods are used to 
aggregate weak signals. To greatly increase computational efficiency, most
methods use as input summary statistics from genome-wide association studies
(GWAS). Subsequently, gene statistics are constructed using linkage
disequilibrium (LD) patterns from a relevant reference panel. However, all
methods, including our own Joint Effect on Phenotype of eQTL/functional single
nucleotide polymorphisms (SNPs) associated with a Gene (JEPEG), assume
homogeneous panels, e.g. European. However, this renders these tools unsuitable
for the analysis of large cosmopolitan cohorts.
RESULTS: We propose a JEPEG extension, JEPEGMIX, which similar to one of our
software tools, Direct Imputation of summary STatistics of unmeasured SNPs from
MIXed ethnicity cohorts, is capable of estimating accurate LD patterns for
cosmopolitan cohorts. JEPEGMIX uses this accurate LD estimates to (i) impute the 
summary statistics at unmeasured functional variants and (ii) test for the joint 
effect of all measured and imputed functional variants which are associated with 
a gene. We illustrate the performance of our tool by analyzing the GWAS
meta-analysis summary statistics from the multi-ethnic Psychiatric Genomics
Consortium Schizophrenia stage 2 cohort. This practical application supports the 
immune system being one of the main drivers of the process leading to
schizophrenia.
AVAILABILITY AND IMPLEMENTATION: Software, annotation database and examples are
available at http://dleelab.github.io/jepegmix/.
CONTACT: donghyung.lee@vcuhealth.org
SUPPLEMENTARY INFORMATION: Supplementary material is available at Bioinformatics 
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv567 
PMCID: PMC4708106
PMID: 26428293  [PubMed - indexed for MEDLINE]


841. Bioinformatics. 2016 Jan 15;32(2):268-75. doi: 10.1093/bioinformatics/btv564.
Epub 2015 Sep 30.

Warpgroup: increased precision of metabolomic data processing by consensus
integration bound analysis.

Mahieu NG(1), Spalding JL(2), Patti GJ(1).

Author information: 
(1)Department of Chemistry, Washington University, St Louis, MO 63130, USA,
Department of Medicine and. (2)Department of Chemistry, Washington University, St
Louis, MO 63130, USA, Department of Genetics, Washington University School of
Medicine, St Louis, MO 63110, USA.

MOTIVATION: Current informatic techniques for processing raw chromatography/mass 
spectrometry data break down under several common, non-ideal conditions.
Importantly, hydrophilic liquid interaction chromatography (a key separation
technology for metabolomics) produces data which are especially challenging to
process. We identify three critical points of failure in current informatic
workflows: compound specific drift, integration region variance, and naive
missing value imputation. We implement the Warpgroup algorithm to address these
challenges.
RESULTS: Warpgroup adds peak subregion detection, consensus integration bound
detection, and intelligent missing value imputation steps to the conventional
informatic workflow. When compared with the conventional workflow, Warpgroup made
major improvements to the processed data. The coefficient of variation for peaks 
detected in replicate injections of a complex Escherichia Coli extract were
halved (a reduction of 19%). Integration regions across samples were much more
robust. Additionally, many signals lost by the conventional workflow were
'rescued' by the Warpgroup refinement, thereby resulting in greater analyte
coverage in the processed data.
AVAILABILITY AND: I: MPLEMENTATION: Warpgroup is an open source R package
available on GitHub at github.com/nathaniel-mahieu/warpgroup. The package
includes example data and XCMS compatibility wrappers for ease of use.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.
CONTACT: nathaniel.mahieu@wustl.edu or gjpattij@wustl.edu.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv564 
PMCID: PMC5013975
PMID: 26424859  [PubMed - indexed for MEDLINE]


842. BMC Bioinformatics. 2015;16 Suppl 13:S10. doi: 10.1186/1471-2105-16-S13-S10. Epub
2015 Sep 25.

Detrimental effects of duplicate reads and low complexity regions on RNA- and
ChIP-seq data.

Dozmorov MG, Adrianto I, Giles CB, Glass E, Glenn SB, Montgomery C, Sivils KL,
Olson LE, Iwayama T, Freeman WM, Lessard CJ, Wren JD.

BACKGROUND: Adapter trimming and removal of duplicate reads are common practices 
in next-generation sequencing pipelines. Sequencing reads ambiguously mapped to
repetitive and low complexity regions can also be problematic for accurate
assessment of the biological signal, yet their impact on sequencing data has not 
received much attention. We investigate how trimming the adapters, removing
duplicates, and filtering out reads overlapping low complexity regions influence 
the significance of biological signal in RNA- and ChIP-seq experiments.
METHODS: We assessed the effect of data processing steps on the alignment
statistics and the functional enrichment analysis results of RNA- and ChIP-seq
data. We compared differentially processed RNA-seq data with matching microarray 
data on the same patient samples to determine whether changes in pre-processing
improved correlation between the two. We have developed a simple tool to remove
low complexity regions, RepeatSoaker, available at
https://github.com/mdozmorov/RepeatSoaker, and tested its effect on the alignment
statistics and the results of the enrichment analyses.
RESULTS: Both adapter trimming and duplicate removal moderately improved the
strength of biological signals in RNA-seq and ChIP-seq data. Aggressive filtering
of reads overlapping with low complexity regions, as defined by RepeatMasker,
further improved the strength of biological signals, and the correlation between 
RNA-seq and microarray gene expression data.
CONCLUSIONS: Adapter trimming and duplicates removal, coupled with filtering out 
reads overlapping low complexity regions, is shown to increase the quality and
reliability of detecting biological signals in RNA-seq and ChIP-seq data.

DOI: 10.1186/1471-2105-16-S13-S10 
PMCID: PMC4597324
PMID: 26423047  [PubMed - indexed for MEDLINE]


843. Cancer Inform. 2015 Sep 13;14:105-7. doi: 10.4137/CIN.S26470. eCollection 2015.

Alview: Portable Software for Viewing Sequence Reads in BAM Formatted Files.

Finney RP(1), Chen QR(1), Nguyen CV(1), Hsu CH(1), Yan C(1), Hu Y(1), Abawi M(1),
Bian X(1), Meerzaman DM(1).

Author information: 
(1)Computational Genomics Research Group, Center for Bioinformatics and
Information Technology, National Cancer Institute, Bethesda, MD, USA.

The name Alview is a contraction of the term Alignment Viewer. Alview is a
compiled to native architecture software tool for visualizing the alignment of
sequencing data. Inputs are files of short-read sequences aligned to a reference 
genome in the SAM/BAM format and files containing reference genome data. Outputs 
are visualizations of these aligned short reads. Alview is written in portable C 
with optional graphical user interface (GUI) code written in C, C++, and
Objective-C. The application can run in three different ways: as a web server, as
a command line tool, or as a native, GUI program. Alview is compatible with
Microsoft Windows, Linux, and Apple OS X. It is available as a web demo at
https://cgwb.nci.nih.gov/cgi-bin/alview. The source code and Windows/Mac/Linux
executables are available via https://github.com/NCIP/alview.

DOI: 10.4137/CIN.S26470 
PMCID: PMC4573065
PMID: 26417198  [PubMed]


844. Bioinformatics. 2016 Jan 15;32(2):260-7. doi: 10.1093/bioinformatics/btv556. Epub
2015 Sep 28.

ScreenBEAM: a novel meta-analysis algorithm for functional genomics screens via
Bayesian hierarchical modeling.

Yu J(1), Silva J(2), Califano A(1).

Author information: 
(1)Department of Biomedical Informatics, Department of Systems Biology, Center
for Computational Biology and Bioinformatics, Herbert Irving Comprehensive Cancer
Center, Columbia University, New York, NY 10032, USA and. (2)Department of
Pathology, Icahn School of Medicine at Mount Sinai, New York, NY 10029, USA.

MOTIVATION: Functional genomics (FG) screens, using RNAi or CRISPR technology,
have become a standard tool for systematic, genome-wide loss-of-function studies 
for therapeutic target discovery. As in many large-scale assays, however,
off-target effects, variable reagents' potency and experimental noise must be
accounted for appropriately control for false positives. Indeed, rigorous
statistical analysis of high-throughput FG screening data remains challenging,
particularly when integrative analyses are used to combine multiple sh/sgRNAs
targeting the same gene in the library.
METHOD: We use large RNAi and CRISPR repositories that are publicly available to 
evaluate a novel meta-analysis approach for FG screens via Bayesian hierarchical 
modeling, Screening Bayesian Evaluation and Analysis Method (ScreenBEAM).
RESULTS: Results from our analysis show that the proposed strategy, which
seamlessly combines all available data, robustly outperforms classical algorithms
developed for microarray data sets as well as recent approaches designed for next
generation sequencing technologies. Remarkably, the ScreenBEAM algorithm works
well even when the quality of FG screens is relatively low, which accounts for
about 80-95% of the public datasets.
AVAILABILITY AND IMPLEMENTATION: R package and source code are available at:
https://github.com/jyyu/ScreenBEAM.
CONTACT: ac2248@columbia.edu, jose.silva@mssm.edu, yujiyang@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv556 
PMCID: PMC4907394
PMID: 26415723  [PubMed - indexed for MEDLINE]


845. BMC Res Notes. 2015 Sep 26;8:479. doi: 10.1186/s13104-015-1462-8.

PanFP: pangenome-based functional profiles for microbial communities.

Jun SR(1,)(2), Robeson MS(3,)(4), Hauser LJ(5), Schadt CW(6,)(7), Gorin AA(8).

Author information: 
(1)Comparative Genomics Group, Bioscience Division, Oak Ridge National
Laboratory, Oak Ridge, TN, USA. junse@ornl.gov. (2)Joint Institute for
Computational Sciences, University of Tennessee, Knoxville, TN, USA.
junse@ornl.gov. (3)Systems Genetics, Biosciences Division, Oak Ridge National
Laboratory, Oak Ridge, TN, USA. robesonms@ornl.gov. (4)Fish, Wildlife and
Conservation Biology, Colorado State University, Fort Collins, CO, USA.
robesonms@ornl.gov. (5)Comparative Genomics Group, Bioscience Division, Oak Ridge
National Laboratory, Oak Ridge, TN, USA. hauserlj@ornl.gov. (6)Systems Genetics, 
Biosciences Division, Oak Ridge National Laboratory, Oak Ridge, TN, USA.
schadtcw@ornl.gov. (7)Department of Microbiology, University of Tennessee,
Knoxville, TN, USA. schadtcw@ornl.gov. (8)Computer Science and Mathematics
Division, Oak Ridge National Laboratory, Oak Ridge, TN, USA. agor@ornl.gov.

BACKGROUND: For decades there has been increasing interest in understanding the
relationships between microbial communities and ecosystem functions. Current DNA 
sequencing technologies allows for the exploration of microbial communities in
two principle ways: targeted rRNA gene surveys and shotgun metagenomics. For
large study designs, it is often still prohibitively expensive to sequence
metagenomes at both the breadth and depth necessary to statistically capture the 
true functional diversity of a community. Although rRNA gene surveys provide no
direct evidence of function, they do provide a reasonable estimation of microbial
diversity, while being a very cost-effective way to screen samples of interest
for later shotgun metagenomic analyses. However, there is a great deal of 16S
rRNA gene survey data currently available from diverse environments, and thus a
need for tools to infer functional composition of environmental samples based on 
16S rRNA gene survey data.
RESULTS: We present a computational method called pangenome-based functional
profiles (PanFP), which infers functional profiles of microbial communities from 
16S rRNA gene survey data for Bacteria and Archaea. PanFP is based on pangenome
reconstruction of a 16S rRNA gene operational taxonomic unit (OTU) from known
genes and genomes pooled from the OTU's taxonomic lineage. From this lineage, we 
derive an OTU functional profile by weighting a pangenome's functional profile
with the OTUs abundance observed in a given sample. We validated our method by
comparing PanFP to the functional profiles obtained from the direct shotgun
metagenomic measurement of 65 diverse communities via Spearman correlation
coefficients. These correlations improved with increasing sequencing depth,
within the range of 0.8-0.9 for the most deeply sequenced Human Microbiome
Project mock community samples. PanFP is very similar in performance to another
recently released tool, PICRUSt, for almost all of survey data analysed here.
But, our method is unique in that any OTU building method can be used, as opposed
to being limited to closed-reference OTU picking strategies against specific
reference sequence databases.
CONCLUSIONS: We developed an automated computational method, which derives an
inferred functional profile based on the 16S rRNA gene surveys of microbial
communities. The inferred functional profile provides a cost effective way to
study complex ecosystems through predicted comparative functional metagenomes and
metadata analysis. All PanFP source code and additional documentation are freely 
available online at GitHub ( https://github.com/srjun/PanFP ).

DOI: 10.1186/s13104-015-1462-8 
PMCID: PMC4584126
PMID: 26409790  [PubMed - indexed for MEDLINE]


846. J Mol Graph Model. 2015 Nov;62:118-27. doi: 10.1016/j.jmgm.2015.09.013. Epub 2015
Sep 16.

PrinCCes: Continuity-based geometric decomposition and systematic visualization
of the void repertoire of proteins.

Czirják G(1).

Author information: 
(1)Department of Physiology, Semmelweis University, P.O. Box 259, H-1444
Budapest, Hungary. Electronic address: czirjak.gabor@med.semmelweis-univ.hu.

Grooves and pockets on the surface, channels through the protein, the chambers or
cavities, and the tunnels connecting the internal points to each other or to the 
external fluid environment are fundamental determinants of a wide range of
biological functions. PrinCCes (Protein internal Channel & Cavity estimation) is 
a computer program supporting the visualization of voids. It includes a novel
algorithm for the decomposition of the entire void volume of the protein or
protein complex to individual entities. The decomposition is based on continuity.
An individual void is defined by uninterrupted extension in space: a spherical
probe can freely move between any two internal locations of a continuous void.
Continuous voids are detected irrespective of their topological complexity, they 
may contain any number of holes and bifurcations. The voids of a protein can be
visualized one by one or in combinations as triangulated surfaces. The output is 
automatically exported to free VMD (Visual Molecular Dynamics) or Chimera
software, allowing the 3D rotation of the surfaces and the production of
publication quality images. PrinCCes with graphic user interface and command line
versions are available for MS Windows and Linux. The source code and executable
can be downloaded at any of the following links:
http://scholar.semmelweis.hu/czirjakgabor/s/princces/#t1
https://github.com/CzirjakGabor/PrinCCes http://1drv.ms/1bP9iJ3.

Copyright © 2015 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.jmgm.2015.09.013 
PMID: 26409191  [PubMed - indexed for MEDLINE]


847. OMICS. 2015 Oct;19(10):648-58. doi: 10.1089/omi.2015.0095. Epub 2015 Sep 25.

Harnessing Computational Biology for Exact Linear B-Cell Epitope Prediction: A
Novel Amino Acid Composition-Based Feature Descriptor.

Saravanan V(1), Gautham N(1).

Author information: 
(1)Center for Advanced Study in Crystallography and Biophysics , University of
Madras, Guindy Campus, Chennai, Tamil Nadu, India .

Proteins embody epitopes that serve as their antigenic determinants. Epitopes
occupy a central place in integrative biology, not to mention as targets for
novel vaccine, pharmaceutical, and systems diagnostics development. The presence 
of T-cell and B-cell epitopes has been extensively studied due to their potential
in synthetic vaccine design. However, reliable prediction of linear B-cell
epitope remains a formidable challenge. Earlier studies have reported discrepancy
in amino acid composition between the epitopes and non-epitopes. Hence, this
study proposed and developed a novel amino acid composition-based feature
descriptor, Dipeptide Deviation from Expected Mean (DDE), to distinguish the
linear B-cell epitopes from non-epitopes effectively. In this study, for the
first time, only exact linear B-cell epitopes and non-epitopes have been utilized
for developing the prediction method, unlike the use of epitope-containing
regions in earlier reports. To evaluate the performance of the DDE feature
vector, models have been developed with two widely used machine-learning
techniques Support Vector Machine and AdaBoost-Random Forest. Five-fold
cross-validation performance of the proposed method with error-free dataset and
dataset from other studies achieved an overall accuracy between nearly 61% and
73%, with balance between sensitivity and specificity metrics. Performance of the
DDE feature vector was better (with accuracy difference of about 2% to 12%), in
comparison to other amino acid-derived features on different datasets. This study
reflects the efficiency of the DDE feature vector in enhancing the linear B-cell 
epitope prediction performance, compared to other feature representations. The
proposed method is made as a stand-alone tool available freely for researchers,
particularly for those interested in vaccine design and novel molecular target
development for systems therapeutics and diagnostics:
https://github.com/brsaran/LBEEP.

DOI: 10.1089/omi.2015.0095 
PMID: 26406767  [PubMed - indexed for MEDLINE]


848. PLoS One. 2015 Sep 25;10(9):e0138030. doi: 10.1371/journal.pone.0138030.
eCollection 2015.

msCentipede: Modeling Heterogeneity across Genomic Sites and Replicates Improves 
Accuracy in the Inference of Transcription Factor Binding.

Raj A(1), Shim H(2), Gilad Y(2), Pritchard JK(3), Stephens M(4).

Author information: 
(1)Department of Genetics, Stanford University, Stanford, California, United
States of America. (2)Department of Human Genetics, University of Chicago,
Chicago, Illinois, United States of America. (3)Department of Genetics, Stanford 
University, Stanford, California, United States of America; Department of
Biology, Stanford University, Stanford, California, United States of America;
Howard Hughes Medical Institute, Chevy Chase, Maryland, United States of America.
(4)Department of Human Genetics, University of Chicago, Chicago, Illinois, United
States of America; Department of Statistics, University of Chicago, Chicago,
Illinois, United States of America.

Understanding global gene regulation depends critically on accurate annotation of
regulatory elements that are functional in a given cell type. CENTIPEDE, a
powerful, probabilistic framework for identifying transcription factor binding
sites from tissue-specific DNase I cleavage patterns and genomic sequence
content, leverages the hypersensitivity of factor-bound chromatin and the
information in the DNase I spatial cleavage profile characteristic of each DNA
binding protein to accurately infer functional factor binding sites. However, the
model for the spatial profile in this framework fails to account for the
substantial variation in the DNase I cleavage profiles across different binding
sites. Neither does it account for variation in the profiles at the same binding 
site across multiple replicate DNase I experiments, which are increasingly
available. In this work, we introduce new methods, based on multi-scale models
for inhomogeneous Poisson processes, to account for such variation in DNase I
cleavage patterns both within and across binding sites. These models account for 
the spatial structure in the heterogeneity in DNase I cleavage patterns for each 
factor. Using DNase-seq measurements assayed in a lymphoblastoid cell line, we
demonstrate the improved performance of this model for several transcription
factors by comparing against the Chip-seq peaks for those factors. Finally, we
explore the effects of DNase I sequence bias on inference of factor binding using
a simple extension to our framework that allows for a more flexible background
model. The proposed model can also be easily applied to paired-end ATAC-seq and
DNase-seq data. msCentipede, a Python implementation of our algorithm, is
available at http://rajanil.github.io/msCentipede.

DOI: 10.1371/journal.pone.0138030 
PMCID: PMC4583425
PMID: 26406244  [PubMed - indexed for MEDLINE]


849. BMC Bioinformatics. 2015 Sep 24;16:307. doi: 10.1186/s12859-015-0729-3.

htsint: a Python library for sequencing pipelines that combines data through gene
set generation.

Richards AJ(1), Herrel A(2,)(3), Bonneaud C(4,)(5).

Author information: 
(1)Station d'Ecologie Expérimentale du CNRS, USR 2936, Route du CNRS, Moulis,
09200, France. adamricha@gmail.com. (2)UMR 7179 CNRS/MNHN, Département d'Ecologie
et de Gestion de la Biodiversité 57 rue Cuvier, Case postale 55, Paris, 75231,
France. anthony.herrel@mnhn.fr. (3)Ghent University, Evolutionary Morphology of
Vertebrates, K.L. Ledeganckstraat 35, Ghent, B-9000, Belgium.
anthony.herrel@mnhn.fr. (4)Station d'Ecologie Expérimentale du CNRS, USR 2936,
Route du CNRS, Moulis, 09200, France. C.Bonneaud@exeter.ac.uk. (5)Centre for
Ecology & Conservation, College of Life and Environmental Sciences, University of
Exeter, Penryn TR10 9FE, Cornwall, UK. C.Bonneaud@exeter.ac.uk.

BACKGROUND: Sequencing technologies provide a wealth of details in terms of
genes, expression, splice variants, polymorphisms, and other features. A standard
for sequencing analysis pipelines is to put genomic or transcriptomic features
into a context of known functional information, but the relationships between
ontology terms are often ignored. For RNA-Seq, considering genes and their
genetic variants at the group level enables a convenient way to both integrate
annotation data and detect small coordinated changes between experimental
conditions, a known caveat of gene level analyses.
RESULTS: We introduce the high throughput data integration tool, htsint, as an
extension to the commonly used gene set enrichment frameworks. The central aim of
htsint is to compile annotation information from one or more taxa in order to
calculate functional distances among all genes in a specified gene space.
Spectral clustering is then used to partition the genes, thereby generating
functional modules. The gene space can range from a targeted list of genes, like 
a specific pathway, all the way to an ensemble of genomes. Given a collection of 
gene sets and a count matrix of transcriptomic features (e.g. expression,
polymorphisms), the gene sets produced by htsint can be tested for 'enrichment'
or conditional differences using one of a number of commonly available packages.
CONCLUSION: The database and bundled tools to generate functional modules were
designed with sequencing pipelines in mind, but the toolkit nature of htsint
allows it to also be used in other areas of genomics. The software is freely
available as a Python library through GitHub at
https://github.com/ajrichards/htsint.

DOI: 10.1186/s12859-015-0729-3 
PMCID: PMC4581156
PMID: 26399714  [PubMed - indexed for MEDLINE]


850. PLoS One. 2015 Sep 23;10(9):e0139047. doi: 10.1371/journal.pone.0139047.
eCollection 2015.

Pyvolve: A Flexible Python Module for Simulating Sequences along Phylogenies.

Spielman SJ(1), Wilke CO(1).

Author information: 
(1)Department of Integrative Biology, Center for Computational Biology and
Bioinformatics, and Institute of Cellular and Molecular Biology, The University
of Texas at Austin, Austin, TX 78712, United States of America.

We introduce Pyvolve, a flexible Python module for simulating genetic data along 
a phylogeny using continuous-time Markov models of sequence evolution. Easily
incorporated into Python bioinformatics pipelines, Pyvolve can simulate sequences
according to most standard models of nucleotide, amino-acid, and codon sequence
evolution. All model parameters are fully customizable. Users can additionally
specify custom evolutionary models, with custom rate matrices and/or states to
evolve. This flexibility makes Pyvolve a convenient framework not only for
simulating sequences under a wide variety of conditions, but also for developing 
and testing new evolutionary models. Pyvolve is an open-source project under a
FreeBSD license, and it is available for download, along with a detailed
user-manual and example scripts, from http://github.com/sjspielman/pyvolve.

DOI: 10.1371/journal.pone.0139047 
PMCID: PMC4580465
PMID: 26397960  [PubMed - indexed for MEDLINE]


851. Bioinformatics. 2016 Jan 15;32(2):252-9. doi: 10.1093/bioinformatics/btv550. Epub
2015 Sep 22.

Positive-unlabeled ensemble learning for kinase substrate prediction from dynamic
phosphoproteomics data.

Yang P(1), Humphrey SJ(2), James DE(3), Yang YH(4), Jothi R(1).

Author information: 
(1)Systems Biology Section, Epigenetics & Stem Cell Biology Laboratory, National 
Institute of Environmental Health Sciences, National Institutes of Health, RTP,
NC 27709, USA. (2)Department of Proteomics and Signal Transduction,
Max-Planck-Institute of Biochemistry, Martinsried, Germany. (3)Charles Perkins
Centre, School of Molecular Bioscience, Sydney Medical School and. (4)School of
Mathematics and Statistics, The University of Sydney, NSW 2006, Australia.

MOTIVATION: Protein phosphorylation is a post-translational modification that
underlines various aspects of cellular signaling. A key step to reconstructing
signaling networks involves identification of the set of all kinases and their
substrates. Experimental characterization of kinase substrates is both expensive 
and time-consuming. To expedite the discovery of novel substrates, computational 
approaches based on kinase recognition sequence (motifs) from known substrates,
protein structure, interaction and co-localization have been proposed. However,
rarely do these methods take into account the dynamic responses of signaling
cascades measured from in vivo cellular systems. Given that recent advances in
mass spectrometry-based technologies make it possible to quantify phosphorylation
on a proteome-wide scale, computational approaches that can integrate static
features with dynamic phosphoproteome data would greatly facilitate the
prediction of biologically relevant kinase-specific substrates.
RESULTS: Here, we propose a positive-unlabeled ensemble learning approach that
integrates dynamic phosphoproteomics data with static kinase recognition motifs
to predict novel substrates for kinases of interest. We extended a
positive-unlabeled learning technique for an ensemble model, which significantly 
improves prediction sensitivity on novel substrates of kinases while retaining
high specificity. We evaluated the performance of the proposed model using
simulation studies and subsequently applied it to predict novel substrates of key
kinases relevant to insulin signaling. Our analyses show that static sequence
motifs and dynamic phosphoproteomics data are complementary and that the proposed
integrated model performs better than methods relying only on static information 
for accurate prediction of kinase-specific substrates.
AVAILABILITY AND IMPLEMENTATION: Executable GUI tool, source code and
documentation are freely available at https://github.com/PengyiYang/KSP-PUEL.
CONTACT: pengyi.yang@nih.gov or jothi@mail.nih.gov
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

Published by Oxford University Press 2015. This work is written by US Government 
employees and is in the public domain in the US.

DOI: 10.1093/bioinformatics/btv550 
PMCID: PMC4739180
PMID: 26395771  [PubMed - indexed for MEDLINE]


852. Mol Ecol Resour. 2016 Mar;16(2):534-9. doi: 10.1111/1755-0998.12469. Epub 2015
Oct 12.

HYBRIDCHECK: software for the rapid detection, visualization and dating of
recombinant regions in genome sequence data.

Ward BJ(1), van Oosterhout C(1).

Author information: 
(1)School of Environmental Sciences, Norwich Research Park, University of East
Anglia, Norwich, NR4 7TJ, UK.

HYBRIDCHECK is a software package to visualize the recombination signal in large 
DNA sequence data set, and it can be used to analyse recombination, genetic
introgression, hybridization and horizontal gene transfer. It can scan large
(multiple kb) contigs and whole-genome sequences of three or more individuals.
HYBRIDCHECK is written in the r software for OS X, Linux and Windows operating
systems, and it has a simple graphical user interface. In addition, the r code
can be readily incorporated in scripts and analysis pipelines. HYBRIDCHECK
implements several ABBA-BABA tests and visualizes the effects of hybridization
and the resulting mosaic-like genome structure in high-density graphics. The
package also reports the following: (i) the breakpoint positions, (ii) the number
of mutations in each introgressed block, (iii) the probability that the
identified region is not caused by recombination and (iv) the estimated age of
each recombination event. The divergence times between the donor and recombinant 
sequence are calculated using a JC, K80, F81, HKY or GTR correction, and the
dating algorithm is exceedingly fast. By estimating the coalescence time of
introgressed blocks, it is possible to distinguish between hybridization and
incomplete lineage sorting. HYBRIDCHECK is libré software and it and its manual
are free to download from http://ward9250.github.io/HybridCheck/.

© 2015 John Wiley & Sons Ltd.

DOI: 10.1111/1755-0998.12469 
PMID: 26394708  [PubMed - indexed for MEDLINE]


853. Genome Biol. 2015 Sep 21;16:198. doi: 10.1186/s13059-015-0767-1.

HiCPlotter integrates genomic data with interaction matrices.

Akdemir KC(1), Chin L(2,)(3).

Author information: 
(1)Department of Genomic Medicine, Division of Cancer Medicine, The University of
Texas MD Anderson Cancer Center, Houston, TX, 77030, USA.
kcakedemir@mdanderson.org. (2)Department of Genomic Medicine, Division of Cancer 
Medicine, The University of Texas MD Anderson Cancer Center, Houston, TX, 77030, 
USA. lchin@mdanderson.org. (3)Institute for Applied Cancer Science, The
University of Texas MD Anderson Cancer Center, Houston, TX, 77030, USA.
lchin@mdanderson.org.

Metazoan genomic material is folded into stable non-randomly arranged chromosomal
structures that are tightly associated with transcriptional regulation and DNA
replication. Various factors including regulators of pluripotency, long
non-coding RNAs, or the presence of architectural proteins have been implicated
in regulation and assembly of the chromatin architecture. Therefore,
comprehensive visualization of this multi-faceted structure is important to
unravel the connections between nuclear architecture and transcriptional
regulation. Here, we present an easy-to-use open-source visualization tool,
HiCPlotter, to facilitate juxtaposition of Hi-C matrices with diverse genomic
assay outputs, as well as to compare interaction matrices between various
conditions. https://github.com/kcakdemir/HiCPlotter.

DOI: 10.1186/s13059-015-0767-1 
PMCID: PMC4576377
PMID: 26392354  [PubMed - indexed for MEDLINE]


854. J Chem Inf Model. 2015 Oct 26;55(10):2288-96. doi: 10.1021/acs.jcim.5b00262. Epub
2015 Oct 4.

Pcetk: A pDynamo-based Toolkit for Protonation State Calculations in Proteins.

Feliks M(1,)(2,)(3), Field MJ(1,)(2,)(3).

Author information: 
(1)Université Grenoble Alpes, IBS , F-38044 Grenoble, France. (2)CNRS, IBS ,
F-38044 Grenoble, France. (3)CEA, IBS , F-38044 Grenoble, France.

Pcetk (a pDynamo-based continuum electrostatic toolkit) is an open-source,
object-oriented toolkit for the calculation of proton binding energetics in
proteins. The toolkit is a module of the pDynamo software library, combining the 
versatility of the Python scripting language and the efficiency of the compiled
languages, C and Cython. In the toolkit, we have connected pDynamo to the
external Poisson-Boltzmann solver, extended-MEAD. Our goal was to provide a
modern and extensible environment for the calculation of protonation states,
electrostatic energies, titration curves, and other electrostatic-dependent
properties of proteins. Pcetk is freely available under the CeCILL license, which
is compatible with the GNU General Public License. The toolkit can be found on
the Web at the address http://github.com/mfx9/pcetk. The calculation of
protonation states in proteins requires a knowledge of pKa values of protonatable
groups in aqueous solution. However, for some groups, such as protonatable
ligands bound to protein, the pKa aq values are often difficult to obtain from
experiment. As a complement to Pcetk, we revisit an earlier computational method 
for the estimation of pKa aq values that has an accuracy of ± 0.5 pKa-units or
better. Finally, we verify the Pcetk module and the method for estimating pKa aq 
values with different model cases.

DOI: 10.1021/acs.jcim.5b00262 
PMID: 26391627  [PubMed - indexed for MEDLINE]


855. Bioinformatics. 2016 Jan 1;32(1):142-4. doi: 10.1093/bioinformatics/btv540. Epub 
2015 Sep 17.

NanoOK: multi-reference alignment analysis of nanopore sequencing data, quality
and error profiles.

Leggett RM(1), Heavens D(1), Caccamo M(1), Clark MD(1), Davey RP(1).

Author information: 
(1)The Genome Analysis Centre (TGAC), Norwich NR4 7UH, UK.

MOTIVATION: The Oxford Nanopore MinION sequencer, currently in pre-release
testing through the MinION Access Programme (MAP), promises long reads in
real-time from an inexpensive, compact, USB device. Tools have been released to
extract FASTA/Q from the MinION base calling output and to provide basic yield
statistics. However, no single tool yet exists to provide comprehensive
alignment-based quality control and error profile analysis--something that is
extremely important given the speed with which the platform is evolving.
RESULTS: NanoOK generates detailed tabular and graphical output plus an in-depth 
multi-page PDF report including error profile, quality and yield data. NanoOK is 
multi-reference, enabling detailed analysis of metagenomic or multiplexed
samples. Four popular Nanopore aligners are supported and it is easily extensible
to include others.
AVAILABILITY AND IMPLEMENTATION: NanoOK is an open-source software, implemented
in Java with supporting R scripts. It has been tested on Linux and Mac OS X and
can be downloaded from https://github.com/TGAC/NanoOK. A VirtualBox VM containing
all dependencies and the DH10B read set used in this article is available from
http://opendata.tgac.ac.uk/nanook/. A Docker image is also available from Docker 
Hub--see program documentation https://documentation.tgac.ac.uk/display/NANOOK.
CONTACT: richard.leggett@tgac.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv540 
PMCID: PMC4681994
PMID: 26382197  [PubMed - indexed for MEDLINE]


856. Bioinformatics. 2016 Jan 1;32(1):133-5. doi: 10.1093/bioinformatics/btv547. Epub 
2015 Sep 17.

CLAMMS: a scalable algorithm for calling common and rare copy number variants
from exome sequencing data.

Packer JS(1), Maxwell EK(1), O'Dushlaine C(1), Lopez AE(1), Dewey FE(1),
Chernomorsky R(1), Baras A(1), Overton JD(1), Habegger L(1), Reid JG(1).

Author information: 
(1)Regeneron Genetics Center, Tarrytown, NY 10591, USA.

MOTIVATION: Several algorithms exist for detecting copy number variants (CNVs)
from human exome sequencing read depth, but previous tools have not been well
suited for large population studies on the order of tens or hundreds of thousands
of exomes. Their limitations include being difficult to integrate into automated 
variant-calling pipelines and being ill-suited for detecting common variants. To 
address these issues, we developed a new algorithm--Copy number estimation using 
Lattice-Aligned Mixture Models (CLAMMS)--which is highly scalable and suitable
for detecting CNVs across the whole allele frequency spectrum.
RESULTS: In this note, we summarize the methods and intended use-case of CLAMMS, 
compare it to previous algorithms and briefly describe results of validation
experiments. We evaluate the adherence of CNV calls from CLAMMS and four other
algorithms to Mendelian inheritance patterns on a pedigree; we compare calls from
CLAMMS and other algorithms to calls from SNP genotyping arrays for a set of 3164
samples; and we use TaqMan quantitative polymerase chain reaction to validate
CNVs predicted by CLAMMS at 39 loci (95% of rare variants validate; across 19
common variant loci, the mean precision and recall are 99% and 94%,
respectively). In the Supplementary Materials (available at the CLAMMS Github
repository), we present our methods and validation results in greater detail.
AVAILABILITY AND IMPLEMENTATION: https://github.com/rgcgithub/clamms (implemented
in C).
CONTACT: jeffrey.reid@regeneron.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv547 
PMCID: PMC4681995
PMID: 26382196  [PubMed - indexed for MEDLINE]


857. Bioinformatics. 2016 Jan 1;32(1):154-6. doi: 10.1093/bioinformatics/btv514. Epub 
2015 Sep 17.

ICT: isotope correction toolbox.

Jungreuthmayer C(1), Neubauer S(2), Mairinger T(2), Zanghellini J(1), Hann S(2).

Author information: 
(1)Austrian Centre of Industrial Biotechnology (ACIB), Vienna, Austria,
Department of Biotechnology, University of Natural Resources and Life Sciences,
Vienna, Austria and. (2)Austrian Centre of Industrial Biotechnology (ACIB),
Vienna, Austria, Department of Chemistry, University of Natural Resources and
Life Sciences, Vienna, Austria.

SUMMARY: Isotope tracer experiments are an invaluable technique to analyze and
study the metabolism of biological systems. However, isotope labeling experiments
are often affected by naturally abundant isotopes especially in cases where mass 
spectrometric methods make use of derivatization. The correction of these
additive interferences--in particular for complex isotopic systems--is
numerically challenging and still an emerging field of research. When positional 
information is generated via collision-induced dissociation, even more complex
calculations for isotopic interference correction are necessary. So far, no
freely available tools can handle tandem mass spectrometry data. We present
isotope correction toolbox, a program that corrects tandem mass isotopomer data
from tandem mass spectrometry experiments. Isotope correction toolbox is written 
in the multi-platform programming language Perl and, therefore, can be used on
all commonly available computer platforms.
AVAILABILITY AND IMPLEMENTATION: Source code and documentation can be freely
obtained under the Artistic License or the GNU General Public License from:
https://github.com/jungreuc/isotope_correction_toolbox/
CONTACT: {christian.jungreuthmayer@boku.ac.at,juergen.zanghellini@boku.ac.at}
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv514 
PMID: 26382193  [PubMed - indexed for MEDLINE]


858. Comput Biol Chem. 2015 Dec;59 Pt B:98-112. doi:
10.1016/j.compbiolchem.2015.08.002. Epub 2015 Sep 1.

A robust and efficient method for estimating enzyme complex abundance and
metabolic flux from expression data.

Barker BE(1), Sadagopan N(2), Wang Y(3), Smallbone K(4), Myers CR(5), Xi H(6),
Locasale JW(7), Gu Z(8).

Author information: 
(1)Center for Advanced Computing, Cornell University, 534 Rhodes Hall, Ithaca,
NY, USA. Electronic address: brandon.barker@cornell.edu. (2)Program of
Bioinformatics and Integrative Biology, University of Massachusetts Medical
School, 55 Lake Avenue North, Worcester, MA, USA. (3)Tri-Institutional Training
Program in Computational Biology and Medicine, 1300 York Avenue, Box 194, New
York, NY, USA. (4)School of Computer Science, The University of Manchester,
Manchester, UK; Manchester Center for Integrative Systems Biology, The University
of Manchester, Manchester, UK. (5)Tri-Institutional Training Program in
Computational Biology and Medicine, 1300 York Avenue, Box 194, New York, NY, USA;
Laboratory of Atomic and Solid State Physics, Cornell University, Ithaca, NY,
USA; Institute of Biotechnology, Cornell University, Ithaca, NY, USA.
(6)Department of Computer Science, Boston University, 111 Cummington Street,
Boston, MA, USA. (7)Tri-Institutional Training Program in Computational Biology
and Medicine, 1300 York Avenue, Box 194, New York, NY, USA; Division of
Nutritional Sciences, Cornell University, Savage Hall, Ithaca, NY, USA.
Electronic address: locasale@cornell.edu. (8)Tri-Institutional Training Program
in Computational Biology and Medicine, 1300 York Avenue, Box 194, New York, NY,
USA; Division of Nutritional Sciences, Cornell University, Savage Hall, Ithaca,
NY, USA. Electronic address: zg27@cornell.edu.

A major theme in constraint-based modeling is unifying experimental data, such as
biochemical information about the reactions that can occur in a system or the
composition and localization of enzyme complexes, with high-throughput data
including expression data, metabolomics, or DNA sequencing. The desired result is
to increase predictive capability and improve our understanding of metabolism.
The approach typically employed when only gene (or protein) intensities are
available is the creation of tissue-specific models, which reduces the available 
reactions in an organism model, and does not provide an objective function for
the estimation of fluxes. We develop a method, flux assignment with LAD (least
absolute deviation) convex objectives and normalization (FALCON), that employs
metabolic network reconstructions along with expression data to estimate fluxes. 
In order to use such a method, accurate measures of enzyme complex abundance are 
needed, so we first present an algorithm that addresses quantification of complex
abundance. Our extensions to prior techniques include the capability to work with
large models and significantly improved run-time performance even for smaller
models, an improved analysis of enzyme complex formation, the ability to handle
large enzyme complex rules that may incorporate multiple isoforms, and either
maintained or significantly improved correlation with experimentally measured
fluxes. FALCON has been implemented in MATLAB and ATS, and can be downloaded
from: https://github.com/bbarker/FALCON. ATS is not required to compile the
software, as intermediate C source code is available. FALCON requires use of the 
COBRA Toolbox, also implemented in MATLAB.

Copyright © 2015 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.compbiolchem.2015.08.002 
PMCID: PMC4684447
PMID: 26381164  [PubMed - indexed for MEDLINE]


859. J Cheminform. 2015 Sep 15;7:46. doi: 10.1186/s13321-015-0094-2. eCollection 2015.

RRegrs: an R package for computer-aided model selection with multiple regression 
models.

Tsiliki G(1), Munteanu CR(2), Seoane JA(3), Fernandez-Lozano C(4), Sarimveis
H(1), Willighagen EL(5).

Author information: 
(1)School of Chemical Engineering, National Technical University of Athens, 9
Heroon Polytechneiou Street, Zografou Campus, 15780 Athens, Greece. (2)Computer
Science Faculty, University of A Coruna, Campus Elviña, s/n, 15071 A Coruña,
Spain ; Department of Bioinformatics-BiGCaT, NUTRIM, Maastricht University, P.O. 
Box 616, UNS50 Box 19, 6200 MD Maastricht, The Netherlands. (3)Stanford Cancer
Institute, Stanford University, C.J.Huang Building, 780 Welch Road, Palo Alto, CA
94304 USA. (4)Computer Science Faculty, University of A Coruna, Campus Elviña,
s/n, 15071 A Coruña, Spain. (5)Department of Bioinformatics-BiGCaT, NUTRIM,
Maastricht University, P.O. Box 616, UNS50 Box 19, 6200 MD Maastricht, The
Netherlands.

BACKGROUND: Predictive regression models can be created with many different
modelling approaches. Choices need to be made for data set splitting,
cross-validation methods, specific regression parameters and best model criteria,
as they all affect the accuracy and efficiency of the produced predictive models,
and therefore, raising model reproducibility and comparison issues.
Cheminformatics and bioinformatics are extensively using predictive modelling and
exhibit a need for standardization of these methodologies in order to assist
model selection and speed up the process of predictive model development. A tool 
accessible to all users, irrespectively of their statistical knowledge, would be 
valuable if it tests several simple and complex regression models and validation 
schemes, produce unified reports, and offer the option to be integrated into more
extensive studies. Additionally, such methodology should be implemented as a free
programming package, in order to be continuously adapted and redistributed by
others.
RESULTS: We propose an integrated framework for creating multiple regression
models, called RRegrs. The tool offers the option of ten simple and complex
regression methods combined with repeated 10-fold and leave-one-out
cross-validation. Methods include Multiple Linear regression, Generalized Linear 
Model with Stepwise Feature Selection, Partial Least Squares regression, Lasso
regression, and Support Vector Machines Recursive Feature Elimination. The new
framework is an automated fully validated procedure which produces standardized
reports to quickly oversee the impact of choices in modelling algorithms and
assess the model and cross-validation results. The methodology was implemented as
an open source R package, available at https://www.github.com/enanomapper/RRegrs,
by reusing and extending on the caret package.
CONCLUSION: The universality of the new methodology is demonstrated using five
standard data sets from different scientific fields. Its efficiency in
cheminformatics and QSAR modelling is shown with three use cases: proteomics data
for surface-modified gold nanoparticles, nano-metal oxides descriptor data, and
molecular descriptors for acute aquatic toxicity data. The results show that for 
all data sets RRegrs reports models with equal or better performance for both
training and test sets than those reported in the original publications. Its good
performance as well as its adaptability in terms of parameter optimization could 
make RRegrs a popular framework to assist the initial exploration of predictive
models, and with that, the design of more comprehensive in silico screening
applications.Graphical abstractRRegrs is a computer-aided model selection
framework for R multiple regression models; this is a fully validated procedure
with application to QSAR modelling.

DOI: 10.1186/s13321-015-0094-2 
PMCID: PMC4570700
PMID: 26379782  [PubMed]


860. Bioinformatics. 2016 Jan 1;32(1):1-8. doi: 10.1093/bioinformatics/btv544. Epub
2015 Sep 15.

A non-negative matrix factorization method for detecting modules in heterogeneous
omics multi-modal data.

Yang Z(1), Michailidis G(1).

Author information: 
(1)Department of Statistics, University of Michigan, Ann Arbor, MI 48109, USA.

MOTIVATION: Recent advances in high-throughput omics technologies have enabled
biomedical researchers to collect large-scale genomic data. As a consequence,
there has been growing interest in developing methods to integrate such data to
obtain deeper insights regarding the underlying biological system. A key
challenge for integrative studies is the heterogeneity present in the different
omics data sources, which makes it difficult to discern the coordinated signal of
interest from source-specific noise or extraneous effects.
RESULTS: We introduce a novel method of multi-modal data analysis that is
designed for heterogeneous data based on non-negative matrix factorization. We
provide an algorithm for jointly decomposing the data matrices involved that also
includes a sparsity option for high-dimensional settings. The performance of the 
proposed method is evaluated on synthetic data and on real DNA methylation, gene 
expression and miRNA expression data from ovarian cancer samples obtained from
The Cancer Genome Atlas. The results show the presence of common modules across
patient samples linked to cancer-related pathways, as well as previously
established ovarian cancer subtypes.
AVAILABILITY AND IMPLEMENTATION: The source code repository is publicly available
at https://github.com/yangzi4/iNMF.
CONTACT: gmichail@umich.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv544 
PMCID: PMC5006236
PMID: 26377073  [PubMed - indexed for MEDLINE]


861. BMC Bioinformatics. 2015 Sep 15;16:294. doi: 10.1186/s12859-015-0716-8.

A weighting approach for judging the effect of patient strata on high-dimensional
risk prediction signatures.

Weyer V(1), Binder H(2).

Author information: 
(1)Institute of Medical Biostatistics, Epidemiology and Informatics (IMBEI),
University Medical Center Mainz, Johannes Gutenberg-University Mainz, Obere
Zahlbacher Strasse 69, Mainz, Germany. weyer@uni-mainz.de. (2)Institute of
Medical Biostatistics, Epidemiology and Informatics (IMBEI), University Medical
Center Mainz, Johannes Gutenberg-University Mainz, Obere Zahlbacher Strasse 69,
Mainz, Germany. binderh@uni-mainz.de.

BACKGROUND: High-dimensional molecular measurements, e.g. gene expression data,
can be linked to clinical time-to-event endpoints by Cox regression models and
regularized estimation approaches, such as componentwise boosting, and can
incorporate a large number of covariates as well as provide variable selection.
If there is heterogeneity due to known patient subgroups, a stratified Cox model 
allows for separate baseline hazards in each subgroup. Variable selection will
still depend on the relative stratum sizes in the data, which might be a
convenience sample and not representative for future applications. Such effects
need to be systematically investigated and could even help to more reliably
identify components of risk prediction signatures.
RESULTS: Correspondingly, we propose a weighted regression approach based on
componentwise likelihood-based boosting which is implemented in the R package
CoxBoost (https://github.com/binderh/CoxBoost). This approach focuses on building
a risk prediction signature for a specific stratum by down-weighting the
observations from the other strata using a range of weights. Stability of
selection for specific covariates as a function of the weights is investigated by
resampling inclusion frequencies, and two types of corresponding visualizations
are suggested. This is illustrated for two applications with methylation and gene
expression measurements from cancer patients.
CONCLUSION: The proposed approach is meant to point out components of risk
prediction signatures that are specific to the stratum of interest and components
that are also important to other strata. Performance is mostly improved by
incorporating down-weighted information from the other strata. This suggests more
general usefulness for risk prediction signature development in data with
heterogeneity due to known subgroups.

DOI: 10.1186/s12859-015-0716-8 
PMCID: PMC4572441
PMID: 26374641  [PubMed - indexed for MEDLINE]


862. Bioinformatics. 2016 Jan 1;32(1):159-60. doi: 10.1093/bioinformatics/btv543. Epub
2015 Sep 14.

PyPDB: a Python API for the Protein Data Bank.

Gilpin W(1).

Author information: 
(1)Department of Applied Physics, Stanford University, Stanford, CA 94305, USA.

SUMMARY: We have created a Python programming interface for the RCSB Protein Data
Bank (PDB) that allows search and data retrieval for a wide range of result
types, including BLAST and sequence motif queries. The API relies on the existing
XML-based API and operates by creating custom XML requests from native Python
types, allowing extensibility and straightforward modification. The package has
the ability to perform many types of advanced search of the PDB that are
otherwise only available through the PDB website.
AVAILABILITY AND IMPLEMENTATION: PyPDB is implemented exclusively in Python 3
using standard libraries for maximal compatibility. The most up-to-date version, 
including iPython notebooks containing usage tutorials, is available
free-of-charge under an open-source MIT license via GitHub at
https://github.com/williamgilpin/pypdb, and the full API reference is at
http://williamgilpin.github.io/pypdb_docs/html/. The latest stable release is
also available on PyPI.
CONTACT: wgilpin@stanford.edu.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv543 
PMID: 26369703  [PubMed - indexed for MEDLINE]


863. Bioinformatics. 2016 Jan 1;32(1):114-21. doi: 10.1093/bioinformatics/btv521. Epub
2015 Sep 11.

Human cell structure-driven model construction for predicting protein subcellular
location from biological images.

Shao W(1), Liu M(1), Zhang D(1).

Author information: 
(1)School of Computer Science and Technology, Nanjing University of Aeronautics
and Astronautics, Nanjing 210016, China.

MOTIVATION: The systematic study of subcellular location pattern is very
important for fully characterizing the human proteome. Nowadays, with the great
advances in automated microscopic imaging, accurate bioimage-based classification
methods to predict protein subcellular locations are highly desired. All existing
models were constructed on the independent parallel hypothesis, where the
cellular component classes are positioned independently in a multi-class
classification engine. The important structural information of cellular
compartments is missed. To deal with this problem for developing more accurate
models, we proposed a novel cell structure-driven classifier construction
approach (SC-PSorter) by employing the prior biological structural information in
the learning model. Specifically, the structural relationship among the cellular 
components is reflected by a new codeword matrix under the error correcting
output coding framework. Then, we construct multiple SC-PSorter-based classifiers
corresponding to the columns of the error correcting output coding codeword
matrix using a multi-kernel support vector machine classification approach.
Finally, we perform the classifier ensemble by combining those multiple
SC-PSorter-based classifiers via majority voting.
RESULTS: We evaluate our method on a collection of 1636 immunohistochemistry
images from the Human Protein Atlas database. The experimental results show that 
our method achieves an overall accuracy of 89.0%, which is 6.4% higher than the
state-of-the-art method.
AVAILABILITY AND IMPLEMENTATION: The dataset and code can be downloaded from
https://github.com/shaoweinuaa/.
CONTACT: dqzhang@nuaa.edu.cn
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv521 
PMID: 26363175  [PubMed - indexed for MEDLINE]


864. Bioinformatics. 2016 Jan 1;32(1):77-84. doi: 10.1093/bioinformatics/btv516. Epub 
2015 Sep 10.

An algorithm for automated layout of process description maps drawn in SBGN.

Genc B(1), Dogrusoz U(2).

Author information: 
(1)The Insight Centre for Data Analytics, University College Cork, Western Road, 
Cork, Ireland, Computer Engineering Department, Faculty of Engineering, Bilkent
University, Ankara 06800, Turkey and. (2)Computer Engineering Department, Faculty
of Engineering, Bilkent University, Ankara 06800, Turkey and Sander Lab, Memorial
Sloan-Kettering Cancer Center, 417 E68th St., New York, NY 10065, USA.

MOTIVATION: Evolving technology has increased the focus on genomics. The
combination of today's advanced techniques with decades of molecular biology
research has yielded huge amounts of pathway data. A standard, named the Systems 
Biology Graphical Notation (SBGN), was recently introduced to allow scientists to
represent biological pathways in an unambiguous, easy-to-understand and efficient
manner. Although there are a number of automated layout algorithms for various
types of biological networks, currently none specialize on process description
(PD) maps as defined by SBGN.
RESULTS: We propose a new automated layout algorithm for PD maps drawn in SBGN.
Our algorithm is based on a force-directed automated layout algorithm called
Compound Spring Embedder (CoSE). On top of the existing force scheme, additional 
heuristics employing new types of forces and movement rules are defined to
address SBGN-specific rules. Our algorithm is the only automatic layout algorithm
that properly addresses all SBGN rules for drawing PD maps, including placement
of substrates and products of process nodes on opposite sides, compact tiling of 
members of molecular complexes and extensively making use of nested structures
(compound nodes) to properly draw cellular locations and molecular complex
structures. As demonstrated experimentally, the algorithm results in significant 
improvements over use of a generic layout algorithm such as CoSE in addressing
SBGN rules on top of commonly accepted graph drawing criteria.
AVAILABILITY AND IMPLEMENTATION: An implementation of our algorithm in Java is
available within ChiLay library (https://github.com/iVis-at-Bilkent/chilay).
CONTACT: ugur@cs.bilkent.edu.tr or dogrusoz@cbio.mskcc.org
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv516 
PMCID: PMC4681988
PMID: 26363029  [PubMed - indexed for MEDLINE]


865. Bioinformatics. 2016 Jan 1;32(1):140-1. doi: 10.1093/bioinformatics/btv539. Epub 
2015 Sep 10.

BamHash: a checksum program for verifying the integrity of sequence data.

Óskarsdóttir A(1), Másson G(1), Melsted P(2).

Author information: 
(1)deCODE Genetics/Amgen, Reykjavík, Iceland and. (2)deCODE Genetics/Amgen,
Reykjavík, Iceland and Faculty of Industrial Engineering, Mechanical Engineering 
and Computer Science, University of Iceland, Reykjavík, Iceland.

SUMMARY: Large resequencing projects require a significant amount of storage for 
raw sequences, as well as alignment files. Because the raw sequences are
redundant once the alignment has been generated, it is possible to keep only the 
alignment files. We present BamHash, a checksum based method to ensure that the
read pairs in FASTQ files match exactly the read pairs stored in BAM files,
regardless of the ordering of reads. BamHash can be used to verify the integrity 
of the files stored and discover any discrepancies. Thus, BamHash can be used to 
determine if it is safe to delete the FASTQ files storing raw sequencing read
after alignment, without the loss of data.
AVAILABILITY AND IMPLEMENTATION: The software is implemented in C++, GPL licensed
and available at https://github.com/DecodeGenetics/BamHash
CONTACT: pmelsted@hi.is.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv539 
PMID: 26363028  [PubMed - indexed for MEDLINE]


866. BMC Proc. 2015 Aug 13;9(Suppl 6 Proceedings of the 5th Symposium on Biological
Data):S6. doi: 10.1186/1753-6561-9-S6-S6. eCollection 2015.

ReactionFlow: an interactive visualization tool for causality analysis in
biological pathways.

Dang TN(1), Murray P(1), Aurisano J(1), Forbes AG(1).

Author information: 
(1)Department of Computer Science M/C 152, University of Illinois at Chicago, 851
S. Morgan, Room 1120, Chicago 60607-7053, IL, USA.

BACKGROUND: Molecular and systems biologists are tasked with the comprehension
and analysis of incredibly complex networks of biochemical interactions, called
pathways, that occur within a cell. Through interviews with domain experts, we
identified four common tasks that require an understanding of the causality
within pathways, that is, the downstream and upstream relationships between
proteins and biochemical reactions, including: visualizing downstream
consequences of perturbing a protein; finding the shortest path between two
proteins; detecting feedback loops within the pathway; and identifying common
downstream elements from two or more proteins.
RESULTS: We introduce ReactionFlow, a visual analytics application for pathway
analysis that emphasizes the structural and causal relationships amongst
proteins, complexes, and biochemical reactions within a given pathway. To support
the identified causality analysis tasks, user interactions allow an analyst to
filter, cluster, and select pathway components across linked views. Animation is 
used to highlight the flow of activity through a pathway.
CONCLUSIONS: We evaluated ReactionFlow by providing our application to two domain
experts who have significant experience with biomolecular pathways, after which
we conducted a series of in-depth interviews focused on each of the four
causality analysis tasks. Their feedback leads us to believe that our techniques 
could be useful to researchers who must be able to understand and analyze the
complex nature of biological pathways. ReactionFlow is available at
https://github.com/CreativeCodingLab/ReactionFlow.

DOI: 10.1186/1753-6561-9-S6-S6 
PMCID: PMC4547159
PMID: 26361502  [PubMed]


867. BMC Proc. 2015 Aug 13;9(Suppl 6 Proceedings of the 5th Symposium on Biological
Data):S3. doi: 10.1186/1753-6561-9-S6-S3. eCollection 2015.

PathwayMatrix: visualizing binary relationships between proteins in biological
pathways.

Dang TN(1), Murray P(1), Forbes AG(1).

Author information: 
(1)Department of Computer Science M/C 152, University of Illinois at Chicago, 851
S. Morgan, Room 1120, Chicago 60607-7053, IL, USA.

BACKGROUND: Molecular activation pathways are inherently complex, and
understanding relations across many biochemical reactions and reaction types is
difficult. Visualizing and analyzing a pathway is a challenge due to the network 
size and the diversity of relations between proteins and molecules.
RESULTS: In this paper, we introduce PathwayMatrix, a visualization tool that
presents the binary relations between proteins in the pathway via the use of an
interactive adjacency matrix. We provide filtering, lensing, clustering, and
brushing and linking capabilities in order to present relevant details about
proteins within a pathway.
CONCLUSIONS: We evaluated PathwayMatrix by conducting a series of in-depth
interviews with domain experts who provided positive feedback, leading us to
believe that our visualization technique could be helpful for the larger
community of researchers utilizing pathway visualizations. PathwayMatrix is
freely available at https://github.com/CreativeCodingLab/PathwayMatrix.

DOI: 10.1186/1753-6561-9-S6-S3 
PMCID: PMC4547148
PMID: 26361499  [PubMed]


868. IEEE/ACM Trans Comput Biol Bioinform. 2015 Jul-Aug;12(4):795-8. doi:
10.1109/TCBB.2014.2366103.

ResSeq: Enhancing Short-Read Sequencing Alignment By Rescuing Error-Containing
Reads.

Feng W, Sang P, Lian D, Dong Y, Song F, Li M, He B, Cao F, Liu Y.

Next-generation short-read sequencing is widely utilized in genomic studies.
Biological applications require an alignment step to map sequencing reads to the 
reference genome, before acquiring expected genomic information. This requirement
makes alignment accuracy a key factor for effective biological interpretation.
Normally, when accounting for measurement errors and single nucleotide
polymorphisms, short read mappings with a few mismatches are generally considered
acceptable. However, to further improve the efficiency of short-read sequencing
alignment, we propose a method to retrieve additional reliably aligned reads
(reads with more than a pre-defined number of mismatches), using a Bayesian-based
approach. In this method, we first retrieve the sequence context around the
mismatched nucleotides within the already aligned reads; these loci contain the
genomic features where sequencing errors occur. Then, using the derived pattern, 
we evaluate the remaining (typically discarded) reads with more than the allowed 
number of mismatches, and calculate a score that represents the probability that 
a specific alignment is correct. This strategy allows the extraction of more
reliably aligned reads, therefore improving alignment sensitivity.IMPLEMENTATION:
The source code of our tool, ResSeq, can be downloaded from:
https://github.com/hrbeubiocenter/Resseq.

DOI: 10.1109/TCBB.2014.2366103 
PMID: 26357318  [PubMed - indexed for MEDLINE]


869. IEEE/ACM Trans Comput Biol Bioinform. 2014 Nov-Dec;11(6):1077-86. doi:
10.1109/TCBB.2014.2338311.

An Efficient and Very Accurate Method for Calculating Steady-State Sensitivities 
in Metabolic Reaction Systems.

Shiraishi F, Yoshida E, Voit EO.

Stability and sensitivity analyses of biological systems require the ad
hocwriting of computer code, which is highly dependent on the particular model
and burdensome for large systems. We propose a very accurate strategy to overcome
this challenge. Its core concept is the conversion of the model into the format
of biochemical systems theory (BST), which greatly facilitates the computation of
sensitivities. First, the steady state of interest is determined by integrating
the model equations toward the steady state and then using a Newton-Raphson
method to fine-tune the result. The second step of conversion into the BST format
requires several instances of numerical differentiation. The accuracy of this
task is ensured by the use of a complex-variable Taylor scheme for all
differentiation steps. The proposed strategy is implemented in a new software
program, COSMOS, which automates the stability and sensitivity analysis of
essentially arbitrary ODE models in a quick, yet highly accurate manner. The
methods underlying the process are theoretically analyzed and illustrated with
four representative examples: a simple metabolic reaction model; a model of
aspartate-derived amino acid biosynthesis; a TCA-cycle model; and a modified
TCA-cycle model. COSMOS has been deposited to
https://github.com/BioprocessdesignLab/COSMOS.

DOI: 10.1109/TCBB.2014.2338311 
PMID: 26357045  [PubMed - indexed for MEDLINE]


870. Bioinformatics. 2016 Jan 1;32(1):136-9. doi: 10.1093/bioinformatics/btv524. Epub 
2015 Sep 9.

RNF: a general framework to evaluate NGS read mappers.

Břinda K(1), Boeva V(2), Kucherov G(1).

Author information: 
(1)LIGM/CNRS, Université Paris-Est, 77454 Marne-la-Vallée, France. (2)Inserm,
U900, Bioinformatics, Biostatistics, Epidemiology and Computational Systems
Biology of Cancer, 75248 Paris, France, Institut Curie, Centre de Recherche, 26
rue d'Ulm, 75248 Paris, France and Mines ParisTech, 77300 Fontainebleau, France.

MOTIVATION: Read simulators combined with alignment evaluation tools provide the 
most straightforward way to evaluate and compare mappers. Simulation of reads is 
accompanied by information about their positions in the source genome. This
information is then used to evaluate alignments produced by the mapper. Finally, 
reports containing statistics of successful read alignments are created.In
default of standards for encoding read origins, every evaluation tool has to be
made explicitly compatible with the simulator used to generate reads.
RESULTS: To solve this obstacle, we have created a generic format Read Naming
Format (Rnf) for assigning read names with encoded information about original
positions. Futhermore, we have developed an associated software package RnfTools 
containing two principal components. MIShmash applies one of popular read
simulating tools (among DwgSim, Art, Mason, CuReSim, etc.) and transforms the
generated reads into Rnf format. LAVEnder evaluates then a given read mapper
using simulated reads in Rnf format. A special attention is payed to mapping
qualities that serve for parametrization of Roc curves, and to evaluation of the 
effect of read sample contamination.
AVAILABILITY AND IMPLEMENTATION: RnfTools: http://karel-brinda.github.io/rnftools
Spec. of Rnf: http://karel-brinda.github.io/rnf-spec
CONTACT: karel.brinda@univ-mlv.fr.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv524 
PMCID: PMC4681991
PMID: 26353839  [PubMed - indexed for MEDLINE]


871. Nucleic Acids Res. 2016 Jan 8;44(1):e8. doi: 10.1093/nar/gkv873. Epub 2015 Sep 8.

Turning publicly available gene expression data into discoveries using gene set
context analysis.

Ji Z(1), Vokes SA(2), Dang CV(3), Ji H(4).

Author information: 
(1)Department of Biostatistics, Johns Hopkins University Bloomberg School of
Public Health, 615 North Wolfe Street, Baltimore, MD 21205, USA. (2)Department of
Molecular Biosciences, The University of Texas at Austin, 2500 Speedway Stop
A4800, Austin, TX 78712, USA Institute for Cellular and Molecular Biology, The
University of Texas at Austin, 2500 Speedway Stop A4800, Austin, TX 78712, USA.
(3)Abramson Cancer Center, University of Pennsylvania, 3400 Spruce Street,
Philadelphia, PA 19104, USA. (4)Department of Biostatistics, Johns Hopkins
University Bloomberg School of Public Health, 615 North Wolfe Street, Baltimore, 
MD 21205, USA hji@jhu.edu.

Gene Set Context Analysis (GSCA) is an open source software package to help
researchers use massive amounts of publicly available gene expression data (PED) 
to make discoveries. Users can interactively visualize and explore gene and gene 
set activities in 25,000+ consistently normalized human and mouse gene expression
samples representing diverse biological contexts (e.g. different cells, tissues
and disease types, etc.). By providing one or multiple genes or gene sets as
input and specifying a gene set activity pattern of interest, users can query the
expression compendium to systematically identify biological contexts associated
with the specified gene set activity pattern. In this way, researchers with new
gene sets from their own experiments may discover previously unknown contexts of 
gene set functions and hence increase the value of their experiments. GSCA has a 
graphical user interface (GUI). The GUI makes the analysis convenient and
customizable. Analysis results can be conveniently exported as publication
quality figures and tables. GSCA is available at https://github.com/zji90/GSCA.
This software significantly lowers the bar for biomedical investigators to use
PED in their daily research for generating and screening hypotheses, which was
previously difficult because of the complexity, heterogeneity and size of the
data.

© The Author(s) 2015. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkv873 
PMCID: PMC4705686
PMID: 26350211  [PubMed - indexed for MEDLINE]


872. Methods. 2016 Jan 15;93:92-102. doi: 10.1016/j.ymeth.2015.08.016. Epub 2015 Sep
2.

Predicting protein function and other biomedical characteristics with
heterogeneous ensembles.

Whalen S(1), Pandey OP(2), Pandey G(3).

Author information: 
(1)Gladstone Institutes, University of California, San Francisco, CA, USA.
Electronic address: shwhalen@gmail.com. (2)Icahn Institute for Genomics and
Multiscale Biology and Department of Genetics and Genomic Sciences, Icahn School 
of Medicine at Mount Sinai, New York, NY, USA. Electronic address:
omprakash.pandey@mssm.edu. (3)Icahn Institute for Genomics and Multiscale Biology
and Department of Genetics and Genomic Sciences, Icahn School of Medicine at
Mount Sinai, New York, NY, USA; Graduate School of Biomedical Sciences, Icahn
School of Medicine at Mount Sinai, New York, NY, USA. Electronic address:
gaurav.pandey@mssm.edu.

Prediction problems in biomedical sciences, including protein function prediction
(PFP), are generally quite difficult. This is due in part to incomplete knowledge
of the cellular phenomenon of interest, the appropriateness and data quality of
the variables and measurements used for prediction, as well as a lack of
consensus regarding the ideal predictor for specific problems. In such scenarios,
a powerful approach to improving prediction performance is to construct
heterogeneous ensemble predictors that combine the output of diverse individual
predictors that capture complementary aspects of the problems and/or datasets. In
this paper, we demonstrate the potential of such heterogeneous ensembles, derived
from stacking and ensemble selection methods, for addressing PFP and other
similar biomedical prediction problems. Deeper analysis of these results shows
that the superior predictive ability of these methods, especially stacking, can
be attributed to their attention to the following aspects of the ensemble
learning process: (i) better balance of diversity and performance, (ii) more
effective calibration of outputs and (iii) more robust incorporation of
additional base predictors. Finally, to make the effective application of
heterogeneous ensembles to large complex datasets (big data) feasible, we present
DataSink, a distributed ensemble learning framework, and demonstrate its sound
scalability using the examined datasets. DataSink is publicly available from
https://github.com/shwhalen/datasink.

Copyright © 2015 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.ymeth.2015.08.016 
PMCID: PMC4718788
PMID: 26342255  [PubMed - indexed for MEDLINE]


873. Bioinformatics. 2016 Jan 1;32(1):9-16. doi: 10.1093/bioinformatics/btv522. Epub
2015 Sep 5.

Hammock: a hidden Markov model-based peptide clustering algorithm to identify
protein-interaction consensus motifs in large datasets.

Krejci A(1), Hupp TR(2), Lexa M(3), Vojtesek B(1), Muller P(1).

Author information: 
(1)RECAMO, Masaryk Memorial Cancer Institute, Zluty kopec 7, 65653, Brno, Czech
Republic. (2)University of Edinburgh, Institute of Genetics and Molecular
Medicine, Cancer Research Centre, Edinburgh EH4 2XR, UK and. (3)Faculty of
Informatics, Masaryk University, Botanicka 68a, 60200 Brno, Czech Republic.

MOTIVATION: Proteins often recognize their interaction partners on the basis of
short linear motifs located in disordered regions on proteins' surface.
Experimental techniques that study such motifs use short peptides to mimic the
structural properties of interacting proteins. Continued development of these
methods allows for large-scale screening, resulting in vast amounts of peptide
sequences, potentially containing information on multiple protein-protein
interactions. Processing of such datasets is a complex but essential task for
large-scale studies investigating protein-protein interactions.
RESULTS: The software tool presented in this article is able to rapidly identify 
multiple clusters of sequences carrying shared specificity motifs in massive
datasets from various sources and generate multiple sequence alignments of
identified clusters. The method was applied on a previously published smaller
dataset containing distinct classes of ligands for SH3 domains, as well as on a
new, an order of magnitude larger dataset containing epitopes for several
monoclonal antibodies. The software successfully identified clusters of sequences
mimicking epitopes of antibody targets, as well as secondary clusters revealing
that the antibodies accept some deviations from original epitope sequences.
Another test indicates that processing of even much larger datasets is
computationally feasible.
AVAILABILITY AND IMPLEMENTATION: Hammock is published under GNU GPL v. 3 license 
and is freely available as a standalone program (from
http://www.recamo.cz/en/software/hammock-cluster-peptides/) or as a tool for the 
Galaxy toolbox (from https://toolshed.g2.bx.psu.edu/view/hammock/hammock). The
source code can be downloaded from
https://github.com/hammock-dev/hammock/releases.
CONTACT: muller@mou.cz
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv522 
PMCID: PMC4681989
PMID: 26342231  [PubMed - indexed for MEDLINE]


874. Bioinformatics. 2016 Jan 1;32(1):106-13. doi: 10.1093/bioinformatics/btv476. Epub
2015 Sep 3.

Large-scale extraction of gene interactions from full-text literature using
DeepDive.

Mallory EK(1), Zhang C(2), Ré C(3), Altman RB(4).

Author information: 
(1)Biomedical Informatics Training Program, Stanford University, Stanford, CA
94305, USA. (2)Department of Computer Sciences, University of Wisconsin-Madison, 
Madison, WI 53706, USA. (3)Department of Computer Science. (4)Department of
Bioengineering, Department of Genetics and Department of Medicine, Stanford
University, Stanford, CA 94305, USA.

MOTIVATION: A complete repository of gene-gene interactions is key for
understanding cellular processes, human disease and drug response. These
gene-gene interactions include both protein-protein interactions and
transcription factor interactions. The majority of known interactions are found
in the biomedical literature. Interaction databases, such as BioGRID and ChEA,
annotate these gene-gene interactions; however, curation becomes difficult as the
literature grows exponentially. DeepDive is a trained system for extracting
information from a variety of sources, including text. In this work, we used
DeepDive to extract both protein-protein and transcription factor interactions
from over 100,000 full-text PLOS articles.
METHODS: We built an extractor for gene-gene interactions that identified
candidate gene-gene relations within an input sentence. For each candidate
relation, DeepDive computed a probability that the relation was a correct
interaction. We evaluated this system against the Database of Interacting
Proteins and against randomly curated extractions.
RESULTS: Our system achieved 76% precision and 49% recall in extracting direct
and indirect interactions involving gene symbols co-occurring in a sentence. For 
randomly curated extractions, the system achieved between 62% and 83% precision
based on direct or indirect interactions, as well as sentence-level and
document-level precision. Overall, our system extracted 3356 unique gene pairs
using 724 features from over 100,000 full-text articles.
AVAILABILITY AND IMPLEMENTATION: Application source code is publicly available at
https://github.com/edoughty/deepdive_genegene_app
CONTACT: russ.altman@stanford.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv476 
PMCID: PMC4681986
PMID: 26338771  [PubMed - indexed for MEDLINE]


875. BMC Bioinformatics. 2015 Sep 3;16:278. doi: 10.1186/s12859-015-0704-z.

EMSAR: estimation of transcript abundance from RNA-seq data by mappability-based 
segmentation and reclustering.

Lee S(1), Seo CH(2), Alver BH(1), Lee S(2,)(3), Park PJ(4,)(5).

Author information: 
(1)Department of Biomedical Informatics, Harvard Medical School, Boston, MA, USA.
(2)Emerging Technology Center, DNA link, Seoul, South Korea. (3)Ewha Womans
University, Seoul, Korea. (4)Department of Biomedical Informatics, Harvard
Medical School, Boston, MA, USA. peter_park@hms.harvard.edu. (5)Informatics
Program, Boston Children's Hospital and Division of Genetics, Brigham and Women's
Hospital, Boston, MA, USA. peter_park@hms.harvard.edu.

BACKGROUND: RNA-seq has been widely used for genome-wide expression profiling.
RNA-seq data typically consists of tens of millions of short sequenced reads from
different transcripts. However, due to sequence similarity among genes and among 
isoforms, the source of a given read is often ambiguous. Existing approaches for 
estimating expression levels from RNA-seq reads tend to compromise between
accuracy and computational cost.
RESULTS: We introduce a new approach for quantifying transcript abundance from
RNA-seq data. EMSAR (Estimation by Mappability-based Segmentation And
Reclustering) groups reads according to the set of transcripts to which they are 
mapped and finds maximum likelihood estimates using a joint Poisson model for
each optimal set of segments of transcripts. The method uses nearly all mapped
reads, including those mapped to multiple genes. With an efficient transcriptome 
indexing based on modified suffix arrays, EMSAR minimizes the use of CPU time and
memory while achieving accuracy comparable to the best existing methods.
CONCLUSIONS: EMSAR is a method for quantifying transcripts from RNA-seq data with
high accuracy and low computational cost. EMSAR is available at
https://github.com/parklab/emsar.

DOI: 10.1186/s12859-015-0704-z 
PMCID: PMC4559005
PMID: 26335049  [PubMed - indexed for MEDLINE]


876. Bioinformatics. 2015 Dec 15;31(24):4017-9. doi: 10.1093/bioinformatics/btv482.
Epub 2015 Aug 30.

BiopLib and BiopTools--a C programming library and toolset for manipulating
protein structure.

Porter CT(1), Martin AC(1).

Author information: 
(1)Institute of Structural and Molecular Biology, Division of Biosciences,
University College London, Darwin Building, Gower Street, London WC1E 6BT, UK.

We describe BiopLib, a mature C programming library for manipulating protein
structure, and BiopTools, a set of command-line tools which exploit BiopLib. The 
library also provides a small number of functions for handling protein sequence
and general purpose programming and mathematics. BiopLib transparently handles
PDBML (XML) format and standard PDB files. BiopTools provides facilities ranging 
from renumbering atoms and residues to calculation of solvent
accessibility.AVAILABILITY AND IMPLEMENTATION: BiopLib and BiopTools are
implemented in standard ANSI C. The core of the BiopLib library is a reliable PDB
parser that handles alternate occupancies and deals with compressed PDB files and
PDBML files automatically. The library is designed to be as flexible as possible,
allowing users to handle PDB data as a simple list of atoms, or in a structured
form using chains, residues and atoms. Many of the BiopTools command-line tools
act as filters, taking a PDB (or PDBML) file as input and producing a PDB (or
PDBML) file as output. All code is open source and documented using Doxygen. It
is provided under the GNU Public Licence and is available from the authors' web
site or from GitHub.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv482 
PMCID: PMC4673973
PMID: 26323716  [PubMed - indexed for MEDLINE]


877. Bioinformatics. 2015 Dec 15;31(24):4003-5. doi: 10.1093/bioinformatics/btv506.
Epub 2015 Aug 30.

BigBWA: approaching the Burrows-Wheeler aligner to Big Data technologies.

Abuín JM(1), Pichel JC(1), Pena TF(1), Amigo J(2).

Author information: 
(1)CITIUS, Universidade de Santiago de Compostela, Spain and. (2)Genomics
Medicine Group (GMX), Universidade de Santiago de Compostela, Spain.

BigBWA is a new tool that uses the Big Data technology Hadoop to boost the
performance of the Burrows-Wheeler aligner (BWA). Important reductions in the
execution times were observed when using this tool. In addition, BigBWA is fault 
tolerant and it does not require any modification of the original BWA source
code.AVAILABILITY AND IMPLEMENTATION: BigBWA is available at the project GitHub
repository: https://github.com/citiususc/BigBWA.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv506 
PMID: 26323715  [PubMed - indexed for MEDLINE]


878. Bioinformatics. 2015 Dec 15;31(24):3906-13. doi: 10.1093/bioinformatics/btv505.
Epub 2015 Aug 30.

RASER: reads aligner for SNPs and editing sites of RNA.

Ahn J(1), Xiao X(1).

Author information: 
(1)Department of Integrative Biology and Physiology and the Molecular Biology
Institute, University of California Los Angeles, Los Angeles, CA 90095, USA.

MOTIVATION: Accurate identification of genetic variants such as single-nucleotide
polymorphisms (SNPs) or RNA editing sites from RNA-Seq reads is important, yet
challenging, because it necessitates a very low false-positive rate in read
mapping. Although many read aligners are available, no single aligner was
specifically developed or tested as an effective tool for SNP and RNA editing
prediction.
RESULTS: We present RASER, an accurate read aligner with novel mapping schemes
and index tree structure that aims to reduce false-positive mappings due to
existence of highly similar regions. We demonstrate that RASER shows the best
mapping accuracy compared with other popular algorithms and highest sensitivity
in identifying multiply mapped reads. As a result, RASER displays superb efficacy
in unbiased mapping of the alternative alleles of SNPs and in identification of
RNA editing sites.
AVAILABILITY AND IMPLEMENTATION: RASER is written in C++ and freely available for
download at https://github.com/jaegyoonahn/RASER.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv505 
PMCID: PMC4692970
PMID: 26323713  [PubMed - indexed for MEDLINE]


879. Bioinformatics. 2015 Dec 15;31(24):4006-8. doi: 10.1093/bioinformatics/btv507.
Epub 2015 Aug 28.

BS-SNPer: SNP calling in bisulfite-seq data.

Gao S(1), Zou D(2), Mao L(3), Liu H(4), Song P(5), Chen Y(6), Zhao S(7), Gao
C(8), Li X(7), Gao Z(7), Fang X(7), Yang H(7), Ørntoft TF(9), Sørensen KD(9),
Bolund L(1).

Author information: 
(1)Department of Biomedicine, Aarhus University, Aarhus, Denmark, BGI Co. Ltd.,
Shenzhen 518083, China, BioInformatics Research Center (BIRC), Aarhus University,
Aarhus 8000, Denmark. (2)BGI Co. Ltd., Shenzhen 518083, China, School of
Computer, National University of Defense Technology, Changsha 410073, China.
(3)BGI Co. Ltd., Shenzhen 518083, China, Genomic Biology Laboratory, QIMR
Berghofer Medical Research Institute, Brisbane, Australia. (4)Departments of
Biostatistics and Informatics, University of Colorado-Anschutz Medical Campus,
Denver 80204, USA. (5)The Fourth People's Hospital of Shenzhen (Futian hospital),
Shenzhen, 518033, China. (6)Department of Obsterics and Gynecology,the First
Hospital Affiliated to Suzhou University, Jiangsu Suzhou 215006,China. (7)BGI Co.
Ltd., Shenzhen 518083, China. (8)College of Information Engineering, Qingdao
University, Qingdao 266071, China and. (9)Department of Molecular Medicine,
Aarhus University Hospital, Aarhus 8000, Denmark.

Sodium bisulfite conversion followed by sequencing (BS-Seq, such as whole genome 
bisulfite sequencing or reduced representation bisulfite sequencing) has become
popular for studying human epigenetic profiles. Identifying single nucleotide
polymorphisms (SNPs) is important for quantification of methylation levels and
for study of allele-specific epigenetic events such as imprinting. However, SNP
calling in such data is complex and time consuming. Here, we present an ultrafast
and memory-efficient package named BS-SNPer for the exploration of SNP sites from
BS-Seq data. Compared with Bis-SNP, a popular BS-Seq specific SNP caller,
BS-SNPer is over 100 times faster and uses less memory. BS-SNPer also offers
higher sensitivity and specificity compared with existing methods.AVAILABILITY
AND IMPLEMENTATION: BS-SNPer is written in C++ and Perl, and is freely available 
at https://github.com/hellbelly/BS-Snper.

© The Author 2015. Published by Oxford University Press. All rights reserved.

DOI: 10.1093/bioinformatics/btv507 
PMCID: PMC4673977
PMID: 26319221  [PubMed - indexed for MEDLINE]


880. Bioinformatics. 2015 Dec 15;31(24):3881-9. doi: 10.1093/bioinformatics/btv483.
Epub 2015 Aug 26.

Fast and accurate approximate inference of transcript expression from RNA-seq
data.

Hensman J(1), Papastamoulis P(2), Glaus P(3), Honkela A(4), Rattray M(2).

Author information: 
(1)Sheffield Institute for Translational Neuroscience (SITraN), Sheffield, UK.
(2)Faculty of Life Sciences. (3)School of Computer Science, The University of
Manchester, Manchester, UK and. (4)Helsinki Institute for Information Technology 
(HIIT), Department of Computer Science, University of Helsinki, Helsinki,
Finland.

MOTIVATION: Assigning RNA-seq reads to their transcript of origin is a
fundamental task in transcript expression estimation. Where ambiguities in
assignments exist due to transcripts sharing sequence, e.g. alternative isoforms 
or alleles, the problem can be solved through probabilistic inference. Bayesian
methods have been shown to provide accurate transcript abundance estimates
compared with competing methods. However, exact Bayesian inference is intractable
and approximate methods such as Markov chain Monte Carlo and Variational Bayes
(VB) are typically used. While providing a high degree of accuracy and modelling 
flexibility, standard implementations can be prohibitively slow for large
datasets and complex transcriptome annotations.
RESULTS: We propose a novel approximate inference scheme based on VB and apply it
to an existing model of transcript expression inference from RNA-seq data. Recent
advances in VB algorithmics are used to improve the convergence of the algorithm 
beyond the standard Variational Bayes Expectation Maximization algorithm. We
apply our algorithm to simulated and biological datasets, demonstrating a
significant increase in speed with only very small loss in accuracy of expression
level estimation. We carry out a comparative study against seven popular
alternative methods and demonstrate that our new algorithm provides excellent
accuracy and inter-replicate consistency while remaining competitive in
computation time.
AVAILABILITY AND IMPLEMENTATION: The methods were implemented in R and C++, and
are available as part of the BitSeq project at github.com/BitSeq. The method is
also available through the BitSeq Bioconductor package. The source code to
reproduce all simulation results can be accessed via
github.com/BitSeq/BitSeqVB_benchmarking.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv483 
PMCID: PMC4673974
PMID: 26315907  [PubMed - indexed for MEDLINE]


881. Bioinformatics. 2015 Dec 15;31(24):4029-31. doi: 10.1093/bioinformatics/btv491.
Epub 2015 Aug 26.

An interactive genome browser of association results from the UK10K cohorts
project.

Geihs M(1), Yan Y(1), Walter K(1), Huang J(1), Memari Y(1), Min JL(2), Mead D(1);
UK10K Consortium, Hubbard TJ(3), Timpson NJ(2), Down TA(4), Soranzo N(5).

Collaborators: Durbin R, Barrett J, Barroso I, Davey-Smith G, Farooqi IS, Hurles 
M, O'Rahilly S, Palotie A, Soranzo N, Spector T, Zeggini E, Beales P, Bentham J, 
Bhattacharya S, Blackwood D, Bolton P, Breen G, Chatterjee K, Collier D,
Fitzpatrick D, Gallagher L, Geschwind D, Gurling H, Humphries S, McGuffin P,
Monaco A, Muntoni F, Owen M, Raymond L, Savage D, Scambler P, Semple R, Skuse D, 
St Clair D, Timpson N.

Author information: 
(1)Wellcome Trust Sanger Institute, Genome Campus, Hinxton CB10 1HH, UK. (2)MRC
Integrative Epidemiology Unit, University of Bristol, Oakfield Grove, Bristol,
UK. (3)Wellcome Trust Sanger Institute, Genome Campus, Hinxton CB10 1HH, UK,
Department of Medical and Molecular Genetics, Division of Genetics and Molecular 
Medicine, King's College London School of Medicine, Guy's Hospital, London SE1
9RT, UK. (4)EMBL-EBI, Hinxton CB10 1SD, UK and. (5)Wellcome Trust Sanger
Institute, Genome Campus, Hinxton CB10 1HH, UK, Department of Haematology,
University of Cambridge, Cambridge CB2 1TN, UK.

High-throughput sequencing technologies survey genetic variation at genome scale 
and are increasingly used to study the contribution of rare and low-frequency
genetic variants to human traits. As part of the Cohorts arm of the UK10K
project, genetic variants called from low-read depth (average 7×) whole genome
sequencing of 3621 cohort individuals were analysed for statistical associations 
with 64 different phenotypic traits of biomedical importance. Here, we describe a
novel genome browser based on the Biodalliance platform developed to provide
interactive access to the association results of the project.AVAILABILITY AND
IMPLEMENTATION: The browser is available at http://www.uk10k.org/dalliance.html. 
Source code for the Biodalliance platform is available under a BSD license from
http://github.com/dasmoth/dalliance, and for the LD-display plugin and backend
from http://github.com/dasmoth/ldserv.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv491 
PMCID: PMC4673976
PMID: 26315906  [PubMed - indexed for MEDLINE]


882. Bioinformatics. 2015 Dec 15;31(24):3988-90. doi: 10.1093/bioinformatics/btv487.
Epub 2015 Aug 26.

EPGA2: memory-efficient de novo assembler.

Luo J(1), Wang J(2), Li W(2), Zhang Z(2), Wu FX(3), Li M(2), Pan Y(4).

Author information: 
(1)School of Information Science and Engineering, Central South University,
ChangSha, 410083, China, College of Computer Science and Technology, Henan
Polytechnic University, JiaoZuo, 454000, China. (2)School of Information Science 
and Engineering, Central South University, ChangSha, 410083, China. (3)Division
of Biomedical Engineering, University of Saskatchewan, Saskatchewan, S7N 5A9,
Canada and. (4)Department of Computer Science, Georgia State University, Atlanta,
GA 30302, USA.

MOTIVATION: In genome assembly, as coverage of sequencing and genome size
growing, most current softwares require a large memory for handling a great deal 
of sequence data. However, most researchers usually cannot meet the requirements 
of computing resources which prevent most current softwares from practical
applications.
RESULTS: In this article, we present an update algorithm called EPGA2, which
applies some new modules and can bring about improved assembly results in small
memory. For reducing peak memory in genome assembly, EPGA2 adopts
memory-efficient DSK to count K-mers and revised BCALM to construct De Bruijn
Graph. Moreover, EPGA2 parallels the step of Contigs Merging and adds Errors
Correction in its pipeline. Our experiments demonstrate that all these changes in
EPGA2 are more useful for genome assembly.
AVAILABILITY AND IMPLEMENTATION: EPGA2 is publicly available for download at
https://github.com/bioinfomaticsCSU/EPGA2.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv487 
PMID: 26315905  [PubMed - indexed for MEDLINE]


883. Bioinformatics. 2015 Dec 15;31(24):4000-2. doi: 10.1093/bioinformatics/btv501.
Epub 2015 Aug 26.

Bayexer: an accurate and fast Bayesian demultiplexer for Illumina sequences.

Yi H(1), Li Z(2), Li T(3), Zhao J(4).

Author information: 
(1)Key Laboratory of Algal Biology, Institute of Hydrobiology, Chinese Academy of
Sciences, Wuhan, Hubei 430072, China, University of Chinese Academy of Sciences, 
Beijing 100049, China. (2)State Key Laboratory of Systematic and Evolutionary
Botany, Institute of Botany, Chinese Academy of Sciences, Beijing 100093, China
and. (3)Key Laboratory of Algal Biology, Institute of Hydrobiology, Chinese
Academy of Sciences, Wuhan, Hubei 430072, China. (4)Key Laboratory of Algal
Biology, Institute of Hydrobiology, Chinese Academy of Sciences, Wuhan, Hubei
430072, China, College of Life Science, Peking University, Beijing 100871, China.

Demultiplexing is used after high-throughput sequencing to in silico assign reads
to the samples of origin based on the sequenced reads of the indices. Existing
demultiplexing tools based on the similarity between the read index and the
reference index sequences may fail to provide satisfactory results on low-quality
datasets. We developed Bayexer, a Bayesian demultiplexing algorithm for Illumina 
sequencers. Bayexer uses the information extracted directly from the contaminant 
sequences of the targeting reads as the training dataset for a naïve Bayes
classifier to assign reads. According to our evaluation, Bayexer provides higher 
capability, accuracy and speed on various real datasets than other
tools.AVAILABILITY AND IMPLEMENTATION: Bayexer is implemented in Perl and freely 
available at https://github.com/HaisiYi/Bayexer.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv501 
PMID: 26315903  [PubMed - indexed for MEDLINE]


884. Bioinformatics. 2015 Dec 15;31(24):3897-905. doi: 10.1093/bioinformatics/btv480. 
Epub 2015 Aug 26.

LncRNA-ID: Long non-coding RNA IDentification using balanced random forests.

Achawanantakun R(1), Chen J(1), Sun Y(1), Zhang Y(1).

Author information: 
(1)Department of Computer Science and Engineering, Michigan State University,
East Lansing, MI 48824, USA.

MOTIVATION: Long non-coding RNAs (lncRNAs), which are non-coding RNAs of length
above 200 nucleotides, play important biological functions such as gene
expression regulation. To fully reveal the functions of lncRNAs, a fundamental
step is to annotate them in various species. However, as lncRNAs tend to encode
one or multiple open reading frames, it is not trivial to distinguish these long 
non-coding transcripts from protein-coding genes in transcriptomic data.
RESULTS: In this work, we design a new tool that calculates the coding potential 
of a transcript using a machine learning model (random forest) based on multiple 
features including sequence characteristics of putative open reading frames,
translation scores based on ribosomal coverage, and conservation against
characterized protein families. The experimental results show that our tool
competes favorably with existing coding potential computation tools in lncRNA
identification.
AVAILABILITY AND IMPLEMENTATION: The scripts and data can be downloaded at
https://github.com/zhangy72/LncRNA-ID.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv480 
PMID: 26315901  [PubMed - indexed for MEDLINE]


885. Bioinformatics. 2015 Dec 15;31(24):4023-5. doi: 10.1093/bioinformatics/btv492.
Epub 2015 Aug 26.

InteractiveROSETTA: a graphical user interface for the PyRosetta protein modeling
suite.

Schenkelberg CD(1), Bystroff C(2).

Author information: 
(1)Department of Biological Sciences and. (2)Department of Biological Sciences
and Department of Computer Science, Rensselaer Polytechnic Institute, Troy, NY
12180, USA.

Modern biotechnical research is becoming increasingly reliant on computational
structural modeling programs to develop novel solutions to scientific questions. 
Rosetta is one such protein modeling suite that has already demonstrated wide
applicability to a number of diverse research projects. Unfortunately, Rosetta is
largely a command-line-driven software package which restricts its use among
non-computational researchers. Some graphical interfaces for Rosetta exist, but
typically are not as sophisticated as commercial software. Here, we present
InteractiveROSETTA, a graphical interface for the PyRosetta framework that
presents easy-to-use controls for several of the most widely used Rosetta
protocols alongside a sophisticated selection system utilizing PyMOL as a
visualizer. InteractiveROSETTA is also capable of interacting with remote Rosetta
servers, facilitating sophisticated protocols that are not accessible in
PyRosetta or which require greater computational resources.AVAILABILITY AND
IMPLEMENTATION: InteractiveROSETTA is freely available at
https://github.com/schenc3/InteractiveROSETTA/releases and relies upon a separate
download of PyRosetta which is available at http://www.pyrosetta.org after
obtaining a license (free for academic use).

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv492 
PMCID: PMC5013933
PMID: 26315900  [PubMed - indexed for MEDLINE]


886. Bioinformatics. 2015 Dec 15;31(24):3994-6. doi: 10.1093/bioinformatics/btv478.
Epub 2015 Aug 18.

svviz: a read viewer for validating structural variants.

Spies N(1), Zook JM(2), Salit M(3), Sidow A(4).

Author information: 
(1)Department of Genetics, Stanford University, Department of Pathology, Stanford
University, Genome Scale Measurements Group, National Institute of Standards and 
Technology, Stanford, CA, USA and. (2)Genome Scale Measurements Group, National
Institute of Standards and Technology, Gaithersburg, MD, USA. (3)Genome Scale
Measurements Group, National Institute of Standards and Technology, Stanford, CA,
USA and. (4)Department of Genetics, Stanford University, Department of Pathology,
Stanford University.

Visualizing read alignments is the most effective way to validate candidate
structural variants (SVs) with existing data. We present svviz, a sequencing read
visualizer for SVs that sorts and displays only reads relevant to a candidate SV.
svviz works by searching input bam(s) for potentially relevant reads, realigning 
them against the inferred sequence of the putative variant allele as well as the 
reference allele and identifying reads that match one allele better than the
other. Separate views of the two alleles are then displayed in a scrollable web
browser view, enabling a more intuitive visualization of each allele, compared
with the single reference genome-based view common to most current read browsers.
The browser view facilitates examining the evidence for or against a putative
variant, estimating zygosity, visualizing affected genomic annotations and manual
refinement of breakpoints. svviz supports data from most modern sequencing
platforms.AVAILABILITY AND IMPLEMENTATION: svviz is implemented in python and
freely available from http://svviz.github.io/.

Published by Oxford University Press 2015. This work is written by US Government 
employees and is in the public domain in the US.

DOI: 10.1093/bioinformatics/btv478 
PMID: 26286809  [PubMed - indexed for MEDLINE]


887. BMC Res Notes. 2015 Aug 19;8:359. doi: 10.1186/s13104-015-1309-3.

Molgenis-impute: imputation pipeline in a box.

Kanterakis A(1), Deelen P(2), van Dijk F(3), Byelas H(4), Dijkstra M(5), Swertz
MA(6).

Author information: 
(1)Department of Genetics, Genomics Coordination Center, University Medical
Center Groningen and University of Groningen, Genetics, UMCG, PO Box 30 001, 9700
RB, Groningen, The Netherlands. alexandros.kanterakis@gmail.com. (2)Department of
Genetics, Genomics Coordination Center, University Medical Center Groningen and
University of Groningen, Genetics, UMCG, PO Box 30 001, 9700 RB, Groningen, The
Netherlands. patrickdeelen@gmail.com. (3)Department of Genetics, Genomics
Coordination Center, University Medical Center Groningen and University of
Groningen, Genetics, UMCG, PO Box 30 001, 9700 RB, Groningen, The Netherlands.
f.van.dijk02@umcg.nl. (4)Department of Genetics, Genomics Coordination Center,
University Medical Center Groningen and University of Groningen, Genetics, UMCG, 
PO Box 30 001, 9700 RB, Groningen, The Netherlands. h.v.byelas01@umcg.nl.
(5)Department of Genetics, Genomics Coordination Center, University Medical
Center Groningen and University of Groningen, Genetics, UMCG, PO Box 30 001, 9700
RB, Groningen, The Netherlands. m.dijkstra@umcg.nl. (6)Department of Genetics,
Genomics Coordination Center, University Medical Center Groningen and University 
of Groningen, Genetics, UMCG, PO Box 30 001, 9700 RB, Groningen, The Netherlands.
m.a.swertz@rug.nl.

BACKGROUND: Genotype imputation is an important procedure in current genomic
analysis such as genome-wide association studies, meta-analyses and fine mapping.
Although high quality tools are available that perform the steps of this process,
considerable effort and expertise is required to set up and run a best practice
imputation pipeline, particularly for larger genotype datasets, where imputation 
has to scale out in parallel on computer clusters.
RESULTS: Here we present MOLGENIS-impute, an 'imputation in a box' solution that 
seamlessly and transparently automates the set up and running of all the steps of
the imputation process. These steps include genome build liftover (liftovering), 
genotype phasing with SHAPEIT2, quality control, sample and chromosomal
chunking/merging, and imputation with IMPUTE2. MOLGENIS-impute builds on
MOLGENIS-compute, a simple pipeline management platform for submission and
monitoring of bioinformatics tasks in High Performance Computing (HPC)
environments like local/cloud servers, clusters and grids. All the required
tools, data and scripts are downloaded and installed in a single step.
Researchers with diverse backgrounds and expertise have tested MOLGENIS-impute on
different locations and imputed over 30,000 samples so far using the 1,000
Genomes Project and new Genome of the Netherlands data as the imputation
reference. The tests have been performed on PBS/SGE clusters, cloud VMs and in a 
grid HPC environment.
CONCLUSIONS: MOLGENIS-impute gives priority to the ease of setting up,
configuring and running an imputation. It has minimal dependencies and wraps the 
pipeline in a simple command line interface, without sacrificing flexibility to
adapt or limiting the options of underlying imputation tools. It does not require
knowledge of a workflow system or programming, and is targeted at researchers who
just want to apply best practices in imputation via simple commands. It is built 
on the MOLGENIS compute workflow framework to enable customization with
additional computational steps or it can be included in other bioinformatics
pipelines. It is available as open source from:
https://github.com/molgenis/molgenis-imputation.

DOI: 10.1186/s13104-015-1309-3 
PMCID: PMC4541731
PMID: 26286716  [PubMed - indexed for MEDLINE]


888. Med Biol Eng Comput. 2016 May;54(5):743-52. doi: 10.1007/s11517-015-1365-9. Epub 
2015 Aug 19.

fMRat: an extension of SPM for a fully automatic analysis of rodent brain
functional magnetic resonance series.

Chavarrías C(1,)(2), García-Vázquez V(3,)(4), Alemán-Gómez Y(3,)(4), Montesinos
P(4), Pascau J(3,)(4), Desco M(3,)(4,)(5).

Author information: 
(1)Departamento de Bioingeniería e Ingeniería Aeroespacial, Universidad Carlos
III de Madrid, Avda. de la Universidad 30, 28911, Leganés, Madrid, Spain.
cchavarrias@hggm.es. (2)Instituto de Investigación Sanitaria Gregorio Marañón,
Doctor Esquerdo 46, 28007, Madrid, Spain. cchavarrias@hggm.es. (3)Departamento de
Bioingeniería e Ingeniería Aeroespacial, Universidad Carlos III de Madrid, Avda. 
de la Universidad 30, 28911, Leganés, Madrid, Spain. (4)Instituto de
Investigación Sanitaria Gregorio Marañón, Doctor Esquerdo 46, 28007, Madrid,
Spain. (5)Centro de Investigación Biomédica en Red de Salud Mental (CIBERSAM),
Madrid, Spain.

The purpose of this study was to develop a multi-platform automatic software tool
for full processing of fMRI rodent studies. Existing tools require the usage of
several different plug-ins, a significant user interaction and/or programming
skills. Based on a user-friendly interface, the tool provides statistical
parametric brain maps (t and Z) and percentage of signal change for user-provided
regions of interest. The tool is coded in MATLAB (MathWorks(®)) and implemented
as a plug-in for SPM (Statistical Parametric Mapping, the Wellcome Trust Centre
for Neuroimaging). The automatic pipeline loads default parameters that are
appropriate for preclinical studies and processes multiple subjects in batch mode
(from images in either Nifti or raw Bruker format). In advanced mode, all
processing steps can be selected or deselected and executed independently.
Processing parameters and workflow were optimized for rat studies and assessed
using 460 male-rat fMRI series on which we tested five smoothing kernel sizes and
three different hemodynamic models. A smoothing kernel of FWHM = 1.2 mm (four
times the voxel size) yielded the highest t values at the somatosensorial primary
cortex, and a boxcar response function provided the lowest residual variance
after fitting. fMRat offers the features of a thorough SPM-based analysis
combined with the functionality of several SPM extensions in a single automatic
pipeline with a user-friendly interface. The code and sample images can be
downloaded from https://github.com/HGGM-LIM/fmrat .

DOI: 10.1007/s11517-015-1365-9 
PMID: 26285671  [PubMed - indexed for MEDLINE]


889. Bioinformatics. 2015 Dec 1;31(23):3859-61. doi: 10.1093/bioinformatics/btv469.
Epub 2015 Aug 17.

aRrayLasso: a network-based approach to microarray interconversion.

Brown AS(1), Patel CJ(1).

Author information: 
(1)Department of Biomedical Informatics, Harvard Medical School, Boston, MA
02115.

Robust conversion between microarray platforms is needed to leverage the wide
variety of microarray expression studies that have been conducted to date.
Currently available conversion methods rely on manufacturer annotations, which
are often incomplete, or on direct alignment of probes from different platforms, 
which often fail to yield acceptable genewise correlation. Here, we describe
aRrayLasso, which uses the Lasso-penalized generalized linear model to model the 
relationships between individual probes in different probe sets. We have
implemented aRrayLasso in a set of five open-source R functions that allow the
user to acquire data from public sources such as Gene Expression Omnibus, train a
set of Lasso models on that data and directly map one microarray platform to
another. aRrayLasso significantly predicts expression levels with similar
fidelity to technical replicates of the same RNA pool, demonstrating its utility 
in the integration of datasets from different platforms.AVAILABILITY AND
IMPLEMENTATION: All functions are available, along with descriptions, at
https://github.com/adam-sam-brown/aRrayLasso.
CONTACT: chirag_patel@hms.harvard.edu.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv469 
PMCID: PMC4653393
PMID: 26283699  [PubMed - indexed for MEDLINE]


890. Forensic Sci Int Genet. 2015 Nov;19:243-9. doi: 10.1016/j.fsigen.2015.08.001.
Epub 2015 Aug 6.

Effect of multiple allelic drop-outs in forensic RMNE calculations.

Van Neste C(1), Deforce D(1), Van Nieuwerburgh F(2).

Author information: 
(1)Laboratory for Pharmaceutical Biotechnology, Ghent University,
Ottergemsesteenweg 460, B-9000 Ghent, Belgium. (2)Laboratory for Pharmaceutical
Biotechnology, Ghent University, Ottergemsesteenweg 460, B-9000 Ghent, Belgium.
Electronic address: Filip.VanNieuwerburgh@UGent.be.

Technological advances such as massively parallel sequencing enable increasing
amounts of genetic information to be obtained from increasingly challenging
samples. Certainly on low template, degraded and multi-contributor samples,
drop-outs will increase in number for many profiles simply by analyzing more
loci, making it difficult to probabilistically assess how many drop-outs have
occurred and at which loci they might have occurred. Previously we developed a
Random Man Not Excluded (RMNE) method that can take into account allelic drop-out
while avoiding detailed estimations of the probability that drop-outs have
occurred, nor making assumptions about at which loci these drop-outs might have
occurred. The number of alleles that have dropped out, does not need to be
exactly known. Here we report a generic Python algorithm to calculate the RMNE
probabilities for any given number of loci. The number of allowed drop-outs can
be set between 0 and twice the number of analyzed loci. The source code has been 
made available on https://github.com/fvnieuwe/rmne. An online web-based RMNE
calculation tool has been made available on http://forensic.ugent.be/rmne. The
tool can calculate these RMNE probabilities from a custom list of probabilities
of the observed and non-observed alleles from any given number of loci. Using
this tool, we explored the effect of allowing allelic drop-outs on the evidential
value of random forensic profiles with a varying number of loci. Our results give
insight into how the number of allowed drop-outs affects the evidential value of 
a profile and how drop-out can be managed in the RMNE approach.

Copyright © 2015 The Authors. Published by Elsevier Ireland Ltd.. All rights
reserved.

DOI: 10.1016/j.fsigen.2015.08.001 
PMID: 26280568  [PubMed - indexed for MEDLINE]


891. PLoS One. 2015 Aug 17;10(8):e0134273. doi: 10.1371/journal.pone.0134273.
eCollection 2015.

JMS: An Open Source Workflow Management System and Web-Based Cluster Front-End
for High Performance Computing.

Brown DK(1), Penkler DL(1), Musyoka TM(1), Bishop ÖT(1).

Author information: 
(1)Research Unit in Bioinformatics (RUBi), Department of Biochemistry and
Microbiology, Rhodes University, Grahamstown, South Africa.

Complex computational pipelines are becoming a staple of modern scientific
research. Often these pipelines are resource intensive and require days of
computing time. In such cases, it makes sense to run them over high performance
computing (HPC) clusters where they can take advantage of the aggregated
resources of many powerful computers. In addition to this, researchers often want
to integrate their workflows into their own web servers. In these cases, software
is needed to manage the submission of jobs from the web interface to the cluster 
and then return the results once the job has finished executing. We have
developed the Job Management System (JMS), a workflow management system and web
interface for high performance computing (HPC). JMS provides users with a
user-friendly web interface for creating complex workflows with multiple stages. 
It integrates this workflow functionality with the resource manager, a tool that 
is used to control and manage batch jobs on HPC clusters. As such, JMS combines
workflow management functionality with cluster administration functionality. In
addition, JMS provides developer tools including a code editor and the ability to
version tools and scripts. JMS can be used by researchers from any field to build
and run complex computational pipelines and provides functionality to include
these pipelines in external interfaces. JMS is currently being used to house a
number of bioinformatics pipelines at the Research Unit in Bioinformatics (RUBi) 
at Rhodes University. JMS is an open-source project and is freely available at
https://github.com/RUBi-ZA/JMS.

DOI: 10.1371/journal.pone.0134273 
PMCID: PMC4539224
PMID: 26280450  [PubMed - indexed for MEDLINE]


892. Nat Methods. 2015 Oct;12(10):943-6. doi: 10.1038/nmeth.3541. Epub 2015 Aug 17.

EMRinger: side chain-directed model and map validation for 3D cryo-electron
microscopy.

Barad BA(1,)(2), Echols N(3), Wang RY(4,)(5), Cheng Y(6), DiMaio F(5,)(7), Adams 
PD(3,)(8), Fraser JS(1).

Author information: 
(1)Department of Bioengineering and Therapeutic Sciences, University of
California, San Francisco, San Francisco, California, USA. (2)Graduate Group in
Biophysics, University of California, San Francisco, San Francisco, California,
USA. (3)Physical Biosciences Division, Lawrence Berkeley National Laboratory,
Berkeley, California, USA. (4)Graduate Program in Biological Physics, Structure
and Design, University of Washington, Seattle, Washington, USA. (5)Department of 
Biochemistry, University of Washington, Seattle, Washington, USA. (6)Keck
Advanced Microscopy Laboratory, Department of Biochemistry and Biophysics,
University of California, San Francisco, San Francisco, California, USA.
(7)Institute for Protein Design, Seattle, Washington, USA. (8)Department of
Bioengineering, University of California, Berkeley, Berkeley, California, USA.

Advances in high-resolution cryo-electron microscopy (cryo-EM) require the
development of validation metrics to independently assess map quality and model
geometry. We report EMRinger, a tool that assesses the precise fitting of an
atomic model into the map during refinement and shows how radiation damage alters
scattering from negatively charged amino acids. EMRinger
(https://github.com/fraser-lab/EMRinger) will be useful for monitoring progress
in resolving and modeling high-resolution features in cryo-EM.

DOI: 10.1038/nmeth.3541 
PMCID: PMC4589481
PMID: 26280328  [PubMed - indexed for MEDLINE]


893. Behav Res Methods. 2016 Sep;48(3):1145-53. doi: 10.3758/s13428-015-0635-7.

ScreenMasker: An Open-source Gaze-contingent Screen Masking Environment.

Orlov PA(1,)(2), Bednarik R(3).

Author information: 
(1)School of Computing, University of Eastern Finland, PO Box 111, FI-80101,
Joensuu, Finland. paul.a.orlov@gmail.com. (2)Department of Engineering Graphics
and Design, Peter the Great St. Petersburg Polytechnic University,
Polytechnicheskaya 29, St. Petersburg, 195251, Russia. paul.a.orlov@gmail.com.
(3)School of Computing, University of Eastern Finland, PO Box 111, FI-80101,
Joensuu, Finland.

The moving-window paradigm, based on gazecontingent technic, traditionally used
in a studies of the visual perceptual span. There is a strong demand for new
environments that could be employed by non-technical researchers. We have
developed an easy-to-use tool with a graphical user interface (GUI) allowing both
execution and control of visual gaze-contingency studies. This work describes
ScreenMasker, an environment that allows create gaze-contingent textured displays
used together with stimuli presentation software. ScreenMasker has an
architecture that meets the requirements of low-latency real-time eye-movement
experiments. It also provides a variety of settings and functions. Effective
rendering times and performance are ensured by means of GPU processing under CUDA
technology. Performance tests show ScreenMasker's latency to be 67-74 ms on a
typical office computer, and high-end 144-Hz screen latencies of about 25-28 ms. 
ScreenMasker is an open-source system distributed under the GNU Lesser General
Public License and is available at https://github.com/PaulOrlov/ScreenMasker .

DOI: 10.3758/s13428-015-0635-7 
PMID: 26276516  [PubMed - in process]


894. Bioinformatics. 2015 Dec 1;31(23):3847-9. doi: 10.1093/bioinformatics/btv470.
Epub 2015 Aug 12.

motifbreakR: an R/Bioconductor package for predicting variant effects at
transcription factor binding sites.

Coetzee SG(1), Coetzee GA(2), Hazelett DJ(1).

Author information: 
(1)Bioinformatics and Computational Biology Research Center, Cedars-Sinai Medical
Center, Los Angeles, CA, USA and. (2)Department of Urology and Preventive
Medicine, USC Norris Comprehensive Cancer Center, Los Angeles, CA, USA.

Functional annotation represents a key step toward the understanding and
interpretation of germline and somatic variation as revealed by genome-wide
association studies (GWAS) and The Cancer Genome Atlas (TCGA), respectively. GWAS
have revealed numerous genetic risk variants residing in non-coding DNA
associated with complex diseases. For sequences that lie within enhancers or
promoters of transcription, it is not straightforward to assess the effects of
variants on likely transcription factor binding sites. Consequently we introduce 
motifbreakR, which allows the biologist to judge whether the sequence surrounding
a polymorphism or mutation is a good match, and how much information is gained or
lost in one allele of the polymorphism or mutation relative to the other.
MotifbreakR is flexible, giving a choice of algorithms for interrogation of
genomes with motifs from many public sources that users can choose from.
MotifbreakR can predict effects for novel or previously described variants in
public databases, making it suitable for tasks beyond the scope of its original
design. Lastly, it can be used to interrogate any genome curated within
bioconductor.AVAILABILITY AND IMPLEMENTATION:
https://github.com/Simon-Coetzee/MotifBreakR, www.bioconductor.org.
CONTACT: dennis.hazelett@cshs.org.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv470 
PMCID: PMC4653394
PMID: 26272984  [PubMed - indexed for MEDLINE]


895. Bioinformatics. 2015 Dec 1;31(23):3868-9. doi: 10.1093/bioinformatics/btv460.
Epub 2015 Aug 12.

cyNeo4j: connecting Neo4j and Cytoscape.

Summer G(1), Kelder T(2), Ono K(3), Radonjic M(2), Heymans S(4), Demchak B(3).

Author information: 
(1)Center for Heart Failure Research, Cardiovascular Research Institute
Maastricht (CARIM), University Hospital Maastricht, Maastricht, The Netherlands, 
TNO, Zeist, The Netherlands. (2)EdgeLeap B.V., Utrecht, The Netherlands and.
(3)Department of Medicine, University of California, San Diego, La Jolla, CA,
USA. (4)Center for Heart Failure Research, Cardiovascular Research Institute
Maastricht (CARIM), University Hospital Maastricht, Maastricht, The Netherlands.

We developed cyNeo4j, a Cytoscape App to link Cytoscape and Neo4j databases to
utilize the performance and storage capacities Neo4j offers. We implemented a
Neo4j NetworkAnalyzer, ForceAtlas2 layout and Cypher component to demonstrate the
possibilities a distributed setup of Cytoscape and Neo4j have.AVAILABILITY AND
IMPLEMENTATION: The app is available from the Cytoscape App Store at
http://apps.cytoscape.org/apps/cyneo4j, the Neo4j plugins at
www.github.com/gsummer/cyneo4j-parent and the community and commercial editions
of Neo4j can be found at http://www.neo4j.com.
CONTACT: georg.summer@gmail.com.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv460 
PMCID: PMC4653389
PMID: 26272981  [PubMed - indexed for MEDLINE]


896. Genome Med. 2015 Jul 20;7:69. doi: 10.1186/s13073-015-0192-9. eCollection 2015.

ENVE: a novel computational framework characterizes copy-number mutational
landscapes in colorectal cancers from African American patients.

Varadan V(1), Singh S(2), Nosrati A(3), Ravi L(3), Lutterbaugh J(3),
Barnholtz-Sloan JS(4), Markowitz SD(5), Willis JE(6), Guda K(7).

Author information: 
(1)Division of General Medical Sciences-Oncology, Case Western Reserve
University, Cleveland, OH 44106 USA ; Case Comprehensive Cancer Center, Case
Western Reserve University, Cleveland, OH 44106 USA ; Case Western Reserve
University, 2103 Cornell Road, Wolstein Research Building, Cleveland, OH 44106
USA. (2)Case Comprehensive Cancer Center, Case Western Reserve University,
Cleveland, OH 44106 USA. (3)Division of Hematology and Oncology, Case Western
Reserve University, Cleveland, OH 44106 USA. (4)Division of General Medical
Sciences-Oncology, Case Western Reserve University, Cleveland, OH 44106 USA ;
Case Comprehensive Cancer Center, Case Western Reserve University, Cleveland, OH 
44106 USA. (5)Case Comprehensive Cancer Center, Case Western Reserve University, 
Cleveland, OH 44106 USA ; Division of Hematology and Oncology, Case Western
Reserve University, Cleveland, OH 44106 USA ; Department of Medicine, Case
Western Reserve University, Cleveland, OH 44106 USA ; Case Medical Center, Case
Western Reserve University, Cleveland, OH 44106 USA. (6)Case Comprehensive Cancer
Center, Case Western Reserve University, Cleveland, OH 44106 USA ; Department of 
Medicine, Case Western Reserve University, Cleveland, OH 44106 USA ; Case Medical
Center, Case Western Reserve University, Cleveland, OH 44106 USA ; Department of 
Pathology, Case Western Reserve University, Cleveland, OH 44106 USA. (7)Division 
of General Medical Sciences-Oncology, Case Western Reserve University, Cleveland,
OH 44106 USA ; Case Comprehensive Cancer Center, Case Western Reserve University,
Cleveland, OH 44106 USA ; Department of Medicine, Case Western Reserve
University, Cleveland, OH 44106 USA ; Case Western Reserve University, 2103
Cornell Road, Wolstein Research Building, Cleveland, OH 44106 USA.

Reliable detection of somatic copy-number alterations (sCNAs) in tumors using
whole-exome sequencing (WES) remains challenging owing to technical (inherent
noise) and sample-associated variability in WES data. We present a novel
computational framework, ENVE, which models inherent noise in any WES dataset,
enabling robust detection of sCNAs across WES platforms. ENVE achieved high
concordance with orthogonal sCNA assessments across two colorectal cancer (CRC)
WES datasets, and consistently outperformed a best-in-class algorithm,
Control-FREEC. We subsequently used ENVE to characterize global sCNA landscapes
in African American CRCs, identifying genomic aberrations potentially associated 
with CRC pathogenesis in this population. ENVE is downloadable at
https://github.com/ENVE-Tools/ENVE.

DOI: 10.1186/s13073-015-0192-9 
PMCID: PMC4534088
PMID: 26269717  [PubMed - indexed for MEDLINE]


897. PLoS Comput Biol. 2015 Aug 12;11(8):e1004448. doi: 10.1371/journal.pcbi.1004448. 
eCollection 2015.

One Size Doesn't Fit All - RefEditor: Building Personalized Diploid Reference
Genome to Improve Read Mapping and Genotype Calling in Next Generation Sequencing
Studies.

Yuan S(1), Johnston HR(2), Zhang G(3), Li Y(3), Hu YJ(2), Qin ZS(2).

Author information: 
(1)Mathematics & Computer Science Department, Emory University, Atlanta, Georgia,
United States of America. (2)Department of Biostatistics and Bioinformatics,
Rollins School of Public Health, Emory University, Atlanta, Georgia, United
States of America. (3)Department of Genetics, Department of Biostatistics,
Department of Computer Science, University of North Carolina, Chapel Hill, Chapel
Hill, North Carolina, United States of America.

With rapid decline of the sequencing cost, researchers today rush to embrace
whole genome sequencing (WGS), or whole exome sequencing (WES) approach as the
next powerful tool for relating genetic variants to human diseases and
phenotypes. A fundamental step in analyzing WGS and WES data is mapping short
sequencing reads back to the reference genome. This is an important issue because
incorrectly mapped reads affect the downstream variant discovery, genotype
calling and association analysis. Although many read mapping algorithms have been
developed, the majority of them uses the universal reference genome and do not
take sequence variants into consideration. Given that genetic variants are
ubiquitous, it is highly desirable if they can be factored into the read mapping 
procedure. In this work, we developed a novel strategy that utilizes genotypes
obtained a priori to customize the universal haploid reference genome into a
personalized diploid reference genome. The new strategy is implemented in a
program named RefEditor. When applying RefEditor to real data, we achieved
encouraging improvements in read mapping, variant discovery and genotype calling.
Compared to standard approaches, RefEditor can significantly increase genotype
calling consistency (from 43% to 61% at 4X coverage; from 82% to 92% at 20X
coverage) and reduce Mendelian inconsistency across various sequencing depths.
Because many WGS and WES studies are conducted on cohorts that have been
genotyped using array-based genotyping platforms previously or concurrently, we
believe the proposed strategy will be of high value in practice, which can also
be applied to the scenario where multiple NGS experiments are conducted on the
same cohort. The RefEditor sources are available at
https://github.com/superyuan/refeditor.

DOI: 10.1371/journal.pcbi.1004448 
PMCID: PMC4534450
PMID: 26267278  [PubMed - indexed for MEDLINE]


898. Stud Health Technol Inform. 2015;216:956.

Computationally Comparing and Analyzing All Published Scoring Systems for
Diagnosis of Disseminated Intravascular Coagulation.

Kury FS(1), Cimino JJ(1).

Author information: 
(1)National Library of Medicine, US National Institutes of Health, Bethesda,
Maryland, USA.

The clinical literature presents four different scoring systems (SS) for the
diagnosis of disseminated intravascular coagulation (DIC) by four institutions:
ISTH, JMHLW, JAAM and KSTH. In this study a Java program was written to retrieve 
medical records from the MIMIC-II database and apply the criteria of all four.
The program then quantified the agreement of each DIC SS with each other and
demonstrated notorious dissent. Furthermore, the average internal composition of 
each score was also quantified. All source code produced is available for
download at https://github.com/fabkury/hedicim.


PMID: 26262258  [PubMed - indexed for MEDLINE]


899. Bioinformatics. 2015 Dec 1;31(23):3875-7. doi: 10.1093/bioinformatics/btv468.
Epub 2015 Aug 10.

Vizardous: interactive analysis of microbial populations with single cell
resolution.

Helfrich S(1), Azzouzi CE(1), Probst C(1), Seiffarth J(1), Grünberger A(1),
Wiechert W(1), Kohlheyer D(1), Nöh K(1).

Author information: 
(1)Institute of Bio- and Geosciences, IBG-1: Biotechnology, Forschungszentrum
Jülich GmbH, Germany.

MOTIVATION: Single cell time-lapse microscopy is a powerful method for
investigating heterogeneous cell behavior. Advances in microfluidic lab-on-a-chip
technologies and live-cell imaging render the parallel observation of the
development of individual cells in hundreds of populations possible. While image 
analysis tools are available for cell detection and tracking, biologists are
still confronted with the challenge of exploring and evaluating this data.
RESULTS: We present the software tool Vizardous that assists scientists with
explorative analysis and interpretation tasks of single cell data in an
interactive, configurable and visual way. With Vizardous, lineage tree drawings
can be augmented with various, time-resolved cellular characteristics. Associated
statistical moments bridge the gap between single cell and the population-average
level.
AVAILABILITY AND IMPLEMENTATION: The software, including documentation and
examples, is available as executable Java archive as well as in source form at
https://github.com/modsim/vizardous.
CONTACT: k.noeh@fz-juelich.de.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv468 
PMID: 26261223  [PubMed - indexed for MEDLINE]


900. Hum Mutat. 2015 Oct;36(10):922-7. doi: 10.1002/humu.22850.

The Matchmaker Exchange API: automating patient matching through the exchange of 
structured phenotypic and genotypic profiles.

Buske OJ(1,)(2,)(3), Schiettecatte F(4), Hutton B(5), Dumitriu S(3), Misyura
A(3), Huang L(6), Hartley T(6), Girdea M(2,)(3), Sobreira N(7), Mungall C(8),
Brudno M(1,)(2,)(3).

Author information: 
(1)Genetics and Genome Biology Program, The Hospital for Sick Children, Toronto, 
Canada. (2)Department of Computer Science, University of Toronto, Toronto,
Canada. (3)Centre for Computational Medicine, The Hospital for Sick Children,
Toronto, Canada. (4)FS Consulting LLC, Salem, Massachusetts. (5)Wellcome Trust
Sanger Institute, Cambridge, UK. (6)Children's Hospital of Eastern Ontario
Research Institute, Ottawa, Ontario, Canada. (7)McKusick-Nathans Institute of
Genetic Medicine, Johns Hopkins University School of Medicine, Baltimore,
Maryland. (8)Genomics Division, Lawrence Berkeley National Laboratory, Berkeley, 
California.

Despite the increasing prevalence of clinical sequencing, the difficulty of
identifying additional affected families is a key obstacle to solving many rare
diseases. There may only be a handful of similar patients worldwide, and their
data may be stored in diverse clinical and research databases. Computational
methods are necessary to enable finding similar patients across the growing
number of patient repositories and registries. We present the Matchmaker Exchange
Application Programming Interface (MME API), a protocol and data format for
exchanging phenotype and genotype profiles to enable matchmaking among patient
databases, facilitate the identification of additional cohorts, and increase the 
rate with which rare diseases can be researched and diagnosed. We designed the
API to be straightforward and flexible in order to simplify its adoption on a
large number of data types and workflows. We also provide a public test data set,
curated from the literature, to facilitate implementation of the API and
development of new matching algorithms. The initial version of the API has been
successfully implemented by three members of the Matchmaker Exchange and was
immediately able to reproduce previously identified matches and generate several 
new leads currently being validated. The API is available at
https://github.com/ga4gh/mme-apis.

© 2015 WILEY PERIODICALS, INC.

DOI: 10.1002/humu.22850 
PMCID: PMC4775166
PMID: 26255989  [PubMed - indexed for MEDLINE]


901. J Chem Phys. 2015 Aug 7;143(5):055101. doi: 10.1063/1.4927565.

Massively parallel sampling of lattice proteins reveals foundations of thermal
adaptation.

Venev SV(1), Zeldovich KB(1).

Author information: 
(1)Program in Bioinformatics and Integrative Biology, University of Massachusetts
Medical School, 368 Plantation St, Worcester, Massachusetts 01605, USA.

Evolution of proteins in bacteria and archaea living in different conditions
leads to significant correlations between amino acid usage and environmental
temperature. The origins of these correlations are poorly understood, and an
important question of protein theory, physics-based prediction of types of amino 
acids overrepresented in highly thermostable proteins, remains largely unsolved. 
Here, we extend the random energy model of protein folding by weighting the
interaction energies of amino acids by their frequencies in protein sequences and
predict the energy gap of proteins designed to fold well at elevated
temperatures. To test the model, we present a novel scalable algorithm for
simultaneous energy calculation for many sequences in many structures, targeting 
massively parallel computing architectures such as graphics processing unit. The 
energy calculation is performed by multiplying two matrices, one representing the
complete set of sequences, and the other describing the contact maps of all
structural templates. An implementation of the algorithm for the CUDA platform is
available at http://www.github.com/kzeldovich/galeprot and calculates protein
folding energies over 250 times faster than a single central processing unit.
Analysis of amino acid usage in 64-mer cubic lattice proteins designed to fold
well at different temperatures demonstrates an excellent agreement between
theoretical and simulated values of energy gap. The theoretical predictions of
temperature trends of amino acid frequencies are significantly correlated with
bioinformatics data on 191 bacteria and archaea, and highlight protein folding
constraints as a fundamental selection pressure during thermal adaptation in
biological evolution.

DOI: 10.1063/1.4927565 
PMID: 26254668  [PubMed - indexed for MEDLINE]


902. J Theor Biol. 2015 Nov 21;385:50-7. doi: 10.1016/j.jtbi.2015.07.030. Epub 2015
Aug 4.

iLM-2L: A two-level predictor for identifying protein lysine methylation sites
and their methylation degrees by incorporating K-gap amino acid pairs into Chou׳s
general PseAAC.

Ju Z(1), Cao JZ(2), Gu H(3).

Author information: 
(1)School of Control Science and Engineering, Dalian University of Technology, #2
Ling-gong Road, Dalian 116024, People׳s Republic of China. Electronic address:
juzhe1120@hotmail.com. (2)School of Control Science and Engineering, Dalian
University of Technology, #2 Ling-gong Road, Dalian 116024, People׳s Republic of 
China. Electronic address: caojunzhe@dlut.edu.cn. (3)School of Control Science
and Engineering, Dalian University of Technology, #2 Ling-gong Road, Dalian
116024, People׳s Republic of China. Electronic address: guhong@dlut.edu.cn.

As one of the most critical post-translational modifications, lysine methylation 
plays a key role in regulating various protein functions. In order to understand 
the molecular mechanism of lysine methylation, it is important to identify lysine
methylation sites and their methylation degrees accurately. As the traditional
experimental methods are time-consuming and labor-intensive, several
computational methods have been developed for the identification of methylation
sites. However, the prediction accuracy of existing computational methods is
still unsatisfactory. Moreover, they are only focused on predicting whether a
query lysine residue is a methylation site, without considering its methylation
degrees. In this paper, a novel two-level predictor named iLM-2L is proposed to
predict lysine methylation sites and their methylation degrees using composition 
of k-spaced amino acid pairs feature coding scheme and support vector machine
algorithm. The 1st level is to identify whether a query lysine residue is a
methylation site, and the 2nd level is to identify which methylation degree(s)
the query lysine residue belongs to if it has been predicted as a methyllysine
site in the 1st level identification. The iLM-2L achieves a promising performance
with a Sensitivity of 76.46%, a Specificity of 91.90%, an Accuracy of 85.31% and 
a Matthew's correlation coefficient of 69.94% for the 1st level as well as a
Precision of 84.81%, an accuracy of 79.35%, a recall of 80.83%, an Absolute_Ture 
of 73.89% and a Hamming_loss of 15.63% for the 2nd level in jackknife test. As
illustrated by independent test, the performance of iLM-2L outperforms other
existing lysine methylation site predictors significantly. A matlab software
package for iLM-2L can be freely downloaded from
https://github.com/juzhe1120/Matlab_Software/blob/master/iLM-2L_Matlab_Software.r
ar.

Copyright © 2015. Published by Elsevier Ltd.

DOI: 10.1016/j.jtbi.2015.07.030 
PMID: 26254214  [PubMed - indexed for MEDLINE]


903. Nucleic Acids Res. 2015 Sep 18;43(16):7762-8. doi: 10.1093/nar/gkv784. Epub 2015 
Aug 6.

High speed BLASTN: an accelerated MegaBLAST search tool.

Chen Y(1), Ye W(1), Zhang Y(2), Xu Y(3).

Author information: 
(1)Guangdong Province Key Laboratory of Computational Science, School of
Mathematics and Computational Science, Sun Yat-sen University, Guangzhou 510275, 
P. R. China. (2)Guangdong Province Key Laboratory of Computational Science,
School of Mathematics and Computational Science, Sun Yat-sen University,
Guangzhou 510275, P. R. China lnszyd@mail.sysu.edu.cn. (3)Guangdong Province Key 
Laboratory of Computational Science, School of Mathematics and Computational
Science, Sun Yat-sen University, Guangzhou 510275, P. R. China Department of
Mathematics, Syracuse University, Syracuse, NY 13244, USA yxu06@syr.edu.

Sequence alignment is a long standing problem in bioinformatics. The Basic Local 
Alignment Search Tool (BLAST) is one of the most popular and fundamental
alignment tools. The explosive growth of biological sequences calls for speedup
of sequence alignment tools such as BLAST. To this end, we develop high speed
BLASTN (HS-BLASTN), a parallel and fast nucleotide database search tool that
accelerates MegaBLAST--the default module of NCBI-BLASTN. HS-BLASTN builds a new 
lookup table using the FMD-index of the database and employs an accurate and
effective seeding method to find short stretches of identities (called seeds)
between the query and the database. HS-BLASTN produces the same alignment results
as MegaBLAST and its computational speed is much faster than MegaBLAST.
Specifically, our experiments conducted on a 12-core server show that HS-BLASTN
can be 22 times faster than MegaBLAST and exhibits better parallel performance
than MegaBLAST. HS-BLASTN is written in C++ and the related source code is
available at https://github.com/chenying2016/queries under the GPLv3 license.

© The Author(s) 2015. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkv784 
PMCID: PMC4652774
PMID: 26250111  [PubMed - indexed for MEDLINE]


904. Bioinformatics. 2015 Dec 1;31(23):3830-1. doi: 10.1093/bioinformatics/btv426.
Epub 2015 Aug 6.

cgmisc: enhanced genome-wide association analyses and visualization.

Kierczak M(1), Jabłońska J(2), Forsberg SK(3), Bianchi M(2), Tengvall K(2),
Pettersson M(1), Scholz V(2), Meadows JR(2), Jern P(2), Carlborg Ö(3),
Lindblad-Toh K(4).

Author information: 
(1)Science for Life Laboratory, Department of Medical Biochemistry and
Microbiology, Uppsala University, Uppsala, Sweden, Computational Genetics
Section, Department of Clinical Sciences, Swedish University of Agricultural
Sciences, Uppsala, Sweden and. (2)Science for Life Laboratory, Department of
Medical Biochemistry and Microbiology, Uppsala University, Uppsala, Sweden.
(3)Computational Genetics Section, Department of Clinical Sciences, Swedish
University of Agricultural Sciences, Uppsala, Sweden and. (4)Science for Life
Laboratory, Department of Medical Biochemistry and Microbiology, Uppsala
University, Uppsala, Sweden, Broad Institute of MIT and Harvard, Boston, MA, USA.

High-throughput genotyping and sequencing technologies facilitate studies of
complex genetic traits and provide new research opportunities. The increasing
popularity of genome-wide association studies (GWAS) leads to the discovery of
new associated loci and a better understanding of the genetic architecture
underlying not only diseases, but also other monogenic and complex phenotypes.
Several softwares are available for performing GWAS analyses, R environment being
one of them.RESULTS: We present cgmisc, an R package that enables enhanced data
analysis and visualization of results from GWAS. The package contains several
utilities and modules that complement and enhance the functionality of the
existing software. It also provides several tools for advanced visualization of
genomic data and utilizes the power of the R language to aid in preparation of
publication-quality figures. Some of the package functions are specific for the
domestic dog (Canis familiaris) data.
AVAILABILITY AND IMPLEMENTATION: The package is operating system-independent and 
is available from: https://github.com/cgmisc-team/cgmisc
CONTACT: marcin.kierczak@imbim.uu.se.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv426 
PMCID: PMC4653382
PMID: 26249815  [PubMed - indexed for MEDLINE]


905. PLoS One. 2015 Aug 6;10(8):e0135028. doi: 10.1371/journal.pone.0135028.
eCollection 2015.

gPGA: GPU Accelerated Population Genetics Analyses.

Zhou C(1), Lang X(1), Wang Y(1), Zhu C(2).

Author information: 
(1)Supercomputing Center, Computer Network Information Center, Chinese Academy of
Sciences, Beijing, 100190, China. (2)Key Laboratory of Zoological Systematics and
Evolution, Institute of Zoology, Chinese Academy of Sciences, Beijing, 100101,
China.

BACKGROUND: The isolation with migration (IM) model is important for studies in
population genetics and phylogeography. IM program applies the IM model to
genetic data drawn from a pair of closely related populations or species based on
Markov chain Monte Carlo (MCMC) simulations of gene genealogies. But
computational burden of IM program has placed limits on its application.
METHODOLOGY: With strong computational power, Graphics Processing Unit (GPU) has 
been widely used in many fields. In this article, we present an effective
implementation of IM program on one GPU based on Compute Unified Device
Architecture (CUDA), which we call gPGA.
CONCLUSIONS: Compared with IM program, gPGA can achieve up to 52.30X speedup on
one GPU. The evaluation results demonstrate that it allows datasets to be
analyzed effectively and rapidly for research on divergence population genetics. 
The software is freely available with source code at
https://github.com/chunbaozhou/gPGA.

DOI: 10.1371/journal.pone.0135028 
PMCID: PMC4527771
PMID: 26248314  [PubMed - indexed for MEDLINE]


906. Microbiome. 2015 Aug 5;3:32. doi: 10.1186/s40168-015-0093-6. eCollection 2015.

Xander: employing a novel method for efficient gene-targeted metagenomic
assembly.

Wang Q(1), Fish JA(2), Gilman M(3), Sun Y(3), Brown CT(4), Tiedje JM(5), Cole
JR(6).

Author information: 
(1)Center for Microbial Ecology, Michigan State University, East Lansing, MI USA.
(2)Center for Microbial Ecology, Michigan State University, East Lansing, MI USA 
; Department of Computer Science and Engineering, Michigan State University, East
Lansing, MI USA. (3)Department of Computer Science and Engineering, Michigan
State University, East Lansing, MI USA. (4)Department of Computer Science and
Engineering, Michigan State University, East Lansing, MI USA ; Department of
Microbiology and Molecular Genetics, Michigan State University, East Lansing, MI 
USA. (5)Center for Microbial Ecology, Michigan State University, East Lansing, MI
USA ; Department of Microbiology and Molecular Genetics, Michigan State
University, East Lansing, MI USA ; Department of Plant, Soil and Microbial
Sciences, Michigan State University, East Lansing, MI USA. (6)Center for
Microbial Ecology, Michigan State University, East Lansing, MI USA ; Department
of Plant, Soil and Microbial Sciences, Michigan State University, East Lansing,
MI USA.

BACKGROUND: Metagenomics can provide important insight into microbial
communities. However, assembling metagenomic datasets has proven to be
computationally challenging. Current methods often assemble only fragmented
partial genes.
RESULTS: We present a novel method for targeting assembly of specific
protein-coding genes. This method combines a de Bruijn graph, as used in standard
assembly approaches, and a protein profile hidden Markov model (HMM) for the gene
of interest, as used in standard annotation approaches. These are used to create 
a novel combined weighted assembly graph. Xander performs both assembly and
annotation concomitantly using information incorporated in this graph. We
demonstrate the utility of this approach by assembling contigs for one
phylogenetic marker gene and for two functional marker genes, first on Human
Microbiome Project (HMP)-defined community Illumina data and then on 21
rhizosphere soil metagenomic datasets from three different crops totaling over
800 Gbp of unassembled data. We compared our method to a recently published bulk 
metagenome assembly method and a recently published gene-targeted assembler and
found our method produced more, longer, and higher quality gene sequences.
CONCLUSION: Xander combines gene assignment with the rapid assembly of
full-length or near full-length functional genes from metagenomic data without
requiring bulk assembly or post-processing to find genes of interest. HMMs used
for assembly can be tailored to the targeted genes, allowing flexibility to
improve annotation over generic annotation pipelines. This method is implemented 
as open source software and is available at
https://github.com/rdpstaff/Xander_assembler.

DOI: 10.1186/s40168-015-0093-6 
PMCID: PMC4526283
PMID: 26246894  [PubMed]


907. Source Code Biol Med. 2015 Aug 5;10:9. doi: 10.1186/s13029-015-0039-1.
eCollection 2015.

CombAlign: a code for generating a one-to-many sequence alignment from a set of
pairwise structure-based sequence alignments.

Zhou CL(1).

Author information: 
(1)Computational Biology Group, Global Security Computing Applications Division, 
Lawrence Livermore National Laboratory, 7000 East Avenue, Livermore, CA 94550
USA.

BACKGROUND: In order to better define regions of similarity among related protein
structures, it is useful to identify the residue-residue correspondences among
proteins. Few codes exist for constructing a one-to-many multiple sequence
alignment derived from a set of structure or sequence alignments, and a need was 
evident for creating such a tool for combining pairwise structure alignments that
would allow for insertion of gaps in the reference structure.
RESULTS: This report describes a new Python code, CombAlign, which takes as input
a set of pairwise sequence alignments (which may be structure based) and
generates a one-to-many, gapped, multiple structure- or sequence-based sequence
alignment (MSSA). The use and utility of CombAlign was demonstrated by generating
gapped MSSAs using sets of pairwise structure-based sequence alignments between
structure models of the matrix protein (VP40) and pre-small/secreted glycoprotein
(sGP) of Reston Ebolavirus and the corresponding proteins of several other
filoviruses. The gapped MSSAs revealed structure-based residue-residue
correspondences, which enabled identification of structurally similar versus
differing regions in the Reston proteins compared to each of the other
corresponding proteins.
CONCLUSIONS: CombAlign is a new Python code that generates a one-to-many, gapped,
multiple structure- or sequence-based sequence alignment (MSSA) given a set of
pairwise sequence alignments (which may be structure based). CombAlign has
utility in assisting the user in distinguishing structurally conserved versus
divergent regions on a reference protein structure relative to other closely
related proteins. CombAlign was developed in Python 2.6, and the source code is
available for download from the GitHub code repository.

DOI: 10.1186/s13029-015-0039-1 
PMCID: PMC4526201
PMID: 26246852  [PubMed]


908. PLoS One. 2015 Aug 4;10(8):e0134474. doi: 10.1371/journal.pone.0134474.
eCollection 2015.

Deconvolution of Complex 1D NMR Spectra Using Objective Model Selection.

Hughes TS(1), Wilson HD(2), de Vera IM(1), Kojetin DJ(1).

Author information: 
(1)Department of Molecular Therapeutics, The Scripps Research Institute, Scripps 
Florida, Jupiter, Florida, 33458, United States of America. (2)Graduate Program, 
The Scripps Research Institute, Scripps Florida, Jupiter, Florida, 33458, United 
States of America.

Fluorine (19F) NMR has emerged as a useful tool for characterization of slow
dynamics in 19F-labeled proteins. One-dimensional (1D) 19F NMR spectra of
proteins can be broad, irregular and complex, due to exchange of probe nuclei
between distinct electrostatic environments; and therefore cannot be deconvoluted
and analyzed in an objective way using currently available software. We have
developed a Python-based deconvolution program, decon1d, which uses Bayesian
information criteria (BIC) to objectively determine which model (number of peaks)
would most likely produce the experimentally obtained data. The method also
allows for fitting of intermediate exchange spectra, which is not supported by
current software in the absence of a specific kinetic model. In current methods, 
determination of the deconvolution model best supported by the data is done
manually through comparison of residual error values, which can be time consuming
and requires model selection by the user. In contrast, the BIC method used by
decond1d provides a quantitative method for model comparison that penalizes for
model complexity helping to prevent over-fitting of the data and allows
identification of the most parsimonious model. The decon1d program is freely
available as a downloadable Python script at the project website
(https://github.com/hughests/decon1d/).

DOI: 10.1371/journal.pone.0134474 
PMCID: PMC4524620
PMID: 26241959  [PubMed - indexed for MEDLINE]


909. J Biomed Inform. 2015 Oct;57:204-18. doi: 10.1016/j.jbi.2015.07.015. Epub 2015
Aug 1.

In the pursuit of a semantic similarity metric based on UMLS annotations for
articles in PubMed Central Open Access.

Garcia Castro LJ(1), Berlanga R(2), Garcia A(3).

Author information: 
(1)Temporal Knowledge Bases Group, Department of Computer Languages and Systems, 
Universitat Jaume I, 12071 Castelló de la Plana, Spain. Electronic address:
al278693@uji.es. (2)Temporal Knowledge Bases Group, Department of Computer
Languages and Systems, Universitat Jaume I, 12071 Castelló de la Plana, Spain.
(3)Ontology Engineering Group, Informatics Department, Universidad Politécnica de
Madrid, 28660 Boadilla del Monte, Madrid, Spain; Linkingdata I/O LLC, Fort
Collins, Colorado, USA.

MOTIVATION: Although full-text articles are provided by the publishers in
electronic formats, it remains a challenge to find related work beyond the title 
and abstract context. Identifying related articles based on their abstract is
indeed a good starting point; this process is straightforward and does not
consume as many resources as full-text based similarity would require. However,
further analyses may require in-depth understanding of the full content. Two
articles with highly related abstracts can be substantially different regarding
the full content. How similarity differs when considering title-and-abstract
versus full-text and which semantic similarity metric provides better results
when dealing with full-text articles are the main issues addressed in this
manuscript.
METHODS: We have benchmarked three similarity metrics - BM25, PMRA, and Cosine,
in order to determine which one performs best when using concept-based
annotations on full-text documents. We also evaluated variations in similarity
values based on title-and-abstract against those relying on full-text. Our test
dataset comprises the Genomics track article collection from the 2005 Text
Retrieval Conference. Initially, we used an entity recognition software to
semantically annotate titles and abstracts as well as full-text with concepts
defined in the Unified Medical Language System (UMLS®). For each article, we
created a document profile, i.e., a set of identified concepts, term frequency,
and inverse document frequency; we then applied various similarity metrics to
those document profiles. We considered correlation, precision, recall, and F1 in 
order to determine which similarity metric performs best with concept-based
annotations. For those full-text articles available in PubMed Central Open Access
(PMC-OA), we also performed dispersion analyses in order to understand how
similarity varies when considering full-text articles.
RESULTS: We have found that the PubMed Related Articles similarity metric is the 
most suitable for full-text articles annotated with UMLS concepts. For similarity
values above 0.8, all metrics exhibited an F1 around 0.2 and a recall around 0.1;
BM25 showed the highest precision close to 1; in all cases the concept-based
metrics performed better than the word-stem-based one. Our experiments show that 
similarity values vary when considering only title-and-abstract versus full-text 
similarity. Therefore, analyses based on full-text become useful when a given
research requires going beyond title and abstract, particularly regarding
connectivity across articles.
AVAILABILITY: Visualization available at ljgarcia.github.io/semsim.benchmark/,
data available at http://dx.doi.org/10.5281/zenodo.13323.

Copyright © 2015 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.jbi.2015.07.015 
PMID: 26241356  [PubMed - in process]


910. J Cheminform. 2015 Aug 1;7:36. doi: 10.1186/s13321-015-0090-6. eCollection 2015.

Synergy Maps: exploring compound combinations using network-based visualization.

Lewis R(1), Guha R(2), Korcsmaros T(3), Bender A(1).

Author information: 
(1)Department of Chemistry, Centre for Molecular Informatics, University of
Cambridge, Lensfield Road, Cambridge, CB2 1EW UK. (2)National Center for
Advancing Translational Sciences, 9800 Medical Center Drive, Rockville, MD 20850 
USA. (3)TGAC, The Genome Analysis Centre, Norwich Research Park, Norwich, UK ;
Gut Health and Food Safety Programme, Institute of Food Research, Norwich
Research Park, Norwich, UK.

BACKGROUND: The phenomenon of super-additivity of biological response to
compounds applied jointly, termed synergy, has the potential to provide many
therapeutic benefits. Therefore, high throughput screening of compound
combinations has recently received a great deal of attention. Large compound
libraries and the feasibility of all-pairs screening can easily generate large,
information-rich datasets. Previously, these datasets have been visualized using 
either a heat-map or a network approach-however these visualizations only
partially represent the information encoded in the dataset.
RESULTS: A new visualization technique for pairwise combination screening data,
termed "Synergy Maps", is presented. In a Synergy Map, information about the
synergistic interactions of compounds is integrated with information about their 
properties (chemical structure, physicochemical properties, bioactivity profiles)
to produce a single visualization. As a result the relationships between compound
and combination properties may be investigated simultaneously, and thus may
afford insight into the synergy observed in the screen. An interactive web app
implementation, available at http://richlewis42.github.io/synergy-maps, has been 
developed for public use, which may find use in navigating and filtering larger
scale combination datasets. This tool is applied to a recent all-pairs dataset of
anti-malarials, tested against Plasmodium falciparum, and a preliminary analysis 
is given as an example, illustrating the disproportionate synergism of histone
deacetylase inhibitors previously described in literature, as well as suggesting 
new hypotheses for future investigation.
CONCLUSIONS: Synergy Maps improve the state of the art in compound combination
visualization, by simultaneously representing individual compound properties and 
their interactions. The web-based tool allows straightforward exploration of
combination data, and easier identification of correlations between compound
properties and interactions.

DOI: 10.1186/s13321-015-0090-6 
PMCID: PMC4521339
PMID: 26236402  [PubMed]


911. Bioinformatics. 2015 Dec 1;31(23):3751-7. doi: 10.1093/bioinformatics/btv443.
Epub 2015 Jul 31.

An efficient algorithm for the extraction of HGVS variant descriptions from
sequences.

Vis JK(1), Vermaat M(2), Taschner PE(3), Kok JN(1), Laros JF(4).

Author information: 
(1)Department of Molecular Epidemiology, Leiden University Medical Center,
Leiden, The Netherlands, Leiden Institute of Advanced Computer Science, Leiden
University, Leiden, The Netherlands. (2)Department of Human Genetics, Leiden
University Medical Center, Leiden, The Netherlands. (3)Department of Human
Genetics, Leiden University Medical Center, Leiden, The Netherlands, Generade
Center of Expertise Genomics, University of Applied Sciences Leiden, Leiden, The 
Netherlands and. (4)Department of Human Genetics, Leiden University Medical
Center, Leiden, The Netherlands, Leiden Genome Technology Center, Leiden
University Medical Center, Leiden, The Netherlands.

MOTIVATION: Unambiguous sequence variant descriptions are important in reporting 
the outcome of clinical diagnostic DNA tests. The standard nomenclature of the
Human Genome Variation Society (HGVS) describes the observed variant sequence
relative to a given reference sequence. We propose an efficient algorithm for the
extraction of HGVS descriptions from two sequences with three main requirements
in mind: minimizing the length of the resulting descriptions, minimizing the
computation time and keeping the unambiguous descriptions biologically
meaningful.
RESULTS: Our algorithm is able to compute the HGVS descriptions of complete
chromosomes or other large DNA strings in a reasonable amount of computation time
and its resulting descriptions are relatively small. Additional applications
include updating of gene variant database contents and reference sequence
liftovers.
AVAILABILITY: The algorithm is accessible as an experimental service in the
Mutalyzer program suite (https://mutalyzer.nl). The C++ source code and Python
interface are accessible at: https://github.com/mutalyzer/description-extractor.
CONTACT: j.k.vis@lumc.nl.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv443 
PMID: 26231427  [PubMed - indexed for MEDLINE]


912. Syst Biol. 2015 Nov;64(6):1048-58. doi: 10.1093/sysbio/syv055. Epub 2015 Jul 30.

Automation and Evaluation of the SOWH Test with SOWHAT.

Church SH(1), Ryan JF(2), Dunn CW(3).

Author information: 
(1)Department of Ecology and Evolutionary Biology, Brown University, Providence, 
Rhode Island, USA; church@g.harvard.edu. (2)Whitney Laboratory for Marine
Biosciences, St. Augustine, Florida, USA; and Sars International Centre For
Marine Molecular Biology, Bergen, Norway. (3)Department of Ecology and
Evolutionary Biology, Brown University, Providence, Rhode Island, USA;

The Swofford-Olsen-Waddell-Hillis (SOWH) test evaluates statistical support for
incongruent phylogenetic topologies. It is commonly applied to determine if the
maximum likelihood tree in a phylogenetic analysis is significantly different
than an alternative hypothesis. The SOWH test compares the observed difference in
log-likelihood between two topologies to a null distribution of differences in
log-likelihood generated by parametric resampling. The test is a well-established
phylogenetic method for topology testing, but it is sensitive to model
misspecification, it is computationally burdensome to perform, and its
implementation requires the investigator to make several decisions that each have
the potential to affect the outcome of the test. We analyzed the effects of
multiple factors using seven data sets to which the SOWH test was previously
applied. These factors include a number of sample replicates, likelihood
software, the introduction of gaps to simulated data, the use of distinct models 
of evolution for data simulation and likelihood inference, and a suggested test
correction wherein an unresolved "zero-constrained" tree is used to simulate
sequence data. To facilitate these analyses and future applications of the SOWH
test, we wrote SOWHAT, a program that automates the SOWH test. We find that
inadequate bootstrap sampling can change the outcome of the SOWH test. The
results also show that using a zero-constrained tree for data simulation can
result in a wider null distribution and higher p-values, but does not change the 
outcome of the SOWH test for most of the data sets tested here. These results
will help others implement and evaluate the SOWH test and allow us to provide
recommendations for future applications of the SOWH test. SOWHAT is available for
download from https://github.com/josephryan/SOWHAT.

© The Author(s) 2015. Published by Oxford University Press, on behalf of the
Society of Systematic Biologists.

DOI: 10.1093/sysbio/syv055 
PMCID: PMC4604836
PMID: 26231182  [PubMed - indexed for MEDLINE]


913. Bioinformation. 2015 Jun 30;11(6):276-9. doi: 10.6026/97320630011276. eCollection
2015.

MapRepeat: an approach for effective assembly of repetitive regions in
prokaryotic genomes.

Mariano DC(1), Pereira FL(2), Ghosh P(3), Barh D(4), Figueiredo HC(2), Silva
A(5), Ramos RT(5), Azevedo VA(1).

Author information: 
(1)Laboratório de Genética Celular e Molecular, Departamento de Biologia Geral,
Instituto de Ciências Biológicas, Universidade Federal de Minas Gerais, CEP
31270-901, Belo Horizonte, Minas Gerais, Brazil. (2)National Reference Laboratory
for Aquatic Animal Diseases of Ministry of Fisheries and Aquaculture,
Universidade Federal de Minas Gerais, CEP 31270-901, Belo Horizonte, Minas
Gerais, Brazil. (3)Centre for Genomics and Applied Gene Technology, Institute of 
Integrative Omics and Applied Biotechnology (IIOAB), Nonakuri, PurbaMedinipur,
WB-721172, India ; Department of Computer Science, Virginia Commonwealth
University, Richmond, Virginia, USA. (4)Centre for Genomics and Applied Gene
Technology, Institute of Integrative Omics and Applied Biotechnology (IIOAB),
Nonakuri, PurbaMedinipur, WB-721172, India. (5)Instituto de Ciências Biológicas, 
Universidade Federal do Pará, Rua Augusto Corrêa, 01 - Guamá, Belém, PA, Brazil.

The newest technologies for DNA sequencing have led to the determination of the
primary structure of the genomes of organisms, mainly prokaryotes, with high
efficiency and at lower costs. However, the presence of regions with repetitive
sequences, in addition to the short reads produced by the Next-Generation
Sequencing (NGS) platforms, created a lot of difficulty in reconstructing the
original genome in silico. Thus, even today, genome assembly continues to be one 
of the major challenges in bioinformatics specifically when repetitive sequences 
are considered. In this paper, we present an approach to assemble repetitive
regions in prokaryotic genomes. Our methodology enables (i) the identification of
these regions through visual tools, (ii) the characterization of sequences on the
extremities of gaps and (iii) the extraction of consensus sequences based on
mapping of raw data to a reference genome. We also present a case study on the
assembly of regions that encode ribosomal RNAs (rRNA) in the genome of
Corynebacterium ulcerans FRC11, in order to show the efficiency of the strategies
presented here. The proposed methods and tools will help in finishing genome
assemblies, besides reducing the running time and associated costs.AVAILABILITY: 
All scripts are available at http://github.com/dcbmariano/maprepeat.

DOI: 10.6026/97320630011276 
PMCID: PMC4512001
PMID: 26229287  [PubMed]


914. Bioinformatics. 2015 Nov 15;31(22):3703-5. doi: 10.1093/bioinformatics/btv442.
Epub 2015 Jul 29.

BackCLIP: a tool to identify common background presence in PAR-CLIP datasets.

Reyes-Herrera PH(1), Speck-Hernandez CA(2), Sierra CA(2), Herrera S(3).

Author information: 
(1)Colombian Corporation for Agricultural Research (CORPOICA), 250047 Bogotá,
Colombia. (2)Universidad Antonio Nariño, 110311 Bogotá, Colombia. (3)Woods Hole
Oceanographic Institution, 02543 Massachusetts, USA and Massachusetts Institute
of Technology, 02139 Massachusetts, USA.

MOTIVATION: PAR-CLIP, a CLIP-seq protocol, derives a transcriptome wide set of
binding sites for RNA-binding proteins. Even though the protocol uses stringent
washing to remove experimental noise, some of it remains. A recent study measured
three sets of non-specific RNA backgrounds which are present in several PAR-CLIP 
datasets. However, a tool to identify the presence of common background in
PAR-CLIP datasets is not yet available.
RESULTS: We used the measured sets of non-specific RNA backgrounds to build a
common background set. Each element from the common background set has a score
that reflects its presence in several PAR-CLIP datasets. We present a tool that
uses this score to identify the amount of common backgrounds present in a
PAR-CLIP dataset, and we provide the user the option to use or remove it. We used
the proposed strategy in 30 PAR-CLIP datasets from nine proteins. It is possible 
to identify the presence of common backgrounds in a dataset and identify
differences in datasets for the same protein. This method is the first step in
the process of completely removing such backgrounds.
AVAILABILITY: The tool was implemented in python. The common background set and
the supplementary data are available at https://github.com/phrh/BackCLIP.
CONTACT: phreyes@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv442 
PMID: 26227145  [PubMed - indexed for MEDLINE]


915. Bioinformatics. 2015 Nov 15;31(22):3709-11. doi: 10.1093/bioinformatics/btv449.
Epub 2015 Jul 29.

SNPGenie: estimating evolutionary parameters to detect natural selection using
pooled next-generation sequencing data.

Nelson CW(1), Moncla LH(2), Hughes AL(1).

Author information: 
(1)Department of Biological Sciences, University of South Carolina, Columbia, SC 
29208, USA and. (2)Department of Pathobiological Sciences, University of
Wisconsin School of Veterinary Medicine, Madison, WI 53706, USA.

New applications of next-generation sequencing technologies use pools of DNA from
multiple individuals to estimate population genetic parameters. However, no
publicly available tools exist to analyse single-nucleotide polymorphism (SNP)
calling results directly for evolutionary parameters important in detecting
natural selection, including nucleotide diversity and gene diversity. We have
developed SNPGenie to fill this gap. The user submits a FASTA reference
sequence(s), a Gene Transfer Format (.GTF) file with CDS information and a SNP
report(s) in an increasing selection of formats. The program estimates nucleotide
diversity, distance from the reference and gene diversity. Sites are flagged for 
multiple overlapping reading frames, and are categorized by polymorphism type:
nonsynonymous, synonymous, or ambiguous. The results allow single nucleotide,
single codon, sliding window, whole gene and whole genome/population analyses
that aid in the detection of positive and purifying natural selection in the
source population.AVAILABILITY AND IMPLEMENTATION: SNPGenie version 1.2 is a Perl
program with no additional dependencies. It is free, open-source, and available
for download at https://github.com/hugheslab/snpgenie.
CONTACT: nelsoncw@email.sc.edu or austin@biol.sc.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv449 
PMCID: PMC4757956
PMID: 26227143  [PubMed - indexed for MEDLINE]


916. BMC Res Notes. 2015 Jul 31;8:328. doi: 10.1186/s13104-015-1281-y.

deFUME: Dynamic exploration of functional metagenomic sequencing data.

van der Helm E(1), Geertz-Hansen HM(2,)(3,)(4), Genee HJ(5), Malla S(6), Sommer
MO(7,)(8).

Author information: 
(1)Novo Nordisk Foundation Center for Biosustainability, Technical University of 
Denmark, 2970, Hørsholm, Denmark. evand@biosustain.dtu.dk. (2)Novo Nordisk
Foundation Center for Biosustainability, Technical University of Denmark, 2970,
Hørsholm, Denmark. HMGH@novozymes.com. (3)Department of Systems Biology, Center
for Biological Sequence Analysis, Technical University of Denmark, 2800, Lyngby, 
Denmark. HMGH@novozymes.com. (4)Novozymes A/S, 2880, Bagsværd, Denmark.
HMGH@novozymes.com. (5)Novo Nordisk Foundation Center for Biosustainability,
Technical University of Denmark, 2970, Hørsholm, Denmark. hansgenee@gmail.com.
(6)Novo Nordisk Foundation Center for Biosustainability, Technical University of 
Denmark, 2970, Hørsholm, Denmark. malla@biosustain.dtu.dk. (7)Novo Nordisk
Foundation Center for Biosustainability, Technical University of Denmark, 2970,
Hørsholm, Denmark. msom@bio.dtu.dk. (8)Department of Systems Biology, Technical
University of Denmark, 2800, Lyngby, Denmark. msom@bio.dtu.dk.

BACKGROUND: Functional metagenomic selections represent a powerful technique that
is widely applied for identification of novel genes from complex metagenomic
sources. However, whereas hundreds to thousands of clones can be easily generated
and sequenced over a few days of experiments, analyzing the data is time
consuming and constitutes a major bottleneck for experimental researchers in the 
field.
FINDINGS: Here we present the deFUME web server, an easy-to-use web-based
interface for processing, annotation and visualization of functional metagenomics
sequencing data, tailored to meet the requirements of non-bioinformaticians. The 
web-server integrates multiple analysis steps into one single workflow: read
assembly, open reading frame prediction, and annotation with BLAST, InterPro and 
GO classifiers. Analysis results are visualized in an online dynamic
web-interface.
CONCLUSION: The deFUME webserver provides a fast track from raw sequence to a
comprehensive visual data overview that facilitates effortless inspection of gene
function, clustering and distribution. The webserver is available at
cbs.dtu.dk/services/deFUME/and the source code is distributed at
github.com/EvdH0/deFUME.

DOI: 10.1186/s13104-015-1281-y 
PMCID: PMC4520277
PMID: 26227142  [PubMed - indexed for MEDLINE]


917. Genetics. 2015 Oct;201(2):473-86. doi: 10.1534/genetics.115.179077. Epub 2015 Jul
29.

Genotype-Frequency Estimation from High-Throughput Sequencing Data.

Maruki T(1), Lynch M(2).

Author information: 
(1)Department of Biology, Indiana University, Bloomington, Indiana 47405
tmaruki@indiana.edu. (2)Department of Biology, Indiana University, Bloomington,
Indiana 47405.

Rapidly improving high-throughput sequencing technologies provide unprecedented
opportunities for carrying out population-genomic studies with various organisms.
To take full advantage of these methods, it is essential to correctly estimate
allele and genotype frequencies, and here we present a maximum-likelihood method 
that accomplishes these tasks. The proposed method fully accounts for
uncertainties resulting from sequencing errors and biparental chromosome sampling
and yields essentially unbiased estimates with minimal sampling variances with
moderately high depths of coverage regardless of a mating system and structure of
the population. Moreover, we have developed statistical tests for examining the
significance of polymorphisms and their genotypic deviations from Hardy-Weinberg 
equilibrium. We examine the performance of the proposed method by computer
simulations and apply it to low-coverage human data generated by high-throughput 
sequencing. The results show that the proposed method improves our ability to
carry out population-genomic analyses in important ways. The software package of 
the proposed method is freely available from
https://github.com/Takahiro-Maruki/Package-GFE.

Copyright © 2015 by the Genetics Society of America.

DOI: 10.1534/genetics.115.179077 
PMCID: PMC4596663
PMID: 26224735  [PubMed - indexed for MEDLINE]


918. Bioinformatics. 2015 Nov 15;31(22):3694-6. doi: 10.1093/bioinformatics/btv440.
Epub 2015 Jul 27.

FermiKit: assembly-based variant calling for Illumina resequencing data.

Li H(1).

Author information: 
(1)Genomics Platform, Broad Institute, Cambridge, MA 02142, USA.

FermiKit is a variant calling pipeline for Illumina whole-genome germline data.
It de novo assembles short reads and then maps the assembly against a reference
genome to call SNPs, short insertions/deletions and structural variations.
FermiKit takes about one day to assemble 30-fold human whole-genome data on a
modern 16-core server with 85 GB RAM at the peak, and calls variants in half an
hour to an accuracy comparable to the current practice. FermiKit assembly is a
reduced representation of raw data while retaining most of the original
information.AVAILABILITY AND IMPLEMENTATION: https://github.com/lh3/fermikit
CONTACT: hengli@broadinstitute.org.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv440 
PMCID: PMC4757955
PMID: 26220959  [PubMed - indexed for MEDLINE]


919. Data Brief. 2015 Mar 4;3:131-6. doi: 10.1016/j.dib.2015.02.016. eCollection 2015.

Data set from gas sensor array under flow modulation.

Ziyatdinov A(1), Fonollosa J(2), Fernández L(3), Gutiérrez-Gálvez A(3), Marco
S(3), Perera A(1).

Author information: 
(1)B2SLab, Department of ESAII, Universitat Politenica de Catalunya, Pau Gargallo
5, Barcelona, Spain ; Centro de Investigacion Biomedica en Red en Bioingenierıa, 
Biomateriales y Nanomedicina (CIBER-BBN), Barcelona, Spain. (2)BioCircuits
Institute, University of California, San Diego, La Jolla, CA 92093, USA ; Signal 
and Information Processing for Sensing Systems Institute for Bioengineering of
Catalonia (IBEC), Baldiri Reixac, 4-8, 08028 Barcelona, Spain. (3)Signal and
Information Processing for Sensing Systems Institute for Bioengineering of
Catalonia (IBEC), Baldiri Reixac, 4-8, 08028 Barcelona, Spain ; Departament
d׳Electronica, Universitat de Barcelona, Marti i Franques 1, 08028 Barcelona,
Spain.

Recent studies in neuroscience suggest that sniffing, namely sampling odors
actively, plays an important role in olfactory system, especially in certain
scenarios such as novel odorant detection. While the computational advantages of 
high frequency sampling have not been yet elucidated, here, in order to motivate 
further investigation in active sampling strategies, we share the data from an
artificial olfactory system made of 16 MOX gas sensors under gas flow modulation.
The data were acquired on a custom set up featured by an external mechanical
ventilator that emulates the biological respiration cycle. 58 samples were
recorded in response to a relatively broad set of 12 gas classes, defined from
different binary mixtures of acetone and ethanol in air. The acquired time series
show two dominant frequency bands: the low-frequency signal corresponds to a
conventional response curve of a sensor in response to a gas pulse, and the
high-frequency signal has a clear principal harmonic at the respiration
frequency. The data are related to the study in [1], and the data analysis
results reported there should be considered as a reference point. The data
presented here have been deposited to the web site of The University of
California at Irvine (UCI) Machine Learning Repository
(https://archive.ics.uci.edu/ml/datasets/Gas+sensor+array+under+flow+modulation).
The code repository for reproducible analysis applied to the data is hosted at
the GutHub web site (https://github.com/variani/pulmon). The data and code can be
used upon citation of [1].

DOI: 10.1016/j.dib.2015.02.016 
PMCID: PMC4510100
PMID: 26217733  [PubMed]


920. Bioinformatics. 2015 Nov 15;31(22):3679-81. doi: 10.1093/bioinformatics/btv431.
Epub 2015 Jul 25.

The MI bundle: enabling network and structural biology in genome visualization
tools.

Céol A(1), Müller H(1).

Author information: 
(1)Center for Genomic Science of IIT@SEMM, Fondazione Istituto Italiano di
Tecnologia (IIT), 20139 Milan, Italy.

Prioritization of candidate genes emanating from large-scale screens requires
integrated analyses at the genomics, molecular, network and structural biology
levels. We have extended the Integrated Genome Browser (IGB) to facilitate these 
tasks. The graphical user interface greatly simplifies building disease networks 
and zooming in at atomic resolution to identify variations in molecular complexes
that may affect molecular interactions in the context of genomic data. All
results are summarized in genome tracks and can be visualized and analyzed at the
transcript level.AVAILABILITY AND IMPLEMENTATION: The MI Bundle is a plugin for
the IGB. The plugin, help, video and tutorial are available at
http://cru.genomics.iit.it/igbmibundle/ and
https://github.com/CRUiit/igb-mi-bundle/wiki. The source code is released under
the Apache License, Version 2.
CONTACT: arnaud.ceol@iit.it
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv431 
PMCID: PMC4817051
PMID: 26209801  [PubMed - indexed for MEDLINE]


921. Bioinformatics. 2015 Nov 15;31(22):3561-8. doi: 10.1093/bioinformatics/btv430.
Epub 2015 Jul 25.

Statistically identifying tumor suppressors and oncogenes from pan-cancer
genome-sequencing data.

Kumar RD(1), Searleman AC(2), Swamidass SJ(3), Griffith OL(4), Bose R(2).

Author information: 
(1)Division of Oncology, Department of Medicine, Washington University School of 
Medicine, Computational and Systems Biology Program, Washington University in St 
Louis. (2)Division of Oncology, Department of Medicine, Washington University
School of Medicine. (3)Computational and Systems Biology Program, Washington
University in St Louis, Department of Pathology and Immunology, Washington
University School of Medicine and. (4)Division of Oncology, Department of
Medicine, Washington University School of Medicine, Division of Oncology,
Department of Medicine, Washington University School of Medicine.

MOTIVATION: Several tools exist to identify cancer driver genes based on somatic 
mutation data. However, these tools do not account for subclasses of cancer
genes: oncogenes, which undergo gain-of-function events, and tumor suppressor
genes (TSGs) which undergo loss-of-function. A method which accounts for these
subclasses could improve performance while also suggesting a mechanism of action 
for new putative cancer genes.
RESULTS: We develop a panel of five complementary statistical tests and assess
their performance against a curated set of 99 HiConf cancer genes using a
pan-cancer dataset of 1.7 million mutations. We identify patient bias as a novel 
signal for cancer gene discovery, and use it to significantly improve detection
of oncogenes over existing methods (AUROC = 0.894). Additionally, our test of
truncation event rate separates oncogenes and TSGs from one another
(AUROC = 0.922). Finally, a random forest integrating the five tests further
improves performance and identifies new cancer genes, including CACNG3, HDAC2,
HIST1H1E, NXF1, GPS2 and HLA-DRB1.
AVAILABILITY AND IMPLEMENTATION: All mutation data, instructions, functions for
computing the statistics and integrating them, as well as the HiConf gene panel, 
are available at www.github.com/Bose-Lab/Improved-Detection-of-Cancer-Genes.
CONTACT: rbose@dom.wustl.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv430 
PMCID: PMC4757952
PMID: 26209800  [PubMed - indexed for MEDLINE]


922. Bioinformatics. 2015 Nov 15;31(22):3584-92. doi: 10.1093/bioinformatics/btv419.
Epub 2015 Jul 25.

Spaced seeds improve k-mer-based metagenomic classification.

Břinda K(1), Sykulski M(1), Kucherov G(1).

Author information: 
(1)LIGM/CNRS, Université Paris-Est, 77454 Marne-la-Vallée, France.

MOTIVATION: Metagenomics is a powerful approach to study genetic content of
environmental samples, which has been strongly promoted by next-generation
sequencing technologies. To cope with massive data involved in modern metagenomic
projects, recent tools rely on the analysis of k-mers shared between the read to 
be classified and sampled reference genomes.
RESULTS: Within this general framework, we show that spaced seeds provide a
significant improvement of classification accuracy, as opposed to traditional
contiguous k-mers. We support this thesis through a series of different
computational experiments, including simulations of large-scale metagenomic
projects.Availability and implementation, Supplementary information: Scripts and 
programs used in this study, as well as supplementary material, are available
from http://github.com/gregorykucherov/spaced-seeds-for-metagenomics.
CONTACT: gregory.kucherov@univ-mlv.fr.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv419 
PMID: 26209798  [PubMed - indexed for MEDLINE]


923. Bioinformatics. 2015 Nov 15;31(22):3666-72. doi: 10.1093/bioinformatics/btv377.
Epub 2015 Jul 24.

Alternative preprocessing of RNA-Sequencing data in The Cancer Genome Atlas leads
to improved analysis results.

Rahman M(1), Jackson LK(2), Johnson WE(3), Li DY(4), Bild AH(5), Piccolo SR(6).

Author information: 
(1)Department of Biomedical Informatics. (2)Department of Pharmacology and
Toxicology. (3)Department of Oncological Sciences, University of Utah, Salt Lake 
City, UT, USA, Division of Computational Biomedicine, Boston University School of
Medicine, Boston, MA 02118, USA. (4)Department of Oncological Sciences,
University of Utah, Salt Lake City, UT, USA, School of Medicine, Department of
Human Genetics, University of Utah, Salt Lake City, UT 84132, USA and.
(5)Department of Biomedical Informatics, Department of Pharmacology and
Toxicology, Department of Oncological Sciences, University of Utah, Salt Lake
City, UT, USA. (6)Department of Biology, Brigham Young University, Provo, UT
84604, USA.

MOTIVATION: The Cancer Genome Atlas (TCGA) RNA-Sequencing data are used widely
for research. TCGA provides 'Level 3' data, which have been processed using a
pipeline specific to that resource. However, we have found using experimentally
derived data that this pipeline produces gene-expression values that vary
considerably across biological replicates. In addition, some RNA-Sequencing
analysis tools require integer-based read counts, which are not provided with the
Level 3 data. As an alternative, we have reprocessed the data for 9264 tumor and 
741 normal samples across 24 cancer types using the Rsubread package. We have
also collated corresponding clinical data for these samples. We provide these
data as a community resource.
RESULTS: We compared TCGA samples processed using either pipeline and found that 
the Rsubread pipeline produced fewer zero-expression genes and more consistent
expression levels across replicate samples than the TCGA pipeline. Additionally, 
we used a genomic-signature approach to estimate HER2 (ERBB2) activation status
for 662 breast-tumor samples and found that the Rsubread data resulted in
stronger predictions of HER2 pathway activity. Finally, we used data from both
pipelines to classify 575 lung cancer samples based on histological type. This
analysis identified various non-coding RNA that may influence lung-cancer
histology.
AVAILABILITY AND IMPLEMENTATION: The RNA-Sequencing and clinical data can be
downloaded from Gene Expression Omnibus (accession number GSE62944). Scripts and 
code that were used to process and analyze the data are available from
https://github.com/srp33/TCGA_RNASeq_Clinical.
CONTACT: stephen_piccolo@byu.edu or andreab@genetics.utah.edu
SUPPLEMENTARY INFORMATION: Supplementary material is available at Bioinformatics 
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv377 
PMCID: PMC4804769
PMID: 26209429  [PubMed - indexed for MEDLINE]


924. BMC Bioinformatics. 2015 Jul 25;16:230. doi: 10.1186/s12859-015-0663-4.

Sealer: a scalable gap-closing application for finishing draft genomes.

Paulino D(1), Warren RL(2), Vandervalk BP(3), Raymond A(4), Jackman SD(5), Birol 
I(6,)(7).

Author information: 
(1)Canada's Michael Smith Genome Sciences Centre, British Columbia Cancer Agency,
Vancouver, BC, V5Z 4S6, Canada. dpaulino@bcgsc.ca. (2)Canada's Michael Smith
Genome Sciences Centre, British Columbia Cancer Agency, Vancouver, BC, V5Z 4S6,
Canada. rwarren@bcgsc.ca. (3)Canada's Michael Smith Genome Sciences Centre,
British Columbia Cancer Agency, Vancouver, BC, V5Z 4S6, Canada. benv@bcgsc.ca.
(4)Canada's Michael Smith Genome Sciences Centre, British Columbia Cancer Agency,
Vancouver, BC, V5Z 4S6, Canada. traymond@bcgsc.ca. (5)Canada's Michael Smith
Genome Sciences Centre, British Columbia Cancer Agency, Vancouver, BC, V5Z 4S6,
Canada. sjackman@bcgsc.ca. (6)Canada's Michael Smith Genome Sciences Centre,
British Columbia Cancer Agency, Vancouver, BC, V5Z 4S6, Canada. ibirol@bcgsc.ca. 
(7)Department of Medical Genetics, University of British Columbia, Vancouver, BC,
V6H 3N1, Canada. ibirol@bcgsc.ca.

BACKGROUND: While next-generation sequencing technologies have made sequencing
genomes faster and more affordable, deciphering the complete genome sequence of
an organism remains a significant bioinformatics challenge, especially for large 
genomes. Low sequence coverage, repetitive elements and short read length make de
novo genome assembly difficult, often resulting in sequence and/or fragment
"gaps" - uncharacterized nucleotide (N) stretches of unknown or estimated
lengths. Some of these gaps can be closed by re-processing latent information in 
the raw reads. Even though there are several tools for closing gaps, they do not 
easily scale up to processing billion base pair genomes.
RESULTS: Here we describe Sealer, a tool designed to close gaps within assembly
scaffolds by navigating de Bruijn graphs represented by space-efficient Bloom
filter data structures. We demonstrate how it scales to successfully close 50.8% 
and 13.8% of gaps in human (3 Gbp) and white spruce (20 Gbp) draft assemblies in 
under 30 and 27 h, respectively - a feat that is not possible with other leading 
tools with the breadth of data used in our study.
CONCLUSION: Sealer is an automated finishing application that uses the succinct
Bloom filter representation of a de Bruijn graph to close gaps in draft
assemblies, including that of very large genomes. We expect Sealer to have broad 
utility for finishing genomes across the tree of life, from bacterial genomes to 
large plant genomes and beyond. Sealer is available for download at
https://github.com/bcgsc/abyss/tree/sealer-release.

DOI: 10.1186/s12859-015-0663-4 
PMCID: PMC4515008
PMID: 26209068  [PubMed - indexed for MEDLINE]


925. Genome Med. 2015 Jul 1;7(1):64. doi: 10.1186/s13073-015-0187-6. eCollection 2015.

Transferring genomics to the clinic: distinguishing Burkitt and diffuse large B
cell lymphomas.

Sha C(1), Barrans S(2), Care MA(3), Cunningham D(4), Tooze RM(5), Jack A(2),
Westhead DR(1).

Author information: 
(1)School of Molecular and Cellular Biology, Garstang Building, University of
Leeds, Leeds, LS2 9JT UK. (2)Haematological, Malignancy Diagnostic Service, St
James's University Hospital, Leeds, UK. (3)Section of Experimental Haematology,
Leeds Institute of Cancer and Pathology, University of Leeds, Leeds, UK. (4)Royal
Marsden Hospital, Fulham Road, London, SW3 6JJ UK. (5)Haematological, Malignancy 
Diagnostic Service, St James's University Hospital, Leeds, UK ; Section of
Experimental Haematology, Leeds Institute of Cancer and Pathology, University of 
Leeds, Leeds, UK.

BACKGROUND: Classifiers based on molecular criteria such as gene expression
signatures have been developed to distinguish Burkitt lymphoma and diffuse large 
B cell lymphoma, which help to explore the intermediate cases where traditional
diagnosis is difficult. Transfer of these research classifiers into a clinical
setting is challenging because there are competing classifiers in the literature 
based on different methodology and gene sets with no clear best choice;
classifiers based on one expression measurement platform may not transfer
effectively to another; and, classifiers developed using fresh frozen samples may
not work effectively with the commonly used and more convenient formalin fixed
paraffin-embedded samples used in routine diagnosis.
METHODS: Here we thoroughly compared two published high profile classifiers
developed on data from different Affymetrix array platforms and fresh-frozen
tissue, examining their transferability and concordance. Based on this analysis, 
a new Burkitt and diffuse large B cell lymphoma classifier (BDC) was developed
and employed on Illumina DASL data from our own paraffin-embedded samples,
allowing comparison with the diagnosis made in a central haematopathology
laboratory and evaluation of clinical relevance.
RESULTS: We show that both previous classifiers can be recapitulated using very
much smaller gene sets than originally employed, and that the classification
result is closely dependent on the Burkitt lymphoma criteria applied in the
training set. The BDC classification on our data exhibits high agreement (~95 %) 
with the original diagnosis. A simple outcome comparison in the patients
presenting intermediate features on conventional criteria suggests that the cases
classified as Burkitt lymphoma by BDC have worse response to standard diffuse
large B cell lymphoma treatment than those classified as diffuse large B cell
lymphoma.
CONCLUSIONS: In this study, we comprehensively investigate two previous Burkitt
lymphoma molecular classifiers, and implement a new gene expression classifier,
BDC, that works effectively on paraffin-embedded samples and provides useful
information for treatment decisions. The classifier is available as a free
software package under the GNU public licence within the R statistical software
environment through the link
http://www.bioinformatics.leeds.ac.uk/labpages/softwares/ or on github
https://github.com/Sharlene/BDC.

DOI: 10.1186/s13073-015-0187-6 
PMCID: PMC4512160
PMID: 26207141  [PubMed]


926. Genome Biol. 2015 Jul 24;16:151. doi: 10.1186/s13059-015-0708-z.

Chromatin segmentation based on a probabilistic model for read counts explains a 
large portion of the epigenome.

Mammana A(1), Chung HR(2).

Author information: 
(1)Otto-Warburg-Laboratory, Epigenomics, Max Planck Institute for Molecular
Genetics, D-14195, Berlin, Germany. mammana@molgen.mpg.de.
(2)Otto-Warburg-Laboratory, Epigenomics, Max Planck Institute for Molecular
Genetics, D-14195, Berlin, Germany. chung@molgen.mpg.de.

Chromatin immunoprecipitation followed by sequencing (ChIP-seq) is an
increasingly common experimental approach to generate genome-wide maps of histone
modifications and to dissect the complexity of the epigenome. Here, we propose
EpiCSeg: a novel algorithm that combines several histone modification maps for
the segmentation and characterization of cell-type specific epigenomic
landscapes. By using an accurate probabilistic model for the read counts, EpiCSeg
provides a useful annotation for a considerably larger portion of the genome,
shows a stronger association with validation data, and yields more consistent
predictions across replicate experiments when compared to existing methods.The
software is available at http://github.com/lamortenera/epicseg.

DOI: 10.1186/s13059-015-0708-z 
PMCID: PMC4514447
PMID: 26206277  [PubMed - indexed for MEDLINE]


927. Bioinformatics. 2015 Nov 15;31(22):3691-3. doi: 10.1093/bioinformatics/btv421.
Epub 2015 Jul 20.

Roary: rapid large-scale prokaryote pan genome analysis.

Page AJ(1), Cummins CA(1), Hunt M(1), Wong VK(2), Reuter S(3), Holden MT(4),
Fookes M(1), Falush D(5), Keane JA(1), Parkhill J(1).

Author information: 
(1)Pathogen Genomics, The Wellcome Trust Sanger Institute, Wellcome Trust Genome 
Campus, Hinxton, Cambridge. (2)Pathogen Genomics, The Wellcome Trust Sanger
Institute, Wellcome Trust Genome Campus, Hinxton, Cambridge, Department of
Medicine, University of Cambridge, Cambridge. (3)Department of Medicine,
University of Cambridge, Cambridge. (4)School of Medicine, University of St.
Andrews, North Haugh, St Andrews and. (5)College of Medicine, Swansea University,
Swansea, UK.

A typical prokaryote population sequencing study can now consist of hundreds or
thousands of isolates. Interrogating these datasets can provide detailed insights
into the genetic structure of prokaryotic genomes. We introduce Roary, a tool
that rapidly builds large-scale pan genomes, identifying the core and accessory
genes. Roary makes construction of the pan genome of thousands of prokaryote
samples possible on a standard desktop without compromising on the accuracy of
results. Using a single CPU Roary can produce a pan genome consisting of 1000
isolates in 4.5 hours using 13 GB of RAM, with further speedups possible using
multiple processors.AVAILABILITY AND IMPLEMENTATION: Roary is implemented in Perl
and is freely available under an open source GPLv3 license from
http://sanger-pathogens.github.io/Roary
CONTACT: roary@sanger.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv421 
PMCID: PMC4817141
PMID: 26198102  [PubMed - indexed for MEDLINE]


928. J Microsc. 2015 Aug;259(2):143-54. doi: 10.1111/jmi.12266. Epub 2015 Jun 12.

Automated tracing of myelinated axons and detection of the nodes of Ranvier in
serial images of peripheral nerves.

Kreshuk A(1), Walecki R(1), Koethe U(1), Gierthmuehlen M(2), Plachta D(3), Genoud
C(4), Haastert-Talini K(5), Hamprecht FA(1).

Author information: 
(1)Heidelberg Collaboratory for Image Processing (HCI), Interdisciplinary Center 
for Scientific Computing (IWR), University of Heidelberg, Heidelberg, Germany.
(2)Department of Neurosurgery, University Medical Center, Freiburg, Germany.
(3)Department of Microsystems, Engineering, University of Freiburg, Freiburg,
Germany. (4)Facility for Advanced Imaging and Microscopy, Friedrich Miescher
Institute for Biomedical Research (FMI), Basel, Switzerland. (5)Institute of
Neuroanatomy, Hannover Medical School, Hannover, Germany and Center for Systems
Neurosciences (ZSN), Hannover, Germany.

The development of realistic neuroanatomical models of peripheral nerves for
simulation purposes requires the reconstruction of the morphology of the
myelinated fibres in the nerve, including their nodes of Ranvier. Currently, this
information has to be extracted by semimanual procedures, which severely limit
the scalability of the experiments. In this contribution, we propose a supervised
machine learning approach for the detailed reconstruction of the geometry of
fibres inside a peripheral nerve based on its high-resolution serial section
images. Learning from sparse expert annotations, the algorithm traces myelinated 
axons, even across the nodes of Ranvier. The latter are detected automatically.
The approach is based on classifying the myelinated membranes in a supervised
fashion, closing the membrane gaps by solving an assignment problem, and
classifying the closed gaps for the nodes of Ranvier detection. The algorithm has
been validated on two very different datasets: (i) rat vagus nerve subvolume,
SBFSEM microscope, 200 × 200 × 200 nm resolution, (ii) rat sensory branch
subvolume, confocal microscope, 384 × 384 × 800 nm resolution. For the first
dataset, the algorithm correctly reconstructed 88% of the axons (241 out of 273) 
and achieved 92% accuracy on the task of Ranvier node detection. For the second
dataset, the gap closing algorithm correctly closed 96.2% of the gaps, and 55% of
axons were reconstructed correctly through the whole volume. On both datasets,
training the algorithm on a small data subset and applying it to the full dataset
takes a fraction of the time required by the currently used semiautomated
protocols. Our software, raw data and ground truth annotations are available at
http://hci.iwr.uni-heidelberg.de/Benchmarks/. The development version of the code
can be found at https://github.com/RWalecki/ATMA.

© 2015 The Authors Journal of Microscopy © 2015 Royal Microscopical Society.

DOI: 10.1111/jmi.12266 
PMID: 26191646  [PubMed - indexed for MEDLINE]


929. BMC Bioinformatics. 2015 Jul 19;16:224. doi: 10.1186/s12859-015-0670-5.

QoRTs: a comprehensive toolset for quality control and data processing of RNA-Seq
experiments.

Hartley SW(1), Mullikin JC(2).

Author information: 
(1)Comparative Genomics Analysis Unit, Cancer Genetics and Comparative Genomics
Branch, National Human Genome Research Institute, National Institutes of Health, 
Bethesda, MD, 20892, USA. stephen.hartley@nih.gov. (2)Comparative Genomics
Analysis Unit, Cancer Genetics and Comparative Genomics Branch, National Human
Genome Research Institute, National Institutes of Health, Bethesda, MD, 20892,
USA.

BACKGROUND: High-throughput next-generation RNA sequencing has matured into a
viable and powerful method for detecting variations in transcript expression and 
regulation. Proactive quality control is of critical importance as unanticipated 
biases, artifacts, or errors can potentially drive false associations and lead to
flawed results.
RESULTS: We have developed the Quality of RNA-Seq Toolset, or QoRTs, a
comprehensive, multifunction toolset that assists in quality control and data
processing of high-throughput RNA sequencing data.
CONCLUSIONS: QoRTs generates an unmatched variety of quality control metrics, and
can provide cross-comparisons of replicates contrasted by batch, biological
sample, or experimental condition, revealing any outliers and/or systematic
issues that could drive false associations or otherwise compromise downstream
analyses. In addition, QoRTs simultaneously replaces the functionality of
numerous other data-processing tools, and can quickly and efficiently generate
quality control metrics, coverage counts (for genes, exons, and known/novel
splice-junctions), and browser tracks. These functions can all be carried out as 
part of a single unified data-processing/quality control run, greatly reducing
both the complexity and the total runtime of the analysis pipeline. The software,
source code, and documentation are available online at
http://hartleys.github.io/QoRTs.

DOI: 10.1186/s12859-015-0670-5 
PMCID: PMC4506620
PMID: 26187896  [PubMed - indexed for MEDLINE]


930. Bioinformatics. 2015 Nov 1;31(21):3421-8. doi: 10.1093/bioinformatics/btv415.
Epub 2015 Jul 14.

Karect: accurate correction of substitution, insertion and deletion errors for
next-generation sequencing data.

Allam A(1), Kalnis P(1), Solovyev V(1).

Author information: 
(1)Computer, Electrical and Mathematical Sciences and Engineering Division
(CEMSE), King Abdullah University of Science and Technology (KAUST), Thuwal
23955-6900, Saudi Arabia.

MOTIVATION: Next-generation sequencing generates large amounts of data affected
by errors in the form of substitutions, insertions or deletions of bases. Error
correction based on the high-coverage information, typically improves de novo
assembly. Most existing tools can correct substitution errors only; some support 
insertions and deletions, but accuracy in many cases is low.
RESULTS: We present Karect, a novel error correction technique based on multiple 
alignment. Our approach supports substitution, insertion and deletion errors. It 
can handle non-uniform coverage as well as moderately covered areas of the
sequenced genome. Experiments with data from Illumina, 454 FLX and Ion Torrent
sequencing machines demonstrate that Karect is more accurate than previous
methods, both in terms of correcting individual-bases errors (up to 10% increase 
in accuracy gain) and post de novo assembly quality (up to 10% increase in
NGA50). We also introduce an improved framework for evaluating the quality of
error correction.
AVAILABILITY AND IMPLEMENTATION: Karect is available at:
http://aminallam.github.io/karect.
CONTACT: amin.allam@kaust.edu.sa
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv415 
PMID: 26177965  [PubMed - indexed for MEDLINE]


931. Cancer Genet. 2015 Jul-Aug;208(7-8):408-13. doi: 10.1016/j.cancergen.2015.04.010.
Epub 2015 May 7.

Concordance of copy number alterations using a common analytic pipeline for
genome-wide analysis of Illumina and Affymetrix genotyping data: a report from
the Children's Oncology Group.

Vujkovic M(1), Attiyeh EF(2), Ries RE(3), Horn M(2), Goodman EK(2), Ding Y(2),
Kavcic M(4), Alonzo TA(5), Gerbing RB(6), Hirsch B(7), Raimondi S(2), Gamis
AS(8), Meshinchi S(3), Aplenc R(2).

Author information: 
(1)Division of Oncology, The Children's Hospital of Philadelphia, Philadelphia,
PA, USA. Electronic address: vujkovicm@email.chop.edu. (2)Division of Oncology,
The Children's Hospital of Philadelphia, Philadelphia, PA, USA. (3)Clinical
Research Division, Fred Hutchinson Cancer Research Center, Seattle, WA, USA.
(4)University Medical Centre, Ljubljana, Slovenia. (5)Keck School of Medicine,
University of Southern California, Los Angeles, CA, USA. (6)Children's Oncology
Group, Monrovia, CA, USA. (7)University of Minnesota, Minneapolis, MN, USA.
(8)Division of Hematology/Oncology/Bone Marrow Transplantation, Children's Mercy 
Hospitals and Clinics, Kansas City, MO, USA.

Copy number alterations (CNAs) are a hallmark of pediatric cancer genomes. An
increasing number of research groups use multiple platforms and software packages
to detect and analyze CNAs. However, different platforms have experimental and
analysis-specific biases that may yield different results. We sought to estimate 
the concordance of CNAs in children with de novo acute myeloid leukemia between
two experimental platforms: Affymetrix SNP 6.0 array and Illumina OmniQuad 2.5
BeadChip. Forty-five paired tumor-remission samples were genotyped on both
platforms, and CNAs were estimated from total signal intensity and allelic
contrast values using the allele-specific copy number analysis of tumors (ASCAT) 
algorithm. The two platforms were comparable in detection of CNAs, each missing
only two segments from a total of 42 CNAs (4.6%). Overall, there was an
interplatform agreement of 96% for allele-specific tumor profiles. However, poor 
quality samples with low signal/noise ratios showed a high rate of false-positive
segments independent of the genotyping platform. These results demonstrate that a
common analytic pipeline can be utilized for SNP array data from these two
platforms. The customized programming template for the preprocessing, data
integration, and analysis is publicly available at
https://github.com/AplenCHOP/affyLumCNA.

Published by Elsevier Inc.

DOI: 10.1016/j.cancergen.2015.04.010 
PMCID: PMC4523450
PMID: 26163103  [PubMed - indexed for MEDLINE]


932. PLoS Comput Biol. 2015 Jul 9;11(7):e1004274. doi: 10.1371/journal.pcbi.1004274.
eCollection 2015.

Genome Modeling System: A Knowledge Management Platform for Genomics.

Griffith M(1), Griffith OL(2), Smith SM(3), Ramu A(3), Callaway MB(3), Brummett
AM(3), Kiwala MJ(3), Coffman AC(3), Regier AA(3), Oberkfell BJ(3), Sanderson
GE(3), Mooney TP(3), Nutter NG(3), Belter EA(3), Du F(3), Long RL(3), Abbott
TE(3), Ferguson IT(3), Morton DL(3), Burnett MM(3), Weible JV(3), Peck JB(3),
Dukes A(3), McMichael JF(3), Lolofie JT(3), Derickson BR(3), Hundal J(3),
Skidmore ZL(3), Ainscough BJ(3), Dees ND(3), Schierding WS(3), Kandoth C(3), Kim 
KH(3), Lu C(3), Harris CC(3), Maher N(4), Maher CA(5), Magrini VJ(1), Abbott
BS(3), Chen K(3), Clark E(3), Das I(3), Fan X(3), Hawkins AE(3), Hepler TG(3),
Wylie TN(3), Leonard SM(3), Schroeder WE(3), Shi X(3), Carmichael LK(3), Weil
MR(3), Wohlstadter RW(3), Stiehr G(3), McLellan MD(3), Pohl CS(3), Miller CA(3), 
Koboldt DC(3), Walker JR(3), Eldred JM(3), Larson DE(1), Dooling DJ(3), Ding
L(6), Mardis ER(7), Wilson RK(7).

Author information: 
(1)The Genome Institute, Washington University in St. Louis, St. Louis, Missouri,
United States of America; Department of Genetics, Washington University School of
Medicine, St. Louis, Missouri, United States of America. (2)The Genome Institute,
Washington University in St. Louis, St. Louis, Missouri, United States of
America; Department of Medicine, Washington University School of Medicine, St.
Louis, Missouri, United States of America. (3)The Genome Institute, Washington
University in St. Louis, St. Louis, Missouri, United States of America.
(4)Department of Medicine, Washington University School of Medicine, St. Louis,
Missouri, United States of America. (5)The Genome Institute, Washington
University in St. Louis, St. Louis, Missouri, United States of America;
Department of Medicine, Washington University School of Medicine, St. Louis,
Missouri, United States of America; Siteman Cancer Center, Washington University 
School of Medicine, St. Louis, Missouri, United States of America. (6)The Genome 
Institute, Washington University in St. Louis, St. Louis, Missouri, United States
of America; Department of Genetics, Washington University School of Medicine, St.
Louis, Missouri, United States of America; Siteman Cancer Center, Washington
University School of Medicine, St. Louis, Missouri, United States of America.
(7)The Genome Institute, Washington University in St. Louis, St. Louis, Missouri,
United States of America; Department of Genetics, Washington University School of
Medicine, St. Louis, Missouri, United States of America; Department of Medicine, 
Washington University School of Medicine, St. Louis, Missouri, United States of
America; Siteman Cancer Center, Washington University School of Medicine, St.
Louis, Missouri, United States of America; Department of Molecular Microbiology, 
Washington University School of Medicine, St. Louis, Missouri, United States of
America.

In this work, we present the Genome Modeling System (GMS), an analysis
information management system capable of executing automated genome analysis
pipelines at a massive scale. The GMS framework provides detailed tracking of
samples and data coupled with reliable and repeatable analysis pipelines. The GMS
also serves as a platform for bioinformatics development, allowing a large team
to collaborate on data analysis, or an individual researcher to leverage the work
of others effectively within its data management system. Rather than separating
ad-hoc analysis from rigorous, reproducible pipelines, the GMS promotes
systematic integration between the two. As a demonstration of the GMS, we
performed an integrated analysis of whole genome, exome and transcriptome
sequencing data from a breast cancer cell line (HCC1395) and matched
lymphoblastoid line (HCC1395BL). These data are available for users to test the
software, complete tutorials and develop novel GMS pipeline configurations. The
GMS is available at https://github.com/genome/gms.

DOI: 10.1371/journal.pcbi.1004274 
PMCID: PMC4497734
PMID: 26158448  [PubMed - indexed for MEDLINE]


933. PeerJ. 2015 Jul 2;3:e1041. doi: 10.7717/peerj.1041. eCollection 2015.

Multi-level machine learning prediction of protein-protein interactions in
Saccharomyces cerevisiae.

Zubek J(1), Tatjewski M(1), Boniecki A(2), Mnich M(3), Basu S(4), Plewczynski
D(5).

Author information: 
(1)Centre of New Technologies, University of Warsaw , Warsaw , Poland ; Institute
of Computer Science, Polish Academy of Sciences , Warsaw , Poland. (2)Faculty of 
Mathematics, Informatics and Mechanics, University of Warsaw , Warsaw , Poland.
(3)Faculty of Mathematics and Computer Science, Jagiellonian University , Cracow 
, Poland. (4)Department of Computer Science and Engineering, Jadavpur University 
, Kolkata, West Bengal , India. (5)Centre of New Technologies, University of
Warsaw , Warsaw , Poland.

Accurate identification of protein-protein interactions (PPI) is the key step in 
understanding proteins' biological functions, which are typically
context-dependent. Many existing PPI predictors rely on aggregated features from 
protein sequences, however only a few methods exploit local information about
specific residue contacts. In this work we present a two-stage machine learning
approach for prediction of protein-protein interactions. We start with the
carefully filtered data on protein complexes available for Saccharomyces
cerevisiae in the Protein Data Bank (PDB) database. First, we build linear
descriptions of interacting and non-interacting sequence segment pairs based on
their inter-residue distances. Secondly, we train machine learning classifiers to
predict binary segment interactions for any two short sequence fragments. The
final prediction of the protein-protein interaction is done using the 2D matrix
representation of all-against-all possible interacting sequence segments of both 
analysed proteins. The level-I predictor achieves 0.88 AUC for micro-scale, i.e.,
residue-level prediction. The level-II predictor improves the results further by 
a more complex learning paradigm. We perform 30-fold macro-scale, i.e.,
protein-level cross-validation experiment. The level-II predictor using
PSIPRED-predicted secondary structure reaches 0.70 precision, 0.68 recall, and
0.70 AUC, whereas other popular methods provide results below 0.6 threshold
(recall, precision, AUC). Our results demonstrate that multi-scale sequence
features aggregation procedure is able to improve the machine learning results by
more than 10% as compared to other sequence representations. Prepared datasets
and source code for our experimental pipeline are freely available for download
from: http://zubekj.github.io/mlppi/ (open source Python implementation, OS
independent).

DOI: 10.7717/peerj.1041 
PMCID: PMC4493684
PMID: 26157620  [PubMed]


934. PLoS One. 2015 Jul 8;10(7):e0127612. doi: 10.1371/journal.pone.0127612.
eCollection 2015.

From Peer-Reviewed to Peer-Reproduced in Scholarly Publishing: The Complementary 
Roles of Data Models and Workflows in Bioinformatics.

González-Beltrán A(1), Li P(2), Zhao J(3), Avila-Garcia MS(4), Roos M(5),
Thompson M(5), van der Horst E(5), Kaliyaperumal R(5), Luo R(6), Lee TL(7), Lam
TW(6), Edmunds SC(2), Sansone SA(1), Rocca-Serra P(1).

Author information: 
(1)Oxford e-Research Centre, University of Oxford, 7 Keble Road, OX1 3QG, United 
Kingdom. (2)GigaScience, BGI HK Research Institute, 16 Dai Fu Street, Tai Po
Industrial Estate, Hong Kong, People's Republic of China. (3)InfoLab21, Lancaster
University, Bailrigg, Lancaster, LA1 4WA, United Kingdom. (4)Nuffield Department 
of Medicine, Experimental Medicine Division, John Radcliffe Hospital, Headley
Way, Headington, Oxford, OX3 9DU, United Kingdom. (5)Department of Human
Genetics, Leiden University Medical Center, P.O. Box 9600, 2300 RC Leiden, The
Netherlands. (6)HKU-BGI Bioinformatics Algorithms and Core Technology Research
Laboratory & Department of Computer Science, University of Hong Kong, Pokfulam,
Hong Kong, People's Republic of China. (7)School of Biomedical Sciences and
CUHK-BGI Innovation Institute of Trans-omics, The Chinese University of Hong
Kong, Shatin, Hong Kong, People's Republic of China.

MOTIVATION: Reproducing the results from a scientific paper can be challenging
due to the absence of data and the computational tools required for their
analysis. In addition, details relating to the procedures used to obtain the
published results can be difficult to discern due to the use of natural language 
when reporting how experiments have been performed. The Investigation/Study/Assay
(ISA), Nanopublications (NP), and Research Objects (RO) models are conceptual
data modelling frameworks that can structure such information from scientific
papers. Computational workflow platforms can also be used to reproduce analyses
of data in a principled manner. We assessed the extent by which ISA, NP, and RO
models, together with the Galaxy workflow system, can capture the experimental
processes and reproduce the findings of a previously published paper reporting on
the development of SOAPdenovo2, a de novo genome assembler.
RESULTS: Executable workflows were developed using Galaxy, which reproduced
results that were consistent with the published findings. A structured
representation of the information in the SOAPdenovo2 paper was produced by
combining the use of ISA, NP, and RO models. By structuring the information in
the published paper using these data and scientific workflow modelling
frameworks, it was possible to explicitly declare elements of experimental
design, variables, and findings. The models served as guides in the curation of
scientific information and this led to the identification of inconsistencies in
the original published paper, thereby allowing its authors to publish corrections
in the form of an errata.
AVAILABILITY: SOAPdenovo2 scripts, data, and results are available through the
GigaScience Database: http://dx.doi.org/10.5524/100044; the workflows are
available from GigaGalaxy: http://galaxy.cbiit.cuhk.edu.hk; and the
representations using the ISA, NP, and RO models are available through the
SOAPdenovo2 case study website http://isa-tools.github.io/soapdenovo2/.
CONTACT: philippe.rocca-serra@oerc.ox.ac.uk and
susanna-assunta.sansone@oerc.ox.ac.uk.

DOI: 10.1371/journal.pone.0127612 
PMCID: PMC4495984
PMID: 26154165  [PubMed - indexed for MEDLINE]


935. Bioinformatics. 2015 Nov 1;31(21):3549-51. doi: 10.1093/bioinformatics/btv393.
Epub 2015 Jul 2.

al3c: high-performance software for parameter inference using Approximate
Bayesian Computation.

Stram AH(1), Marjoram P(2), Chen GK(2).

Author information: 
(1)Cancer Center - Research, USC, Los Angeles, CA 90089, USA and. (2)Division of 
Biostatistics, Department of Preventive Medicine, USC, Los Angeles, CA 90033,
USA.

MOTIVATION: The development of Approximate Bayesian Computation (ABC) algorithms 
for parameter inference which are both computationally efficient and scalable in 
parallel computing environments is an important area of research. Monte Carlo
rejection sampling, a fundamental component of ABC algorithms, is trivial to
distribute over multiple processors but is inherently inefficient. While
development of algorithms such as ABC Sequential Monte Carlo (ABC-SMC) help
address the inherent inefficiencies of rejection sampling, such approaches are
not as easily scaled on multiple processors. As a result, current Bayesian
inference software offerings that use ABC-SMC lack the ability to scale in
parallel computing environments.
RESULTS: We present al3c, a C++ framework for implementing ABC-SMC in parallel.
By requiring only that users define essential functions such as the simulation
model and prior distribution function, al3c abstracts the user from both the
complexities of parallel programming and the details of the ABC-SMC algorithm. By
using the al3c framework, the user is able to scale the ABC-SMC algorithm in
parallel computing environments for his or her specific application, with minimal
programming overhead.
AVAILABILITY AND IMPLEMENTATION: al3c is offered as a static binary for Linux and
OS-X computing environments. The user completes an XML configuration file and C++
plug-in template for the specific application, which are used by al3c to obtain
the desired results. Users can download the static binaries, source code,
reference documentation and examples (including those in this article) by
visiting https://github.com/ahstram/al3c.
CONTACT: astram@usc.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv393 
PMCID: PMC4626746
PMID: 26142186  [PubMed - indexed for MEDLINE]


936. BioData Min. 2015 Jul 1;8:20. doi: 10.1186/s13040-015-0051-7. eCollection 2015.

Uncovering correlated variability in epigenomic datasets using the Karhunen-Loeve
transform.

Madrigal P(1), Krajewski P(2).

Author information: 
(1)Department of Biometry and Bioinformatics, Institute of Plant Genetics of the 
Polish Academy of Sciences, Strzeszyńska 34, Poznań, 60-479 Poland ; Present
address: Wellcome Trust-MRC Cambridge Stem Cell Institute, Anne McLaren
Laboratory for Regenerative Medicine, Department of Surgery, University of
Cambridge, West Forvie Building, Forvie Site, Robinson Way, Cambridge, CB2 0SZ UK
; Present address: Wellcome Trust Sanger Institute, Wellcome Trust Genome Campus,
Hinxton, Cambridge, CB10 1SA UK. (2)Department of Biometry and Bioinformatics,
Institute of Plant Genetics of the Polish Academy of Sciences, Strzeszyńska 34,
Poznań, 60-479 Poland.

BACKGROUND: Larger variation exists in epigenomes than in genomes, as a single
genome shapes the identity of multiple cell types. With the advent of
next-generation sequencing, one of the key problems in computational epigenomics 
is the poor understanding of correlations and quantitative differences between
large scale data sets.
RESULTS: Here we bring to genomics a scenario of functional principal component
analysis, a finite Karhunen-Loève transform, and explicitly decompose the
variation in the coverage profiles of 27 chromatin mark ChIP-seq datasets at
transcription start sites for H1, one of the most used human embryonic stem cell 
lines. Using this approach we identify positive correlations between H3K4me3 and 
H3K36me3, as well as between H3K9ac and H3K36me3, so far undetected by the most
commonly used Pearson correlation between read enrichment coverages. We uncover
highly negative correlations between H2A.Z, H3K4me3, and several histone
acetylation marks, but these occur only between principal components of first and
second order. We also demonstrate that levels of gene expression correlate
significantly with scores of components of order higher than one, demonstrating
that transcriptional regulation by histone marks escapes simple one-to-one
relationships. This correlations were higher in significance and magnitude in
protein coding genes than in non-coding RNAs.
CONCLUSIONS: In summary, we present a methodology to explore and uncover novel
patterns of epigenomic variability and covariability in genomic data sets by
using a functional eigenvalue decomposition of genomic data. R code is available 
at: http://github.com/pmb59/KLTepigenome.

DOI: 10.1186/s13040-015-0051-7 
PMCID: PMC4488123
PMID: 26140054  [PubMed]


937. Genome Med. 2015 Jun 9;7(1):52. doi: 10.1186/s13073-015-0176-9. eCollection 2015.

Phylogenetically typing bacterial strains from partial SNP genotypes observed
from direct sequencing of clinical specimen metagenomic data.

Sahl JW(1), Schupp JM(2), Rasko DA(3), Colman RE(2), Foster JT(4), Keim P(1).

Author information: 
(1)Department of Pathogen Genomics, Translational Genomics Research Institute,
Flagstaff, AZ USA ; Center for Microbial Genetics and Genomics, Northern Arizona 
University, Flagstaff, AZ 86011 USA. (2)Department of Pathogen Genomics,
Translational Genomics Research Institute, Flagstaff, AZ USA. (3)Institute for
Genome Sciences, University of Maryland School of Medicine, Baltimore, MD USA.
(4)Center for Microbial Genetics and Genomics, Northern Arizona University,
Flagstaff, AZ 86011 USA ; Current address: Department of Molecular, Cellular &
Biomedical Sciences, University of New Hampshire, Durham, NH USA.

We describe an approach for genotyping bacterial strains from low coverage genome
datasets, including metagenomic data from complex samples. Sequence reads from
unknown samples are aligned to a reference genome where the allele states of
known SNPs are determined. The Whole Genome Focused Array SNP Typing (WG-FAST)
pipeline can identify unknown strains with much less read data than is needed for
genome assembly. To test WG-FAST, we resampled SNPs from real samples to
understand the relationship between low coverage metagenomic data and accurate
phylogenetic placement. WG-FAST can be downloaded from
https://github.com/jasonsahl/wgfast.

DOI: 10.1186/s13073-015-0176-9 
PMCID: PMC4487561
PMID: 26136847  [PubMed]


938. BMC Bioinformatics. 2015 Jul 2;16:208. doi: 10.1186/s12859-015-0623-z.

MetaDiff: differential isoform expression analysis using random-effects
meta-regression.

Jia C(1), Guan W(2), Yang A(3), Xiao R(4), Tang WH(5), Moravec CS(6), Margulies
KB(7), Cappola TP(8), Li M(9), Li C(10).

Author information: 
(1)Department of Biostatistics and Epidemiology, University of Pennsylvania
Perelman School of Medicine, Philadelphia, PA, 19104, USA.
jiacheng@mail.med.upenn.edu. (2)Division of Biostatistics, School of Public
Health, University of Minnesota School of Public Health, Minneapolis, MN, 55455, 
USA. wguan@umn.edu. (3)Department of Biostatistics and Epidemiology, University
of Pennsylvania Perelman School of Medicine, Philadelphia, PA, 19104, USA.
sheepsheep.yang@gmail.com. (4)Department of Biostatistics and Epidemiology,
University of Pennsylvania Perelman School of Medicine, Philadelphia, PA, 19104, 
USA. rxiao@mail.med.upenn.edu. (5)Department of Cardiovascular Medicine,
Cleveland Clinic, Cleveland, OH, 44195, USA. TANGW@ccf.org. (6)Department of
Cardiovascular Medicine, Cleveland Clinic, Cleveland, OH, 44195, USA.
MORAVEC@ccf.org. (7)Cardiovascular Institute, University of Pennsylvania Perelman
School of Medicine, Philadelphia, PA, 19104, USA.
Kenneth.Margulies@uphs.upenn.edu. (8)Cardiovascular Institute, University of
Pennsylvania Perelman School of Medicine, Philadelphia, PA, 19104, USA.
thomas.cappola@uphs.upenn.edu. (9)Department of Biostatistics and Epidemiology,
University of Pennsylvania Perelman School of Medicine, Philadelphia, PA, 19104, 
USA. mingyao@mail.med.upenn.edu. (10)Department of Epidemiology and
Biostatistics, Case Western Reserve University, Cleveland, OH, 44106, USA.
cxl791@case.edu.

BACKGROUND: RNA sequencing (RNA-Seq) allows an unbiased survey of the entire
transcriptome in a high-throughput manner. A major application of RNA-Seq is to
detect differential isoform expression across experimental conditions, which is
of great biological interest due to its direct relevance to protein function and 
disease pathogenesis. Detection of differential isoform expression is challenging
because of uncertainty in isoform expression estimation owing to ambiguous reads 
and variability in precision of the estimates across samples. It is desirable to 
have a method that can account for these issues and is flexible enough to allow
adjustment for covariates.
RESULTS: In this paper, we present MetaDiff, a random-effects meta-regression
model that naturally fits for the above purposes. Through extensive simulations
and analysis of an RNA-Seq dataset on human heart failure, we show that the
random-effects meta-regression approach is computationally fast, reliable, and
can improve the power of differential expression analysis while controlling for
false positives due to the effect of covariates or confounding variables. In
contrast, several existing methods either fail to control false discovery rate or
have reduced power in the presence of covariates or confounding variables. The
source code, compiled JAR package and documentation of MetaDiff are freely
available at https://github.com/jiach/MetaDiff.
CONCLUSION: Our results indicate that random-effects meta-regression offers a
flexible framework for differential expression analysis of isoforms, particularly
when gene expression is influenced by other variables.

DOI: 10.1186/s12859-015-0623-z 
PMCID: PMC4489045
PMID: 26134005  [PubMed - indexed for MEDLINE]


939. Bioinformatics. 2015 Nov 1;31(21):3445-50. doi: 10.1093/bioinformatics/btv391.
Epub 2015 Jun 30.

A DNA shape-based regulatory score improves position-weight matrix-based
recognition of transcription factor binding sites.

Yang J(1), Ramsey SA(2).

Author information: 
(1)Department of Biomedical Sciences and. (2)Department of Biomedical Sciences
and School of Electrical Engineering and Computer Science, Oregon State
University, Corvallis, OR, USA.

MOTIVATION: The position-weight matrix (PWM) is a useful representation of a
transcription factor binding site (TFBS) sequence pattern because the PWM can be 
estimated from a small number of representative TFBS sequences. However, because 
the PWM probability model assumes independence between individual nucleotide
positions, the PWMs for some TFs poorly discriminate binding sites from
non-binding-sites that have similar sequence content. Since the local
three-dimensional DNA structure ('shape') is a determinant of TF binding
specificity and since DNA shape has a significant sequence-dependence, we
combined DNA shape-derived features into a TF-generalized regulatory score and
tested whether the score could improve PWM-based discrimination of TFBS from
non-binding-sites.
RESULTS: We compared a traditional PWM model to a model that combines the PWM
with a DNA shape feature-based regulatory potential score, for accuracy in
detecting binding sites for 75 vertebrate transcription factors. The PWM+shape
model was more accurate than the PWM-only model, for 45% of TFs tested, with no
significant loss of accuracy for the remaining TFs.
AVAILABILITY AND IMPLEMENTATION: The shape-based model is available as an
open-source R package at that is archived on the GitHub software repository at
https://github.com/ramseylab/regshape/.
CONTACT: stephen.ramsey@oregonstate.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv391 
PMCID: PMC4838056
PMID: 26130577  [PubMed - indexed for MEDLINE]


940. Bioinformatics. 2015 Nov 1;31(21):3429-36. doi: 10.1093/bioinformatics/btv345.
Epub 2015 Jun 30.

ProFET: Feature engineering captures high-level protein functions.

Ofer D(1), Linial M(1).

Author information: 
(1)Department of Biological Chemistry, Institute of Life Sciences, The Edmond J. 
Safra Campus, The Hebrew University of Jerusalem, Givat Ram, 91904, Israel.

MOTIVATION: The amount of sequenced genomes and proteins is growing at an
unprecedented pace. Unfortunately, manual curation and functional knowledge lag
behind. Homologous inference often fails at labeling proteins with diverse
functions and broad classes. Thus, identifying high-level protein functionality
remains challenging. We hypothesize that a universal feature engineering approach
can yield classification of high-level functions and unified properties when
combined with machine learning approaches, without requiring external databases
or alignment.
RESULTS: In this study, we present a novel bioinformatics toolkit called ProFET
(Protein Feature Engineering Toolkit). ProFET extracts hundreds of features
covering the elementary biophysical and sequence derived attributes. Most
features capture statistically informative patterns. In addition, different
representations of sequences and the amino acids alphabet provide a compact,
compressed set of features. The results from ProFET were incorporated in data
analysis pipelines, implemented in python and adapted for multi-genome scale
analysis. ProFET was applied on 17 established and novel protein benchmark
datasets involving classification for a variety of binary and multi-class tasks. 
The results show state of the art performance. The extracted features' show
excellent biological interpretability. The success of ProFET applies to a wide
range of high-level functions such as subcellular localization, structural
classes and proteins with unique functional properties (e.g. neuropeptide
precursors, thermophilic and nucleic acid binding). ProFET allows easy, universal
discovery of new target proteins, as well as understanding the features
underlying different high-level protein functions.
AVAILABILITY AND IMPLEMENTATION: ProFET source code and the datasets used are
freely available at https://github.com/ddofer/ProFET.
CONTACT: michall@cc.huji.ac.il
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv345 
PMID: 26130574  [PubMed - indexed for MEDLINE]


941. Bioinformation. 2015 Apr 30;11(4):173-5. doi: 10.6026/97320630011173. eCollection
2015.

BlastXtract2: Improving early exploration of (meta) genomes.

de Weerd H(1), van der Veen BE(2), Claesson MJ(3).

Author information: 
(1)Microbiology and Systems Biology, TNO, Zeist, The Netherlands. (2)Genomics
Core Facility, The Netherlands Cancer Institute, Amsterdam, The Netherlands.
(3)School of microbiology and alimentary pharmabiotic centre, university college 
cork, cork, Ireland.

To manage and intelligently mine the avalanche of genomic sequences intuitive and
user-friendly graphical interfaces are required. Here we present BlastXtract2
which exclusively facilitates early exploration of un-annotated genomic and
metagenomic sequences. Various formats of translated searches, including the
commonly used BlastX, of multiple sequences against multiple protein databases
can be uploaded to a relational database server, which can be accessed via a
locally installed web-server. There, an intuitive GUI allows straightforward
data-mining and enables quick detection of potential frameshifts and poorly
sequenced or assembled regions, thereby contributing in making BlastXtract2 a
unique and valuable tool for early exploration of (meta)genomic
sequences.AVAILABILITY: Source code, documentation and an online demo version are
available at https://github.com/ ClaessonLab/BlastXtract2.

DOI: 10.6026/97320630011173 
PMCID: PMC4479055
PMID: 26124555  [PubMed]


942. Bioinformatics. 2015 Nov 1;31(21):3546-8. doi: 10.1093/bioinformatics/btv381.
Epub 2015 Jun 26.

nextflu: real-time tracking of seasonal influenza virus evolution in humans.

Neher RA(1), Bedford T(2).

Author information: 
(1)Max Planck Institute for Developmental Biology, 72076 Tübingen, Germany and.
(2)Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Research
Center, Seattle, WA 98109, USA.

Seasonal influenza viruses evolve rapidly, allowing them to evade immunity in
their human hosts and reinfect previously infected individuals. Similarly,
vaccines against seasonal influenza need to be updated frequently to protect
against an evolving virus population. We have thus developed a processing
pipeline and browser-based visualization that allows convenient exploration and
analysis of the most recent influenza virus sequence data. This web-application
displays a phylogenetic tree that can be decorated with additional information
such as the viral genotype at specific sites, sampling location and derived
statistics that have been shown to be predictive of future virus dynamics. In
addition, mutation, genotype and clade frequency trajectories are calculated and 
displayed.AVAILABILITY AND IMPLEMENTATION: Python and Javascript source code is
freely available from https://github.com/blab/nextflu, while the web-application 
is live at http://nextflu.org.
CONTACT: tbedford@fredhutch.org.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv381 
PMCID: PMC4612219
PMID: 26115986  [PubMed - indexed for MEDLINE]


943. Bioinformatics. 2015 Oct 15;31(20):3371-3. doi: 10.1093/bioinformatics/btv386.
Epub 2015 Jun 25.

damidseq_pipeline: an automated pipeline for processing DamID sequencing
datasets.

Marshall OJ(1), Brand AH(1).

Author information: 
(1)Wellcome Trust/Cancer Research UK Gurdon Institute, Cambridge, CB2 1QN, UK.

DamID is a powerful technique for identifying regions of the genome bound by a
DNA-binding (or DNA-associated) protein. Currently, no method exists for
automatically processing next-generation sequencing DamID (DamID-seq) data, and
the use of DamID-seq datasets with normalization based on read-counts alone can
lead to high background and the loss of bound signal. DamID-seq thus presents
novel challenges in terms of normalization and background minimization. We
describe here damidseq_pipeline, a software pipeline that performs automatic
normalization and background reduction on multiple DamID-seq FASTQ
datasets.AVAILABILITY AND IMPLEMENTATION: Open-source and freely available from
http://owenjm.github.io/damidseq_pipeline. The damidseq_pipeline is implemented
in Perl and is compatible with any Unix-based operating system (e.g. Linux, Mac
OSX).
CONTACT: o.marshall@gurdon.cam.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv386 
PMCID: PMC4595905
PMID: 26112292  [PubMed - indexed for MEDLINE]


944. Bioinformatics. 2015 Oct 15;31(20):3398-400. doi: 10.1093/bioinformatics/btv387. 
Epub 2015 Jun 25.

Real-time multi-view deconvolution.

Schmid B(1), Huisken J(1).

Author information: 
(1)Max Planck Institute of Molecular Cell Biology and Genetics, 01307 Dresden,
Germany.

In light-sheet microscopy, overall image content and resolution are improved by
acquiring and fusing multiple views of the sample from different directions.
State-of-the-art multi-view (MV) deconvolution simultaneously fuses and
deconvolves the images in 3D, but processing takes a multiple of the acquisition 
time and constitutes the bottleneck in the imaging pipeline. Here, we show that
MV deconvolution in 3D can finally be achieved in real-time by processing
cross-sectional planes individually on the massively parallel architecture of a
graphics processing unit (GPU). Our approximation is valid in the typical case
where the rotation axis lies in the imaging plane.AVAILABILITY AND
IMPLEMENTATION: Source code and binaries are available on github
(https://github.com/bene51/), native code under the repository
'gpu_deconvolution', Java wrappers implementing Fiji plugins under
'SPIM_Reconstruction_Cuda'.
CONTACT: bschmid@mpi-cbg.de or huisken@mpi-cbg.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv387 
PMCID: PMC4595906
PMID: 26112291  [PubMed - indexed for MEDLINE]


945. J Cheminform. 2015 Jun 22;7:26. doi: 10.1186/s13321-015-0078-2. eCollection 2015.

Open Drug Discovery Toolkit (ODDT): a new open-source player in the drug
discovery field.

Wójcikowski M(1), Zielenkiewicz P(2), Siedlecki P(2).

Author information: 
(1)Institute of Biochemistry and Biophysics PAS, Pawinskiego 5a, 02-106 Warsaw,
Poland. (2)Institute of Biochemistry and Biophysics PAS, Pawinskiego 5a, 02-106
Warsaw, Poland ; Department of Systems Biology, Institute of Experimental Plant
Biology and Biotechnology, University of Warsaw, Miecznikowa 1, 02-096 Warsaw,
Poland.

BACKGROUND: There has been huge progress in the open cheminformatics field in
both methods and software development. Unfortunately, there has been little
effort to unite those methods and software into one package. We here describe the
Open Drug Discovery Toolkit (ODDT), which aims to fulfill the need for
comprehensive and open source drug discovery software.
RESULTS: The Open Drug Discovery Toolkit was developed as a free and open source 
tool for both computer aided drug discovery (CADD) developers and researchers.
ODDT reimplements many state-of-the-art methods, such as machine learning scoring
functions (RF-Score and NNScore) and wraps other external software to ease the
process of developing CADD pipelines. ODDT is an out-of-the-box solution designed
to be easily customizable and extensible. Therefore, users are strongly
encouraged to extend it and develop new methods. We here present three use cases 
for ODDT in common tasks in computer-aided drug discovery.
CONCLUSION: Open Drug Discovery Toolkit is released on a permissive 3-clause BSD 
license for both academic and industrial use. ODDT's source code, additional
examples and documentation are available on GitHub
(https://github.com/oddt/oddt).

DOI: 10.1186/s13321-015-0078-2 
PMCID: PMC4475766
PMID: 26101548  [PubMed]


946. Nucleic Acids Res. 2015 Oct 30;43(19):e123. doi: 10.1093/nar/gkv595. Epub 2015
Jun 22.

BioJazz: in silico evolution of cellular networks with unbounded complexity using
rule-based modeling.

Feng S(1), Ollivier JF(2), Swain PS(3), Soyer OS(4).

Author information: 
(1)School of Life Sciences, University of Warwick, Coventry, United Kingdom.
(2)Department of Physiology, McGill University, Montreal, Quebec. (3)SynthSys,
The University of Edinburgh, Edinburgh, United Kingdom peter.swain@ed.ac.uk.
(4)School of Life Sciences, University of Warwick, Coventry, United Kingdom
O.Soyer@warwick.ac.uk.

Systems biologists aim to decipher the structure and dynamics of signaling and
regulatory networks underpinning cellular responses; synthetic biologists can use
this insight to alter existing networks or engineer de novo ones. Both tasks will
benefit from an understanding of which structural and dynamic features of
networks can emerge from evolutionary processes, through which intermediary steps
these arise, and whether they embody general design principles. As natural
evolution at the level of network dynamics is difficult to study, in silico
evolution of network models can provide important insights. However, current
tools used for in silico evolution of network dynamics are limited to ad hoc
computer simulations and models. Here we introduce BioJazz, an extendable,
user-friendly tool for simulating the evolution of dynamic biochemical networks. 
Unlike previous tools for in silico evolution, BioJazz allows for the evolution
of cellular networks with unbounded complexity by combining rule-based modeling
with an encoding of networks that is akin to a genome. We show that BioJazz can
be used to implement biologically realistic selective pressures and allows
exploration of the space of network architectures and dynamics that implement
prescribed physiological functions. BioJazz is provided as an open-source tool to
facilitate its further development and use. Source code and user manuals are
available at: http://oss-lab.github.io/biojazz and
http://osslab.lifesci.warwick.ac.uk/BioJazz.aspx.

© The Author(s) 2015. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkv595 
PMCID: PMC4627059
PMID: 26101250  [PubMed - indexed for MEDLINE]


947. Bioinformatics. 2015 Oct 15;31(20):3350-2. doi: 10.1093/bioinformatics/btv383.
Epub 2015 Jun 22.

Bandage: interactive visualization of de novo genome assemblies.

Wick RR(1), Schultz MB(1), Zobel J(2), Holt KE(1).

Author information: 
(1)Department of Biochemistry and Molecular Biology, Bio21 Molecular Science and 
Biotechnology Institute, University of Melbourne and. (2)Department of Computing 
and Information Systems, University of Melbourne, Parkville, Victoria, Australia.

Although de novo assembly graphs contain assembled contigs (nodes), the
connections between those contigs (edges) are difficult for users to access.
Bandage (a Bioinformatics Application for Navigating De novo Assembly Graphs
Easily) is a tool for visualizing assembly graphs with connections. Users can
zoom in to specific areas of the graph and interact with it by moving nodes,
adding labels, changing colors and extracting sequences. BLAST searches can be
performed within the Bandage graphical user interface and the hits are displayed 
as highlights in the graph. By displaying connections between contigs, Bandage
presents new possibilities for analyzing de novo assemblies that are not possible
through investigation of contigs alone.AVAILABILITY AND IMPLEMENTATION: Source
code and binaries are freely available at https://github.com/rrwick/Bandage.
Bandage is implemented in C++ and supported on Linux, OS X and Windows. A full
feature list and screenshots are available at http://rrwick.github.io/Bandage.
CONTACT: rrwick@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv383 
PMCID: PMC4595904
PMID: 26099265  [PubMed - indexed for MEDLINE]


948. Bioinformatics. 2015 Oct 15;31(20):3377-9. doi: 10.1093/bioinformatics/btv372.
Epub 2015 Jun 22.

Forna (force-directed RNA): Simple and effective online RNA secondary structure
diagrams.

Kerpedjiev P(1), Hammer S(2), Hofacker IL(2).

Author information: 
(1)Institute for Theoretical Chemistry, University of Vienna, Währinger Straße
17/3, A-1090 Vienna, Austria and. (2)Institute for Theoretical Chemistry,
University of Vienna, Währinger Straße 17/3, A-1090 Vienna, Austria and Research 
Group Bioinformatics and Computational Biology, University of Vienna, Währinger
Straße 29, A-1090 Vienna, Austria.

MOTIVATION: The secondary structure of RNA is integral to the variety of
functions it carries out in the cell and its depiction allows researchers to
develop hypotheses about which nucleotides and base pairs are functionally
relevant. Current approaches to visualizing secondary structure provide an
adequate platform for the conversion of static text-based representations to 2D
images, but are limited in their offer of interactivity as well as their ability 
to display larger structures, multiple structures and pseudoknotted structures.
RESULTS: In this article, we present forna, a web-based tool for displaying RNA
secondary structure which allows users to easily convert sequences and secondary 
structures to clean, concise and customizable visualizations. It supports, among 
other features, the simultaneous visualization of multiple structures, the
display of pseudoknotted structures, the interactive editing of the displayed
structures, and the automatic generation of secondary structure diagrams from PDB
files. It requires no software installation apart from a modern web browser.
AVAILABILITY AND IMPLEMENTATION: The web interface of forna is available at
http://rna.tbi.univie.ac.at/forna while the source code is available on github at
www.github.com/pkerpedjiev/forna.
CONTACT: pkerp@tbi.univie.ac.at
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv372 
PMCID: PMC4595900
PMID: 26099263  [PubMed - indexed for MEDLINE]


949. Bioinformatics. 2015 Oct 15;31(20):3348-9. doi: 10.1093/bioinformatics/btv376.
Epub 2015 Jun 20.

GenomeD3Plot: a library for rich, interactive visualizations of genomic data in
web applications.

Laird MR(1), Langille MG(2), Brinkman FS(1).

Author information: 
(1)Department of Molecular Biology and Biochemistry, Simon Fraser University,
Burnaby, British Columbia, V5A 1S6 and. (2)Department of Pharmacology, Dalhousie 
University, Halifax, Nova Scotia, B3H 4R2, Canada.

MOTIVATION: A simple static image of genomes and associated metadata is very
limiting, as researchers expect rich, interactive tools similar to the web
applications found in the post-Web 2.0 world. GenomeD3Plot is a light weight
visualization library written in javascript using the D3 library. GenomeD3Plot
provides a rich API to allow the rapid visualization of complex genomic data
using a convenient standards based JSON configuration file. When integrated into 
existing web services GenomeD3Plot allows researchers to interact with data,
dynamically alter the view, or even resize or reposition the visualization in
their browser window. In addition GenomeD3Plot has built in functionality to
export any resulting genome visualization in PNG or SVG format for easy inclusion
in manuscripts or presentations.
RESULTS: GenomeD3Plot is being utilized in the recently released Islandviewer 3
(www.pathogenomics.sfu.ca/islandviewer/) to visualize predicted genomic islands
with other genome annotation data. However, its features enable it to be more
widely applicable for dynamic visualization of genomic data in general.
AVAILABILITY AND IMPLEMENTATION: GenomeD3Plot is licensed under the GNU-GPL v3 at
https://github.com/brinkmanlab/GenomeD3Plot/.
CONTACT: brinkman@sfu.ca.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv376 
PMCID: PMC4595901
PMID: 26093150  [PubMed - indexed for MEDLINE]


950. Bioinformatics. 2015 Oct 15;31(20):3282-9. doi: 10.1093/bioinformatics/btv378.
Epub 2015 Jun 20.

An efficient Bayesian inference framework for coalescent-based nonparametric
phylodynamics.

Lan S(1), Palacios JA(2), Karcher M(3), Minin VN(4), Shahbaba B(5).

Author information: 
(1)Department of Statistics, University of Warwick, Coventry CV4 7AL, UK.
(2)Department of Organismic and Evolutionary Biology, Harvard University, MA
02138, US, Department of Ecology and Evolutionary Biology, Brown University, RI
02912, US, Center for Computational Molecular Biology, Brown University.
(3)Department of Statistics, University of Washington, WA 98195, US.
(4)Department of Statistics, University of Washington, WA 98195, US, Department
of Biology, University of Washington and. (5)Department of Statistics, University
of California, Irvine, CA 92697, US.

MOTIVATION: The field of phylodynamics focuses on the problem of reconstructing
population size dynamics over time using current genetic samples taken from the
population of interest. This technique has been extensively used in many areas of
biology but is particularly useful for studying the spread of quickly evolving
infectious diseases agents, e.g. influenza virus. Phylodynamic inference uses a
coalescent model that defines a probability density for the genealogy of randomly
sampled individuals from the population. When we assume that such a genealogy is 
known, the coalescent model, equipped with a Gaussian process prior on population
size trajectory, allows for nonparametric Bayesian estimation of population size 
dynamics. Although this approach is quite powerful, large datasets collected
during infectious disease surveillance challenge the state-of-the-art of Bayesian
phylodynamics and demand inferential methods with relatively low computational
cost.
RESULTS: To satisfy this demand, we provide a computationally efficient Bayesian 
inference framework based on Hamiltonian Monte Carlo for coalescent process
models. Moreover, we show that by splitting the Hamiltonian function, we can
further improve the efficiency of this approach. Using several simulated and real
datasets, we show that our method provides accurate estimates of population size 
dynamics and is substantially faster than alternative methods based on elliptical
slice sampler and Metropolis-adjusted Langevin algorithm.
AVAILABILITY AND IMPLEMENTATION: The R code for all simulation studies and real
data analysis conducted in this article are publicly available at
http://www.ics.uci.edu/∼slan/lanzi/CODES.html and in the R package phylodyn
available at https://github.com/mdkarcher/phylodyn.
CONTACT: S.Lan@warwick.ac.uk or babaks@uci.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv378 
PMCID: PMC4795633
PMID: 26093147  [PubMed - indexed for MEDLINE]


951. Bioinformatics. 2015 Oct 15;31(20):3353-5. doi: 10.1093/bioinformatics/btv328.
Epub 2015 Jun 18.

atSNP: transcription factor binding affinity testing for regulatory SNP
detection.

Zuo C(1), Shin S(1), Keleş S(1).

Author information: 
(1)Department of Statistics and Department of Biostatistics and Medical
Informatics, University of Wisconsin-Madison, Madison, WI, USA.

MOTIVATION: Genome-wide association studies revealed that most disease-associated
single nucleotide polymorphisms (SNPs) are located in regulatory regions within
introns or in regions between genes. Regulatory SNPs (rSNPs) are such SNPs that
affect gene regulation by changing transcription factor (TF) binding affinities
to genomic sequences. Identifying potential rSNPs is crucial for understanding
disease mechanisms. In silico methods that evaluate the impact of SNPs on TF
binding affinities are not scalable for large-scale analysis.
RESULTS: We describe A: ffinity T: esting for regulatory SNP: s (atSNP), a
computationally efficient R package for identifying rSNPs in silico. atSNP
implements an importance sampling algorithm coupled with a first-order Markov
model for the background nucleotide sequences to test the significance of
affinity scores and SNP-driven changes in these scores. Application of atSNP with
>20 K SNPs indicates that atSNP is the only available tool for such a large-scale
task. atSNP provides user-friendly output in the form of both tables and
composite logo plots for visualizing SNP-motif interactions. Evaluations of atSNP
with known rSNP-TF interactions indicate that SNP is able to prioritize motifs
for a given set of SNPs with high accuracy.
AVAILABILITY AND IMPLEMENTATION: https://github.com/keleslab/atSNP.
CONTACT: keles@stat.wisc.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv328 
PMCID: PMC4643619
PMID: 26092860  [PubMed - indexed for MEDLINE]


952. J Appl Crystallogr. 2015 May 9;48(Pt 3):953-961. eCollection 2015.

SCT: a suite of programs for comparing atomistic models with small-angle
scattering data.

Wright DW(1), Perkins SJ(1).

Author information: 
(1)Department of Structural and Molecular Biology, Division of Biosciences,
University College London , Darwin Building, Gower Street, London WC1E 6BT, UK.

Small-angle X-ray and neutron scattering techniques characterize proteins in
solution and complement high-resolution structural studies. They are of
particular utility when large proteins cannot be crystallized or when the
structure is altered by solution conditions. Atomistic models of the averaged
structure can be generated through constrained modelling, a technique in which
known domain or subunit structures are combined with linker models to produce
candidate global conformations. By randomizing the configuration adopted by the
different elements of the model, thousands of candidate structures are produced. 
Next, theoretical scattering curves are generated for each model for
trial-and-error fits to the experimental data. From these, a small family of
best-fit models is identified. In order to facilitate both the computation of
theoretical scattering curves from atomistic models and their comparison with
experiment, the SCT suite of tools was developed. SCT also includes programs that
provide sequence-based estimates of protein volume (either incorporating
hydration or not) and add a hydration layer to models for X-ray scattering
modelling. The original SCT software, written in Fortran, resulted in the first
atomistic scattering structures to be deposited in the Protein Data Bank, and
77 structures for antibodies, complement proteins and anionic oligosaccharides
were determined between 1998 and 2014. For the first time, this software is
publicly available, alongside an easier-to-use reimplementation of the same
algorithms in Python. Both versions of SCT have been released as open-source
software under the Apache 2 license and are available for download from
https://github.com/dww100/sct.

DOI: 10.1107/S1600576715007062 
PMCID: PMC4453981
PMID: 26089768  [PubMed]


953. J Transl Med. 2015 Jun 19;13:196. doi: 10.1186/s12967-015-0541-x.

An interactive web application for the dissemination of human systems immunology 
data.

Speake C(1), Presnell S(2), Domico K(3), Zeitner B(4), Bjork A(5), Anderson D(6),
Mason MJ(7), Whalen E(8), Vargas O(9), Popov D(10), Rinchai D(11), Jourde-Chiche 
N(12), Chiche L(13), Quinn C(14), Chaussabel D(15,)(16).

Author information: 
(1)Benaroya Research Institute, Systems Immunology Laboratory, 1201 Ninth Ave.,
Seattle, WA, 98101, USA. cspeake@benaroyaresearch.org. (2)Benaroya Research
Institute, Systems Immunology Laboratory, 1201 Ninth Ave., Seattle, WA, 98101,
USA. spresnell@benaroyaresearch.org. (3)Benaroya Research Institute, Systems
Immunology Laboratory, 1201 Ninth Ave., Seattle, WA, 98101, USA.
kdomico@gmail.com. (4)Benaroya Research Institute, Systems Immunology Laboratory,
1201 Ninth Ave., Seattle, WA, 98101, USA. bzeitner@benaroyaresearch.org.
(5)Benaroya Research Institute, Systems Immunology Laboratory, 1201 Ninth Ave.,
Seattle, WA, 98101, USA. abjork@benaroyaresearch.org. (6)Benaroya Research
Institute, Systems Immunology Laboratory, 1201 Ninth Ave., Seattle, WA, 98101,
USA. dma36@columbia.edu. (7)Benaroya Research Institute, Systems Immunology
Laboratory, 1201 Ninth Ave., Seattle, WA, 98101, USA.
mmason@benaroyaresearch.org. (8)Benaroya Research Institute, Systems Immunology
Laboratory, 1201 Ninth Ave., Seattle, WA, 98101, USA.
ewhalen@benaroyaresearch.org. (9)Benaroya Research Institute, Systems Immunology 
Laboratory, 1201 Ninth Ave., Seattle, WA, 98101, USA. ovargas@uw.edu.
(10)Benaroya Research Institute, Systems Immunology Laboratory, 1201 Ninth Ave., 
Seattle, WA, 98101, USA. dpopov@benaroyaresearch.org. (11)Sidra Medical and
Research Center, Doha, Qatar. drinchai@sidra.org. (12)Aix-Marseille University,
Marseille, France. Noemie.JOURDE@ap-hm.fr. (13)Department of Internal Medicine
and Infectious Diseases, European Hospital, Marseille, France.
laurentchiche@hotmail.com. (14)Benaroya Research Institute, Systems Immunology
Laboratory, 1201 Ninth Ave., Seattle, WA, 98101, USA.
cquinn@benaroyaresearch.org. (15)Benaroya Research Institute, Systems Immunology 
Laboratory, 1201 Ninth Ave., Seattle, WA, 98101, USA. dchaussabel@sidra.org.
(16)Sidra Medical and Research Center, Doha, Qatar. dchaussabel@sidra.org.

BACKGROUND: Systems immunology approaches have proven invaluable in translational
research settings. The current rate at which large-scale datasets are generated
presents unique challenges and opportunities. Mining aggregates of these datasets
could accelerate the pace of discovery, but new solutions are needed to integrate
the heterogeneous data types with the contextual information that is necessary
for interpretation. In addition, enabling tools and technologies facilitating
investigators' interaction with large-scale datasets must be developed in order
to promote insight and foster knowledge discovery.
METHODS: State of the art application programming was employed to develop an
interactive web application for browsing and visualizing large and complex
datasets. A collection of human immune transcriptome datasets were loaded
alongside contextual information about the samples.
RESULTS: We provide a resource enabling interactive query and navigation of
transcriptome datasets relevant to human immunology research. Detailed
information about studies and samples are displayed dynamically; if desired the
associated data can be downloaded. Custom interactive visualizations of the data 
can be shared via email or social media. This application can be used to browse
context-rich systems-scale data within and across systems immunology studies.
This resource is publicly available online at [Gene Expression Browser Landing
Page ( https://gxb.benaroyaresearch.org/dm3/landing.gsp )]. The source code is
also available openly [Gene Expression Browser Source Code (
https://github.com/BenaroyaResearch/gxbrowser )].
CONCLUSIONS: We have developed a data browsing and visualization application
capable of navigating increasingly large and complex datasets generated in the
context of immunological studies. This intuitive tool ensures that, whether taken
individually or as a whole, such datasets generated at great effort and expense
remain interpretable and a ready source of insight for years to come.

DOI: 10.1186/s12967-015-0541-x 
PMCID: PMC4474328
PMID: 26088622  [PubMed - indexed for MEDLINE]


954. PLoS One. 2015 Jun 18;10(6):e0129183. doi: 10.1371/journal.pone.0129183.
eCollection 2015.

Weighted Statistical Binning: Enabling Statistically Consistent Genome-Scale
Phylogenetic Analyses.

Bayzid MS(1), Mirarab S(1), Boussau B(2), Warnow T(3).

Author information: 
(1)Department of Computer Science, University of Texas at Austin, Austin, Texas, 
USA. (2)Laboratoire de Biométrie et Biologie Évolutive, Université de Lyons,
France. (3)Department of Computer Science, University of Illinois at
Urbana-Champaign, Urbana, IL, USA.

Because biological processes can result in different loci having different
evolutionary histories, species tree estimation requires multiple loci from
across multiple genomes. While many processes can result in discord between gene 
trees and species trees, incomplete lineage sorting (ILS), modeled by the
multi-species coalescent, is considered to be a dominant cause for gene tree
heterogeneity. Coalescent-based methods have been developed to estimate species
trees, many of which operate by combining estimated gene trees, and so are called
"summary methods". Because summary methods are generally fast (and much faster
than more complicated coalescent-based methods that co-estimate gene trees and
species trees), they have become very popular techniques for estimating species
trees from multiple loci. However, recent studies have established that summary
methods can have reduced accuracy in the presence of gene tree estimation error, 
and also that many biological datasets have substantial gene tree estimation
error, so that summary methods may not be highly accurate in biologically
realistic conditions. Mirarab et al. (Science 2014) presented the "statistical
binning" technique to improve gene tree estimation in multi-locus analyses, and
showed that it improved the accuracy of MP-EST, one of the most popular
coalescent-based summary methods. Statistical binning, which uses a simple
heuristic to evaluate "combinability" and then uses the larger sets of genes to
re-calculate gene trees, has good empirical performance, but using statistical
binning within a phylogenomic pipeline does not have the desirable property of
being statistically consistent. We show that weighting the re-calculated gene
trees by the bin sizes makes statistical binning statistically consistent under
the multispecies coalescent, and maintains the good empirical performance. Thus, 
"weighted statistical binning" enables highly accurate genome-scale species tree 
estimation, and is also statistically consistent under the multi-species
coalescent model. New data used in this study are available at DOI:
http://dx.doi.org/10.6084/m9.figshare.1411146, and the software is available at
https://github.com/smirarab/binning.

DOI: 10.1371/journal.pone.0129183 
PMCID: PMC4472720
PMID: 26086579  [PubMed - indexed for MEDLINE]


955. Bioinformatics. 2015 Oct 15;31(20):3299-305. doi: 10.1093/bioinformatics/btv352. 
Epub 2015 Jun 17.

Fast-SL: an efficient algorithm to identify synthetic lethal sets in metabolic
networks.

Pratapa A(1), Balachandran S(2), Raman K(1).

Author information: 
(1)Department of Biotechnology, Bhupat and Jyoti Mehta School of Biosciences and.
(2)Department of Computer Science and Engineering, Indian Institute of Technology
Madras, Chennai 600 036, India.

MOTIVATION: Synthetic lethal sets are sets of reactions/genes where only the
simultaneous removal of all reactions/genes in the set abolishes growth of an
organism. Previous approaches to identify synthetic lethal genes in genome-scale 
metabolic networks have built on the framework of flux balance analysis (FBA),
extending it either to exhaustively analyze all possible combinations of genes or
formulate the problem as a bi-level mixed integer linear programming (MILP)
problem. We here propose an algorithm, Fast-SL, which surmounts the computational
complexity of previous approaches by iteratively reducing the search space for
synthetic lethals, resulting in a substantial reduction in running time, even for
higher order synthetic lethals.
RESULTS: We performed synthetic reaction and gene lethality analysis, using
Fast-SL, for genome-scale metabolic networks of Escherichia coli, Salmonella
enterica Typhimurium and Mycobacterium tuberculosis. Fast-SL also rigorously
identifies synthetic lethal gene deletions, uncovering synthetic lethal triplets 
that were not reported previously. We confirm that the triple lethal gene sets
obtained for the three organisms have a precise match with the results obtained
through exhaustive enumeration of lethals performed on a computer cluster. We
also parallelized our algorithm, enabling the identification of synthetic lethal 
gene quadruplets for all three organisms in under 6 h. Overall, Fast-SL enables
an efficient enumeration of higher order synthetic lethals in metabolic networks,
which may help uncover previously unknown genetic interactions and combinatorial 
drug targets.
AVAILABILITY AND IMPLEMENTATION: The MATLAB implementation of the algorithm,
compatible with COBRA toolbox v2.0, is available at
https://github.com/RamanLab/FastSL CONTACT: kraman@iitm.ac.in
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv352 
PMID: 26085504  [PubMed - indexed for MEDLINE]


956. BMC Genomics. 2015 Jun 17;16:464. doi: 10.1186/s12864-015-1643-9.

Whole-genome cartography of p53 response elements ranked on transactivation
potential.

Tebaldi T(1), Zaccara S(2), Alessandrini F(3), Bisio A(4), Ciribilli Y(5), Inga
A(6).

Author information: 
(1)Centre for Integrative Biology (CIBIO), University of Trento, via delle Regole
101, 38123, Mattarello, TN, Italy. t.tebaldi@unitn.it. (2)Centre for Integrative 
Biology (CIBIO), University of Trento, via delle Regole 101, 38123, Mattarello,
TN, Italy. sara.zaccara@unitn.it. (3)Centre for Integrative Biology (CIBIO),
University of Trento, via delle Regole 101, 38123, Mattarello, TN, Italy.
f.alessandrini@unitn.it. (4)Centre for Integrative Biology (CIBIO), University of
Trento, via delle Regole 101, 38123, Mattarello, TN, Italy.
alessandra.bisio@unitn.it. (5)Centre for Integrative Biology (CIBIO), University 
of Trento, via delle Regole 101, 38123, Mattarello, TN, Italy.
yari.ciribilli@unitn.it. (6)Centre for Integrative Biology (CIBIO), University of
Trento, via delle Regole 101, 38123, Mattarello, TN, Italy.
alberto.inga@unitn.it.

BACKGROUND: Many recent studies using ChIP-seq approaches cross-referenced to
trascriptome data and also to potentially unbiased in vitro DNA binding selection
experiments are detailing with increasing precision the p53-directed gene
regulatory network that, nevertheless, is still expanding. However, most
experiments have been conducted in established cell lines subjected to specific
p53-inducing stimuli, both factors potentially biasing the results.
RESULTS: We developed p53retriever, a pattern search algorithm that maps p53
response elements (REs) and ranks them according to predicted transactivation
potentials in five classes. Besides canonical, full site REs, we developed
specific pattern searches for non-canonical half sites and 3/4 sites and show
that they can mediate p53-dependent responsiveness of associated coding
sequences. Using ENCODE data, we also mapped p53 REs in about 44,000 distant
enhancers and identified a 16-fold enrichment for high activity REs within those 
sites in the comparison with genomic regions near transcriptional start sites
(TSS). Predictions from our pattern search were cross-referenced to ChIP-seq,
ChIP-exo, expression, and various literature data sources. Based on the mapping
of predicted functional REs near TSS, we examined expression changes of thirteen 
genes as a function of different p53-inducing conditions, providing further
evidence for PDE2A, GAS6, E2F7, APOBEC3H, KCTD1, TRIM32, DICER, HRAS, KITLG and
TGFA p53-dependent regulation, while MAP2K3, DNAJA1 and potentially YAP1 were
identified as new direct p53 target genes.
CONCLUSIONS: We provide a comprehensive annotation of canonical and non-canonical
p53 REs in the human genome, ranked on predicted transactivation potential. We
also establish or corroborate direct p53 transcriptional control of thirteen
genes. The entire list of identified and functionally classified p53 REs near all
UCSC-annotated genes and within ENCODE mapped enhancer elements is provided. Our 
approach is distinct from, and complementary to, existing methods designed to
identify p53 response elements. p53retriever is available as an R package at:
http://tomateba.github.io/p53retriever .

DOI: 10.1186/s12864-015-1643-9 
PMCID: PMC4470028
PMID: 26081755  [PubMed - indexed for MEDLINE]


957. BMC Med Imaging. 2015 Jun 16;15:19. doi: 10.1186/s12880-015-0062-3.

ROCKETSHIP: a flexible and modular software tool for the planning, processing and
analysis of dynamic MRI studies.

Barnes SR(1), Ng TS(2,)(3), Santa-Maria N(4), Montagne A(5), Zlokovic BV(6),
Jacobs RE(7).

Author information: 
(1)Division of Biology and Biological Engineering, California Institute of
Technology, Pasadena, CA, 91125, USA. srbarnes@caltech.edu. (2)Division of
Biology and Biological Engineering, California Institute of Technology, Pasadena,
CA, 91125, USA. thomas.ng@uci.edu. (3)Department of Medicine, University of
California, Irvine Medical Center, Orange, CA, USA. thomas.ng@uci.edu.
(4)Division of Biology and Biological Engineering, California Institute of
Technology, Pasadena, CA, 91125, USA. naomism@caltech.edu. (5)Zilkha Neurogenetic
Institute and Department of Physiology and Biophysics, Keck School of Medicine,
University of Southern California, Los Angeles, CA, USA. montagne@usc.edu.
(6)Zilkha Neurogenetic Institute and Department of Physiology and Biophysics,
Keck School of Medicine, University of Southern California, Los Angeles, CA, USA.
zlokovic@usc.edu. (7)Division of Biology and Biological Engineering, California
Institute of Technology, Pasadena, CA, 91125, USA. rjacobs@caltech.edu.

BACKGROUND: Dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) is a
promising technique to characterize pathology and evaluate treatment response.
However, analysis of DCE-MRI data is complex and benefits from concurrent
analysis of multiple kinetic models and parameters. Few software tools are
currently available that specifically focuses on DCE-MRI analysis with multiple
kinetic models. Here, we developed ROCKETSHIP, an open-source, flexible and
modular software for DCE-MRI analysis. ROCKETSHIP incorporates analyses with
multiple kinetic models, including data-driven nested model analysis.
RESULTS: ROCKETSHIP was implemented using the MATLAB programming language.
Robustness of the software to provide reliable fits using multiple kinetic models
is demonstrated using simulated data. Simulations also demonstrate the utility of
the data-driven nested model analysis. Applicability of ROCKETSHIP for both
preclinical and clinical studies is shown using DCE-MRI studies of the human
brain and a murine tumor model.
CONCLUSION: A DCE-MRI software suite was implemented and tested using
simulations. Its applicability to both preclinical and clinical datasets is
shown. ROCKETSHIP was designed to be easily accessible for the beginner, but
flexible enough for changes or additions to be made by the advanced user as well.
The availability of a flexible analysis tool will aid future studies using
DCE-MRI. A public release of ROCKETSHIP is available at
https://github.com/petmri/ROCKETSHIP .

DOI: 10.1186/s12880-015-0062-3 
PMCID: PMC4466867
PMID: 26076957  [PubMed - indexed for MEDLINE]


958. Genome Biol. 2015 Jun 16;16:124. doi: 10.1186/s13059-015-0688-z.

Ultra-large alignments using phylogeny-aware profiles.

Nguyen NP(1), Mirarab S(2), Kumar K(3), Warnow T(4,)(5,)(6).

Author information: 
(1)Carl R. Woese Institute for Genomic Biology, University of Illinois at
Urbana-Champaign, 1206 West Gregory Drive, Urbana, 61801, Illinois, USA.
namphuon@illinois.edu. (2)Department of Computer Science, University of Texas at 
Austin, 2505 Speedway, Austin, 78712, Texas, USA. smirarab@cs.utexas.edu.
(3)Department of Computer Science, University of Texas at Austin, 2505 Speedway, 
Austin, 78712, Texas, USA. kk8@cs.utexas.edu. (4)Carl R. Woese Institute for
Genomic Biology, University of Illinois at Urbana-Champaign, 1206 West Gregory
Drive, Urbana, 61801, Illinois, USA. warnow@illinois.edu. (5)Department of
Bioengineering, University of Illinois at Urbana-Champaign, 1270 Digital Computer
Laboratory, Urbana, 61801, Illinois, USA. warnow@illinois.edu. (6)Department of
Computer Science, University of Illinois at Urbana-Champaign, 201 North Goodwin
Avenue, Urbana, 61801, Illinois, USA. warnow@illinois.edu.

Many biological questions, including the estimation of deep evolutionary
histories and the detection of remote homology between protein sequences, rely
upon multiple sequence alignments and phylogenetic trees of large datasets.
However, accurate large-scale multiple sequence alignment is very difficult,
especially when the dataset contains fragmentary sequences. We present UPP, a
multiple sequence alignment method that uses a new machine learning technique,
the ensemble of hidden Markov models, which we propose here. UPP produces highly 
accurate alignments for both nucleotide and amino acid sequences, even on
ultra-large datasets or datasets containing fragmentary sequences. UPP is
available at https://github.com/smirarab/sepp .

DOI: 10.1186/s13059-015-0688-z 
PMCID: PMC4492008
PMID: 26076734  [PubMed - indexed for MEDLINE]


959. Bioinformatics. 2015 Oct 15;31(20):3345-7. doi: 10.1093/bioinformatics/btv361.
Epub 2015 Jun 15.

MetaPathways v2.5: quantitative functional, taxonomic and usability improvements.

Konwar KM(1), Hanson NW(2), Bhatia MP(1), Kim D(3), Wu SJ(3), Hahn AS(1),
Morgan-Lang C(2), Cheung HK(1), Hallam SJ(4).

Author information: 
(1)Department of Microbiology & Immunology, University of British Columbia, 2350 
Health Sciences Mall, Vancouver, BC, Canada. (2)Graduate Program in
Bioinformatics, University of British Columbia, Genome Sciences Centre, 100-570
West 7th Avenue, Vancouver, BC, Canada and. (3)Department of Computer Science,
University of British Columbia, 2366 Main Mall, Vancouver, BC, Canada.
(4)Department of Microbiology & Immunology, University of British Columbia, 2350 
Health Sciences Mall, Vancouver, BC, Canada, Graduate Program in Bioinformatics, 
University of British Columbia, Genome Sciences Centre, 100-570 West 7th Avenue, 
Vancouver, BC, Canada and.

Next-generation sequencing is producing vast amounts of sequence information from
natural and engineered ecosystems. Although this data deluge has an enormous
potential to transform our lives, knowledge creation and translation need
software applications that scale with increasing data processing and analysis
requirements. Here, we present improvements to MetaPathways, an annotation and
analysis pipeline for environmental sequence information that expedites this
transformation. We specifically address pathway prediction hazards through
integration of a weighted taxonomic distance and enable quantitative comparison
of assembled annotations through a normalized read-mapping measure. Additionally,
we improve LAST homology searches through BLAST-equivalent E-values and output
formats that are natively compatible with prevailing software applications.
Finally, an updated graphical user interface allows for keyword annotation query 
and projection onto user-defined functional gene hierarchies, including the
Carbohydrate-Active Enzyme database.AVAILABILITY AND IMPLEMENTATION: MetaPathways
v2.5 is available on GitHub: http://github.com/hallamlab/metapathways2.
CONTACT: shallam@mail.ubc.ca
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv361 
PMCID: PMC4595896
PMID: 26076725  [PubMed - indexed for MEDLINE]


960. Nat Methods. 2015 Aug;12(8):755-8. doi: 10.1038/nmeth.3439. Epub 2015 Jun 15.

Efficient set tests for the genetic analysis of correlated traits.

Casale FP(1), Rakitsch B(1), Lippert C(2), Stegle O(1).

Author information: 
(1)European Molecular Biology Laboratory, European Bioinformatics Institute,
Wellcome Trust Genome Campus, Hinxton, Cambridge, UK. (2)1] Microsoft Research,
Los Angeles, California, USA. [2] Human Longevity, Inc., Mountain View,
California, USA.

Set tests are a powerful approach for genome-wide association testing between
groups of genetic variants and quantitative traits. We describe mtSet
(http://github.com/PMBio/limix), a mixed-model approach that enables joint
analysis across multiple correlated traits while accounting for population
structure and relatedness. mtSet effectively combines the benefits of set tests
with multi-trait modeling and is computationally efficient, enabling genetic
analysis of large cohorts (up to 500,000 individuals) and multiple traits.

DOI: 10.1038/nmeth.3439 
PMID: 26076425  [PubMed - indexed for MEDLINE]


961. Bioinformatics. 2015 Jun 15;31(12):i44-52. doi: 10.1093/bioinformatics/btv234.

ASTRAL-II: coalescent-based species tree estimation with many hundreds of taxa
and thousands of genes.

Mirarab S(1), Warnow T(1).

Author information: 
(1)Department of Computer Science, The University of Texas at Austin, Austin, TX 
78712, USA and Departments of Computer Science and Bioengineering, The University
of Illinois at Urbana-Champaign, Champaign, IL 61801, USA.

MOTIVATION: The estimation of species phylogenies requires multiple loci, since
different loci can have different trees due to incomplete lineage sorting,
modeled by the multi-species coalescent model. We recently developed a
coalescent-based method, ASTRAL, which is statistically consistent under the
multi-species coalescent model and which is more accurate than other
coalescent-based methods on the datasets we examined. ASTRAL runs in polynomial
time, by constraining the search space using a set of allowed 'bipartitions'.
Despite the limitation to allowed bipartitions, ASTRAL is statistically
consistent.
RESULTS: We present a new version of ASTRAL, which we call ASTRAL-II. We show
that ASTRAL-II has substantial advantages over ASTRAL: it is faster, can analyze 
much larger datasets (up to 1000 species and 1000 genes) and has substantially
better accuracy under some conditions. ASTRAL's running time is [Formula: see
text], and ASTRAL-II's running time is [Formula: see text], where n is the number
of species, k is the number of loci and X is the set of allowed bipartitions for 
the search space.
AVAILABILITY AND IMPLEMENTATION: ASTRAL-II is available in open source at
https://github.com/smirarab/ASTRAL and datasets used are available at
http://www.cs.utexas.edu/~phylo/datasets/astral2/.
CONTACT: smirarab@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv234 
PMCID: PMC4765870
PMID: 26072508  [PubMed - indexed for MEDLINE]


962. Bioinformatics. 2015 Jun 15;31(12):i375-84. doi: 10.1093/bioinformatics/btv266.

Using collective expert judgements to evaluate quality measures of mass
spectrometry images.

Palmer A(1), Ovchinnikova E(1), Thuné M(2), Lavigne R(2), Guével B(2), Dyatlov
A(1), Vitek O(2), Pineau C(2), Borén M(2), Alexandrov T(3).

Author information: 
(1)European Molecular Biology Laboratory, Heidelberg, Germany, Center for
Industrial Mathematics, University of Bremen, Bremen, Germany, High Performance
Humanoid Technologies Lab, Institute for Anthropomatics, Karlsruhe Institute of
Technology, Karlsruhe, Germany, Denator, Uppsala, Sweden, Protim, Inserm U1085 - 
Irset, University of Rennes 1, Rennes, France, SCiLS GmbH, Bremen, Germany,
College of Computer and Information Science, Northeastern University, Boston, MA,
USA and Skaggs School of Pharmacy and Pharmaceutical Sciences, University of
California San Diego, La Jolla, CA, USA European Molecular Biology Laboratory,
Heidelberg, Germany, Center for Industrial Mathematics, University of Bremen,
Bremen, Germany, High Performance Humanoid Technologies Lab, Institute for
Anthropomatics, Karlsruhe Institute of Technology, Karlsruhe, Germany, Denator,
Uppsala, Sweden, Protim, Inserm U1085 - Irset, University of Rennes 1, Rennes,
France, SCiLS GmbH, Bremen, Germany, College of Computer and Information Science,
Northeastern University, Boston, MA, USA and Skaggs School of Pharmacy and
Pharmaceutical Sciences, University of California San Diego, La Jolla, CA, USA.
(2)European Molecular Biology Laboratory, Heidelberg, Germany, Center for
Industrial Mathematics, University of Bremen, Bremen, Germany, High Performance
Humanoid Technologies Lab, Institute for Anthropomatics, Karlsruhe Institute of
Technology, Karlsruhe, Germany, Denator, Uppsala, Sweden, Protim, Inserm U1085 - 
Irset, University of Rennes 1, Rennes, France, SCiLS GmbH, Bremen, Germany,
College of Computer and Information Science, Northeastern University, Boston, MA,
USA and Skaggs School of Pharmacy and Pharmaceutical Sciences, University of
California San Diego, La Jolla, CA, USA. (3)European Molecular Biology
Laboratory, Heidelberg, Germany, Center for Industrial Mathematics, University of
Bremen, Bremen, Germany, High Performance Humanoid Technologies Lab, Institute
for Anthropomatics, Karlsruhe Institute of Technology, Karlsruhe, Germany,
Denator, Uppsala, Sweden, Protim, Inserm U1085 - Irset, University of Rennes 1,
Rennes, France, SCiLS GmbH, Bremen, Germany, College of Computer and Information 
Science, Northeastern University, Boston, MA, USA and Skaggs School of Pharmacy
and Pharmaceutical Sciences, University of California San Diego, La Jolla, CA,
USA European Molecular Biology Laboratory, Heidelberg, Germany, Center for
Industrial Mathematics, University of Bremen, Bremen, Germany, High Performance
Humanoid Technologies Lab, Institute for Anthropomatics, Karlsruhe Institute of
Technology, Karlsruhe, Germany, Denator, Uppsala, Sweden, Protim, Inserm U1085 - 
Irset, University of Rennes 1, Rennes, France, SCiLS GmbH, Bremen, Germany,
College of Computer and Information Science, Northeastern University, Boston, MA,
USA and Skaggs School of Pharmacy and Pharmaceutical Sciences, University of
California San Diego, La Jolla, CA, USA European Molecular Biology Laboratory,
Heidelberg, Germany, Center for Industrial Mathematics, University of Bremen,
Bremen, Germany, High Performance Humanoid Technologies Lab, Institute for
Anthropomatics, Karlsruhe Institute of Technology, Karlsruhe, Germany, Denator,
Uppsala, Sweden, Protim, Inserm U1085 - Irset, University of Rennes 1, Rennes,
France, SCiLS GmbH, Bremen, Germany, College of Computer and Information Science,
Northeastern University, Boston, MA, USA and Skaggs School of Pharmacy and
Pharmaceutical Sciences, University of California San Diego, La Jolla, CA, USA
European Molecular Biology Laboratory, Heidelberg, Germany, Center for Industrial
Mathematics, University of Bremen, Bremen, Germany, High Performance Humanoid
Technologies Lab, Institute for Anthropomatics, Karlsruhe Institute of Technolo

MOTIVATION: Imaging mass spectrometry (IMS) is a maturating technique of
molecular imaging. Confidence in the reproducible quality of IMS data is
essential for its integration into routine use. However, the predominant method
for assessing quality is visual examination, a time consuming, unstandardized and
non-scalable approach. So far, the problem of assessing the quality has only been
marginally addressed and existing measures do not account for the spatial
information of IMS data. Importantly, no approach exists for unbiased evaluation 
of potential quality measures.
RESULTS: We propose a novel approach for evaluating potential measures by
creating a gold-standard set using collective expert judgements upon which we
evaluated image-based measures. To produce a gold standard, we engaged 80 IMS
experts, each to rate the relative quality between 52 pairs of ion images from
MALDI-TOF IMS datasets of rat brain coronal sections. Experts' optional feedback 
on their expertise, the task and the survey showed that (i) they had diverse
backgrounds and sufficient expertise, (ii) the task was properly understood, and 
(iii) the survey was comprehensible. A moderate inter-rater agreement was
achieved with Krippendorff's alpha of 0.5. A gold-standard set of 634 pairs of
images with accompanying ratings was constructed and showed a high agreement of
0.85. Eight families of potential measures with a range of parameters and
statistical descriptors, giving 143 in total, were evaluated. Both
signal-to-noise and spatial chaos-based measures performed highly with a
correlation of 0.7 to 0.9 with the gold standard ratings. Moreover, we showed
that a composite measure with the linear coefficients (trained on the gold
standard with regularized least squares optimization and lasso) showed a strong
linear correlation of 0.94 and an accuracy of 0.98 in predicting which image in a
pair was of higher quality.
AVAILABILITY AND IMPLEMENTATION: The anonymized data collected from the survey
and the Matlab source code for data processing can be found at:
https://github.com/alexandrovteam/IMS_quality.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv266 
PMCID: PMC4765867
PMID: 26072506  [PubMed - indexed for MEDLINE]


963. Bioinformatics. 2015 Jun 15;31(12):i357-64. doi: 10.1093/bioinformatics/btv260.

Exploiting ontology graph for predicting sparsely annotated gene function.

Wang S(1), Cho H(1), Zhai C(1), Berger B(2), Peng J(1).

Author information: 
(1)Department of Computer Science, University of Illinois at Urbana-Champaign,
Urbana, IL, Computer Science and Artificial Intelligence Laboratory, MIT,
Cambridge, MA and Department of Mathematics, MIT, Cambridge, MA, USA.
(2)Department of Computer Science, University of Illinois at Urbana-Champaign,
Urbana, IL, Computer Science and Artificial Intelligence Laboratory, MIT,
Cambridge, MA and Department of Mathematics, MIT, Cambridge, MA, USA Department
of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL,
Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, MA and
Department of Mathematics, MIT, Cambridge, MA, USA.

MOTIVATION: Systematically predicting gene (or protein) function based on
molecular interaction networks has become an important tool in refining and
enhancing the existing annotation catalogs, such as the Gene Ontology (GO)
database. However, functional labels with only a few (<10) annotated genes, which
constitute about half of the GO terms in yeast, mouse and human, pose a unique
challenge in that any prediction algorithm that independently considers each
label faces a paucity of information and thus is prone to capture
non-generalizable patterns in the data, resulting in poor predictive performance.
There exist a variety of algorithms for function prediction, but none properly
address this 'overfitting' issue of sparsely annotated functions, or do so in a
manner scalable to tens of thousands of functions in the human catalog.
RESULTS: We propose a novel function prediction algorithm, clusDCA, which
transfers information between similar functional labels to alleviate the
overfitting problem for sparsely annotated functions. Our method is scalable to
datasets with a large number of annotations. In a cross-validation experiment in 
yeast, mouse and human, our method greatly outperformed previous state-of-the-art
function prediction algorithms in predicting sparsely annotated functions,
without sacrificing the performance on labels with sufficient information.
Furthermore, we show that our method can accurately predict genes that will be
assigned a functional label that has no known annotations, based only on the
ontology graph structure and genes associated with other labels, which further
suggests that our method effectively utilizes the similarity between gene
functions.
AVAILABILITY AND IMPLEMENTATION: https://github.com/wangshenguiuc/clusDCA.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv260 
PMCID: PMC4542782
PMID: 26072504  [PubMed - indexed for MEDLINE]


964. Bioinformatics. 2015 Jun 15;31(12):i35-43. doi: 10.1093/bioinformatics/btv231.

Reconstructing 16S rRNA genes in metagenomic data.

Yuan C(1), Lei J(1), Cole J(1), Sun Y(1).

Author information: 
(1)Computer Science and Engineering, Michigan State Univerisity, 428 South Shaw
Rd East Lansing, MI 48824, USA and Center for Microbial Ecology, Michigan State
University, East Lansing, MI 48824, USA.

Metagenomic data, which contains sequenced DNA reads of uncultured microbial
species from environmental samples, provide a unique opportunity to thoroughly
analyze microbial species that have never been identified before. Reconstructing 
16S ribosomal RNA, a phylogenetic marker gene, is usually required to analyze the
composition of the metagenomic data. However, massive volume of dataset, high
sequence similarity between related species, skewed microbial abundance and lack 
of reference genes make 16S rRNA reconstruction difficult. Generic de novo
assembly tools are not optimized for assembling 16S rRNA genes. In this work, we 
introduce a targeted rRNA assembly tool, REAGO (REconstruct 16S ribosomal RNA
Genes from metagenOmic data). It addresses the above challenges by combining
secondary structure-aware homology search, zproperties of rRNA genes and de novo 
assembly. Our experimental results show that our tool can correctly recover more 
rRNA genes than several popular generic metagenomic assembly tools and specially 
designed rRNA construction tools.AVAILABILITY AND IMPLEMENTATION: The source code
of REAGO is freely available at https://github.com/chengyuan/reago.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv231 
PMCID: PMC4765874
PMID: 26072503  [PubMed - indexed for MEDLINE]


965. Bioinformatics. 2015 Jun 15;31(12):i27-34. doi: 10.1093/bioinformatics/btv232.

Cypiripi: exact genotyping of CYP2D6 using high-throughput sequencing data.

Numanagić I(1), Malikić S(1), Pratt VM(2), Skaar TC(2), Flockhart DA(2), Sahinalp
SC(1).

Author information: 
(1)School of Computing Science, Simon Fraser University, Burnaby, BC V5A 1S6,
Canada, Department of Medicine, Division of Clinical Pharmacology, Indiana
University School of Medicine, Indianapolis, IN 46202, USA and School of
Informatics and Computing, Indiana University, Bloomington, IN 47401, USA School 
of Computing Science, Simon Fraser University, Burnaby, BC V5A 1S6, Canada,
Department of Medicine, Division of Clinical Pharmacology, Indiana University
School of Medicine, Indianapolis, IN 46202, USA and School of Informatics and
Computing, Indiana University, Bloomington, IN 47401, USA. (2)School of Computing
Science, Simon Fraser University, Burnaby, BC V5A 1S6, Canada, Department of
Medicine, Division of Clinical Pharmacology, Indiana University School of
Medicine, Indianapolis, IN 46202, USA and School of Informatics and Computing,
Indiana University, Bloomington, IN 47401, USA.

MOTIVATION: CYP2D6 is highly polymorphic gene which encodes the (CYP2D6) enzyme, 
involved in the metabolism of 20-25% of all clinically prescribed drugs and other
xenobiotics in the human body. CYP2D6 genotyping is recommended prior to
treatment decisions involving one or more of the numerous drugs sensitive to
CYP2D6 allelic composition. In this context, high-throughput sequencing (HTS)
technologies provide a promising time-efficient and cost-effective alternative to
currently used genotyping techniques. To achieve accurate interpretation of HTS
data, however, one needs to overcome several obstacles such as high sequence
similarity and genetic recombinations between CYP2D6 and evolutionarily related
pseudogenes CYP2D7 and CYP2D8, high copy number variation among individuals and
short read lengths generated by HTS technologies.
RESULTS: In this work, we present the first algorithm to computationally infer
CYP2D6 genotype at basepair resolution from HTS data. Our algorithm is able to
resolve complex genotypes, including alleles that are the products of
duplication, deletion and fusion events involving CYP2D6 and its evolutionarily
related cousin CYP2D7. Through extensive experiments using simulated and real
datasets, we show that our algorithm accurately solves this important problem
with potential clinical implications.
AVAILABILITY AND IMPLEMENTATION: Cypiripi is available at
http://sfu-compbio.github.io/cypiripi.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv232 
PMCID: PMC4542776
PMID: 26072492  [PubMed - indexed for MEDLINE]


966. Bioinformatics. 2015 Jun 15;31(12):i230-9. doi: 10.1093/bioinformatics/btv258.

Gene network inference by fusing data from diverse distributions.

Žitnik M(1), Zupan B(2).

Author information: 
(1)Faculty of Computer and Information Science, University of Ljubljana,
Ljubljana, Slovenia and Department of Molecular and Human Genetics, Baylor
College of Medicine, Houston, TX, USA. (2)Faculty of Computer and Information
Science, University of Ljubljana, Ljubljana, Slovenia and Department of Molecular
and Human Genetics, Baylor College of Medicine, Houston, TX, USA Faculty of
Computer and Information Science, University of Ljubljana, Ljubljana, Slovenia
and Department of Molecular and Human Genetics, Baylor College of Medicine,
Houston, TX, USA.

MOTIVATION: Markov networks are undirected graphical models that are widely used 
to infer relations between genes from experimental data. Their state-of-the-art
inference procedures assume the data arise from a Gaussian distribution.
High-throughput omics data, such as that from next generation sequencing, often
violates this assumption. Furthermore, when collected data arise from multiple
related but otherwise nonidentical distributions, their underlying networks are
likely to have common features. New principled statistical approaches are needed 
that can deal with different data distributions and jointly consider collections 
of datasets.
RESULTS: We present FuseNet, a Markov network formulation that infers networks
from a collection of nonidentically distributed datasets. Our approach is
computationally efficient and general: given any number of distributions from an 
exponential family, FuseNet represents model parameters through shared latent
factors that define neighborhoods of network nodes. In a simulation study, we
demonstrate good predictive performance of FuseNet in comparison to several
popular graphical models. We show its effectiveness in an application to breast
cancer RNA-sequencing and somatic mutation data, a novel application of graphical
models. Fusion of datasets offers substantial gains relative to inference of
separate networks for each dataset. Our results demonstrate that network
inference methods for non-Gaussian data can help in accurate modeling of the data
generated by emergent high-throughput technologies.
AVAILABILITY AND IMPLEMENTATION: Source code is at
https://github.com/marinkaz/fusenet.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv258 
PMCID: PMC4542780
PMID: 26072487  [PubMed - indexed for MEDLINE]


967. Bioinformatics. 2015 Jun 15;31(12):i181-9. doi: 10.1093/bioinformatics/btv230.

Adapt-Mix: learning local genetic correlation structure improves summary
statistics-based analyses.

Park DS(1), Brown B(1), Eng C(1), Huntsman S(1), Hu D(1), Torgerson DG(1),
Burchard EG(2), Zaitlen N(2).

Author information: 
(1)Department of Bioengineering and Therapeutic Sciences, University of
California San Francisco, San Francisco, Department of Computer Science,
University of California Berkeley, Berkeley and Department of Medicine,
University of California San Francisco, San Francisco, CA, USA. (2)Department of 
Bioengineering and Therapeutic Sciences, University of California San Francisco, 
San Francisco, Department of Computer Science, University of California Berkeley,
Berkeley and Department of Medicine, University of California San Francisco, San 
Francisco, CA, USA Department of Bioengineering and Therapeutic Sciences,
University of California San Francisco, San Francisco, Department of Computer
Science, University of California Berkeley, Berkeley and Department of Medicine, 
University of California San Francisco, San Francisco, CA, USA.

MOTIVATION: Approaches to identifying new risk loci, training risk prediction
models, imputing untyped variants and fine-mapping causal variants from summary
statistics of genome-wide association studies are playing an increasingly
important role in the human genetics community. Current summary statistics-based 
methods rely on global 'best guess' reference panels to model the genetic
correlation structure of the dataset being studied. This approach, especially in 
admixed populations, has the potential to produce misleading results, ignores
variation in local structure and is not feasible when appropriate reference
panels are missing or small. Here, we develop a method, Adapt-Mix, that combines 
information across all available reference panels to produce estimates of local
genetic correlation structure for summary statistics-based methods in arbitrary
populations.
RESULTS: We applied Adapt-Mix to estimate the genetic correlation structure of
both admixed and non-admixed individuals using simulated and real data. We
evaluated our method by measuring the performance of two summary statistics-based
methods: imputation and joint-testing. When using our method as opposed to the
current standard of 'best guess' reference panels, we observed a 28% decrease in 
mean-squared error for imputation and a 73.7% decrease in mean-squared error for 
joint-testing.
AVAILABILITY AND IMPLEMENTATION: Our method is publicly available in a software
package called ADAPT-Mix available at https://github.com/dpark27/adapt_mix.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv230 
PMCID: PMC4553832
PMID: 26072481  [PubMed - indexed for MEDLINE]


968. Bioinformatics. 2015 Jun 15;31(12):i142-50. doi: 10.1093/bioinformatics/btv251.

Deconvolving molecular signatures of interactions between microbial colonies.

Harn YC(1), Powers MJ(1), Shank EA(2), Jojic V(1).

Author information: 
(1)Department of Biology, University of North Carolina, Chapel Hill, NC
27599-3280, USA, Department of Biology, University of North Carolina, Chapel
Hill, NC 27599-32800, USA, Department of Microbiology and Immunology, University 
of North Carolina, Chapel Hill, NC 27599-7290, USA and Curriculum of Genetics and
Molecular Biology, University of North Carolina, Chapel Hill, NC, USA.
(2)Department of Biology, University of North Carolina, Chapel Hill, NC
27599-3280, USA, Department of Biology, University of North Carolina, Chapel
Hill, NC 27599-32800, USA, Department of Microbiology and Immunology, University 
of North Carolina, Chapel Hill, NC 27599-7290, USA and Curriculum of Genetics and
Molecular Biology, University of North Carolina, Chapel Hill, NC, USA Department 
of Biology, University of North Carolina, Chapel Hill, NC 27599-3280, USA,
Department of Biology, University of North Carolina, Chapel Hill, NC 27599-32800,
USA, Department of Microbiology and Immunology, University of North Carolina,
Chapel Hill, NC 27599-7290, USA and Curriculum of Genetics and Molecular Biology,
University of North Carolina, Chapel Hill, NC, USA Department of Biology,
University of North Carolina, Chapel Hill, NC 27599-3280, USA, Department of
Biology, University of North Carolina, Chapel Hill, NC 27599-32800, USA,
Department of Microbiology and Immunology, University of North Carolina, Chapel
Hill, NC 27599-7290, USA and Curriculum of Genetics and Molecular Biology,
University of North Carolina, Chapel Hill, NC, USA.

MOTIVATION: The interactions between microbial colonies through chemical
signaling are not well understood. A microbial colony can use different molecules
to inhibit or accelerate the growth of other colonies. A better understanding of 
the molecules involved in these interactions could lead to advancements in health
and medicine. Imaging mass spectrometry (IMS) applied to co-cultured microbial
communities aims to capture the spatial characteristics of the colonies'
molecular fingerprints. These data are high-dimensional and require computational
analysis methods to interpret.
RESULTS: Here, we present a dictionary learning method that deconvolves spectra
of different molecules from IMS data. We call this method MOLecular Dictionary
Learning ( MOLDL: ). Unlike standard dictionary learning methods which assume
Gaussian-distributed data, our method uses the Poisson distribution to capture
the count nature of the mass spectrometry data. Also, our method incorporates
universally applicable information on common ion types of molecules in MALDI mass
spectrometry. This greatly reduces model parameterization and increases
deconvolution accuracy by eliminating spurious solutions. Moreover, our method
leverages the spatial nature of IMS data by assuming that nearby locations share 
similar abundances, thus avoiding overfitting to noise. Tests on simulated
datasets show that this method has good performance in recovering molecule
dictionaries. We also tested our method on real data measured on a microbial
community composed of two species. We confirmed through follow-up validation
experiments that our method recovered true and complete signatures of molecules. 
These results indicate that our method can discover molecules in IMS data
reliably, and hence can help advance the study of interaction of microbial
colonies.
AVAILABILITY AND IMPLEMENTATION: The code used in this paper is available at:
https://github.com/frizfealer/IMS_project.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv251 
PMCID: PMC4765860
PMID: 26072476  [PubMed - indexed for MEDLINE]


969. Bioinformatics. 2015 Jun 15;31(12):i124-32. doi: 10.1093/bioinformatics/btv241.

Using kernelized partial canonical correlation analysis to study directly coupled
side chains and allostery in small G proteins.

Soltan Ghoraie L(1), Burkowski F(1), Zhu M(1).

Author information: 
(1)Department of Computer Science and Department of Statistics and Actuarial
Science, University of Waterloo, Waterloo, ON, Canada.

MOTIVATION: Inferring structural dependencies among a protein's side chains helps
us understand their coupled motions. It is known that coupled fluctuations can
reveal pathways of communication used for information propagation in a molecule. 
Side-chain conformations are commonly represented by multivariate angular
variables, but existing partial correlation methods that can be applied to this
inference task are not capable of handling multivariate angular data. We propose 
a novel method to infer direct couplings from this type of data, and show that
this method is useful for identifying functional regions and their interactions
in allosteric proteins.
RESULTS: We developed a novel extension of canonical correlation analysis (CCA), 
which we call 'kernelized partial CCA' (or simply KPCCA), and used it to infer
direct couplings between side chains, while disentangling these couplings from
indirect ones. Using the conformational information and fluctuations of the
inactive structure alone for allosteric proteins in the Ras and other Ras-like
families, our method identified allosterically important residues not only as
strongly coupled ones but also in densely connected regions of the interaction
graph formed by the inferred couplings. Our results were in good agreement with
other empirical findings. By studying distinct members of the Ras, Rho and Rab
sub-families, we show further that KPCCA was capable of inferring common
allosteric characteristics in the small G protein super-family.
AVAILABILITY AND IMPLEMENTATION: https://github.com/lsgh/ismb15

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv241 
PMCID: PMC4765857
PMID: 26072474  [PubMed - indexed for MEDLINE]


970. BMC Genomics. 2015 Jun 13;16:455. doi: 10.1186/s12864-015-1676-0.

deGPS is a powerful tool for detecting differential expression in RNA-sequencing 
studies.

Chu C(1,)(2,)(3), Fang Z(4), Hua X(5,)(6), Yang Y(7), Chen E(8), Cowley AW Jr(9),
Liang M(10), Liu P(11,)(12,)(13), Lu Y(14,)(15).

Author information: 
(1)Department of Statistics and Finance, University of Science and Technology of 
China, Hefei, Anhui, 230026, China. chenchu@mcw.edu. (2)Department of Physiology,
Medical College of Wisconsin, Milwaukee, WI, 53226, USA. chenchu@mcw.edu.
(3)Department of Gynecologic Oncology, The Affiliated Women's Hospital, School of
Medicine, Zhejiang University, Hangzhou, Zhejiang, 310029, China.
chenchu@mcw.edu. (4)Department of Statistics and Finance, University of Science
and Technology of China, Hefei, Anhui, 230026, China. zbfang@ustc.edu.cn.
(5)Department of Statistics and Finance, University of Science and Technology of 
China, Hefei, Anhui, 230026, China. xing.hua@nih.gov. (6)Department of
Physiology, Medical College of Wisconsin, Milwaukee, WI, 53226, USA.
xing.hua@nih.gov. (7)Department of Statistics and Finance, University of Science 
and Technology of China, Hefei, Anhui, 230026, China. ynyang@ustc.edu.cn.
(8)Division of Respiratory Medicine, Sir Run Run Shaw Hospital, School of
Medicine, Zhejiang University, Hangzhou, Zhejiang, 310058, China.
georgechen100@gmail.com. (9)Department of Physiology, Medical College of
Wisconsin, Milwaukee, WI, 53226, USA. cowley@mcw.edu. (10)Department of
Physiology, Medical College of Wisconsin, Milwaukee, WI, 53226, USA.
mliang@mcw.edu. (11)Department of Physiology, Medical College of Wisconsin,
Milwaukee, WI, 53226, USA. pliu@mcw.edu. (12)Division of Respiratory Medicine,
Sir Run Run Shaw Hospital, School of Medicine, Zhejiang University, Hangzhou,
Zhejiang, 310058, China. pliu@mcw.edu. (13)Institute for Translational Medicine, 
School of Medicine, Zhejiang University, Hangzhou, Zhejiang, 310029, China.
pliu@mcw.edu. (14)Department of Gynecologic Oncology, The Affiliated Women's
Hospital, School of Medicine, Zhejiang University, Hangzhou, Zhejiang, 310029,
China. yanlu76@zju.edu.cn. (15)Institute for Translational Medicine, School of
Medicine, Zhejiang University, Hangzhou, Zhejiang, 310029, China.
yanlu76@zju.edu.cn.

BACKGROUND: The advent of the NGS technologies has permitted profiling of
whole-genome transcriptomes (i.e., RNA-Seq) at unprecedented speed and very low
cost. RNA-Seq provides a far more precise measurement of transcript levels and
their isoforms compared to other methods such as microarrays. A fundamental goal 
of RNA-Seq is to better identify expression changes between different biological 
or disease conditions. However, existing methods for detecting differential
expression from RNA-Seq count data have not been comprehensively evaluated in
large-scale RNA-Seq datasets. Many of them suffer from inflation of type I error 
and failure in controlling false discovery rate especially in the presence of
abnormal high sequence read counts in RNA-Seq experiments.
RESULTS: To address these challenges, we propose a powerful and robust tool,
termed deGPS, for detecting differential expression in RNA-Seq data. This
framework contains new normalization methods based on generalized Poisson
distribution modeling sequence count data, followed by permutation-based
differential expression tests. We systematically evaluated our new tool in
simulated datasets from several large-scale TCGA RNA-Seq projects, unbiased
benchmark data from compcodeR package, and real RNA-Seq data from the development
transcriptome of Drosophila. deGPS can precisely control type I error and false
discovery rate for the detection of differential expression and is robust in the 
presence of abnormal high sequence read counts in RNA-Seq experiments.
CONCLUSIONS: Software implementing our deGPS was released within an R package
with parallel computations ( https://github.com/LL-LAB-MCW/deGPS ). deGPS is a
powerful and robust tool for data normalization and detecting different
expression in RNA-Seq experiments. Beyond RNA-Seq, deGPS has the potential to
significantly enhance future data analysis efforts from many other
high-throughput platforms such as ChIP-Seq, MBD-Seq and RIP-Seq.

DOI: 10.1186/s12864-015-1676-0 
PMCID: PMC4465298
PMID: 26070955  [PubMed - indexed for MEDLINE]


971. BMC Bioinformatics. 2015 Jun 11;16:193. doi: 10.1186/s12859-015-0632-y.

A composite genome approach to identify phylogenetically informative data from
next-generation sequencing.

Schwartz RS(1), Harkins KM(2,)(3), Stone AC(4), Cartwright RA(5,)(6).

Author information: 
(1)The Biodesign Institute, Arizona State University, Tempe, AZ, USA.
Rachel.Schwartz@asu.edu. (2)School of Human Evolution and Social Change, Arizona 
State University, Tempe, AZ, USA. kmharkin@ucsc.edu. (3)Department of
Anthropology, University of California - Santa Cruz, Santa Cruz, CA, USA.
kmharkin@ucsc.edu. (4)School of Human Evolution and Social Change, Arizona State 
University, Tempe, AZ, USA. acstone@asu.edu. (5)The Biodesign Institute, Arizona 
State University, Tempe, AZ, USA. cartwright@asu.edu. (6)School of Life Sciences,
Arizona State University, Tempe, AZ, USA. cartwright@asu.edu.

BACKGROUND: Improvements in sequencing technology now allow easy acquisition of
large datasets; however, analyzing these data for phylogenetics can be
challenging. We have developed a novel method to rapidly obtain homologous
genomic data for phylogenetics directly from next-generation sequencing reads
without the use of a reference genome. This software, called SISRS, avoids the
time consuming steps of de novo whole genome assembly, multiple genome alignment,
and annotation.
RESULTS: For simulations SISRS is able to identify large numbers of loci
containing variable sites with phylogenetic signal. For genomic data from apes,
SISRS identified thousands of variable sites, from which we produced an accurate 
phylogeny. Finally, we used SISRS to identify phylogenetic markers that we used
to estimate the phylogeny of placental mammals. We recovered eight phylogenies
that resolved the basal relationships among mammals using datasets with different
levels of missing data. The three alternate resolutions of the basal
relationships are consistent with the major hypotheses for the relationships
among mammals, all of which have been supported previously by different molecular
datasets.
CONCLUSIONS: SISRS has the potential to transform phylogenetic research. This
method eliminates the need for expensive marker development in many studies by
using whole genome shotgun sequence data directly. SISRS is open source and
freely available at https://github.com/rachelss/SISRS/releases.

DOI: 10.1186/s12859-015-0632-y 
PMCID: PMC4464851
PMID: 26062548  [PubMed - indexed for MEDLINE]


972. PeerJ. 2015 Jun 2;3:e996. doi: 10.7717/peerj.996. eCollection 2015.

NxRepair: error correction in de novo sequence assembly using Nextera mate pairs.

Murphy RR(1), O'Connell J(2), Cox AJ(2), Schulz-Trieglaff O(2).

Author information: 
(1)Department of Chemistry, University of Cambridge , UK. (2)Illumina Cambridge, 
Chesterford Research Park , Essex , UK.

Scaffolding errors and incorrect repeat disambiguation during de novo assembly
can result in large scale misassemblies in draft genomes. Nextera mate pair
sequencing data provide additional information to resolve assembly ambiguities
during scaffolding. Here, we introduce NxRepair, an open source toolkit for error
correction in de novo assemblies that uses Nextera mate pair libraries to
identify and correct large-scale errors. We show that NxRepair can identify and
correct large scaffolding errors, without use of a reference sequence, resulting 
in quantitative improvements in the assembly quality. NxRepair can be downloaded 
from GitHub or PyPI, the Python Package Index; a tutorial and user documentation 
are also available.

DOI: 10.7717/peerj.996 
PMCID: PMC4458127
PMID: 26056623  [PubMed]


973. Bioinformatics. 2015 Oct 1;31(19):3172-80. doi: 10.1093/bioinformatics/btv349.
Epub 2015 Jun 4.

CCLasso: correlation inference for compositional data through Lasso.

Fang H(1), Huang C(2), Zhao H(3), Deng M(4).

Author information: 
(1)LMAN, School of Mathematical Sciences, Beijing International Center for
Mathematical Research, Center for Quantitative Biology, Academy for Advanced
Interdisciplinary Studies, Peking University, Beijing 100871, China. (2)College
of Global Change and Earth System Science, Beijing Normal University, Beijing
100875, China. (3)Department of Biostatistics, Yale School of Public Health, New 
Haven, CT 06510, USA and. (4)LMAN, School of Mathematical Sciences, Center for
Quantitative Biology, Academy for Advanced Interdisciplinary Studies, Peking
University, Beijing 100871, China, Center for Statistical Science, Peking
University, Beijing 100871, China.

MOTIVATION: Direct analysis of microbial communities in the environment and human
body has become more convenient and reliable owing to the advancements of
high-throughput sequencing techniques for 16S rRNA gene profiling. Inferring the 
correlation relationship among members of microbial communities is of fundamental
importance for genomic survey study. Traditional Pearson correlation analysis
treating the observed data as absolute abundances of the microbes may lead to
spurious results because the data only represent relative abundances. Special
care and appropriate methods are required prior to correlation analysis for these
compositional data.
RESULTS: In this article, we first discuss the correlation definition of latent
variables for compositional data. We then propose a novel method called CCLasso
based on least squares with [Formula: see text] penalty to infer the correlation 
network for latent variables of compositional data from metagenomic data. An
effective alternating direction algorithm from augmented Lagrangian method is
used to solve the optimization problem. The simulation results show that CCLasso 
outperforms existing methods, e.g. SparCC, in edge recovery for compositional
data. It also compares well with SparCC in estimating correlation network of
microbe species from the Human Microbiome Project.
AVAILABILITY AND IMPLEMENTATION: CCLasso is open source and freely available from
https://github.com/huayingfang/CCLasso under GNU LGPL v3.
CONTACT: dengmh@pku.edu.cn
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv349 
PMCID: PMC4693003
PMID: 26048598  [PubMed - indexed for MEDLINE]


974. Front Genet. 2015 May 19;6:172. doi: 10.3389/fgene.2015.00172. eCollection 2015.

FAST: FAST Analysis of Sequences Toolbox.

Lawrence TJ(1), Kauffman KT(2), Amrine KC(3), Carper DL(1), Lee RS(4), Becich
PJ(2), Canales CJ(4), Ardell DH(5).

Author information: 
(1)Quantitative and Systems Biology Program, University of California, Merced
Merced, CA, USA. (2)Molecular Cell Biology Unit, School of Natural Sciences,
University of California, Merced Merced, CA, USA. (3)Quantitative and Systems
Biology Program, University of California, Merced Merced, CA, USA ; Department of
Viticulture and Enology, University of California, Davis Davis, CA, USA.
(4)School of Engineering, University of California, Merced Merced, CA, USA.
(5)Quantitative and Systems Biology Program, University of California, Merced
Merced, CA, USA ; Molecular Cell Biology Unit, School of Natural Sciences,
University of California, Merced Merced, CA, USA.

FAST (FAST Analysis of Sequences Toolbox) provides simple, powerful open source
command-line tools to filter, transform, annotate and analyze biological sequence
data. Modeled after the GNU (GNU's Not Unix) Textutils such as grep, cut, and tr,
FAST tools such as fasgrep, fascut, and fastr make it easy to rapidly prototype
expressive bioinformatic workflows in a compact and generic command vocabulary.
Compact combinatorial encoding of data workflows with FAST commands can simplify 
the documentation and reproducibility of bioinformatic protocols, supporting
better transparency in biological data science. Interface self-consistency and
conformity with conventions of GNU, Matlab, Perl, BioPerl, R, and GenBank help
make FAST easy and rewarding to learn. FAST automates numerical, taxonomic, and
text-based sorting, selection and transformation of sequence records and
alignment sites based on content, index ranges, descriptive tags, annotated
features, and in-line calculated analytics, including composition and codon
usage. Automated content- and feature-based extraction of sites and support for
molecular population genetic statistics make FAST useful for molecular
evolutionary analysis. FAST is portable, easy to install and secure thanks to the
relative maturity of its Perl and BioPerl foundations, with stable releases
posted to CPAN. Development as well as a publicly accessible Cookbook and Wiki
are available on the FAST GitHub repository at
https://github.com/tlawrence3/FAST. The default data exchange format in FAST is
Multi-FastA (specifically, a restriction of BioPerl FastA format). Sanger and
Illumina 1.8+ FastQ formatted files are also supported. FAST makes it easier for 
non-programmer biologists to interactively investigate and control biological
data at the speed of thought.

DOI: 10.3389/fgene.2015.00172 
PMCID: PMC4437040
PMID: 26042145  [PubMed]


975. Bioinformatics. 2015 Oct 1;31(19):3207-9. doi: 10.1093/bioinformatics/btv280.
Epub 2015 Jun 3.

FinisherSC: a repeat-aware tool for upgrading de novo assembly using long reads.

Lam KK(1), LaButti K(2), Khalak A(3), Tse D(4).

Author information: 
(1)Department of Electrical Engineering and Computer Sciences, UC Berkeley.
(2)U.S. Department of Energy Joint Genome Institute, Walnut Creek. (3)Pacific
Biosciences, Menlo Park, and. (4)Department of Electrical Engineering and
Computer Sciences, UC Berkeley, Department of Electrical Engineering, Stanford
University, Palo Alto, CA, USA.

We introduce FinisherSC, a repeat-aware and scalable tool for upgrading de novo
assembly using long reads. Experiments with real data suggest that FinisherSC can
provide longer and higher quality contigs than existing tools while maintaining
high concordance.AVAILABILITY AND IMPLEMENTATION: The tool and data are available
and will be maintained at http://kakitone.github.io/finishingTool/
CONTACT: : dntse@stanford.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv280 
PMID: 26040454  [PubMed - indexed for MEDLINE]


976. J Chem Inf Model. 2015 Jul 27;55(7):1495-507. doi: 10.1021/acs.jcim.5b00082. Epub
2015 Jun 15.

ProPairs: A Data Set for Protein-Protein Docking.

Krull F(1), Korff G(1), Elghobashi-Meinhardt N(1), Knapp EW(1).

Author information: 
(1)Institute of Chemistry and Biochemistry, Freie Universität Berlin,
Fabeckstrasse 36a, 14195 Berlin, Germany.

ProPairs is a data set of crystal structures of protein complexes defined as
biological assemblies in the protein data bank (PDB), which are classified as
legitimate protein-protein docking complexes by also identifying the
corresponding unbound protein structures in the PDB. The underlying program
selecting suitable protein complexes, also called ProPairs, is an automated
method to extract structures of legitimate protein docking complexes and their
unbound partner proteins from the PDB which fulfill specific criteria. In this
way a total of 5,642 protein complexes have been identified with 11,600 different
decompositions in unbound protein pairs yielding legitimate protein docking
partners. After removing sequence redundancy (requiring a sequence identity of
the residues in the interface of less than 40%), 2,070 different legitimate
protein docking complexes remain. For 810 of these protein docking complexes,
both docking partners possess corresponding unbound structures in the PDB. From
the 2,070 nonredundant protein docking complexes there are 417 which possess a
cofactor at the interface. From the 176 protein docking complexes of the
Protein-Protein Docking Benchmark 4.0 (DB4.0) data set, 13 differ from the
ProPairs data set. Twelve of them differ with respect to the composition of the
unbound structures but are contained in the large redundant ProPairs data set.
One protein docking complex of the DB4.0 data set is not contained in ProPairs
since the biological assembly specified in the PDB is wrong (PDB id 1d6r ). For
one protein complex (PDB id 1bgx ) the DB4.0 data set uses a fabricated unbound
structure. For public use interactive online access is provided to the ProPairs
data set of nonredundant protein docking complexes along with the source code of 
the underlying method [ http://propairs.github.io].

DOI: 10.1021/acs.jcim.5b00082 
PMID: 26035493  [PubMed - indexed for MEDLINE]


977. Bioinformatics. 2015 Oct 1;31(19):3092-8. doi: 10.1093/bioinformatics/btv336.
Epub 2015 Jun 1.

Mango: a bias-correcting ChIA-PET analysis pipeline.

Phanstiel DH(1), Boyle AP(2), Heidari N(1), Snyder MP(1).

Author information: 
(1)Department of Genetics, Stanford University School of Medicine, Stanford, CA
94305 and. (2)Department of Computational Medicine & Bioinformatics, University
of Michigan, Ann Arbor, MI 48109, USA.

MOTIVATION: Chromatin Interaction Analysis by Paired-End Tag sequencing
(ChIA-PET) is an established method for detecting genome-wide looping
interactions at high resolution. Current ChIA-PET analysis software packages
either fail to correct for non-specific interactions due to genomic proximity or 
only address a fraction of the steps required for data processing. We present
Mango, a complete ChIA-PET data analysis pipeline that provides statistical
confidence estimates for interactions and corrects for major sources of bias
including differential peak enrichment and genomic proximity.
RESULTS: Comparison to the existing software packages, ChIA-PET Tool and ChiaSig 
revealed that Mango interactions exhibit much better agreement with
high-resolution Hi-C data. Importantly, Mango executes all steps required for
processing ChIA-PET datasets, whereas ChiaSig only completes 20% of the required 
steps. Application of Mango to multiple available ChIA-PET datasets permitted the
independent rediscovery of known trends in chromatin loops including enrichment
of CTCF, RAD21, SMC3 and ZNF143 at the anchor regions of interactions and strong 
bias for convergent CTCF motifs.
AVAILABILITY AND IMPLEMENTATION: Mango is open source and distributed through
github at https://github.com/dphansti/mango.
CONTACT: mpsnyder@standford.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv336 
PMCID: PMC4592333
PMID: 26034063  [PubMed - indexed for MEDLINE]


978. Hum Immunol. 2015 Dec;76(12):917-22. doi: 10.1016/j.humimm.2015.04.007. Epub 2015
May 28.

Development and validation of a sample sparing strategy for HLA typing utilizing 
next generation sequencing.

McKinney DM(1), Fu Z(2), Le L(1), Greenbaum JA(2), Peters B(1), Sette A(3).

Author information: 
(1)Department of Vaccine Development, La Jolla Institute for Allergy and
Immunology, 9820 Athena Circle, La Jolla, CA 92037, USA. (2)Bioinformatics Core
Facility, La Jolla Institute for Allergy and Immunology, 9820 Athena Circle, La
Jolla, CA 92037, USA. (3)Department of Vaccine Development, La Jolla Institute
for Allergy and Immunology, 9820 Athena Circle, La Jolla, CA 92037, USA.
Electronic address: alex@liai.org.

We report the development of a general methodology to genotype HLA class I and
class II loci. A Whole Genome Amplification (WGA) step was used as a sample
sparing methodology. HLA typing data could be obtained with as few as 300 cells, 
underlining the usefulness of the methodology for studies for which limited cells
are available. The next generation sequencing platform was validated using a
panel of cell lines from the International Histocompatibility Working Group
(IHWG) for HLA-A, -B, and -C. Concordance with the known, previously determined
HLA types was 99%. We next developed a panel of primers to allow HLA typing of
alpha and beta chains of the HLA DQ and DP loci and the beta chain of the DRB1
locus. For the beta chain genes, we employed a novel strategy using primers in
the intron regions surrounding exon 2, and the introns surrounding exons 3
through 4 (DRB1) or 5 (DQB1 and DPB1). Concordance with previously determined HLA
Class II types was also 99%. To increase throughput and decrease cost, we
developed strategies combining multiple loci from each donor. Multiplexing of 96 
samples per run resulted in increases in throughput of approximately 8-fold. The 
pipeline developed for this analysis (HLATyphon) is available for download at
https://github.com/LJI-Bioinformatics/HLATyphon.

Copyright © 2015 American Society for Histocompatibility and Immunogenetics.
Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.humimm.2015.04.007 
PMCID: PMC4662932
PMID: 26027778  [PubMed - indexed for MEDLINE]


979. Bioinformatics. 2015 Oct 1;31(19):3222-4. doi: 10.1093/bioinformatics/btv333.
Epub 2015 May 29.

DisVis: quantifying and visualizing accessible interaction space of
distance-restrained biomolecular complexes.

van Zundert GC(1), Bonvin AM(1).

Author information: 
(1)Bijvoet Center for Biomolecular Research, Faculty of Science - Chemistry,
Utrecht University, Utrecht 3584CH, The Netherlands.

We present DisVis, a Python package and command line tool to calculate the
reduced accessible interaction space of distance-restrained binary protein
complexes, allowing for direct visualization and quantification of the
information content of the distance restraints. The approach is general and can
also be used as a knowledge-based distance energy term in FFT-based docking
directly during the sampling stage.AVAILABILITY AND IMPLEMENTATION: The source
code with documentation is freely available from
https://github.com/haddocking/disvis.
CONTACT: a.m.j.j.bonvin@uu.nl
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv333 
PMCID: PMC4576694
PMID: 26026169  [PubMed - indexed for MEDLINE]


980. Bioinformatics. 2015 Oct 1;31(19):3122-9. doi: 10.1093/bioinformatics/btv330.
Epub 2015 May 28.

QVZ: lossy compression of quality values.

Malysa G(1), Hernaez M(1), Ochoa I(1), Rao M(1), Ganesan K(1), Weissman T(1).

Author information: 
(1)Department of Electrical Engineering, Stanford University, Stanford, CA 94305,
USA.

MOTIVATION: Recent advancements in sequencing technology have led to a drastic
reduction in the cost of sequencing a genome. This has generated an unprecedented
amount of genomic data that must be stored, processed and transmitted. To
facilitate this effort, we propose a new lossy compressor for the quality values 
presented in genomic data files (e.g. FASTQ and SAM files), which comprise
roughly half of the storage space (in the uncompressed domain). Lossy compression
allows for compression of data beyond its lossless limit.
RESULTS: The proposed algorithm QVZ exhibits better rate-distortion performance
than the previously proposed algorithms, for several distortion metrics and for
the lossless case. Moreover, it allows the user to define any quasi-convex
distortion function to be minimized, a feature not supported by the previous
algorithms. Finally, we show that QVZ-compressed data exhibit better performance 
in the genotyping than data compressed with previously proposed algorithms, in
the sense that for a similar rate, a genotyping closer to that achieved with the 
original quality values is obtained.
AVAILABILITY AND IMPLEMENTATION: QVZ is written in C and can be downloaded from
https://github.com/mikelhernaez/qvz.
CONTACT: mhernaez@stanford.edu or gmalysa@stanford.edu or iochoa@stanford.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv330 
PMID: 26026138  [PubMed - indexed for MEDLINE]


981. Bioinformatics. 2015 Oct 1;31(19):3216-8. doi: 10.1093/bioinformatics/btv332.
Epub 2015 May 28.

ACE: accurate correction of errors using K-mer tries.

Sheikhizadeh S(1), de Ridder D(1).

Author information: 
(1)Bioinformatics Group, Wageningen University, 6700 AP Wageningen, The
Netherlands.

The quality of high-throughput next-generation sequencing data significantly
influences the performance and memory consumption of assembly and mapping
algorithms. The most ubiquitous platform, Illumina, mainly suffers from
substitution errors. We have developed a tool, ACE, based on K-mer tries to
correct such errors. On real MiSeq and HiSeq Illumina archives, ACE yields higher
gains in terms of coverage depth, outperforming state-of-the-art competitors in
the majority of cases.AVAILABILITY AND IMPLEMENTATION: ACE is licensed under the 
GPL license and can be freely obtained at https://github.com/sheikhizadeh/ACE/.
The program is implemented in C++ and runs on most Unix-derived operating
systems.
CONTACT: siavash.sheikhizadehanari@wur.nl
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv332 
PMID: 26026137  [PubMed - indexed for MEDLINE]


982. PLoS One. 2015 May 28;10(5):e0128026. doi: 10.1371/journal.pone.0128026.
eCollection 2015.

UniqTag: Content-Derived Unique and Stable Identifiers for Gene Annotation.

Jackman SD(1), Bohlmann J(2), Birol İ(3).

Author information: 
(1)Genome Sciences Centre, British Columbia Cancer Agency, Vancouver, BC, Canada;
Graduate Program in Bioinformatics, University of British Columbia, Vancouver,
BC, Canada. (2)Michael Smith Laboratories, University of British Columbia,
Vancouver, BC, Canada. (3)Genome Sciences Centre, British Columbia Cancer Agency,
Vancouver, BC, Canada; Department of Medical Genetics, University of British
Columbia, Vancouver, BC, Canada.

When working on an ongoing genome sequencing and assembly project, it is rather
inconvenient when gene identifiers change from one build of the assembly to the
next. The gene labelling system described here, UniqTag, addresses this common
challenge. UniqTag assigns a unique identifier to each gene that is a
representative k-mer, a string of length k, selected from the sequence of that
gene. Unlike serial numbers, these identifiers are stable between different
assemblies and annotations of the same data without requiring that previous
annotations be lifted over by sequence alignment. We assign UniqTag identifiers
to ten builds of the Ensembl human genome spanning eight years to demonstrate
this stability. The implementation of UniqTag in Ruby and an R package are
available at https://github.com/sjackman/uniqtag sjackman/uniqtag. The R package 
is also available from CRAN: install.packages ("uniqtag"). Supplementary material
and code to reproduce it is available at
https://github.com/sjackman/uniqtag-paper.

DOI: 10.1371/journal.pone.0128026 
PMCID: PMC4447347
PMID: 26020645  [PubMed - indexed for MEDLINE]


983. PeerJ. 2015 May 5;3:e933. doi: 10.7717/peerj.933. eCollection 2015.

GFVO: the Genomic Feature and Variation Ontology.

Baran J(1), Durgahee BS(2), Eilbeck K(2), Antezana E(3), Hoehndorf R(4),
Dumontier M(1).

Author information: 
(1)Stanford Center for Biomedical Informatics Research, School of Medicine,
Stanford University , Stanford, CA , USA. (2)Department of Biomedical
Informatics, School of Medicine, University of Utah , Salt Lake City, UT , USA.
(3)Department of Biology, Norwegian University of Science and Technology ,
Trondheim , Norway. (4)Computer, Electrical and Mathematical Sciences &
Engineering Division and Computational Bioscience Research Center, King Abdullah 
University of Science and Technology , Thuwal , Kingdom of Saudi Arabia.

Falling costs in genomic laboratory experiments have led to a steady increase of 
genomic feature and variation data. Multiple genomic data formats exist for
sharing these data, and whilst they are similar, they are addressing slightly
different data viewpoints and are consequently not fully compatible with each
other. The fragmentation of data format specifications makes it hard to integrate
and interpret data for further analysis with information from multiple data
providers. As a solution, a new ontology is presented here for annotating and
representing genomic feature and variation dataset contents. The Genomic Feature 
and Variation Ontology (GFVO) specifically addresses genomic data as it is
regularly shared using the GFF3 (incl. FASTA), GTF, GVF and VCF file formats.
GFVO simplifies data integration and enables linking of genomic annotations
across datasets through common semantics of genomic types and relations.
Availability and implementation. The latest stable release of the ontology is
available via its base URI; previous and development versions are available at
the ontology's GitHub repository: https://github.com/BioInterchange/Ontologies;
versions of the ontology are indexed through BioPortal (without external
class-/property-equivalences due to BioPortal release 4.10 limitations); examples
and reference documentation is provided on a separate web-page:
http://www.biointerchange.org/ontologies.html. GFVO version 1.0.2 is licensed
under the CC0 1.0 Universal license
(https://creativecommons.org/publicdomain/zero/1.0) and therefore de facto within
the public domain; the ontology can be appropriated without attribution for
commercial and non-commercial use.

DOI: 10.7717/peerj.933 
PMCID: PMC4435477
PMID: 26019997  [PubMed]


984. Genome Med. 2015 May 11;7(1):43. doi: 10.1186/s13073-015-0167-x. eCollection
2015.

JAFFA: High sensitivity transcriptome-focused fusion gene detection.

Davidson NM(1), Majewski IJ(2), Oshlack A(3).

Author information: 
(1)Murdoch Childrens Research Institute, Royal Children's Hospital, Flemington
Road, Parkville, Victoria 3052 Australia. (2)Division of Cancer and Haematology, 
The Walter and Eliza Hall Institute, 1G Royal Parade, Parkville, Victoria 3052
Australia ; Department of Medical Biology, The University of Melbourne,
Parkville, Victoria 3010 Australia. (3)Murdoch Childrens Research Institute,
Royal Children's Hospital, Flemington Road, Parkville, Victoria 3052 Australia ; 
Department of Genetics, The University of Melbourne, Parkville, Victoria 3010
Australia.

Genomic instability is a hallmark of cancer and, as such, structural alterations 
and fusion genes are common events in the cancer landscape. RNA sequencing
(RNA-Seq) is a powerful method for profiling cancers, but current methods for
identifying fusion genes are optimised for short reads. JAFFA
(https://github.com/Oshlack/JAFFA/wiki) is a sensitive fusion detection method
that outperforms other methods with reads of 100 bp or greater. JAFFA compares a 
cancer transcriptome to the reference transcriptome, rather than the genome,
where the cancer transcriptome is inferred using long reads directly or by de
novo assembling short reads.

DOI: 10.1186/s13073-015-0167-x 
PMCID: PMC4445815
PMID: 26019724  [PubMed]


985. BMC Bioinformatics. 2015 May 28;16:175. doi: 10.1186/s12859-015-0613-1.

tcR: an R package for T cell receptor repertoire advanced data analysis.

Nazarov VI(1,)(2), Pogorelyy MV(3), Komech EA(4), Zvyagin IV(5,)(6), Bolotin
DA(7), Shugay M(8), Chudakov DM(9,)(10), Lebedev YB(11), Mamedov IZ(12).

Author information: 
(1)Shemyakin-Ovchinnikov Institute of Bioorganic Chemistry, 16/10
Miklukho-Maklaya, Moscow, 117997, Russia. vdm.nazarov@gmail.com. (2)National
Research University Higher School of Economics, 20 Myasnitskaya Ulitsa, Moscow,
101000, Russia. vdm.nazarov@gmail.com. (3)Shemyakin-Ovchinnikov Institute of
Bioorganic Chemistry, 16/10 Miklukho-Maklaya, Moscow, 117997, Russia.
m.pogorely@gmail.com. (4)Shemyakin-Ovchinnikov Institute of Bioorganic Chemistry,
16/10 Miklukho-Maklaya, Moscow, 117997, Russia. ekomech@gmail.com.
(5)Shemyakin-Ovchinnikov Institute of Bioorganic Chemistry, 16/10
Miklukho-Maklaya, Moscow, 117997, Russia. izvyagin@gmail.com. (6)Central European
Institute of Technology, Masaryk University, Brno, Czech Republic.
izvyagin@gmail.com. (7)Shemyakin-Ovchinnikov Institute of Bioorganic Chemistry,
16/10 Miklukho-Maklaya, Moscow, 117997, Russia. bolotin.dmitriy@gmail.com.
(8)Shemyakin-Ovchinnikov Institute of Bioorganic Chemistry, 16/10
Miklukho-Maklaya, Moscow, 117997, Russia. mikhail.shugay@gmail.com.
(9)Shemyakin-Ovchinnikov Institute of Bioorganic Chemistry, 16/10
Miklukho-Maklaya, Moscow, 117997, Russia. chudakovdm@mail.ru. (10)Central
European Institute of Technology, Masaryk University, Brno, Czech Republic.
chudakovdm@mail.ru. (11)Shemyakin-Ovchinnikov Institute of Bioorganic Chemistry, 
16/10 Miklukho-Maklaya, Moscow, 117997, Russia. lebedev_yb@ibch.ru.
(12)Shemyakin-Ovchinnikov Institute of Bioorganic Chemistry, 16/10
Miklukho-Maklaya, Moscow, 117997, Russia. imamedov78@gmail.com.

BACKGROUND: The Immunoglobulins (IG) and the T cell receptors (TR) play the key
role in antigen recognition during the adaptive immune response. Recent progress 
in next-generation sequencing technologies has provided an opportunity for the
deep T cell receptor repertoire profiling. However, a specialised software is
required for the rational analysis of massive data generated by next-generation
sequencing.
RESULTS: Here we introduce tcR, a new R package, representing a platform for the 
advanced analysis of T cell receptor repertoires, which includes diversity
measures, shared T cell receptor sequences identification, gene usage statistics 
computation and other widely used methods. The tool has proven its utility in
recent research studies.
CONCLUSIONS: tcR is an R package for the advanced analysis of T cell receptor
repertoires after primary TR sequences extraction from raw sequencing reads. The 
stable version can be directly installed from The Comprehensive R Archive Network
( http://cran.r-project.org/mirrors.html ). The source code and development
version are available at tcR GitHub ( http://imminfo.github.io/tcr/ ) along with 
the full documentation and typical usage examples.

DOI: 10.1186/s12859-015-0613-1 
PMCID: PMC4445501
PMID: 26017500  [PubMed - indexed for MEDLINE]


986. Methods. 2015 Sep 1;85:44-53. doi: 10.1016/j.ymeth.2015.05.016. Epub 2015 May 23.

Computer vision for image-based transcriptomics.

Stoeger T(1), Battich N(1), Herrmann MD(1), Yakimovich Y(2), Pelkmans L(3).

Author information: 
(1)Faculty of Sciences, Institute of Molecular Life Sciences, University of
Zurich, Winterthurerstrasse 190, CH-8057 Zurich, Switzerland; Life Science Zurich
Graduate School, Ph.D. program in Systems Biology, Switzerland. (2)Faculty of
Sciences, Institute of Molecular Life Sciences, University of Zurich,
Winterthurerstrasse 190, CH-8057 Zurich, Switzerland. (3)Faculty of Sciences,
Institute of Molecular Life Sciences, University of Zurich, Winterthurerstrasse
190, CH-8057 Zurich, Switzerland. Electronic address: lucas.pelkmans@imls.uzh.ch.

Single-cell transcriptomics has recently emerged as one of the most promising
tools for understanding the diversity of the transcriptome among single cells.
Image-based transcriptomics is unique compared to other methods as it does not
require conversion of RNA to cDNA prior to signal amplification and transcript
quantification. Thus, its efficiency in transcript detection is unmatched by
other methods. In addition, image-based transcriptomics allows the study of the
spatial organization of the transcriptome in single cells at single-molecule,
and, when combined with superresolution microscopy, nanometer resolution.
However, in order to unlock the full power of image-based transcriptomics, robust
computer vision of single molecules and cells is required. Here, we shortly
discuss the setup of the experimental pipeline for image-based transcriptomics,
and then describe in detail the algorithms that we developed to extract, at
high-throughput, robust multivariate feature sets of transcript molecule
abundance, localization and patterning in tens of thousands of single cells
across the transcriptome. These computer vision algorithms and pipelines can be
downloaded from: https://github.com/pelkmanslab/ImageBasedTranscriptomics.

Copyright © 2015. Published by Elsevier Inc.

DOI: 10.1016/j.ymeth.2015.05.016 
PMID: 26014038  [PubMed - indexed for MEDLINE]


987. Nucleic Acids Res. 2015 Sep 30;43(17):e109. doi: 10.1093/nar/gkv537. Epub 2015
May 24.

Tailor: a computational framework for detecting non-templated tailing of small
silencing RNAs.

Chou MT(1), Han BW(2), Hsiao CP(1), Zamore PD(2), Weng Z(3), Hung JH(4).

Author information: 
(1)Institute of Bioinformatics and Systems Biology and Department of Biological
Science and Technology, National Chiao Tung University, HsinChu, Taiwan, 300,
Republic of China. (2)RNA Therapeutics Institute, Howard Hughes Medical
Institute, and Department of Biochemistry and Molecular Pharmacology, University 
of Massachusetts Medical School, Worcester, MA 01605, USA. (3)Program in
Bioinformatics and Integrative Biology, University of Massachusetts Medical
School, Worcester, MA 01605, USA. (4)Institute of Bioinformatics and Systems
Biology and Department of Biological Science and Technology, National Chiao Tung 
University, HsinChu, Taiwan, 300, Republic of China juihunghung@gmail.com
jhhung@nctu.edu.tw.

Small silencing RNAs, including microRNAs, endogenous small interfering RNAs
(endo-siRNAs) and Piwi-interacting RNAs (piRNAs), have been shown to play
important roles in fine-tuning gene expression, defending virus and controlling
transposons. Loss of small silencing RNAs or components in their pathways often
leads to severe developmental defects, including lethality and sterility.
Recently, non-templated addition of nucleotides to the 3' end, namely tailing,
was found to associate with the processing and stability of small silencing RNAs.
Next Generation Sequencing has made it possible to detect such modifications at
nucleotide resolution in an unprecedented throughput. Unfortunately, detecting
such events from millions of short reads confounded by sequencing errors and RNA 
editing is still a tricky problem. Here, we developed a computational framework, 
Tailor, driven by an efficient and accurate aligner specifically designed for
capturing the tailing events directly from the alignments without extensive
post-processing. The performance of Tailor was fully tested and compared
favorably with other general-purpose aligners using both simulated and real
datasets for tailing analysis. Moreover, to show the broad utility of Tailor, we 
used Tailor to reanalyze published datasets and revealed novel findings worth
further experimental validation. The source code and the executable binaries are 
freely available at https://github.com/jhhung/Tailor.

© The Author(s) 2015. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkv537 
PMCID: PMC4632877
PMID: 26007652  [PubMed - indexed for MEDLINE]


988. Bioinformatics. 2015 Oct 1;31(19):3213-5. doi: 10.1093/bioinformatics/btv326.
Epub 2015 May 25.

IgSimulator: a versatile immunosequencing simulator.

Safonova Y(1), Lapidus A(1), Lill J(2).

Author information: 
(1)Center of Algorithmic biotechnology, Institute of Translational Biomedicine,
St. Petersburg State University, Russia, Algorithmic Biology Laboratory, St.
Petersburg Academic University, St. Petersburg, Russia and. (2)Department of
Protein Chemistry, Genentech, 1 DNA Way, South San Francisco, CA 94080, USA.

MOTIVATION: The recent introduction of next-generation sequencing technologies to
antibody studies have resulted in a growing number of immunoinformatics tools for
antibody repertoire analysis. However, benchmarking these newly emerging tools
remains problematic since the gold standard datasets that are needed to validate 
these tools are typically not available.
RESULTS: Since simulating antibody repertoires is often the only feasible way to 
benchmark new immunoinformatics tools, we developed the IgSimulator tool that
addresses various complications in generating realistic antibody repertoires.
IgSimulator's code has modular structure and can be easily adapted to new
requirements to simulation.
AVAILABILITY AND IMPLEMENTATION: IgSimulator is open source and freely available 
as a C++ and Python program running on all Unix-compatible platforms. The source 
code is available from yana-safonova.github.io/ig_simulator.
CONTACT: safonova.yana@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv326 
PMID: 26007226  [PubMed - indexed for MEDLINE]


989. Neuroinformatics. 2015 Oct;13(4):471-86. doi: 10.1007/s12021-015-9271-8.

Wyrm: A Brain-Computer Interface Toolbox in Python.

Venthur B(1), Dähne S(2,)(3,)(4), Höhne J(2), Heller H(2), Blankertz B(2).

Author information: 
(1)Department of Neurotechnology, Technische Universität Berlin, Sekr. MAR 4-3
Marchstraße 23, 10587, Berlin, Germany. bastian.venthur@tu-berlin.de.
(2)Department of Neurotechnology, Technische Universität Berlin, Sekr. MAR 4-3
Marchstraße 23, 10587, Berlin, Germany. (3)Department of Machine Learning,
Technische Universität, Berlin, Germany. (4)Bernstein Center for Computational
Neuroscience, Berlin, Germany.

In the last years Python has gained more and more traction in the scientific
community. Projects like NumPy, SciPy, and Matplotlib have created a strong
foundation for scientific computing in Python and machine learning packages like 
scikit-learn or packages for data analysis like Pandas are building on top of it.
In this paper we present Wyrm ( https://github.com/bbci/wyrm ), an open source
BCI toolbox in Python. Wyrm is applicable to a broad range of neuroscientific
problems. It can be used as a toolbox for analysis and visualization of
neurophysiological data and in real-time settings, like an online BCI
application. In order to prevent software defects, Wyrm makes extensive use of
unit testing. We will explain the key aspects of Wyrm's software architecture and
design decisions for its data structure, and demonstrate and validate the use of 
our toolbox by presenting our approach to the classification tasks of two
different data sets from the BCI Competition III. Furthermore, we will give a
brief analysis of the data sets using our toolbox, and demonstrate how we
implemented an online experiment using Wyrm. With Wyrm we add the final piece to 
our ongoing effort to provide a complete, free and open source BCI system in
Python.

DOI: 10.1007/s12021-015-9271-8 
PMCID: PMC4626531
PMID: 26001643  [PubMed - indexed for MEDLINE]


990. Bioinformatics. 2015 Sep 15;31(18):3057-9. doi: 10.1093/bioinformatics/btv321.
Epub 2015 May 20.

ABC: a tool to identify SNVs causing allele-specific transcription factor binding
from ChIP-Seq experiments.

Bailey SD(1), Virtanen C(2), Haibe-Kains B(1), Lupien M(3).

Author information: 
(1)Princess Margaret Cancer Centre, University Health Network, Toronto, ON,
Canada, Department of Medical Biophysics, University of Toronto, Toronto, ON,
Canada and Ontario Institute for Cancer Research, Toronto, ON, Canada Princess
Margaret Cancer Centre, University Health Network, Toronto, ON, Canada,
Department of Medical Biophysics, University of Toronto, Toronto, ON, Canada and 
Ontario Institute for Cancer Research, Toronto, ON, Canada. (2)Princess Margaret 
Cancer Centre, University Health Network, Toronto, ON, Canada, Department of
Medical Biophysics, University of Toronto, Toronto, ON, Canada and Ontario
Institute for Cancer Research, Toronto, ON, Canada. (3)Princess Margaret Cancer
Centre, University Health Network, Toronto, ON, Canada, Department of Medical
Biophysics, University of Toronto, Toronto, ON, Canada and Ontario Institute for 
Cancer Research, Toronto, ON, Canada Princess Margaret Cancer Centre, University 
Health Network, Toronto, ON, Canada, Department of Medical Biophysics, University
of Toronto, Toronto, ON, Canada and Ontario Institute for Cancer Research,
Toronto, ON, Canada Princess Margaret Cancer Centre, University Health Network,
Toronto, ON, Canada, Department of Medical Biophysics, University of Toronto,
Toronto, ON, Canada and Ontario Institute for Cancer Research, Toronto, ON,
Canada.

MOTIVATION: Detection of allelic imbalances in ChIP-Seq reads is a powerful
approach to identify functional non-coding single nucleotide variants (SNVs),
either polymorphisms or mutations, which modulate the affinity of transcription
factors for chromatin. We present ABC, a computational tool that identifies
allele-specific binding of transcription factors from aligned ChIP-Seq reads at
heterozygous SNVs. ABC controls for potential false positives resulting from
biases introduced by the use of short sequencing reads in ChIP-Seq and can
efficiently process a large number of heterozygous SNVs.
RESULTS: ABC successfully identifies previously characterized functional SNVs,
such as the rs4784227 breast cancer risk associated SNP that modulates the
affinity of FOXA1 for the chromatin.
AVAILABILITY AND IMPLEMENTATION: The code is open-source under an Artistic-2.0
license and versioned on GitHub (https://github.com/mlupien/ABC/). ABC is written
in PERL and can be run on any platform with both PERL (≥5.18.1) and R (≥3.1.1)
installed. The script requires the PERL Statistics::R module.
CONTACT: mlupien@uhnres.utoronto.ca
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv321 
PMCID: PMC4668780
PMID: 25995231  [PubMed - indexed for MEDLINE]


991. Bioinformatics. 2015 Sep 15;31(18):3046-7. doi: 10.1093/bioinformatics/btv322.
Epub 2015 May 20.

agplus: a rapid and flexible tool for aggregation plots.

Maehara K(1), Ohkawa Y(1).

Author information: 
(1)Department of Advanced Medical Initiatives, JST-CREST, Faculty of Medicine,
Kyushu University, Fukuoka 812-8582, Japan.

Aggregation plots are frequently used to evaluate signal distributions at
user-interested points in ChIP-Seq data analysis. agplus, a new and simple
command-line tool, enables rapid and flexible generation of text tables tailored 
for aggregation plots from which users can easily design multiple groups based on
user-definitions such as regulatory regions or transcription initiation
sites.AVAILABILITY AND IMPLEMENTATION: This software is implemented in Ruby,
supported on Linux and Mac OSX, and freely available at
http://github.com/kazumits/agplus
CONTACT: yohkawa@epigenetics.med.kyushu-u.ac.jp.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv322 
PMID: 25995229  [PubMed - indexed for MEDLINE]


992. PLoS One. 2015 May 18;10(5):e0127659. doi: 10.1371/journal.pone.0127659.
eCollection 2015.

QuantiFly: Robust Trainable Software for Automated Drosophila Egg Counting.

Waithe D(1), Rennert P(2), Brostow G(2), Piper MD(3).

Author information: 
(1)Department of Computer Science, University College London, Gower St, London,
WC1E 6BT, United Kingdom; Wolfson Imaging Centre, Weatherall Institute of
Molecular Medicine, University of Oxford, John Radcliffe Hospital, Oxford, OX3
9DS, United Kingdom. (2)Department of Computer Science, University College
London, Gower St, London, WC1E 6BT, United Kingdom. (3)Institute of Healthy
Ageing and Department of Genetics, Evolution and Environment, University College 
London, Gower St, London, WC1E 6BT, United Kingdom.

We report the development and testing of software called QuantiFly: an automated 
tool to quantify Drosophila egg laying. Many laboratories count Drosophila eggs
as a marker of fitness. The existing method requires laboratory researchers to
count eggs manually while looking down a microscope. This technique is both
time-consuming and tedious, especially when experiments require daily counts of
hundreds of vials. The basis of the QuantiFly software is an algorithm which
applies and improves upon an existing advanced pattern recognition and
machine-learning routine. The accuracy of the baseline algorithm is additionally 
increased in this study through correction of bias observed in the algorithm
output. The QuantiFly software, which includes the refined algorithm, has been
designed to be immediately accessible to scientists through an intuitive and
responsive user-friendly graphical interface. The software is also open-source,
self-contained, has no dependencies and is easily installed
(https://github.com/dwaithe/quantifly). Compared to manual egg counts made from
digital images, QuantiFly achieved average accuracies of 94% and 85% for eggs
laid on transparent (defined) and opaque (yeast-based) fly media. Thus, the
software is capable of detecting experimental differences in most experimental
situations. Significantly, the advanced feature recognition capabilities of the
software proved to be robust to food surface artefacts like bubbles and crevices.
The user experience involves image acquisition, algorithm training by labelling a
subset of eggs in images of some of the vials, followed by a batch analysis mode 
in which new images are automatically assessed for egg numbers. Initial training 
typically requires approximately 10 minutes, while subsequent image evaluation by
the software is performed in just a few seconds. Given the average time per vial 
for manual counting is approximately 40 seconds, our software introduces a
timesaving advantage for experiments starting with as few as 20 vials. We also
describe an optional acrylic box to be used as a digital camera mount and to
provide controlled lighting during image acquisition which will guarantee the
conditions used in this study.

DOI: 10.1371/journal.pone.0127659 
PMCID: PMC4436334
PMID: 25992957  [PubMed - indexed for MEDLINE]


993. Nat Methods. 2015 Jul;12(7):623-30. doi: 10.1038/nmeth.3407. Epub 2015 May 18.

Combining tumor genome simulation with crowdsourcing to benchmark somatic
single-nucleotide-variant detection.

Ewing AD(1), Houlahan KE(2), Hu Y(3), Ellrott K(4), Caloian C(2), Yamaguchi
TN(2), Bare JC(3), P'ng C(2), Waggott D(2), Sabelnykova VY(2); ICGC-TCGA DREAM
Somatic Mutation Calling Challenge participants, Kellen MR(3), Norman TC(3),
Haussler D(4), Friend SH(3), Stolovitzky G(5), Margolin AA(6), Stuart JM(4),
Boutros PC(7).

Collaborators: Xi L, Dewal N, Fan Y, Wang W, Wheeler D, Wilm A, Ting GH, Li C,
Bertrand D, Nagarajan N, Chen QR, Hsu CH, Hu Y, Yan C, Kibbe W, Meerzaman D,
Cibulskis K, Rosenberg M, Bergelson L, Kiezun A, Radenbaugh A, Sertier AS,
Ferrari A, Tonton L, Bhutani K, Hansen NF, Wang D, Song L, Lai Z, Liao Y, Shi W, 
Carbonell-Caballero J, Dopazo J, Lau CC, Guinney J.

Author information: 
(1)1] Department of Biomolecular Engineering, University of California, Santa
Cruz, Santa Cruz, California, USA. [2] Mater Research Institute, University of
Queensland, Woolloongabba, Queensland, Australia. (2)Informatics and Biocomputing
Program, Ontario Institute for Cancer Research, Toronto, Ontario, Canada. (3)Sage
Bionetworks, Seattle, Washington, USA. (4)Department of Biomolecular Engineering,
University of California, Santa Cruz, Santa Cruz, California, USA. (5)IBM
Computational Biology Center, T.J. Watson Research Center, Yorktown Heights, New 
York, USA. (6)1] Sage Bionetworks, Seattle, Washington, USA. [2] Computational
Biology Program, Oregon Health &Science University, Portland, Oregon, USA. [3]
Department of Biomedical Engineering, Oregon Health &Science University,
Portland, Oregon, USA. (7)1] Informatics and Biocomputing Program, Ontario
Institute for Cancer Research, Toronto, Ontario, Canada. [2] Department of
Medical Biophysics, University of Toronto, Toronto, Ontario, Canada. [3]
Department of Pharmacology &Toxicology, University of Toronto, Toronto, Ontario, 
Canada.

The detection of somatic mutations from cancer genome sequences is key to
understanding the genetic basis of disease progression, patient survival and
response to therapy. Benchmarking is needed for tool assessment and improvement
but is complicated by a lack of gold standards, by extensive resource
requirements and by difficulties in sharing personal genomic information. To
resolve these issues, we launched the ICGC-TCGA DREAM Somatic Mutation Calling
Challenge, a crowdsourced benchmark of somatic mutation detection algorithms.
Here we report the BAMSurgeon tool for simulating cancer genomes and the results 
of 248 analyses of three in silico tumors created with it. Different algorithms
exhibit characteristic error profiles, and, intriguingly, false positives show a 
trinucleotide profile very similar to one found in human tumors. Although the
three simulated tumors differ in sequence contamination (deviation from normal
cell sequence) and in subclonality, an ensemble of pipelines outperforms the best
individual pipeline in all cases. BAMSurgeon is available at
https://github.com/adamewing/bamsurgeon/.

DOI: 10.1038/nmeth.3407 
PMCID: PMC4856034
PMID: 25984700  [PubMed - indexed for MEDLINE]


994. BMC Bioinformatics. 2015 May 19;16:165. doi: 10.1186/s12859-015-0585-1.

PathRings: a web-based tool for exploration of ortholog and expression data in
biological pathways.

Zhu Y(1,)(2), Sun L(3), Garbarino A(4), Schmidt C(5), Fang J(6), Chen J(7).

Author information: 
(1)Department of Computer Science and Electrical Engineering, University of
Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD, USA.
yongnan@umbc.edu. (2)Department of Computer Science, Hangzhou Dianzi University, 
Hangzhou, Zhejiang Province, P.R. China. yongnan@umbc.edu. (3)Department of
Animal & Food Sciences, University of Delaware, Newark, DE, USA.
sunliang@udel.edu. (4)Department of Computer Science and Electrical Engineering, 
University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD,
USA. garba1@umbc.edu. (5)Department of Animal & Food Sciences, University of
Delaware, Newark, DE, USA. schmidtc@udel.edu. (6)Department of Computer Science, 
Hangzhou Dianzi University, Hangzhou, Zhejiang Province, P.R. China.
fjl@hdu.edu.cn. (7)Department of Computer Science and Electrical Engineering,
University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore, MD,
USA. jichen@umbc.edu.

BACKGROUND: High-throughput methods are generating biological data on a vast
scale. In many instances, genomic, transcriptomic, and proteomic data must be
interpreted in the context of signaling and metabolic pathways to yield testable 
hypotheses. Since humans can interpret visual information rapidly, a means for
interactive visual exploration that lets biologists interpret such data in a
comprehensive and exploratory manner would be invaluable. However, humans have
limited memory capacity. Current visualization tools have limited viewing and
manipulation capabilities to address complex data analysis problems, and visual
exploratory tools are needed to reduce the high mental workload imposed on
biologists.
RESULTS: We present PathRings, a new interactive web-based, scalable biological
pathway visualization tool for biologists to explore and interpret biological
pathways. PathRings integrates metabolic and signaling pathways from Reactome in 
a single compound graph visualization, and uses color to highlight genes and
pathways affected by input data. Pathways are available for multiple species and 
analysis of user-defined species or input is also possible. PathRings permits an 
overview of the impact of gene expression data on all pathways to facilitate
visual pattern finding. Detailed pathways information can be opened in new
visualizations while maintaining the overview, that form a visual exploration
provenance. A dynamic multi-view bubbles interface is designed to support
biologists' analytical tasks by letting users construct incremental views that
further reflect biologists' analytical process. This approach decomposes complex 
tasks into simpler ones and automates multi-view management.
CONCLUSIONS: PathRings has been designed to accommodate interactive visual
analysis of experimental data in the context of pathways defined by Reactome. Our
new approach to interface design can effectively support comparative tasks over
substantially larger collection than existing tools. The dynamic interaction
among multi-view dataset visualization improves the data exploration. PathRings
is available free at http://raven.anr.udel.edu/~sunliang/PathRings and the source
code is hosted on Github: https://github.com/ivcl/PathRings .

DOI: 10.1186/s12859-015-0585-1 
PMCID: PMC4436019
PMID: 25982732  [PubMed - indexed for MEDLINE]


995. Anal Chem. 2015 Jun 16;87(12):6319-27. doi: 10.1021/acs.analchem.5b01166. Epub
2015 Jun 3.

SuperQuant: A Data Processing Approach to Increase Quantitative Proteome
Coverage.

Gorshkov V(1), Verano-Braga T(1), Kjeldsen F(1).

Author information: 
(1)Department of Biochemistry and Molecular Biology, University of Southern
Denmark, Campusvej 55, 5230 Odense M, Denmark.

SuperQuant is a quantitative proteomics data processing approach that uses
complementary fragment ions to identify multiple coisolated peptides in tandem
mass spectra allowing for their quantification. This approach can be applied to
any shotgun proteomics data set acquired with high mass accuracy for
quantification at the MS(1) level. The SuperQuant approach was developed and
implemented as a processing node within the Thermo Proteome Discoverer 2.x. The
performance of the developed approach was tested using dimethyl-labeled HeLa
lysate samples having a ratio between channels of 10(heavy):4(medium):1(light).
Peptides were fragmented with collision-induced dissociation using isolation
windows of 1, 2, and 4 Th while recording data both with high-resolution and
low-resolution. The results obtained using SuperQuant were compared to those
using the conventional ion trap-based approach (low mass accuracy MS(2) spectra),
which is known to achieve high identification performance. Compared to the common
high-resolution approach, the SuperQuant approach identifies up to 70% more
peptide-spectrum matches (PSMs), 40% more peptides, and 20% more proteins at the 
0.01 FDR level. It identifies more PSMs and peptides than the ion trap-based
approach. Improvements in identifications resulted in up to 10% more PSMs, 15%
more peptides, and 10% more proteins quantified on the same raw data. The
developed approach does not affect the accuracy of the quantification and
observed coefficients of variation between replicates of the same proteins were
close to the values typical for other precursor ion-based quantification methods.
The raw data is deposited to ProteomeXchange (PXD001907). The developed node is
available for testing at https://github.com/caetera/SuperQuantNode.

DOI: 10.1021/acs.analchem.5b01166 
PMID: 25978296  [PubMed - indexed for MEDLINE]


996. Bioinformatics. 2015 Sep 15;31(18):3063-5. doi: 10.1093/bioinformatics/btv299.
Epub 2015 May 13.

Fast parametric time warping of peak lists.

Wehrens R(1), Bloemberg TG(2), Eilers PH(1).

Author information: 
(1)Biometris, Wageningen UR, Wageningen, The Netherlands, Educational Institute
for Molecular Sciences and Institute for Molecules and Materials, Radboud
University, Nijmegen, The Netherlands. (2)Biometris, Wageningen UR, Wageningen,
The Netherlands, Educational Institute for Molecular Sciences and Institute for
Molecules and Materials, Radboud University, Nijmegen, The Netherlands Biometris,
Wageningen UR, Wageningen, The Netherlands, Educational Institute for Molecular
Sciences and Institute for Molecules and Materials, Radboud University, Nijmegen,
The Netherlands.

Alignment of peaks across samples is a difficult but unavoidable step in the data
analysis for all analytical techniques containing a separation step like
chromatography. Important application examples are the fields of metabolomics and
proteomics. Parametric time warping (PTW) has already shown to be very useful in 
these fields because of the highly restricted form of the warping functions,
avoiding overfitting. Here, we describe a new formulation of PTW, working on
peak-picked features rather than on complete profiles. Not only does this allow
for a much more smooth integration in existing pipelines, it also speeds up the
(already among the fastest) algorithm by orders of magnitude. Using two publicly 
available datasets we show the potential of the new approach. The first set is a 
LC-DAD dataset of grape samples, and the second an LC-MS dataset of apple
extracts.AVAILABILITY AND IMPLEMENTATION: Parametric time warping of peak lists
is implemented in the ptw package, version 1.9.1 and onwards, available from
Github (https://github.com/rwehrens/ptw) and CRAN (http://cran.r-project.org).
The package also contains a vignette, providing more theoretical details and
scripts to reproduce the results below.
CONTACT: ron.wehrens@wur.nl.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv299 
PMID: 25971741  [PubMed - indexed for MEDLINE]


997. PLoS One. 2015 May 13;10(5):e0127285. doi: 10.1371/journal.pone.0127285.
eCollection 2015.

PAPST, a User Friendly and Powerful Java Platform for ChIP-Seq Peak
Co-Localization Analysis and Beyond.

Bible PW(1), Kanno Y(2), Wei L(3), Brooks SR(4), O'Shea JJ(2), Morasso MI(1),
Loganantharaj R(5), Sun HW(4).

Author information: 
(1)Laboratory of Skin Biology, Intramural Research Program, National Institute of
Arthritis and Musculoskeletal and Skin Diseases, Bethesda, Maryland, United
States of America. (2)Molecular Immunology and Inflammation Branch, Intramural
Research Program, National Institute of Arthritis and Musculoskeletal and Skin
Diseases, Bethesda, Maryland, United States of America. (3)State Key Laboratory
of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen University, Guangzhou,
China. (4)Biodata Mining and Discovery Section, Office of Science and Technology,
Intramural Research Program, National Institute of Arthritis and Musculoskeletal 
and Skin Diseases, Bethesda, Maryland, United States of America. (5)Laboratory of
Bioinformatics, Center for Advanced Computer Studies, University of Louisiana at 
Lafayette, Lafayette, Louisiana, United States of America.

Comparative co-localization analysis of transcription factors (TFs) and
epigenetic marks (EMs) in specific biological contexts is one of the most
critical areas of ChIP-Seq data analysis beyond peak calling. Yet there is a
significant lack of user-friendly and powerful tools geared towards
co-localization analysis based exploratory research. Most tools currently used
for co-localization analysis are command line only and require extensive
installation procedures and Linux expertise. Online tools partially address the
usability issues of command line tools, but slow response times and few
customization features make them unsuitable for rapid data-driven interactive
exploratory research. We have developed PAPST: Peak Assignment and Profile Search
Tool, a user-friendly yet powerful platform with a unique design, which
integrates both gene-centric and peak-centric co-localization analysis into a
single package. Most of PAPST's functions can be completed in less than five
seconds, allowing quick cycles of data-driven hypothesis generation and testing. 
With PAPST, a researcher with or without computational expertise can perform
sophisticated co-localization pattern analysis of multiple TFs and EMs, either
against all known genes or a set of genomic regions obtained from public
repositories or prior analysis. PAPST is a versatile, efficient, and customizable
tool for genome-wide data-driven exploratory research. Creatively used, PAPST can
be quickly applied to any genomic data analysis that involves a comparison of two
or more sets of genomic coordinate intervals, making it a powerful tool for a
wide range of exploratory genomic research. We first present PAPST's general
purpose features then apply it to several public ChIP-Seq data sets to
demonstrate its rapid execution and potential for cutting-edge research with a
case study in enhancer analysis. To our knowledge, PAPST is the first software of
its kind to provide efficient and sophisticated post peak-calling ChIP-Seq data
analysis as an easy-to-use interactive application. PAPST is available at
https://github.com/paulbible/papst and is a public domain work.

DOI: 10.1371/journal.pone.0127285 
PMCID: PMC4430287
PMID: 25970601  [PubMed - indexed for MEDLINE]


998. Med Image Anal. 2015 Jul;23(1):56-69. doi: 10.1016/j.media.2015.04.014. Epub 2015
Apr 24.

Robust inverse-consistent affine CT-MR registration in MRI-assisted and MRI-alone
prostate radiation therapy.

Rivest-Hénault D(1), Dowson N(2), Greer PB(3), Fripp J(4), Dowling JA(5).

Author information: 
(1)CSIRO, The Australian e-Health Research Centre, Herston, Queensland 4029,
Australia. Electronic address: david.rivest.henault@gmail.com. (2)CSIRO, The
Australian e-Health Research Centre, Herston, Queensland 4029, Australia.
Electronic address: nicholas.dowson@csiro.au. (3)Calvary Mater Newcastle
Hospital, Newcastle, New South Wales 2298, Australia; University of Newcastle,
Newcastle, New South Wales 2308, Australia. (4)CSIRO, The Australian e-Health
Research Centre, Herston, Queensland 4029, Australia. (5)CSIRO, The Australian
e-Health Research Centre, Herston, Queensland 4029, Australia; University of
Newcastle, Newcastle, New South Wales 2308, Australia. Electronic address:
jason.dowling@csiro.au.

BACKGROUND: CT-MR registration is a critical component of many radiation oncology
protocols. In prostate external beam radiation therapy, it allows the propagation
of MR-derived contours to reference CT images at the planning stage, and it
enables dose mapping during dosimetry studies. The use of carefully registered
CT-MR atlases allows the estimation of patient specific electron density maps
from MRI scans, enabling MRI-alone radiation therapy planning and treatment
adaptation. In all cases, the precision and accuracy achieved by registration
influences the quality of the entire process.
PROBLEM: Most current registration algorithms do not robustly generalize and lack
inverse-consistency, increasing the risk of human error and acting as a source of
bias in studies where information is propagated in a particular direction, e.g.
CT to MR or vice versa. In MRI-based treatment planning where both CT and MR
scans serve as spatial references, inverse-consistency is critical, if
under-acknowledged.
PURPOSE: A robust, inverse-consistent, rigid/affine registration algorithm that
is well suited to CT-MR alignment in prostate radiation therapy is presented.
METHOD: The presented method is based on a robust block-matching optimization
process that utilises a half-way space definition to maintain
inverse-consistency. Inverse-consistency substantially reduces the influence of
the order of input images, simplifying analysis, and increasing robustness. An
open source implementation is available online at http://aehrc.github.io/Mirorr/.
RESULTS: Experimental results on a challenging 35 CT-MR pelvis dataset
demonstrate that the proposed method is more accurate than other popular
registration packages and is at least as accurate as the state of the art, while 
being more robust and having an order of magnitude higher inverse-consistency
than competing approaches.
CONCLUSION: The presented results demonstrate that the proposed registration
algorithm is readily applicable to prostate radiation therapy planning.

Copyright © 2015. Published by Elsevier B.V.

DOI: 10.1016/j.media.2015.04.014 
PMID: 25966468  [PubMed - indexed for MEDLINE]


999. Bioinformatics. 2015 Sep 1;31(17):2912-4. doi: 10.1093/bioinformatics/btv300.
Epub 2015 May 11.

GOplot: an R package for visually combining expression data with functional
analysis.

Walter W(1), Sánchez-Cabo F(2), Ricote M(1).

Author information: 
(1)Department of Cardiovascular Development and Repair and. (2)Bioinformatics
Unit, Centro Nacional de Investigaciones Cardiovasculares (CNIC), Madrid, Spain.

Despite the plethora of methods available for the functional analysis of omics
data, obtaining comprehensive-yet detailed understanding of the results remains
challenging. This is mainly due to the lack of publicly available tools for the
visualization of this type of information. Here we present an R package called
GOplot, based on ggplot2, for enhanced graphical representation. Our package
takes the output of any general enrichment analysis and generates plots at
different levels of detail: from a general overview to identify the most enriched
categories (bar plot, bubble plot) to a more detailed view displaying different
types of information for molecules in a given set of categories (circle plot,
chord plot, cluster plot). The package provides a deeper insight into omics data 
and allows scientists to generate insightful plots with only a few lines of code 
to easily communicate the findings.AVAILABILITY AND IMPLEMENTATION: The R package
GOplot is available via CRAN-The Comprehensive R Archive Network:
http://cran.r-project.org/web/packages/GOplot. The shiny web application of the
Venn diagram can be found at: https://wwalter.shinyapps.io/Venn/. A detailed
manual of the package with sample figures can be found at
https://wencke.github.io/
CONTACT: fscabo@cnic.es or mricote@cnic.es.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv300 
PMID: 25964631  [PubMed - indexed for MEDLINE]


1000. Gigascience. 2015 May 9;4:22. doi: 10.1186/s13742-015-0063-8. eCollection 2015.

BioMAJ2Galaxy: automatic update of reference data in Galaxy using BioMAJ.

Bretaudeau A(1), Monjeaud C(2), Le Bras Y(2), Legeai F(3), Collin O(2).

Author information: 
(1)INRA, UMR Institut de Génétique, Environnement et Protection des Plantes
(IGEPP), BioInformatics Platform for Agroecosystems Arthropods (BIPAA), Campus
Beaulieu, Rennes, 35042 France ; INRIA, IRISA, GenOuest Core Facility, Campus de 
Beaulieu, Rennes, 35042 France. (2)INRIA, IRISA, GenOuest Core Facility, Campus
de Beaulieu, Rennes, 35042 France. (3)INRA, UMR Institut de Génétique,
Environnement et Protection des Plantes (IGEPP), BioInformatics Platform for
Agroecosystems Arthropods (BIPAA), Campus Beaulieu, Rennes, 35042 France ; INRIA,
IRISA, GenScale, Campus de Beaulieu, Rennes, 35042 France.

BACKGROUND: Many bioinformatics tools use reference data, such as genome
assemblies or sequence databanks. Galaxy offers multiple ways to give access to
this data through its web interface. However, the process of adding new reference
data was customarily manual and time consuming, even more so when this data
needed to be indexed in a variety of formats (e.g. Blast, Bowtie, BWA, or 2bit). 
BioMAJ is a widely used and stable software that is designed to automate the
download and transformation of data from various sources. This data can be used
directly from the command line, in more complex systems, such as Mobyle, or by
using a REST API.
FINDINGS: To ease the process of giving access to reference data in Galaxy, we
have developed the BioMAJ2Galaxy module, which enables the gap between BioMAJ and
Galaxy to be bridged. With this module, it is now possible to configure BioMAJ to
automatically download some reference data, to then convert and/or index it in
various formats, and then make this data available in a Galaxy server using data 
libraries or data managers.
CONCLUSIONS: The developments presented in this paper allow us to integrate the
reference data in Galaxy in an automatic, reliable, and diskspace-saving way. The
code is freely available on the GenOuest GitHub account
(https://github.com/genouest/biomaj2galaxy).

DOI: 10.1186/s13742-015-0063-8 
PMCID: PMC4425870
PMID: 25960870  [PubMed - indexed for MEDLINE]


1001. Database (Oxford). 2015 May 9;2015:bav043. doi: 10.1093/database/bav043. Print
2015.

The Confidence Information Ontology: a step towards a standard for asserting
confidence in annotations.

Bastian FB(1), Chibucos MC(2), Gaudet P(2), Giglio M(2), Holliday GL(2), Huang
H(2), Lewis SE(2), Niknejad A(1), Orchard S(2), Poux S(2), Skunca N(1),
Robinson-Rechavi M(1).

Author information: 
(1)Department of Ecology and Evolution, University of Lausanne, 1015 Lausanne,
Switzerland, SIB Swiss Institute of Bioinformatics, 1015 Lausanne, Switzerland,
Department of Microbiology and Immunology and Institute for Genome Sciences,
University of Maryland School of Medicine, Baltimore MD, USA, SIB Swiss Institute
of Bioinformatics, 1 Rue Michel Servet, 1211 Geneva, Switzerland, Department of
Medicine and Institute for Genome Sciences, University of Maryland School of
Medicine, Baltimore MD, USA, Department of Bioengineering and Therapeutic
Sciences, University of California, San Francisco, CA 94158, USA, School of
Information, University of South Florida, Tampa, FL, 33647, USA, Genomics
Division, Lawrence Berkeley National Lab, 1 Cyclotron Rd., Berkeley, 94720 CA
USA, European Molecular Biology Laboratory, European Bioinformatics Institute
(EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SD, UK,
Swiss-Prot Group, SIB Swiss Institute of Bioinformatics, Centre Medical
Universitaire, Geneva, Switzerland, ETH Zurich, Department of Computer Science,
Universitätstr. 19, 8092 Zürich, Switzerland, SIB Swiss Institute of
Bioinformatics, Universitätstr. 6, 8092 Zürich, Switzerland and University
College London, Gower St, London WC1E 6BT, UK Department of Ecology and
Evolution, University of Lausanne, 1015 Lausanne, Switzerland, SIB Swiss
Institute of Bioinformatics, 1015 Lausanne, Switzerland, Department of
Microbiology and Immunology and Institute for Genome Sciences, University of
Maryland School of Medicine, Baltimore MD, USA, SIB Swiss Institute of
Bioinformatics, 1 Rue Michel Servet, 1211 Geneva, Switzerland, Department of
Medicine and Institute for Genome Sciences, University of Maryland School of
Medicine, Baltimore MD, USA, Department of Bioengineering and Therapeutic
Sciences, University of California, San Francisco, CA 94158, USA, School of
Information, University of South Florida, Tampa, FL, 33647, USA, Genomics
Division, Lawrence Berkeley Nat (2)Department of Ecology and Evolution,
University of Lausanne, 1015 Lausanne, Switzerland, SIB Swiss Institute of
Bioinformatics, 1015 Lausanne, Switzerland, Department of Microbiology and
Immunology and Institute for Genome Sciences, University of Maryland School of
Medicine, Baltimore MD, USA, SIB Swiss Institute of Bioinformatics, 1 Rue Michel 
Servet, 1211 Geneva, Switzerland, Department of Medicine and Institute for Genome
Sciences, University of Maryland School of Medicine, Baltimore MD, USA,
Department of Bioengineering and Therapeutic Sciences, University of California, 
San Francisco, CA 94158, USA, School of Information, University of South Florida,
Tampa, FL, 33647, USA, Genomics Division, Lawrence Berkeley National Lab, 1
Cyclotron Rd., Berkeley, 94720 CA USA, European Molecular Biology Laboratory,
European Bioinformatics Institute (EMBL-EBI), Wellcome Trust Genome Campus,
Hinxton, Cambridge CB10 1SD, UK, Swiss-Prot Group, SIB Swiss Institute of
Bioinformatics, Centre Medical Universitaire, Geneva, Switzerland, ETH Zurich,
Department of Computer Science, Universitätstr. 19, 8092 Zürich, Switzerland, SIB
Swiss Institute of Bioinformatics, Universitätstr. 6, 8092 Zürich, Switzerland
and University College London, Gower St, London WC1E 6BT, UK.

Biocuration has become a cornerstone for analyses in biology, and to meet needs, 
the amount of annotations has considerably grown in recent years. However, the
reliability of these annotations varies; it has thus become necessary to be able 
to assess the confidence in annotations. Although several resources already
provide confidence information about the annotations that they produce, a
standard way of providing such information has yet to be defined. This lack of
standardization undermines the propagation of knowledge across resources, as well
as the credibility of results from high-throughput analyses. Seeded at a workshop
during the Biocuration 2012 conference, a working group has been created to
address this problem. We present here the elements that were identified as
essential for assessing confidence in annotations, as well as a draft
ontology--the Confidence Information Ontology--to illustrate how the problems
identified could be addressed. We hope that this effort will provide a home for
discussing this major issue among the biocuration community. Tracker URL:
https://github.com/BgeeDB/confidence-information-ontology Ontology URL:
https://raw.githubusercontent.com/BgeeDB/confidence-information-ontology/master/s
rc/ontology/cio-simple.obo

© The Author(s) 2015. Published by Oxford University Press.

DOI: 10.1093/database/bav043 
PMCID: PMC4425939
PMID: 25957950  [PubMed - indexed for MEDLINE]


1002. Bioinformatics. 2015 Sep 1;31(17):2885-7. doi: 10.1093/bioinformatics/btv290.
Epub 2015 May 6.

BFC: correcting Illumina sequencing errors.

Li H(1).

Author information: 
(1)Medical Population Genetics Program, Broad Institute, Cambridge, MA 02142,
USA.

BFC is a free, fast and easy-to-use sequencing error corrector designed for
Illumina short reads. It uses a non-greedy algorithm but still maintains a speed 
comparable to implementations based on greedy methods. In evaluations on real
data, BFC appears to correct more errors with fewer overcorrections in comparison
to existing tools. It particularly does well in suppressing systematic sequencing
errors, which helps to improve the base accuracy of de novo
assemblies.AVAILABILITY AND IMPLEMENTATION: https://github.com/lh3/bfc
CONTACT: hengli@broadinstitute.org
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv290 
PMCID: PMC4635656
PMID: 25953801  [PubMed - indexed for MEDLINE]


1003. BMC Genet. 2015;16 Suppl 2:S1. doi: 10.1186/1471-2156-16-S2-S1. Epub 2015 Apr 23.

An integrative framework for the identification of double minute chromosomes
using next generation sequencing data.

Hayes M, Li J.

BACKGROUND: Double minute chromosomes are circular fragments of DNA whose
presence is associated with the onset of certain cancers. Double minutes are
lethal, as they are highly amplified and typically contain oncogenes. Locating
double minutes can supplement the process of cancer diagnosis, and it can help to
identify therapeutic targets. However, there is currently a dearth of
computational methods available to identify double minutes. We propose a
computational framework for the idenfication of double minute chromosomes using
next-generation sequencing data. Our framework integrates predictions from
algorithms that detect DNA copy number variants, and it also integrates
predictions from algorithms that locate genomic structural variants. This
information is used by a graph-based algorithm to predict the presence of double 
minute chromosomes.
RESULTS: Using a previously published copy number variant algorithm and two
structural variation prediction algorithms, we implemented our framework and
tested it on a dataset consisting of simulated double minute chromosomes. Our
approach uncovered double minutes with high accuracy, demonstrating its
plausibility.
CONCLUSIONS: Although we only tested the framework with three programs
(RDXplorer, BreakDancer, Delly), it can be extended to incorporate results from
programs that 1) detect amplified copy number and from programs that 2) detect
genomic structural variants like deletions, translocations, inversions, and
tandem repeats. The software that implements the framework can be accessed here: 
https://github.com/mhayes20/DMFinder

DOI: 10.1186/1471-2156-16-S2-S1 
PMCID: PMC4423570
PMID: 25953282  [PubMed - indexed for MEDLINE]


1004. J Biomed Semantics. 2015 Apr 2;6:22. doi: 10.1186/s13326-015-0015-3. eCollection 
2015.

Formalizing biomedical concepts from textual definitions.

Petrova A(1), Ma Y(2), Tsatsaronis G(1), Kissa M(1), Distel F(2), Baader F(2),
Schroeder M(1).

Author information: 
(1)Biotechnology Center, Technische Universität Dresden, Dresden, Germany.
(2)Institute of Theoretical Computer Science, Technische Universität Dresden,
Dresden, Germany.

BACKGROUND: Ontologies play a major role in life sciences, enabling a number of
applications, from new data integration to knowledge verification. SNOMED CT is a
large medical ontology that is formally defined so that it ensures global
consistency and support of complex reasoning tasks. Most biomedical ontologies
and taxonomies on the other hand define concepts only textually, without the use 
of logic. Here, we investigate how to automatically generate formal concept
definitions from textual ones. We develop a method that uses machine learning in 
combination with several types of lexical and semantic features and outputs
formal definitions that follow the structure of SNOMED CT concept definitions.
RESULTS: We evaluate our method on three benchmarks and test both the underlying 
relation extraction component as well as the overall quality of output concept
definitions. In addition, we provide an analysis on the following aspects: (1)
How do definitions mined from the Web and literature differ from the ones mined
from manually created definitions, e.g., MeSH? (2) How do different feature
representations, e.g., the restrictions of relations' domain and range, impact on
the generated definition quality?, (3) How do different machine learning
algorithms compare to each other for the task of formal definition generation?,
and, (4) What is the influence of the learning data size to the task? We discuss 
all of these settings in detail and show that the suggested approach can achieve 
success rates of over 90%. In addition, the results show that the choice of
corpora, lexical features, learning algorithm and data size do not impact the
performance as strongly as semantic types do. Semantic types limit the domain and
range of a predicted relation, and as long as relations' domain and range pairs
do not overlap, this information is most valuable in formalizing textual
definitions.
CONCLUSIONS: The analysis presented in this manuscript implies that automated
methods can provide a valuable contribution to the formalization of biomedical
knowledge, thus paving the way for future applications that go beyond retrieval
and into complex reasoning. The method is implemented and accessible to the
public from: https://github.com/alifahsyamsiyah/learningDL.

DOI: 10.1186/s13326-015-0015-3 
PMCID: PMC4422531
PMID: 25949785  [PubMed]


1005. Bioinformatics. 2015 Sep 1;31(17):2888-90. doi: 10.1093/bioinformatics/btv277.
Epub 2015 May 5.

pez: phylogenetics for the environmental sciences.

Pearse WD(1), Cadotte MW(2), Cavender-Bares J(3), Ives AR(4), Tucker CM(5),
Walker SC(6), Helmus MR(7).

Author information: 
(1)Department of Ecology, Evolution, and Behavior, University of Minnesota, Saint
Paul, MN, USA, Department of Biology, McGill University, Montréal, QC, Canada,
Département des Sciences Biologiques, Université du Québec à Montréal, Succursale
Centre-ville, Montréal, QC, Canada. (2)Department of Biological Sciences,
University of Toronto Scarborough, Scarborough, ON, Canada. (3)Department of
Ecology, Evolution, and Behavior, University of Minnesota, Saint Paul, MN, USA.
(4)Department of Zoology, University of Wisconsin, Madison, WI, USA.
(5)Department of Ecology and Evolutionary Biology, University of Colorado,
Boulder, CO, USA. (6)Department of Mathematics and Statistics, McMaster
University, Hamilton, ON, Canada, and. (7)Department of Animal Ecology, Vrije
Universiteit, Amsterdam, The Netherlands.

pez is an R package that permits measurement, modelling and simulation of
phylogenetic structure in ecological data. pez contains the first implementation 
of many methods in R, and aggregates existing data structures and methods into a 
single, coherent package.AVAILABILITY AND IMPLEMENTATION: pez is released under
the GPL v3 open-source license, available on the Internet from CRAN
(http://cran.r-project.org). The package is under active development, and the
authors welcome contributions (see http://github.com/willpearse/pez).
CONTACT: will.pearse@gmail.com.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv277 
PMID: 25948716  [PubMed - indexed for MEDLINE]


1006. BMC Bioinformatics. 2015 May 7;16:146. doi: 10.1186/s12859-015-0591-3.

Determining minimum set of driver nodes in protein-protein interaction networks.

Zhang XF(1), Ou-Yang L(2), Zhu Y(3), Wu MY(4), Dai DQ(5).

Author information: 
(1)School of Mathematics and Statistics, Central China Normal University, Luoyu
Road, Wuhan, 430079, China. zhangxf@mail.ccnu.edu.cn. (2)Intelligent Data Center 
and Department of Mathematics, Sun Yat-Sen University, Xingang West Road,
Guangzhou, 510275, China. ouyangle@mail2.sysu.edu.cn. (3)School of Mathematics
and Statistics, Guangdong University of Finance and Economics, ChiSha Road,
Guangzhou, 510320, China. zhuyuan7@mail2.sysu.edu.cn. (4)School of Statistics and
Management, Shanghai University of Finance and Economics, Guoding Road, Shanghai,
200433, China. wu.mengyun@mail.shufe.edu.cn. (5)Intelligent Data Center and
Department of Mathematics, Sun Yat-Sen University, Xingang West Road, Guangzhou, 
510275, China. stsddq@mail.sysu.edu.cn.

BACKGROUND: Recently, several studies have drawn attention to the determination
of a minimum set of driver proteins that are important for the control of the
underlying protein-protein interaction (PPI) networks. In general, the minimum
dominating set (MDS) model is widely adopted. However, because the MDS model does
not generate a unique MDS configuration, multiple different MDSs would be
generated when using different optimization algorithms. Therefore, among these
MDSs, it is difficult to find out the one that represents the true driver set of 
proteins.
RESULTS: To address this problem, we develop a centrality-corrected minimum
dominating set (CC-MDS) model which includes heterogeneity in degree and
betweenness centralities of proteins. Both the MDS model and the CC-MDS model are
applied on three human PPI networks. Unlike the MDS model, the CC-MDS model
generates almost the same sets of driver proteins when we implement it using
different optimization algorithms. The CC-MDS model targets more high-degree and 
high-betweenness proteins than the uncorrected counterpart. The more central
position allows CC-MDS proteins to be more important in maintaining the overall
network connectivity than MDS proteins. To indicate the functional significance, 
we find that CC-MDS proteins are involved in, on average, more protein complexes 
and GO annotations than MDS proteins. We also find that more essential genes,
aging genes, disease-associated genes and virus-targeted genes appear in CC-MDS
proteins than in MDS proteins. As for the involvement in regulatory functions,
the sets of CC-MDS proteins show much stronger enrichment of transcription
factors and protein kinases. The results about topological and functional
significance demonstrate that the CC-MDS model can capture more driver proteins
than the MDS model.
CONCLUSIONS: Based on the results obtained, the CC-MDS model presents to be a
powerful tool for the determination of driver proteins that can control the
underlying PPI networks. The software described in this paper and the datasets
used are available at https://github.com/Zhangxf-ccnu/CC-MDS .

DOI: 10.1186/s12859-015-0591-3 
PMCID: PMC4428234
PMID: 25947063  [PubMed - indexed for MEDLINE]


1007. Genome Biol. 2015 May 6;16:91. doi: 10.1186/s13059-015-0647-8.

Fast and scalable inference of multi-sample cancer lineages.

Popic V(1), Salari R(2), Hajirasouliha I(3), Kashef-Haghighi D(4), West RB(5),
Batzoglou S(6).

Author information: 
(1)Department of Computer Science, Stanford University, Stanford, CA, USA.
viq@stanford.edu. (2)Department of Computer Science, Stanford University,
Stanford, CA, USA. rahelehs@cs.stanford.edu. (3)Department of Computer Science,
Stanford University, Stanford, CA, USA. imanh@stanford.edu. (4)Department of
Computer Science, Stanford University, Stanford, CA, USA. dkashef@stanford.edu.
(5)Department of Pathology, Stanford University School of Medicine, Stanford, CA,
USA. rbwest@stanford.edu. (6)Department of Computer Science, Stanford University,
Stanford, CA, USA. serafim@cs.stanford.edu.

Somatic variants can be used as lineage markers for the phylogenetic
reconstruction of cancer evolution. Since somatic phylogenetics is complicated by
sample heterogeneity, novel specialized tree-building methods are required for
cancer phylogeny reconstruction. We present LICHeE (Lineage Inference for Cancer 
Heterogeneity and Evolution), a novel method that automates the phylogenetic
inference of cancer progression from multiple somatic samples. LICHeE uses
variant allele frequencies of somatic single nucleotide variants obtained by deep
sequencing to reconstruct multi-sample cell lineage trees and infer the subclonal
composition of the samples. LICHeE is open source and available at
http://viq854.github.io/lichee .

DOI: 10.1186/s13059-015-0647-8 
PMCID: PMC4501097
PMID: 25944252  [PubMed - indexed for MEDLINE]


1008. PLoS One. 2015 May 5;10(5):e0124449. doi: 10.1371/journal.pone.0124449.
eCollection 2015.

RLT-S: A Web System for Record Linkage.

Mamun AA(1), Aseltine R(2), Rajasekaran S(1).

Author information: 
(1)Department of Computer Science and Engineering, University of Connecticut,
Storrs, Connecticut, United States of America. (2)Institute for Public Health
Research, University of Connecticut, East Hartford, Connecticut, United States of
America.

BACKGROUND: Record linkage integrates records across multiple related data
sources identifying duplicates and accounting for possible errors. Real life
applications require efficient algorithms to merge these voluminous data sources 
to find out all records belonging to same individuals. Our recently devised
highly efficient record linkage algorithms provide best-known solutions to this
challenging problem.
METHOD: We have developed RLT-S, a freely available web tool, which implements
our single linkage clustering algorithm for record linkage. This tool requires
input data sets and a small set of configuration settings about these files to
work efficiently. RLT-S employs exact match clustering, blocking on a specified
attribute and single linkage based hierarchical clustering among these blocks.
RESULTS: RLT-S is an implementation package of our sequential record linkage
algorithm. It outperforms previous best-known implementations by a large margin. 
The tool is at least two times faster for any dataset than the previous
best-known tools.
CONCLUSIONS: RLT-S tool implements our record linkage algorithm that outperforms 
previous best-known algorithms in this area. This website also contains necessary
information such as instructions, submission history, feedback, publications and 
some other sections to facilitate the usage of the tool.
AVAILABILITY: RLT-S is integrated into http://www.rlatools.com, which is
currently serving this tool only. The tool is freely available and can be used
without login. All data files used in this paper have been stored in
https://github.com/abdullah009/DataRLATools. For copies of the relevant programs 
please see https://github.com/abdullah009/RLATools.

DOI: 10.1371/journal.pone.0124449 
PMCID: PMC4420456
PMID: 25942687  [PubMed - indexed for MEDLINE]


1009. Bioinformatics. 2015 Sep 1;31(17):2794-800. doi: 10.1093/bioinformatics/btv276.
Epub 2015 May 4.

Phylesystem: a git-based data store for community-curated phylogenetic estimates.

McTavish EJ(1), Hinchliff CE(2), Allman JF(3), Brown JW(2), Cranston KA(4),
Holder MT(1), Rees JA(4), Smith SA(2).

Author information: 
(1)Department of Ecology and Evolutionary Biology, University of Kansas,
Lawrence, KS, USA, Heidelberg Institute for Theoretical Studies, Heidelberg
69118, Germany. (2)Department of Ecology and Evolutionary Biology, University of 
Michigan, Ann Arbor, MI, USA. (3)Interrobang Corporation, Wake Forest, NC 27587, 
USA and. (4)National Evolutionary Synthesis Center, Duke University, Durham, NC, 
USA.

MOTIVATION: Phylogenetic estimates from published studies can be archived using
general platforms like Dryad (Vision, 2010) or TreeBASE (Sanderson et al., 1994).
Such services fulfill a crucial role in ensuring transparency and reproducibility
in phylogenetic research. However, digital tree data files often require some
editing (e.g. rerooting) to improve the accuracy and reusability of the
phylogenetic statements. Furthermore, establishing the mapping between tip labels
used in a tree and taxa in a single common taxonomy dramatically improves the
ability of other researchers to reuse phylogenetic estimates. As the process of
curating a published phylogenetic estimate is not error-free, retaining a full
record of the provenance of edits to a tree is crucial for openness, allowing
editors to receive credit for their work and making errors introduced during
curation easier to correct.
RESULTS: Here, we report the development of software infrastructure to support
the open curation of phylogenetic data by the community of biologists. The
backend of the system provides an interface for the standard database operations 
of creating, reading, updating and deleting records by making commits to a git
repository. The record of the history of edits to a tree is preserved by git's
version control features. Hosting this data store on GitHub (http://github.com/) 
provides open access to the data store using tools familiar to many developers.
We have deployed a server running the 'phylesystem-api', which wraps the
interactions with git and GitHub. The Open Tree of Life project has also
developed and deployed a JavaScript application that uses the phylesystem-api and
other web services to enable input and curation of published phylogenetic
statements.
AVAILABILITY AND IMPLEMENTATION: Source code for the web service layer is
available at https://github.com/OpenTreeOfLife/phylesystem-api. The data store
can be cloned from: https://github.com/OpenTreeOfLife/phylesystem. A web
application that uses the phylesystem web services is deployed at
http://tree.opentreeoflife.org/curator. Code for that tool is available from
https://github.com/OpenTreeOfLife/opentree.
CONTACT: mtholder@gmail.com.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv276 
PMCID: PMC4547614
PMID: 25940563  [PubMed - indexed for MEDLINE]


1010. PLoS One. 2015 May 4;10(5):e0126070. doi: 10.1371/journal.pone.0126070.
eCollection 2015.

Tn-seq explorer: a tool for analysis of high-throughput sequencing data of
transposon mutant libraries.

Solaimanpour S(1), Sarmiento F(2), Mrázek J(3).

Author information: 
(1)Department of Computer Science, University of Georgia, Athens, GA 30602,
United States of America. (2)Swissaustral USA, 111 Riverbend Rd., Athens, GA
30602, United States of America. (3)Department of Microbiology and Institute of
Bioinformatics, University of Georgia, Athens, GA 30602, United States of
America.

Tn-seq is a high throughput technique for analysis of transposon mutant
libraries. Tn-seq Explorer was developed as a convenient and easy-to-use package 
of tools for exploration of the Tn-seq data. In a typical application, the user
will have obtained a collection of sequence reads adjacent to transposon
insertions in a reference genome. The reads are first aligned to the reference
genome using one of the tools available for this task. Tn-seq Explorer reads the 
alignment and the gene annotation, and provides the user with a set of tools to
investigate the data and identify possibly essential or advantageous genes as
those that contain significantly low counts of transposon insertions. Emphasis is
placed on providing flexibility in selecting parameters and methodology most
appropriate for each particular dataset. Tn-seq Explorer is written in Java as a 
menu-driven, stand-alone application. It was tested on Windows, Mac OS, and Linux
operating systems. The source code is distributed under the terms of GNU General 
Public License. The program and the source code are available for download at
http://www.cmbl.uga.edu/downloads/programs/Tn_seq_Explorer/ and
https://github.com/sina-cb/Tn-seqExplorer.

DOI: 10.1371/journal.pone.0126070 
PMCID: PMC4418687
PMID: 25938432  [PubMed - indexed for MEDLINE]


1011. J Proteome Res. 2015 Jul 2;14(7):2988-97. doi: 10.1021/acs.jproteome.5b00121.
Epub 2015 Jun 10.

PIA: An Intuitive Protein Inference Engine with a Web-Based User Interface.

Uszkoreit J(1), Maerkens A(1), Perez-Riverol Y(1), Meyer HE(1), Marcus K(1),
Stephan C(1), Kohlbacher O(1), Eisenacher M(1).

Author information: 
(1)Medizinisches Proteom-Center, Ruhr-Universität Bochum, 44801 Bochum, Germany.

Protein inference connects the peptide spectrum matches (PSMs) obtained from
database search engines back to proteins, which are typically at the heart of
most proteomics studies. Different search engines yield different PSMs and thus
different protein lists. Analysis of results from one or multiple search engines 
is often hampered by different data exchange formats and lack of convenient and
intuitive user interfaces. We present PIA, a flexible software suite for
combining PSMs from different search engine runs and turning these into
consistent results. PIA can be integrated into proteomics data analysis workflows
in several ways. A user-friendly graphical user interface can be run either
locally or (e.g., for larger core facilities) from a central server. For
automated data processing, stand-alone tools are available. PIA implements
several established protein inference algorithms and can combine results from
different search engines seamlessly. On several benchmark data sets, we show that
PIA can identify a larger number of proteins at the same protein FDR when
compared to that using inference based on a single search engine. PIA supports
the majority of established search engines and data in the mzIdentML standard
format. It is implemented in Java and freely available at
https://github.com/mpc-bioinformatics/pia.

DOI: 10.1021/acs.jproteome.5b00121 
PMID: 25938255  [PubMed - indexed for MEDLINE]


1012. Comput Biol Chem. 2015 Jun;56:142-51. doi: 10.1016/j.compbiolchem.2015.03.002.
Epub 2015 Mar 27.

Gene network coherence based on prior knowledge using direct and indirect
relationships.

Gómez-Vela F(1), Lagares JA(2), Díaz-Díaz N(3).

Author information: 
(1)School of Engineering, Pablo de Olavide University, Seville, Spain. Electronic
address: fgomez@upo.es. (2)School of Engineering, Pablo de Olavide University,
Seville, Spain. Electronic address: jalagrod@alu.upo.es. (3)School of
Engineering, Pablo de Olavide University, Seville, Spain. Electronic address:
ndiaz@upo.es.

Gene networks (GNs) have become one of the most important approaches for modeling
biological processes. They are very useful to understand the different complex
biological processes that may occur in living organisms. Currently, one of the
biggest challenge in any study related with GN is to assure the quality of these 
GNs. In this sense, recent works use artificial data sets or a direct comparison 
with prior biological knowledge. However, these approaches are not entirely
accurate as they only take into account direct gene-gene interactions for
validation, leaving aside the weak (indirect) relationships. We propose a new
measure, named gene network coherence (GNC), to rate the coherence of an input
network according to different biological databases. In this sense, the measure
considers not only the direct gene-gene relationships but also the indirect ones 
to perform a complete and fairer evaluation of the input network. Hence, our
approach is able to use the whole information stored in the networks. A GNC
JAVA-based implementation is available at: http://fgomezvela.github.io/GNC/. The 
results achieved in this work show that GNC outperforms the classical approaches 
for assessing GNs by means of three different experiments using different
biological databases and input networks. According to the results, we can
conclude that the proposed measure, which considers the inherent information
stored in the direct and indirect gene-gene relationships, offers a new robust
solution to the problem of GNs biological validation.

Copyright © 2015 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.compbiolchem.2015.03.002 
PMID: 25935118  [PubMed - indexed for MEDLINE]


1013. Cancer Inform. 2015 Feb 12;14(Suppl 1):37-44. doi: 10.4137/CIN.S24657.
eCollection 2015.

Toolbox for mobile-element insertion detection on cancer genomes.

Lee WP(1), Wu J(2), Marth GT(3).

Author information: 
(1)Department of Biology, Boston College, Chestnut Hill, MA, USA. ; Currently at 
Seven Bridges Genomics, Cambridge, MA, USA. (2)Department of Biology, Boston
College, Chestnut Hill, MA, USA. ; Currently at Yelp, Inc. San Francisco, CA,
USA. (3)Department of Biology, Boston College, Chestnut Hill, MA, USA. ;
Currently at the Department of Human Genetics and Utah Center for Genetic
Discovery, University of Utah, Salt Lake City, UT, USA.

Mobile elements constitute greater than 45% of the human genome as a result of
repeated insertion events during human genome evolution. Although most of mobile 
elements are fixed within the human population, some elements (including ALU,
long interspersed elements (LINE) 1 (L1), and SVA) are still actively duplicating
and may result in life-threatening human diseases such as cancer, motivating the 
need for accurate mobile-element insertion (MEI) detection tools. We developed a 
software package, TANGRAM, for MEI detection in next-generation sequencing data, 
currently serving as the primary MEI detection tool in the 1000 Genomes Project. 
TANGRAM takes advantage of valuable mapping information provided by our own
MOSAIK mapper, and until recently required MOSAIK mappings as its input. In this 
study, we report a new feature that enables TANGRAM to be used on alignments
generated by any mainstream short-read mapper, making it accessible for many
genomic users. To demonstrate its utility for cancer genome analysis, we have
applied TANGRAM to the TCGA (The Cancer Genome Atlas) mutation calling benchmark 
4 dataset. TANGRAM is fast, accurate, easy to use, and open source on
https://github.com/jiantao/Tangram.

DOI: 10.4137/CIN.S24657 
PMCID: PMC4338948
PMID: 25931804  [PubMed]


1014. BMC Bioinformatics. 2015 Apr 28;16:131. doi: 10.1186/s12859-015-0568-2.

coMET: visualisation of regional epigenome-wide association scan results and DNA 
co-methylation patterns.

Martin TC(1), Yet I(2), Tsai PC(3), Bell JT(4).

Author information: 
(1)Department of Twin Research and Genetic Epidemiology, St Thomas' Hospital
Campus, King's College London, Westminster Bridge Road, London, UK.
tiphaine.martin@kcl.ac.uk. (2)Department of Twin Research and Genetic
Epidemiology, St Thomas' Hospital Campus, King's College London, Westminster
Bridge Road, London, UK. idil.erte@kcl.ac.uk. (3)Department of Twin Research and 
Genetic Epidemiology, St Thomas' Hospital Campus, King's College London,
Westminster Bridge Road, London, UK. pei-chien.tsai@kcl.ac.uk. (4)Department of
Twin Research and Genetic Epidemiology, St Thomas' Hospital Campus, King's
College London, Westminster Bridge Road, London, UK. jordana.bell@kcl.ac.uk.

BACKGROUND: Epigenome-wide association scans (EWAS) are an increasingly powerful 
and widely-used approach to assess the role of epigenetic variation in human
complex traits. However, this rapidly emerging field lacks dedicated
visualisation tools that can display features specific to epigenetic datasets.
RESULT: We developed coMET, an R package and online tool for visualisation of
EWAS results in a genomic region of interest. coMET generates a regional plot of 
epigenetic-phenotype association results and the estimated DNA methylation
correlation between CpG sites (co-methylation), with further options to visualise
genomic annotations based on ENCODE data, gene tracks, reference CpG-sites, and
user-defined features. The tool can be used to display phenotype association
signals and correlation patterns of microarray or sequencing-based DNA
methylation data, such as Illumina Infinium 450k, WGBS, or MeDIP-seq, as well as 
other types of genomic data, such as gene expression profiles. The software is
available as a user-friendly online tool from http://epigen.kcl.ac.uk/comet and
as an R Bioconductor package. Source code, examples, and full documentation are
also available from GitHub.
CONCLUSION: Our new software allows visualisation of EWAS results with functional
genomic annotations and with estimation of co-methylation patterns. coMET is
available to a wide audience as an online tool and R package, and can be a
valuable resource to interpret results in the fast growing field of epigenetics. 
The software is designed for epigenetic data, but can also be applied to genomic 
and functional genomic datasets in any species.

DOI: 10.1186/s12859-015-0568-2 
PMCID: PMC4422463
PMID: 25928765  [PubMed - indexed for MEDLINE]


1015. PLoS One. 2015 Apr 30;10(4):e0125108. doi: 10.1371/journal.pone.0125108.
eCollection 2015.

Fast and Efficient XML Data Access for Next-Generation Mass Spectrometry.

Röst HL(1), Schmitt U(2), Aebersold R(3), Malmström L(4).

Author information: 
(1)Department of Biology, Institute of Molecular Systems Biology, ETH Zurich,
CH-8093 Zurich, Switzerland; Ph.D. Program in Systems Biology, University of
Zurich and ETH Zurich, CH-8057 Zurich, Switzerland. (2)ID Scientific IT Services,
ETH Zurich, CH-8092 Zurich, Switzerland. (3)Department of Biology, Institute of
Molecular Systems Biology, ETH Zurich, CH-8093 Zurich, Switzerland; Competence
Center for Systems Physiology and Metabolic Diseases, CH-8093 Zurich,
Switzerland; Faculty of Science, University of Zurich, CH-8057 Zurich,
Switzerland. (4)Department of Biology, Institute of Molecular Systems Biology,
ETH Zurich, CH-8093 Zurich, Switzerland; S3IT, University of Zurich, CH-8057
Zurich, Switzerland.

MOTIVATION: In mass spectrometry-based proteomics, XML formats such as mzML and
mzXML provide an open and standardized way to store and exchange the raw data
(spectra and chromatograms) of mass spectrometric experiments. These file formats
are being used by a multitude of open-source and cross-platform tools which allow
the proteomics community to access algorithms in a vendor-independent fashion and
perform transparent and reproducible data analysis. Recent improvements in mass
spectrometry instrumentation have increased the data size produced in a single
LC-MS/MS measurement and put substantial strain on open-source tools,
particularly those that are not equipped to deal with XML data files that reach
dozens of gigabytes in size.
RESULTS: Here we present a fast and versatile parsing library for mass
spectrometric XML formats available in C++ and Python, based on the mature OpenMS
software framework. Our library implements an API for obtaining spectra and
chromatograms under memory constraints using random access or sequential access
functions, allowing users to process datasets that are much larger than system
memory. For fast access to the raw data structures, small XML files can also be
completely loaded into memory. In addition, we have improved the parsing speed of
the core mzML module by over 4-fold (compared to OpenMS 1.11), making our library
suitable for a wide variety of algorithms that need fast access to dozens of
gigabytes of raw mass spectrometric data.
AVAILABILITY: Our C++ and Python implementations are available for the Linux,
Mac, and Windows operating systems. All proposed modifications to the OpenMS code
have been merged into the OpenMS mainline codebase and are available to the
community at https://github.com/OpenMS/OpenMS.

DOI: 10.1371/journal.pone.0125108 
PMCID: PMC4416046
PMID: 25927999  [PubMed - indexed for MEDLINE]


1016. Bioinformatics. 2016 Apr 1;32(7):961-7. doi: 10.1093/bioinformatics/btv273. Epub 
2015 Apr 28.

PopIns: population-scale detection of novel sequence insertions.

Kehr B(1), Melsted P(2), Halldórsson BV(3).

Author information: 
(1)deCODE genetics/Amgen, Reykjavík, Iceland. (2)deCODE genetics/Amgen,
Reykjavík, Iceland, Faculty of Industrial Engineering, Mechanical Engineering and
Computer Science, University of Iceland, Reykjavík, Iceland and. (3)deCODE
genetics/Amgen, Reykjavík, Iceland, Institute of Biomedical and Neural
Engineering, Reykjavík University, Reykjavík, Iceland.

MOTIVATION: The detection of genomic structural variation (SV) has advanced
tremendously in recent years due to progress in high-throughput sequencing
technologies. Novel sequence insertions, insertions without similarity to a human
reference genome, have received less attention than other types of SVs due to the
computational challenges in their detection from short read sequencing data,
which inherently involves de novo assembly. De novo assembly is not only
computationally challenging, but also requires high-quality data. Although the
reads from a single individual may not always meet this requirement, using reads 
from multiple individuals can increase power to detect novel insertions.
RESULTS: We have developed the program PopIns, which can discover and
characterize non-reference insertions of 100 bp or longer on a population scale. 
In this article, we describe the approach we implemented in PopIns. It takes as
input a reads-to-reference alignment, assembles unaligned reads using a standard 
assembly tool, merges the contigs of different individuals into high-confidence
sequences, anchors the merged sequences into the reference genome, and finally
genotypes all individuals for the discovered insertions. Our tests on simulated
data indicate that the merging step greatly improves the quality and reliability 
of predicted insertions and that PopIns shows significantly better recall and
precision than the recent tool MindTheGap. Preliminary results on a dataset of
305 Icelanders demonstrate the practicality of the new approach.
AVAILABILITY AND IMPLEMENTATION: The source code of PopIns is available from
http://github.com/bkehr/popins
CONTACT: birte.kehr@decode.is
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv273 
PMID: 25926346  [PubMed - in process]


1017. PLoS One. 2015 Apr 29;10(4):e0125201. doi: 10.1371/journal.pone.0125201.
eCollection 2015.

Computel: computation of mean telomere length from whole-genome next-generation
sequencing data.

Nersisyan L(1), Arakelyan A(1).

Author information: 
(1)Group of Bioinformatics of the Institute of Molecular Biology of the National 
Academy of Sciences of the Republic of Armenia, Yerevan, Armenia.

Telomeres are the ends of eukaryotic chromosomes, consisting of consecutive short
repeats that protect chromosome ends from degradation. Telomeres shorten with
each cell division, leading to replicative cell senescence. Deregulation of
telomere length homeostasis is associated with the development of various
age-related diseases and cancers. A number of experimental techniques exist for
telomere length measurement; however, until recently, the absence of tools for
extracting telomere lengths from high-throughput sequencing data has
significantly obscured the association of telomere length with molecular
processes in normal and diseased conditions. We have developed Computel, a
program in R for computing mean telomere length from whole-genome next-generation
sequencing data. Computel is open source, and is freely available at
https://github.com/lilit-nersisyan/computel. It utilizes a short-read
alignment-based approach and integrates various popular tools for sequencing data
analysis. We validated it with synthetic and experimental data, and compared its 
performance with the previously available software. The results have shown that
Computel outperforms existing software in accuracy, independence of results from 
sequencing conditions, stability against inherent sequencing errors, and better
ability to distinguish pure telomeric sequences from interstitial telomeric
repeats. By providing a highly reliable methodology for determining telomere
lengths from whole-genome sequencing data, Computel should help to elucidate the 
role of telomeres in cellular health and disease.

DOI: 10.1371/journal.pone.0125201 
PMCID: PMC4414351
PMID: 25923330  [PubMed - indexed for MEDLINE]


1018. Front Genet. 2015 Apr 9;6:139. doi: 10.3389/fgene.2015.00139. eCollection 2015.

Transposon insertion mapping with PIMMS - Pragmatic Insertional Mutation Mapping 
System.

Blanchard AM(1), Leigh JA(1), Egan SA(1), Emes RD(1).

Author information: 
(1)School of Veterinary Medicine and Science, University of Nottingham
Loughborough, UK.

The PIMMS (Pragmatic Insertional Mutation Mapping System) pipeline has been
developed for simple conditionally essential genome discovery experiments in
bacteria. Capable of using raw sequence data files alongside a FASTA sequence of 
the reference genome and GFF file, PIMMS will generate a tabulated output of each
coding sequence with corresponding mapped insertions accompanied with normalized 
results enabling streamlined analysis. This allows for a quick assay of the
genome to identify conditionally essential genes on a standard desktop computer
prioritizing results for further investigation.AVAILABILITY: The PIMMS script,
manual and accompanying test data is freely available at
https://github.com/ADAC-UoN/PIMMS.

DOI: 10.3389/fgene.2015.00139 
PMCID: PMC4391243
PMID: 25914720  [PubMed]


1019. Bioinformatics. 2015 Sep 1;31(17):2909-11. doi: 10.1093/bioinformatics/btv269.
Epub 2015 Apr 25.

phylogeo: an R package for geographic analysis and visualization of microbiome
data.

Charlop-Powers Z(1), Brady SF(1).

Author information: 
(1)Laboratory of Genetically Encoded Small Molecules, The Rockefeller University,
New York, NY 10065, USA.

MOTIVATION: We have created an R package named phylogeo that provides a set of
geographic utilities for sequencing-based microbial ecology studies. Although the
geographic location of samples is an important aspect of environmental
microbiology, none of the major software packages used in processing microbiome
data include utilities that allow users to map and explore the spatial dimension 
of their data. phylogeo solves this problem by providing a set of plotting and
mapping functions that can be used to visualize the geographic distribution of
samples, to look at the relatedness of microbiomes using ecological distance, and
to map the geographic distribution of particular sequences. By extending the
popular phyloseq package and using the same data structures and command formats, 
phylogeo allows users to easily map and explore the geographic dimensions of
their data from the R programming language.
AVAILABILITY AND IMPLEMENTATION: phylogeo is documented and freely available
http://zachcp.github.io/phylogeo
CONTACT: : zcharlop@rockefeller.edu.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv269 
PMCID: PMC4547612
PMID: 25913208  [PubMed - indexed for MEDLINE]


1020. Bioinformatics. 2015 Sep 1;31(17):2900-2. doi: 10.1093/bioinformatics/btv205.
Epub 2015 Apr 24.

chipPCR: an R package to pre-process raw data of amplification curves.

Rödiger S(1), Burdukiewicz M(2), Schierack P(1).

Author information: 
(1)Faculty of Natural Sciences, Brandenburg University of Technology
Cottbus-Senftenberg, Senftenberg, Germany and. (2)Department of Genomics, Faculty
of Biotechnology, University of Wrocław, Wrocław, Poland.

MOTIVATION: Both the quantitative real-time polymerase chain reaction (qPCR) and 
quantitative isothermal amplification (qIA) are standard methods for nucleic acid
quantification. Numerous real-time read-out technologies have been developed.
Despite the continuous interest in amplification-based techniques, there are only
few tools for pre-processing of amplification data. However, a transparent tool
for precise control of raw data is indispensable in several scenarios, for
example, during the development of new instruments.
RESULTS: chipPCR is an R: package for the pre-processing and quality analysis of 
raw data of amplification curves. The package takes advantage of R: 's S4 object 
model and offers an extensible environment. chipPCR contains tools for raw data
exploration: normalization, baselining, imputation of missing values, a powerful 
wrapper for amplification curve smoothing and a function to detect the start and 
end of an amplification curve. The capabilities of the software are enhanced by
the implementation of algorithms unavailable in R: , such as a 5-point stencil
for derivative interpolation. Simulation tools, statistical tests, plots for data
quality management, amplification efficiency/quantification cycle calculation,
and datasets from qPCR and qIA experiments are part of the package. Core
functionalities are integrated in GUIs (web-based and standalone shiny
applications), thus streamlining analysis and report generation.
AVAILABILITY AND IMPLEMENTATION: http://cran.r-project.org/web/packages/chipPCR. 
Source code: https://github.com/michbur/chipPCR.
CONTACT: stefan.roediger@b-tu.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv205 
PMID: 25913204  [PubMed - indexed for MEDLINE]


1021. Bioinformatics. 2015 Sep 1;31(17):2903-5. doi: 10.1093/bioinformatics/btv250.
Epub 2015 Apr 24.

ms-data-core-api: an open-source, metadata-oriented library for computational
proteomics.

Perez-Riverol Y(1), Uszkoreit J(2), Sanchez A(3), Ternent T(1), Del Toro N(1),
Hermjakob H(1), Vizcaíno JA(1), Wang R(1).

Author information: 
(1)European Molecular Biology Laboratory, European Bioinformatics Institute
(EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1SD, UK.
(2)Ruhr-Universität Bochum, Medizinisches Proteom-Zenter, Medical Bioinformatics,
ZKF, E.142, Universitätsstr. 150, D-44801 Bochum, Germany and. (3)Department of
Proteomics, Center for Genetic Engineering and Biotechnology, Ciudad de la
Habana, Cuba.

The ms-data-core-api is a free, open-source library for developing computational 
proteomics tools and pipelines. The Application Programming Interface, written in
Java, enables rapid tool creation by providing a robust, pluggable programming
interface and common data model. The data model is based on controlled
vocabularies/ontologies and captures the whole range of data types included in
common proteomics experimental workflows, going from spectra to peptide/protein
identifications to quantitative results. The library contains readers for three
of the most used Proteomics Standards Initiative standard file formats: mzML,
mzIdentML, and mzTab. In addition to mzML, it also supports other common mass
spectra data formats: dta, ms2, mgf, pkl, apl (text-based), mzXML and mzData
(XML-based). Also, it can be used to read PRIDE XML, the original format used by 
the PRIDE database, one of the world-leading proteomics resources. Finally, we
present a set of algorithms and tools whose implementation illustrates the
simplicity of developing applications using the library.AVAILABILITY AND
IMPLEMENTATION: The software is freely available at
https://github.com/PRIDE-Utilities/ms-data-core-api.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online
CONTACT: juan@ebi.ac.uk.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv250 
PMCID: PMC4547611
PMID: 25910694  [PubMed - indexed for MEDLINE]


1022. Bioinformatics. 2015 Aug 15;31(16):2691-6. doi: 10.1093/bioinformatics/btv219.
Epub 2015 Apr 22.

ESPRESSO: taking into account assessment errors on outcome and exposures in power
analysis for association studies.

Gaye A(1), Burton TW(2), Burton PR(1).

Author information: 
(1)School of Social and Community Medicine, University of Bristol, UK and.
(2)School of Computing Science, Newcastle University, UK.

MOTIVATION: Very large studies are required to provide sufficiently big sample
sizes for adequately powered association analyses. This can be an expensive
undertaking and it is important that an accurate sample size is identified. For
more realistic sample size calculation and power analysis, the impact of
unmeasured aetiological determinants and the quality of measurement of both
outcome and explanatory variables should be taken into account. Conventional
methods to analyse power use closed-form solutions that are not flexible enough
to cater for all of these elements easily. They often result in a potentially
substantial overestimation of the actual power.
RESULTS: In this article, we describe the Estimating Sample-size and Power in R
by Exploring Simulated Study Outcomes tool that allows assessment errors in power
calculation under various biomedical scenarios to be incorporated. We also report
a real world analysis where we used this tool to answer an important strategic
question for an existing cohort.
AVAILABILITY AND IMPLEMENTATION: The software is available for online calculation
and downloads at http://espresso-research.org. The code is freely available at
https://github.com/ESPRESSO-research.
CONTACT: louqman@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv219 
PMCID: PMC4528636
PMID: 25908791  [PubMed - indexed for MEDLINE]


1023. Behav Res Methods. 2015 Sep;47(3):608-19. doi: 10.3758/s13428-015-0586-z.

PsyGlass: Capitalizing on Google Glass for naturalistic data collection.

Paxton A(1), Rodriguez K, Dale R.

Author information: 
(1)Cognitive and Information Sciences, University of California, Merced, 5200
North Lake Road, Merced, CA, 95343, USA, paxton.alexandra@gmail.com.

As commercial technology moves further into wearable technologies, cognitive and 
psychological scientists can capitalize on these devices to facilitate
naturalistic research designs while still maintaining strong experimental
control. One such wearable technology is Google Glass (Google, Inc.:
www.google.com/glass), which can present wearers with audio and visual stimuli
while tracking a host of multimodal data. In this article, we introduce PsyGlass,
a framework for incorporating Google Glass into experimental work that is freely 
available for download and community improvement over time
(www.github.com/a-paxton/PsyGlass). As a proof of concept, we use this framework 
to investigate dual-task pressures on naturalistic interaction. The preliminary
study demonstrates how designs from classic experimental psychology may be
integrated in naturalistic interactive designs with emerging technologies. We
close with a series of recommendations for using PsyGlass and a discussion of how
wearable technology more broadly may contribute to new or adapted naturalistic
research designs.

DOI: 10.3758/s13428-015-0586-z 
PMID: 25893865  [PubMed - indexed for MEDLINE]


1024. BMC Bioinformatics. 2015 Apr 16;16:118. doi: 10.1186/s12859-015-0562-8.

IPO: a tool for automated optimization of XCMS parameters.

Libiseller G(1), Dvorzak M(2), Kleb U(3), Gander E(4), Eisenberg T(5), Madeo
F(6,)(7), Neumann S(8), Trausinger G(9), Sinner F(10,)(11), Pieber T(12,)(13),
Magnes C(14).

Author information: 
(1)Joanneum Research Forschungsgesellschaft m.b.H., HEALTH, Institute for
Biomedicine and Health Sciences, Graz, Austria. gunnar.libiseller@joanneum.at.
(2)Joanneum Research Forschungsgesellschaft m.b.H., POLICIES, Institute for
Economic and Innovation Research, Graz, Austria. michaela.dvorzak@joanneum.at.
(3)Joanneum Research Forschungsgesellschaft m.b.H., POLICIES, Institute for
Economic and Innovation Research, Graz, Austria. ulrike.kleb@joanneum.at.
(4)Joanneum Research Forschungsgesellschaft m.b.H., HEALTH, Institute for
Biomedicine and Health Sciences, Graz, Austria. edgar.gander@joanneum.at.
(5)Institute of Molecular Biosciences, NAWI Graz, University of Graz, 8010, Graz,
Austria. tobias.eisenberg@uni-graz.at. (6)Institute of Molecular Biosciences,
NAWI Graz, University of Graz, 8010, Graz, Austria. frank.madeo@uni-graz.at.
(7)BioTechMed Graz, 8010, Graz, Austria. frank.madeo@uni-graz.at. (8)Department
of Stress- and Developmental Biology, Leibniz Institute of Plant Biochemistry,
Halle, Germany. sneumann@ipb-halle.de. (9)Joanneum Research
Forschungsgesellschaft m.b.H., HEALTH, Institute for Biomedicine and Health
Sciences, Graz, Austria. gert.trausinger@joanneum.at. (10)Joanneum Research
Forschungsgesellschaft m.b.H., HEALTH, Institute for Biomedicine and Health
Sciences, Graz, Austria. frank.sinner@joanneum.at. (11)Department of Internal
Medicine, Medical University of Graz, Graz, Austria. frank.sinner@joanneum.at.
(12)Joanneum Research Forschungsgesellschaft m.b.H., HEALTH, Institute for
Biomedicine and Health Sciences, Graz, Austria. thomas.pieber@medunigraz.at.
(13)Department of Internal Medicine, Medical University of Graz, Graz, Austria.
thomas.pieber@medunigraz.at. (14)Joanneum Research Forschungsgesellschaft m.b.H.,
HEALTH, Institute for Biomedicine and Health Sciences, Graz, Austria.
ca.health@joanneum.at.

BACKGROUND: Untargeted metabolomics generates a huge amount of data. Software
packages for automated data processing are crucial to successfully process these 
data. A variety of such software packages exist, but the outcome of data
processing strongly depends on algorithm parameter settings. If they are not
carefully chosen, suboptimal parameter settings can easily lead to biased
results. Therefore, parameter settings also require optimization. Several
parameter optimization approaches have already been proposed, but a software
package for parameter optimization which is free of intricate experimental
labeling steps, fast and widely applicable is still missing.
RESULTS: We implemented the software package IPO ('Isotopologue Parameter
Optimization') which is fast and free of labeling steps, and applicable to data
from different kinds of samples and data from different methods of liquid
chromatography - high resolution mass spectrometry and data from different
instruments. IPO optimizes XCMS peak picking parameters by using natural, stable 
(13)C isotopic peaks to calculate a peak picking score. Retention time correction
is optimized by minimizing relative retention time differences within peak
groups. Grouping parameters are optimized by maximizing the number of peak groups
that show one peak from each injection of a pooled sample. The different
parameter settings are achieved by design of experiments, and the resulting
scores are evaluated using response surface models. IPO was tested on three
different data sets, each consisting of a training set and test set. IPO resulted
in an increase of reliable groups (146% - 361%), a decrease of non-reliable
groups (3% - 8%) and a decrease of the retention time deviation to one third.
CONCLUSIONS: IPO was successfully applied to data derived from liquid
chromatography coupled to high resolution mass spectrometry from three studies
with different sample types and different chromatographic methods and devices. We
were also able to show the potential of IPO to increase the reliability of
metabolomics data. The source code is implemented in R, tested on Linux and
Windows and it is freely available for download at
https://github.com/glibiseller/IPO . The training sets and test sets can be
downloaded from https://health.joanneum.at/IPO .

DOI: 10.1186/s12859-015-0562-8 
PMCID: PMC4404568
PMID: 25888443  [PubMed - indexed for MEDLINE]


1025. BMC Bioinformatics. 2015 Apr 1;16:108. doi: 10.1186/s12859-015-0516-1.

Efficient representation of uncertainty in multiple sequence alignments using
directed acyclic graphs.

Herman JL(1,)(2), Novák Á(3), Lyngsø R(4), Szabó A(5), Miklós I(6,)(7), Hein
J(8).

Author information: 
(1)Department of Statistics, University of Oxford, 1 South Parks Road, Oxford,
OX1 3TG, UK. herman@stats.ox.ac.uk. (2)Division of Mathematical Biology, National
Institute of Medical Research,, The Ridgeway, London, NW7 1AA, UK.
herman@stats.ox.ac.uk. (3)Department of Statistics, University of Oxford, 1 South
Parks Road, Oxford, OX1 3TG, UK. novak@stats.ox.ac.uk. (4)Department of
Statistics, University of Oxford, 1 South Parks Road, Oxford, OX1 3TG, UK.
rune@lyngsoe.eu. (5)Institute of Computer Science and Control, Hungarian Academy 
of Sciences, Lagymanyosi u. 11., Budapest, 1111, Hungary.
adrienn.szabo@sztaki.mta.hu. (6)Institute of Computer Science and Control,
Hungarian Academy of Sciences, Lagymanyosi u. 11., Budapest, 1111, Hungary.
miklosi@renyi.hu. (7)Department of Stochastics, Rényi Institute, Reáltanoda u.
13-15, Budapest, 1053, Hungary. miklosi@renyi.hu. (8)Department of Statistics,
University of Oxford, 1 South Parks Road, Oxford, OX1 3TG, UK.
hein@stats.ox.ac.uk.

BACKGROUND: A standard procedure in many areas of bioinformatics is to use a
single multiple sequence alignment (MSA) as the basis for various types of
analysis. However, downstream results may be highly sensitive to the alignment
used, and neglecting the uncertainty in the alignment can lead to significant
bias in the resulting inference. In recent years, a number of approaches have
been developed for probabilistic sampling of alignments, rather than simply
generating a single optimum. However, this type of probabilistic information is
currently not widely used in the context of downstream inference, since most
existing algorithms are set up to make use of a single alignment.
RESULTS: In this work we present a framework for representing a set of sampled
alignments as a directed acyclic graph (DAG) whose nodes are alignment columns;
each path through this DAG then represents a valid alignment. Since the
probabilities of individual columns can be estimated from empirical frequencies, 
this approach enables sample-based estimation of posterior alignment
probabilities. Moreover, due to conditional independencies between columns, the
graph structure encodes a much larger set of alignments than the original set of 
sampled MSAs, such that the effective sample size is greatly increased.
CONCLUSIONS: The alignment DAG provides a natural way to represent a distribution
in the space of MSAs, and allows for existing algorithms to be efficiently scaled
up to operate on large sets of alignments. As an example, we show how this can be
used to compute marginal probabilities for tree topologies, averaging over a very
large number of MSAs. This framework can also be used to generate a statistically
meaningful summary alignment; example applications show that this summary
alignment is consistently more accurate than the majority of the alignment
samples, leading to improvements in downstream tree inference. Implementations of
the methods described in this article are available at
http://statalign.github.io/WeaveAlign .

DOI: 10.1186/s12859-015-0516-1 
PMCID: PMC4395974
PMID: 25888064  [PubMed - indexed for MEDLINE]


1026. BMC Bioinformatics. 2015 Mar 25;16:98. doi: 10.1186/s12859-015-0515-2.

aTRAM - automated target restricted assembly method: a fast method for assembling
loci across divergent taxa from next-generation sequencing data.

Allen JM(1), Huang DI(2), Cronk QC(3), Johnson KP(4).

Author information: 
(1)Illinois Natural History Survey, University of Illinois, Champaign, IL, 61820,
USA. juliema@illinois.edu. (2)Department of Botany and Beaty Biodiversity Centre,
University of British Columbia, Vancouver, BC, V6T 1Z4, Canada. daisie@mac.com.
(3)Department of Botany and Beaty Biodiversity Centre, University of British
Columbia, Vancouver, BC, V6T 1Z4, Canada. quentin.cronk@ubc.ca. (4)Illinois
Natural History Survey, University of Illinois, Champaign, IL, 61820, USA.
kpjohnso@illinois.edu.

BACKGROUND: Assembling genes from next-generation sequencing data is not only
time consuming but computationally difficult, particularly for taxa without a
closely related reference genome. Assembling even a draft genome using de novo
approaches can take days, even on a powerful computer, and these assemblies
typically require data from a variety of genomic libraries. Here we describe
software that will alleviate these issues by rapidly assembling genes from
distantly related taxa using a single library of paired-end reads: aTRAM,
automated Target Restricted Assembly Method. The aTRAM pipeline uses a reference 
sequence, BLAST, and an iterative approach to target and locally assemble the
genes of interest.
RESULTS: Our results demonstrate that aTRAM rapidly assembles genes across
distantly related taxa. In comparative tests with a closely related taxon, aTRAM 
assembled the same sequence as reference-based and de novo approaches taking on
average < 1 min per gene. As a test case with divergent sequences, we assembled
>1,000 genes from six taxa ranging from 25 - 110 million years divergent from the
reference taxon. The gene recovery was between 97 - 99% from each taxon.
CONCLUSIONS: aTRAM can quickly assemble genes across distantly-related taxa,
obviating the need for draft genome assembly of all taxa of interest. Because
aTRAM uses a targeted approach, loci can be assembled in minutes depending on the
size of the target. Our results suggest that this software will be useful in
rapidly assembling genes for phylogenomic projects covering a wide taxonomic
range, as well as other applications. The software is freely available
http://www.github.com/juliema/aTRAM .

DOI: 10.1186/s12859-015-0515-2 
PMCID: PMC4380108
PMID: 25887972  [PubMed - indexed for MEDLINE]


1027. BMC Bioinformatics. 2015 Feb 13;16:43. doi: 10.1186/s12859-015-0485-4.

NMF-mGPU: non-negative matrix factorization on multi-GPU systems.

Mejía-Roa E(1), Tabas-Madrid D(2), Setoain J(3), García C(4), Tirado F(5),
Pascual-Montano A(6).

Author information: 
(1)ArTeCS Group, Department of Computer Architecture, Complutense University of
Madrid (UCM), Madrid, 28040, Spain. edgardomejia@fis.ucm.es. (2)Functional
Bioinformatics Group, Biocomputing Unit, National Center for Biotechnology-CSIC, 
UAM, Madrid, 28049, Spain. dtabas@cnb.csic.es. (3)Functional Bioinformatics
Group, Biocomputing Unit, National Center for Biotechnology-CSIC, UAM, Madrid,
28049, Spain. jsetoain@cnb.csic.es. (4)ArTeCS Group, Department of Computer
Architecture, Complutense University of Madrid (UCM), Madrid, 28040, Spain.
garsanca@dacya.ucm.es. (5)ArTeCS Group, Department of Computer Architecture,
Complutense University of Madrid (UCM), Madrid, 28040, Spain.
ptirado@dacya.ucm.es. (6)Functional Bioinformatics Group, Biocomputing Unit,
National Center for Biotechnology-CSIC, UAM, Madrid, 28049, Spain.
pascual@cnb.csic.es.

BACKGROUND: In the last few years, the Non-negative Matrix Factorization ( NMF ) 
technique has gained a great interest among the Bioinformatics community, since
it is able to extract interpretable parts from high-dimensional datasets.
However, the computing time required to process large data matrices may become
impractical, even for a parallel application running on a multiprocessors
cluster. In this paper, we present NMF-mGPU, an efficient and easy-to-use
implementation of the NMF algorithm that takes advantage of the high computing
performance delivered by Graphics-Processing Units ( GPUs ). Driven by the
ever-growing demands from the video-games industry, graphics cards usually
provided in PCs and laptops have evolved from simple graphics-drawing platforms
into high-performance programmable systems that can be used as coprocessors for
linear-algebra operations. However, these devices may have a limited amount of
on-board memory, which is not considered by other NMF implementations on GPU.
RESULTS: NMF-mGPU is based on CUDA ( Compute Unified Device Architecture ), the
NVIDIA's framework for GPU computing. On devices with low memory available, large
input matrices are blockwise transferred from the system's main memory to the
GPU's memory, and processed accordingly. In addition, NMF-mGPU has been
explicitly optimized for the different CUDA architectures. Finally, platforms
with multiple GPUs can be synchronized through MPI ( Message Passing Interface ).
In a four-GPU system, this implementation is about 120 times faster than a single
conventional processor, and more than four times faster than a single GPU device 
(i.e., a super-linear speedup).
CONCLUSIONS: Applications of GPUs in Bioinformatics are getting more and more
attention due to their outstanding performance when compared to traditional
processors. In addition, their relatively low price represents a highly
cost-effective alternative to conventional clusters. In life sciences, this
results in an excellent opportunity to facilitate the daily work of
bioinformaticians that are trying to extract biological meaning out of hundreds
of gigabytes of experimental information. NMF-mGPU can be used "out of the box"
by researchers with little or no expertise in GPU programming in a variety of
platforms, such as PCs, laptops, or high-end GPU clusters. NMF-mGPU is freely
available at https://github.com/bioinfo-cnb/bionmf-gpu .

DOI: 10.1186/s12859-015-0485-4 
PMCID: PMC4339678
PMID: 25887585  [PubMed - indexed for MEDLINE]


1028. BMC Bioinformatics. 2015 Mar 27;16:105. doi: 10.1186/s12859-015-0532-1.

FlowClus: efficiently filtering and denoising pyrosequenced amplicons.

Gaspar JM(1), Thomas WK(2).

Author information: 
(1)Department of Molecular Cellular & Biomedical Sciences, University of New
Hampshire, Durham, NH, USA. jsh58@unh.edu. (2)Department of Molecular Cellular & 
Biomedical Sciences, University of New Hampshire, Durham, NH, USA.
kelley.thomas@unh.edu.

BACKGROUND: Reducing the effects of sequencing errors and PCR artifacts has
emerged as an essential component in amplicon-based metagenomic studies.
Denoising algorithms have been designed that can reduce error rates in mock
community data, but they change the sequence data in a manner that can be
inconsistent with the process of removing errors in studies of real communities. 
In addition, they are limited by the size of the dataset and the sequencing
technology used.
RESULTS: FlowClus uses a systematic approach to filter and denoise reads
efficiently. When denoising real datasets, FlowClus provides feedback about the
process that can be used as the basis to adjust the parameters of the algorithm
to suit the particular dataset. When used to analyze a mock community dataset,
FlowClus produced a lower error rate compared to other denoising algorithms,
while retaining significantly more sequence information. Among its other
attributes, FlowClus can analyze longer reads being generated from all stages of 
454 sequencing technology, as well as from Ion Torrent. It has processed a large 
dataset of 2.2 million GS-FLX Titanium reads in twelve hours; using its more
efficient (but less precise) trie analysis option, this time was further reduced,
to seven minutes.
CONCLUSIONS: Many of the amplicon-based metagenomics datasets generated over the 
last several years have been processed through a denoising pipeline that likely
caused deleterious effects on the raw data. By using FlowClus, one can avoid such
negative outcomes while maintaining control over the filtering and denoising
processes. Because of its efficiency, FlowClus can be used to re-analyze multiple
large datasets together, thereby leading to more standardized conclusions.
FlowClus is freely available on GitHub (jsh58/FlowClus); it is written in C and
supported on Linux.

DOI: 10.1186/s12859-015-0532-1 
PMCID: PMC4380255
PMID: 25885646  [PubMed - indexed for MEDLINE]


1029. BMC Bioinformatics. 2015 Apr 2;16:111. doi: 10.1186/s12859-015-0530-3.

YOC, A new strategy for pairwise alignment of collinear genomes.

Uricaru R(1,)(2,)(3), Michotey C(4), Chiapello H(5,)(6), Rivals E(7).

Author information: 
(1)University of Bordeaux, CNRS / LaBRI, F-33405, Talence, France.
ruricaru@labri.fr. (2)University of Bordeaux, CBiB, F-33000, Bordeaux, France.
ruricaru@labri.fr. (3)LIRMM, UMR 5506, Computational Biology Institute, CNRS,
University of Montpellier 2, Montpellier, France. ruricaru@labri.fr. (4)MIG, UR
1077, INRA, 78026, Jouy-en-Josas cedex, France.
celia.michotey@versailles.inra.fr. (5)MIG, UR 1077, INRA, 78026, Jouy-en-Josas
cedex, France. helene.chiapello@toulouse.inra.fr. (6)MIA-T, UR 0875, INRA, BP
52627, 31326, Castanet-Tolosan cedex, France. helene.chiapello@toulouse.inra.fr. 
(7)LIRMM, UMR 5506, Computational Biology Institute, CNRS, University of
Montpellier 2, Montpellier, France. rivals@lirmm.fr.

BACKGROUND: Comparing and aligning genomes is a key step in analyzing closely
related genomes. Despite the development of many genome aligners in the last 15
years, the problem is not yet fully resolved, even when aligning closely related 
bacterial genomes of the same species. In addition, no procedures are available
to assess the quality of genome alignments or to compare genome aligners.
RESULTS: We designed an original method for pairwise genome alignment, named YOC,
which employs a highly sensitive similarity detection method together with a
recent collinear chaining strategy that allows overlaps. YOC improves the
reliability of collinear genome alignments, while preserving or even improving
sensitivity. We also propose an original qualitative evaluation criterion for
measuring the relevance of genome alignments. We used this criterion to compare
and benchmark YOC with five recent genome aligners on large bacterial genome
datasets, and showed it is suitable for identifying the specificities and the
potential flaws of their underlying strategies.
CONCLUSIONS: The YOC prototype is available at https://github.com/ruricaru/YOC . 
It has several advantages over existing genome aligners: (1) it is based on a
simplified two phase alignment strategy, (2) it is easy to parameterize, (3) it
produces reliable genome alignments, which are easier to analyze and to use.

DOI: 10.1186/s12859-015-0530-3 
PMCID: PMC4411659
PMID: 25885358  [PubMed - indexed for MEDLINE]


1030. PLoS Comput Biol. 2015 Apr 17;11(4):e1004132. doi: 10.1371/journal.pcbi.1004132. 
eCollection 2015.

Loregic: a method to characterize the cooperative logic of regulatory factors.

Wang D(1), Yan KK(1), Sisu C(1), Cheng C(2), Rozowsky J(1), Meyerson W(3),
Gerstein MB(4).

Author information: 
(1)Program in Computational Biology and Bioinformatics, Yale University, New
Haven, Connecticut, United States of America; Department of Molecular Biophysics 
and Biochemistry, Yale University, New Haven, Connecticut, United States of
America. (2)Department of Genetics, Geisel School of Medicine at Dartmouth,
Hanover, New Hampshire, United States of America. (3)School of Medicine, Yale
University, New Haven, Connecticut, United States of America. (4)Program in
Computational Biology and Bioinformatics, Yale University, New Haven,
Connecticut, United States of America; Department of Molecular Biophysics and
Biochemistry, Yale University, New Haven, Connecticut, United States of America; 
Department of Computer Science, Yale University, New Haven, Connecticut, United
States of America.

The topology of the gene-regulatory network has been extensively analyzed. Now,
given the large amount of available functional genomic data, it is possible to go
beyond this and systematically study regulatory circuits in terms of logic
elements. To this end, we present Loregic, a computational method integrating
gene expression and regulatory network data, to characterize the cooperativity of
regulatory factors. Loregic uses all 16 possible two-input-one-output logic gates
(e.g. AND or XOR) to describe triplets of two factors regulating a common target.
We attempt to find the gate that best matches each triplet's observed gene
expression pattern across many conditions. We make Loregic available as a
general-purpose tool (github.com/gersteinlab/loregic). We validate it with known 
yeast transcription-factor knockout experiments. Next, using human ENCODE
ChIP-Seq and TCGA RNA-Seq data, we are able to demonstrate how Loregic
characterizes complex circuits involving both proximally and distally regulating 
transcription factors (TFs) and also miRNAs. Furthermore, we show that MYC, a
well-known oncogenic driving TF, can be modeled as acting independently from
other TFs (e.g., using OR gates) but antagonistically with repressing miRNAs.
Finally, we inter-relate Loregic's gate logic with other aspects of regulation,
such as indirect binding via protein-protein interactions, feed-forward loop
motifs and global regulatory hierarchy.

DOI: 10.1371/journal.pcbi.1004132 
PMCID: PMC4401777
PMID: 25884877  [PubMed - indexed for MEDLINE]


1031. PLoS Comput Biol. 2015 Apr 17;11(4):e1004124. doi: 10.1371/journal.pcbi.1004124. 
eCollection 2015.

Segmentation and tracking of adherens junctions in 3D for the analysis of
epithelial tissue morphogenesis.

Cilla R(1), Mechery V(1), Hernandez de Madrid B(1), Del Signore S(1), Dotu I(2), 
Hatini V(1).

Author information: 
(1)Department of Developmental, Molecular & Chemical Biology. Sackler School of
Graduate Biomedical Sciences, Tufts University School of Medicine, Boston,
Massachusetts, United States of America. (2)Department of Biology, Boston
College, Boston, Massachusetts, United States of America.

Epithelial morphogenesis generates the shape of tissues, organs and embryos and
is fundamental for their proper function. It is a dynamic process that occurs at 
multiple spatial scales from macromolecular dynamics, to cell deformations,
mitosis and apoptosis, to coordinated cell rearrangements that lead to global
changes of tissue shape. Using time lapse imaging, it is possible to observe
these events at a system level. However, to investigate morphogenetic events it
is necessary to develop computational tools to extract quantitative information
from the time lapse data. Toward this goal, we developed an image-based
computational pipeline to preprocess, segment and track epithelial cells in 4D
confocal microscopy data. The computational pipeline we developed, for the first 
time, detects the adherens junctions of epithelial cells in 3D, without the need 
to first detect cell nuclei. We accentuate and detect cell outlines in a series
of steps, symbolically describe the cells and their connectivity, and employ this
information to track the cells. We validated the performance of the pipeline for 
its ability to detect vertices and cell-cell contacts, track cells, and identify 
mitosis and apoptosis in surface epithelia of Drosophila imaginal discs. We
demonstrate the utility of the pipeline to extract key quantitative features of
cell behavior with which to elucidate the dynamics and biomechanical control of
epithelial tissue morphogenesis. We have made our methods and data available as
an open-source multiplatform software tool called TTT
(http://github.com/morganrcu/TTT).

DOI: 10.1371/journal.pcbi.1004124 
PMCID: PMC4401792
PMID: 25884654  [PubMed - indexed for MEDLINE]


1032. PLoS One. 2015 Apr 17;10(4):e0121453. doi: 10.1371/journal.pone.0121453.
eCollection 2015.

CoMeta: classification of metagenomes using k-mers.

Kawulok J(1), Deorowicz S(1).

Author information: 
(1)Institute of Informatics, Silesian University of Technology, Gliwice, Poland.

Nowadays, the study of environmental samples has been developing rapidly.
Characterization of the environment composition broadens the knowledge about the 
relationship between species composition and environmental conditions. An
important element of extracting the knowledge of the sample composition is to
compare the extracted fragments of DNA with sequences derived from known
organisms. In the presented paper, we introduce an algorithm called CoMeta
(Classification of metagenomes), which assigns a query read (a DNA fragment) into
one of the groups previously prepared by the user. Typically, this is one of the 
taxonomic rank (e.g., phylum, genus), however prepared groups may contain
sequences having various functions. In CoMeta, we used the exact method for read 
classification using short subsequences (k-mers) and fast program for indexing
large set of k-mers. In contrast to the most popular methods based on BLAST,
where the query is compared with each reference sequence, we begin the
classification from the top of the taxonomy tree to reduce the number of
comparisons. The presented experimental study confirms that CoMeta outperforms
other programs used in this context. CoMeta is available at
https://github.com/jkawulok/cometa under a free GNU GPL 2 license.

DOI: 10.1371/journal.pone.0121453 
PMCID: PMC4401624
PMID: 25884504  [PubMed - indexed for MEDLINE]


1033. BMC Res Notes. 2015 Mar 7;8:70. doi: 10.1186/s13104-015-1009-z.

Mason: a JavaScript web site widget for visualizing and comparing annotated
features in nucleotide or protein sequences.

Jaschob D(1), Davis TN(2), Riffle M(3,)(4).

Author information: 
(1)Department of Biochemistry, University of Washington, UW Box 357350, 1705 NE
Pacific St, Seattle, WA, 98195-7350, USA. djaschob@uw.edu. (2)Department of
Biochemistry, University of Washington, UW Box 357350, 1705 NE Pacific St,
Seattle, WA, 98195-7350, USA. tdavis@uw.edu. (3)Department of Biochemistry,
University of Washington, UW Box 357350, 1705 NE Pacific St, Seattle, WA,
98195-7350, USA. mriffle@uw.edu. (4)Department of Genome Sciences, University of 
Washington, UW Box 357350, 1705 NE Pacific St, Seattle, WA, 98195-7350, USA.
mriffle@uw.edu.

BACKGROUND: Sequence feature annotations (e.g., protein domain boundaries,
binding sites, and secondary structure predictions) are an essential part of
biological research. Annotations are widely used by scientists during research
and experimental design, and are frequently the result of biological studies. A
generalized and simple means of disseminating and visualizing these data via the 
web would be of value to the research community.
FINDINGS: Mason is a web site widget designed to visualize and compare annotated 
features of one or more nucleotide or protein sequence. Annotated features may be
of virtually any type, ranging from annotating transcription binding sites or
exons and introns in DNA to secondary structure or domain boundaries in proteins.
Mason is simple to use and easy to integrate into web sites. Mason has a highly
dynamic and configurable interface supporting multiple sets of annotations per
sequence, overlapping regions, customization of interface and user-driven events 
(e.g., clicks and text to appear for tooltips). It is written purely in
JavaScript and SVG, requiring no 3(rd) party plugins or browser customization.
CONCLUSIONS: Mason is a solution for dissemination of sequence annotation data on
the web. It is highly flexible, customizable, simple to use, and is designed to
be easily integrated into web sites. Mason is open source and freely available at
https://github.com/yeastrc/mason.

DOI: 10.1186/s13104-015-1009-z 
PMCID: PMC4354989
PMID: 25884379  [PubMed - indexed for MEDLINE]


1034. BMC Syst Biol. 2015;9 Suppl 2:S1. doi: 10.1186/1752-0509-9-S2-S1. Epub 2015 Apr
15.

Bicluster Sampled Coherence Metric (BSCM) provides an accurate environmental
context for phenotype predictions.

Danziger SA, Reiss DJ, Ratushny AV, Smith JJ, Plaisier CL, Aitchison JD, Baliga
NS.

BACKGROUND: Biclustering is a popular method for identifying under which
experimental conditions biological signatures are co-expressed. However, the
general biclustering problem is NP-hard, offering room to focus algorithms on
specific biological tasks. We hypothesize that conditional co-regulation of genes
is a key factor in determining cell phenotype and that accurately segregating
conditions in biclusters will improve such predictions. Thus, we developed a
bicluster sampled coherence metric (BSCM) for determining which conditions and
signals should be included in a bicluster.
RESULTS: Our BSCM calculates condition and cluster size specific p-values, and we
incorporated these into the popular integrated biclustering algorithm cMonkey. We
demonstrate that incorporation of our new algorithm significantly improves
bicluster co-regulation scores (p-value = 0.009) and GO annotation scores
(p-value = 0.004). Additionally, we used a bicluster based signal to predict
whether a given experimental condition will result in yeast peroxisome induction.
Using the new algorithm, the classifier accuracy improves from 41.9% to 76.1%
correct.
CONCLUSIONS: We demonstrate that the proposed BSCM helps determine which signals 
ought to be co-clustered, resulting in more accurately assigned bicluster
membership. Furthermore, we show that BSCM can be extended to more accurately
detect under which experimental conditions the genes are co-clustered. Features
derived from this more accurate analysis of conditional regulation results in a
dramatic improvement in the ability to predict a cellular phenotype in yeast. The
latest cMonkey is available for download at
https://github.com/baliga-lab/cmonkey2. The experimental data and source code
featured in this paper is available http://AitchisonLab.com/BSCM. BSCM has been
incorporated in the official cMonkey release.

DOI: 10.1186/1752-0509-9-S2-S1 
PMCID: PMC4407105
PMID: 25881257  [PubMed - indexed for MEDLINE]


1035. Nucleic Acids Res. 2015 May 19;43(9):4408-28. doi: 10.1093/nar/gkv281. Epub 2015 
Apr 14.

Assessing the translational landscape of myogenic differentiation by ribosome
profiling.

de Klerk E(1), Fokkema IF(1), Thiadens KA(2), Goeman JJ(3), Palmblad M(4), den
Dunnen JT(1), von Lindern M(2), 't Hoen PA(5).

Author information: 
(1)Department of Human Genetics, Leiden University Medical Center, Postzone S4-P,
PO Box 9600, 2300 RC Leiden, The Netherlands. (2)Department of Hematopoiesis,
Sanquin Research and Landsteiner Laboratory, AMC/UvA, 1066CX 125 Amsterdam, The
Netherlands. (3)Biostatistics, Department for Health Evidence, Radboud University
Medical Center, Postzone 133, P.O. Box 9101, 6500 HB Nijmegen, The Netherlands.
(4)Center for Proteomics and Metabolomics, Leiden University Medical Center, 2300
RC Leiden, The Netherlands. (5)Department of Human Genetics, Leiden University
Medical Center, Postzone S4-P, PO Box 9600, 2300 RC Leiden, The Netherlands
P.A.C._t_Hoen@lumc.nl.

The formation of skeletal muscles is associated with drastic changes in protein
requirements known to be safeguarded by tight control of gene transcription and
mRNA processing. The contribution of regulation of mRNA translation during
myogenesis has not been studied so far. We monitored translation during myogenic 
differentiation of C2C12 myoblasts, using a simplified protocol for ribosome
footprint profiling. Comparison of ribosome footprints to total RNA showed that
gene expression is mostly regulated at the transcriptional level. However, a
subset of transcripts, enriched for mRNAs encoding for ribosomal proteins, was
regulated at the level of translation. Enrichment was also found for specific
pathways known to regulate muscle biology. We developed a dedicated pipeline to
identify translation initiation sites (TISs) and discovered 5333 unannotated
TISs, providing a catalog of upstream and alternative open reading frames used
during myogenesis. We identified 298 transcripts with a significant switch in TIS
usage during myogenesis, which was not explained by alternative promoter usage,
as profiled by DeepCAGE. Also these transcripts were enriched for ribosomal
protein genes. This study demonstrates that differential mRNA translation
controls protein expression of specific subsets of genes during myogenesis.
Experimental protocols, analytical workflows, tools and data are available
through public
repositories (http://lumc.github.io/ribosome-profiling-analysis-framework/).

© The Author(s) 2015. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkv281 
PMCID: PMC4482065
PMID: 25873627  [PubMed - indexed for MEDLINE]


1036. Nucleic Acids Res. 2015 Jul 27;43(13):e87. doi: 10.1093/nar/gkv300. Epub 2015 Apr
14.

cMonkey2: Automated, systematic, integrated detection of co-regulated gene
modules for any organism.

Reiss DJ(1), Plaisier CL(2), Wu WJ(2), Baliga NS(3).

Author information: 
(1)Institute for Systems Biology, 401 Terry Ave N, Seattle, WA 98109, USA
dreiss@systemsbiology.org. (2)Institute for Systems Biology, 401 Terry Ave N,
Seattle, WA 98109, USA. (3)Institute for Systems Biology, 401 Terry Ave N,
Seattle, WA 98109, USA Department of Microbiology, University of Washington,
Seattle, WA 98103, USA nbaliga@systemsbiology.org.

The cMonkey integrated biclustering algorithm identifies conditionally
co-regulated modules of genes (biclusters). cMonkey integrates various orthogonal
pieces of information which support evidence of gene co-regulation, and optimizes
biclusters to be supported simultaneously by one or more of these prior
constraints. The algorithm served as the cornerstone for constructing the first
global, predictive Environmental Gene Regulatory Influence Network (EGRIN) model 
for a free-living cell, and has now been applied to many more organisms. However,
due to its computational inefficiencies, long run-time and complexity of various 
input data types, cMonkey was not readily usable by the wider community. To
address these primary concerns, we have significantly updated the cMonkey
algorithm and refactored its implementation, improving its usability and
extendibility. These improvements provide a fully functioning and user-friendly
platform for building co-regulated gene modules and the tools necessary for their
exploration and interpretation. We show, via three separate analyses of data for 
E. coli, M. tuberculosis and H. sapiens, that the updated algorithm and inclusion
of novel scoring functions for new data types (e.g. ChIP-seq and transcription
factor over-expression [TFOE]) improve discovery of biologically informative
co-regulated modules. The complete cMonkey2 software package, including source
code, is available at https://github.com/baliga-lab/cmonkey2.

© The Author(s) 2015. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkv300 
PMCID: PMC4513845
PMID: 25873626  [PubMed - indexed for MEDLINE]


1037. Bioinformatics. 2015 Aug 15;31(16):2683-90. doi: 10.1093/bioinformatics/btv197.
Epub 2015 Apr 10.

Applying stability selection to consistently estimate sparse principal components
in high-dimensional molecular data.

Sill M(1), Saadati M(1), Benner A(1).

Author information: 
(1)Division of Biostatistics, DKFZ, 69120 Heidelberg, Germany.

MOTIVATION: Principal component analysis (PCA) is a basic tool often used in
bioinformatics for visualization and dimension reduction. However, it is known
that PCA may not consistently estimate the true direction of maximal variability 
in high-dimensional, low sample size settings, which are typical for molecular
data. Assuming that the underlying signal is sparse, i.e. that only a fraction of
features contribute to a principal component (PC), this estimation consistency
can be retained. Most existing sparse PCA methods use L1-penalization, i.e. the
lasso, to perform feature selection. But, the lasso is known to lack variable
selection consistency in high dimensions and therefore a subsequent
interpretation of selected features can give misleading results.
RESULTS: We present S4VDPCA, a sparse PCA method that incorporates a subsampling 
approach, namely stability selection. S4VDPCA can consistently select the truly
relevant variables contributing to a sparse PC while also consistently estimate
the direction of maximal variability. The performance of the S4VDPCA is assessed 
in a simulation study and compared to other PCA approaches, as well as to a
hypothetical oracle PCA that 'knows' the truly relevant features in advance and
thus finds optimal, unbiased sparse PCs. S4VDPCA is computationally efficient and
performs best in simulations regarding parameter estimation consistency and
feature selection consistency. Furthermore, S4VDPCA is applied to a publicly
available gene expression data set of medulloblastoma brain tumors. Features
contributing to the first two estimated sparse PCs represent genes significantly 
over-represented in pathways typically deregulated between molecular subgroups of
medulloblastoma.
AVAILABILITY AND IMPLEMENTATION: Software is available at
https://github.com/mwsill/s4vdpca.
CONTACT: m.sill@dkfz.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv197 
PMCID: PMC4528629
PMID: 25861969  [PubMed - indexed for MEDLINE]


1038. Bioinformatics. 2015 Aug 15;31(16):2741-4. doi: 10.1093/bioinformatics/btv204.
Epub 2015 Apr 10.

MetaSV: an accurate and integrative structural-variant caller for next generation
sequencing.

Mohiyuddin M(1), Mu JC(1), Li J(1), Bani Asadi N(1), Gerstein MB(2), Abyzov A(3),
Wong WH(4), Lam HY(1).

Author information: 
(1)Bina Technologies, Roche Sequencing, Redwood City, CA 94065, USA. (2)Program
in Computational Biology and Bioinformatics, Yale University, New Haven, CT
06520, USA. (3)Department of Health Sciences Research, Center for Individualized 
Medicine, Mayo Clinic, Rochester, MN 55905, USA. (4)Department of Statistics,
Stanford University, Stanford, CA 94035, USA and Department of Health Research
and Policy, Stanford University, Stanford, CA 94035, USA.

Structural variations (SVs) are large genomic rearrangements that vary
significantly in size, making them challenging to detect with the relatively
short reads from next-generation sequencing (NGS). Different SV detection methods
have been developed; however, each is limited to specific kinds of SVs with
varying accuracy and resolution. Previous works have attempted to combine
different methods, but they still suffer from poor accuracy particularly for
insertions. We propose MetaSV, an integrated SV caller which leverages multiple
orthogonal SV signals for high accuracy and resolution. MetaSV proceeds by
merging SVs from multiple tools for all types of SVs. It also analyzes
soft-clipped reads from alignment to detect insertions accurately since existing 
tools underestimate insertion SVs. Local assembly in combination with dynamic
programming is used to improve breakpoint resolution. Paired-end and coverage
information is used to predict SV genotypes. Using simulation and experimental
data, we demonstrate the effectiveness of MetaSV across various SV types and
sizes.AVAILABILITY AND IMPLEMENTATION: Code in Python is at
http://bioinform.github.io/metasv/.
CONTACT: rd@bina.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv204 
PMCID: PMC4528635
PMID: 25861968  [PubMed - indexed for MEDLINE]


1039. Genome Biol. 2015 Feb 20;16:39. doi: 10.1186/s13059-015-0604-6.

DGEclust: differential expression analysis of clustered count data.

Vavoulis DV, Francescatto M, Heutink P, Gough J.

We present a statistical methodology, DGEclust, for differential expression
analysis of digital expression data. Our method treats differential expression as
a form of clustering, thus unifying these two concepts. Furthermore, it
simultaneously addresses the problem of how many clusters are supported by the
data and uncertainty in parameter estimation. DGEclust successfully identifies
differentially expressed genes under a number of different scenarios, maintaining
a low error rate and an excellent control of its false discovery rate with
reasonable computational requirements. It is formulated to perform particularly
well on low-replicated data and be applicable to multi-group data. DGEclust is
available at http://dvav.github.io/dgeclust/.

DOI: 10.1186/s13059-015-0604-6 
PMCID: PMC4365804
PMID: 25853652  [PubMed - indexed for MEDLINE]


1040. Bioinformatics. 2015 Aug 15;31(16):2757-60. doi: 10.1093/bioinformatics/btv194.
Epub 2015 Apr 5.

MetaMapR: pathway independent metabolomic network analysis incorporating
unknowns.

Grapov D(1), Wanichthanarak K(1), Fiehn O(2).

Author information: 
(1)National Institutes of Health West Coast Metabolomics Center, Genome Center,
University of California Davis, Davis CA 95616, USA and. (2)National Institutes
of Health West Coast Metabolomics Center, Genome Center, University of California
Davis, Davis CA 95616, USA and King Abdulaziz University, Biochemistry
Department, Jeddah, Saudi Arabia.

Metabolic network mapping is a widely used approach for integration of
metabolomic experimental results with biological domain knowledge. However,
current approaches can be limited by biochemical domain or pathway knowledge
which results in sparse disconnected graphs for real world metabolomic
experiments. MetaMapR integrates enzymatic transformations with metabolite
structural similarity, mass spectral similarity and empirical associations to
generate richly connected metabolic networks. This open source, web-based or
desktop software, written in the R programming language, leverages KEGG and
PubChem databases to derive associations between metabolites even in cases where 
biochemical domain or molecular annotations are unknown. Network calculation is
enhanced through an interface to the Chemical Translation System, which allows
metabolite identifier translation between >200 common biochemical databases.
Analysis results are presented as interactive visualizations or can be exported
as high-quality graphics and numerical tables which can be imported into common
network analysis and visualization tools.AVAILABILITY AND IMPLEMENTATION: Freely 
available at http://dgrapov.github.io/MetaMapR/. Requires R and a modern web
browser. Installation instructions, tutorials and application examples are
available at http://dgrapov.github.io/MetaMapR/.
CONTACT: ofiehn@ucdavis.edu.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv194 
PMCID: PMC4528626
PMID: 25847005  [PubMed - indexed for MEDLINE]


1041. Database (Oxford). 2015 Apr 4;2015:bav032. doi: 10.1093/database/bav032. Print
2015.

Generating a focused view of disease ontology cancer terms for pan-cancer data
integration and analysis.

Wu TJ(1), Schriml LM(1), Chen QR(1), Colbert M(1), Crichton DJ(1), Finney R(1),
Hu Y(1), Kibbe WA(1), Kincaid H(1), Meerzaman D(1), Mitraka E(1), Pan Y(1), Smith
KM(1), Srivastava S(1), Ward S(1), Yan C(1), Mazumder R(2).

Author information: 
(1)Department of Biochemistry and Molecular Medicine, George Washington
University, Washington, DC 20037, USA, Institute for Genome Sciences, University 
of Maryland School of Medicine, Baltimore, MD 21201, USA, Center for
Bioinformatics and Information Technology, National Cancer Institute, 9609
Medical Center Drive, Rockville, MD 20892-9760, USA, NASA Jet Propulsion
Laboratory, Pasadena, CA, USA, Division of Cancer Prevention, National Cancer
Institute, 9609 Medical Center Drive, Rockville, MD 20892-9760, USA, Wellcome
Trust Sanger Institute, Cambridge, UK and McCormick Genomic and Proteomic Center,
George Washington University, Washington, DC 20037, USA. (2)Department of
Biochemistry and Molecular Medicine, George Washington University, Washington, DC
20037, USA, Institute for Genome Sciences, University of Maryland School of
Medicine, Baltimore, MD 21201, USA, Center for Bioinformatics and Information
Technology, National Cancer Institute, 9609 Medical Center Drive, Rockville, MD
20892-9760, USA, NASA Jet Propulsion Laboratory, Pasadena, CA, USA, Division of
Cancer Prevention, National Cancer Institute, 9609 Medical Center Drive,
Rockville, MD 20892-9760, USA, Wellcome Trust Sanger Institute, Cambridge, UK and
McCormick Genomic and Proteomic Center, George Washington University, Washington,
DC 20037, USA Department of Biochemistry and Molecular Medicine, George
Washington University, Washington, DC 20037, USA, Institute for Genome Sciences, 
University of Maryland School of Medicine, Baltimore, MD 21201, USA, Center for
Bioinformatics and Information Technology, National Cancer Institute, 9609
Medical Center Drive, Rockville, MD 20892-9760, USA, NASA Jet Propulsion
Laboratory, Pasadena, CA, USA, Division of Cancer Prevention, National Cancer
Institute, 9609 Medical Center Drive, Rockville, MD 20892-9760, USA, Wellcome
Trust Sanger Institute, Cambridge, UK and McCormick Genomic and Proteomic Center,
George Washington University, Washington, DC 20037, USA mazumder@gwu.edu.

Bio-ontologies provide terminologies for the scientific community to describe
biomedical entities in a standardized manner. There are multiple initiatives that
are developing biomedical terminologies for the purpose of providing better
annotation, data integration and mining capabilities. Terminology resources
devised for multiple purposes inherently diverge in content and structure. A
major issue of biomedical data integration is the development of overlapping
terms, ambiguous classifications and inconsistencies represented across databases
and publications. The disease ontology (DO) was developed over the past decade to
address data integration, standardization and annotation issues for human disease
data. We have established a DO cancer project to be a focused view of cancer
terms within the DO. The DO cancer project mapped 386 cancer terms from the
Catalogue of Somatic Mutations in Cancer (COSMIC), The Cancer Genome Atlas
(TCGA), International Cancer Genome Consortium, Therapeutically Applicable
Research to Generate Effective Treatments, Integrative Oncogenomics and the Early
Detection Research Network into a cohesive set of 187 DO terms represented by 63 
top-level DO cancer terms. For example, the COSMIC term 'kidney, NS, carcinoma,
clear_cell_renal_cell_carcinoma' and TCGA term 'Kidney renal clear cell
carcinoma' were both grouped to the term 'Disease Ontology Identification
(DOID):4467 / renal clear cell carcinoma' which was mapped to the
TopNodes_DOcancerslim term 'DOID:263 / kidney cancer'. Mapping of diverse cancer 
terms to DO and the use of top level terms (DO slims) will enable pan-cancer
analysis across datasets generated from any of the cancer term sources where
pan-cancer means including or relating to all or multiple types of cancer. The
terms can be browsed from the DO web site (http://www.disease-ontology.org) and
downloaded from the DO's Apache Subversion or GitHub repositories. Database URL: 
http://www.disease-ontology.org

© The Author(s) 2015. Published by Oxford University Press.

DOI: 10.1093/database/bav032 
PMCID: PMC4385274
PMID: 25841438  [PubMed - indexed for MEDLINE]


1042. Neuroimage. 2015 Aug 15;117:343-57. doi: 10.1016/j.neuroimage.2015.03.055. Epub
2015 Mar 31.

An automated pipeline for constructing personalized virtual brains from
multimodal neuroimaging data.

Schirner M(1), Rothmeier S(1), Jirsa VK(2), McIntosh AR(3), Ritter P(4).

Author information: 
(1)Dept. Neurology, Charité - University Medicine, Berlin, Germany; Bernstein
Focus State Dependencies of Learning, Bernstein Center for Computational
Neuroscience, Berlin, Germany. (2)Institut de Neurosciences des Systèmes UMR
INSERM 1106, Aix-Marseille Université Faculté de Médecine, Marseille, France.
(3)Rotman Research Institute of Baycrest Centre, University of Toronto, Toronto, 
Canada. (4)Dept. Neurology, Charité - University Medicine, Berlin, Germany;
Bernstein Focus State Dependencies of Learning, Bernstein Center for
Computational Neuroscience, Berlin, Germany; Minerva Research Group BrainModes,
Max Planck Institute for Human Cognitive and Brain Sciences, Leipzig, Germany;
Berlin School of Mind and Brain, Mind and Brain Institute, Humboldt University,
Berlin, Germany. Electronic address: petra.ritter@charite.de.

Large amounts of multimodal neuroimaging data are acquired every year worldwide. 
In order to extract high-dimensional information for computational neuroscience
applications standardized data fusion and efficient reduction into integrative
data structures are required. Such self-consistent multimodal data sets can be
used for computational brain modeling to constrain models with individual
measurable features of the brain, such as done with The Virtual Brain (TVB). TVB 
is a simulation platform that uses empirical structural and functional data to
build full brain models of individual humans. For convenient model construction, 
we developed a processing pipeline for structural, functional and
diffusion-weighted magnetic resonance imaging (MRI) and optionally
electroencephalography (EEG) data. The pipeline combines several state-of-the-art
neuroinformatics tools to generate subject-specific cortical and subcortical
parcellations, surface-tessellations, structural and functional connectomes, lead
field matrices, electrical source activity estimates and region-wise aggregated
blood oxygen level dependent (BOLD) functional MRI (fMRI) time-series. The output
files of the pipeline can be directly uploaded to TVB to create and simulate
individualized large-scale network models that incorporate intra- and
intercortical interaction on the basis of cortical surface triangulations and
white matter tractograpy. We detail the pitfalls of the individual processing
streams and discuss ways of validation. With the pipeline we also introduce novel
ways of estimating the transmission strengths of fiber tracts in whole-brain
structural connectivity (SC) networks and compare the outcomes of different
tractography or parcellation approaches. We tested the functionality of the
pipeline on 50 multimodal data sets. In order to quantify the robustness of the
connectome extraction part of the pipeline we computed several metrics that
quantify its rescan reliability and compared them to other tractography
approaches. Together with the pipeline we present several principles to guide
future efforts to standardize brain model construction. The code of the pipeline 
and the fully processed data sets are made available to the public via The
Virtual Brain website (thevirtualbrain.org) and via github
(https://github.com/BrainModes/TVB-empirical-data-pipeline). Furthermore, the
pipeline can be directly used with High Performance Computing (HPC) resources on 
the Neuroscience Gateway Portal (http://www.nsgportal.org) through a convenient
web-interface.

Copyright © 2015 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2015.03.055 
PMID: 25837600  [PubMed - indexed for MEDLINE]


1043. Anal Chem. 2015 Apr 21;87(8):4104-9. doi: 10.1021/ac504767d. Epub 2015 Apr 8.

High-resolution twin-ion metabolite extraction (HiTIME) mass spectrometry:
nontargeted detection of unknown drug metabolites by isotope labeling, liquid
chromatography mass spectrometry, and automated high-performance computing.

Leeming MG(1), Isaac AP(2), Pope BJ(2,)(3), Cranswick N(4,)(5), Wright CE(4,)(6),
Ziogas J(4,)(6), O'Hair RA(1,)(6), Donald WA(7).

Author information: 
(1)†School of Chemistry and Bio21 Institute of Molecular Science and
Biotechnology, University of Melbourne, 30 Flemington Road, Melbourne, Victoria
3010, Australia. (2)‡Victorian Life Sciences Computation Initiative, University
of Melbourne, 187 Grattan Street, Carlton, Victoria 3010, Australia.
(3)§Department of Computing and Information Systems, University of Melbourne,
Parkville, Victoria 3010, Australia. (4)∥Department of Pharmacology and
Therapeutics, University of Melbourne, Victoria 3010, Australia. (5)¶Royal
Children's Hospital Melbourne, 50 Flemington Road, Victoria 3052, Australia.
(6)⊥ARC Centre of Excellence for Free Radical Chemistry and Biotechnology,
University of Melbourne, Melbourne, Victoria 3010, Australia. (7)#School of
Chemistry, University of New South Wales, Sydney, New South Wales 2052,
Australia.

The metabolic fate of a compound can often determine the success of a new drug
lead. Thus, significant effort is directed toward identifying the metabolites
formed from a given molecule. Here, an automated and nontargeted procedure is
introduced for detecting drug metabolites without authentic metabolite standards 
via the use of stable isotope labeling, liquid chromatography mass spectrometry
(LC/MS), and high-performance computing. LC/MS of blood plasma extracts from rats
that were administered a 1:1 mixture of acetaminophen (APAP) and (13)C6-APAP
resulted in mass spectra that contained "twin" ions for drug metabolites that
were not detected in control spectra (i.e., no APAP administered). Because of the
development of a program (high-resolution twin-ion metabolite extraction; HiTIME)
that can identify twin-ions in high-resolution mass spectra without centroiding
(i.e., reduction of mass spectral peaks to single data points), 9 doublets
corresponding to APAP metabolites were identified. This is nearly twice that
obtained by use of existing programs that make use of centroiding to reduce
computational cost under these conditions with a quadrupole time-of-flight mass
spectrometer. By a manual search for all reported APAP metabolite ions, no
additional twin-ion signals were assigned. These data indicate that all the major
metabolites of APAP and multiple low-abundance metabolites (e.g., acetaminophen
hydroxy- and methoxysulfate) that are rarely reported were detected. This
methodology can be used to detect drug metabolites without prior knowledge of
their identity. HiTIME is freely available from https://github.com/bjpop/HiTIME .

DOI: 10.1021/ac504767d 
PMID: 25818563  [PubMed - indexed for MEDLINE]


1044. J Biomed Semantics. 2015 Mar 21;6:10. doi: 10.1186/s13326-015-0005-5. eCollection
2015.

eNanoMapper: harnessing ontologies to enable data integration for nanomaterial
risk assessment.

Hastings J(1), Jeliazkova N(2), Owen G(1), Tsiliki G(3), Munteanu CR(4),
Steinbeck C(1), Willighagen E(5).

Author information: 
(1)European Molecular Biology Laboratory - European Bioinformatics Institute
(EMBL-EBI), Cambridge, United Kingdom. (2)IdeaConsult Ltd., 4.A.Kanchev str.,
Sofia, Bulgaria. (3)National Technical University of Athens (NTUA), Athens,
Greece. (4)Computer Science Faculty, University of A Coruña, A Coruña, Spain ;
Department of Bioinformatics - BiGCaT, NUTRIM, Maastricht University, Maastricht,
Netherlands. (5)Department of Bioinformatics - BiGCaT, NUTRIM, Maastricht
University, Maastricht, Netherlands.

Engineered nanomaterials (ENMs) are being developed to meet specific application 
needs in diverse domains across the engineering and biomedical sciences (e.g.
drug delivery). However, accompanying the exciting proliferation of novel
nanomaterials is a challenging race to understand and predict their possibly
detrimental effects on human health and the environment. The eNanoMapper project 
(www.enanomapper.net) is creating a pan-European computational infrastructure for
toxicological data management for ENMs, based on semantic web standards and
ontologies. Here, we describe the development of the eNanoMapper ontology based
on adopting and extending existing ontologies of relevance for the nanosafety
domain. The resulting eNanoMapper ontology is available at
http://purl.enanomapper.net/onto/enanomapper.owl. We aim to make the re-use of
external ontology content seamless and thus we have developed a library to
automate the extraction of subsets of ontology content and the assembly of the
subsets into an integrated whole. The library is available (open source) at
http://github.com/enanomapper/slimmer/. Finally, we give a comprehensive survey
of the domain content and identify gap areas. ENM safety is at the boundary
between engineering and the life sciences, and at the boundary between molecular 
granularity and bulk granularity. This creates challenges for the definition of
key entities in the domain, which we also discuss.

DOI: 10.1186/s13326-015-0005-5 
PMCID: PMC4374589
PMID: 25815161  [PubMed]


1045. J Cheminform. 2015 Mar 22;7:10. doi: 10.1186/s13321-015-0061-y. eCollection 2015.

Wikipedia Chemical Structure Explorer: substructure and similarity searching of
molecules from Wikipedia.

Ertl P(1), Patiny L(2), Sander T(3), Rufener C(3), Zasso M(2).

Author information: 
(1)Novartis Institutes for BioMedical Research, Novartis Campus, CH-4056 Basel,
Switzerland. (2)Ecole Polytechnique Fédérale de Lausanne (EPFL), Institute of
Chemical Sciences and Engineering (ISIC), 1015 Lausanne, Switzerland. (3)Actelion
Pharmaceuticals Ltd., Gewerbestrasse 16, CH-4123 Allschwil, Switzerland.

BACKGROUND: Wikipedia, the world's largest and most popular encyclopedia is an
indispensable source of chemistry information. It contains among others also
entries for over 15,000 chemicals including metabolites, drugs, agrochemicals and
industrial chemicals. To provide an easy access to this wealth of information we 
decided to develop a substructure and similarity search tool for chemical
structures referenced in Wikipedia.
RESULTS: We extracted chemical structures from entries in Wikipedia and
implemented a web system allowing structure and similarity searching on these
data. The whole search as well as visualization system is written in JavaScript
and therefore can run locally within a web page and does not require a central
server. The Wikipedia Chemical Structure Explorer is accessible on-line at
www.cheminfo.org/wikipedia and is available also as an open source project from
GitHub for local installation.
CONCLUSIONS: The web-based Wikipedia Chemical Structure Explorer provides a
useful resource for research as well as for chemical education enabling both
researchers and students easy and user friendly chemistry searching and
identification of relevant information in Wikipedia. The tool can also help to
improve quality of chemical entries in Wikipedia by providing potential
contributors regularly updated list of entries with problematic structures. And
last but not least this search system is a nice example of how the modern web
technology can be applied in the field of cheminformatics. Graphical
abstractWikipedia Chemical Structure Explorer allows substructure and similarity 
searches on molecules referenced in Wikipedia.

DOI: 10.1186/s13321-015-0061-y 
PMCID: PMC4374119
PMID: 25815062  [PubMed]


1046. J Comput Aided Mol Des. 2015 May;29(5):397-411. doi: 10.1007/s10822-015-9840-9.
Epub 2015 Mar 26.

Guidelines for the analysis of free energy calculations.

Klimovich PV(1), Shirts MR, Mobley DL.

Author information: 
(1)Department of Pharmaceutical Sciences and Department of Chemistry, University 
of California, Irvine, 147 Bison Modular, Irvine, CA, 92697, USA.

Free energy calculations based on molecular dynamics simulations show
considerable promise for applications ranging from drug discovery to prediction
of physical properties and structure-function studies. But these calculations are
still difficult and tedious to analyze, and best practices for analysis are not
well defined or propagated. Essentially, each group analyzing these calculations 
needs to decide how to conduct the analysis and, usually, develop its own
analysis tools. Here, we review and recommend best practices for analysis
yielding reliable free energies from molecular simulations. Additionally, we
provide a Python tool, alchemical-analysis.py, freely available on GitHub as part
of the pymbar package (located at http://github.com/choderalab/pymbar), that
implements the analysis practices reviewed here for several reference simulation 
packages, which can be adapted to handle data from other packages. Both this
review and the tool covers analysis of alchemical calculations generally,
including free energy estimates via both thermodynamic integration and free
energy perturbation-based estimators. Our Python tool also handles output from
multiple types of free energy calculations, including expanded ensemble and
Hamiltonian replica exchange, as well as standard fixed ensemble calculations. We
also survey a range of statistical and graphical ways of assessing the quality of
the data and free energy estimates, and provide prototypes of these in our tool. 
We hope this tool and discussion will serve as a foundation for more
standardization of and agreement on best practices for analysis of free energy
calculations.

DOI: 10.1007/s10822-015-9840-9 
PMCID: PMC4420631
PMID: 25808134  [PubMed - indexed for MEDLINE]


1047. Nucleic Acids Res. 2015 Jul 13;43(12):e80. doi: 10.1093/nar/gkv242. Epub 2015 Mar
23.

SplicePie: a novel analytical approach for the detection of alternative,
non-sequential and recursive splicing.

Pulyakhina I(1), Gazzoli I(1), 't Hoen PA(1), Verwey N(1), den Dunnen JT(2),
Aartsma-Rus A(1), Laros JF(3).

Author information: 
(1)Department of Human Genetics, Leiden University Medical Center, Leiden, The
Netherlands. (2)Department of Human Genetics, Leiden University Medical Center,
Leiden, The Netherlands Leiden Genome Technology Center, Leiden University
Medical Center, Leiden, The Netherlands. (3)Department of Human Genetics, Leiden 
University Medical Center, Leiden, The Netherlands Leiden Genome Technology
Center, Leiden University Medical Center, Leiden, The Netherlands
j.f.j.laros@lumc.nl.

Erratum in
    Nucleic Acids Res. 2015 Dec 15;43(22):11068. den Dunnen, Johan [Corrected to den 
Dunnen, Johan T].

Alternative splicing is a powerful mechanism present in eukaryotic cells to
obtain a wide range of transcripts and protein isoforms from a relatively small
number of genes. The mechanisms regulating (alternative) splicing and the
paradigm of consecutive splicing have recently been challenged, especially for
genes with a large number of introns. RNA-Seq, a powerful technology using deep
sequencing in order to determine transcript structure and expression levels, is
usually performed on mature mRNA, therefore not allowing detailed analysis of
splicing progression. Sequencing pre-mRNA at different stages of splicing
potentially provides insight into mRNA maturation. Although the number of tools
that analyze total and cytoplasmic RNA in order to elucidate the transcriptome
composition is rapidly growing, there are no tools specifically designed for the 
analysis of nuclear RNA (which contains mixtures of pre- and mature mRNA). We
developed dedicated algorithms to investigate the splicing process. In this
paper, we present a new classification of RNA-Seq reads based on three major
stages of splicing: pre-, intermediate- and post-splicing. Applying this novel
classification we demonstrate the possibility to analyze the order of splicing.
Furthermore, we uncover the potential to investigate the multi-step nature of
splicing, assessing various types of recursive splicing events. We provide the
data that gives biological insight into the order of splicing, show that
non-sequential splicing of certain introns is reproducible and coinciding in
multiple cell lines. We validated our observations with independent experimental 
technologies and showed the reliability of our method. The pipeline, named
SplicePie, is freely available at:
https://github.com/pulyakhina/splicing_analysis_pipeline. The example data can be
found at: https://barmsijs.lumc.nl/HG/irina/example_data.tar.gz.

© The Author(s) 2015. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkv242 
PMCID: PMC4499118
PMID: 25800735  [PubMed - indexed for MEDLINE]


1048. Nat Methods. 2015 May;12(5):433-8. doi: 10.1038/nmeth.3329. Epub 2015 Mar 23.

Identification of active transcriptional regulatory elements from GRO-seq data.

Danko CG(1), Hyland SL(2), Core LJ(3), Martins AL(4), Waters CT(3), Lee HW(3),
Cheung VG(5), Kraus WL(6), Lis JT(3), Siepel A(7).

Author information: 
(1)1] Baker Institute for Animal Health, Cornell University, Ithaca, New York,
USA. [2] Department of Biomedical Sciences, Cornell University, Ithaca, New York,
USA. [3] Department of Biological Statistics and Computational Biology, Cornell
University, Ithaca, New York, USA. (2)Tri-Institutional Training Program in
Computational Biology and Medicine, New York, New York, USA. (3)Department of
Molecular Biology and Genetics, Cornell University, Ithaca, New York, USA.
(4)Graduate Field in Computational Biology, Cornell University, Ithaca, New York,
USA. (5)1] Life Sciences Institute, University of Michigan, Ann Arbor, Michigan, 
USA. [2] Howard Hughes Medical Institute, Chevy Chase, Maryland, USA. (6)1]
Laboratory of Signaling and Gene Regulation, Cecil H. and Ida Green Center for
Reproductive Biology Sciences, University of Texas Southwestern Medical Center,
Dallas, Texas, USA. [2] Division of Basic Research, Department of Obstetrics and 
Gynecology, University of Texas Southwestern Medical Center, Dallas, Texas, USA. 
(7)Department of Biological Statistics and Computational Biology, Cornell
University, Ithaca, New York, USA.

Modifications to the global run-on and sequencing (GRO-seq) protocol that enrich 
for 5'-capped RNAs can be used to reveal active transcriptional regulatory
elements (TREs) with high accuracy. Here, we introduce discriminative
regulatory-element detection from GRO-seq (dREG), a sensitive machine learning
method that uses support vector regression to identify active TREs from GRO-seq
data without requiring cap-based enrichment (https://github.com/Danko-Lab/dREG/).
This approach allows TREs to be assayed together with gene expression levels and 
other transcriptional features in a single experiment. Predicted TREs are more
enriched for several marks of transcriptional activation—including expression
quantitative trait loci, disease-associated polymorphisms, acetylated histone 3
lysine 27 (H3K27ac) and transcription factor binding—than those identified by
alternative functional assays. Using dREG, we surveyed TREs in eight human cell
types and provide new insights into global patterns of TRE function.

DOI: 10.1038/nmeth.3329 
PMCID: PMC4507281
PMID: 25799441  [PubMed - indexed for MEDLINE]


1049. Bioinformatics. 2015 Jul 15;31(14):2364-70. doi: 10.1093/bioinformatics/btv156.
Epub 2015 Mar 19.

Automatic determination of NET (neutrophil extracellular traps) coverage in
fluorescent microscopy images.

Coelho LP(1), Pato C(1), Friães A(1), Neumann A(1), von Köckritz-Blickwede M(1), 
Ramirez M(1), Carriço JA(1).

Author information: 
(1)Unidade de Biofísica e Expressão Genética, Instituto de Medicina Molecular
and.

MOTIVATION: Neutrophil extracellular traps (NETs) are believed to be essential in
controlling several bacterial pathogens. Quantification of NETs in vitro is an
important tool in studies aiming to clarify the biological and chemical factors
contributing to NET production, stabilization and degradation. This estimation
can be performed on the basis of fluorescent microscopy images using appropriate 
labelings. In this context, it is desirable to automate the analysis to eliminate
both the tedious process of manual annotation and possible operator-specific
biases.
RESULTS: We propose a framework for the automated determination of NET content,
based on visually annotated images which are used to train a supervised
machine-learning method. We derive several methods in this framework. The best
results are obtained by combining these into a single prediction. The overall
Q(2) of the combined method is 93%. By having two experts label part of the image
set, we were able to compare the performance of the algorithms to the human
interoperator variability. We find that the two operators exhibited a very high
correlation on their overall assessment of the NET coverage area in the images
(R(2) is 97%), although there were consistent differences in labeling at pixel
level (Q(2), which unlike R(2) does not correct for additive and multiplicative
biases, was only 89%).
AVAILABILITY AND IMPLEMENTATION: Open source software (under the MIT license) is 
available at https://github.com/luispedro/Coelho2015_NetsDetermination for both
reproducibility and application to new data.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv156 
PMID: 25792554  [PubMed - indexed for MEDLINE]


1050. Bioinformatics. 2015 Jul 15;31(14):2318-23. doi: 10.1093/bioinformatics/btv157.
Epub 2015 Mar 18.

Test set bias affects reproducibility of gene signatures.

Patil P(1), Bachant-Winner PO(2), Haibe-Kains B(3), Leek JT(1).

Author information: 
(1)Department of Biostatistics, Johns Hopkins School of Public Health, Baltimore,
MD, USA. (2)Institut de Recherches Cliniques de Montréal, Montreal, Quebec H2W
1R7, Canada. (3)Princess Margaret Cancer Centre, University Health Network,
Toronto, Ontario M5G 1L7, Canada and Department of Medical Biophysics, University
of Toronto, Toronto, Ontario M5G 1L7, Canada.

MOTIVATION: Prior to applying genomic predictors to clinical samples, the genomic
data must be properly normalized to ensure that the test set data are comparable 
to the data upon which the predictor was trained. The most effective
normalization methods depend on data from multiple patients. From a biomedical
perspective, this implies that predictions for a single patient may change
depending on which other patient samples they are normalized with. This test set 
bias will occur when any cross-sample normalization is used before clinical
prediction.
RESULTS: We demonstrate that results from existing gene signatures which rely on 
normalizing test data may be irreproducible when the patient population changes
composition or size using a set of curated, publicly available breast cancer
microarray experiments. As an alternative, we examine the use of gene signatures 
that rely on ranks from the data and show why signatures using rank-based
features can avoid test set bias while maintaining highly accurate
classification, even across platforms.
AVAILABILITY AND IMPLEMENTATION: The code, data and instructions necessary to
reproduce our entire analysis is available at
https://github.com/prpatil/testsetbias.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv157 
PMCID: PMC4495301
PMID: 25788628  [PubMed - indexed for MEDLINE]


1051. Bioinformatics. 2015 Jul 15;31(14):2415-7. doi: 10.1093/bioinformatics/btv152.
Epub 2015 Mar 18.

Efficient visualization of high-throughput targeted proteomics experiments:
TAPIR.

Röst HL(1), Rosenberger G(1), Aebersold R(2), Malmström L(2).

Author information: 
(1)ETH Zurich, Institute of Molecular Systems Biology, CH-8093 Zurich,
Switzerland and Ph.D. Program in Systems Biology, University of Zurich and ETH
Zurich, CH-8057 Zurich, Switzerland. (2)ETH Zurich, Institute of Molecular
Systems Biology, CH-8093 Zurich, Switzerland and.

MOTIVATION: Targeted mass spectrometry comprises a set of powerful methods to
obtain accurate and consistent protein quantification in complex samples. To
fully exploit these techniques, a cross-platform and open-source software stack
based on standardized data exchange formats is required.
RESULTS: We present TAPIR, a fast and efficient Python visualization software for
chromatograms and peaks identified in targeted proteomics experiments. The input 
formats are open, community-driven standardized data formats (mzML for raw data
storage and TraML encoding the hierarchical relationships between transitions,
peptides and proteins). TAPIR is scalable to proteome-wide targeted proteomics
studies (as enabled by SWATH-MS), allowing researchers to visualize
high-throughput datasets. The framework integrates well with existing automated
analysis pipelines and can be extended beyond targeted proteomics to other types 
of analyses.
AVAILABILITY AND IMPLEMENTATION: TAPIR is available for all computing platforms
under the 3-clause BSD license at
https://github.com/msproteomicstools/msproteomicstools.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv152 
PMID: 25788625  [PubMed - indexed for MEDLINE]


1052. Brief Bioinform. 2015 Nov;16(6):932-40. doi: 10.1093/bib/bbv007. Epub 2015 Mar
18.

A comparative study of RNA-seq analysis strategies.

Jänes J, Hu F, Lewin A, Turro E.

Three principal approaches have been proposed for inferring the set of
transcripts expressed in RNA samples using RNA-seq. The simplest approach uses
curated annotations, which assumes the transcripts in a sample are a subset of
the transcripts listed in a curated database. A more ambitious method involves
aligning reads to a reference genome and using the alignments to infer the
transcript structures, possibly with the aid of a curated transcript database.
The most challenging approach is to assemble reads into putative transcripts de
novo without the aid of reference data. We have systematically assessed the
properties of these three approaches through a simulation study. We have found
that the sensitivity of computational transcript set estimation is severely
limited. Computational approaches (both genome-guided and de novo assembly)
produce a large number of artefacts, which are assigned large expression
estimates and absorb a substantial proportion of the signal when performing
expression analysis. The approach using curated annotations shows good expression
correlation even when the annotations are incomplete. Furthermore, any incorrect 
transcripts present in a curated set do not absorb much signal, so it is
preferable to have a curation set with high sensitivity than high precision.
Software to simulate transcript sets, expression values and sequence reads under 
a wider range of parameter values and to compare sensitivity, precision and
signal-to-noise ratios of different methods is freely available online
(https://github.com/boboppie/RSSS) and can be expanded by interested parties to
include methods other than the exemplars presented in this article.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bib/bbv007 
PMCID: PMC4652615
PMID: 25788326  [PubMed - indexed for MEDLINE]


1053. Genome Biol. 2015 Feb 13;16:35. doi: 10.1186/s13059-015-0602-8.

PhyloWGS: reconstructing subclonal composition and evolution from whole-genome
sequencing of tumors.

Deshwar AG, Vembu S, Yung CK, Jang GH, Stein L, Morris Q.

Tumors often contain multiple subpopulations of cancerous cells defined by
distinct somatic mutations. We describe a new method, PhyloWGS, which can be
applied to whole-genome sequencing data from one or more tumor samples to
reconstruct complete genotypes of these subpopulations based on variant allele
frequencies (VAFs) of point mutations and population frequencies of structural
variations. We introduce a principled phylogenic correction for VAFs in loci
affected by copy number alterations and we show that this correction greatly
improves subclonal reconstruction compared to existing methods. PhyloWGS is free,
open-source software, available at https://github.com/morrislab/phylowgs.

DOI: 10.1186/s13059-015-0602-8 
PMCID: PMC4359439
PMID: 25786235  [PubMed - indexed for MEDLINE]


1054. Genome Biol. 2015 Feb 12;16:33. doi: 10.1186/s13059-015-0598-0.

Spectacle: fast chromatin state annotation using spectral learning.

Song J, Chen KC.

Epigenomic data from ENCODE can be used to associate specific combinations of
chromatin marks with regulatory elements in the human genome. Hidden Markov
models and the expectation-maximization (EM) algorithm are often used to analyze 
epigenomic data. However, the EM algorithm can have overfitting problems in data 
sets where the chromatin states show high class-imbalance and it is often slow to
converge. Here we use spectral learning instead of EM and find that our software 
Spectacle overcame these problems. Furthermore, Spectacle is able to find
enhancer subtypes not found by ChromHMM but strongly enriched in GWAS SNPs.
Spectacle is available at https://github.com/jiminsong/Spectacle.

DOI: 10.1186/s13059-015-0598-0 
PMCID: PMC4355146
PMID: 25786205  [PubMed - indexed for MEDLINE]


1055. PeerJ. 2015 Mar 3;3:e808. doi: 10.7717/peerj.808. eCollection 2015.

Arioc: high-throughput read alignment with GPU-accelerated exploration of the
seed-and-extend search space.

Wilton R(1), Budavari T(2), Langmead B(3), Wheelan SJ(4), Salzberg SL(5), Szalay 
AS(6).

Author information: 
(1)Department of Physics and Astronomy, Johns Hopkins University , Baltimore, MD 
, USA. (2)Department of Applied Mathematics and Statistics, Johns Hopkins
University , USA. (3)Department of Computer Science, Johns Hopkins University ,
USA ; Center for Computational Biology, McKusick-Nathans Institute of Genetic
Medicine, Johns Hopkins University , USA. (4)Department of Oncology, Johns
Hopkins University School of Medicine , USA ; Center for Computational Genomics, 
Johns Hopkins University , USA. (5)Department of Computer Science, Johns Hopkins 
University , USA ; Department of Biomedical Engineering, Johns Hopkins University
, USA ; Center for Computational Biology, McKusick-Nathans Institute of Genetic
Medicine, Johns Hopkins University , USA. (6)Department of Physics and Astronomy,
Johns Hopkins University , Baltimore, MD , USA ; Department of Computer Science, 
Johns Hopkins University , USA.

When computing alignments of DNA sequences to a large genome, a key element in
achieving high processing throughput is to prioritize locations in the genome
where high-scoring mappings might be expected. We formulated this task as a
series of list-processing operations that can be efficiently performed on
graphics processing unit (GPU) hardware.We followed this approach in implementing
a read aligner called Arioc that uses GPU-based parallel sort and reduction
techniques to identify high-priority locations where potential alignments may be 
found. We then carried out a read-by-read comparison of Arioc's reported
alignments with the alignments found by several leading read aligners. With
simulated reads, Arioc has comparable or better accuracy than the other read
aligners we tested. With human sequencing reads, Arioc demonstrates significantly
greater throughput than the other aligners we evaluated across a wide range of
sensitivity settings. The Arioc software is available at
https://github.com/RWilton/Arioc. It is released under a BSD open-source license.

DOI: 10.7717/peerj.808 
PMCID: PMC4358639
PMID: 25780763  [PubMed]


1056. Bioinformatics. 2015 Jul 15;31(14):2397-9. doi: 10.1093/bioinformatics/btv142.
Epub 2015 Mar 11.

Structure-PPi: a module for the annotation of cancer-related single-nucleotide
variants at protein-protein interfaces.

Vázquez M(1), Valencia A(1), Pons T(1).

Author information: 
(1)Structural Biology and BioComputing Programme, Spanish National Cancer
Research Centre (CNIO), 28029 Madrid, Spain.

MOTIVATION: The interpretation of cancer-related single-nucleotide variants
(SNVs) considering the protein features they affect, such as known functional
sites, protein-protein interfaces, or relation with already annotated mutations, 
might complement the annotation of genetic variants in the analysis of NGS data. 
Current tools that annotate mutations fall short on several aspects, including
the ability to use protein structure information or the interpretation of
mutations in protein complexes.
RESULTS: We present the Structure-PPi system for the comprehensive analysis of
coding SNVs based on 3D protein structures of protein complexes. The 3D
repository used, Interactome3D, includes experimental and modeled structures for 
proteins and protein-protein complexes. Structure-PPi annotates SNVs with
features extracted from UniProt, InterPro, APPRIS, dbNSFP and COSMIC databases.
We illustrate the usefulness of Structure-PPi with the interpretation of
1 027 122 non-synonymous SNVs from COSMIC and the 1000G Project that provides a
collection of ∼172 700 SNVs mapped onto the protein 3D structure of 8726 human
proteins (43.2% of the 20 214 SwissProt-curated proteins in UniProtKB release
2014_06) and protein-protein interfaces with potential functional implications.
AVAILABILITY AND IMPLEMENTATION: Structure-PPi, along with a user manual and
examples, isavailable at http://structureppi.bioinfo.cnio.es/Structure, the code 
for local installations at https://github.com/Rbbt-Workflows

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv142 
PMCID: PMC4495296
PMID: 25765346  [PubMed - indexed for MEDLINE]


1057. Biotechniques. 2015 Mar 1;58(3):140-2. doi: 10.2144/000114266. eCollection 2015.

SIFTER-T: a scalable and optimized framework for the SIFTER phylogenomic method
of probabilistic protein domain annotation.

Almeida-e-Silva DC(1), Vêncio RZ(1).

Author information: 
(1)Department of Computing and Mathematics FFCLRP-USP, University of Sao Paulo,
Ribeirão Preto, Brazil.

Statistical Inference of Function Through Evolutionary Relationships (SIFTER) is 
a powerful computational platform for probabilistic protein domain annotation.
Nevertheless, SIFTER is not widely used, likely due to usability and scalability 
issues. Here we present SIFTER-T (SIFTER Throughput-optimized), a substantial
improvement over SIFTER's original proof-of-principle implementation. SIFTER-T is
optimized for better performance, allowing it to be used at the genome-wide
scale. Compared to SIFTER 2.0, SIFTER-T achieved an 87-fold performance
improvement using published test data sets for the known annotations recovering
module and a 72.3% speed increase for the gene tree generation module in
quad-core machines, as well as a major decrease in memory usage during the
realignment phase. Memory optimization allowed an expanded set of proteins to be 
handled by SIFTER's probabilistic method. The improvement in performance and
automation that we achieved allowed us to build a web server to bring the power
of Bayesian phylogenomic inference to the genomics community. SIFTER-T and its
online interface are freely available under GNU license at
http://labpib.fmrp.usp.br/methods/SIFTER-t/ and
https://github.com/dcasbioinfo/SIFTER-t.

DOI: 10.2144/000114266 
PMID: 25757547  [PubMed - indexed for MEDLINE]


1058. Bioinformatics. 2015 Jul 15;31(14):2377-9. doi: 10.1093/bioinformatics/btv135.
Epub 2015 Mar 8.

Reducing the search space for causal genetic variants with VASP.

Field MA(1), Cho V(2), Cook MC(3), Enders A(4), Vinuesa CG(1), Whittle B(2),
Andrews TD(1), Goodnow CC(5).

Author information: 
(1)Department of Immunology, John Curtin School of Medical Research, Australian
National University, Canberra City, ACT 2601, Australia. (2)Australian Phenomics 
Facility, Australian National University, Canberra, ACT 2601, Australia.
(3)Department of Immunology, John Curtin School of Medical Research, Australian
National University, Canberra City, ACT 2601, Australia, Department of
Immunology, The Canberra Hospital, Canberra, ACT 2605, Australia. (4)Department
of Immunology, John Curtin School of Medical Research, Australian National
University, Canberra City, ACT 2601, Australia, Rammaciotti Immunisation Genomics
Laboratory, John Curtin School of Medical Research, Australian National
University, Canberra City, ACT 2601, Australia and. (5)Department of Immunology, 
John Curtin School of Medical Research, Australian National University, Canberra 
City, ACT 2601, Australia, Immunogenomics Group, Immunology Research Program,
Garvan Institute of Medical Research, Darlinghurst, NSW 2010, Australia.

MOTIVATION: Increasingly, cost-effective high-throughput DNA sequencing
technologies are being utilized to sequence human pedigrees to elucidate the
genetic cause of a wide variety of human diseases. While numerous tools exist for
variant prioritization within a single genome, the ability to concurrently
analyze variants within pedigrees remains a challenge, especially should there be
no prior indication of the underlying genetic cause of the disease. Here, we
present a tool, variant analysis of sequenced pedigrees (VASP), a flexible data
integration environment capable of producing a summary of pedigree variation,
providing relevant information such as compound heterozygosity, genome phasing
and disease inheritance patterns. Designed to aggregate data across a sequenced
pedigree, VASP allows both powerful filtering and custom prioritization of both
single nucleotide variants (SNVs) and small indels. Hence, clinical and research 
users with prior knowledge of a disease are able to dramatically reduce the
variant search space based on a wide variety of custom prioritization criteria.
AVAILABILITY AND IMPLEMENTATION: Source code available for academic
non-commercial research purposes at https://github.com/mattmattmattmatt/VASP.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv135 
PMCID: PMC4495293
PMID: 25755272  [PubMed - indexed for MEDLINE]


1059. Sci Rep. 2015 Mar 10;5:8930. doi: 10.1038/srep08930.

Metabolomics integrated elementary flux mode analysis in large metabolic
networks.

Gerstl MP(1), Ruckerbauer DE(1), Mattanovich D(1), Jungreuthmayer C(1),
Zanghellini J(1).

Author information: 
(1)1] Austrian Centre of Industrial Biotechnology, Vienna, Austria, EU [2]
Department of Biotechnology, University of Natural Resources and Life Sciences,
Vienna, Austria, EU.

Elementary flux modes (EFMs) are non-decomposable steady-state pathways in
metabolic networks. They characterize phenotypes, quantify robustness or identify
engineering targets. An EFM analysis (EFMA) is currently restricted to
medium-scale models, as the number of EFMs explodes with the network's size.
However, many topologically feasible EFMs are biologically irrelevant. We present
thermodynamic EFMA (tEFMA), which calculates only the small(er) subset of
thermodynamically feasible EFMs. We integrate network embedded thermodynamics
into EFMA and show that we can use the metabolome to identify and remove
thermodynamically infeasible EFMs during an EFMA without losing biologically
relevant EFMs. Calculating only the thermodynamically feasible EFMs strongly
reduces memory consumption and program runtime, allowing the analysis of larger
networks. We apply tEFMA to study the central carbon metabolism of E. coli and
find that up to 80% of its EFMs are thermodynamically infeasible. Moreover, we
identify glutamate dehydrogenase as a bottleneck, when E. coli is grown on
glucose and explain its inactivity as a consequence of network embedded
thermodynamics. We implemented tEFMA as a Java package which is available for
download at https://github.com/mpgerstl/tEFMA.

DOI: 10.1038/srep08930 
PMCID: PMC4354105
PMID: 25754258  [PubMed - indexed for MEDLINE]


1060. J Chem Phys. 2015 Mar 7;142(9):091105. doi: 10.1063/1.4914315.

Communication: Accurate hydration free energies at a wide range of temperatures
from 3D-RISM.

Misin M(1), Fedorov MV(1), Palmer DS(2).

Author information: 
(1)Department of Physics, SUPA, University of Strathclyde, 107 Rottenrow, Glasgow
G4 0NG, United Kingdom. (2)Department of Pure and Applied Chemistry, University
of Strathclyde, Thomas Graham Building, 295 Cathedral Street, Glasgow G1 1XL,
United Kingdom.

We present a new model for computing hydration free energies by 3D reference
interaction site model (3D-RISM) that uses an appropriate initial state of the
system (as suggested by Sergiievskyi et al.). The new adjustment to 3D-RISM
theory significantly improves hydration free energy predictions for various
classes of organic molecules at both ambient and non-ambient temperatures. An
extensive benchmarking against experimental data shows that the accuracy of the
model is comparable to (much more computationally expensive) molecular dynamics
simulations. The calculations can be readily performed with a standard 3D-RISM
algorithm. In our work, we used an open source package AmberTools; a script to
automate the whole procedure is available on the web
(https://github.com/MTS-Strathclyde/ISc).

DOI: 10.1063/1.4914315 
PMID: 25747054  [PubMed]


1061. Bioinformatics. 2015 Jul 15;31(14):2374-6. doi: 10.1093/bioinformatics/btv120.
Epub 2015 Feb 28.

IVA: accurate de novo assembly of RNA virus genomes.

Hunt M(1), Gall A(1), Ong SH(1), Brener J(2), Ferns B(3), Goulder P(2), Nastouli 
E(4), Keane JA(1), Kellam P(5), Otto TD(1).

Author information: 
(1)Wellcome Trust Sanger Institute, Wellcome Trust Genome Campus, Cambridge, UK. 
(2)Department of Paediatrics, University of Oxford, Oxford, UK. (3)Division of
Infection and Immunity, Faculty of Medical Sciences, University College London,
London, UK and. (4)Department of Virology, University College London Hospital NHS
Foundation Trust, London, UK. (5)Wellcome Trust Sanger Institute, Wellcome Trust 
Genome Campus, Cambridge, UK, Division of Infection and Immunity, Faculty of
Medical Sciences, University College London, London, UK and.

MOTIVATION: An accurate genome assembly from short read sequencing data is
critical for downstream analysis, for example allowing investigation of variants 
within a sequenced population. However, assembling sequencing data from virus
samples, especially RNA viruses, into a genome sequence is challenging due to the
combination of viral population diversity and extremely uneven read depth caused 
by amplification bias in the inevitable reverse transcription and polymerase
chain reaction amplification process of current methods.
RESULTS: We developed a new de novo assembler called IVA (Iterative Virus
Assembler) designed specifically for read pairs sequenced at highly variable
depth from RNA virus samples. We tested IVA on datasets from 140 sequenced
samples from human immunodeficiency virus-1 or influenza-virus-infected people
and demonstrated that IVA outperforms all other virus de novo assemblers.
AVAILABILITY AND IMPLEMENTATION: The software runs under Linux, has the GPLv3
licence and is freely available from http://sanger-pathogens.github.io/iva

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv120 
PMCID: PMC4495290
PMID: 25725497  [PubMed - indexed for MEDLINE]


1062. Bioinformatics. 2015 Jul 1;31(13):2066-74. doi: 10.1093/bioinformatics/btv117.
Epub 2015 Feb 27.

hiHMM: Bayesian non-parametric joint inference of chromatin state maps.

Sohn KA(1), Ho JW(1), Djordjevic D(2), Jeong HH(3), Park PJ(2), Kim JH(2).

Author information: 
(1)Department of Information and Computer Engineering, Ajou University, Suwon
443-749, South Korea, Seoul National University Biomedical Informatics (SNUBI),
Division of Biomedical Informatics, Seoul National University College of
Medicine, Seoul 110799, Korea, Systems Biomedical Informatics Research Center,
Seoul National University, Seoul 110799, Korea, Victor Chang Cardiac Research
Institute, Sydney, NSW 2010, Australia, The University of New South Wales,
Sydney, NSW 2052, Australia, Center for Biomedical Informatics, Harvard Medical
School, Boston, MA 02115, USA and Division of Genetics, Department of Medicine,
Brigham and Women's Hospital, Harvard Medical School, Boston, MA 02115, USA
Department of Information and Computer Engineering, Ajou University, Suwon
443-749, South Korea, Seoul National University Biomedical Informatics (SNUBI),
Division of Biomedical Informatics, Seoul National University College of
Medicine, Seoul 110799, Korea, Systems Biomedical Informatics Research Center,
Seoul National University, Seoul 110799, Korea, Victor Chang Cardiac Research
Institute, Sydney, NSW 2010, Australia, The University of New South Wales,
Sydney, NSW 2052, Australia, Center for Biomedical Informatics, Harvard Medical
School, Boston, MA 02115, USA and Division of Genetics, Department of Medicine,
Brigham and Women's Hospital, Harvard Medical School, Boston, MA 02115, USA
Department of Information and Computer Engineering, Ajou University, Suwon
443-749, South Korea, Seoul National University Biomedical Informatics (SNUBI),
Division of Biomedical Informatics, Seoul National University College of
Medicine, Seoul 110799, Korea, Systems Biomedical Informatics Research Center,
Seoul National University, Seoul 110799, Korea, Victor Chang Cardiac Research
Institute, Sydney, NSW 2010, Australia, The University of New South Wales,
Sydney, NSW 2052, Australia, Center for Biomedical Informatics, Harvard Medical
School, Boston, MA 02115, USA and Division of Genetics, Department o
(2)Department of Information and Computer Engineering, Ajou University, Suwon
443-749, South Korea, Seoul National University Biomedical Informatics (SNUBI),
Division of Biomedical Informatics, Seoul National University College of
Medicine, Seoul 110799, Korea, Systems Biomedical Informatics Research Center,
Seoul National University, Seoul 110799, Korea, Victor Chang Cardiac Research
Institute, Sydney, NSW 2010, Australia, The University of New South Wales,
Sydney, NSW 2052, Australia, Center for Biomedical Informatics, Harvard Medical
School, Boston, MA 02115, USA and Division of Genetics, Department of Medicine,
Brigham and Women's Hospital, Harvard Medical School, Boston, MA 02115, USA
Department of Information and Computer Engineering, Ajou University, Suwon
443-749, South Korea, Seoul National University Biomedical Informatics (SNUBI),
Division of Biomedical Informatics, Seoul National University College of
Medicine, Seoul 110799, Korea, Systems Biomedical Informatics Research Center,
Seoul National University, Seoul 110799, Korea, Victor Chang Cardiac Research
Institute, Sydney, NSW 2010, Australia, The University of New South Wales,
Sydney, NSW 2052, Australia, Center for Biomedical Informatics, Harvard Medical
School, Boston, MA 02115, USA and Division of Genetics, Department of Medicine,
Brigham and Women's Hospital, Harvard Medical School, Boston, MA 02115, USA.
(3)Department of Information and Computer Engineering, Ajou University, Suwon
443-749, South Korea, Seoul National University Biomedical Informatics (SNUBI),
Division of Biomedical Informatics, Seoul National University College of
Medicine, Seoul 110799, Korea, Systems Biomedical Informatics Research Center,
Seoul National University, Seoul 110799, Korea, Victor Chang Cardiac Research
Institute, Sydney, NSW 2010, Australia, The University of New South Wales,
Sydney, NSW 2052, Australia, Center for Biomedical Informatics, Harvard Medical
School, Boston, MA 02115, USA and Division of Genetics, Department of Medicine,
Brigham and Women's Hospital, Harvard Medical School, Boston, MA 02115, USA.

MOTIVATION: Genome-wide mapping of chromatin states is essential for defining
regulatory elements and inferring their activities in eukaryotic genomes. A
number of hidden Markov model (HMM)-based methods have been developed to infer
chromatin state maps from genome-wide histone modification data for an individual
genome. To perform a principled comparison of evolutionarily distant epigenomes, 
we must consider species-specific biases such as differences in genome size,
strength of signal enrichment and co-occurrence patterns of histone
modifications.
RESULTS: Here, we present a new Bayesian non-parametric method called
hierarchically linked infinite HMM (hiHMM) to jointly infer chromatin state maps 
in multiple genomes (different species, cell types and developmental stages)
using genome-wide histone modification data. This flexible framework provides a
new way to learn a consistent definition of chromatin states across multiple
genomes, thus facilitating a direct comparison among them. We demonstrate the
utility of this method using synthetic data as well as multiple modENCODE
ChIP-seq datasets.
CONCLUSION: The hierarchical and Bayesian non-parametric formulation in our
approach is an important extension to the current set of methodologies for
comparative chromatin landscape analysis.
AVAILABILITY AND IMPLEMENTATION: Source codes are available at
https://github.com/kasohn/hiHMM. Chromatin data are available at
http://encode-x.med.harvard.edu/data_sets/chromatin/.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv117 
PMCID: PMC4481846
PMID: 25725496  [PubMed - indexed for MEDLINE]


1063. Bioinformatics. 2015 Jul 1;31(13):2061-5. doi: 10.1093/bioinformatics/btv121.
Epub 2015 Feb 27.

Mammalian genome evolution is governed by multiple pacemakers.

Duchêne S(1), Ho SY(1).

Author information: 
(1)School of Biological Sciences, University of Sydney, Sydney, NSW 2006,
Australia.

Genomic evolution is shaped by a dynamic combination of mutation, selection and
genetic drift. These processes lead to evolutionary rate variation across loci
and among lineages. In turn, interactions between these two forms of rate
variation can produce residual effects, whereby the pattern of among-lineage rate
heterogeneity varies across loci. The nature of rate variation is encapsulated in
the pacemaker models of genome evolution, which differ in the degree of
importance assigned to residual effects: none (Universal Pacemaker), some
(Multiple Pacemaker) or total (Degenerate Multiple Pacemaker). Here we use a
phylogenetic method to partition the rate variation across loci, allowing
comparison of these pacemaker models. Our analysis of 431 genes from 29 mammalian
taxa reveals that rate variation across these genes can be explained by 13
pacemakers, consistent with the Multiple Pacemaker model. We find no evidence
that these pacemakers correspond to gene function. Our results have important
consequences for understanding the factors driving genomic evolution and for
molecular-clock analyses.AVAILABILITY AND IMPLEMENTATION: ClockstaR-G is freely
available for download from github
(https://github.com/sebastianduchene/clockstarg).

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv121 
PMID: 25725495  [PubMed - indexed for MEDLINE]


1064. Mol Phylogenet Evol. 2015 Apr;85:180-8. doi: 10.1016/j.ympev.2015.02.009. Epub
2015 Feb 23.

MitoPhAST, a new automated mitogenomic phylogeny tool in the post-genomic era
with a case study of 89 decapod mitogenomes including eight new freshwater
crayfish mitogenomes.

Tan MH(1), Gan HM(2), Schultz MB(3), Austin CM(4).

Author information: 
(1)School of Science, Monash University Malaysia, Jalan Lagoon Selatan, Bandar
Sunway, 46150 Petaling Jaya, Selangor, Malaysia; Monash University Malaysia
Genomics Facility, Jalan Lagoon Selatan, Bandar Sunway, 46150 Petaling Jaya,
Selangor, Malaysia. Electronic address: tan.mun.hua@monash.edu. (2)School of
Science, Monash University Malaysia, Jalan Lagoon Selatan, Bandar Sunway, 46150
Petaling Jaya, Selangor, Malaysia; Monash University Malaysia Genomics Facility, 
Jalan Lagoon Selatan, Bandar Sunway, 46150 Petaling Jaya, Selangor, Malaysia.
Electronic address: gan.han.ming@monash.edu. (3)Faculty of Medical and Dental
Health Sciences, The University of Melbourne, Bio21 Research Institute, 30
Flemington Rd, Parkville, Victoria 3010, Australia. Electronic address:
mark.schultz@unimelb.edu.au. (4)School of Science, Monash University Malaysia,
Jalan Lagoon Selatan, Bandar Sunway, 46150 Petaling Jaya, Selangor, Malaysia;
Monash University Malaysia Genomics Facility, Jalan Lagoon Selatan, Bandar
Sunway, 46150 Petaling Jaya, Selangor, Malaysia. Electronic address:
chris.austin@monash.edu.

Erratum in
    Mol Phylogenet Evol. 2015 Jun;87(1):118.

The increased rate at which complete mitogenomes are being sequenced and their
increasing use for phylogenetic studies have resulted in a bioinformatic
bottleneck in preparing and utilising such data for phylogenetic analysis. Hence,
we present MitoPhAST, an automated tool that (1) identifies annotated
protein-coding gene features and generates a standardised, concatenated and
partitioned amino acid alignment directly from complete/partial
GenBank/EMBL-format mitogenome flat files, (2) generates a maximum likelihood
phylogenetic tree using optimised protein models and (3) reports various
mitochondrial genes and sequence information in a table format. To demonstrate
the capacity of MitoPhAST in handling a large dataset, we used 81 publicly
available decapod mitogenomes, together with eight new complete mitogenomes of
Australian freshwater crayfishes, including the first for the genus Gramastacus, 
to undertake an updated test of the monophyly of the major groups of the order
Decapoda and their phylogenetic relationships. The recovered phylogenetic trees
using both Bayesian and ML methods support the results of studies using fragments
of mtDNA and nuclear markers and other smaller-scale studies using whole
mitogenomes. In comparison to the fragment-based phylogenies, nodal support
values are generally higher despite reduced taxon sampling suggesting there is
value in utilising more fully mitogenomic data. Additionally, the simple table
output from MitoPhAST provides an efficient summary and statistical overview of
the mitogenomes under study at the gene level, allowing the identification of
missing or duplicated genes and gene rearrangements. The finding of new mtDNA
gene rearrangements in several genera of Australian freshwater crayfishes
indicates that this group has undergone an unusually high rate of evolutionary
change for this organelle compared to other major families of decapod
crustaceans. As a result, freshwater crayfishes are likely to be a useful model
for studies designed to understand the evolution of mtDNA rearrangements. We
anticipate that our bioinformatics pipeline will substantially help
mitogenome-based studies increase the speed, accuracy and efficiency of
phylogenetic studies utilising mitogenome information. MitoPhAST is available for
download at https://github.com/mht85/MitoPhAST.

Copyright © 2015 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.ympev.2015.02.009 
PMID: 25721538  [PubMed - indexed for MEDLINE]


1065. Bioinformatics. 2015 Jul 1;31(13):2075-83. doi: 10.1093/bioinformatics/btv128.
Epub 2015 Feb 25.

An event-driven approach for studying gene block evolution in bacteria.

Ream DC(1), Bankapur AR(1), Friedberg I(2).

Author information: 
(1)Department of Microbiology, Miami University, Oxford, OH, USA and Department
of Computer Science and Software Engineering, Miami University, Oxford, OH, USA. 
(2)Department of Microbiology, Miami University, Oxford, OH, USA and Department
of Computer Science and Software Engineering, Miami University, Oxford, OH, USA
Department of Microbiology, Miami University, Oxford, OH, USA and Department of
Computer Science and Software Engineering, Miami University, Oxford, OH, USA.

MOTIVATION: Gene blocks are genes co-located on the chromosome. In many cases,
gene blocks are conserved between bacterial species, sometimes as operons, when
genes are co-transcribed. The conservation is rarely absolute: gene loss, gain,
duplication, block splitting and block fusion are frequently observed. An open
question in bacterial molecular evolution is that of the formation and breakup of
gene blocks, for which several models have been proposed. These models, however, 
are not generally applicable to all types of gene blocks, and consequently cannot
be used to broadly compare and study gene block evolution. To address this
problem, we introduce an event-based method for tracking gene block evolution in 
bacteria.
RESULTS: We show here that the evolution of gene blocks in proteobacteria can be 
described by a small set of events. Those include the insertion of genes into, or
the splitting of genes out of a gene block, gene loss, and gene duplication. We
show how the event-based method of gene block evolution allows us to determine
the evolutionary rateand may be used to trace the ancestral states of their
formation. We conclude that the event-based method can be used to help us
understand the formation of these important bacterial genomic structures.
AVAILABILITY AND IMPLEMENTATION: The software is available under GPLv3 license on
http://github.com/reamdc1/gene_block_evolution.git. Supplementary online
material: http://iddo-friedberg.net/operon-evolution

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv128 
PMCID: PMC4481853
PMID: 25717195  [PubMed - indexed for MEDLINE]


1066. BMC Genomics. 2015;16 Suppl 2:S1. doi: 10.1186/1471-2164-16-S2-S1. Epub 2015 Jan 
21.

MixClone: a mixture model for inferring tumor subclonal populations.

Li Y, Xie X.

BACKGROUND: Tumor genomes are often highly heterogeneous, consisting of genomes
from multiple subclonal types. Complete characterization of all subclonal types
is a fundamental need in tumor genome analysis. With the advancement of
next-generation sequencing, computational methods have recently been developed to
infer tumor subclonal populations directly from cancer genome sequencing data.
Most of these methods are based on sequence information from somatic point
mutations, However, the accuracy of these algorithms depends crucially on the
quality of the somatic mutations returned by variant calling algorithms, and
usually requires a deep coverage to achieve a reasonable level of accuracy.
RESULTS: We describe a novel probabilistic mixture model, MixClone, for inferring
the cellular prevalences of subclonal populations directly from whole genome
sequencing of paired normal-tumor samples. MixClone integrates sequence
information of somatic copy number alterations and allele frequencies within a
unified probabilistic framework. We demonstrate the utility of the method using
both simulated and real cancer sequencing datasets, and show that it
significantly outperforms existing methods for inferring tumor subclonal
populations. The MixClone package is written in Python and is publicly available 
at https://github.com/uci-cbcl/MixClone.
CONCLUSIONS: The probabilistic mixture model proposed here provides a new
framework for subclonal analysis based on cancer genome sequencing data. By
applying the method to both simulated and real cancer sequencing data, we show
that integrating sequence information from both somatic copy number alterations
and allele frequencies can significantly improve the accuracy of inferring tumor 
subclonal populations.

DOI: 10.1186/1471-2164-16-S2-S1 
PMCID: PMC4331709
PMID: 25707430  [PubMed - indexed for MEDLINE]


1067. Hum Mutat. 2015 Apr;36(4):E2423-9. doi: 10.1002/humu.22771. Epub 2015 Mar 16.

Oncotator: cancer variant annotation tool.

Ramos AH(1), Lichtenstein L, Gupta M, Lawrence MS, Pugh TJ, Saksena G, Meyerson
M, Getz G.

Author information: 
(1)Cancer Program, Broad Institute, Cambridge, MA 02142, USA; Department of
Medical Oncology, Dana-Farber Cancer Institute, Boston, MA 02115, USA; Department
of Pathology, Harvard Medical School, Boston, MA 02115, USA; Cancer Center and
Department of Pathology, Massachusetts General Hospital, Boston, MA 02114, USA.

Oncotator is a tool for annotating genomic point mutations and short nucleotide
insertions/deletions (indels) with variant- and gene-centric information relevant
to cancer researchers. This information is drawn from 14 different publicly
available resources that have been pooled and indexed, and we provide an
extensible framework to add additional data sources. Annotations linked to
variants range from basic information, such as gene names and functional
classification (e.g. missense), to cancer-specific data from resources such as
the Catalogue of Somatic Mutations in Cancer (COSMIC), the Cancer Gene Census,
and The Cancer Genome Atlas (TCGA). For local use, Oncotator is freely available 
as a python module hosted on Github
(https://github.com/broadinstitute/oncotator). Furthermore, Oncotator is also
available as a web service and web application at
http://www.broadinstitute.org/oncotator/.

© 2015 WILEY PERIODICALS, INC.

DOI: 10.1002/humu.22771 
PMID: 25703262  [PubMed - indexed for MEDLINE]


1068. Bioinformatics. 2015 Jul 1;31(13):2199-201. doi: 10.1093/bioinformatics/btv106.
Epub 2015 Feb 19.

Annocript: a flexible pipeline for the annotation of transcriptomes able to
identify putative long noncoding RNAs.

Musacchia F(1), Basu S(1), Petrosino G(1), Salvemini M(1), Sanges R(1).

Author information: 
(1)Biology and Evolution of Marine Organisms, Stazione Zoologica "Anton Dohrn",
Villa Comunale, 80121, Naples, Italy and Department of Biology, University of
Naples Federico II, Via Mezzocannone 8, 80134, Naples, Italy.

The eukaryotic transcriptome is composed of thousands of coding and long
non-coding RNAs (lncRNAs). However, we lack a software platform to identify both 
RNA classes in a given transcriptome. Here we introduce Annocript, a pipeline
that combines the annotation of protein coding transcripts with the prediction of
putative lncRNAs in whole transcriptomes. It downloads and indexes the needed
databases, runs the analysis and produces human readable and standard outputs
together with summary statistics of the whole analysis.AVAILABILITY AND
IMPLEMENTATION: Annocript is distributed under the GNU General Public License
(version 3 or later) and is freely available at
https://github.com/frankMusacchia/Annocript.
CONTACT: remo.sanges@szn.it.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv106 
PMID: 25701574  [PubMed - indexed for MEDLINE]


1069. Bioinformatics. 2015 Jul 1;31(13):2202-4. doi: 10.1093/bioinformatics/btv112.
Epub 2015 Feb 19.

Unified representation of genetic variants.

Tan A(1), Abecasis GR(1), Kang HM(1).

Author information: 
(1)Department of Biostatistics and Center for Statistical Genetics, University of
Michigan, Ann Arbor, MI 48109, USA.

A genetic variant can be represented in the Variant Call Format (VCF) in multiple
different ways. Inconsistent representation of variants between variant callers
and analyses will magnify discrepancies between them and complicate variant
filtering and duplicate removal. We present a software tool vt normalize that
normalizes representation of genetic variants in the VCF. We formally define
variant normalization as the consistent representation of genetic variants in an 
unambiguous and concise way and derive a simple general algorithm to enforce it. 
We demonstrate the inconsistent representation of variants across existing
sequence analysis tools and show that our tool facilitates integration of diverse
variant types and call sets.AVAILABILITY AND IMPLEMENTATION: The source code is
available for download at http://github.com/atks/vt. More detailed documentation 
is available at http://genome.sph.umich.edu/wiki/Variant_Normalization.
CONTACT: hmkang@umich.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv112 
PMCID: PMC4481842
PMID: 25701572  [PubMed - indexed for MEDLINE]


1070. Bioinformatics. 2015 Jul 1;31(13):2232-4. doi: 10.1093/bioinformatics/btv111.
Epub 2015 Feb 19.

tEFMA: computing thermodynamically feasible elementary flux modes in metabolic
networks.

Gerstl MP(1), Jungreuthmayer C(1), Zanghellini J(1).

Author information: 
(1)Austrian Centre of Industrial Biotechnology, Vienna, Austria and Department of
Biotechnology, University of Natural Resources and Life Sciences, Vienna, Austria
Austrian Centre of Industrial Biotechnology, Vienna, Austria and Department of
Biotechnology, University of Natural Resources and Life Sciences, Vienna,
Austria.

: Elementary flux modes (EFMs) are important structural tools for the analysis of
metabolic networks. It is known that many topologically feasible EFMs are
biologically irrelevant. Therefore, tools are needed to find the relevant ones.
We present thermodynamic tEFM analysis (tEFMA) which uses the cellular metabolome
to avoid the enumeration of thermodynamically infeasible EFMs. Specifically,
given a metabolic network and a not necessarily complete metabolome, tEFMA
efficiently returns the full set of thermodynamically feasible EFMs consistent
with the metabolome. Compared with standard approaches, tEFMA strongly reduces
the memory consumption and the overall runtime. Thus tEFMA provides a new way to 
analyze unbiasedly hitherto inaccessible large-scale metabolic
networks.AVAILABILITY AND IMPLEMENTATION: https://github.com/mpgerstl/tEFMA
CONTACT: : christian.jungreuthmayer@boku.ac.at or juergen.zanghellini@boku.ac.at
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv111 
PMID: 25701571  [PubMed - indexed for MEDLINE]


1071. Appl Plant Sci. 2015 Feb 9;3(2). pii: apps.1400088. doi: 10.3732/apps.1400088.
eCollection 2015.

MatrixConverter: Facilitating construction of phenomic character matrices.

Liu J(1), Endara L(2), Burleigh JG(2).

Author information: 
(1)Department of Biology, University of Florida, P.O. Box 118526, Gainesville,
Florida 32611 USA ; State Key Laboratory of Software Engineering, Computer
School, Wuhan University, Wuhan 430072, People's Republic of China. (2)Department
of Biology, University of Florida, P.O. Box 118526, Gainesville, Florida 32611
USA.

•PREMISE OF THE STUDY: While numerous software packages enable scientists to
evaluate molecular data and transform them for phylogenetic analyses, few such
tools exist for phenomic data. We introduce MatrixConverter, a program that helps
expedite and facilitate the transformation of raw phenomic character data into
discrete character matrices that can be used in most evolutionary inference
programs. •
METHODS AND RESULTS: MatrixConverter is an open source program written in Java; a
platform-independent binary executable, as well as sample data sets and a user's 
manual, are available at
https://github.com/gburleigh/MatrixConverter/tree/master/distribution.
MatrixConverter has a simple, intuitive user interface that enables the user to
immediately begin scoring phenomic characters. We demonstrate the performance of 
MatrixConverter on a phenomic data set from cycads. •
CONCLUSIONS: New technologies and software make it possible to obtain phenomic
data from species across the tree of life, and MatrixConverter helps to transform
these new data for evolutionary or ecological inference.

DOI: 10.3732/apps.1400088 
PMCID: PMC4332142
PMID: 25699217  [PubMed]


1072. Nucleic Acids Res. 2015 Apr 30;43(8):e54. doi: 10.1093/nar/gkv100. Epub 2015 Feb 
17.

Inferential modeling of 3D chromatin structure.

Wang S(1), Xu J(2), Zeng J(3).

Author information: 
(1)Department of Automation, Tsinghua University, Beijing 100084, P.R. China.
(2)Toyota Technological Institute at Chicago, 6045 S Kenwood, IL 60637, USA.
(3)Institute for Interdisciplinary Information Sciences, Tsinghua University,
Beijing 100084, P.R. China MOE Key Laboratory of Bioinformatics, Tsinghua
University, Beijing 100084, P.R. China zengjy321@tsinghua.edu.cn.

For eukaryotic cells, the biological processes involving regulatory DNA elements 
play an important role in cell cycle. Understanding 3D spatial arrangements of
chromosomes and revealing long-range chromatin interactions are critical to
decipher these biological processes. In recent years, chromosome conformation
capture (3C) related techniques have been developed to measure the interaction
frequencies between long-range genome loci, which have provided a great
opportunity to decode the 3D organization of the genome. In this paper, we
develop a new Bayesian framework to derive the 3D architecture of a chromosome
from 3C-based data. By modeling each chromosome as a polymer chain, we define the
conformational energy based on our current knowledge on polymer physics and use
it as prior information in the Bayesian framework. We also propose an
expectation-maximization (EM) based algorithm to estimate the unknown parameters 
of the Bayesian model and infer an ensemble of chromatin structures based on
interaction frequency data. We have validated our Bayesian inference approach
through cross-validation and verified the computed chromatin conformations using 
the geometric constraints derived from fluorescence in situ hybridization (FISH) 
experiments. We have further confirmed the inferred chromatin structures using
the known genetic interactions derived from other studies in the literature. Our 
test results have indicated that our Bayesian framework can compute an accurate
ensemble of 3D chromatin conformations that best interpret the distance
constraints derived from 3C-based data and also agree with other sources of
geometric constraints derived from experimental evidence in the previous studies.
The source code of our approach can be found in
https://github.com/wangsy11/InfMod3DGen.

© The Author(s) 2015. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gkv100 
PMCID: PMC4417147
PMID: 25690896  [PubMed - indexed for MEDLINE]


1073. Viruses. 2015 Feb 16;7(2):781-97. doi: 10.3390/v7020781.

Bioinformatics tools for small genomes, such as hepatitis B virus.

Bell TG(1), Kramvis A(2).

Author information: 
(1)Hepatitis Virus Diversity Research Programme (HVDRP), Department of Internal
Medicine, School of Clinical Medicine, Faculty of Health Sciences, University of 
the Witwatersrand, Johannesburg 2050, South Africa. TrevorGrahamBell@gmail.com.
(2)Hepatitis Virus Diversity Research Programme (HVDRP), Department of Internal
Medicine, School of Clinical Medicine, Faculty of Health Sciences, University of 
the Witwatersrand, Johannesburg 2050, South Africa. Anna.Kramvis@wits.ac.za.

DNA sequence analysis is undertaken in many biological research laboratories. The
workflow consists of several steps involving the bioinformatic processing of
biological data. We have developed a suite of web-based online bioinformatic
tools to assist with processing, analysis and curation of DNA sequence data. Most
of these tools are genome-agnostic, with two tools specifically designed for
hepatitis B virus sequence data. Tools in the suite are able to process sequence 
data from Sanger sequencing, ultra-deep amplicon resequencing (pyrosequencing)
and chromatograph (trace files), as appropriate. The tools are available online
at no cost and are aimed at researchers without specialist technical computer
knowledge. The tools can be accessed at
http://hvdr.bioinf.wits.ac.za/SmallGenomeTools, and the source code is available 
online at https://github.com/DrTrevorBell/SmallGenomeTools.

DOI: 10.3390/v7020781 
PMCID: PMC4353916
PMID: 25690798  [PubMed - indexed for MEDLINE]


1074. Bioinformatics. 2015 Jul 1;31(13):2084-90. doi: 10.1093/bioinformatics/btv086.
Epub 2015 Feb 16.

RAPTR-SV: a hybrid method for the detection of structural variants.

Bickhart DM(1), Hutchison JL(1), Xu L(1), Schnabel RD(1), Taylor JF(1), Reecy
JM(1), Schroeder S(1), Van Tassell CP(1), Sonstegard TS(1), Liu GE(1).

Author information: 
(1)Animal Genomics and Improvement Laboratory, ARS, USDA, Beltsville, MD 20705,
USA, Department of Animal and Avian Sciences, University of Maryland, College
Park, MD 20705, USA, Division of Animal Sciences, University of Missouri,
Columbia, MO 65211, USA and Department of Animal Science, Iowa State University, 
Ames, IA 50011, USA.

MOTIVATION: Identification of structural variants (SVs) in sequence data results 
in a large number of false positive calls using existing software, which
overburdens subsequent validation.
RESULTS: Simulations using RAPTR-SV and other, similar algorithms for SV
detection revealed that RAPTR-SV had superior sensitivity and precision, as it
recovered 66.4% of simulated tandem duplications with a precision of 99.2%. When 
compared with calls made by Delly and LUMPY on available datasets from the 1000
genomes project, RAPTR-SV showed superior sensitivity for tandem duplications, as
it identified 2-fold more duplications than Delly, while making ∼85% fewer
duplication predictions.
AVAILABILITY AND IMPLEMENTATION: RAPTR-SV is written in Java and uses new
features in the collections framework in the latest release of the Java version 8
language specifications. A compiled version of the software, instructions for
usage and test results files are available on the GitHub repository page:
https://github.com/njdbickhart/RAPTR-SV.
CONTACT: derek.bickhart@ars.usda.gov.

Published by Oxford University Press 2015. This work is written by US Government 
employees and is in the public domain in the US.

DOI: 10.1093/bioinformatics/btv086 
PMID: 25686638  [PubMed - indexed for MEDLINE]


1075. Bioinformatics. 2015 Jun 15;31(12):2040-2. doi: 10.1093/bioinformatics/btv089.
Epub 2015 Feb 13.

A trimming-and-retrieving alignment scheme for reduced representation bisulfite
sequencing.

Wang X(1), Yu X(2), Zhu W(2), McCombie WR(2), Antoniou E(2), Powers RS(3),
Davidson NO(2), Li E(2), Williams J(2).

Author information: 
(1)Department of Preventive Medicine, Department of Biomedical Informatics, and
Department of Applied Mathematics and Statistics, Stony Brook University, Stony
Brook, NY 11794, Department of Biostatistics, Yale University, New Haven, CT
06520, Cold Spring Harbor Laboratory, Cold Spring Harbor, NY 11724, Department of
Pathology, Stony Brook University, Stony Brook, NY 11794, Department of Medicine,
Washington University St Louis, St Louis, MO 63110 and Department of Medicine,
Stony Brook University, Stony Brook, NY 11794, USA Department of Preventive
Medicine, Department of Biomedical Informatics, and Department of Applied
Mathematics and Statistics, Stony Brook University, Stony Brook, NY 11794,
Department of Biostatistics, Yale University, New Haven, CT 06520, Cold Spring
Harbor Laboratory, Cold Spring Harbor, NY 11724, Department of Pathology, Stony
Brook University, Stony Brook, NY 11794, Department of Medicine, Washington
University St Louis, St Louis, MO 63110 and Department of Medicine, Stony Brook
University, Stony Brook, NY 11794, USA Department of Preventive Medicine,
Department of Biomedical Informatics, and Department of Applied Mathematics and
Statistics, Stony Brook University, Stony Brook, NY 11794, Department of
Biostatistics, Yale University, New Haven, CT 06520, Cold Spring Harbor
Laboratory, Cold Spring Harbor, NY 11724, Department of Pathology, Stony Brook
University, Stony Brook, NY 11794, Department of Medicine, Washington University 
St Louis, St Louis, MO 63110 and Department of Medicine, Stony Brook University, 
Stony Brook, NY 11794, USA. (2)Department of Preventive Medicine, Department of
Biomedical Informatics, and Department of Applied Mathematics and Statistics,
Stony Brook University, Stony Brook, NY 11794, Department of Biostatistics, Yale 
University, New Haven, CT 06520, Cold Spring Harbor Laboratory, Cold Spring
Harbor, NY 11724, Department of Pathology, Stony Brook University, Stony Brook,
NY 11794, Department of Medicine, Washington University St Louis, St Louis, MO
63110 and Department of Medicine, Stony Brook University, Stony Brook, NY 11794, 
USA. (3)Department of Preventive Medicine, Department of Biomedical Informatics, 
and Department of Applied Mathematics and Statistics, Stony Brook University,
Stony Brook, NY 11794, Department of Biostatistics, Yale University, New Haven,
CT 06520, Cold Spring Harbor Laboratory, Cold Spring Harbor, NY 11724, Department
of Pathology, Stony Brook University, Stony Brook, NY 11794, Department of
Medicine, Washington University St Louis, St Louis, MO 63110 and Department of
Medicine, Stony Brook University, Stony Brook, NY 11794, USA Department of
Preventive Medicine, Department of Biomedical Informatics, and Department of
Applied Mathematics and Statistics, Stony Brook University, Stony Brook, NY
11794, Department of Biostatistics, Yale University, New Haven, CT 06520, Cold
Spring Harbor Laboratory, Cold Spring Harbor, NY 11724, Department of Pathology, 
Stony Brook University, Stony Brook, NY 11794, Department of Medicine, Washington
University St Louis, St Louis, MO 63110 and Department of Medicine, Stony Brook
University, Stony Brook, NY 11794, USA.

Currently available bisulfite sequencing tools frequently suffer from low mapping
rates and low methylation calls, especially for data generated from the Illumina 
sequencer, NextSeq. Here, we introduce a sequential trimming-and-retrieving
alignment approach for investigating DNA methylation patterns, which
significantly improves the number of mapped reads and covered CpG sites. The
method is implemented in an automated analysis toolkit for processing bisulfite
sequencing reads.AVAILABILITY AND IMPLEMENTATION:
http://mysbfiles.stonybrook.edu/~xuefenwang/software.html and
https://github.com/xfwang/BStools.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv089 
PMCID: PMC4481698
PMID: 25681254  [PubMed - indexed for MEDLINE]


1076. Bioinformatics. 2015 Jun 15;31(12):1988-98. doi: 10.1093/bioinformatics/btv063.
Epub 2015 Feb 9.

A multiobjective memetic algorithm for PPI network alignment.

Clark C(1), Kalita J(1).

Author information: 
(1)Department of Computer Science, University of Colorado Colorado Springs,
Colorado Springs, CO 80918, USA.

MOTIVATION: There recently has been great interest in aligning protein-protein
interaction (PPI) networks to identify potentially orthologous proteins between
species. It is thought that the topological information contained in these
networks will yield better orthology predictions than sequence similarity alone. 
Recent work has found that existing aligners have difficulty making use of both
topological and sequence similarity when aligning, with either one or the other
being better matched. This can be at least partially attributed to the fact that 
existing aligners try to combine these two potentially conflicting objectives
into a single objective.
RESULTS: We present Optnetalign, a multiobjective memetic algorithm for the
problem of PPI network alignment that uses extremely efficient swap-based local
search, mutation and crossover operations to create a population of alignments.
This algorithm optimizes the conflicting goals of topological and sequence
similarity using the concept of Pareto dominance, exploring the tradeoff between 
the two objectives as it runs. This allows us to produce many high-quality
candidate alignments in a single run. Our algorithm produces alignments that are 
much better compromises between topological and biological match quality than
previous work, while better characterizing the diversity of possible good
alignments between two networks. Our aligner's results have several interesting
implications for future research on alignment evaluation, the design of network
alignment objectives and the interpretation of alignment results.
AVAILABILITY AND IMPLEMENTATION: The C++ source code to our program, along with
compilation and usage instructions, is available at
https://github.com/crclark/optnetaligncpp/

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv063 
PMID: 25667548  [PubMed - indexed for MEDLINE]


1077. Nat Methods. 2015 Apr;12(4):332-4. doi: 10.1038/nmeth.3285. Epub 2015 Feb 9.

Accurate liability estimation improves power in ascertained case-control studies.

Weissbrod O(1), Lippert C(2), Geiger D(1), Heckerman D(2).

Author information: 
(1)Computer Science Department, Technion - Israel Institute of Technology, Haifa,
Israel. (2)eScience Group, Microsoft Research, Los Angeles, California, USA.

Linear mixed models (LMMs) have emerged as the method of choice for confounded
genome-wide association studies. However, the performance of LMMs in nonrandomly 
ascertained case-control studies deteriorates with increasing sample size. We
propose a framework called LEAP (liability estimator as a phenotype;
https://github.com/omerwe/LEAP) that tests for association with estimated latent 
values corresponding to severity of phenotype, and we demonstrate that this can
lead to a substantial power increase.

DOI: 10.1038/nmeth.3285 
PMID: 25664543  [PubMed - indexed for MEDLINE]


1078. Bioinformatics. 2015 Jun 15;31(12):2035-7. doi: 10.1093/bioinformatics/btv057.
Epub 2015 Feb 5.

NxTrim: optimized trimming of Illumina mate pair reads.

O'Connell J(1), Schulz-Trieglaff O(1), Carlson E(1), Hims MM(1), Gormley NA(1),
Cox AJ(1).

Author information: 
(1)Computational Biology Group and Technology Development, Illumina Cambridge
Ltd., Chesterford Research Park, Little Chesterford, Essex CB10 1XL, UK.

MOTIVATION: Mate pair protocols add to the utility of paired-end sequencing by
boosting the genomic distance spanned by each pair of reads, potentially allowing
larger repeats to be bridged and resolved. The Illumina Nextera Mate Pair (NMP)
protocol uses a circularization-based strategy that leaves behind 38-bp adapter
sequences, which must be computationally removed from the data. While 'adapter
trimming' is a well-studied area of bioinformatics, existing tools do not fully
exploit the particular properties of NMP data and discard more data than is
necessary.
RESULTS: We present NxTrim, a tool that strives to discard as little sequence as 
possible from NMP reads. NxTrim makes full use of the sequence on both sides of
the adapter site to build 'virtual libraries' of mate pairs, paired-end reads and
single-ended reads. For bacterial data, we show that aggregating these datasets
allows a single NMP library to yield an assembly whose quality compares
favourably to that obtained from regular paired-end reads.
AVAILABILITY AND IMPLEMENTATION: The source code is available at
https://github.com/sequencing/NxTrim

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv057 
PMID: 25661542  [PubMed - indexed for MEDLINE]


1079. Sensors (Basel). 2015 Feb 3;15(2):3362-78. doi: 10.3390/s150203362.

Real-time noise removal for line-scanning hyperspectral devices using a minimum
noise fraction-based approach.

Bjorgan A(1), Randeberg LL(2).

Author information: 
(1)Department of Electronics and Telecommunications, Norwegian University of
Science and Technology, 7491 Trondheim, Norway. asgeir.bjorgan@iet.ntnu.no.
(2)Department of Electronics and Telecommunications, Norwegian University of
Science and Technology, 7491 Trondheim, Norway. lise.randeberg@iet.ntnu.no.

Processing line-by-line and in real-time can be convenient for some applications 
of line-scanning hyperspectral imaging technology. Some types of processing, like
inverse modeling and spectral analysis, can be sensitive to noise. The MNF
(minimum noise fraction) transform provides suitable denoising performance, but
requires full image availability for the estimation of image and noise
statistics. In this work, a modified algorithm is proposed. Incrementally-updated
statistics enables the algorithm to denoise the image line-by-line. The denoising
performance has been compared to conventional MNF and found to be equal. With a
satisfying denoising performance and real-time implementation, the developed
algorithm can denoise line-scanned hyperspectral images in real-time. The
elimination of waiting time before denoised data are available is an important
step towards real-time visualization of processed hyperspectral data. The source 
code can be found at http://www.github.com/ntnu-bioopt/mnf. This includes an
implementation of conventional MNF denoising.

DOI: 10.3390/s150203362 
PMCID: PMC4367363
PMID: 25654717  [PubMed - indexed for MEDLINE]


1080. Genome Biol. 2015 Jan 5;16:7. doi: 10.1186/s13059-014-0558-0.

Identification of novel fusion genes in lung cancer using breakpoint assembly of 
transcriptome sequencing data.

Fernandez-Cuesta L, Sun R, Menon R, George J, Lorenz S, Meza-Zepeda LA, Peifer M,
Plenker D, Heuckmann JM, Leenders F, Zander T, Dahmen I, Koker M, Schöttle J,
Ullrich RT, Altmüller J, Becker C, Nürnberg P, Seidel H, Böhm D, Göke F, Ansén S,
Russell PA, Wright GM, Wainer Z, Solomon B, Petersen I, Clement JH, Sänger J,
Brustugun OT, Helland Å, Solberg S, Lund-Iversen M, Buettner R, Wolf J, Brambilla
E, Vingron M, Perner S, Haas SA, Thomas RK.

Genomic translocation events frequently underlie cancer development through
generation of gene fusions with oncogenic properties. Identification of such
fusion transcripts by transcriptome sequencing might help to discover new
potential therapeutic targets. We developed TRUP (Tumor-specimen suited RNA-seq
Unified Pipeline) (https://github.com/ruping/TRUP), a computational approach that
combines split-read and read-pair analysis with de novo assembly for the
identification of chimeric transcripts in cancer specimens. We apply TRUP to
RNA-seq data of different tumor types, and find it to be more sensitive than
alternative tools in detecting chimeric transcripts, such as secondary
rearrangements in EML4-ALK-positive lung tumors, or recurrent inactivating
rearrangements affecting RASSF8.

DOI: 10.1186/s13059-014-0558-0 
PMCID: PMC4300615
PMID: 25650807  [PubMed - indexed for MEDLINE]


1081. Bioinformatics. 2015 Jun 15;31(12):1999-2006. doi: 10.1093/bioinformatics/btv072.
Epub 2015 Feb 2.

Incorporating peak grouping information for alignment of multiple liquid
chromatography-mass spectrometry datasets.

Wandy J(1), Daly R(1), Breitling R(1), Rogers S(1).

Author information: 
(1)School of Computing Science, University of Glasgow, Glasgow, UK, School of
Computing and Mathematical Sciences, Liverpool John Moores University,
Merseyside, UK and Manchester Centre for Synthetic Biology of Fine and Speciality
Chemicals (SYNBIOCHEM), Manchester Institute of Biotechnology, University of
Manchester, Manchester, UK.

MOTIVATION: The combination of liquid chromatography and mass spectrometry
(LC/MS) has been widely used for large-scale comparative studies in systems
biology, including proteomics, glycomics and metabolomics. In almost all
experimental design, it is necessary to compare chromatograms across biological
or technical replicates and across sample groups. Central to this is the peak
alignment step, which is one of the most important but challenging preprocessing 
steps. Existing alignment tools do not take into account the structural
dependencies between related peaks that coelute and are derived from the same
metabolite or peptide. We propose a direct matching peak alignment method for
LC/MS data that incorporates related peaks information (within each LC/MS run)
and investigate its effect on alignment performance (across runs). The groupings 
of related peaks necessary for our method can be obtained from any peak
clustering method and are built into a pair-wise peak similarity score function. 
The similarity score matrix produced is used by an approximation algorithm for
the weighted matching problem to produce the actual alignment result.
RESULTS: We demonstrate that related peak information can improve alignment
performance. The performance is evaluated on a set of benchmark datasets, where
our method performs competitively compared to other popular alignment tools.
AVAILABILITY: The proposed alignment method has been implemented as a stand-alone
application in Python, available for download at
http://github.com/joewandy/peak-grouping-alignment.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv072 
PMCID: PMC4760236
PMID: 25649621  [PubMed - indexed for MEDLINE]


1082. Bioinformatics. 2015 Jun 15;31(12):1897-903. doi: 10.1093/bioinformatics/btv046. 
Epub 2015 Feb 3.

Analysis of nanopore data using hidden Markov models.

Schreiber J(1), Karplus K(1).

Author information: 
(1)Nanopore Group, Department of Biomolecular Engineering, University of
California Santa Cruz, CA 95064, USA.

MOTIVATION: Nanopore-based sequencing techniques can reconstruct properties of
biosequences by analyzing the sequence-dependent ionic current steps produced as 
biomolecules pass through a pore. Typically this involves alignment of new data
to a reference, where both reference construction and alignment have been
performed by hand.
RESULTS: We propose an automated method for aligning nanopore data to a reference
through the use of hidden Markov models. Several features that arise from prior
processing steps and from the class of enzyme used can be simply incorporated
into the model. Previously, the M2MspA nanopore was shown to be sensitive enough 
to distinguish between cytosine, methylcytosine and hydroxymethylcytosine. We
validated our automated methodology on a subset of that data by automatically
calculating an error rate for the distinction between the three cytosine variants
and show that the automated methodology produces a 2-3% error rate, lower than
the 10% error rate from previous manual segmentation and alignment.
AVAILABILITY AND IMPLEMENTATION: The data, output, scripts and tutorials
replicating the analysis are available at
https://github.com/UCSCNanopore/Data/tree/master/Automation.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv046 
PMCID: PMC4553831
PMID: 25649617  [PubMed - indexed for MEDLINE]


1083. Mol Cell Proteomics. 2015 Apr;14(4):1137-47. doi: 10.1074/mcp.O114.042259. Epub
2015 Feb 3.

xiNET: cross-link network maps with residue resolution.

Combe CW(1), Fischer L(1), Rappsilber J(2).

Author information: 
(1)From the ‡Wellcome Trust Centre for Cell Biology, School of Biological
Sciences, University of Edinburgh, Edinburgh EH9 3BF, United Kingdom; (2)From the
‡Wellcome Trust Centre for Cell Biology, School of Biological Sciences,
University of Edinburgh, Edinburgh EH9 3BF, United Kingdom; §Department of
Bioanalytics, Institute of Biotechnology, Technische Universität Berlin, 13355
Berlin, Germany juri.rappsilber@ed.ac.uk.

xiNET is a visualization tool for exploring cross-linking/mass spectrometry
results. The interactive maps of the cross-link network that it generates are a
type of node-link diagram. In these maps xiNET displays: (1) residue resolution
positional information including linkage sites and linked peptides; (2) all types
of cross-linking reaction product; (3) ambiguous results; and, (4) additional
sequence information such as domains. xiNET runs in a browser and exports vector 
graphics which can be edited in common drawing packages to create publication
quality figures.AVAILABILITY: xiNET is open source, released under the Apache
version 2 license. Results can be viewed by uploading data to
http://crosslinkviewer.org/ or by downloading the software from
http://github.com/colin-combe/crosslink-viewer and running it locally.

© 2015 by The American Society for Biochemistry and Molecular Biology, Inc.

DOI: 10.1074/mcp.O114.042259 
PMCID: PMC4390258
PMID: 25648531  [PubMed - indexed for MEDLINE]


1084. J Sep Sci. 2015 Mar;38(6):965-74. doi: 10.1002/jssc.201401235. Epub 2015 Feb 23.

Robust alignment of chromatograms by statistically analyzing the shifts matrix
generated by moving window fast Fourier transform cross-correlation.

Zhang M(1), Wen M, Zhang ZM, Lu H, Liang Y, Zhan D.

Author information: 
(1)College of Chemistry and Chemical Engineering, Central South University,
Changsha, P. R. China.

Retention time shift is one of the most challenging problems during the
preprocessing of massive chromatographic datasets. Here, an improved version of
the moving window fast Fourier transform cross-correlation algorithm is presented
to perform nonlinear and robust alignment of chromatograms by analyzing the
shifts matrix generated by moving window procedure. The shifts matrix in
retention time can be estimated by fast Fourier transform cross-correlation with 
a moving window procedure. The refined shift of each scan point can be obtained
by calculating the mode of corresponding column of the shifts matrix. This
version is simple, but more effective and robust than the previously published
moving window fast Fourier transform cross-correlation method. It can handle
nonlinear retention time shift robustly if proper window size has been selected. 
The window size is the only one parameter needed to adjust and optimize. The
properties of the proposed method are investigated by comparison with the
previous moving window fast Fourier transform cross-correlation and recursive
alignment by fast Fourier transform using chromatographic datasets. The pattern
recognition results of a gas chromatography mass spectrometry dataset of
metabolic syndrome can be improved significantly after preprocessing by this
method. Furthermore, the proposed method is available as an open source package
at https://github.com/zmzhang/MWFFT2.

© 2015 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim.

DOI: 10.1002/jssc.201401235 
PMID: 25645318  [PubMed - indexed for MEDLINE]


1085. Bioinformatics. 2015 Jun 1;31(11):1827-9. doi: 10.1093/bioinformatics/btv059.
Epub 2015 Feb 1.

Transposome: a toolkit for annotation of transposable element families from
unassembled sequence reads.

Staton SE(1), Burke JM(1).

Author information: 
(1)Department of Genetics and Department of Plant Biology, University of Georgia,
Athens, GA 30602, USA.

MOTIVATION: Transposable elements (TEs) can be found in virtually all eukaryotic 
genomes and have the potential to produce evolutionary novelty. Despite the broad
taxonomic distribution of TEs, the evolutionary history of these sequences is
largely unknown for many taxa due to a lack of genomic resources and
identification methods. Given that most TE annotation methods are designed to
work on genome assemblies, we sought to develop a method to provide a
fine-grained classification of TEs from DNA sequence reads. Here, we present a
toolkit for the efficient annotation of TE families from low-coverage
whole-genome shotgun (WGS) data, enabling the rapid identification of TEs in a
large number of taxa. We compared our software, Transposome, with other
approaches for annotating repeats from WGS data, and we show that it offers
significant improvements in run time and produces more precise estimates of
genomic repeat abundance. Transposome may also be used as a general toolkit for
working with Next Generation Sequencing (NGS) data, and for constructing custom
genome analysis pipelines.
AVAILABILITY AND IMPLEMENTATION: The source code for Transposome is freely
available (http://sestaton.github.io/Transposome), implemented in Perl and is
supported on Linux.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv059 
PMID: 25644271  [PubMed - indexed for MEDLINE]


1086. Methods Cell Biol. 2015;125:353-72. doi: 10.1016/bs.mcb.2014.10.017. Epub 2015
Jan 8.

Quantification of collagen contraction in three-dimensional cell culture.

Kopanska KS(1), Bussonnier M(1), Geraldo S(2), Simon A(2), Vignjevic D(2), Betz
T(1).

Author information: 
(1)Centre de Recherche, Institut Curie, Paris Cedex 05, France; Centre National
de la Recherche Scientifique, Paris Cedex 05, France; UPMC University Paris VI,
Paris, France. (2)Centre de Recherche, Institut Curie, Paris Cedex 05, France;
Centre National de la Recherche Scientifique, Paris Cedex 05, France.

Many different cell types including fibroblasts, smooth muscle cells, endothelial
cells, and cancer cells exert traction forces on the fibrous components of the
extracellular matrix. This can be observed as matrix contraction both macro- and 
microscopically in three-dimensional (3D) tissues models such as collagen type I 
gels. The quantification of local contraction at the micron scale, including its 
directionality and speed, in correlation with other parameters such as cell
invasion, local protein or gene expression, can provide useful information to
study wound healing, organism development, and cancer metastasis. In this
article, we present a set of tools to quantify the flow dynamics of collagen
contraction, induced by cells migrating out of a multicellular cancer spheroid
into a three-dimensional (3D) collagen matrix. We adapted a pseudo-speckle
technique that can be applied to bright-field and fluorescent microscopy time
series. The image analysis presented here is based on an in-house written
software developed in the Matlab (Mathworks) programming environment. The
analysis program is freely available from GitHub following the link:
http://dx.doi.org/10.5281/zenodo.10116. This tool provides an automatized
technique to measure collagen contraction that can be utilized in different 3D
cellular systems.

Copyright © 2015 Elsevier Inc. All rights reserved.

DOI: 10.1016/bs.mcb.2014.10.017 
PMID: 25640438  [PubMed - indexed for MEDLINE]


1087. Bioinformatics. 2015 Jun 15;31(12):1913-9. doi: 10.1093/bioinformatics/btv053.
Epub 2015 Jan 31.

Starcode: sequence clustering based on all-pairs search.

Zorita E(1), Cuscó P(1), Filion GJ(1).

Author information: 
(1)Genome Architecture, Gene Regulation, Stem Cells and Cancer Programme, Centre 
for Genomic Regulation (CRG), Dr. Aiguader 88, 08003 Barcelona and Universitat
Pompeu Fabra (UPF), 08002 Barcelona, Spain Genome Architecture, Gene Regulation, 
Stem Cells and Cancer Programme, Centre for Genomic Regulation (CRG), Dr.
Aiguader 88, 08003 Barcelona and Universitat Pompeu Fabra (UPF), 08002 Barcelona,
Spain.

MOTIVATION: The increasing throughput of sequencing technologies offers new
applications and challenges for computational biology. In many of those
applications, sequencing errors need to be corrected. This is particularly
important when sequencing reads from an unknown reference such as random DNA
barcodes. In this case, error correction can be done by performing a pairwise
comparison of all the barcodes, which is a computationally complex problem.
RESULTS: Here, we address this challenge and describe an exact algorithm to
determine which pairs of sequences lie within a given Levenshtein distance. For
error correction or redundancy reduction purposes, matched pairs are then merged 
into clusters of similar sequences. The efficiency of starcode is attributable to
the poucet search, a novel implementation of the Needleman-Wunsch algorithm
performed on the nodes of a trie. On the task of matching random barcodes,
starcode outperforms sequence clustering algorithms in both speed and precision.
AVAILABILITY AND IMPLEMENTATION: The C source code is available at
http://github.com/gui11aume/starcode.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv053 
PMCID: PMC4765884
PMID: 25638815  [PubMed - indexed for MEDLINE]


1088. Bioinformatics. 2015 Jun 1;31(11):1824-6. doi: 10.1093/bioinformatics/btv056.
Epub 2015 Jan 30.

RAMPART: a workflow management system for de novo genome assembly.

Mapleson D(1), Drou N(1), Swarbreck D(1).

Author information: 
(1)The Genome Analysis Centre, Norwich Research Park, Norwich NR4 7UH, UK.

MOTIVATION: The de novo assembly of genomes from whole- genome shotgun sequence
data is a computationally intensive, multi-stage task and it is not known a
priori which methods and parameter settings will produce optimal results. In
current de novo assembly projects, a popular strategy involves trying many
approaches, using different tools and settings, and then comparing and
contrasting the results in order to select a final assembly for publication.
RESULTS: Herein, we present RAMPART, a configurable workflow management system
for de novo genome assembly, which helps the user identify combinations of
third-party tools and settings that provide good results for their particular
genome and sequenced reads. RAMPART is designed to exploit High performance
computing environments, such as clusters and shared memory systems, where
available.
AVAILABILITY AND IMPLEMENTATION: RAMPART is available under the GPLv3 license at:
https://github.com/TGAC/RAMPART.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv056 
PMCID: PMC4443680
PMID: 25637556  [PubMed - indexed for MEDLINE]


1089. Bioinformatics. 2015 Jun 1;31(11):1830-2. doi: 10.1093/bioinformatics/btv049.
Epub 2015 Jan 27.

MetAmp: combining amplicon data from multiple markers for OTU analysis.

Zhbannikov IY(1), Foster JA(2).

Author information: 
(1)Graduate Program in Bioinformatics and Computational Biology, University of
Idaho and Institute of Bioinformatics and Evolutionary Studies (IBEST),
University of Idaho, Moscow, ID, USA. (2)Graduate Program in Bioinformatics and
Computational Biology, University of Idaho and Institute of Bioinformatics and
Evolutionary Studies (IBEST), University of Idaho, Moscow, ID, USA Graduate
Program in Bioinformatics and Computational Biology, University of Idaho and
Institute of Bioinformatics and Evolutionary Studies (IBEST), University of
Idaho, Moscow, ID, USA.

MOTIVATION: We present a novel method and corresponding application, MetAmp, to
combine amplicon data from multiple genomic markers into Operational Taxonomic
Units (OTUs) for microbial community analysis, calibrating the markers using data
from known microbial genomes. When amplicons for multiple markers such as the 16S
rRNA gene hypervariable regions are available, MetAmp improves the accuracy of
OTU-based methods for characterizing bacterial composition and community
structure. MetAmp works best with at least three markers, and is applicable to
non-bacterial analyses and to non 16S markers. Our application and testing have
been limited to 16S analysis of microbial communities.
RESULTS: We clustered standard test sequences derived from the Human Microbiome
Mock Community test sets and compared MetAmp and other tools with respect to
their ability to recover OTUs for these benchmark bacterial communities. MetAmp
compared favorably to QIIME, UPARSE and Mothur using amplicons from one, two, and
three markers.
AVAILABILITY AND IMPLEMENTATION: MetAmp is available at
http://izhbannikov.github.io/MetAmp/.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv049 
PMCID: PMC4443678
PMID: 25630378  [PubMed - indexed for MEDLINE]


1090. BMC Bioinformatics. 2015 Jan 28;16:17. doi: 10.1186/s12859-014-0428-5.

Quantitative analysis of differences in copy numbers using read depth obtained
from PCR-enriched samples and controls.

Reinecke F(1), Satya RV(2), DiCarlo J(3).

Author information: 
(1)Bioinformatics Assay Design & Analysis, QIAGEN GmbH, Max-Volmer-Straße 4,
Hilden, 40724, Germany. frank.reinecke@qiagen.com. (2)Bioinformatics Assay Design
& Analysis, QIAGEN Sciences Inc., 6951 Executive Way, Frederick MD, 21703, USA.
ravi.vijayasatya@qiagen.com. (3)Bioinformatics Assay Design & Analysis, QIAGEN
Sciences Inc., 6951 Executive Way, Frederick MD, 21703, USA.
john.dicarlo@qiagen.com.

BACKGROUND: Next-generation sequencing (NGS) is rapidly becoming common practice 
in clinical diagnostics and cancer research. In addition to the detection of
single nucleotide variants (SNVs), information on copy number variants (CNVs) is 
of great interest. Several algorithms exist to detect CNVs by analyzing whole
genome sequencing data or data from samples enriched by hybridization-capture.
PCR-enriched amplicon-sequencing data have special characteristics that have been
taken into account by only one publicly available algorithm so far.
RESULTS: We describe a new algorithm named quandico to detect copy number
differences based on NGS data generated following PCR-enrichment. A weighted
t-test statistic was applied to calculate probabilities (p-values) of copy number
changes. We assessed the performance of the method using sequencing reads
generated from reference DNA with known CNVs, and we were able to detect these
variants with 98.6% sensitivity and 98.5% specificity which is significantly
better than another recently described method for amplicon sequencing. The source
code (R-package) of quandico is licensed under the GPLv3 and it is available at
https://github.com/reineckef/quandico .
CONCLUSION: We demonstrated that our new algorithm is suitable to call copy
number changes using data from PCR-enriched samples with high sensitivity and
specificity even for single copy differences.

DOI: 10.1186/s12859-014-0428-5 
PMCID: PMC4384318
PMID: 25626454  [PubMed - indexed for MEDLINE]


1091. Microbiome. 2015 Jan 20;3(1):1. doi: 10.1186/s40168-014-0066-1. eCollection 2015.

VizBin - an application for reference-independent visualization and
human-augmented binning of metagenomic data.

Laczny CC(1), Sternal T(2), Plugaru V(3), Gawron P(1), Atashpendar A(3),
Margossian HH(3), Coronado S(1), der Maaten Lv(4), Vlassis N(5), Wilmes P(1).

Author information: 
(1)Luxembourg Centre for Systems Biomedicine, University of Luxembourg,
Esch-sur-Alzette, 4362 Luxembourg. (2)Institute of Computing Science, Poznan
University of Technology, Poznan, 60-965 Poland. (3)Computer Science and
Communications Research Unit, University of Luxembourg, Luxembourg, 1359
Luxembourg. (4)Pattern Recognition and Bioinformatics Group, Delft University of 
Technology, CD Delft, 2628 Netherlands. (5)Adobe Research, Adobe, San Jose, 95110
USA.

BACKGROUND: Metagenomics is limited in its ability to link distinct microbial
populations to genetic potential due to a current lack of representative isolate 
genome sequences. Reference-independent approaches, which exploit for example
inherent genomic signatures for the clustering of metagenomic fragments
(binning), offer the prospect to resolve and reconstruct population-level genomic
complements without the need for prior knowledge.
RESULTS: We present VizBin, a Java™-based application which offers efficient and 
intuitive reference-independent visualization of metagenomic datasets from single
samples for subsequent human-in-the-loop inspection and binning. The method is
based on nonlinear dimension reduction of genomic signatures and exploits the
superior pattern recognition capabilities of the human eye-brain system for
cluster identification and delineation. We demonstrate the general applicability 
of VizBin for the analysis of metagenomic sequence data by presenting results
from two cellulolytic microbial communities and one human-borne microbial
consortium. The superior performance of our application compared to other
analogous metagenomic visualization and binning methods is also presented.
CONCLUSIONS: VizBin can be applied de novo for the visualization and subsequent
binning of metagenomic datasets from single samples, and it can be used for the
post hoc inspection and refinement of automatically generated bins. Due to its
computational efficiency, it can be run on common desktop machines and enables
the analysis of complex metagenomic datasets in a matter of minutes. The software
implementation is available at https://claczny.github.io/VizBin under the BSD
License (four-clause) and runs under Microsoft Windows™, Apple Mac OS X™ (10.7 to
10.10), and Linux.

DOI: 10.1186/s40168-014-0066-1 
PMCID: PMC4305225
PMID: 25621171  [PubMed]


1092. Bioinformatics. 2015 Jun 1;31(11):1745-53. doi: 10.1093/bioinformatics/btv031.
Epub 2015 Jan 22.

ASSIGN: context-specific genomic profiling of multiple heterogeneous biological
pathways.

Shen Y(1), Rahman M(1), Piccolo SR(2), Gusenleitner D(1), El-Chaar NN(1), Cheng
L(1), Monti S(1), Bild AH(2), Johnson WE(2).

Author information: 
(1)Division of Computational Biomedicine, Boston University School of Medicine,
Boston, MA 02118 USA, Department of Biomedical Informatics and Department of
Pharmacology and Toxicology, University of Utah, Salt Lake City, UT 84112 USA.
(2)Division of Computational Biomedicine, Boston University School of Medicine,
Boston, MA 02118 USA, Department of Biomedical Informatics and Department of
Pharmacology and Toxicology, University of Utah, Salt Lake City, UT 84112 USA
Division of Computational Biomedicine, Boston University School of Medicine,
Boston, MA 02118 USA, Department of Biomedical Informatics and Department of
Pharmacology and Toxicology, University of Utah, Salt Lake City, UT 84112 USA.

MOTIVATION: Although gene-expression signature-based biomarkers are often
developed for clinical diagnosis, many promising signatures fail to replicate
during validation. One major challenge is that biological samples used to
generate and validate the signature are often from heterogeneous biological
contexts-controlled or in vitro samples may be used to generate the signature,
but patient samples may be used for validation. In addition, systematic technical
biases from multiple genome-profiling platforms often mask true biological
variation. Addressing such challenges will enable us to better elucidate disease 
mechanisms and provide improved guidance for personalized therapeutics.
RESULTS: Here, we present a pathway profiling toolkit, Adaptive Signature
Selection and InteGratioN (ASSIGN), which enables robust and context-specific
pathway analyses by efficiently capturing pathway activity in heterogeneous sets 
of samples and across profiling technologies. The ASSIGN framework is based on a 
flexible Bayesian factor analysis approach that allows for simultaneous profiling
of multiple correlated pathways and for the adaptation of pathway signatures into
specific disease. We demonstrate the robustness and versatility of ASSIGN in
estimating pathway activity in simulated data, cell lines perturbed pathways and 
in primary tissues samples including The Cancer Genome Atlas breast carcinoma
samples and liver samples exposed to genotoxic carcinogens.
AVAILABILITY AND IMPLEMENTATION: Software for our approach is available for
download at: http://www.bioconductor.org/packages/release/bioc/html/ASSIGN.html
and https://github.com/wevanjohnson/ASSIGN.

© The Author 2015. Published by Oxford University Press. All rights reserved. For
Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btv031 
PMCID: PMC4443674
PMID: 25617415  [PubMed - indexed for MEDLINE]


1093. Bioinformatics. 2015 Jun 1;31(11):1762-70. doi: 10.1093/bioinformatics/btv014.
Epub 2015 Jan 21.

Gaussian process test for high-throughput sequencing time series: application to 
experimental evolution.

Topa H(1), Jónás Á(2), Kofler R(1), Kosiol C(1), Honkela A(1).

Author information: 
(1)Helsinki Institute for Information Technology (HIIT), Department of
Information and Computer Science, Aalto University, Espoo, Finland, Institut für 
Populationsgenetik, Vetmeduni Vienna, 1210 Wien, Austria, Vienna Graduate School 
of Population Genetics, Wien, Austria and Helsinki Institute for Information
Technology (HIIT), Department of Computer Science, University of Helsinki,
Helsinki, Finland. (2)Helsinki Institute for Information Technology (HIIT),
Department of Information and Computer Science, Aalto University, Espoo, Finland,
Institut für Populationsgenetik, Vetmeduni Vienna, 1210 Wien, Austria, Vienna
Graduate School of Population Genetics, Wien, Austria and Helsinki Institute for 
Information Technology (HIIT), Department of Computer Science, University of
Helsinki, Helsinki, Finland Helsinki Institute for Information Technology (HIIT),
Department of Information and Computer Science, Aalto University, Espoo, Finland,
Institut für Populationsgenetik, Vetmeduni Vienna, 1210 Wien, Austria, Vienna
Graduate School of Population Genetics, Wien, Austria and Helsinki Institute for 
Information Technology (HIIT), Department of Computer Science, University of
Helsinki, Helsinki, Finland.

MOTIVATION: Recent advances in high-throughput sequencing (HTS) have made it
possible to monitor genomes in great detail. New experiments not only use HTS to 
measure genomic features at one time point but also monitor them changing over
time with the aim of identifying significant changes in their abundance. In
population genetics, for example, allele frequencies are monitored over time to
detect significant frequency changes that indicate selection pressures. Previous 
attempts at analyzing data from HTS experiments have been limited as they could
not simultaneously include data at intermediate time points, replicate
experiments and sources of uncertainty specific to HTS such as sequencing depth.
RESULTS: We present the beta-binomial Gaussian process model for ranking features
with significant non-random variation in abundance over time. The features are
assumed to represent proportions, such as proportion of an alternative allele in 
a population. We use the beta-binomial model to capture the uncertainty arising
from finite sequencing depth and combine it with a Gaussian process model over
the time series. In simulations that mimic the features of experimental evolution
data, the proposed method clearly outperforms classical testing in average
precision of finding selected alleles. We also present simulations exploring
different experimental design choices and results on real data from Drosophila
experimental evolution experiment in temperature adaptation.
AVAILABILITY AND IMPLEMENTATION: R software implementing the test is available at
https://github.com/handetopa/BBGP.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv014 
PMCID: PMC4443671
PMID: 25614471  [PubMed - indexed for MEDLINE]


1094. JMIR Med Inform. 2014 Dec 1;2(2):e32. doi: 10.2196/medinform.3339.

CohortExplorer: A Generic Application Programming Interface for Entity Attribute 
Value Database Schemas.

Dixit A(1), Dobson RJ.

Author information: 
(1)Institute of Psychiatry, NIHR Biomedical Research Centre for Mental Health &
Biomedical Research Unit for Dementia, South London and Maudsley NHS Foundation
Trust & Institute of Psychiatry, Kings College London, London, United Kingdom.
abhishek.dixit@kcl.ac.uk.

BACKGROUND: Most electronic data capture (EDC) and electronic data management
(EDM) systems developed to collect and store clinical data from participants
recruited into studies are based on generic entity-attribute-value (EAV) database
schemas which enable rapid and flexible deployment in a range of study designs.
The drawback to such schemas is that they are cumbersome to query with structured
query language (SQL). The problem increases when researchers involved in multiple
studies use multiple electronic data capture and management systems each with
variation on the EAV schema.
OBJECTIVE: The aim of this study is to develop a generic application which allows
easy and rapid exploration of data and metadata stored under EAV schemas that are
organized into a survey format (questionnaires/events, questions, values), in
other words, the Clinical Data Interchange Standards Consortium (CDISC)
Observational Data Model (ODM).
METHODS: CohortExplorer is written in Perl programming language and uses the
concept of SQL abstract which allows the SQL query to be treated like a hash
(key-value pairs).
RESULTS: We have developed a tool, CohortExplorer, which once configured for a
EAV system will "plug-n-play" with EAV schemas, enabling the easy construction of
complex queries through an abstracted interface. To demonstrate the utility of
the CohortExplorer system, we show how it can be used with the popular EAV based 
frameworks; Opal (OBiBa) and REDCap.
CONCLUSIONS: The application is available under a GPL-3+ license at the CPAN
website. Currently the application only provides datasource application
programming interfaces (APIs) for Opal and REDCap. In the future the application 
will be available with datasource APIs for all major electronic data capture and 
management systems such as OpenClinica and LabKey. At present the application is 
only compatible with EAV systems where the metadata is organized into surveys,
questionnaires and events. Further work is needed to make the application
compatible with EAV schemas where the metadata is organized into hierarchies such
as Informatics for Integrating Biology & the Bedside (i2b2). A video tutorial
demonstrating the application setup, datasource configuration, and search
features is available on YouTube. The application source code is available at the
GitHub website and the users are encouraged to suggest new features and
contribute to the development of APIs for new EAV systems.

DOI: 10.2196/medinform.3339 
PMCID: PMC4288104
PMID: 25601296  [PubMed]


1095. Malar J. 2015 Jan 19;14:4. doi: 10.1186/1475-2875-14-4.

COIL: a methodology for evaluating malarial complexity of infection using
likelihood from single nucleotide polymorphism data.

Galinsky K(1), Valim C(2), Salmier A(3), de Thoisy B(4), Musset L(5), Legrand
E(6), Faust A(7), Baniecki ML(8), Ndiaye D(9), Daniels RF(10,)(11), Hartl
DL(12,)(13), Sabeti PC(14,)(15), Wirth DF(16,)(17), Volkman SK(18,)(19,)(20),
Neafsey DE(21).

Author information: 
(1)Department of Biostatistics, Harvard School of Public Health, Boston, MA,
02115, USA. kgalinsky@gmail.com. (2)Department of Immunology and Infectious
Disease, Harvard School of Public Health, Boston, MA, 02115, USA.
cvalim@hsph.harvard.edu. (3)Laboratoire de Parasitologie, National Reference
Centre for Malaria, Institut Pasteur de la Guyane, Cayenne, French Guiana,
France. Arielle.salmier@gmail.com. (4)Laboratoire de Parasitologie, National
Reference Centre for Malaria, Institut Pasteur de la Guyane, Cayenne, French
Guiana, France. bdethoisy@pasteur-cayenne.fr. (5)Laboratoire de Parasitologie,
National Reference Centre for Malaria, Institut Pasteur de la Guyane, Cayenne,
French Guiana, France. lmusset@pasteur-cayenne.fr. (6)Laboratoire de
Parasitologie, National Reference Centre for Malaria, Institut Pasteur de la
Guyane, Cayenne, French Guiana, France. elegrand@pasteur-cayenne.fr. (7)Faculty
of Arts and Sciences, Harvard University, Cambridge, MA, 02138, USA.
afaust@college.harvard.edu. (8)Broad Institute of MIT and Harvard, Cambridge, MA,
02142, USA. baniecki@broadinstitute.org. (9)Faculty of Medicine and Pharmacy,
Cheikh Anta Diop University, Dakar, Senegal. daouda.ndiaye@ucad.edu.sn.
(10)Faculty of Arts and Sciences, Harvard University, Cambridge, MA, 02138, USA. 
rdaniels@broadinstitute.org. (11)Broad Institute of MIT and Harvard, Cambridge,
MA, 02142, USA. rdaniels@broadinstitute.org. (12)Faculty of Arts and Sciences,
Harvard University, Cambridge, MA, 02138, USA. dhartl@oeb.harvard.edu. (13)Broad 
Institute of MIT and Harvard, Cambridge, MA, 02142, USA. dhartl@oeb.harvard.edu. 
(14)Faculty of Arts and Sciences, Harvard University, Cambridge, MA, 02138, USA. 
pardis@broadinstitute.org. (15)Broad Institute of MIT and Harvard, Cambridge, MA,
02142, USA. pardis@broadinstitute.org. (16)Department of Immunology and
Infectious Disease, Harvard School of Public Health, Boston, MA, 02115, USA.
dfwirth@hsph.harvard.edu. (17)Broad Institute of MIT and Harvard, Cambridge, MA, 
02142, USA. dfwirth@hsph.harvard.edu. (18)Department of Immunology and Infectious
Disease, Harvard School of Public Health, Boston, MA, 02115, USA.
svolkman@hsph.harvard.edu. (19)Broad Institute of MIT and Harvard, Cambridge, MA,
02142, USA. svolkman@hsph.harvard.edu. (20)Simmons College School of Nursing and 
Health Sciences, Boston, MA, 02115, USA. svolkman@hsph.harvard.edu. (21)Broad
Institute of MIT and Harvard, Cambridge, MA, 02142, USA.
neafsey@broadinstitute.org.

BACKGROUND: Complex malaria infections are defined as those containing more than 
one genetically distinct lineage of Plasmodium parasite. Complexity of infection 
(COI) is a useful parameter to estimate from patient blood samples because it is 
associated with clinical outcome, epidemiology and disease transmission rate.
This manuscript describes a method for estimating COI using likelihood, called
COIL, from a panel of bi-allelic genotyping assays.
METHODS: COIL assumes that distinct parasite lineages in complex infections are
unrelated and that genotyped loci do not exhibit significant linkage
disequilibrium. Using the population minor allele frequency (MAF) of the
genotyped loci, COIL uses the binomial distribution to estimate the likelihood of
a COI level given the prevalence of observed monomorphic or polymorphic genotypes
within each sample.
RESULTS: COIL reliably estimates COI up to a level of three or five with at least
24 or 96 unlinked genotyped loci, respectively, as determined by in silico
simulation and empirical validation. Evaluation of COI levels greater than five
in patient samples may require a very large collection of genotype data, making
sequencing a more cost-effective approach for evaluating COI under conditions
when disease transmission is extremely high. Performance of the method is
positively correlated with the MAF of the genotyped loci. COI estimates from
existing SNP genotype datasets create a more detailed portrait of disease than
analyses based simply on the number of polymorphic genotypes observed within
samples.
CONCLUSIONS: The capacity to reliably estimate COI from a genome-wide panel of
SNP genotypes provides a potentially more accurate alternative to methods relying
on PCR amplification of a small number of loci for estimating COI. This approach 
will also increase the number of applications of SNP genotype data, providing
additional motivation to employ SNP barcodes for studies of disease epidemiology 
or control measure efficacy. The COIL program is available for download from
GitHub, and users may also upload their SNP genotype data to a web interface for 
simple and efficient determination of sample COI.

DOI: 10.1186/1475-2875-14-4 
PMCID: PMC4417311
PMID: 25599890  [PubMed - indexed for MEDLINE]


1096. Genome Biol. 2015 Jan 13;16:3. doi: 10.1186/s13059-014-0573-1.

ALLMAPS: robust scaffold ordering based on multiple maps.

Tang H(1,)(2,)(3), Zhang X(4), Miao C(5), Zhang J(6), Ming R(7), Schnable
JC(8,)(9), Schnable PS(10,)(11), Lyons E(12), Lu J(13).

Author information: 
(1)Center for Genomics and Biotechnology, Fujian Agriculture and Forestry
University, Fuzhou, 350002, Fujian Province, China. tanghaibao@gmail.com.
(2)School of Plant Sciences, iPlant Collaborative, University of Arizona, Tucson,
AZ, 85721, USA. tanghaibao@gmail.com. (3)Data2Bio LLC, 2079 Roy J. Carver Co-Lab,
Ames, Iowa, 50011, USA. tanghaibao@gmail.com. (4)J. Craig Venter Institute, 9704 
Medical Center Dr, Rockville, MD, 20850, USA. tanger.zhang@gmail.com. (5)Center
for Genomics and Biotechnology, Fujian Agriculture and Forestry University,
Fuzhou, 350002, Fujian Province, China. miaochenyong@163.com. (6)Center for
Genomics and Biotechnology, Fujian Agriculture and Forestry University, Fuzhou,
350002, Fujian Province, China. zjisen@gmail.com. (7)Center for Genomics and
Biotechnology, Fujian Agriculture and Forestry University, Fuzhou, 350002, Fujian
Province, China. rming@life.illinois.edu. (8)Data2Bio LLC, 2079 Roy J. Carver
Co-Lab, Ames, Iowa, 50011, USA. james.schnable@gmail.com. (9)Department of
Agronomy and Horticulture, University of Nebraska, Lincoln, NE, 68588, USA.
james.schnable@gmail.com. (10)Data2Bio LLC, 2079 Roy J. Carver Co-Lab, Ames,
Iowa, 50011, USA. schnable@iastate.edu. (11)Department of Agronomy, Iowa State
University, Ames, IA, 50011, USA. schnable@iastate.edu. (12)School of Plant
Sciences, iPlant Collaborative, University of Arizona, Tucson, AZ, 85721, USA.
elyons.uoa@gmail.com. (13)Heilongjiang River Fisheries Research Institute,
Harbin, 150070, China. jianguonk@gmail.com.

The ordering and orientation of genomic scaffolds to reconstruct chromosomes is
an essential step during de novo genome assembly. Because this process utilizes
various mapping techniques that each provides an independent line of evidence, a 
combination of multiple maps can improve the accuracy of the resulting
chromosomal assemblies. We present ALLMAPS, a method capable of computing a
scaffold ordering that maximizes colinearity across a collection of maps. ALLMAPS
is robust against common mapping errors, and generates sequences that are
maximally concordant with the input maps. ALLMAPS is a useful tool in building
high-quality genome assemblies. ALLMAPS is available at:
https://github.com/tanghaibao/jcvi/wiki/ALLMAPS .

DOI: 10.1186/s13059-014-0573-1 
PMCID: PMC4305236
PMID: 25583564  [PubMed - indexed for MEDLINE]


1097. Bioinformatics. 2015 May 1;31(9):1496-8. doi: 10.1093/bioinformatics/btv002. Epub
2015 Jan 7.

RNA-Rocket: an RNA-Seq analysis resource for infectious disease research.

Warren AS(1), Aurrecoechea C(1), Brunk B(2), Desai P(1), Emrich S(2),
Giraldo-Calderón GI(1), Harb O(2), Hix D(1), Lawson D(1), Machi D(1), Mao C(1),
McClelland M(1), Nordberg E(1), Shukla M(1), Vosshall LB(1), Wattam AR(1), Will
R(1), Yoo HS(1), Sobral B(1).

Author information: 
(1)Virginia Bioinformatics Institute, Virginia Tech, Blacksburg, VA 24060, USA,
Center for Tropical & Emerging Global Diseases, University of Georgia, Athens, GA
30602, USA, Penn Center for Bioinformatics and Department of Biology, University 
of Pennsylvania, Philadelphia, PA 19104, USA, European Bioinformatics Institute
(EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, CB10 1SD, UK, Department of
Biological Sciences, University of Notre Dame, Notre Dame, IN 46556, USA,
Department of Computer Science and Engineering, University of Notre Dame, Notre
Dame, IN 46556, USA, Eck Institute for Global Health, University of Notre Dame,
Notre Dame, IN 46656-0369, USA, University of California, Department of
Microbiology and Molecular Genetics, Irvine, California, USA and The Rockefeller 
University, Howard Hughes Medical Institute, New York, NY 10065, USA. (2)Virginia
Bioinformatics Institute, Virginia Tech, Blacksburg, VA 24060, USA, Center for
Tropical & Emerging Global Diseases, University of Georgia, Athens, GA 30602,
USA, Penn Center for Bioinformatics and Department of Biology, University of
Pennsylvania, Philadelphia, PA 19104, USA, European Bioinformatics Institute
(EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, CB10 1SD, UK, Department of
Biological Sciences, University of Notre Dame, Notre Dame, IN 46556, USA,
Department of Computer Science and Engineering, University of Notre Dame, Notre
Dame, IN 46556, USA, Eck Institute for Global Health, University of Notre Dame,
Notre Dame, IN 46656-0369, USA, University of California, Department of
Microbiology and Molecular Genetics, Irvine, California, USA and The Rockefeller 
University, Howard Hughes Medical Institute, New York, NY 10065, USA Virginia
Bioinformatics Institute, Virginia Tech, Blacksburg, VA 24060, USA, Center for
Tropical & Emerging Global Diseases, University of Georgia, Athens, GA 30602,
USA, Penn Center for Bioinformatics and Department of Biology, University of
Pennsylvania, Philadelphia, PA 19104, USA, European Bioinformatics Institute
(EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, CB10 1SD, UK, Department of
Biological Sciences, University of Notre Dame, Notre Dame, IN 46556, USA,
Department of Computer Science and Engineering, University of Notre Dame, Notre
Dame, IN 46556, USA, Eck Institute for Global Health, University of Notre Dame,
Notre Dame, IN 46656-0369, USA, University of California, Department of
Microbiology and Molecular Genetics, Irvine, California, USA and The Rockefeller 
University, Howard Hughes Medical Institute, New York, NY 10065, USA.

MOTIVATION: RNA-Seq is a method for profiling transcription using high-throughput
sequencing and is an important component of many research projects that wish to
study transcript isoforms, condition specific expression and transcriptional
structure. The methods, tools and technologies used to perform RNA-Seq analysis
continue to change, creating a bioinformatics challenge for researchers who wish 
to exploit these data. Resources that bring together genomic data, analysis
tools, educational material and computational infrastructure can minimize the
overhead required of life science researchers.
RESULTS: RNA-Rocket is a free service that provides access to RNA-Seq and
ChIP-Seq analysis tools for studying infectious diseases. The site makes
available thousands of pre-indexed genomes, their annotations and the ability to 
stream results to the bioinformatics resources VectorBase, EuPathDB and PATRIC.
The site also provides a combination of experimental data and metadata, examples 
of pre-computed analysis, step-by-step guides and a user interface designed to
enable both novice and experienced users of RNA-Seq data.
AVAILABILITY AND IMPLEMENTATION: RNA-Rocket is available at
rnaseq.pathogenportal.org. Source code for this project can be found at
github.com/cidvbi/PathogenPortal.
CONTACT: anwarren@vt.edu
SUPPLEMENTARY INFORMATION: Supplementary materials are available at
Bioinformatics online.

© The Author 2015. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btv002 
PMCID: PMC4410666
PMID: 25573919  [PubMed - indexed for MEDLINE]


1098. Cytometry A. 2015 Jul;87(7):636-45. doi: 10.1002/cyto.a.22625. Epub 2015 Jan 8.

FlowSOM: Using self-organizing maps for visualization and interpretation of
cytometry data.

Van Gassen S(1,)(2,)(3), Callebaut B(1), Van Helden MJ(2,)(3), Lambrecht
BN(2,)(3), Demeester P(1), Dhaene T(1), Saeys Y(2,)(3).

Author information: 
(1)Department of Information Technology, Ghent University, iMinds, Ghent,
Belgium. (2)Inflammation Research Center, VIB, Ghent, Belgium. (3)Department of
Respiratory Medicine, Ghent University Hospital, Ghent, Belgium.

The number of markers measured in both flow and mass cytometry keeps increasing
steadily. Although this provides a wealth of information, it becomes infeasible
to analyze these datasets manually. When using 2D scatter plots, the number of
possible plots increases exponentially with the number of markers and therefore, 
relevant information that is present in the data might be missed. In this
article, we introduce a new visualization technique, called FlowSOM, which
analyzes Flow or mass cytometry data using a Self-Organizing Map. Using a
two-level clustering and star charts, our algorithm helps to obtain a clear
overview of how all markers are behaving on all cells, and to detect subsets that
might be missed otherwise. R code is available at
https://github.com/SofieVG/FlowSOM and will be made available at Bioconductor.

© 2015 International Society for Advancement of Cytometry.

DOI: 10.1002/cyto.a.22625 
PMID: 25573116  [PubMed - indexed for MEDLINE]


1099. Ecol Evol. 2014 Dec;4(24):4658-68. doi: 10.1002/ece3.1273. Epub 2014 Dec 2.

MODISTools - downloading and processing MODIS remotely sensed data in R.

Tuck SL(1), Phillips HR(2), Hintzen RE(2), Scharlemann JP(3), Purvis A(2), Hudson
LN(4).

Author information: 
(1)Department of Plant Sciences, University of Oxford Oxford, OX1 3RB, U.K.
(2)Department of Life Sciences, Imperial College London, Silwood Park Buckhurst
Road, Ascot, Berkshire, SL5 7PY, U.K ; Department of Life Sciences, Natural
History Museum Cromwell Road, London, SW7 5BD, U.K. (3)School of Life Sciences,
University of Sussex Brighton, BN1 9QG, U.K. (4)Department of Life Sciences,
Natural History Museum Cromwell Road, London, SW7 5BD, U.K.

Remotely sensed data - available at medium to high resolution across global
spatial and temporal scales - are a valuable resource for ecologists. In
particular, products from NASA's MODerate-resolution Imaging Spectroradiometer
(MODIS), providing twice-daily global coverage, have been widely used for
ecological applications. We present MODISTools, an R package designed to improve 
the accessing, downloading, and processing of remotely sensed MODIS data.
MODISTools automates the process of data downloading and processing from any
number of locations, time periods, and MODIS products. This automation reduces
the risk of human error, and the researcher effort required compared to manual
per-location downloads. The package will be particularly useful for ecological
studies that include multiple sites, such as meta-analyses, observation networks,
and globally distributed experiments. We give examples of the simple,
reproducible workflow that MODISTools provides and of the checks that are carried
out in the process. The end product is in a format that is amenable to
statistical modeling. We analyzed the relationship between species richness
across multiple higher taxa observed at 526 sites in temperate forests and
vegetation indices, measures of aboveground net primary productivity. We
downloaded MODIS derived vegetation index time series for each location where the
species richness had been sampled, and summarized the data into three measures:
maximum time-series value, temporal mean, and temporal variability. On average,
species richness covaried positively with our vegetation index measures.
Different higher taxa show different positive relationships with vegetation
indices. Models had high R (2) values, suggesting higher taxon identity and a
gradient of vegetation index together explain most of the variation in species
richness in our data. MODISTools can be used on Windows, Mac, and Linux
platforms, and is available from CRAN and GitHub
(https://github.com/seantuck12/MODISTools).

DOI: 10.1002/ece3.1273 
PMCID: PMC4278818
PMID: 25558360  [PubMed]


1100. J Bioinform Comput Biol. 2014 Dec;12(6):1442005. doi: 10.1142/S0219720014420050.

AKSmooth: enhancing low-coverage bisulfite sequencing data via kernel-based
smoothing.

Chen J(1), Lutsik P, Akulenko R, Walter J, Helms V.

Author information: 
(1)Center for Bioinformatics, Saarland University, Saarbrücken 66123, Germany ,
Department of Genetics, Saarland University, Saarbrücken 66123, Germany.

Whole-genome bisulfite sequencing (WGBS) is an approach of growing importance. It
is the only approach that provides a comprehensive picture of the genome-wide DNA
methylation profile. However, obtaining a sufficient amount of genome and read
coverage typically requires high sequencing costs. Bioinformatics tools can
reduce this cost burden by improving the quality of sequencing data. We have
developed a statistical method Ajusted Local Kernel Smoother (AKSmooth) that can 
accurately and efficiently reconstruct the single CpG methylation estimate across
the entire methylome using low-coverage bisulfite sequencing (Bi-Seq) data. We
demonstrate the AKSmooth performance on the low-coverage (~ 4 ×) DNA methylation 
profiles of three human colon cancer samples and matched controls. Under the best
set of parameters, AKSmooth-curated data showed high concordance with the gold
standard high-coverage sample (Pearson 0.90), outperforming the popular analogous
method. In addition, AKSmooth showed computational efficiency with runtime
benchmark over 4.5 times better than the reference tool. To summarize, AKSmooth
is a simple and efficient tool that can provide an accurate human colon methylome
estimation profile from low-coverage WGBS data. The proposed method is
implemented in R and is available at https://github.com/Junfang/AKSmooth.

DOI: 10.1142/S0219720014420050 
PMID: 25553811  [PubMed - indexed for MEDLINE]


1101. Ann Biomed Eng. 2015 Jun;43(6):1461-73. doi: 10.1007/s10439-014-1234-y. Epub 2014
Dec 31.

pyNS: an open-source framework for 0D haemodynamic modelling.

Manini S(1), Antiga L, Botti L, Remuzzi A.

Author information: 
(1)Orobix Srl, Bergamo, Italy, simone.manini@gmail.com.

A number of computational approaches have been proposed for the simulation of
haemodynamics and vascular wall dynamics in complex vascular networks. Among
them, 0D pulse wave propagation methods allow to efficiently model flow and
pressure distributions and wall displacements throughout vascular networks at low
computational costs. Although several techniques are documented in literature,
the availability of open-source computational tools is still limited. We here
present python Network Solver, a modular solver framework for 0D problems
released under a BSD license as part of the archToolkit (
http://archtk.github.com ). As an application, we describe patient-specific
models of the systemic circulation and detailed upper extremity for use in the
prediction of maturation after surgical creation of vascular access for
haemodialysis.

DOI: 10.1007/s10439-014-1234-y 
PMID: 25549775  [PubMed - indexed for MEDLINE]


1102. Version 2. F1000Res. 2015 Oct 9 [revised 2016 Apr 8];4:1030. doi:
10.12688/f1000research.7118.2. eCollection 2015.

DREAMTools: a Python package for scoring collaborative challenges.

Cokelaer T(1), Bansal M(2), Bare C(3), Bilal E(4), Bot BM(3), Chaibub Neto E(3), 
Eduati F(5), de la Fuente A(6), Gönen M(7), Hill SM(8), Hoff B(3), Karr JR(9),
Küffner R(10), Menden MP(5), Meyer P(4), Norel R(4), Pratap A(3), Prill RJ(11),
Weirauch MT(12), Costello JC(13), Stolovitzky G(14), Saez-Rodriguez J(15).

Author information: 
(1)European Molecular Biology Laboratory, European Bioinformatics Institute
(EMBL-EBI),Wellcome Trust Genome Campus, Cambridge, UK; Bioinformatics and
Biostatistics Hub, C3BI, Institut Pasteur, Paris, France. (2)Department of
Systems Biology, Columbia University, New York, USA. (3)Sage Bionetworks,
Seattle, WA, USA. (4)IBM, TJ Watson, Computational Biology Center, New York, USA.
(5)European Molecular Biology Laboratory, European Bioinformatics Institute
(EMBL-EBI),Wellcome Trust Genome Campus, Cambridge, UK. (6)Leibniz Institute for 
Farm Animal Biology, Institute of Genetics and Biometry, Dummerstorf, Germany.
(7)Oregon Health & Science University, Portland, OR, USA. (8)MRC Biostatistics
Unit, Cambridge Institute of Public Health, Cambridge, UK. (9)Department of
Genetics & Genomic Sciences, Icahn School of Medicine at Mount Sinai, New York,
USA. (10)Institute of Bioinformatics and Systems Biology, German Research Center 
for Environmental Health, Munich, Germany. (11)IBM Almaden Research Center, San
Jose, CA, USA. (12)Center for Autoimmune Genomics and Etiology and Divisions of
Biomedical Informatics and Developmental Biology, Cincinnati Children's Hospital,
Cincinnati, OH, USA. (13)Department of Pharmacology, University of Colorado
Anschutz Medical Campus, Aurora, CO, USA. (14)IBM, TJ Watson, Computational
Biology Center, New York, USA; Department of Genetics & Genomic Sciences, Icahn
School of Medicine at Mount Sinai, New York, USA. (15)European Molecular Biology 
Laboratory, European Bioinformatics Institute (EMBL-EBI),Wellcome Trust Genome
Campus, Cambridge, UK; RWTH Aachen University Medical Hospital, Joint Research
Centre for Computational Biomedicine (JRCCOMBINE), Aachen, Germany.

DREAM challenges are community competitions designed to advance computational
methods and address fundamental questions in system biology and translational
medicine. Each challenge asks participants to develop and apply computational
methods to either predict unobserved outcomes or to identify unknown model
parameters given a set of training data. Computational methods are evaluated
using an automated scoring metric, scores are posted to a public leaderboard, and
methods are published to facilitate community discussions on how to build
improved methods. By engaging participants from a wide range of science and
engineering backgrounds, DREAM challenges can comparatively evaluate a wide range
of statistical, machine learning, and biophysical methods. Here, we describe
DREAMTools, a Python package for evaluating DREAM challenge scoring metrics.
DREAMTools provides a command line interface that enables researchers to test new
methods on past challenges, as well as a framework for scoring new challenges. As
of March 2016, DREAMTools includes more than 80% of completed DREAM challenges.
DREAMTools complements the data, metadata, and software tools available at the
DREAM website http://dreamchallenges.org and on the Synapse platform at
https://www.synapse.org.AVAILABILITY:   DREAMTools is a Python package. Releases 
and documentation are available at http://pypi.python.org/pypi/dreamtools. The
source code is available at http://github.com/dreamtools/dreamtools.

DOI: 10.12688/f1000research.7118.2 
PMCID: PMC4837986
PMID: 27134723  [PubMed]


1103. Version 2. F1000Res. 2015 Feb 4 [revised 2015 Oct 30];4:36. doi:
10.12688/f1000research.6077.2. eCollection 2015.

Tetranucleotide usage highlights genomic heterogeneity among mycobacteriophages.

Siranosian B(1), Perera S(2), Williams E(2), Ye C(2), de Graffenried C(3), Shank 
P(3).

Author information: 
(1)Center for Computational Molecular Biology, Brown University, Providence, RI, 
02912, USA; Division of Biology and Medicine, Brown University, Providence, RI,
02912, USA. (2)Division of Biology and Medicine, Brown University, Providence,
RI, 02912, USA. (3)Department of Molecular Microbiology and Immunology, Brown
University, Providence, RI, 02912, USA.

Background The genomic sequences of mycobacteriophages, phages infecting
mycobacterial hosts, are diverse and mosaic. Mycobacteriophages often share
little nucleotide similarity, but most of them have been grouped into lettered
clusters and further into subclusters. Traditionally, mycobacteriophage genomes
are analyzed based on sequence alignment or knowledge of gene content. However,
these approaches are computationally expensive and can be ineffective for
significantly diverged sequences. As an alternative to alignment-based genome
analysis, we evaluated tetranucleotide usage in mycobacteriophage genomes. These 
methods make it easier to characterize features of the mycobacteriophage
population at many scales. Description We computed tetranucleotide usage
deviation (TUD), the ratio of observed counts of 4-mers in a genome to the
expected count under a null model. TUD values are comparable between members of a
phage subcluster and distinct between subclusters. With few exceptions, neighbor 
joining phylogenetic trees and hierarchical clustering dendrograms constructed
using TUD values place phages in a monophyletic clade with members of the same
subcluster. Regions in a genome with exceptional TUD values can point to
interesting features of genomic architecture. Finally, we found that subcluster
B3 mycobacteriophages contain significantly overrepresented 4-mers and 6-mers
that are atypical of phage genomes. Conclusions Statistics based on
tetranucleotide usage support established clustering of mycobacteriophages and
can uncover interesting relationships within and between sequenced phage genomes.
These methods are efficient to compute and do not require sequence alignment or
knowledge of gene content. The code to download mycobacteriophage genome
sequences and reproduce our analysis is freely available at
https://github.com/bsiranosian/tango_final.

DOI: 10.12688/f1000research.6077.2 
PMCID: PMC4841201
PMID: 27134721  [PubMed]


1104. AMIA Annu Symp Proc. 2015 Nov 5;2015:804-13. eCollection 2015.

Reproducing a Prospective Clinical Study as a Computational Retrospective Study
in MIMIC-II.

Kury FS(1), Huser V(1), Cimino JJ(1).

Author information: 
(1)National Library of Medicine, Bethesda, MD, United States.

In this paper we sought to reproduce, as a computational retrospective study in
an EHR database (MIMIC-II), a recent large prospective clinical study: the 2013
publication, by the Japanese Association for Acute Medicine (JAAM), about
disseminated intravascular coagulation, in the journal Critical Care (PMID:
23787004). We designed in SQL and Java a set of electronic phenotypes that
reproduced the study's data sampling, and used R to perform the same statistical 
inference procedures. All produced source code is available online at
https://github.com/fabkury/paamia2015. Our program identified 2,257 eligible
patients in MIMIC-II, and the results remarkably agreed with the prospective
study. A minority of the needed data elements was not found in MIMIC-II, and
statistically significant inferences were possible in the majority of the cases.


PMCID: PMC4765583
PMID: 26958216  [PubMed - in process]


1105. AMIA Annu Symp Proc. 2015 Nov 5;2015:297-305.

OpenHealth Platform for Interactive Contextualization of Population Health Open
Data.

Almeida JS(1), Hajagos J(1), Crnosija I(1), Kurc T(1), Saltz M(2), Saltz J(1).

Author information: 
(1)Dept Biomedical Informatics, Stony Brook University, State University of New
York. (2)Dept Radiology, Stony Brook University, State University of New York.

The financial incentives for data science applications leading to improved health
outcomes, such as DSRIP (bit.ly/dsrip), are well-aligned with the broad adoption 
of Open Data by State and Federal agencies. This creates entirely novel
opportunities for analytical applications that make exclusive use of the
pervasive Web Computing platform. The framework described here explores this new 
avenue to contextualize Health data in a manner that relies exclusively on the
native JavaScript interpreter and data processing resources of the ubiquitous Web
Browser. The OpenHealth platform is made publicly available, and is publicly
hosted with version control and open source, at
https://github.com/mathbiol/openHealth. The different data/analytics workflow
architectures explored are accompanied with live applications ranging from DSRIP,
such as Hospital Inpatient Prevention Quality Indicators at
http://bit.ly/pqiSuffolk, to The Cancer Genome Atlas (TCGA) as illustrated by
http://bit.ly/tcgascopeGBM.


PMCID: PMC4765591
PMID: 26958160  [PubMed - in process]


1106. Bioinformatics. 2015 May 1;31(9):1490-2. doi: 10.1093/bioinformatics/btu849. Epub
2014 Dec 26.

An automatic tool to analyze and cluster macromolecular conformations based on
self-organizing maps.

Bouvier G(1), Desdouits N(1), Ferber M(1), Blondel A(1), Nilges M(1).

Author information: 
(1)Institut Pasteur, Unité de Bioinformatique Structurale; CNRS UMR 3528;
Département de Biologie Structurale et Chimie; F-75015, Paris, France.

MOTIVATION: Sampling the conformational space of biological macromolecules
generates large sets of data with considerable complexity. Data-mining
techniques, such as clustering, can extract meaningful information. Among them,
the self-organizing maps (SOMs) algorithm has shown great promise; in particular 
since its computation time rises only linearly with the size of the data set.
Whereas SOMs are generally used with few neurons, we investigate here their
behavior with large numbers of neurons.
RESULTS: We present here a python library implementing the full SOM analysis
workflow. Large SOMs can readily be applied on heavy data sets. Coupled with
visualization tools they have very interesting properties. Descriptors for each
conformation of a trajectory are calculated and mapped onto a 3D landscape, the
U-matrix, reporting the distance between neighboring neurons. To delineate
clusters, we developed the flooding algorithm, which hierarchically identifies
local basins of the U-matrix from the global minimum to the maximum.
AVAILABILITY AND IMPLEMENTATION: The python implementation of the SOM library is 
freely available on github: https://github.com/bougui505/SOM.
CONTACT: michael.nilges@pasteur.fr or guillaume.bouvier@pasteur.fr
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu849 
PMID: 25543048  [PubMed - indexed for MEDLINE]


1107. Bioinformatics. 2015 May 1;31(9):1382-8. doi: 10.1093/bioinformatics/btu843. Epub
2014 Dec 23.

UProC: tools for ultra-fast protein domain classification.

Meinicke P(1).

Author information: 
(1)Department of Bioinformatics, Institute for Microbiology and Genetics,
University of Göttingen, Germany.

MOTIVATION: With rapidly increasing volumes of biological sequence data the
functional analysis of new sequences in terms of similarities to known protein
families challenges classical bioinformatics.
RESULTS: The ultrafast protein classification (UProC) toolbox implements a novel 
algorithm ('Mosaic Matching') for large-scale sequence analysis. UProC is by
three orders of magnitude faster than profile-based methods and in a metagenome
simulation study achieved up to 80% higher sensitivity on unassembled 100 bp
reads.
AVAILABILITY AND IMPLEMENTATION: UProC is available as an open-source software at
https://github.com/gobics/uproc. Precompiled databases (Pfam) are linked on the
UProC homepage: http://uproc.gobics.de/.
CONTACT: peter@gobics.de.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu843 
PMCID: PMC4410661
PMID: 25540185  [PubMed - indexed for MEDLINE]


1108. Bioinformatics. 2015 Apr 15;31(8):1286-9. doi: 10.1093/bioinformatics/btu771.
Epub 2014 Dec 2.

Population-based structural variation discovery with Hydra-Multi.

Lindberg MR(1), Hall IM(2), Quinlan AR(3).

Author information: 
(1)Department of Biochemistry and Molecular Genetics, Center for Public Health
Genomics, University of Virginia, Charlottesville, VA, USA, Department of
Medicine, The Genome Institute, Washington University School of Medicine, St.
Louis MO, USA and Department of Public Health Sciences, University of Virginia,
Charlottesville, VA, USA. (2)Department of Biochemistry and Molecular Genetics,
Center for Public Health Genomics, University of Virginia, Charlottesville, VA,
USA, Department of Medicine, The Genome Institute, Washington University School
of Medicine, St. Louis MO, USA and Department of Public Health Sciences,
University of Virginia, Charlottesville, VA, USA Department of Biochemistry and
Molecular Genetics, Center for Public Health Genomics, University of Virginia,
Charlottesville, VA, USA, Department of Medicine, The Genome Institute,
Washington University School of Medicine, St. Louis MO, USA and Department of
Public Health Sciences, University of Virginia, Charlottesville, VA, USA
Department of Biochemistry and Molecular Genetics, Center for Public Health
Genomics, University of Virginia, Charlottesville, VA, USA, Department of
Medicine, The Genome Institute, Washington University School of Medicine, St.
Louis MO, USA and Department of Public Health Sciences, University of Virginia,
Charlottesville, VA, USA Department of Biochemistry and Molecular Genetics,
Center for Public Health Genomics, University of Virginia, Charlottesville, VA,
USA, Department of Medicine, The Genome Institute, Washington University School
of Medicine, St. Louis MO, USA and Department of Public Health Sciences,
University of Virginia, Charlottesville, VA, USA. (3)Department of Biochemistry
and Molecular Genetics, Center for Public Health Genomics, University of
Virginia, Charlottesville, VA, USA, Department of Medicine, The Genome Institute,
Washington University School of Medicine, St. Louis MO, USA and Department of
Public Health Sciences, University of Virginia, Charlottesville, VA, USA
Department of Biochemistry and Molecular Genetics, Center for Public Health
Genomics, University of Virginia, Charlottesville, VA, USA, Department of
Medicine, The Genome Institute, Washington University School of Medicine, St.
Louis MO, USA and Department of Public Health Sciences, University of Virginia,
Charlottesville, VA, USA Department of Biochemistry and Molecular Genetics,
Center for Public Health Genomics, University of Virginia, Charlottesville, VA,
USA, Department of Medicine, The Genome Institute, Washington University School
of Medicine, St. Louis MO, USA and Department of Public Health Sciences,
University of Virginia, Charlottesville, VA, USA.

Current strategies for SNP and INDEL discovery incorporate sequence alignments
from multiple individuals to maximize sensitivity and specificity. It is widely
accepted that this approach also improves structural variant (SV) detection.
However, multisample SV analysis has been stymied by the fundamental difficulties
of SV calling, e.g. library insert size variability, SV alignment signal
integration and detecting long-range genomic rearrangements involving disjoint
loci. Extant tools suffer from poor scalability, which limits the number of
genomes that can be co-analyzed and complicates analysis workflows. We have
developed an approach that enables multisample SV analysis in hundreds to
thousands of human genomes using commodity hardware. Here, we describe
Hydra-Multi and measure its accuracy, speed and scalability using publicly
available datasets provided by The 1000 Genomes Project and by The Cancer Genome 
Atlas (TCGA).AVAILABILITY AND IMPLEMENTATION: Hydra-Multi is written in C++ and
is freely available at https://github.com/arq5x/Hydra.
CONTACT: aaronquinlan@gmail.com or ihall@genome.wustl.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu771 
PMCID: PMC4393510
PMID: 25527832  [PubMed - indexed for MEDLINE]


1109. BMC Bioinformatics. 2014 Dec 20;15:388. doi: 10.1186/s12859-014-0388-9.

Linear-time computation of minimal absent words using suffix array.

Barton C(1), Heliou A(2,)(3), Mouchard L(4), Pissis SP(5).

Author information: 
(1)Department of Informatics, King's College London, The Strand, WC2R 2LS,
London, UK. carl.barton@kcl.ac.uk. (2)Inria Saclay-Île de France, AMIB, Bâtiment 
Alan Turing, Palaiseau, France. alice.heliou@lix.polytechnique.fr. (3)Laboratoire
d'Informatique de l'École Polytechnique (LIX), CNRS UMR 7161, Palaiseau, France. 
alice.heliou@lix.polytechnique.fr. (4)University of Rouen, LITIS EA 4108, TIBS,
Rouen, France. laurent.mouchard@univ-rouen.fr. (5)Department of Informatics,
King's College London, The Strand, WC2R 2LS, London, UK. solon.pissis@kcl.ac.uk.

BACKGROUND: An absent word of a word y of length n is a word that does not occur 
in y. It is a minimal absent word if all its proper factors occur in y. Minimal
absent words have been computed in genomes of organisms from all domains of life;
their computation also provides a fast alternative for measuring approximation in
sequence comparison. There exists an [Formula: see text]-time and [Formula: see
text]-space algorithm for computing all minimal absent words on a fixed-sized
alphabet based on the construction of suffix automata (Crochemore et al., 1998). 
No implementation of this algorithm is publicly available. There also exists an
[Formula: see text]-time and [Formula: see text]-space algorithm for the same
problem based on the construction of suffix arrays (Pinho et al., 2009). An
implementation of this algorithm was also provided by the authors and is
currently the fastest available.
RESULTS: Our contribution in this article is twofold: first, we bridge this
unpleasant gap by presenting an [Formula: see text]-time and [Formula: see
text]-space algorithm for computing all minimal absent words based on the
construction of suffix arrays; and second, we provide the respective
implementation of this algorithm. Experimental results, using real and synthetic 
data, show that this implementation outperforms the one by Pinho et al. The
open-source code of our implementation is freely available at
http://github.com/solonas13/maw .
CONCLUSIONS: Classical notions for sequence comparison are increasingly being
replaced by other similarity measures that refer to the composition of sequences 
in terms of their constituent patterns. One such measure is the minimal absent
words. In this article, we present a new linear-time and linear-space algorithm
for the computation of minimal absent words based on the suffix array.

DOI: 10.1186/s12859-014-0388-9 
PMCID: PMC4297395
PMID: 25526884  [PubMed - indexed for MEDLINE]


1110. Bioinformatics. 2015 May 1;31(9):1469-71. doi: 10.1093/bioinformatics/btu828.
Epub 2014 Dec 17.

VarSim: a high-fidelity simulation and validation framework for high-throughput
genome sequencing with cancer applications.

Mu JC(1), Mohiyuddin M(2), Li J(2), Bani Asadi N(2), Gerstein MB(2), Abyzov A(2),
Wong WH(1), Lam HY(2).

Author information: 
(1)Department of Electrical Engineering, Stanford University, Stanford, CA 94035,
USA, Department of Bioinformatics, Bina Technologies, Redwood City, CA 94065,
USA, Program in Computational Biology and Bioinformatics, Yale University, New
Haven, CT 06520, USA, Mayo Clinics, Department of Health Sciences Research,
Rochester, MN 55902, USA, Department of Statistics, Stanford University,
Stanford, CA 94035, USA and Department of Health Research and Policy, Stanford
University, Stanford, CA 94035, USA Department of Electrical Engineering,
Stanford University, Stanford, CA 94035, USA, Department of Bioinformatics, Bina 
Technologies, Redwood City, CA 94065, USA, Program in Computational Biology and
Bioinformatics, Yale University, New Haven, CT 06520, USA, Mayo Clinics,
Department of Health Sciences Research, Rochester, MN 55902, USA, Department of
Statistics, Stanford University, Stanford, CA 94035, USA and Department of Health
Research and Policy, Stanford University, Stanford, CA 94035, USA. (2)Department 
of Electrical Engineering, Stanford University, Stanford, CA 94035, USA,
Department of Bioinformatics, Bina Technologies, Redwood City, CA 94065, USA,
Program in Computational Biology and Bioinformatics, Yale University, New Haven, 
CT 06520, USA, Mayo Clinics, Department of Health Sciences Research, Rochester,
MN 55902, USA, Department of Statistics, Stanford University, Stanford, CA 94035,
USA and Department of Health Research and Policy, Stanford University, Stanford, 
CA 94035, USA.

SUMMARY: VarSim is a framework for assessing alignment and variant calling
accuracy in high-throughput genome sequencing through simulation or real data. In
contrast to simulating a random mutation spectrum, it synthesizes diploid genomes
with germline and somatic mutations based on a realistic model. This model
leverages information such as previously reported mutations to make the synthetic
genomes biologically relevant. VarSim simulates and validates a wide range of
variants, including single nucleotide variants, small indels and large structural
variants. It is an automated, comprehensive compute framework supporting parallel
computation and multiple read simulators. Furthermore, we developed a novel map
data structure to validate read alignments, a strategy to compare variants binned
in size ranges and a lightweight, interactive, graphical report to visualize
validation results with detailed statistics. Thus far, it is the most
comprehensive validation tool for secondary analysis in next generation
sequencing.
AVAILABILITY AND IMPLEMENTATION: Code in Java and Python along with instructions 
to download the reads and variants is at http://bioinform.github.io/varsim.
CONTACT: rd@bina.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu828 
PMCID: PMC4410653
PMID: 25524895  [PubMed - indexed for MEDLINE]


1111. BMC Med Genomics. 2014;7 Suppl 3:S3. doi: 10.1186/1755-8794-7-S3-S3. Epub 2014
Dec 8.

Molecular profiling of thyroid cancer subtypes using large-scale text mining.

Wu C, Schwartz JM, Brabant G, Nenadic G.

BACKGROUND: Thyroid cancer is the most common endocrine tumor with a steady
increase in incidence. It is classified into multiple histopathological subtypes 
with potentially distinct molecular mechanisms. Identifying the most relevant
genes and biological pathways reported in the thyroid cancer literature is vital 
for understanding of the disease and developing targeted therapeutics.
RESULTS: We developed a large-scale text mining system to generate a molecular
profiling of thyroid cancer subtypes. The system first uses a subtype
classification method for the thyroid cancer literature, which employs a scoring 
scheme to assign different subtypes to articles. We evaluated the classification 
method on a gold standard derived from the PubMed Supplementary Concept
annotations, achieving a micro-average F1-score of 85.9% for primary subtypes. We
then used the subtype classification results to extract genes and pathways
associated with different thyroid cancer subtypes and successfully unveiled
important genes and pathways, including some instances that are missing from
current manually annotated databases or most recent review articles.
CONCLUSIONS: Identification of key genes and pathways plays a central role in
understanding the molecular biology of thyroid cancer. An integration of subtype 
context can allow prioritized screening for diagnostic biomarkers and novel
molecular targeted therapeutics. Source code used for this study is made freely
available online at https://github.com/chengkun-wu/GenesThyCan.

DOI: 10.1186/1755-8794-7-S3-S3 
PMCID: PMC4290788
PMID: 25521965  [PubMed - indexed for MEDLINE]


1112. Nucleic Acids Res. 2015 Jan;43(2):691-8. doi: 10.1093/nar/gku1327. Epub 2014 Dec 
17.

Annotating RNA motifs in sequences and alignments.

Gardner PP(1), Eldai H(2).

Author information: 
(1)School of Biological Sciences, University of Canterbury, Private Bag 4800,
Christchurch 8140, New Zealand Biomolecular Interaction Centre, University of
Canterbury, Private Bag 4800, Christchurch 8140, New Zealand
paul.gardner@canterbury.ac.nz. (2)School of Biological Sciences, University of
Canterbury, Private Bag 4800, Christchurch 8140, New Zealand Biomolecular
Interaction Centre, University of Canterbury, Private Bag 4800, Christchurch
8140, New Zealand.

RNA performs a diverse array of important functions across all cellular life.
These functions include important roles in translation, building translational
machinery and maturing messenger RNA. More recent discoveries include the miRNAs 
and bacterial sRNAs that regulate gene expression, the thermosensors,
riboswitches and other cis-regulatory elements that help prokaryotes sense their 
environment and eukaryotic piRNAs that suppress transposition. However, there can
be a long period between the initial discovery of a RNA and determining its
function. We present a bioinformatic approach to characterize RNA motifs, which
are critical components of many RNA structure-function relationships. These
motifs can, in some instances, provide researchers with functional hypotheses for
uncharacterized RNAs. Moreover, we introduce a new profile-based database of RNA 
motifs--RMfam--and illustrate some applications for investigating the evolution
and functional characterization of RNA. All the data and scripts associated with 
this work are available from: https://github.com/ppgardne/RMfam.

© The Author(s) 2014. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gku1327 
PMCID: PMC4333381
PMID: 25520192  [PubMed - indexed for MEDLINE]


1113. Genome Biol. 2014;15(12):555.

Determining the quality and complexity of next-generation sequencing data without
a reference genome.

Anvar SY, Khachatryan L, Vermaat M, van Galen M, Pulyakhina I, Ariyurek Y,
Kraaijeveld K, den Dunnen JT, de Knijff P, 't Hoen PA, Laros JF.

We describe an open-source kPAL package that facilitates an alignment-free
assessment of the quality and comparability of sequencing datasets by analyzing
k-mer frequencies. We show that kPAL can detect technical artefacts such as high 
duplication rates, library chimeras, contamination and differences in library
preparation protocols. kPAL also successfully captures the complexity and
diversity of microbiomes and provides a powerful means to study changes in
microbial communities. Together, these features make kPAL an attractive and
broadly applicable tool to determine the quality and comparability of sequence
libraries even in the absence of a reference sequence. kPAL is freely available
at https://github.com/LUMC/kPAL webcite.

DOI: 10.1186/s13059-014-0555-3 
PMCID: PMC4298064
PMID: 25514851  [PubMed - indexed for MEDLINE]


1114. Bioinformatics. 2015 Apr 15;31(8):1316-8. doi: 10.1093/bioinformatics/btu823.
Epub 2014 Dec 12.

Detection of circular permutations within protein structures using CE-CP.

Bliven SE(1), Bourne PE(1), Prlić A(2).

Author information: 
(1)Bioinformatics and Systems Biology Program, University of California, San
Diego, La Jolla, CA 92093, USA, National Center for Biotechnology Information,
National Library of Medicine, National Institutes of Health, Bethesda, MD 20894, 
USA and RCSB Protein Data Bank, San Diego Supercomputer Center, University of
California, San Diego, La Jolla, CA 92093, USA Bioinformatics and Systems Biology
Program, University of California, San Diego, La Jolla, CA 92093, USA, National
Center for Biotechnology Information, National Library of Medicine, National
Institutes of Health, Bethesda, MD 20894, USA and RCSB Protein Data Bank, San
Diego Supercomputer Center, University of California, San Diego, La Jolla, CA
92093, USA. (2)Bioinformatics and Systems Biology Program, University of
California, San Diego, La Jolla, CA 92093, USA, National Center for Biotechnology
Information, National Library of Medicine, National Institutes of Health,
Bethesda, MD 20894, USA and RCSB Protein Data Bank, San Diego Supercomputer
Center, University of California, San Diego, La Jolla, CA 92093, USA.

MOTIVATION: Circular permutation is an important type of protein rearrangement.
Natural circular permutations have implications for protein function, stability
and evolution. Artificial circular permutations have also been used for protein
studies. However, such relationships are difficult to detect for many sequence
and structure comparison algorithms and require special consideration.
RESULTS: We developed a new algorithm, called Combinatorial Extension for
Circular Permutations (CE-CP), which allows the structural comparison of
circularly permuted proteins. CE-CP was designed to be user friendly and is
integrated into the RCSB Protein Data Bank. It was tested on two collections of
circularly permuted proteins. Pairwise alignments can be visualized both in a
desktop application or on the web using Jmol and exported to other programs in a 
variety of formats.
AVAILABILITY AND IMPLEMENTATION: The CE-CP algorithm can be accessed through the 
RCSB website at http://www.rcsb.org/pdb/workbench/workbench.do. Source code is
available under the LGPL 2.1 as part of BioJava 3 (http://biojava.org;
http://github.com/biojava/biojava).
CONTACT: sbliven@ucsd.edu or info@rcsb.org.

Published by Oxford University Press 2014. This work is written by US Government 
employees and is in the public domain in the US.

DOI: 10.1093/bioinformatics/btu823 
PMCID: PMC4393524
PMID: 25505094  [PubMed - indexed for MEDLINE]


1115. Bioinformatics. 2015 Apr 15;31(8):1298-301. doi: 10.1093/bioinformatics/btu818.
Epub 2014 Dec 12.

Sputnik: ad hoc distributed computation.

Völkel G(1), Lausser L(2), Schmid F(2), Kraus JM(2), Kestler HA(1).

Author information: 
(1)Core Unit Medical Systems Biology, Theoretical Computer Science, Ulm
University, D-89069 Ulm, Germany and Leibniz Institute for Age Research-Fritz
Lipmann Institute and FSU Jena, D-07745 Jena Core Unit Medical Systems Biology,
Theoretical Computer Science, Ulm University, D-89069 Ulm, Germany and Leibniz
Institute for Age Research-Fritz Lipmann Institute and FSU Jena, D-07745 Jena.
(2)Core Unit Medical Systems Biology, Theoretical Computer Science, Ulm
University, D-89069 Ulm, Germany and Leibniz Institute for Age Research-Fritz
Lipmann Institute and FSU Jena, D-07745 Jena.

MOTIVATION: In bioinformatic applications, computationally demanding algorithms
are often parallelized to speed up computation. Nevertheless, setting up
computational environments for distributed computation is often tedious. Aim of
this project were the lightweight ad hoc set up and fault-tolerant computation
requiring only a Java runtime, no administrator rights, while utilizing all CPU
cores most effectively.
RESULTS: The Sputnik framework provides ad hoc distributed computation on the
Java Virtual Machine which uses all supplied CPU cores fully. It provides a
graphical user interface for deployment setup and a web user interface displaying
the current status of current computation jobs. Neither a permanent setup nor
administrator privileges are required. We demonstrate the utility of our approach
on feature selection of microarray data.
AVAILABILITY AND IMPLEMENTATION: The Sputnik framework is available on Github
http://github.com/sysbio-bioinf/sputnik under the Eclipse Public License.
CONTACT: hkestler@fli-leibniz.de or hans.kestler@uni-ulm.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu818 
PMID: 25505087  [PubMed - indexed for MEDLINE]


1116. Bioinformatics. 2015 Apr 15;31(8):1310-2. doi: 10.1093/bioinformatics/btu825.
Epub 2014 Dec 12.

Phy-Mer: a novel alignment-free and reference-independent mitochondrial
haplogroup classifier.

Navarro-Gomez D(1), Leipzig J(1), Shen L(1), Lott M(1), Stassen AP(1), Wallace
DC(2), Wiggs JL(1), Falk MJ(2), van Oven M(1), Gai X(1).

Author information: 
(1)Department of Ophthalmology, Harvard Medical School, Massachusetts Eye and Ear
Infirmary, Boston, MA, USA, Center for Biomedical Informaticsand Center for
Mitochondrial and Epigenomic Medicine, The Children's Hospital of Philadelphia,
Philadelphia, PA, USA, Department of Clinical Genetics, Maastricht University
Medical Centre, The Netherlands, Department of Pathology and Laboratory Medicine,
University of Pennsylvania Perelman School of Medicine, Philadelphia, PA, USA,
Division of Human Genetics, The Children's Hospital of Philadelphia,
Philadelphia, PA, USA and Department of Forensic Molecular Biology, Erasmus MC,
University Medical Center Rotterdam, Rotterdam, The Netherlands. (2)Department of
Ophthalmology, Harvard Medical School, Massachusetts Eye and Ear Infirmary,
Boston, MA, USA, Center for Biomedical Informaticsand Center for Mitochondrial
and Epigenomic Medicine, The Children's Hospital of Philadelphia, Philadelphia,
PA, USA, Department of Clinical Genetics, Maastricht University Medical Centre,
The Netherlands, Department of Pathology and Laboratory Medicine, University of
Pennsylvania Perelman School of Medicine, Philadelphia, PA, USA, Division of
Human Genetics, The Children's Hospital of Philadelphia, Philadelphia, PA, USA
and Department of Forensic Molecular Biology, Erasmus MC, University Medical
Center Rotterdam, Rotterdam, The Netherlands Department of Ophthalmology, Harvard
Medical School, Massachusetts Eye and Ear Infirmary, Boston, MA, USA, Center for 
Biomedical Informaticsand Center for Mitochondrial and Epigenomic Medicine, The
Children's Hospital of Philadelphia, Philadelphia, PA, USA, Department of
Clinical Genetics, Maastricht University Medical Centre, The Netherlands,
Department of Pathology and Laboratory Medicine, University of Pennsylvania
Perelman School of Medicine, Philadelphia, PA, USA, Division of Human Genetics,
The Children's Hospital of Philadelphia, Philadelphia, PA, USA and Department of 
Forensic Molecular Biology, Erasmus MC, University Medical Center Rotterdam,
Rotterdam, The Netherlands.

MOTIVATION: All current mitochondrial haplogroup classification tools require
variants to be detected from an alignment with the reference sequence and to be
properly named according to the canonical nomenclature standards for describing
mitochondrial variants, before they can be compared with the haplogroup
determining polymorphisms. With the emergence of high-throughput sequencing
technologies and hence greater availability of mitochondrial genome sequences,
there is a strong need for an automated haplogroup classification tool that is
alignment-free and agnostic to reference sequence.
RESULTS: We have developed a novel mitochondrial genome haplogroup-defining
algorithm using a k-mer approach namely Phy-Mer. Phy-Mer performs equally well as
the leading haplogroup classifier, HaploGrep, while avoiding the errors that may 
occur when preparing variants to required formats and notations. We have further 
expanded Phy-Mer functionality such that next-generation sequencing data can be
used directly as input.
AVAILABILITY AND IMPLEMENTATION: Phy-Mer is publicly available under the GNU
Affero General Public License v3.0 on GitHub
(https://github.com/danielnavarrogomez/phy-mer).
CONTACT: Xiaowu_Gai@meei.harvard.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu825 
PMCID: PMC4393525
PMID: 25505086  [PubMed - indexed for MEDLINE]


1117. Bioinformatics. 2015 Apr 15;31(8):1169-75. doi: 10.1093/bioinformatics/btu815.
Epub 2014 Dec 10.

andi: fast and accurate estimation of evolutionary distances between closely
related genomes.

Haubold B(1), Klötzl F(2), Pfaffelhuber P(1).

Author information: 
(1)Department of Evolutionary Genetics, Max-Planck-Institute for Evolutionary
Biology, 24306 Plön, Germany, Institue for Neuro- and Bioinformatics, Lübeck
University, 23562 Lübeck, Germany and Mathematical Stochastics, Mathematical
Institute, Freiburg University, Germany. (2)Department of Evolutionary Genetics, 
Max-Planck-Institute for Evolutionary Biology, 24306 Plön, Germany, Institue for 
Neuro- and Bioinformatics, Lübeck University, 23562 Lübeck, Germany and
Mathematical Stochastics, Mathematical Institute, Freiburg University, Germany
Department of Evolutionary Genetics, Max-Planck-Institute for Evolutionary
Biology, 24306 Plön, Germany, Institue for Neuro- and Bioinformatics, Lübeck
University, 23562 Lübeck, Germany and Mathematical Stochastics, Mathematical
Institute, Freiburg University, Germany.

MOTIVATION: A standard approach to classifying sets of genomes is to calculate
their pairwise distances. This is difficult for large samples. We have therefore 
developed an algorithm for rapidly computing the evolutionary distances between
closely related genomes.
RESULTS: Our distance measure is based on ungapped local alignments that we
anchor through pairs of maximal unique matches of a minimum length. These exact
matches can be looked up efficiently using enhanced suffix arrays and our
implementation requires approximately only 1 s and 45 MB RAM/Mbase analysed. The 
pairing of matches distinguishes non-homologous from homologous regions leading
to accurate distance estimation. We show this by analysing simulated data and
genome samples ranging from 29 Escherichia coli/Shigella genomes to 3085 genomes 
of Streptococcus pneumoniae.
AVAILABILITY AND IMPLEMENTATION: We have implemented the computation of anchor
distances in the multithreaded UNIX command-line program andi for ANchor
DIstances. C sources and documentation are posted at
http://github.com/evolbioinf/andi/
CONTACT: haubold@evolbio.mpg.de
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu815 
PMID: 25504847  [PubMed - indexed for MEDLINE]


1118. Bioinformatics. 2015 Apr 15;31(8):1331-3. doi: 10.1093/bioinformatics/btu809.
Epub 2014 Dec 6.

ICMA: an integrated cardiac modeling and analysis platform.

Hussan JR(1), Hunter PJ(1), Gladding PA(1), Greenberg N(2), Christie R(1), Wu
A(1), Sorby H(1), Thomas JD(2).

Author information: 
(1)Auckland Bioengineering Institute, University of Auckland, Auckland, New
Zealand, Waitemata District Health Board, North Shore Hospital, Auckland 0622,
New Zealand, National Space Biomedical Research Institute, Houston, TX
77030-1402, USA, Cleveland Clinic Foundation, Cleveland, OH 44195, USA and
Feinberg School of Medicine, Northwestern University, Chicago, IL 60611, USA.
(2)Auckland Bioengineering Institute, University of Auckland, Auckland, New
Zealand, Waitemata District Health Board, North Shore Hospital, Auckland 0622,
New Zealand, National Space Biomedical Research Institute, Houston, TX
77030-1402, USA, Cleveland Clinic Foundation, Cleveland, OH 44195, USA and
Feinberg School of Medicine, Northwestern University, Chicago, IL 60611, USA
Auckland Bioengineering Institute, University of Auckland, Auckland, New Zealand,
Waitemata District Health Board, North Shore Hospital, Auckland 0622, New
Zealand, National Space Biomedical Research Institute, Houston, TX 77030-1402,
USA, Cleveland Clinic Foundation, Cleveland, OH 44195, USA and Feinberg School of
Medicine, Northwestern University, Chicago, IL 60611, USA.

ICMA, a software framework to create 3D finite element models of the left
ventricle from cardiac ultrasound or magnetic resonance imaging (MRI) data, has
been made available as an open-source code. The framework is hardware vendor
independent and uses speckle tracking (endocardial border detection) on
ultrasound (MRI) imaging data in the form of DICOM. Standard American Heart
Association segment-based strain analysis can be performed using a browser-based 
interface. The speckle tracking, border detection and model fitting methods are
implemented in C++ using open-source tools. They are wrapped as web services and 
orchestrated via a JBOSS-based application server.AVAILABILITY AND
IMPLEMENTATION: The source code for ICMA is freely available under MPL 1.1 or GPL
2.0 or LGPL 2.1 license at https://github.com/ABI-Software-Laboratory/ICMA and a 
standalone virtual machine at http://goo.gl/M4lJKH for download.
CONTACT: r.jagir@auckland.ac.nz
SUPPLEMENTARY INFORMATION: Supplementary materials are available at
Bioinformatics online.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu809 
PMCID: PMC4393521
PMID: 25481009  [PubMed - indexed for MEDLINE]


1119. Bioinformatics. 2015 Apr 15;31(8):1305-6. doi: 10.1093/bioinformatics/btu808.
Epub 2014 Dec 5.

Kablammo: an interactive, web-based BLAST results visualizer.

Wintersinger JA(1), Wasmuth JD(1).

Author information: 
(1)Department of Ecosystem and Public Health, Faculty of Veterinary Medicine,
University of Calgary, Calgary, Alberta, Canada.

MOTIVATION: Kablammo is a web-based application that produces interactive,
vector-based visualizations of sequence alignments generated by BLAST. These
visualizations can illustrate many features, including shared protein domains,
chromosome structural modifications and genome misassembly.
AVAILABILITY AND IMPLEMENTATION: Kablammo can be used at
http://kablammo.wasmuthlab.org. For a local installation, the source code and
instructions are available under the MIT license at
http://github.com/jwintersinger/kablammo.
CONTACT: jeff@wintersinger.org.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu808 
PMID: 25481007  [PubMed - indexed for MEDLINE]


1120. Bioinformatics. 2015 Apr 15;31(8):1235-42. doi: 10.1093/bioinformatics/btu802.
Epub 2014 Dec 4.

QuASAR: quantitative allele-specific analysis of reads.

Harvey CT(1), Moyerbrailean GA(1), Davis GO(1), Wen X(1), Luca F(1), Pique-Regi
R(1).

Author information: 
(1)Center for Molecular Medicine and Genetics, Department of Obstetrics and
Gynecology, Wayne State University, 540 E Canfield, Scott Hall, Detroit, MI
48201, USA and Department of Biostatistics, University of Michigan, Ann Arbor, MI
48109, USA.

MOTIVATION: Expression quantitative trait loci (eQTL) studies have discovered
thousands of genetic variants that regulate gene expression, enabling a better
understanding of the functional role of non-coding sequences. However, eQTL
studies are costly, requiring large sample sizes and genome-wide genotyping of
each sample. In contrast, analysis of allele-specific expression (ASE) is
becoming a popular approach to detect the effect of genetic variation on gene
expression, even within a single individual. This is typically achieved by
counting the number of RNA-seq reads matching each allele at heterozygous sites
and testing the null hypothesis of a 1:1 allelic ratio. In principle, when
genotype information is not readily available, it could be inferred from the
RNA-seq reads directly. However, there are currently no existing methods that
jointly infer genotypes and conduct ASE inference, while considering uncertainty 
in the genotype calls.
RESULTS: We present QuASAR, quantitative allele-specific analysis of reads, a
novel statistical learning method for jointly detecting heterozygous genotypes
and inferring ASE. The proposed ASE inference step takes into consideration the
uncertainty in the genotype calls, while including parameters that model
base-call errors in sequencing and allelic over-dispersion. We validated our
method with experimental data for which high-quality genotypes are available.
Results for an additional dataset with multiple replicates at different
sequencing depths demonstrate that QuASAR is a powerful tool for ASE analysis
when genotypes are not available.
AVAILABILITY AND IMPLEMENTATION: http://github.com/piquelab/QuASAR.
CONTACT: fluca@wayne.edu or rpique@wayne.edu
SUPPLEMENTARY INFORMATION: Supplementary Material is available at Bioinformatics 
online.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu802 
PMCID: PMC4393517
PMID: 25480375  [PubMed - indexed for MEDLINE]


1121. PLoS Comput Biol. 2014 Dec 4;10(12):e1003919. doi: 10.1371/journal.pcbi.1003919. 
eCollection 2014.

Bayesian inference of sampled ancestor trees for epidemiology and fossil
calibration.

Gavryushkina A(1), Welch D(2), Stadler T(3), Drummond AJ(1).

Author information: 
(1)Department of Computer Science, University of Auckland, Auckland, New Zealand;
Allan Wilson Centre for Molecular Ecology and Evolution, Massey University,
Palmerston North, New Zealand. (2)Department of Computer Science, University of
Auckland, Auckland, New Zealand. (3)Department of Biosystems Science and
Engineering, ETH Zürich, Switzerland.

Phylogenetic analyses which include fossils or molecular sequences that are
sampled through time require models that allow one sample to be a direct ancestor
of another sample. As previously available phylogenetic inference tools assume
that all samples are tips, they do not allow for this possibility. We have
developed and implemented a Bayesian Markov Chain Monte Carlo (MCMC) algorithm to
infer what we call sampled ancestor trees, that is, trees in which sampled
individuals can be direct ancestors of other sampled individuals. We use a family
of birth-death models where individuals may remain in the tree process after
sampling, in particular we extend the birth-death skyline model [Stadler et al., 
2013] to sampled ancestor trees. This method allows the detection of sampled
ancestors as well as estimation of the probability that an individual will be
removed from the process when it is sampled. We show that even if sampled
ancestors are not of specific interest in an analysis, failing to account for
them leads to significant bias in parameter estimates. We also show that sampled 
ancestor birth-death models where every sample comes from a different time point 
are non-identifiable and thus require one parameter to be known in order to infer
other parameters. We apply our phylogenetic inference accounting for sampled
ancestors to epidemiological data, where the possibility of sampled ancestors
enables us to identify individuals that infected other individuals after being
sampled and to infer fundamental epidemiological parameters. We also apply the
method to infer divergence times and diversification rates when fossils are
included along with extant species samples, so that fossilisation events are
modelled as a part of the tree branching process. Such modelling has many
advantages as argued in the literature. The sampler is available as an
open-source BEAST2 package (https://github.com/CompEvol/sampled-ancestors).

DOI: 10.1371/journal.pcbi.1003919 
PMCID: PMC4263412
PMID: 25474353  [PubMed - indexed for MEDLINE]


1122. PLoS One. 2014 Dec 2;9(12):e114253. doi: 10.1371/journal.pone.0114253.
eCollection 2014.

PERGA: a paired-end read guided de novo assembler for extending contigs using SVM
and look ahead approach.

Zhu X(1), Leung HC(2), Chin FY(2), Yiu SM(2), Quan G(3), Liu B(1), Wang Y(1).

Author information: 
(1)Center for Bioinformatics, School of Computer Science and Technology, Harbin
Institute of Technology, Harbin, Heilongjiang, China. (2)Department of Computer
Science, University of Hong Kong, Hong Kong. (3)National Pilot School of
Software, Harbin Institute of Technology, Weihai, Shandong, China.

Since the read lengths of high throughput sequencing (HTS) technologies are
short, de novo assembly which plays significant roles in many applications
remains a great challenge. Most of the state-of-the-art approaches base on de
Bruijn graph strategy and overlap-layout strategy. However, these approaches
which depend on k-mers or read overlaps do not fully utilize information of
paired-end and single-end reads when resolving branches. Since they treat all
single-end reads with overlapped length larger than a fix threshold equally, they
fail to use the more confident long overlapped reads for assembling and mix up
with the relative short overlapped reads. Moreover, these approaches have not
been special designed for handling tandem repeats (repeats occur adjacently in
the genome) and they usually break down the contigs near the tandem repeats. We
present PERGA (Paired-End Reads Guided Assembler), a novel sequence-reads-guided 
de novo assembly approach, which adopts greedy-like prediction strategy for
assembling reads to contigs and scaffolds using paired-end reads and different
read overlap size ranging from Omax to Omin to resolve the gaps and branches. By 
constructing a decision model using machine learning approach based on branch
features, PERGA can determine the correct extension in 99.7% of cases. When the
correct extension cannot be determined, PERGA will try to extend the contig by
all feasible extensions and determine the correct extension by using look-ahead
approach. Many difficult-resolved branches are due to tandem repeats which are
close in the genome. PERGA detects such different copies of the repeats to
resolve the branches to make the extension much longer and more accurate. We
evaluated PERGA on both Illumina real and simulated datasets ranging from small
bacterial genomes to large human chromosome, and it constructed longer and more
accurate contigs and scaffolds than other state-of-the-art assemblers. PERGA can 
be freely downloaded at https://github.com/hitbio/PERGA.

DOI: 10.1371/journal.pone.0114253 
PMCID: PMC4252104
PMID: 25461763  [PubMed - indexed for MEDLINE]


1123. Cancer Inform. 2014 Oct 15;13(Suppl 4):45-52. doi: 10.4137/CIN.S13979.
eCollection 2014.

Toolbox for mobile-element insertion detection on cancer genomes.

Lee WP(1), Wu J(2), Marth GT(3).

Author information: 
(1)Department of Biology, Boston College, Chestnut Hill, MA, USA. ; Currently at 
Seven Bridges Genomics, Cambridge, MA, USA. (2)Department of Biology, Boston
College, Chestnut Hill, MA, USA. ; Currently at Yelp, Inc. San Francisco, CA,
USA. (3)Department of Biology, Boston College, Chestnut Hill, MA, USA. ;
Currently at the Department of Human Genetics and Utah Center for Genetic
Discovery, University of Utah, Salt Lake City, UT, USA.

Mobile elements constitute greater than 45% of the human genome as a result of
repeated insertion events during human genome evolution. Although most of mobile 
elements are fixed within the human population, some elements (including ALU,
long interspersed elements (LINE) 1 (L1), and SVA) are still actively duplicating
and may result in life-threatening human diseases such as cancer, motivating the 
need for accurate mobile-element insertion (MEI) detection tools. We developed a 
software package, TANGRAM, for MEI detection in next-generation sequencing data, 
currently serving as the primary MEI detection tool in the 1000 Genomes Project. 
TANGRAM takes advantage of valuable mapping information provided by our own
MOSAIK mapper, and until recently required MOSAIK mappings as its input. In this 
study, we report a new feature that enables TANGRAM to be used on alignments
generated by any mainstream short-read mapper, making it accessible for many
genomic users. To demonstrate its utility for cancer genome analysis, we have
applied TANGRAM to the TCGA (The Cancer Genome Atlas) mutation calling benchmark 
4 dataset. TANGRAM is fast, accurate, easy to use, and open source on
https://github.com/jiantao/Tangram.

DOI: 10.4137/CIN.S13979 
PMCID: PMC4218655
PMID: 25452688  [PubMed]


1124. Mol Cell Proteomics. 2015 Feb;14(2):405-17. doi: 10.1074/mcp.O114.041376. Epub
2014 Nov 30.

Preprocessing significantly improves the peptide/protein identification
sensitivity of high-resolution isobarically labeled tandem mass spectrometry
data.

Sheng Q(1), Li R(2), Dai J(3), Li Q(2), Su Z(2), Guo Y(4), Li C(2), Shyr Y(5),
Zeng R(6).

Author information: 
(1)From the ‡Key Laboratory of Systems Biology, Institute of Biochemistry and
Cell Biology, Shanghai Institutes for Biological Science, Chinese Academy of
Sciences, Shanghai 200031, China; §Center for Quantitative Sciences, Vanderbilt
University, Nashville, Tennessee 37232-6848; (2)From the ‡Key Laboratory of
Systems Biology, Institute of Biochemistry and Cell Biology, Shanghai Institutes 
for Biological Science, Chinese Academy of Sciences, Shanghai 200031, China;
(3)¶Department of Biochemistry and Molecular Biology, University of Southern
Denmark, Odense M 5230, Denmark. (4)§Center for Quantitative Sciences, Vanderbilt
University, Nashville, Tennessee 37232-6848; (5)§Center for Quantitative
Sciences, Vanderbilt University, Nashville, Tennessee 37232-6848; zr@sibs.ac.cn
yu.shyr@vanderbilt.edu. (6)From the ‡Key Laboratory of Systems Biology, Institute
of Biochemistry and Cell Biology, Shanghai Institutes for Biological Science,
Chinese Academy of Sciences, Shanghai 200031, China; zr@sibs.ac.cn
yu.shyr@vanderbilt.edu.

Isobaric labeling techniques coupled with high-resolution mass spectrometry have 
been widely employed in proteomic workflows requiring relative quantification.
For each high-resolution tandem mass spectrum (MS/MS), isobaric labeling
techniques can be used not only to quantify the peptide from different samples by
reporter ions, but also to identify the peptide it is derived from. Because the
ions related to isobaric labeling may act as noise in database searching, the
MS/MS spectrum should be preprocessed before peptide or protein identification.
In this article, we demonstrate that there are a lot of high-frequency,
high-abundance isobaric related ions in the MS/MS spectrum, and removing isobaric
related ions combined with deisotoping and deconvolution in MS/MS preprocessing
procedures significantly improves the peptide/protein identification sensitivity.
The user-friendly software package TurboRaw2MGF (v2.0) has been implemented for
converting raw TIC data files to mascot generic format files and can be
downloaded for free from https://github.com/shengqh/RCPA.Tools/releases as part
of the software suite ProteomicsTools. The data have been deposited to the
ProteomeXchange with identifier PXD000994.

© 2015 by The American Society for Biochemistry and Molecular Biology, Inc.

DOI: 10.1074/mcp.O114.041376 
PMCID: PMC4350035
PMID: 25435543  [PubMed - indexed for MEDLINE]


1125. BMC Bioinformatics. 2014 Nov 28;15:370. doi: 10.1186/s12859-014-0370-6.

PyTMs: a useful PyMOL plugin for modeling common post-translational
modifications.

Warnecke A(1), Sandalova T(2), Achour A(3), Harris RA(4).

Author information: 
(1)Department of Clinical Neuroscience, Karolinska Institutet, Center for
Molecular Medicine, Applied Immunology & Immunotherapy, L8:04, Karolinska
Hospital, SE-171 76, Stockholm, Sweden. andreas.warnecke@ki.se. (2)Department of 
Medicine Solna, Science for Life Laboratory, Karolinska Institutet, Stockholm,
Sweden. Tatyana.Sandalova@ki.se. (3)Department of Medicine Solna, Science for
Life Laboratory, Karolinska Institutet, Stockholm, Sweden. Adnane.Achour@ki.se.
(4)Department of Clinical Neuroscience, Karolinska Institutet, Center for
Molecular Medicine, Applied Immunology & Immunotherapy, L8:04, Karolinska
Hospital, SE-171 76, Stockholm, Sweden. robert.harris@ki.se.

BACKGROUND: Post-translational modifications (PTMs) constitute a major aspect of 
protein biology, particularly signaling events. Conversely, several different
pathophysiological PTMs are hallmarks of oxidative imbalance or inflammatory
states and are strongly associated with pathogenesis of autoimmune diseases or
cancers. Accordingly, it is of interest to assess both the biological and
structural effects of modification. For the latter, computer-based modeling
offers an attractive option. We thus identified the need for easily applicable
modeling options for PTMs.
RESULTS: We developed PyTMs, a plugin implemented with the commonly used
visualization software PyMOL. PyTMs enables users to introduce a set of common
PTMs into protein/peptide models and can be used to address research questions
related to PTMs. Ten types of modification are currently supported, including
acetylation, carbamylation, citrullination, cysteine oxidation, malondialdehyde
adducts, methionine oxidation, methylation, nitration, proline hydroxylation and 
phosphorylation. Furthermore, advanced settings integrate the pre-selection of
surface-exposed atoms, define stereochemical alternatives and allow for basic
structure optimization of the newly modified residues.
CONCLUSION: PyTMs is a useful, user-friendly modelling plugin for PyMOL.
Advantages of PyTMs include standardized generation of PTMs, rapid time-to-result
and facilitated user control. Although modeling cannot substitute for
conventional structure determination it constitutes a convenient tool that allows
uncomplicated exploration of potential implications prior to experimental
investments and basic explanation of experimental data. PyTMs is freely available
as part of the PyMOL script repository project on GitHub and will further evolve.
Graphical Abstract PyTMs is a useful PyMOL plugin for modeling common
post-translational modifications.

DOI: 10.1186/s12859-014-0370-6 
PMCID: PMC4256751
PMID: 25431162  [PubMed - indexed for MEDLINE]


1126. Nucleic Acids Res. 2015 Feb 18;43(3):e16. doi: 10.1093/nar/gku1197. Epub 2014 Nov
26.

HiTSelect: a comprehensive tool for high-complexity-pooled screen analysis.

Diaz AA(1), Qin H(2), Ramalho-Santos M(3), Song JS(4).

Author information: 
(1)Institute for Human Genetics, University of California, San Francisco, CA, USA
The Eli and Edythe Broad Center of Regeneration Medicine and Stem Cell Research, 
University of California, San Francisco, CA, USA Department of Epidemiology and
Biostatistics, University of California, San Francisco, CA, USA. (2)The Eli and
Edythe Broad Center of Regeneration Medicine and Stem Cell Research, University
of California, San Francisco, CA, USA Departments of Obstetrics and Gynecology
and Pathology and Center for Reproductive Sciences, University of California, San
Francisco, CA, USA Diabetes Center, University of California, San Francisco, CA, 
USA. (3)The Eli and Edythe Broad Center of Regeneration Medicine and Stem Cell
Research, University of California, San Francisco, CA, USA Departments of
Obstetrics and Gynecology and Pathology and Center for Reproductive Sciences,
University of California, San Francisco, CA, USA Diabetes Center, University of
California, San Francisco, CA, USA songj@illinois.edu. (4)Institute for Human
Genetics, University of California, San Francisco, CA, USA The Eli and Edythe
Broad Center of Regeneration Medicine and Stem Cell Research, University of
California, San Francisco, CA, USA Department of Epidemiology and Biostatistics, 
University of California, San Francisco, CA, USA songj@illinois.edu.

Genetic screens of an unprecedented scale have recently been made possible by the
availability of high-complexity libraries of synthetic oligonucleotides designed 
to mediate either gene knockdown or gene knockout, coupled with next-generation
sequencing. However, several sources of random noise and statistical biases
complicate the interpretation of the resulting high-throughput data. We developed
HiTSelect, a comprehensive analysis pipeline for rigorously selecting screen hits
and identifying functionally relevant genes and pathways by addressing off-target
effects, controlling for variance in both gene silencing efficiency and
sequencing depth of coverage and integrating relevant metadata. We document the
superior performance of HiTSelect using data from both genome-wide RNAi and
CRISPR/Cas9 screens. HiTSelect is implemented as an open-source package, with a
user-friendly interface for data visualization and pathway exploration. Binary
executables are available at http://sourceforge.net/projects/hitselect/, and the 
source code is available at https://github.com/diazlab/HiTSelect.

© The Author(s) 2014. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gku1197 
PMCID: PMC4330337
PMID: 25428347  [PubMed - indexed for MEDLINE]


1127. Genome Med. 2014 Nov 20;6(11):90. doi: 10.1186/s13073-014-0090-6. eCollection
2014.

SRST2: Rapid genomic surveillance for public health and hospital microbiology
labs.

Inouye M(1), Dashnow H(2), Raven LA(3), Schultz MB(4), Pope BJ(5), Tomita T(6),
Zobel J(7), Holt KE(4).

Author information: 
(1)Medical Systems Biology, Department of Pathology, The University of Melbourne,
Parkville, Victoria Australia ; Department of Microbiology and Immunology, The
University of Melbourne, Parkville, Victoria Australia. (2)Department of
Biochemistry and Molecular Biology, Bio21 Molecular Science and Biotechnology
Institute, University of Melbourne, Parkville, Victoria 3010 Australia ;
Victorian Life Sciences Computation Initiative, The University of Melbourne, 187 
Grattan Street Carlton, Melbourne, Victoria Australia. (3)Medical Systems
Biology, Department of Pathology, The University of Melbourne, Parkville,
Victoria Australia. (4)Department of Biochemistry and Molecular Biology, Bio21
Molecular Science and Biotechnology Institute, University of Melbourne,
Parkville, Victoria 3010 Australia. (5)Victorian Life Sciences Computation
Initiative, The University of Melbourne, 187 Grattan Street Carlton, Melbourne,
Victoria Australia ; Department of Computing and Information Systems, The
University of Melbourne, Parkville, Victoria Australia. (6)Department of
Microbiology and Immunology, The University of Melbourne, Parkville, Victoria
Australia ; Microbiological Diagnostic Unit, The University of Melbourne,
Parkville, Victoria Australia. (7)Department of Computing and Information
Systems, The University of Melbourne, Parkville, Victoria Australia.

Rapid molecular typing of bacterial pathogens is critical for public health
epidemiology, surveillance and infection control, yet routine use of whole genome
sequencing (WGS) for these purposes poses significant challenges. Here we present
SRST2, a read mapping-based tool for fast and accurate detection of genes,
alleles and multi-locus sequence types (MLST) from WGS data. Using >900 genomes
from common pathogens, we show SRST2 is highly accurate and outperforms
assembly-based methods in terms of both gene detection and allele assignment. We 
include validation of SRST2 within a public health laboratory, and demonstrate
its use for microbial genome surveillance in the hospital setting. In the face of
rising threats of antimicrobial resistance and emerging virulence among bacterial
pathogens, SRST2 represents a powerful tool for rapidly extracting clinically
useful information from raw WGS data. Source code is available from
http://katholt.github.io/srst2/.

DOI: 10.1186/s13073-014-0090-6 
PMCID: PMC4237778
PMID: 25422674  [PubMed]


1128. Bioinformatics. 2015 Apr 1;31(7):1138-40. doi: 10.1093/bioinformatics/btu773.
Epub 2014 Nov 19.

The Victor C++ library for protein representation and advanced manipulation.

Hirsh L(1), Piovesan D(2), Giollo M(1), Ferrari C(2), Tosatto SC(2).

Author information: 
(1)Department of Biomedical Sciences, University of Padua, Viale G. Colombo 3,
35131 Padova, Italy, Department of Engineering, Pontificia Universidad Católica
del Perú, San Miguel, 32 Lima, Perú and Department of Information Engineering,
University of Padua, Via Gradenigo 6, 35121 Padova, Italy Department of
Biomedical Sciences, University of Padua, Viale G. Colombo 3, 35131 Padova,
Italy, Department of Engineering, Pontificia Universidad Católica del Perú, San
Miguel, 32 Lima, Perú and Department of Information Engineering, University of
Padua, Via Gradenigo 6, 35121 Padova, Italy. (2)Department of Biomedical
Sciences, University of Padua, Viale G. Colombo 3, 35131 Padova, Italy,
Department of Engineering, Pontificia Universidad Católica del Perú, San Miguel, 
32 Lima, Perú and Department of Information Engineering, University of Padua, Via
Gradenigo 6, 35121 Padova, Italy.

MOTIVATION: Protein sequence and structure representation and manipulation
require dedicated software libraries to support methods of increasing complexity.
Here, we describe the VIrtual Constrution TOol for pRoteins (Victor) C++ library,
an open source platform dedicated to enabling inexperienced users to develop
advanced tools and gathering contributions from the community. The provided
application examples cover statistical energy potentials, profile-profile
sequence alignments and ab initio loop modeling. Victor was used over the last 15
years in several publications and optimized for efficiency. It is provided as a
GitHub repository with source files and unit tests, plus extensive online
documentation, including a Wiki with help files and tutorials, examples and
Doxygen documentation.
AVAILABILITY AND IMPLEMENTATION: The C++ library and online documentation,
distributed under a GPL license are available from URL:
http://protein.bio.unipd.it/victor/.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu773 
PMID: 25414364  [PubMed - indexed for MEDLINE]


1129. Nucleic Acids Res. 2015 Feb 18;43(3):e15. doi: 10.1093/nar/gku1196. Epub 2014 Nov
20.

Rapid phylogenetic analysis of large samples of recombinant bacterial whole
genome sequences using Gubbins.

Croucher NJ(1), Page AJ(2), Connor TR(3), Delaney AJ(4), Keane JA(2), Bentley
SD(5), Parkhill J(2), Harris SR(6).

Author information: 
(1)Pathogen Genomics, The Wellcome Trust Sanger Institute, Wellcome Trust Genome 
Campus, Hinxton, Cambridge CB10 1SA, UK Center for Communicable Disease Dynamics,
Harvard School of Public Health, 677 Longwood Avenue, Boston, MA 02115, USA
Department of Infectious Disease Epidemiology, Imperial College London, St.
Mary's Campus, Norfolk Place, London W2 1PG, UK. (2)Pathogen Genomics, The
Wellcome Trust Sanger Institute, Wellcome Trust Genome Campus, Hinxton, Cambridge
CB10 1SA, UK. (3)Pathogen Genomics, The Wellcome Trust Sanger Institute, Wellcome
Trust Genome Campus, Hinxton, Cambridge CB10 1SA, UK Cardiff School of
Biosciences, Sir Martin Evans Building, Museum Avenue, Cardiff CF10 3AX, UK.
(4)School of Computing, Engineering and Mathematics, University of Brighton,
Brighton BN2 4GJ, UK. (5)Pathogen Genomics, The Wellcome Trust Sanger Institute, 
Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SA, UK Department of
Medicine, University of Cambridge, Addenbrooke's Hospital, Cambridge CB2 0SP, UK.
(6)Pathogen Genomics, The Wellcome Trust Sanger Institute, Wellcome Trust Genome 
Campus, Hinxton, Cambridge CB10 1SA, UK simon.harris@sanger.ac.uk.

The emergence of new sequencing technologies has facilitated the use of bacterial
whole genome alignments for evolutionary studies and outbreak analyses. These
datasets, of increasing size, often include examples of multiple different
mechanisms of horizontal sequence transfer resulting in substantial alterations
to prokaryotic chromosomes. The impact of these processes demands rapid and
flexible approaches able to account for recombination when reconstructing
isolates' recent diversification. Gubbins is an iterative algorithm that uses
spatial scanning statistics to identify loci containing elevated densities of
base substitutions suggestive of horizontal sequence transfer while concurrently 
constructing a maximum likelihood phylogeny based on the putative point mutations
outside these regions of high sequence diversity. Simulations demonstrate the
algorithm generates highly accurate reconstructions under realistically
parameterized models of bacterial evolution, and achieves convergence in only a
few hours on alignments of hundreds of bacterial genome sequences. Gubbins is
appropriate for reconstructing the recent evolutionary history of a variety of
haploid genotype alignments, as it makes no assumptions about the underlying
mechanism of recombination. The software is freely available for download at
github.com/sanger-pathogens/Gubbins, implemented in Python and C and supported on
Linux and Mac OS X.

© The Author(s) 2014. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gku1196 
PMCID: PMC4330336
PMID: 25414349  [PubMed - indexed for MEDLINE]


1130. Genome Biol. 2014;15(11):524.

The Harvest suite for rapid core-genome alignment and visualization of thousands 
of intraspecific microbial genomes.

Treangen TJ, Ondov BD, Koren S, Phillippy AM.

Whole-genome sequences are now available for many microbial species and clades,
however existing whole-genome alignment methods are limited in their ability to
perform sequence comparisons of multiple sequences simultaneously. Here we
present the Harvest suite of core-genome alignment and visualization tools for
the rapid and simultaneous analysis of thousands of intraspecific microbial
strains. Harvest includes Parsnp, a fast core-genome multi-aligner, and Gingr, a 
dynamic visual platform. Together they provide interactive core-genome
alignments, variant calls, recombination detection, and phylogenetic trees. Using
simulated and real data we demonstrate that our approach exhibits unrivaled speed
while maintaining the accuracy of existing methods. The Harvest suite is
open-source and freely available from: http://github.com/marbl/harvest.

DOI: 10.1186/PREACCEPT-2573980311437212 
PMCID: PMC4262987
PMID: 25410596  [PubMed - indexed for MEDLINE]


1131. Int J Comput Assist Radiol Surg. 2015 Mar;10(3):301-16. doi:
10.1007/s11548-014-1124-7. Epub 2014 Nov 20.

The NifTK software platform for image-guided interventions: platform overview and
NiftyLink messaging.

Clarkson MJ(1), Zombori G, Thompson S, Totz J, Song Y, Espak M, Johnsen S, Hawkes
D, Ourselin S.

Author information: 
(1)Centre For Medical Image Computing, University College London, Engineering
Front Building, Malet Place, London, UK, m.clarkson@ucl.ac.uk.

PURPOSE: To perform research in image-guided interventions, researchers need a
wide variety of software components, and assembling these components into a
flexible and reliable system can be a challenging task. In this paper, the NifTK 
software platform is presented. A key focus has been high-performance streaming
of stereo laparoscopic video data, ultrasound data and tracking data
simultaneously.
METHODS: A new messaging library called NiftyLink is introduced that uses the
OpenIGTLink protocol and provides the user with easy-to-use asynchronous two-way 
messaging, high reliability and comprehensive error reporting. A small suite of
applications called NiftyGuide has been developed, containing lightweight
applications for grabbing data, currently from position trackers and ultrasound
scanners. These applications use NiftyLink to stream data into NiftyIGI, which is
a workstation-based application, built on top of MITK, for visualisation and user
interaction. Design decisions, performance characteristics and initial
applications are described in detail. NiftyLink was tested for latency when
transmitting images, tracking data, and interleaved imaging and tracking data.
RESULTS: NiftyLink can transmit tracking data at 1,024 frames per second (fps)
with latency of 0.31 milliseconds, and 512 KB images with latency of
6.06 milliseconds at 32 fps. NiftyIGI was tested, receiving stereo
high-definition laparoscopic video at 30 fps, tracking data from 4 rigid bodies
at 20-30 fps and ultrasound data at 20 fps with rendering refresh rates between 2
and 20 Hz with no loss of user interaction.
CONCLUSION: These packages form part of the NifTK platform and have proven to be 
successful in a variety of image-guided surgery projects. Code and documentation 
for the NifTK platform are available from http://www.niftk.org . NiftyLink is
provided open-source under a BSD license and available from
http://github.com/NifTK/NiftyLink . The code for this paper is tagged
IJCARS-2014.

DOI: 10.1007/s11548-014-1124-7 
PMCID: PMC4338364
PMID: 25408304  [PubMed - indexed for MEDLINE]


1132. BMC Bioinformatics. 2014 Nov 19;15:357. doi: 10.1186/s12859-014-0357-3.

NeatFreq: reference-free data reduction and coverage normalization for De Novo
sequence assembly.

McCorrison JM(1), Venepally P(2), Singh I(3), Fouts DE(4), Lasken RS(5), Methé
BA(6,)(7).

Author information: 
(1)Informatics Core Services, The J. Craig Venter Institute (JCVI), 9704 Medical 
Center Drive, Rockville, MD, 20850, USA. jmccorri@jcvi.org. (2)Informatics Core
Services, The J. Craig Venter Institute (JCVI), 9704 Medical Center Drive,
Rockville, MD, 20850, USA. pratap@jcvi.org. (3)Informatics Core Services, The J. 
Craig Venter Institute (JCVI), 9704 Medical Center Drive, Rockville, MD, 20850,
USA. isingh@jcvi.org. (4)Department of Genomic Medicine, The J. Craig Venter
Institute (JCVI), 9704 Medical Center Drive, Rockville, MD, 20850, USA.
dfouts@jcvi.org. (5)Department of Microbial & Environmental Genomics, The J.
Craig Venter Institute (JCVI), 9704 Medical Center Drive, Rockville, MD20850,
USA. rlasken@jcvi.org. (6)Department of Genomic Medicine, The J. Craig Venter
Institute (JCVI), 9704 Medical Center Drive, Rockville, MD, 20850, USA.
bmethe@jcvi.org. (7)Department of Microbial & Environmental Genomics, The J.
Craig Venter Institute (JCVI), 9704 Medical Center Drive, Rockville, MD20850,
USA. bmethe@jcvi.org.

BACKGROUND: Deep shotgun sequencing on next generation sequencing (NGS) platforms
has contributed significant amounts of data to enrich our understanding of
genomes, transcriptomes, amplified single-cell genomes, and metagenomes. However,
deep coverage variations in short-read data sets and high sequencing error rates 
of modern sequencers present new computational challenges in data interpretation,
including mapping and de novo assembly. New lab techniques such as multiple
displacement amplification (MDA) of single cells and sequence independent single 
primer amplification (SISPA) allow for sequencing of organisms that cannot be
cultured, but generate highly variable coverage due to amplification biases.
RESULTS: Here we introduce NeatFreq, a software tool that reduces a data set to
more uniform coverage by clustering and selecting from reads binned by their
median kmer frequency (RMKF) and uniqueness. Previous algorithms normalize read
coverage based on RMKF, but do not include methods for the preferred selection of
(1) extremely low coverage regions produced by extremely variable sequencing of
random-primed products and (2) 2-sided paired-end sequences. The algorithm
increases the incorporation of the most unique, lowest coverage, segments of a
genome using an error-corrected data set. NeatFreq was applied to bacterial,
viral plaque, and single-cell sequencing data. The algorithm showed an increase
in the rate at which the most unique reads in a genome were included in the
assembled consensus while also reducing the count of duplicative and erroneous
contigs (strings of high confidence overlaps) in the deliverable consensus. The
results obtained from conventional Overlap-Layout-Consensus (OLC) were compared
to simulated multi-de Bruijn graph assembly alternatives trained for variable
coverage input using sequence before and after normalization of coverage.
Coverage reduction was shown to increase processing speed and reduce memory
requirements when using conventional bacterial assembly algorithms.
CONCLUSIONS: The normalization of deep coverage spikes, which would otherwise
inhibit consensus resolution, enables High Throughput Sequencing (HTS) assembly
projects to consistently run to completion with existing assembly software. The
NeatFreq software package is free, open source and available at
https://github.com/bioh4x/NeatFreq .

DOI: 10.1186/s12859-014-0357-3 
PMCID: PMC4245761
PMID: 25407910  [PubMed - indexed for MEDLINE]


1133. RNA. 2015 Jan;21(1):14-27. doi: 10.1261/rna.046037.114. Epub 2014 Nov 18.

IsoSCM: improved and alternative 3' UTR annotation using multiple change-point
inference.

Shenker S(1), Miura P(2), Sanfilippo P(1), Lai EC(3).

Author information: 
(1)Department of Developmental Biology, Sloan-Kettering Institute, New York, New 
York 10065, USA Tri-Institutional Program in Computational Biology and Medicine, 
Weill Cornell Medical College, New York, New York 10065, USA. (2)Department of
Developmental Biology, Sloan-Kettering Institute, New York, New York 10065, USA. 
(3)Department of Developmental Biology, Sloan-Kettering Institute, New York, New 
York 10065, USA laie@mskcc.org.

Major applications of RNA-seq data include studies of how the transcriptome is
modulated at the levels of gene expression and RNA processing, and how these
events are related to cellular identity, environmental condition, and/or disease 
status. While many excellent tools have been developed to analyze RNA-seq data,
these generally have limited efficacy for annotating 3' UTRs. Existing assembly
strategies often fragment long 3' UTRs, and importantly, none of the algorithms
in popular use can apportion data into tandem 3' UTR isoforms, which are
frequently generated by alternative cleavage and polyadenylation (APA).
Consequently, it is often not possible to identify patterns of differential APA
using existing assembly tools. To address these limitations, we present a new
method for transcript assembly, Isoform Structural Change Model (IsoSCM) that
incorporates change-point analysis to improve the 3' UTR annotation process.
Through evaluation on simulated and genuine data sets, we demonstrate that IsoSCM
annotates 3' termini with higher sensitivity and specificity than can be achieved
with existing methods. We highlight the utility of IsoSCM by demonstrating its
ability to recover known patterns of tissue-regulated APA. IsoSCM will facilitate
future efforts for 3' UTR annotation and genome-wide studies of the breadth,
regulation, and roles of APA leveraging RNA-seq data. The IsoSCM software and
source code are available from our website https://github.com/shenkers/isoscm.

© 2014 Shenker et al.; Published by Cold Spring Harbor Laboratory Press for the
RNA Society.

DOI: 10.1261/rna.046037.114 
PMCID: PMC4274634
PMID: 25406361  [PubMed - indexed for MEDLINE]


1134. PLoS One. 2014 Nov 17;9(11):e110263. doi: 10.1371/journal.pone.0110263.
eCollection 2014.

Exome-wide somatic microsatellite variation is altered in cells with DNA repair
deficiencies.

Vaksman Z(1), Fonville NC(1), Tae H(1), Garner HR(2).

Author information: 
(1)Virginia Bioinformatics Institute, Virginia Tech, Blacksburg, Virginia, 24061,
United States of America. (2)Virginia Bioinformatics Institute, Virginia Tech,
Blacksburg, Virginia, 24061, United States of America; Genomeon LLC, Floyd,
Virginia, 24091, United States of America.

Microsatellites (MST), tandem repeats of 1-6 nucleotide motifs, are mutational
hot-spots with a bias for insertions and deletions (INDELs) rather than single
nucleotide polymorphisms (SNPs). The majority of MST instability studies are
limited to a small number of loci, the Bethesda markers, which are only
informative for a subset of colorectal cancers. In this paper we evaluate
non-haplotype alleles present within next-gen sequencing data to evaluate somatic
MST variation (SMV) within DNA repair proficient and DNA repair defective cell
lines. We confirm that alleles present within next-gen data that do not
contribute to the haplotype can be reliably quantified and utilized to evaluate
the SMV without requiring comparisons of matched samples. We observed that SMV
patterns found in DNA repair proficient cell lines without DNA repair defects,
MCF10A, HEK293 and PD20 RV:D2, had consistent patterns among samples. Further, we
were able to confirm that changes in SMV patterns in cell lines lacking
functional BRCA2, FANCD2 and mismatch repair were consistent with the different
pathways perturbed. Using this new exome sequencing analysis approach we show
that DNA instability can be identified in a sample and that patterns of
instability vary depending on the impaired DNA repair mechanism, and that genes
harboring minor alleles are strongly associated with cancer pathways. The MST
Minor Allele Caller used for this study is available at
https://github.com/zalmanv/MST_minor_allele_caller.

DOI: 10.1371/journal.pone.0110263 
PMCID: PMC4234249
PMID: 25402475  [PubMed - indexed for MEDLINE]


1135. Microsc Microanal. 2014 Dec;20(6):1764-71. doi: 10.1017/S1431927614013506. Epub
2014 Nov 17.

Atom column indexing: atomic resolution image analysis through a matrix
representation.

Sang X(1), Oni AA(1), LeBeau JM(1).

Author information: 
(1)Department of Materials Science and Engineering,North Carolina State
University,Raleigh,NC 27695-7907,USA.

Here, we report the development of an approach to map atomic resolution images
into a convenient matrix representation. Through the combination of
two-dimensional Gaussian fitting and the projective standard deviation, atom
column locations are projected onto two noncollinear reference lattice vectors
that are used to assign each a unique (i, j) matrix index. By doing so,
straightforward atomic resolution image analysis becomes possible. Using
practical examples, we demonstrate that the matrix representation greatly
simplifies categorizing atom columns to different sublattices. This enables a
myriad of direct analyses, such as mapping atom column properties and correlating
long-range atom column pairs. MATLAB source code can be downloaded from
https://github.com/subangstrom/aci.

DOI: 10.1017/S1431927614013506 
PMID: 25399553  [PubMed]


1136. PLoS Genet. 2014 Nov 13;10(11):e1004787. doi: 10.1371/journal.pgen.1004787.
eCollection 2014.

GPA: a statistical approach to prioritizing GWAS results by integrating
pleiotropy and annotation.

Chung D(1), Yang C(2), Li C(3), Gelernter J(4), Zhao H(5).

Author information: 
(1)Department of Biostatistics, Yale School of Public Health, New Haven,
Connecticut, United States of America; Department of Public Health Sciences,
Medical University of South Carolina, Charleston, South Carolina, United States
of America. (2)Department of Biostatistics, Yale School of Public Health, New
Haven, Connecticut, United States of America; Department of Psychiatry, Yale
School of Medicine, New Haven, Connecticut, United States of America; Department 
of Mathematics, Hong Kong Baptist University, Hong Kong, China. (3)Program in
Computational Biology and Bioinformatics, Yale University, New Haven,
Connecticut, United States of America. (4)Department of Psychiatry, Yale School
of Medicine, New Haven, Connecticut, United States of America; VA CT Healthcare
Center, West Haven, Connecticut, United States of America; Department of
Genetics, Yale School of Medicine, West Haven, Connecticut, United States of
America; Department of Neurobiology, Yale School of Medicine, New Haven,
Connecticut, United States of America. (5)Department of Biostatistics, Yale
School of Public Health, New Haven, Connecticut, United States of America;
Program in Computational Biology and Bioinformatics, Yale University, New Haven, 
Connecticut, United States of America; Department of Genetics, Yale School of
Medicine, West Haven, Connecticut, United States of America; VA Cooperative
Studies Program Coordinating Center, West Haven, Connecticut, United States of
America.

Results from Genome-Wide Association Studies (GWAS) have shown that complex
diseases are often affected by many genetic variants with small or moderate
effects. Identifications of these risk variants remain a very challenging
problem. There is a need to develop more powerful statistical methods to leverage
available information to improve upon traditional approaches that focus on a
single GWAS dataset without incorporating additional data. In this paper, we
propose a novel statistical approach, GPA (Genetic analysis incorporating
Pleiotropy and Annotation), to increase statistical power to identify risk
variants through joint analysis of multiple GWAS data sets and annotation
information because: (1) accumulating evidence suggests that different complex
diseases share common risk bases, i.e., pleiotropy; and (2) functionally
annotated variants have been consistently demonstrated to be enriched among GWAS 
hits. GPA can integrate multiple GWAS datasets and functional annotations to seek
association signals, and it can also perform hypothesis testing to test the
presence of pleiotropy and enrichment of functional annotation. Statistical
inference of the model parameters and SNP ranking is achieved through an EM
algorithm that can handle genome-wide markers efficiently. When we applied GPA to
jointly analyze five psychiatric disorders with annotation information, not only 
did GPA identify many weak signals missed by the traditional single phenotype
analysis, but it also revealed relationships in the genetic architecture of these
disorders. Using our hypothesis testing framework, statistically significant
pleiotropic effects were detected among these psychiatric disorders, and the
markers annotated in the central nervous system genes and eQTLs from the
Genotype-Tissue Expression (GTEx) database were significantly enriched. We also
applied GPA to a bladder cancer GWAS data set with the ENCODE DNase-seq data from
125 cell lines. GPA was able to detect cell lines that are biologically more
relevant to bladder cancer. The R implementation of GPA is currently available at
http://dongjunchung.github.io/GPA/.

DOI: 10.1371/journal.pgen.1004787 
PMCID: PMC4230845
PMID: 25393678  [PubMed - indexed for MEDLINE]


1137. PLoS One. 2014 Nov 6;9(11):e111795. doi: 10.1371/journal.pone.0111795.
eCollection 2014.

Computational approaches for predicting biomedical research collaborations.

Zhang Q(1), Yu H(2).

Author information: 
(1)Department of Quantitative Health Sciences, University of Massachusetts
Medical School, Worcester, Massachusetts, United States of America. (2)Department
of Quantitative Health Sciences, University of Massachusetts Medical School,
Worcester, Massachusetts, United States of America; VA Central Massachusetts,
Leeds, Massachusetts, United States of America.

Biomedical research is increasingly collaborative, and successful collaborations 
often produce high impact work. Computational approaches can be developed for
automatically predicting biomedical research collaborations. Previous works of
collaboration prediction mainly explored the topological structures of research
collaboration networks, leaving out rich semantic information from the
publications themselves. In this paper, we propose supervised machine learning
approaches to predict research collaborations in the biomedical field. We
explored both the semantic features extracted from author research interest
profile and the author network topological features. We found that the most
informative semantic features for author collaborations are related to research
interest, including similarity of out-citing citations, similarity of abstracts. 
Of the four supervised machine learning models (naïve Bayes, naïve Bayes
multinomial, SVMs, and logistic regression), the best performing model is
logistic regression with an ROC ranging from 0.766 to 0.980 on different
datasets. To our knowledge we are the first to study in depth how research
interest and productivities can be used for collaboration prediction. Our
approach is computationally efficient, scalable and yet simple to implement. The 
datasets of this study are available at
https://github.com/qingzhanggithub/medline-collaboration-datasets.

DOI: 10.1371/journal.pone.0111795 
PMCID: PMC4222920
PMID: 25375164  [PubMed - indexed for MEDLINE]


1138. PLoS One. 2014 Nov 5;9(11):e110289. doi: 10.1371/journal.pone.0110289.
eCollection 2014.

SlideToolkit: an assistive toolset for the histological quantification of whole
slide images.

Nelissen BG(1), van Herwaarden JA(1), Moll FL(1), van Diest PJ(2), Pasterkamp
G(3).

Author information: 
(1)Department of Vascular Surgery, University Medical Center Utrecht, Utrecht,
The Netherlands. (2)Department of Pathology, University Medical Center Utrecht,
Utrecht, The Netherlands. (3)Laboratory of Experimental Cardiology, University
Medical Center Utrecht, Utrecht, The Netherlands.

The demand for accurate and reproducible phenotyping of a disease trait increases
with the rising number of biobanks and genome wide association studies. Detailed 
analysis of histology is a powerful way of phenotyping human tissues.
Nonetheless, purely visual assessment of histological slides is time-consuming
and liable to sampling variation and optical illusions and thereby observer
variation, and external validation may be cumbersome. Therefore, within our own
biobank, computerized quantification of digitized histological slides is often
preferred as a more precise and reproducible, and sometimes more sensitive
approach. Relatively few free toolkits are, however, available for fully
digitized microscopic slides, usually known as whole slides images. In order to
comply with this need, we developed the slideToolkit as a fast method to handle
large quantities of low contrast whole slides images using advanced cell
detecting algorithms. The slideToolkit has been developed for modern personal
computers and high-performance clusters (HPCs) and is available as an open-source
project on github.com. We here illustrate the power of slideToolkit by a repeated
measurement of 303 digital slides containing CD3 stained (DAB) abdominal aortic
aneurysm tissue from a tissue biobank. Our workflow consists of four consecutive 
steps. In the first step (acquisition), whole slide images are collected and
converted to TIFF files. In the second step (preparation), files are organized.
The third step (tiles), creates multiple manageable tiles to count. In the fourth
step (analysis), tissue is analyzed and results are stored in a data set. Using
this method, two consecutive measurements of 303 slides showed an intraclass
correlation of 0.99. In conclusion, slideToolkit provides a free, powerful and
versatile collection of tools for automated feature analysis of whole slide
images to create reproducible and meaningful phenotypic data sets.

DOI: 10.1371/journal.pone.0110289 
PMCID: PMC4220929
PMID: 25372389  [PubMed - indexed for MEDLINE]


1139. J Phys Chem B. 2014 Dec 11;118(49):14203-14. doi: 10.1021/jp504942t. Epub 2014
Nov 25.

Implementation of the forward-reverse method for calculating the potential of
mean force using a dynamic restraining protocol.

Nategholeslam M(1), Gray CG, Tomberli B.

Author information: 
(1)Department of Physics and Biophysics Interdepartmental Group, University of
Guelph , Guelph, Ontario, Canada.

We present a new sampling and analysis scheme for calculating the potential of
mean force (PMF) of systems studied by steered molecular dynamics simulations.
This scheme, which we call the bin-passing method, is based on the
forward-reverse (FR) method (due to I. Kosztin and co-workers, Kosztin et al. J. 
Chem. Phys. 2006, 124(6), 064106) and arguments based on the second law of
thermodynamics. Applying the bin-passing method results in enhanced sampling,
better separation of the reversible and irreversible work distributions, and
faster convergence to the underlying PMF of the system under study.
Post-simulation analysis is performed using a purpose-built software that we have
made publicly available at https://github.com/1particle/bin-passing_analyzer
under the terms of the GNU General Public License (version 3). Three examples are
provided, for systems of varying sizes and complexities, to demonstrate the
efficiency of this method and the quality of the results: for the dissociation
PMF of NaCl in water, the bin-passing method obtains PMFs in excellent agreement 
with that obtained for the same system and using the same force-field through
static (equilibrium) methods. The bin-passing method gives a very symmetric PMF
for passage of a single water molecule through a DPPC bilayer, and the resultant 
PMF leads to permeability values in better agreement with experiments than those 
obtained through previous simulation studies. Finally, we consider the
interaction of the antimicrobial peptide HHC-36 with two model membranes and
employ the bin-passing method to obtain the PMFs for peptide adsorption to the
membranes. The characteristics of these PMFs are consistent with the qualities
established for the HHC-36 peptide through in vivo and in vitro experiments, as a
non-toxic strong antimicrobial agent.

DOI: 10.1021/jp504942t 
PMID: 25372312  [PubMed]


1140. Bioinformatics. 2015 Mar 1;31(5):791-3. doi: 10.1093/bioinformatics/btu729. Epub 
2014 Nov 3.

JAMSS: proteomics mass spectrometry simulation in Java.

Smith R(1), Prince JT(1).

Author information: 
(1)Department of Computer Science, University of Montana, Missoula, MT 59812, USA
and Department of Chemistry, Brigham Young University, Provo, UT 84602, USA.

Countless proteomics data processing algorithms have been proposed, yet few have 
been critically evaluated due to lack of labeled data (data with known identities
and quantities). Although labeling techniques exist, they are limited in terms of
confidence and accuracy. In silico simulators have recently been used to create
complex data with known identities and quantities. We propose Java Mass
Spectrometry Simulator (JAMSS): a fast, self-contained in silico simulator
capable of generating simulated MS and LC-MS runs while providing meta
information on the provenance of each generated signal. JAMSS improves upon
previous in silico simulators in terms of its ease to install, minimal
parameters, graphical user interface, multithreading capability, retention time
shift model and reproducibility.AVAILABILITY AND IMPLEMENTATION: The simulator
creates mzML 1.1.0. It is open source software licensed under the GPLv3. The
software and source are available at https://github.com/optimusmoose/JAMSS.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu729 
PMID: 25371478  [PubMed - indexed for MEDLINE]


1141. Genome Biol. 2014;15(10):501.

Bayesian transcriptome assembly.

Maretty L(1), Sibbesen JA, Krogh A.

Author information: 
(1)The Bioinformatics Centre, Department of Biology and Biotech Research
andInnovation Centre (BRIC), University of Copenhagen, Ole Maaløes Vej 5, 2200,
Copenhagen, Denmark.

Comment in
    Genome Biol. 2014;15(10):498.

RNA sequencing allows for simultaneous transcript discovery and quantification,
but reconstructing complete transcripts from such data remains difficult. Here,
we introduce Bayesembler, a novel probabilistic method for transcriptome assembly
built on a Bayesian model of the RNA sequencing process. Under this model,
samples from the posterior distribution over transcripts and their abundance
values are obtained using Gibbs sampling. By using the frequency at which
transcripts are observed during sampling to select the final assembly, we
demonstrate marked improvements in sensitivity and precision over
state-of-the-art assemblers on both simulated and real data. Bayesembler is
available at https://github.com/bioinformatics-centre/bayesembler.

DOI: 10.1186/s13059-014-0501-4 
PMCID: PMC4397945
PMID: 25367074  [PubMed - indexed for MEDLINE]


1142. J Am Med Inform Assoc. 2015 Jan;22(1):65-75. doi: 10.1136/amiajnl-2013-002577.
Epub 2014 Oct 31.

BiobankConnect: software to rapidly connect data elements for pooled analysis
across biobanks using ontological and lexical indexing.

Pang C(1), Hendriksen D(2), Dijkstra M(2), van der Velde KJ(3), Kuiper J(1),
Hillege HL(4), Swertz MA(3).

Author information: 
(1)Department of Genetics, Genomics Coordination Center, University of Groningen,
University Medical Center Groningen, Groningen, The Netherlands Department of
Epidemiology, University of Groningen, University Medical Center Groningen,
Groningen, The Netherlands. (2)Department of Genetics, Genomics Coordination
Center, University of Groningen, University Medical Center Groningen, Groningen, 
The Netherlands. (3)Department of Genetics, Genomics Coordination Center,
University of Groningen, University Medical Center Groningen, Groningen, The
Netherlands Groningen Bioinformatics Center, University of Groningen, Groningen, 
The Netherlands. (4)Department of Epidemiology, University of Groningen,
University Medical Center Groningen, Groningen, The Netherlands.

OBJECTIVE: Pooling data across biobanks is necessary to increase statistical
power, reveal more subtle associations, and synergize the value of data sources. 
However, searching for desired data elements among the thousands of available
elements and harmonizing differences in terminology, data collection, and
structure, is arduous and time consuming.
MATERIALS AND METHODS: To speed up biobank data pooling we developed
BiobankConnect, a system to semi-automatically match desired data elements to
available elements by: (1) annotating the desired elements with ontology terms
using BioPortal; (2) automatically expanding the query for these elements with
synonyms and subclass information using OntoCAT; (3) automatically searching
available elements for these expanded terms using Lucene lexical matching; and
(4) shortlisting relevant matches sorted by matching score.
RESULTS: We evaluated BiobankConnect using human curated matches from
EU-BioSHaRE, searching for 32 desired data elements in 7461 available elements
from six biobanks. We found 0.75 precision at rank 1 and 0.74 recall at rank 10
compared to a manually curated set of relevant matches. In addition, best matches
chosen by BioSHaRE experts ranked first in 63.0% and in the top 10 in 98.4% of
cases, indicating that our system has the potential to significantly reduce
manual matching work.
CONCLUSIONS: BiobankConnect provides an easy user interface to significantly
speed up the biobank harmonization process. It may also prove useful for other
forms of biomedical data integration. All the software can be downloaded as a
MOLGENIS open source app from http://www.github.com/molgenis, with a demo
available at http://www.biobankconnect.org.

© The Author 2014. Published by Oxford University Press on behalf of the American
Medical Informatics Association.

DOI: 10.1136/amiajnl-2013-002577 
PMCID: PMC4433361
PMID: 25361575  [PubMed - indexed for MEDLINE]


1143. Bioinformatics. 2015 Mar 1;31(5):621-5. doi: 10.1093/bioinformatics/btu723. Epub 
2014 Oct 29.

Automated structural classification of lipids by machine learning.

Taylor R(1), Miller RH(1), Miller RD(1), Porter M(1), Dalgleish J(1), Prince
JT(1).

Author information: 
(1)Department of Chemistry and Biochemistry and Department of Microbiology and
Molecular Biology, Brigham Young University, Provo, UT 84602, USA.

MOTIVATION: Modern lipidomics is largely dependent upon structural ontologies
because of the great diversity exhibited in the lipidome, but no automated lipid 
classification exists to facilitate this partitioning. The size of the putative
lipidome far exceeds the number currently classified, despite a decade of work.
Automated classification would benefit ongoing classification efforts by
decreasing the time needed and increasing the accuracy of classification while
providing classifications for mass spectral identification algorithms.
RESULTS: We introduce a tool that automates classification into the LIPID MAPS
ontology of known lipids with >95% accuracy and novel lipids with 63% accuracy.
The classification is based upon simple chemical characteristics and modern
machine learning algorithms. The decision trees produced are intelligible and can
be used to clarify implicit assumptions about the current LIPID MAPS
classification scheme. These characteristics and decision trees are made
available to facilitate alternative implementations. We also discovered many
hundreds of lipids that are currently misclassified in the LIPID MAPS database,
strongly underscoring the need for automated classification.
AVAILABILITY AND IMPLEMENTATION: Source code and chemical characteristic lists as
SMARTS search strings are available under an open-source license at
https://www.github.com/princelab/lipid_classifier.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu723 
PMID: 25359887  [PubMed - indexed for MEDLINE]


1144. PLoS Comput Biol. 2014 Oct 30;10(10):e1003929. doi: 10.1371/journal.pcbi.1003929.
eCollection 2014.

dcGOR: an R package for analysing ontologies and protein domain annotations.

Fang H(1).

Author information: 
(1)Computational Genomics Group, Department of Computer Science, University of
Bristol, Bristol, United Kingdom.

I introduce an open-source R package 'dcGOR' to provide the bioinformatics
community with the ease to analyse ontologies and protein domain annotations,
particularly those in the dcGO database. The dcGO is a comprehensive resource for
protein domain annotations using a panel of ontologies including Gene Ontology.
Although increasing in popularity, this database needs statistical and graphical 
support to meet its full potential. Moreover, there are no bioinformatics tools
specifically designed for domain ontology analysis. As an add-on package built in
the R software environment, dcGOR offers a basic infrastructure with great
flexibility and functionality. It implements new data structure to represent
domains, ontologies, annotations, and all analytical outputs as well. For each
ontology, it provides various mining facilities, including: (i) domain-based
enrichment analysis and visualisation; (ii) construction of a domain (semantic
similarity) network according to ontology annotations; and (iii) significance
analysis for estimating a contact (statistical significance) network. To reduce
runtime, most analyses support high-performance parallel computing. Taking as
inputs a list of protein domains of interest, the package is able to easily carry
out in-depth analyses in terms of functional, phenotypic and diseased relevance, 
and network-level understanding. More importantly, dcGOR is designed to allow
users to import and analyse their own ontologies and annotations on domains
(taken from SCOP, Pfam and InterPro) and RNAs (from Rfam) as well. The package is
freely available at CRAN for easy installation, and also at GitHub for version
control. The dedicated website with reproducible demos can be found at
http://supfam.org/dcGOR.

DOI: 10.1371/journal.pcbi.1003929 
PMCID: PMC4214615
PMID: 25356683  [PubMed - indexed for MEDLINE]


1145. Version 2. F1000Res. 2014 Aug 29 [revised 2014 Sep 19];3:206. doi:
10.12688/f1000research.4952.2. eCollection 2014.

PAGAL - Properties and corresponding graphics of alpha helical structures in
proteins.

Chakraborty S(1), Rao B(2), Dandekar A(3).

Author information: 
(1)Plant Sciences Department, University of California, Davis, 95616, USA ;
Department of Biological Sciences, Tata Institute of Fundamental Research,
Mumbai, 400 005, India. (2)Department of Biological Sciences, Tata Institute of
Fundamental Research, Mumbai, 400 005, India. (3)Plant Sciences Department,
University of California, Davis, 95616, USA.

Alpha helices (AH) are peptide fragments characterized by regular patterns of
hydrogen bonding between the carbonyl oxygen and amino nitrogen of residues
regularly spaced in sequence, resulting in spiral conformations. Their
preponderance in protein structures underlines their importance. Interestingly,
AHs are present in most anti-microbial peptides, although they might remain in
random-coil conformations depending on the solvent dielectric. For example, the
cecropin component of the chimeric anti-microbial protein designed previously by 
our group comprises of two AHs linked by a short stretch of random coil. These
anti-microbial peptides are often amphipathic (quantified by a hydrophobic
moment), aligning hydrophobic residues on one surface and charged residues on the
others. In the current work, we reproduce previously described computational
methods to compute the hydrophobic moment of AHs - and provide open access to the
source code (PAGAL). We simultaneously generated input files for TikZ (a package 
for creating high resolution graphics programmatically) to obtain the Edmundson
wheel and showing the direction and magnitude of the hydrophobic moment, and
Pymol scripts to generate color coded protein surfaces. Additionally, we have
observed an empirical structural property of AHs: the distance between the Cα
atoms of the ith and (i+4)th residue is equal to the distance between the
carbonyl oxygens of the ith and (i+4)th residue. We validated this using 100
non-homologous high resolution structures from the PISCES database. The source
code and manual is available at http://github.com/sanchak/pagal and on
http://dx.doi.org/10.5281/zenodo.11136.

DOI: 10.12688/f1000research.4952.2 
PMCID: PMC4207245
PMID: 25352981  [PubMed]


1146. Nucleic Acids Res. 2015 Jan;43(Database issue):D662-9. doi: 10.1093/nar/gku1010. 
Epub 2014 Oct 28.

Ensembl 2015.

Cunningham F(1), Amode MR(1), Barrell D(2), Beal K(1), Billis K(1), Brent S(3),
Carvalho-Silva D(1), Clapham P(3), Coates G(3), Fitzgerald S(1), Gil L(1), Girón 
CG(1), Gordon L(1), Hourlier T(1), Hunt SE(1), Janacek SH(1), Johnson N(1),
Juettemann T(1), Kähäri AK(3), Keenan S(1), Martin FJ(1), Maurel T(1), McLaren
W(1), Murphy DN(2), Nag R(1), Overduin B(1), Parker A(1), Patricio M(1), Perry
E(1), Pignatelli M(1), Riat HS(1), Sheppard D(1), Taylor K(1), Thormann A(1),
Vullo A(1), Wilder SP(1), Zadissa A(1), Aken BL(1), Birney E(1), Harrow J(3),
Kinsella R(1), Muffato M(1), Ruffier M(1), Searle SM(3), Spudich G(1), Trevanion 
SJ(1), Yates A(1), Zerbino DR(1), Flicek P(4).

Author information: 
(1)European Molecular Biology Laboratory, European Bioinformatics Institute,
Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SD, UK. (2)European
Molecular Biology Laboratory, European Bioinformatics Institute, Wellcome Trust
Genome Campus, Hinxton, Cambridge CB10 1SD, UK Wellcome Trust Sanger Institute,
Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1SA, UK. (3)Wellcome Trust
Sanger Institute, Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1SA, UK.
(4)European Molecular Biology Laboratory, European Bioinformatics Institute,
Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SD, UK Wellcome Trust
Sanger Institute, Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1SA, UK 
flicek@ebi.ac.uk.

Ensembl (http://www.ensembl.org) is a genomic interpretation system providing the
most up-to-date annotations, querying tools and access methods for chordates and 
key model organisms. This year we released updated annotation (gene models,
comparative genomics, regulatory regions and variation) on the new human
assembly, GRCh38, although we continue to support researchers using the
GRCh37.p13 assembly through a dedicated site (http://grch37.ensembl.org). Our
Regulatory Build has been revamped to identify regulatory regions of interest and
to efficiently highlight their activity across disparate epigenetic data sets. A 
number of new interfaces allow users to perform large-scale comparisons of their 
data against our annotations. The REST server (http://rest.ensembl.org), which
allows programs written in any language to query our databases, has moved to a
full service alongside our upgraded website tools. Our online Variant Effect
Predictor tool has been updated to process more variants and calculate summary
statistics. Lastly, the WiggleTools package enables users to summarize large
collections of data sets and view them as single tracks in Ensembl. The Ensembl
code base itself is more accessible: it is now hosted on our GitHub organization 
page (https://github.com/Ensembl) under an Apache 2.0 open source license.

© The Author(s) 2014. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gku1010 
PMCID: PMC4383879
PMID: 25352552  [PubMed - indexed for MEDLINE]


1147. BMC Bioinformatics. 2014;15 Suppl 11:S15. doi: 10.1186/1471-2105-15-S11-S15. Epub
2014 Oct 21.

LacSubPred: predicting subtypes of Laccases, an important lignin
metabolism-related enzyme class, using in silico approaches.

Weirick T, Sahu SS, Mahalingam R, Kaundal R.

BACKGROUND: Laccases (E.C. 1.10.3.2) are multi-copper oxidases that have gained
importance in many industries such as biofuels, pulp production, textile dye
bleaching, bioremediation, and food production. Their usefulness stems from the
ability to act on a diverse range of phenolic compounds such as o-/p-quinols,
aminophenols, polyphenols, polyamines, aryl diamines, and aromatic thiols.
Despite acting on a wide range of compounds as a family, individual Laccases
often exhibit distinctive and varied substrate ranges. This is likely due to
Laccases involvement in many metabolic roles across diverse taxa. Classification 
systems for multi-copper oxidases have been developed using multiple sequence
alignments, however, these systems seem to largely follow species taxonomy rather
than substrate ranges, enzyme properties, or specific function. It has been
suggested that the roles and substrates of various Laccases are related to their 
optimal pH. This is consistent with the observation that fungal Laccases usually 
prefer acidic conditions, whereas plant and bacterial Laccases prefer basic
conditions. Based on these observations, we hypothesize that a descriptor-based
unsupervised learning system could generate homology independent classification
system for better describing the functional properties of Laccases.
RESULTS: In this study, we first utilized unsupervised learning approach to
develop a novel homology independent Laccase classification system. From the
descriptors considered, physicochemical properties showed the best performance.
Physicochemical properties divided the Laccases into twelve subtypes. Analysis of
the clusters using a t-test revealed that the majority of the physicochemical
descriptors had statistically significant differences between the classes.
Feature selection identified the most important features as negatively charges
residues, the peptide isoelectric point, and acidic or amidic residues. Secondly,
to allow for classification of new Laccases, a supervised learning system was
developed from the clusters. The models showed high performance with an overall
accuracy of 99.03%, error of 0.49%, MCC of 0.9367, precision of 94.20%,
sensitivity of 94.20%, and specificity of 99.47% in a 5-fold cross-validation
test. In an independent test, our models still provide a high accuracy of 97.98%,
error rate of 1.02%, MCC of 0.8678, precision of 87.88%, sensitivity of 87.88%
and specificity of 98.90%.
CONCLUSION: This study provides a useful classification system for better
understanding of Laccases from their physicochemical properties perspective. We
also developed a publically available web tool for the characterization of
Laccase protein sequences (http://lacsubpred.bioinfo.ucr.edu/). Finally, the
programs used in the study are made available for researchers interested in
applying the system to other enzyme classes
(https://github.com/tweirick/SubClPred).

DOI: 10.1186/1471-2105-15-S11-S15 
PMCID: PMC4251044
PMID: 25350584  [PubMed - indexed for MEDLINE]


1148. Bioinformatics. 2015 Mar 1;31(5):788-90. doi: 10.1093/bioinformatics/btu705. Epub
2014 Oct 27.

MetMSLine: an automated and fully integrated pipeline for rapid processing of
high-resolution LC-MS metabolomic datasets.

Edmands WM(1), Barupal DK(1), Scalbert A(1).

Author information: 
(1)Department of Biomarkers, Nutrition and Metabolism Section, International
Agency for Research on Cancer (IARC), F-69372 Cedex 08, Lyon, France.

MetMSLine represents a complete collection of functions in the R programming
language as an accessible GUI for biomarker discovery in large-scale
liquid-chromatography high-resolution mass spectral datasets from acquisition
through to final metabolite identification forming a backend to output from any
peak-picking software such as XCMS. MetMSLine automatically creates
subdirectories, data tables and relevant figures at the following steps: (i)
signal smoothing, normalization, filtration and noise transformation
(PreProc.QC.LSC.R); (ii) PCA and automatic outlier removal (Auto.PCA.R); (iii)
automatic regression, biomarker selection, hierarchical clustering and cluster
ion/artefact identification (Auto.MV.Regress.R); (iv) Biomarker-MS/MS
fragmentation spectra matching and fragment/neutral loss annotation
(Auto.MS.MS.match.R) and (v) semi-targeted metabolite identification based on a
list of theoretical masses obtained from public databases
(DBAnnotate.R).AVAILABILITY AND IMPLEMENTATION: All source code and suggested
parameters are available in an un-encapsulated layout on
http://wmbedmands.github.io/MetMSLine/. Readme files and a synthetic dataset of
both X-variables (simulated LC-MS data), Y-variables (simulated continuous
variables) and metabolite theoretical masses are also available on our GitHub
repository.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu705 
PMCID: PMC4341062
PMID: 25348215  [PubMed - indexed for MEDLINE]


1149. Bioinformatics. 2015 Mar 1;31(5):776-8. doi: 10.1093/bioinformatics/btu711. Epub 
2014 Oct 27.

PPDMs-a resource for mapping small molecule bioactivities from ChEMBL to Pfam-A
protein domains.

Kruger FA(1), Gaulton A(1), Nowotka M(1), Overington JP(1).

Author information: 
(1)ChEMBL group, EMBL-EBI, Wellcome Trust Genome Campus, Hinxton, UK.

PPDMs is a resource that maps small molecule bioactivities to protein domains
from the Pfam-A collection of protein families. Small molecule bioactivities
mapped to protein domains add important precision to approaches that use protein 
sequence searches alignments to assist applications in computational drug
discovery and systems and chemical biology. We have previously proposed a mapping
heuristic for a subset of bioactivities stored in ChEMBL with the Pfam-A domain
most likely to mediate small molecule binding. We have since refined this mapping
using a manual procedure. Here, we present a resource that provides up-to-date
mappings and the possibility to review assigned mappings as well as to
participate in their assignment and curation. We also describe how mappings
provided through the PPDMs resource are made accessible through the main schema
of the ChEMBL database.AVAILABILITY AND IMPLEMENTATION: The PPDMs resource and
curation interface is available at
https://www.ebi.ac.uk/chembl/research/ppdms/pfam_maps. The source-code for PPDMs 
is available under the Apache license at https://github.com/chembl/pfam_maps.
Source code is available at https://github.com/chembl/pfam_map_loader to
demonstrate the integration process with the main schema of ChEMBL.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu711 
PMCID: PMC4341065
PMID: 25348214  [PubMed - indexed for MEDLINE]


1150. Bioinformatics. 2015 Mar 1;31(5):642-6. doi: 10.1093/bioinformatics/btu706. Epub 
2014 Oct 24.

Using 2k + 2 bubble searches to find single nucleotide polymorphisms in k-mer
graphs.

Younsi R(1), MacLean D(1).

Author information: 
(1)The Sainsbury Laboratory, Norwich Research Park, Norwich NR4 7UH, UK.

MOTIVATION: Single nucleotide polymorphism (SNP) discovery is an important
preliminary for understanding genetic variation. With current sequencing methods,
we can sample genomes comprehensively. SNPs are found by aligning sequence reads 
against longer assembled references. De Bruijn graphs are efficient data
structures that can deal with the vast amount of data from modern technologies.
Recent work has shown that the topology of these graphs captures enough
information to allow the detection and characterization of genetic variants,
offering an alternative to alignment-based methods. Such methods rely on
depth-first walks of the graph to identify closing bifurcations. These methods
are conservative or generate many false-positive results, particularly when
traversing highly inter-connected (complex) regions of the graph or in regions of
very high coverage.
RESULTS: We devised an algorithm that calls SNPs in converted De Bruijn graphs by
enumerating 2k + 2 cycles. We evaluated the accuracy of predicted SNPs by
comparison with SNP lists from alignment-based methods. We tested accuracy of the
SNP calling using sequence data from 16 ecotypes of Arabidopsis thaliana and
found that accuracy was high. We found that SNP calling was even across the
genome and genomic feature types. Using sequence-based attributes of the graph to
train a decision tree allowed us to increase accuracy of SNP calls further.
Together these results indicate that our algorithm is capable of finding SNPs
accurately in complex sub-graphs and potentially comprehensively from whole
genome graphs.
AVAILABILITY AND IMPLEMENTATION: The source code for a C++ implementation of our 
algorithm is available under the GNU Public Licence v3 at:
https://github.com/danmaclean/2kplus2. The datasets used in this study are
available at the European Nucleotide Archive, reference ERP00565,
http://www.ebi.ac.uk/ena/data/view/ERP000565.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu706 
PMCID: PMC4341063
PMID: 25344498  [PubMed - indexed for MEDLINE]


1151. Bioinformatics. 2015 Mar 1;31(5):794-6. doi: 10.1093/bioinformatics/btu707. Epub 
2014 Oct 24.

Semantic Body Browser: graphical exploration of an organism and spatially
resolved expression data visualization.

Lekschas F(1), Stachelscheid H(1), Seltmann S(1), Kurtz A(2).

Author information: 
(1)Berlin-Brandenburg Center for Regenerative Therapies,
Charité-Universitätsmedizin Berlin, 13353 Berlin, Germany and Seoul National
University, College of Veterinary Medicine and Research Institute for Veterinary 
Science, Seoul 151-742, Republic of Korea. (2)Berlin-Brandenburg Center for
Regenerative Therapies, Charité-Universitätsmedizin Berlin, 13353 Berlin, Germany
and Seoul National University, College of Veterinary Medicine and Research
Institute for Veterinary Science, Seoul 151-742, Republic of Korea
Berlin-Brandenburg Center for Regenerative Therapies, Charité-Universitätsmedizin
Berlin, 13353 Berlin, Germany and Seoul National University, College of
Veterinary Medicine and Research Institute for Veterinary Science, Seoul 151-742,
Republic of Korea.

Advancing technologies generate large amounts of molecular and phenotypic data on
cells, tissues and organisms, leading to an ever-growing detail and complexity
while information retrieval and analysis becomes increasingly time-consuming. The
Semantic Body Browser is a web application for intuitively exploring the body of 
an organism from the organ to the subcellular level and visualising expression
profiles by means of semantically annotated anatomical illustrations. It is used 
to comprehend biological and medical data related to the different body
structures while relying on the strong pattern recognition capabilities of human 
users.AVAILABILITY AND IMPLEMENTATION: The Semantic Body Browser is a JavaScript 
web application that is freely available at http://sbb.cellfinder.org. The source
code is provided on https://github.com/flekschas/sbb.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu707 
PMID: 25344497  [PubMed - indexed for MEDLINE]


1152. Genome Biol. 2014;15(10):500.

mirMark: a site-level and UTR-level classifier for miRNA target prediction.

Menor M(1), Ching T, Zhu X, Garmire D, Garmire LX.

Author information: 
(1)Department of Information and Computer Sciences, University of Hawaii at
Manoa, Honolulu, HI 96822, USA.

MiRNAs play important roles in many diseases including cancers. However
computational prediction of miRNA target genes is challenging and the accuracies 
of existing methods remain poor. We report mirMark, a new machine learning-based 
method of miRNA target prediction at the site and UTR levels. This method uses
experimentally verified miRNA targets from miRecords and mirTarBase as training
sets and considers over 700 features. By combining Correlation-based Feature
Selection with a variety of statistical or machine learning methods for the site-
and UTR-level classifiers, mirMark significantly improves the overall predictive 
performance compared to existing publicly available methods. MirMark is available
from https://github.com/lanagarmire/MirMark.

DOI: 10.1186/s13059-014-0500-5 
PMCID: PMC4243195
PMID: 25344330  [PubMed - indexed for MEDLINE]


1153. PLoS One. 2014 Oct 24;9(10):e109356. doi: 10.1371/journal.pone.0109356.
eCollection 2014.

An online database for informing ecological network models:
http://kelpforest.ucsc.edu.

Beas-Luna R(1), Novak M(2), Carr MH(1), Tinker MT(3), Black A(4), Caselle JE(4), 
Hoban M(1), Malone D(1), Iles A(2).

Author information: 
(1)Department of Ecology and Evolutionary Biology, University of California Santa
Cruz, Santa Cruz, California, United States of America. (2)Department of
Integrative Biology, Oregon State University, Corvallis, Oregon, United States of
America. (3)Department of Ecology and Evolutionary Biology, University of
California Santa Cruz, Santa Cruz, California, United States of America; Western 
Ecological Research Center, United States Geological Survey, Santa Cruz,
California, United States of America. (4)Marine Science Institute, University of 
California Santa Barbara, Santa Barbara, California, United States of America.

Ecological network models and analyses are recognized as valuable tools for
understanding the dynamics and resiliency of ecosystems, and for informing
ecosystem-based approaches to management. However, few databases exist that can
provide the life history, demographic and species interaction information
necessary to parameterize ecological network models. Faced with the difficulty of
synthesizing the information required to construct models for kelp forest
ecosystems along the West Coast of North America, we developed an online database
(http://kelpforest.ucsc.edu/) to facilitate the collation and dissemination of
such information. Many of the database's attributes are novel yet the structure
is applicable and adaptable to other ecosystem modeling efforts. Information for 
each taxonomic unit includes stage-specific life history, demography, and
body-size allometries. Species interactions include trophic, competitive,
facilitative, and parasitic forms. Each data entry is temporally and spatially
explicit. The online data entry interface allows researchers anywhere to
contribute and access information. Quality control is facilitated by attributing 
each entry to unique contributor identities and source citations. The database
has proven useful as an archive of species and ecosystem-specific information in 
the development of several ecological network models, for informing management
actions, and for education purposes (e.g., undergraduate and graduate training). 
To facilitate adaptation of the database by other researches for other
ecosystems, the code and technical details on how to customize this database and 
apply it to other ecosystems are freely available and located at the following
link (https://github.com/kelpforest-cameo/databaseui).

DOI: 10.1371/journal.pone.0109356 
PMCID: PMC4208745
PMID: 25343723  [PubMed - indexed for MEDLINE]


1154. Bioinformatics. 2015 Feb 15;31(4):593-5. doi: 10.1093/bioinformatics/btu647. Epub
2014 Oct 17.

piPipes: a set of pipelines for piRNA and transposon analysis via small RNA-seq, 
RNA-seq, degradome- and CAGE-seq, ChIP-seq and genomic DNA sequencing.

Han BW(1), Wang W(2), Zamore PD(1), Weng Z(3).

Author information: 
(1)RNA Therapeutics Institute, Howard Hughes Medical Institute, Department of
Biochemistry & Molecular Pharmacology and Program in Bioinformatics and
Integrative Biology, University of Massachusetts Medical School, 368 Plantation
Street, Worcester, MA 01605, USA RNA Therapeutics Institute, Howard Hughes
Medical Institute, Department of Biochemistry & Molecular Pharmacology and
Program in Bioinformatics and Integrative Biology, University of Massachusetts
Medical School, 368 Plantation Street, Worcester, MA 01605, USA RNA Therapeutics 
Institute, Howard Hughes Medical Institute, Department of Biochemistry &
Molecular Pharmacology and Program in Bioinformatics and Integrative Biology,
University of Massachusetts Medical School, 368 Plantation Street, Worcester, MA 
01605, USA. (2)RNA Therapeutics Institute, Howard Hughes Medical Institute,
Department of Biochemistry & Molecular Pharmacology and Program in Bioinformatics
and Integrative Biology, University of Massachusetts Medical School, 368
Plantation Street, Worcester, MA 01605, USA RNA Therapeutics Institute, Howard
Hughes Medical Institute, Department of Biochemistry & Molecular Pharmacology and
Program in Bioinformatics and Integrative Biology, University of Massachusetts
Medical School, 368 Plantation Street, Worcester, MA 01605, USA RNA Therapeutics 
Institute, Howard Hughes Medical Institute, Department of Biochemistry &
Molecular Pharmacology and Program in Bioinformatics and Integrative Biology,
University of Massachusetts Medical School, 368 Plantation Street, Worcester, MA 
01605, USA RNA Therapeutics Institute, Howard Hughes Medical Institute,
Department of Biochemistry & Molecular Pharmacology and Program in Bioinformatics
and Integrative Biology, University of Massachusetts Medical School, 368
Plantation Street, Worcester, MA 01605, USA. (3)RNA Therapeutics Institute,
Howard Hughes Medical Institute, Department of Biochemistry & Molecular
Pharmacology and Program in Bioinformatics and Integrative Biology, University of
Massachusetts Medical School, 368 Plantation Street, Worcester, MA 01605, USA RNA
Therapeutics Institute, Howard Hughes Medical Institute, Department of
Biochemistry & Molecular Pharmacology and Program in Bioinformatics and
Integrative Biology, University of Massachusetts Medical School, 368 Plantation
Street, Worcester, MA 01605, USA.

MOTIVATION: PIWI-interacting RNAs (piRNAs), 23-36 nt small silencing RNAs,
repress transposon expression in the metazoan germ line, thereby protecting the
genome. Although high-throughput sequencing has made it possible to examine the
genome and transcriptome at unprecedented resolution, extracting useful
information from gigabytes of sequencing data still requires substantial
computational skills. Additionally, researchers may analyze and interpret the
same data differently, generating results that are difficult to reconcile. To
address these issues, we developed a coordinated set of pipelines, 'piPipes', to 
analyze piRNA and transposon-derived RNAs from a variety of high-throughput
sequencing libraries, including small RNA, RNA, degradome or 7-methyl guanosine
cap analysis of gene expression (CAGE), chromatin immunoprecipitation (ChIP) and 
genomic DNA-seq. piPipes can also produce figures and tables suitable for
publication. By facilitating data analysis, piPipes provides an opportunity to
standardize computational methods in the piRNA field.
SUPPLEMENTARY INFORMATION: Supplementary information, including flowcharts and
example figures for each pipeline, are available at Bioinformatics online.
AVAILABILITY AND IMPLEMENTATION: piPipes is implemented in Bash, C++, Python,
Perl and R. piPipes is free, open-source software distributed under the GPLv3
license and is available at http://bowhan.github.io/piPipes/.
CONTACT: Phillip.Zamore@umassmed.edu or Zhiping.Weng@umassmed.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu647 
PMCID: PMC4325541
PMID: 25342065  [PubMed - indexed for MEDLINE]


1155. Bioinformatics. 2015 Mar 1;31(5):714-9. doi: 10.1093/bioinformatics/btu695. Epub 
2014 Oct 22.

A model for the expression of gap genes based on the Jeffreys-type equation.

Gula IA(1), Samsonov AM(2).

Author information: 
(1)The Ioffe Physical Technical Institute, St. Petersburg, 194021 Russia and
State Polytechnical University, St. Petersburg, 195251 Russia. (2)The Ioffe
Physical Technical Institute, St. Petersburg, 194021 Russia and State
Polytechnical University, St. Petersburg, 195251 Russia The Ioffe Physical
Technical Institute, St. Petersburg, 194021 Russia and State Polytechnical
University, St. Petersburg, 195251 Russia.

MOTIVATION: We propose the third-order model equation of the Jeffreys type for
concentrations of gap gene proteins in order to take into account particle
inertia. Gap genes are responsible for formation of body segments in Drosophila
melanogaster embryo during its early development. Usually the expression of the
genes is described by the model of protein transport based on conventional
diffusion equation. However, the model is known to govern the Brownian
(non-inertial) motion of particles; hence, it is hardly applicable to the
description of protein transport.
RESULTS: Analysis of the Jeffreys-type equation results in the necessary
condition for the problem to be well-posed. Application of the Jeffreys-type
equation with non-linear terms to description of the dynamics of gap gene network
demonstrates better fitting to experimental data than the conventional model.
AVAILABILITY AND IMPLEMENTATION: Implementation of solver algorithms and the
software are freely available from:
https://github.com/wswgG/solver-for-the-Jeffreys-type-equations-system .

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu695 
PMID: 25338721  [PubMed - indexed for MEDLINE]


1156. Bioinformatics. 2015 Mar 1;31(5):665-73. doi: 10.1093/bioinformatics/btu696. Epub
2014 Oct 22.

FlaiMapper: computational annotation of small ncRNA-derived fragments using
RNA-seq high-throughput data.

Hoogstrate Y(1), Jenster G(1), Martens-Uzunova ES(1).

Author information: 
(1)Department of Urology, Erasmus University Medical Center, Be 362a, PO Box
2040, 3000 CA Rotterdam, The Netherlands.

MOTIVATION: Recent discoveries show that most types of small non-coding RNAs
(sncRNAs) such as miRNAs, snoRNAs and tRNAs get further processed into putatively
active smaller RNA species. Their roles, genetic profiles and underlying
processing mechanisms are only partially understood. To find their quantities and
characteristics, a proper annotation is essential. Here, we present FlaiMapper, a
method that extracts and annotates the locations of sncRNA-derived RNAs
(sncdRNAs). These sncdRNAs are often detected in sequencing data and observed as 
fragments of their precursor sncRNA. Using small RNA-seq read alignments,
FlaiMapper is able to annotate fragments primarily by peak detection on the start
and end position densities followed by filtering and a reconstruction process.
RESULTS: To assess performance of FlaiMapper, we used independent publicly
available small RNA-seq data. We were able to detect fragments representing
putative sncdRNAs from nearly all types of sncRNA, including 97.8% of the
annotated miRNAs in miRBase that have supporting reads. Comparison of
FlaiMapper-predicted boundaries of miRNAs with miRBase entries demonstrated that 
89% of the start and 54% of the end positions are identical. Additional
benchmarking showed that FlaiMapper is superior in performance compared with
existing software. Further analysis indicated a variety of characteristics in the
fragments, including sequence motifs and relations with RNA interacting factors. 
These characteristics set a good basis for further research on sncdRNAs.
AVAILABILITY AND IMPLEMENTATION: The platform independent GPL licensed Python 2.7
code is available at: https://github.com/yhoogstrate/flaimapper.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu696 
PMID: 25338717  [PubMed - indexed for MEDLINE]


1157. Bioinformatics. 2015 Feb 15;31(4):599-601. doi: 10.1093/bioinformatics/btu691.
Epub 2014 Oct 21.

Simple, rapid and accurate genotyping-by-sequencing from aligned whole genomes
with ArrayMaker.

Willet CE(1), Haase B(1), Charleston MA(1), Wade CM(1).

Author information: 
(1)Faculty of Veterinary Science and School of Information Technologies,
University of Sydney, Sydney, New South Wales 2006, Australia.

SUMMARY: Whole-genome sequencing has revolutionized the study of genetics.
Genotyping-by-sequencing is now a viable method of genotyping, yet the
bioinformatics involved can be daunting if not prohibitive for some laboratories.
Here we present ArrayMaker, a user-friendly tool that extracts accurate single
nucleotide polymorphism genotypes at pre-defined loci from whole-genome
alignments and presents them in a standard genotyping format compatible with
association analysis software and datasets genotyped on commercial array
platforms. Using this tool, geneticists with only basic computing ability can
genotype samples at any desired list of markers, facilitating genome-wide
association analysis, fine mapping, candidate variant assessment, data sharing
and compatibility of data sourced from multiple technologies.
AVAILABILITY AND IMPLEMENTATION: ArrayMaker is licensed under The MIT License and
can be freely obtained at https://github.com/cw2014/ArrayMaker/. The program is
implemented in Perl and runs on Linux operating systems.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.
CONTACT: cali.willet@sydney.edu.au.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu691 
PMCID: PMC4325546
PMID: 25336502  [PubMed - indexed for MEDLINE]


1158. Bioinformatics. 2015 Feb 15;31(4):602-3. doi: 10.1093/bioinformatics/btu693. Epub
2014 Oct 20.

Seed: a user-friendly tool for exploring and visualizing microbial community
data.

Beck D(1), Dennis C(1), Foster JA(1).

Author information: 
(1)Department of Biological Sciences, University of Idaho, Moscow, ID 83844, USA.

SUMMARY: In this article we present Simple Exploration of Ecological Data (Seed),
a data exploration tool for microbial communities. Seed is written in R using the
Shiny library. This provides access to powerful R-based functions and libraries
through a simple user interface. Seed allows users to explore ecological datasets
using principal coordinate analyses, scatter plots, bar plots, hierarchal
clustering and heatmaps.
AVAILABILITY AND IMPLEMENTATION: Seed is open source and available at
https://github.com/danlbek/Seed.
CONTACT: danlbek@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu693 
PMCID: PMC4325548
PMID: 25332377  [PubMed - indexed for MEDLINE]


1159. PLoS One. 2014 Oct 17;9(10):e110726. doi: 10.1371/journal.pone.0110726.
eCollection 2014.

MacSyFinder: a program to mine genomes for molecular systems with an application 
to CRISPR-Cas systems.

Abby SS(1), Néron B(2), Ménager H(2), Touchon M(1), Rocha EP(1).

Author information: 
(1)Microbial Evolutionary Genomics, Institut Pasteur, Paris, France; UMR3525,
CNRS, Paris, France. (2)Centre d'Informatique pour la Biologie, Institut Pasteur,
Paris, France.

MOTIVATION: Biologists often wish to use their knowledge on a few experimental
models of a given molecular system to identify homologs in genomic data. We
developed a generic tool for this purpose.
RESULTS: Macromolecular System Finder (MacSyFinder) provides a flexible framework
to model the properties of molecular systems (cellular machinery or pathway)
including their components, evolutionary associations with other systems and
genetic architecture. Modelled features also include functional analogs, and the 
multiple uses of a same component by different systems. Models are used to search
for molecular systems in complete genomes or in unstructured data like
metagenomes. The components of the systems are searched by sequence similarity
using Hidden Markov model (HMM) protein profiles. The assignment of hits to a
given system is decided based on compliance with the content and organization of 
the system model. A graphical interface, MacSyView, facilitates the analysis of
the results by showing overviews of component content and genomic context. To
exemplify the use of MacSyFinder we built models to detect and class CRISPR-Cas
systems following a previously established classification. We show that
MacSyFinder allows to easily define an accurate "Cas-finder" using publicly
available protein profiles.
AVAILABILITY AND IMPLEMENTATION: MacSyFinder is a standalone application
implemented in Python. It requires Python 2.7, Hmmer and makeblastdb (version
2.2.28 or higher). It is freely available with its source code under a GPLv3
license at https://github.com/gem-pasteur/macsyfinder. It is compatible with all 
platforms supporting Python and Hmmer/makeblastdb. The "Cas-finder" (models and
HMM profiles) is distributed as a compressed tarball archive as Supporting
Information.

DOI: 10.1371/journal.pone.0110726 
PMCID: PMC4201578
PMID: 25330359  [PubMed - indexed for MEDLINE]


1160. Version 2. F1000Res. 2014 Jan 16 [revised 2014 Apr 7];3:14. doi:
10.12688/f1000research.3-14.v2. eCollection 2014.

mfSBA: Multifractal analysis of spatial patterns in ecological communities.

Saravia LA(1).

Author information: 
(1)Instituto de Ciencias Básicas, Universidad Nacional de General Sarmiento,
Buenos Aires, Argentina.

Multifractals have been applied to characterize complex communities in a spatial 
context. They were developed for nonlinear systems and are particularly suited to
capture multiplicative processes observed in ecological systems. Multifractals
characterize variability in a scale-independent way within an experimental range.
I have developed an open-source software package to estimate multifractals using 
a box-counting algorithm (available from https://github.com/lsaravia/mfsba and
permanently available at doi: 10.5281/zenodo.8481). The software is specially
designed for two dimensional (2D) images such as the ones obtained from
remote sensing, but other 2D data types can also be analyzed. Additionally I
developed a new metric to analyze MULTISPECIES SPATIAL PATTERNS WITH
MULTIFRACTALS: spatial rank surface, which is included in the software.

DOI: 10.12688/f1000research.3-14.v2 
PMCID: PMC4197745
PMID: 25324962  [PubMed]


1161. Bioinformatics. 2015 Feb 1;31(3):436-7. doi: 10.1093/bioinformatics/btu680. Epub 
2014 Oct 15.

Rcount: simple and flexible RNA-Seq read counting.

Schmid MW(1), Grossniklaus U(1).

Author information: 
(1)Institute of Plant Biology and Zürich-Basel Plant Science Center, University
of Zurich, 8008 Zürich, Switzerland.

SUMMARY: Analysis of differential gene expression by RNA sequencing (RNA-Seq) is 
frequently done using feature counts, i.e. the number of reads mapping to a gene.
However, commonly used count algorithms (e.g. HTSeq) do not address the problem
of reads aligning with multiple locations in the genome (multireads) or reads
aligning with positions where two or more genes overlap (ambiguous reads). Rcount
specifically addresses these issues. Furthermore, Rcount allows the user to
assign priorities to certain feature types (e.g. higher priority for
protein-coding genes compared to rRNA-coding genes) or to add flanking regions.
AVAILABILITY AND IMPLEMENTATION: Rcount provides a fast and easy-to-use graphical
user interface requiring no command line or programming skills. It is implemented
in C++ using the SeqAn (www.seqan.de) and the Qt libraries (qt-project.org).
Source code and 64 bit binaries for (Ubuntu) Linux, Windows (7) and MacOSX are
released under the GPLv3 license and are freely available on
github.com/MWSchmid/Rcount.
CONTACT: marcschmid@gmx.ch
SUPPLEMENTARY INFORMATION: Test data, genome annotation files, useful Python and 
R scripts and a step-by-step user guide (including run-time and memory usage
tests) are available on github.com/MWSchmid/Rcount.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu680 
PMID: 25322836  [PubMed - indexed for MEDLINE]


1162. Bioinformatics. 2015 Feb 15;31(4):596-8. doi: 10.1093/bioinformatics/btu676. Epub
2014 Oct 15.

miRseqViewer: multi-panel visualization of sequence, structure and expression for
analysis of microRNA sequencing data.

Jang I(1), Chang H(1), Jun Y(1), Park S(1), Yang JO(1), Lee B(1), Kim W(1), Kim
VN(1), Lee S(1).

Author information: 
(1)Korean Bioinformation Center (KOBIC), KRIBB, Daejeon 305-806, Korea, School of
Biological Sciences, Seoul National University, Seoul 151-742, Korea and
Department of Life Science and Ewha Research Center for Systems Biology (ERCSB), 
Ewha Womans University, Seoul 120-750, Korea.

SUMMARY: Deep sequencing of small RNAs has become a routine process in recent
years, but no dedicated viewer is as yet available to explore the sequence
features simultaneously along with secondary structure and gene expression of
microRNA (miRNA). We present a highly interactive application that visualizes the
sequence alignment, secondary structure and normalized read counts in synchronous
multipanel windows. This helps users to easily examine the relationships between 
the structure of precursor and the sequences and abundance of final products and 
thereby will facilitate the studies on miRNA biogenesis and regulation. The
project manager handles multiple samples of multiple groups. The read alignment
is imported in BAM file format. Implemented features comprise sorting, zooming,
highlighting, editing, filtering, saving, exporting, etc. Currently, miRseqViewer
supports 84 organisms whose annotation is available at miRBase.
AVAILABILITY AND IMPLEMENTATION: miRseqViewer, implemented in Java, is available 
at https://github.com/insoo078/mirseqviewer or at http://msv.kobic.re.kr.
CONTACT: sanghyuk@ewha.ac.kr.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu676 
PMID: 25322835  [PubMed - indexed for MEDLINE]


1163. BMC Bioinformatics. 2014 Oct 16;15:332. doi: 10.1186/1471-2105-15-332.

Detection of internal exon deletion with exon Del.

Guo Y(1), Zhao S, Lehmann BD, Sheng Q, Shaver TM, Stricker TP, Pietenpol JA, Shyr
Y.

Author information: 
(1)Vanderbilt Ingram Cancer Center, Center for Quantitative Sciences, 2220 Pierce
Ave, 549 Preston Research Building, Nashville, TN 37232, USA.
yan.guo@vanderbilt.edu.

BACKGROUND: Exome sequencing allows researchers to study the human genome in
unprecedented detail. Among the many types of variants detectable through exome
sequencing, one of the most over looked types of mutation is internal deletion of
exons. Internal exon deletions are the absence of consecutive exons in a gene.
Such deletions have potentially significant biological meaning, and they are
often too short to be considered copy number variation. Therefore, to the need
for efficient detection of such deletions using exome sequencing data exists.
RESULTS: We present ExonDel, a tool specially designed to detect homozygous exon 
deletions efficiently. We tested ExonDel on exome sequencing data generated from 
16 breast cancer cell lines and identified both novel and known IEDs.
Subsequently, we verified our findings using RNAseq and PCR technologies. Further
comparisons with multiple sequencing-based CNV tools showed that ExonDel is
capable of detecting unique IEDs not found by other CNV tools.
CONCLUSIONS: ExonDel is an efficient way to screen for novel and known IEDs using
exome sequencing data. ExonDel and its source code can be downloaded freely at
https://github.com/slzhao/ExonDel.

DOI: 10.1186/1471-2105-15-332 
PMCID: PMC4288651
PMID: 25322818  [PubMed - indexed for MEDLINE]


1164. Bioinformatics. 2015 Feb 1;31(3):442-4. doi: 10.1093/bioinformatics/btu669. Epub 
2014 Oct 14.

GeneNet Toolbox for MATLAB: a flexible platform for the analysis of gene
connectivity in biological networks.

Taylor A(1), Steinberg J(2), Andrews TS(1), Webber C(1).

Author information: 
(1)MRC Functional Genomics Unit, Department of Physiology, Anatomy and Genetics, 
University of Oxford, Oxford OX1 3QX, UK and The Wellcome Trust Centre for Human 
Genetics, University of Oxford, Oxford OX3 7BN, UK. (2)MRC Functional Genomics
Unit, Department of Physiology, Anatomy and Genetics, University of Oxford,
Oxford OX1 3QX, UK and The Wellcome Trust Centre for Human Genetics, University
of Oxford, Oxford OX3 7BN, UK MRC Functional Genomics Unit, Department of
Physiology, Anatomy and Genetics, University of Oxford, Oxford OX1 3QX, UK and
The Wellcome Trust Centre for Human Genetics, University of Oxford, Oxford OX3
7BN, UK.

SUMMARY: We present GeneNet Toolbox for MATLAB (also available as a set of
standalone applications for Linux). The toolbox, available as command-line or
with a graphical user interface, enables biologists to assess connectivity among 
a set of genes of interest ('seed-genes') within a biological network of their
choosing. Two methods are implemented for calculating the significance of
connectivity among seed-genes: 'seed randomization' and 'network permutation'.
Options include restricting analyses to a specified subnetwork of the primary
biological network, and calculating connectivity from the seed-genes to a second 
set of interesting genes. Pre-analysis tools help the user choose the best
connectivity-analysis algorithm for their network. The toolbox also enables
visualization of the connections among seed-genes. GeneNet Toolbox functions
execute in reasonable time for very large networks (∼10 million edges) on a
desktop computer.
AVAILABILITY AND IMPLEMENTATION: GeneNet Toolbox is open source and freely
available from http://avigailtaylor.github.io/gntat14.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.
CONTACT: avigail.taylor@dpag.ox.ac.uk.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu669 
PMCID: PMC4308667
PMID: 25319962  [PubMed - indexed for MEDLINE]


1165. Nucleic Acids Res. 2014 Dec 1;42(21). doi: 10.1093/nar/gku864. Epub 2014 Oct 7.

svaseq: removing batch effects and other unwanted noise from sequencing data.

Leek JT(1).

Author information: 
(1)Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health
Baltimore, MD 21212, US jtleek@gmail.com.

It is now known that unwanted noise and unmodeled artifacts such as batch effects
can dramatically reduce the accuracy of statistical inference in genomic
experiments. These sources of noise must be modeled and removed to accurately
measure biological variability and to obtain correct statistical inference when
performing high-throughput genomic analysis. We introduced surrogate variable
analysis (sva) for estimating these artifacts by (i) identifying the part of the 
genomic data only affected by artifacts and (ii) estimating the artifacts with
principal components or singular vectors of the subset of the data matrix. The
resulting estimates of artifacts can be used in subsequent analyses as adjustment
factors to correct analyses. Here I describe a version of the sva approach
specifically created for count data or FPKMs from sequencing experiments based on
appropriate data transformation. I also describe the addition of supervised sva
(ssva) for using control probes to identify the part of the genomic data only
affected by artifacts. I present a comparison between these versions of sva and
other methods for batch effect estimation on simulated data, real count-based
data and FPKM-based data. These updates are available through the sva
Bioconductor package and I have made fully reproducible analysis using these
methods available from: https://github.com/jtleek/svaseq.

© The Author(s) 2014. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gku864 
PMCID: PMC4245966
PMID: 25294822  [PubMed - indexed for MEDLINE]


1166. Version 2. F1000Res. 2014 Jul 30 [revised 2014 Sep 19];3:175. doi:
10.12688/f1000research.4680.2. eCollection 2014.

shinyMethyl: interactive quality control of Illumina 450k DNA methylation arrays 
in R.

Fortin JP(1), Fertig E(2), Hansen K(3).

Author information: 
(1)Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health, 
Baltimore, MD, 21205, USA. (2)Department of Oncology, Sidney Kimmel Cancer
Center, Johns Hopkins School of Medicine, Baltimore, MD, 21205, USA.
(3)Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health, 
Baltimore, MD, 21205, USA ; McKusick-Nathans Institute of Genetic Medicine, Johns
Hopkins School of Medicine, Baltimore, MD, 21205, USA.

We present shinyMethyl, a Bioconductor package for interactive quality control of
DNA methylation data from Illumina 450k arrays. The package summarizes 450k
experiments into small exportable R objects from which an interactive interface
is launched. Reactive plots allow fast and intuitive quality control assessment
of the samples. In addition, exploration of the phenotypic associations is
possible through coloring and principal component analysis. Altogether, the
package makes it easy to perform quality assessment of large-scale methylation
datasets, such as epigenome-wide association studies or the datasets available
through The Cancer Genome Atlas portal. The shinyMethyl package is implemented in
R and available via Bioconductor. Its development repository is at
https://github.com/jfortin1/shinyMethyl.

DOI: 10.12688/f1000research.4680.2 
PMCID: PMC4176427
PMID: 25285208  [PubMed]


1167. Database (Oxford). 2014 Oct 3;2014. pii: bau098. doi: 10.1093/database/bau098.
Print 2014.

CanvasDB: a local database infrastructure for analysis of targeted- and whole
genome re-sequencing projects.

Ameur A(1), Bunikis I(2), Enroth S(2), Gyllensten U(2).

Author information: 
(1)Department of Immunology, Genetics and Pathology, Science for Life Laboratory,
Uppsala University, Sweden adam.ameur@igp.uu.se. (2)Department of Immunology,
Genetics and Pathology, Science for Life Laboratory, Uppsala University, Sweden.

CanvasDB is an infrastructure for management and analysis of genetic variants
from massively parallel sequencing (MPS) projects. The system stores SNP and
indel calls in a local database, designed to handle very large datasets, to allow
for rapid analysis using simple commands in R. Functional annotations are
included in the system, making it suitable for direct identification of
disease-causing mutations in human exome- (WES) or whole-genome sequencing (WGS) 
projects. The system has a built-in filtering function implemented to
simultaneously take into account variant calls from all individual samples. This 
enables advanced comparative analysis of variant distribution between groups of
samples, including detection of candidate causative mutations within family
structures and genome-wide association by sequencing. In most cases, these
analyses are executed within just a matter of seconds, even when there are
several hundreds of samples and millions of variants in the database. We
demonstrate the scalability of canvasDB by importing the individual variant calls
from all 1092 individuals present in the 1000 Genomes Project into the system,
over 4.4 billion SNPs and indels in total. Our results show that canvasDB makes
it possible to perform advanced analyses of large-scale WGS projects on a local
server. Database URL: https://github.com/UppsalaGenomeCenter/CanvasDB.

© The Author(s) 2014. Published by Oxford University Press.

DOI: 10.1093/database/bau098 
PMCID: PMC4184106
PMID: 25281234  [PubMed - indexed for MEDLINE]


1168. J Biomed Semantics. 2014 Sep 18;5(1):41. doi: 10.1186/2041-1480-5-41. eCollection
2014.

Structuring research methods and data with the research object model: genomics
workflows as a case study.

Hettne KM(1), Dharuri H(1), Zhao J(2), Wolstencroft K(3), Belhajjame K(4),
Soiland-Reyes S(4), Mina E(1), Thompson M(1), Cruickshank D(2), Verdes-Montenegro
L(5), Garrido J(5), de Roure D(2), Corcho O(6), Klyne G(2), van Schouwen R(1), 't
Hoen PA(1), Bechhofer S(4), Goble C(4), Roos M(1).

Author information: 
(1)Department of Human Genetics, Leiden University Medical Center, Leiden, The
Netherlands. (2)Department of Zoology, University of Oxford, Oxford, UK.
(3)School of Computer Science, University of Manchester, Manchester, UK ; Leiden 
Institute of Advanced Computer Science, Leiden University, Leiden, The
Netherlands. (4)School of Computer Science, University of Manchester, Manchester,
UK. (5)Instituto de Astrofísica de Andalucía, Granada, Spain. (6)Ontology
Engineering Group, Universidad Politécnica de Madrid, Madrid, Spain.

BACKGROUND: One of the main challenges for biomedical research lies in the
computer-assisted integrative study of large and increasingly complex
combinations of data in order to understand molecular mechanisms. The
preservation of the materials and methods of such computational experiments with 
clear annotations is essential for understanding an experiment, and this is
increasingly recognized in the bioinformatics community. Our assumption is that
offering means of digital, structured aggregation and annotation of the objects
of an experiment will provide necessary meta-data for a scientist to understand
and recreate the results of an experiment. To support this we explored a model
for the semantic description of a workflow-centric Research Object (RO), where an
RO is defined as a resource that aggregates other resources, e.g., datasets,
software, spreadsheets, text, etc. We applied this model to a case study where we
analysed human metabolite variation by workflows.
RESULTS: We present the application of the workflow-centric RO model for our
bioinformatics case study. Three workflows were produced following recently
defined Best Practices for workflow design. By modelling the experiment as an RO,
we were able to automatically query the experiment and answer questions such as
"which particular data was input to a particular workflow to test a particular
hypothesis?", and "which particular conclusions were drawn from a particular
workflow?".
CONCLUSIONS: Applying a workflow-centric RO model to aggregate and annotate the
resources used in a bioinformatics experiment, allowed us to retrieve the
conclusions of the experiment in the context of the driving hypothesis, the
executed workflows and their input data. The RO model is an extendable reference 
model that can be used by other systems as well.
AVAILABILITY: The Research Object is available at
http://www.myexperiment.org/packs/428 The Wf4Ever Research Object Model is
available at http://wf4ever.github.io/ro.

DOI: 10.1186/2041-1480-5-41 
PMCID: PMC4177597
PMID: 25276335  [PubMed]


1169. Bioinformatics. 2015 Feb 1;31(3):432-3. doi: 10.1093/bioinformatics/btu648. Epub 
2014 Oct 1.

MulRF: a software package for phylogenetic analysis using multi-copy gene trees.

Chaudhary R(1), Fernández-Baca D(1), Burleigh JG(1).

Author information: 
(1)Department of Biology, University of Florida, Gainesville, FL 32611 and
Department of Computer Science, Iowa State University, Ames, IA 50011, USA.

SUMMARY: MulRF is a platform-independent software package for phylogenetic
analysis using multi-copy gene trees. It seeks the species tree that minimizes
the Robinson-Foulds (RF) distance to the input trees using a generalization of
the RF distance to multi-labeled trees. The underlying generic tree distance
measure and fast running time make MulRF useful for inferring phylogenies from
large collections of gene trees, in which multiple evolutionary processes as well
as phylogenetic error may contribute to gene tree discord. MulRF implements
several features for customizing the species tree search and assessing the
results, and it provides a user-friendly graphical user interface (GUI) with tree
visualization. The species tree search is implemented in C++ and the GUI in Java 
Swing.
AVAILABILITY: MulRF's executable as well as sample datasets and manual are
available at http://genome.cs.iastate.edu/CBL/MulRF/, and the source code is
available at https://github.com/ruchiherself/MulRFRepo.
CONTACT: ruchic@ufl.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu648 
PMID: 25273112  [PubMed - indexed for MEDLINE]


1170. Bioinformatics. 2015 Jan 15;31(2):187-93. doi: 10.1093/bioinformatics/btu591.
Epub 2014 Sep 29.

Consensus Genotyper for Exome Sequencing (CGES): improving the quality of exome
variant genotypes.

Trubetskoy V(1), Rodriguez A(1), Dave U(1), Campbell N(2), Crawford EL(2), Cook
EH(1), Sutcliffe JS(2), Foster I(1), Madduri R(1), Cox NJ(1), Davis LK(1).

Author information: 
(1)Department of Medicine, Section of Genetic Medicine, Computation Institute,
University of Chicago, Chicago, IL 60637, Department of Molecular Physiology and 
Biophysics, Vanderbilt University, Nashville, Tennessee 37232, USA, Vanderbilt
Brain Institute, Vanderbilt University School of Medicine, Nashville, TN 37232
and Department of Psychiatry, University of Illinois at Chicago, Chicago, IL
60608, USA. (2)Department of Medicine, Section of Genetic Medicine, Computation
Institute, University of Chicago, Chicago, IL 60637, Department of Molecular
Physiology and Biophysics, Vanderbilt University, Nashville, Tennessee 37232,
USA, Vanderbilt Brain Institute, Vanderbilt University School of Medicine,
Nashville, TN 37232 and Department of Psychiatry, University of Illinois at
Chicago, Chicago, IL 60608, USA Department of Medicine, Section of Genetic
Medicine, Computation Institute, University of Chicago, Chicago, IL 60637,
Department of Molecular Physiology and Biophysics, Vanderbilt University,
Nashville, Tennessee 37232, USA, Vanderbilt Brain Institute, Vanderbilt
University School of Medicine, Nashville, TN 37232 and Department of Psychiatry, 
University of Illinois at Chicago, Chicago, IL 60608, USA.

MOTIVATION: The development of cost-effective next-generation sequencing methods 
has spurred the development of high-throughput bioinformatics tools for detection
of sequence variation. With many disparate variant-calling algorithms available, 
investigators must ask, 'Which method is best for my data?' Machine learning
research has shown that so-called ensemble methods that combine the output of
multiple models can dramatically improve classifier performance. Here we describe
a novel variant-calling approach based on an ensemble of variant-calling
algorithms, which we term the Consensus Genotyper for Exome Sequencing (CGES).
CGES uses a two-stage voting scheme among four algorithm implementations. While
our ensemble method can accept variants generated by any variant-calling
algorithm, we used GATK2.8, SAMtools, FreeBayes and Atlas-SNP2 in building CGES
because of their performance, widespread adoption and diverse but complementary
algorithms.
RESULTS: We apply CGES to 132 samples sequenced at the Hudson Alpha Institute for
Biotechnology (HAIB, Huntsville, AL) using the Nimblegen Exome Capture and
Illumina sequencing technology. Our sample set consisted of 40 complete trios,
two families of four, one parent-child duo and two unrelated individuals. CGES
yielded the fewest total variant calls (N(CGES) = 139° 897), the highest Ts/Tv
ratio (3.02), the lowest Mendelian error rate across all genotypes (0.028%), the 
highest rediscovery rate from the Exome Variant Server (EVS; 89.3%) and 1000
Genomes (1KG; 84.1%) and the highest positive predictive value (PPV; 96.1%) for a
random sample of previously validated de novo variants. We describe these and
other quality control (QC) metrics from consensus data and explain how the CGES
pipeline can be used to generate call sets of varying quality stringency,
including consensus calls present across all four algorithms, calls that are
consistent across any three out of four algorithms, calls that are consistent
across any two out of four algorithms or a more liberal set of all calls made by 
any algorithm.
AVAILABILITY AND IMPLEMENTATION: To enable accessible, efficient and reproducible
analysis, we implement CGES both as a stand-alone command line tool available for
download in GitHub and as a set of Galaxy tools and workflows configured to
execute on parallel computers.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu591 
PMCID: PMC4287941
PMID: 25270638  [PubMed - indexed for MEDLINE]


1171. Bioinformatics. 2015 Jan 15;31(2):282-3. doi: 10.1093/bioinformatics/btu616. Epub
2014 Sep 26.

Shiny-phyloseq: Web application for interactive microbiome analysis with
provenance tracking.

McMurdie PJ(1), Holmes S(1).

Author information: 
(1)Department of Statistics, Stanford University, Stanford, CA 94305, USA.

We have created a Shiny-based Web application, called Shiny-phyloseq, for dynamic
interaction with microbiome data that runs on any modern Web browser and requires
no programming, increasing the accessibility and decreasing the entrance
requirement to using phyloseq and related R tools. Along with a data- and
context-aware dynamic interface for exploring the effects of parameter and method
choices, Shiny-phyloseq also records the complete user input and subsequent
graphical results of a user's session, allowing the user to archive, share and
reproduce the sequence of steps that created their result-without writing any new
code themselves.AVAILABILITY AND IMPLEMENTATION: Shiny-phyloseq is implemented
entirely in the R language. It can be hosted/launched by any system with R
installed, including Windows, Mac OS and most Linux distributions. Information
technology administrators can also host Shiny--phyloseq from a remote server, in 
which case users need only have a Web browser installed. Shiny-phyloseq is
provided free of charge under a GPL-3 open-source license through GitHub at
http://joey711.github.io/shiny-phyloseq/.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu616 
PMCID: PMC4287943
PMID: 25262154  [PubMed - indexed for MEDLINE]


1172. PLoS Comput Biol. 2014 Sep 25;10(9):e1003842. doi: 10.1371/journal.pcbi.1003842. 
eCollection 2014.

IDEPI: rapid prediction of HIV-1 antibody epitopes and other phenotypic features 
from sequence data using a flexible machine learning platform.

Hepler NL(1), Scheffler K(2), Weaver S(2), Murrell B(2), Richman DD(3), Burton
DR(4), Poignard P(5), Smith DM(6), Kosakovsky Pond SL(2).

Author information: 
(1)Interdisciplinary Bioinformatics and Systems Biology Program, University of
California San Diego, La Jolla, California, United States of America.
(2)Department of Medicine, University of California San Diego, La Jolla,
California, United States of America. (3)Department of Pathology, University of
California San Diego, La Jolla, California, United States of America; San Diego
Veterans Affairs Healthcare System, San Diego, California, United States of
America. (4)The Scripps Research Institute, La Jolla, California, United States
of America; Ragon Institute of MGH, MIT, and Harvard, Boston, Massachusetts,
United States of America. (5)The Scripps Research Institute, La Jolla,
California, United States of America. (6)Department of Medicine, University of
California San Diego, La Jolla, California, United States of America; San Diego
Veterans Affairs Healthcare System, San Diego, California, United States of
America.

Since its identification in 1983, HIV-1 has been the focus of a research effort
unprecedented in scope and difficulty, whose ultimate goals--a cure and a
vaccine--remain elusive. One of the fundamental challenges in accomplishing these
goals is the tremendous genetic variability of the virus, with some genes
differing at as many as 40% of nucleotide positions among circulating strains.
Because of this, the genetic bases of many viral phenotypes, most notably the
susceptibility to neutralization by a particular antibody, are difficult to
identify computationally. Drawing upon open-source general-purpose machine
learning algorithms and libraries, we have developed a software package IDEPI
(IDentify EPItopes) for learning genotype-to-phenotype predictive models from
sequences with known phenotypes. IDEPI can apply learned models to classify
sequences of unknown phenotypes, and also identify specific sequence features
which contribute to a particular phenotype. We demonstrate that IDEPI achieves
performance similar to or better than that of previously published approaches on 
four well-studied problems: finding the epitopes of broadly neutralizing
antibodies (bNab), determining coreceptor tropism of the virus, identifying
compartment-specific genetic signatures of the virus, and deducing
drug-resistance associated mutations. The cross-platform Python source code
(released under the GPL 3.0 license), documentation, issue tracking, and a
pre-configured virtual machine for IDEPI can be found at
https://github.com/veg/idepi.

DOI: 10.1371/journal.pcbi.1003842 
PMCID: PMC4177671
PMID: 25254639  [PubMed - indexed for MEDLINE]


1173. BMC Bioinformatics. 2014;15 Suppl 9:S16. doi: 10.1186/1471-2105-15-S9-S16. Epub
2014 Sep 10.

Detecting epigenetic motifs in low coverage and metagenomics settings.

Beckmann ND, Karri S, Fang G, Bashir A.

BACKGROUND: It has recently become possible to rapidly and accurately detect
epigenetic signatures in bacterial genomes using third generation sequencing
data. Monitoring the speed at which a single polymerase inserts a base in the
read strand enables one to infer whether a modification is present at that
specific site on the template strand. These sites can be challenging to detect in
the absence of high coverage and reliable reference genomes.
METHODS: Here we provide a new method for detecting epigenetic motifs in bacteria
on datasets with low-coverage, with incomplete references, and with mixed samples
(i.e. metagenomic data). Our approach treats motif inference as a kmer comparison
problem. First, genomes (or contigs) are deconstructed into kmers. Then, native
genome-wide distributions of interpulse durations (IPDs) for kmers are compared
with corresponding whole genome amplified (WGA, modification free) IPD
distributions using log likelihood ratios. Finally, kmers are ranked and greedily
selected by iteratively correcting for sequences within a particular kmer's
neighborhood.
CONCLUSIONS: Our method can detect multiple types of modifications, even at very 
low-coverage and in the presence of mixed genomes. Additionally, we are able to
predict modified motifs when genomes with "neighbor" modified motifs exist within
the sample. Lastly, we show that these motifs can provide an alternative source
of information by which to cluster metagenomics contigs and that iterative
refinement on these clustered contigs can further improve both sensitivity and
specificity of motif detection.
AVAILABILITY: https://github.com/alibashir/EMMCKmer.

DOI: 10.1186/1471-2105-15-S9-S16 
PMCID: PMC4168715
PMID: 25253358  [PubMed - indexed for MEDLINE]


1174. BMC Bioinformatics. 2014;15 Suppl 9:S12. doi: 10.1186/1471-2105-15-S9-S12. Epub
2014 Sep 10.

ARYANA: Aligning Reads by Yet Another Approach.

Gholami M, Arbabi A, Sharifi-Zarchi A, Chitsaz H, Sadeghi M.

MOTIVATION: Although there are many different algorithms and software tools for
aligning sequencing reads, fast gapped sequence search is far from solved. Strong
interest in fast alignment is best reflected in the $10(6) prize for the
Innocentive competition on aligning a collection of reads to a given database of 
reference genomes. In addition, de novo assembly of next-generation sequencing
long reads requires fast overlap-layout-concensus algorithms which depend on fast
and accurate alignment.
CONTRIBUTION: We introduce ARYANA, a fast gapped read aligner, developed on the
base of BWA indexing infrastructure with a completely new alignment engine that
makes it significantly faster than three other aligners: Bowtie2, BWA and
SeqAlto, with comparable generality and accuracy. Instead of the time-consuming
backtracking procedures for handling mismatches, ARYANA comes with the
seed-and-extend algorithmic framework and a significantly improved efficiency by 
integrating novel algorithmic techniques including dynamic seed selection,
bidirectional seed extension, reset-free hash tables, and gap-filling dynamic
programming. As the read length increases ARYANA's superiority in terms of speed 
and alignment rate becomes more evident. This is in perfect harmony with the read
length trend as the sequencing technologies evolve. The algorithmic platform of
ARYANA makes it easy to develop mission-specific aligners for other applications 
using ARYANA engine.
AVAILABILITY: ARYANA with complete source code can be obtained from
http://github.com/aryana-aligner.

DOI: 10.1186/1471-2105-15-S9-S12 
PMCID: PMC4168712
PMID: 25252881  [PubMed - indexed for MEDLINE]


1175. Bioinformatics. 2015 Jan 1;31(1):143-5. doi: 10.1093/bioinformatics/btu613. Epub 
2014 Sep 17.

The Ensembl REST API: Ensembl Data for Any Language.

Yates A(1), Beal K(1), Keenan S(1), McLaren W(1), Pignatelli M(1), Ritchie GR(2),
Ruffier M(1), Taylor K(1), Vullo A(1), Flicek P(2).

Author information: 
(1)European Molecular Biology Laboratory, European Bioinformatics Institute,
Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SD and Wellcome Trust
Sanger Institute, Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SA, UK. 
(2)European Molecular Biology Laboratory, European Bioinformatics Institute,
Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SD and Wellcome Trust
Sanger Institute, Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SA, UK
European Molecular Biology Laboratory, European Bioinformatics Institute,
Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SD and Wellcome Trust
Sanger Institute, Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SA, UK.

MOTIVATION: We present a Web service to access Ensembl data using
Representational State Transfer (REST). The Ensembl REST server enables the easy 
retrieval of a wide range of Ensembl data by most programming languages, using
standard formats such as JSON and FASTA while minimizing client work. We also
introduce bindings to the popular Ensembl Variant Effect Predictor tool
permitting large-scale programmatic variant analysis independent of any specific 
programming language.
AVAILABILITY AND IMPLEMENTATION: The Ensembl REST API can be accessed at
http://rest.ensembl.org and source code is freely available under an Apache 2.0
license from http://github.com/Ensembl/ensembl-rest.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu613 
PMCID: PMC4271150
PMID: 25236461  [PubMed - indexed for MEDLINE]


1176. Front Neuroinform. 2014 Aug 29;8:73. doi: 10.3389/fninf.2014.00073. eCollection
2014.

PyNCS: a microkernel for high-level definition and configuration of neuromorphic 
electronic systems.

Stefanini F(1), Neftci EO(2), Sheik S(1), Indiveri G(1).

Author information: 
(1)Department of Information Technology and Electrical Engineering, Institute of 
Neuroinformatics, University of Zurich and ETH Zurich Zurich, Switzerland.
(2)Department of Bioengineering, Institute for Neural Computation, University of 
California at San Diego La Jolla, CA, USA.

Neuromorphic hardware offers an electronic substrate for the realization of
asynchronous event-based sensory-motor systems and large-scale spiking neural
network architectures. In order to characterize these systems, configure them,
and carry out modeling experiments, it is often necessary to interface them to
workstations. The software used for this purpose typically consists of a large
monolithic block of code which is highly specific to the hardware setup used.
While this approach can lead to highly integrated hardware/software systems, it
hampers the development of modular and reconfigurable infrastructures thus
preventing a rapid evolution of such systems. To alleviate this problem, we
propose PyNCS, an open-source front-end for the definition of neural network
models that is interfaced to the hardware through a set of Python Application
Programming Interfaces (APIs). The design of PyNCS promotes modularity,
portability and expandability and separates implementation from hardware
description. The high-level front-end that comes with PyNCS includes tools to
define neural network models as well as to create, monitor and analyze spiking
data. Here we report the design philosophy behind the PyNCS framework and
describe its implementation. We demonstrate its functionality with two
representative case studies, one using an event-based neuromorphic vision sensor,
and one using a set of multi-neuron devices for carrying out a cognitive
decision-making task involving state-dependent computation. PyNCS, already
applicable to a wide range of existing spike-based neuromorphic setups, will
accelerate the development of hybrid software/hardware neuromorphic systems,
thanks to its code flexibility. The code is open-source and available online at
https://github.com/inincs/pyNCS.

DOI: 10.3389/fninf.2014.00073 
PMCID: PMC4152885
PMID: 25232314  [PubMed]


1177. Database (Oxford). 2014 Sep 16;2014. pii: bau095. doi: 10.1093/database/bau095.
Print 2014.

WholeCellSimDB: a hybrid relational/HDF database for whole-cell model
predictions.

Karr JR(1), Phillips NC(1), Covert MW(2).

Author information: 
(1)Graduate Program in Biophysics, Stanford University, Stanford, CA 94305, USA, 
Computer Science and Information Technology, University of Prince Edward Island, 
Charlottetown, PE C1A 4P3, Canada and Department of Bioengineering, Stanford
University, Stanford, CA 94305, USA. (2)Graduate Program in Biophysics, Stanford 
University, Stanford, CA 94305, USA, Computer Science and Information Technology,
University of Prince Edward Island, Charlottetown, PE C1A 4P3, Canada and
Department of Bioengineering, Stanford University, Stanford, CA 94305, USA
mcovert@stanford.edu.

Mechanistic 'whole-cell' models are needed to develop a complete understanding of
cell physiology. However, extracting biological insights from whole-cell models
requires running and analyzing large numbers of simulations. We developed
WholeCellSimDB, a database for organizing whole-cell simulations. WholeCellSimDB 
was designed to enable researchers to search simulation metadata to identify
simulations for further analysis, and quickly slice and aggregate simulation
results data. In addition, WholeCellSimDB enables users to share simulations with
the broader research community. The database uses a hybrid
relational/hierarchical data format architecture to efficiently store and
retrieve both simulation setup metadata and results data. WholeCellSimDB provides
a graphical Web-based interface to search, browse, plot and export simulations; a
JavaScript Object Notation (JSON) Web service to retrieve data for Web-based
visualizations; a command-line interface to deposit simulations; and a Python API
to retrieve data for advanced analysis. Overall, we believe WholeCellSimDB will
help researchers use whole-cell models to advance basic biological science and
bioengineering.DATABASE URL: http://www.wholecellsimdb.org SOURCE CODE
REPOSITORY: URL: http://github.com/CovertLab/WholeCellSimDB.

© The Author(s) 2014. Published by Oxford University Press.

DOI: 10.1093/database/bau095 
PMCID: PMC4165886
PMID: 25231498  [PubMed - indexed for MEDLINE]


1178. Bioinformatics. 2015 Jan 1;31(1):134-6. doi: 10.1093/bioinformatics/btu605. Epub 
2014 Sep 10.

cddApp: a Cytoscape app for accessing the NCBI conserved domain database.

Morris JH(1), Wu A(1), Yamashita RA(1), Marchler-Bauer A(1), Ferrin TE(1).

Author information: 
(1)Resource for Biocomputing, Visualization, and Informatics, University of
California, San Francisco, CA 94143, USA and National Center for Biotechnology
Information, National Library of Medicine, National Institutes of Health,
Bethesda, MD 20894, USA.

MOTIVATION: cddApp is a Cytoscape extension that supports the annotation of
protein networks with information about domains and specific functional sites
from the National Center for Biotechnology Information's conserved domain
database (CDD). CDD information is loaded for nodes annotated with NCBI numbers
or UniProt identifiers and (optionally) Protein Data Bank structures. cddApp
integrates with the Cytoscape apps structureViz2 and enhancedGraphics. Together, 
these three apps provide powerful tools to annotate nodes with CDD domain and
site information and visualize that information in both network and structural
contexts.
AVAILABILITY AND IMPLEMENTATION: cddApp is written in Java and freely available
for download from the Cytoscape app store (http://apps.cytoscape.org).
Documentation is provided at http://www.rbvi.ucsf.edu/cytoscape, and the source
is publically available from GitHub http://github.com/RBVI/cddApp.

Published by Oxford University Press 2014. This work is written by US Government 
employees and is in the public domain in the US.

DOI: 10.1093/bioinformatics/btu605 
PMCID: PMC4271147
PMID: 25212755  [PubMed - indexed for MEDLINE]


1179. Front Genet. 2014 Aug 26;5:293. doi: 10.3389/fgene.2014.00293. eCollection 2014.

A bioinformatics workflow for detecting signatures of selection in genomic data.

Cadzow M(1), Boocock J(1), Nguyen HT(2), Wilcox P(3), Merriman TR(1), Black
MA(1).

Author information: 
(1)Department of Biochemistry, University of Otago Dunedin, New Zealand ; Virtual
Institute of Statistical Genetics Rotorua, New Zealand. (2)Department of
Biochemistry, University of Otago Dunedin, New Zealand ; Virtual Institute of
Statistical Genetics Rotorua, New Zealand ; Department of Mathematics and
Statistics, University of Otago Dunedin, New Zealand. (3)Department of
Biochemistry, University of Otago Dunedin, New Zealand ; Virtual Institute of
Statistical Genetics Rotorua, New Zealand ; New Zealand Forest Research Institute
Ltd Rotorua, New Zealand.

The detection of "signatures of selection" is now possible on a genome-wide scale
in many plant and animal species, and can be performed in a population-specific
manner due to the wealth of per-population genome-wide genotype data that is
available. With genomic regions that exhibit evidence of having been under
selection shown to also be enriched for genes associated with biologically
important traits, detection of evidence of selective pressure is emerging as an
additional approach for identifying novel gene-trait associations. While
high-density genotype data is now relatively easy to obtain, for many researchers
it is not immediately obvious how to go about identifying signatures of selection
in these data sets. Here we describe a basic workflow, constructed from open
source tools, for detecting and examining evidence of selection in genomic data. 
Code to install and implement the pipeline components, and instructions to run a 
basic analysis using the workflow described here, can be downloaded from our
public GitHub repository: http://www.github.com/smilefreak/selectionTools/

DOI: 10.3389/fgene.2014.00293 
PMCID: PMC4144660
PMID: 25206364  [PubMed]


1180. Appl Plant Sci. 2014 Jan 7;2(1). pii: apps.1300083. doi: 10.3732/apps.1300083.
eCollection 2014.

2matrix: A utility for indel coding and phylogenetic matrix concatenation(1.).

Salinas NR(1), Little DP(2).

Author information: 
(1)The Graduate Center, City University of New York, 365 Fifth Avenue, New York, 
New York 10016 USA ; Cullman Program for Molecular Systematics, The New York
Botanical Garden, Bronx, New York 10458 USA. (2)Cullman Program for Molecular
Systematics, The New York Botanical Garden, Bronx, New York 10458 USA.

PREMISE OF THE STUDY: Phylogenetic analysis of DNA and amino acid sequences
requires the creation of files formatted specifically for each analysis package. 
Programs currently available cannot simultaneously code inferred
insertion/deletion (indel) events in sequence alignments and concatenate data
sets. •
METHODS AND RESULTS: A novel Perl script, 2matrix, was created to concatenate
matrices of non-molecular characters and/or aligned sequences and to code indels.
2matrix outputs a variety of formats compatible with popular phylogenetic
programs. •
CONCLUSIONS: 2matrix efficiently codes indels and concatenates matrices of
sequences and non-molecular data. It is available for free download under a GPL
(General Public License) open source license
(https://github.com/nrsalinas/2matrix/archive/master.zip).

DOI: 10.3732/apps.1300083 
PMCID: PMC4123383
PMID: 25202595  [PubMed]


1181. Bioinformatics. 2015 Jan 1;31(1):116-8. doi: 10.1093/bioinformatics/btu593. Epub 
2014 Sep 4.

Genomon ITDetector: a tool for somatic internal tandem duplication detection from
cancer genome sequencing data.

Chiba K(1), Shiraishi Y(1), Nagata Y(1), Yoshida K(1), Imoto S(1), Ogawa S(1),
Miyano S(1).

Author information: 
(1)Laboratory of DNA Information Analysis, Human Genome Center, the Institute of 
Medical Science, The University of Tokyo, Tokyo 108-8639 and Department of
Pathology and Tumor Biology, Graduate School of Medicine, Kyoto University, Kyoto
606-8501, Japan.

SUMMARY: Somatic internal tandem duplications (ITDs) are known to play important 
roles in cancer pathogenesis. Although recent advances in high-throughput
sequencing technologies have enabled genome-wide detection of various types of
genomic mutations, including single nucleotide variants, indels and structural
variations, only a few studies have focused on ITDs. We have developed an
analytical tool called 'Genomon ITDetector' for genome-wide detection of somatic 
ITDs. After evaluating the sensitivity and precision of the proposed approach
using synthetic data, we have demonstrated that it can successfully detect not
only common ITDs involving FLT3, but also a number of ITDs affecting other
putative driver genes in acute myeloid leukemia exome sequencing data.
Availability and implementaion: Genomon ITDetector is freely available at
https://github.com/ken0-1n/Genomon-ITDetector.

© Crown copyright 2014.

DOI: 10.1093/bioinformatics/btu593 
PMID: 25192740  [PubMed - indexed for MEDLINE]


1182. Bioinformatics. 2015 Jan 1;31(1):112-3. doi: 10.1093/bioinformatics/btu547. Epub 
2014 Sep 4.

mod_bio: Apache modules for Next-Generation sequencing data.

Lindenbaum P(1), Redon R(1).

Author information: 
(1)Institut National de la Santé et de la Recherche Médicale (INSERM) Unité Mixte
de Recherche (UMR) 1087, L'Institut du Thorax, Centre National de la Recherche
Scientifique (CNRS) UMR 6291, Centre Hospitalier Universitaire (CHU) de Nantes,
L'Institut du Thorax, Service de Cardiologie, 44000 Nantes and Université de
Nantes, 44000 Nantes, France Institut National de la Santé et de la Recherche
Médicale (INSERM) Unité Mixte de Recherche (UMR) 1087, L'Institut du Thorax,
Centre National de la Recherche Scientifique (CNRS) UMR 6291, Centre Hospitalier 
Universitaire (CHU) de Nantes, L'Institut du Thorax, Service de Cardiologie,
44000 Nantes and Université de Nantes, 44000 Nantes, France Institut National de 
la Santé et de la Recherche Médicale (INSERM) Unité Mixte de Recherche (UMR)
1087, L'Institut du Thorax, Centre National de la Recherche Scientifique (CNRS)
UMR 6291, Centre Hospitalier Universitaire (CHU) de Nantes, L'Institut du Thorax,
Service de Cardiologie, 44000 Nantes and Université de Nantes, 44000 Nantes,
France Institut National de la Santé et de la Recherche Médicale (INSERM) Unité
Mixte de Recherche (UMR) 1087, L'Institut du Thorax, Centre National de la
Recherche Scientifique (CNRS) UMR 6291, Centre Hospitalier Universitaire (CHU) de
Nantes, L'Institut du Thorax, Service de Cardiologie, 44000 Nantes and Université
de Nantes, 44000 Nantes, France.

SUMMARY: We describe mod_bio, a set of modules for the Apache HTTP server that
allows the users to access and query fastq, tabix, fasta and bam files through a 
Web browser. Those data are made available in plain text, HTML, XML, JSON and
JSON-P. A javascript-based genome browser using the JSON-P communication
technique is provided as an example of cross-domain Web service.
AVAILABILITY AND IMPLEMENTATION: https://github.com/lindenb/mod_bio.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu547 
PMID: 25192739  [PubMed - indexed for MEDLINE]


1183. Bioinformatics. 2014 Dec 1;30(23):3424-6. doi: 10.1093/bioinformatics/btu552.
Epub 2014 Sep 3.

subSeq: determining appropriate sequencing depth through efficient read
subsampling.

Robinson DG(1), Storey JD(2).

Author information: 
(1)Lewis-Sigler Institute for Integrative Genomics and Department of Molecular
Biology, Princeton University, Princeton, NJ 08544, USA. (2)Lewis-Sigler
Institute for Integrative Genomics and Department of Molecular Biology, Princeton
University, Princeton, NJ 08544, USA Lewis-Sigler Institute for Integrative
Genomics and Department of Molecular Biology, Princeton University, Princeton, NJ
08544, USA.

MOTIVATION: Next-generation sequencing experiments, such as RNA-Seq, play an
increasingly important role in biological research. One complication is that the 
power and accuracy of such experiments depend substantially on the number of
reads sequenced, so it is important and challenging to determine the optimal read
depth for an experiment or to verify whether one has adequate depth in an
existing experiment.
RESULTS: By randomly sampling lower depths from a sequencing experiment and
determining where the saturation of power and accuracy occurs, one can determine 
what the most useful depth should be for future experiments, and furthermore,
confirm whether an existing experiment had sufficient depth to justify its
conclusions. We introduce the subSeq R package, which uses a novel efficient
approach to perform this subsampling and to calculate informative metrics at each
depth.
AVAILABILITY AND IMPLEMENTATION: The subSeq R package is available at
http://github.com/StoreyLab/subSeq/.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu552 
PMCID: PMC4296149
PMID: 25189781  [PubMed - indexed for MEDLINE]


1184. Bioinformatics. 2015 Jan 1;31(1):10-6. doi: 10.1093/bioinformatics/btu595. Epub
2014 Sep 3.

BigDataScript: a scripting language for data pipelines.

Cingolani P(1), Sladek R(2), Blanchette M(2).

Author information: 
(1)McGill University School of Computer Science, 3480 University Street,
Montreal, Québec H3A 0E9 and McGill University and Génome Québec Innovation
Centre, 740 Dr. Penfield Avenue, Montréal, Québec H3A 0G1, Canada McGill
University School of Computer Science, 3480 University Street, Montreal, Québec
H3A 0E9 and McGill University and Génome Québec Innovation Centre, 740 Dr.
Penfield Avenue, Montréal, Québec H3A 0G1, Canada. (2)McGill University School of
Computer Science, 3480 University Street, Montreal, Québec H3A 0E9 and McGill
University and Génome Québec Innovation Centre, 740 Dr. Penfield Avenue,
Montréal, Québec H3A 0G1, Canada.

MOTIVATION: The analysis of large biological datasets often requires complex
processing pipelines that run for a long time on large computational
infrastructures. We designed and implemented a simple script-like programming
language with a clean and minimalist syntax to develop and manage pipeline
execution and provide robustness to various types of software and hardware
failures as well as portability.
RESULTS: We introduce the BigDataScript (BDS) programming language for data
processing pipelines, which improves abstraction from hardware resources and
assists with robustness. Hardware abstraction allows BDS pipelines to run without
modification on a wide range of computer architectures, from a small laptop to
multi-core servers, server farms, clusters and clouds. BDS achieves robustness by
incorporating the concepts of absolute serialization and lazy processing, thus
allowing pipelines to recover from errors. By abstracting pipeline concepts at
programming language level, BDS simplifies implementation, execution and
management of complex bioinformatics pipelines, resulting in reduced development 
and debugging cycles as well as cleaner code.
AVAILABILITY AND IMPLEMENTATION: BigDataScript is available under open-source
license at http://pcingola.github.io/BigDataScript.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu595 
PMCID: PMC4271142
PMID: 25189778  [PubMed - indexed for MEDLINE]


1185. Database (Oxford). 2014 Sep 1;2014. pii: bau087. doi: 10.1093/database/bau087.
Print 2014.

Integrating information retrieval with distant supervision for gene ontology
annotation.

Zhu D(1), Li D(2), Carterette B(2), Liu H(3).

Author information: 
(1)Department of Health Sciences Research, Mayo Clinic, 200 First St SW,
Rochester, MN 55905 and Department of Computer & Information Sciences, University
of Delaware, 101 SMITH HALL, Newark, DE 19716, USA Department of Health Sciences 
Research, Mayo Clinic, 200 First St SW, Rochester, MN 55905 and Department of
Computer & Information Sciences, University of Delaware, 101 SMITH HALL, Newark, 
DE 19716, USA. (2)Department of Health Sciences Research, Mayo Clinic, 200 First 
St SW, Rochester, MN 55905 and Department of Computer & Information Sciences,
University of Delaware, 101 SMITH HALL, Newark, DE 19716, USA. (3)Department of
Health Sciences Research, Mayo Clinic, 200 First St SW, Rochester, MN 55905 and
Department of Computer & Information Sciences, University of Delaware, 101 SMITH 
HALL, Newark, DE 19716, USA liu.hongfang@mayo.edu.

This article describes our participation of the Gene Ontology Curation task (GO
task) in BioCreative IV where we participated in both subtasks: A) identification
of GO evidence sentences (GOESs) for relevant genes in full-text articles and B) 
prediction of GO terms for relevant genes in full-text articles. For subtask A,
we trained a logistic regression model to detect GOES based on annotations in the
training data supplemented with more noisy negatives from an external resource.
Then, a greedy approach was applied to associate genes with sentences. For
subtask B, we designed two types of systems: (i) search-based systems, which
predict GO terms based on existing annotations for GOESs that are of different
textual granularities (i.e., full-text articles, abstracts, and sentences) using 
state-of-the-art information retrieval techniques (i.e., a novel application of
the idea of distant supervision) and (ii) a similarity-based system, which
assigns GO terms based on the distance between words in sentences and GO
terms/synonyms. Our best performing system for subtask A achieves an F1 score of 
0.27 based on exact match and 0.387 allowing relaxed overlap match. Our best
performing system for subtask B, a search-based system, achieves an F1 score of
0.075 based on exact match and 0.301 considering hierarchical matches. Our
search-based systems for subtask B significantly outperformed the
similarity-based system.DATABASE URL: https://github.com/noname2020/Bioc.

© The Author(s) 2014. Published by Oxford University Press.

DOI: 10.1093/database/bau087 
PMCID: PMC4150992
PMID: 25183856  [PubMed - indexed for MEDLINE]


1186. Bioinformatics. 2015 Jan 1;31(1):102-8. doi: 10.1093/bioinformatics/btu589. Epub 
2014 Sep 2.

Over-representation of correlation analysis (ORCA): a method for identifying
associations between variable sets.

Pomyen Y(1), Segura M(2), Ebbels TM(2), Keun HC(2).

Author information: 
(1)Department of Surgery and Cancer, Section of Computational and Systems
Medicine, Imperial College London, Exhibition Road, London SW7 2AZ, UK and
Translational Research Unit, Chulabhorn Research Institute, Bangkok 10210,
Thailand Department of Surgery and Cancer, Section of Computational and Systems
Medicine, Imperial College London, Exhibition Road, London SW7 2AZ, UK and
Translational Research Unit, Chulabhorn Research Institute, Bangkok 10210,
Thailand. (2)Department of Surgery and Cancer, Section of Computational and
Systems Medicine, Imperial College London, Exhibition Road, London SW7 2AZ, UK
and Translational Research Unit, Chulabhorn Research Institute, Bangkok 10210,
Thailand.

MOTIVATION: Often during the analysis of biological data, it is of importance to 
interpret the correlation structure that exists between variables. Such
correlations may reveal patterns of co-regulation that are indicative of
biochemical pathways or common mechanisms of response to a related set of
treatments. However, analyses of correlations are usually conducted by either
subjective interpretation of the univariate covariance matrix or by applying
multivariate modeling techniques, which do not take prior biological knowledge
into account. Over-representation analysis (ORA) is a simple method for
objectively deciding whether a set of variables of known or suspected biological 
relevance, such as a gene set or pathway, is more prevalent in a set of variables
of interest than we expect by chance. However, ORA is usually applied to a set of
variables differentiating a single experimental variable and does not take into
account correlations.
RESULTS: Over-representation of correlation analysis (ORCA) is a novel
combination of ORA and correlation analysis that provides a means to test whether
more associations exist between two specific groups of variables than expected by
chance. The method is exemplified by application to drug sensitivity and microRNA
expression data from a panel of cancer cell lines (NCI60). ORCA highlighted a
previously reported correlation between sensitivity to alkylating anticancer
agents and topoisomerase inhibitors. We also used this approach to validate
microRNA clusters predicted by mRNA correlations. These observations suggest that
ORCA has the potential to reveal novel insights from these data, which are not
readily apparent using classical ORA.
AVAILABILITY AND IMPLEMENTATION: The R code of the method is available at
https://github.com/ORCABioinfo/ORCAcode.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu589 
PMID: 25183485  [PubMed - indexed for MEDLINE]


1187. PLoS One. 2014 Sep 2;9(9):e106397. doi: 10.1371/journal.pone.0106397. eCollection
2014.

RTCGAToolbox: a new tool for exporting TCGA Firehose data.

Samur MK(1).

Author information: 
(1)Department of Biostatistics and Computational Biology, Dana-Farber Cancer
Institute and Harvard School of Public Health, Boston, Massachusetts, United
States of America; Lebow Institute of Myeloma Therapeutics and Jerome Lipper
Multiple Myeloma Center, Dana-Farber Cancer Institute and Harvard Medical School,
Boston, Massachusetts, United States of America.

BACKGROUND & OBJECTIVE: Managing data from large-scale projects (such as The
Cancer Genome Atlas (TCGA)) for further analysis is an important and time
consuming step for research projects. Several efforts, such as the Firehose
project, make TCGA pre-processed data publicly available via web services and
data portals, but this information must be managed, downloaded and prepared for
subsequent steps. We have developed an open source and extensible R based data
client for pre-processed data from the Firehouse, and demonstrate its use with
sample case studies. Results show that our RTCGAToolbox can facilitate data
management for researchers interested in working with TCGA data. The RTCGAToolbox
can also be integrated with other analysis pipelines for further data processing.
AVAILABILITY AND IMPLEMENTATION: The RTCGAToolbox is open-source and licensed
under the GNU General Public License Version 2.0. All documentation and source
code for RTCGAToolbox is freely available at
http://mksamur.github.io/RTCGAToolbox/ for Linux and Mac OS X operating systems.

DOI: 10.1371/journal.pone.0106397 
PMCID: PMC4152273
PMID: 25181531  [PubMed - indexed for MEDLINE]


1188. Bioinformatics. 2015 Jan 1;31(1):109-11. doi: 10.1093/bioinformatics/btu588. Epub
2014 Aug 31.

GenPlay Multi-Genome, a tool to compare and analyze multiple human genomes in a
graphical interface.

Lajugie J(1), Fourel N(1), Bouhassira EE(1).

Author information: 
(1)Department of Cell Biology, Albert Einstein College of Medicine, New York, NY 
10461, USA.

SUMMARY: Parallel visualization of multiple individual human genomes is a complex
endeavor that is rapidly gaining importance with the increasing number of
personal, phased and cancer genomes that are being generated. It requires the
display of variants such as SNPs, indels and structural variants that are unique 
to specific genomes and the introduction of multiple overlapping gaps in the
reference sequence. Here, we describe GenPlay Multi-Genome, an application
specifically written to visualize and analyze multiple human genomes in parallel.
GenPlay Multi-Genome is ideally suited for the comparison of allele-specific
expression and functional genomic data obtained from multiple phased genomes in a
graphical interface with access to multiple-track operation. It also allows the
analysis of data that have been aligned to custom genomes rather than to a
standard reference and can be used as a variant calling format file browser and
as a tool to compare different genome assembly, such as hg19 and hg38.
AVAILABILITY AND IMPLEMENTATION: GenPlay is available under the GNU public
license (GPL-3) from http://genplay.einstein.yu.edu. The source code is available
at https://github.com/JulienLajugie/GenPlay.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu588 
PMCID: PMC4402384
PMID: 25178461  [PubMed - indexed for MEDLINE]


1189. PeerJ. 2014 Aug 21;2:e545. doi: 10.7717/peerj.545. eCollection 2014.

Subsampled open-reference clustering creates consistent, comprehensive OTU
definitions and scales to billions of sequences.

Rideout JR(1), He Y(2), Navas-Molina JA(3), Walters WA(4), Ursell LK(5), Gibbons 
SM(6), Chase J(7), McDonald D(8), Gonzalez A(9), Robbins-Pianka A(8), Clemente
JC(10), Gilbert JA(11), Huse SM(12), Zhou HW(2), Knight R(13), Caporaso JG(14).

Author information: 
(1)Center for Microbial Genetics and Genomics, Northern Arizona University ,
Flagstaff, AZ , USA ; Department of Genetics and Genomic Sciences, Icahn School
of Medicine at Mount Sinai , New York, NY , USA. (2)State Key Laboratory of Organ
Failure Prevention, and Department of Environmental Health, School of Public
Health and Tropical Medicine, Southern Medical University , Guangzhou, Guangdong 
, China. (3)Department of Computer Science, University of Colorado Boulder ,
Boulder, CO , USA. (4)Department of Molecular, Cellular, and Developmental
Biology, University of Colorado at Boulder , Boulder, CO , USA. (5)Department of 
Chemistry and Biochemistry, University of Colorado at Boulder , Boulder, CO ,
USA. (6)Graduate Program in Biophysical Sciences, University of Chicago ,
Chicago, IL , USA ; Institute for Genomics and Systems Biology, Argonne National 
Laboratory , Lemont, IL , USA. (7)Department of Biological Sciences, Northern
Arizona University , AZ , USA. (8)Department of Computer Science, University of
Colorado Boulder , Boulder, CO , USA ; BioFrontiers Institute, University of
Colorado at Boulder , Boulder, CO , USA. (9)BioFrontiers Institute, University of
Colorado at Boulder , Boulder, CO , USA. (10)Department of Genetics and Genomic
Sciences, Icahn School of Medicine at Mount Sinai , New York, NY , USA.
(11)Institute for Genomics and Systems Biology, Argonne National Laboratory ,
Lemont, IL , USA ; Department of Ecology and Evolution, University of Chicago ,
Chicago, IL , USA. (12)Department of Pathology and Laboratory Science, Warren
Alpert Medical School, Brown University , Providence, RI , USA. (13)BioFrontiers 
Institute, University of Colorado at Boulder , Boulder, CO , USA ; Howard Hughes 
Medical Institute , Boulder, CO , USA. (14)Center for Microbial Genetics and
Genomics, Northern Arizona University , Flagstaff, AZ , USA ; Department of
Biological Sciences, Northern Arizona University , AZ , USA.

We present a performance-optimized algorithm, subsampled open-reference OTU
picking, for assigning marker gene (e.g., 16S rRNA) sequences generated on
next-generation sequencing platforms to operational taxonomic units (OTUs) for
microbial community analysis. This algorithm provides benefits over de novo OTU
picking (clustering can be performed largely in parallel, reducing runtime) and
closed-reference OTU picking (all reads are clustered, not only those that match 
a reference database sequence with high similarity). Because more of our
algorithm can be run in parallel relative to "classic" open-reference OTU
picking, it makes open-reference OTU picking tractable on massive amplicon
sequence data sets (though on smaller data sets, "classic" open-reference OTU
clustering is often faster). We illustrate that here by applying it to the first 
15,000 samples sequenced for the Earth Microbiome Project (1.3 billion V4 16S
rRNA amplicons). To the best of our knowledge, this is the largest OTU picking
run ever performed, and we estimate that our new algorithm runs in less than 1/5 
the time than would be required of "classic" open reference OTU picking. We show 
that subsampled open-reference OTU picking yields results that are highly
correlated with those generated by "classic" open-reference OTU picking through
comparisons on three well-studied datasets. An implementation of this algorithm
is provided in the popular QIIME software package, which uses uclust for read
clustering. All analyses were performed using QIIME's uclust wrappers, though we 
provide details (aided by the open-source code in our GitHub repository) that
will allow implementation of subsampled open-reference OTU picking independently 
of QIIME (e.g., in a compiled programming language, where runtimes should be
further reduced). Our analyses should generalize to other implementations of
these OTU picking algorithms. Finally, we present a comparison of parameter
settings in QIIME's OTU picking workflows and make recommendations on settings
for these free parameters to optimize runtime without reducing the quality of the
results. These optimized parameters can vastly decrease the runtime of
uclust-based OTU picking in QIIME.

DOI: 10.7717/peerj.545 
PMCID: PMC4145071
PMID: 25177538  [PubMed]


1190. Bioinformatics. 2014 Dec 1;30(23):3342-8. doi: 10.1093/bioinformatics/btu571.
Epub 2014 Aug 27.

VSEAMS: a pipeline for variant set enrichment analysis using summary GWAS data
identifies IKZF3, BATF and ESRRA as key transcription factors in type 1 diabetes.

Burren OS(1), Guo H(1), Wallace C(2).

Author information: 
(1)Department of Medical Genetics, JDRF/Wellcome Trust Diabetes and Inflammation 
Laboratory, NIHR Cambridge Biomedical Research Centre, Cambridge Institute for
Medical Research, University of Cambridge, Wellcome Trust/MRC Building, Cambridge
Biomedical Campus, Cambridge, CB2 0XY, UK and MRC Biostatistics Unit, Cambridge
Institute of Public Health, Forvie Site, Robinson Way, Cambridge Biomedical
Campus, Cambridge, CB2 0SR, UK. (2)Department of Medical Genetics, JDRF/Wellcome 
Trust Diabetes and Inflammation Laboratory, NIHR Cambridge Biomedical Research
Centre, Cambridge Institute for Medical Research, University of Cambridge,
Wellcome Trust/MRC Building, Cambridge Biomedical Campus, Cambridge, CB2 0XY, UK 
and MRC Biostatistics Unit, Cambridge Institute of Public Health, Forvie Site,
Robinson Way, Cambridge Biomedical Campus, Cambridge, CB2 0SR, UK Department of
Medical Genetics, JDRF/Wellcome Trust Diabetes and Inflammation Laboratory, NIHR 
Cambridge Biomedical Research Centre, Cambridge Institute for Medical Research,
University of Cambridge, Wellcome Trust/MRC Building, Cambridge Biomedical
Campus, Cambridge, CB2 0XY, UK and MRC Biostatistics Unit, Cambridge Institute of
Public Health, Forvie Site, Robinson Way, Cambridge Biomedical Campus, Cambridge,
CB2 0SR, UK.

MOTIVATION: Genome-wide association studies (GWAS) have identified many loci
implicated in disease susceptibility. Integration of GWAS summary statistics
(P-values) and functional genomic datasets should help to elucidate mechanisms.
RESULTS: We extended a non-parametric SNP set enrichment method to test for
enrichment of GWAS signals in functionally defined loci to a situation where only
GWAS P-values are available. The approach is implemented in VSEAMS, a freely
available software pipeline. We use VSEAMS to identify enrichment of type 1
diabetes (T1D) GWAS associations near genes that are targets for the
transcription factors IKZF3, BATF and ESRRA. IKZF3 lies in a known T1D
susceptibility region, while BATF and ESRRA overlap other immune disease
susceptibility regions, validating our approach and suggesting novel avenues of
research for T1D.
AVAILABILITY AND IMPLEMENTATION: VSEAMS is available for download
(http://github.com/ollyburren/vseams).

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu571 
PMCID: PMC4296156
PMID: 25170024  [PubMed - indexed for MEDLINE]


1191. Iperception. 2014 Feb 5;5(1):75-8. doi: 10.1068/i004ir. eCollection 2014.

Sharing code.

Kubilius J(1).

Author information: 
(1)Laboratories of Biological and Experimental Psychology, KU Leuven,
Tiensestraat 102 bus 3714, B-3000 Leuven, Belgium; e-mail:
jonas.kubilius@ppw.kuleuven.be.

Sharing code is becoming increasingly important in the wake of Open Science. In
this review I describe and compare two popular code-sharing utilities, GitHub and
Open Science Framework (OSF). GitHub is a mature, industry-standard tool but
lacks focus towards researchers. In comparison, OSF offers a one-stop solution
for researchers but a lot of functionality is still under development. I conclude
by listing alternative lesser-known tools for code and materials sharing.

DOI: 10.1068/i004ir 
PMCID: PMC4130510
PMID: 25165519  [PubMed]


1192. Bioinformatics. 2014 Dec 1;30(23):3432-4. doi: 10.1093/bioinformatics/btu564.
Epub 2014 Aug 26.

MR_predictor: a simulation engine for Mendelian Randomization studies.

Voight BF(1).

Author information: 
(1)Department of Pharmacology and Department of Genetics, University of
Pennsylvania - Perelman School of Medicine, Philadelphia, PA 19143, USA
Department of Pharmacology and Department of Genetics, University of Pennsylvania
- Perelman School of Medicine, Philadelphia, PA 19143, USA.

I present MR_predictor, a simulation engine designed to guide the development and
interpretation of statistical tests of causality between phenotypes using genetic
instruments. MR_predictor provides a framework to model either individual traits 
or complex scenarios where multiple phenotypes are correlated or dependent on
each other. Crucially, MR_predictor can incorporate the effects of multiple
biallelic loci (linked or unlinked) contributing genotypic variability to one or 
more simulated phenotypes. The software has a range of options for sample
generation, and output files generated by MR_predictor port into commonly used
analysis tools (e.g. PLINK, R), facilitating analyses germane for Mendelian
Randomization studies. Benchmarks for speed and power calculations for summary
statistic-based Mendelian Randomization analyses are presented and compared with 
analytical expectation.AVAILABILITY AND IMPLEMENTATION: The simulation engine is 
implemented in PERL, and the associated scripts can be downloaded from
github.com, and online documentation, tutorial and example datasets are available
at http://coruscant.itmat.upenn.edu/mr_predictor.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu564 
PMID: 25165093  [PubMed - indexed for MEDLINE]


1193. Bioinformatics. 2014 Sep 1;30(17):i556-63. doi: 10.1093/bioinformatics/btu464.

Drug susceptibility prediction against a panel of drugs using kernelized Bayesian
multitask learning.

Gönen M(1), Margolin AA(1).

Author information: 
(1)Sage Bionetworks, Seattle, WA 98109, USA.

MOTIVATION: Human immunodeficiency virus (HIV) and cancer require personalized
therapies owing to their inherent heterogeneous nature. For both diseases,
large-scale pharmacogenomic screens of molecularly characterized samples have
been generated with the hope of identifying genetic predictors of drug
susceptibility. Thus, computational algorithms capable of inferring robust
predictors of drug responses from genomic information are of great practical
importance. Most of the existing computational studies that consider drug
susceptibility prediction against a panel of drugs formulate a separate learning 
problem for each drug, which cannot make use of commonalities between subsets of 
drugs.
RESULTS: In this study, we propose to solve the problem of drug susceptibility
prediction against a panel of drugs in a multitask learning framework by
formulating a novel Bayesian algorithm that combines kernel-based non-linear
dimensionality reduction and binary classification (or regression). The main
novelty of our method is the joint Bayesian formulation of projecting data points
into a shared subspace and learning predictive models for all drugs in this
subspace, which helps us to eliminate off-target effects and drug-specific
experimental noise. Another novelty of our method is the ability of handling
missing phenotype values owing to experimental conditions and quality control
reasons. We demonstrate the performance of our algorithm via cross-validation
experiments on two benchmark drug susceptibility datasets of HIV and cancer. Our 
method obtains statistically significantly better predictive performance on most 
of the drugs compared with baseline single-task algorithms that learn
drug-specific models. These results show that predicting drug susceptibility
against a panel of drugs simultaneously within a multitask learning framework
improves overall predictive performance over single-task learning approaches.
AVAILABILITY AND IMPLEMENTATION: Our Matlab implementations for binary
classification and regression are available at
https://github.com/mehmetgonen/kbmtl.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu464 
PMCID: PMC4147917
PMID: 25161247  [PubMed - indexed for MEDLINE]


1194. Bioinformatics. 2014 Sep 1;30(17):i541-8. doi: 10.1093/bioinformatics/btu462.

ASTRAL: genome-scale coalescent-based species tree estimation.

Mirarab S(1), Reaz R(1), Bayzid MS(1), Zimmermann T(2), Swenson MS(1), Warnow
T(1).

Author information: 
(1)Department of Computer Science, The University of Texas at Austin, Austin, TX 
78712, USA, Departement d'informatique, Ecole Normale Superieure, 45 Rue d'Ulm,
F-75230 Paris Cedex 05, France and Department of Electrical Engineering, The
University of Southern California, Los Angeles, CA 90089, USA. (2)Department of
Computer Science, The University of Texas at Austin, Austin, TX 78712, USA,
Departement d'informatique, Ecole Normale Superieure, 45 Rue d'Ulm, F-75230 Paris
Cedex 05, France and Department of Electrical Engineering, The University of
Southern California, Los Angeles, CA 90089, USA Department of Computer Science,
The University of Texas at Austin, Austin, TX 78712, USA, Departement
d'informatique, Ecole Normale Superieure, 45 Rue d'Ulm, F-75230 Paris Cedex 05,
France and Department of Electrical Engineering, The University of Southern
California, Los Angeles, CA 90089, USA.

MOTIVATION: Species trees provide insight into basic biology, including the
mechanisms of evolution and how it modifies biomolecular function and structure, 
biodiversity and co-evolution between genes and species. Yet, gene trees often
differ from species trees, creating challenges to species tree estimation. One of
the most frequent causes for conflicting topologies between gene trees and
species trees is incomplete lineage sorting (ILS), which is modelled by the
multi-species coalescent. While many methods have been developed to estimate
species trees from multiple genes, some which have statistical guarantees under
the multi-species coalescent model, existing methods are too computationally
intensive for use with genome-scale analyses or have been shown to have poor
accuracy under some realistic conditions.
RESULTS: We present ASTRAL, a fast method for estimating species trees from
multiple genes. ASTRAL is statistically consistent, can run on datasets with
thousands of genes and has outstanding accuracy-improving on MP-EST and the
population tree from BUCKy, two statistically consistent leading coalescent-based
methods. ASTRAL is often more accurate than concatenation using maximum
likelihood, except when ILS levels are low or there are too few gene trees.
AVAILABILITY AND IMPLEMENTATION: ASTRAL is available in open source form at
https://github.com/smirarab/ASTRAL/. Datasets studied in this article are
available at http://www.cs.utexas.edu/users/phylo/datasets/astral.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu462 
PMCID: PMC4147915
PMID: 25161245  [PubMed - indexed for MEDLINE]


1195. Bioinformatics. 2014 Sep 1;30(17):i534-40. doi: 10.1093/bioinformatics/btu461.

Point estimates in phylogenetic reconstructions.

Benner P(1), Bačák M(1), Bourguignon PY(2).

Author information: 
(1)Max-Planck Institute for Mathematics in the Sciences, 04103 Leipzig, Germany
and Isthmus SARL, 75002 Paris, France. (2)Max-Planck Institute for Mathematics in
the Sciences, 04103 Leipzig, Germany and Isthmus SARL, 75002 Paris, France
Max-Planck Institute for Mathematics in the Sciences, 04103 Leipzig, Germany and 
Isthmus SARL, 75002 Paris, France.

MOTIVATION: The construction of statistics for summarizing posterior samples
returned by a Bayesian phylogenetic study has so far been hindered by the poor
geometric insights available into the space of phylogenetic trees, and ad hoc
methods such as the derivation of a consensus tree makeup for the ill-definition 
of the usual concepts of posterior mean, while bootstrap methods mitigate the
absence of a sound concept of variance. Yielding satisfactory results with
sufficiently concentrated posterior distributions, such methods fall short of
providing a faithful summary of posterior distributions if the data do not offer 
compelling evidence for a single topology.
RESULTS: Building upon previous work of Billera et al., summary statistics such
as sample mean, median and variance are defined as the geometric median, Fréchet 
mean and variance, respectively. Their computation is enabled by recently
published works, and embeds an algorithm for computing shortest paths in the
space of trees. Studying the phylogeny of a set of plants, where several tree
topologies occur in the posterior sample, the posterior mean balances correctly
the contributions from the different topologies, where a consensus tree would be 
biased. Comparisons of the posterior mean, median and consensus trees with the
ground truth using simulated data also reveals the benefits of a sound averaging 
method when reconstructing phylogenetic trees.
AVAILABILITY AND IMPLEMENTATION: We provide two independent implementations of
the algorithm for computing Fréchet means, geometric medians and variances in the
space of phylogenetic trees. TFBayes: https://github.com/pbenner/tfbayes, TrAP:
https://github.com/bacak/TrAP.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu461 
PMCID: PMC4147914
PMID: 25161244  [PubMed - indexed for MEDLINE]


1196. Bioinformatics. 2014 Sep 1;30(17):i482-8. doi: 10.1093/bioinformatics/btu458.

PconsFold: improved contact predictions improve protein models.

Michel M(1), Hayat S(2), Skwark MJ(2), Sander C(2), Marks DS(2), Elofsson A(1).

Author information: 
(1)Department of Biochemistry and Biophysics, Stockholm University, 10691
Stockholm, Sweden, Science for Life Laboratory, Stockholm University, Box 1031,
17121 Solna, Sweden, Department of Systems Biology, Harvard Medical School,
Boston, MA, USA, Department of Information and Computer Science, Aalto
University, PO Box 15400, FI-00076 Aalto, Finland and Computational Biology,
Memorial Sloan-Kettering Cancer Center, New York, NY, USA Department of
Biochemistry and Biophysics, Stockholm University, 10691 Stockholm, Sweden,
Science for Life Laboratory, Stockholm University, Box 1031, 17121 Solna, Sweden,
Department of Systems Biology, Harvard Medical School, Boston, MA, USA,
Department of Information and Computer Science, Aalto University, PO Box 15400,
FI-00076 Aalto, Finland and Computational Biology, Memorial Sloan-Kettering
Cancer Center, New York, NY, USA. (2)Department of Biochemistry and Biophysics,
Stockholm University, 10691 Stockholm, Sweden, Science for Life Laboratory,
Stockholm University, Box 1031, 17121 Solna, Sweden, Department of Systems
Biology, Harvard Medical School, Boston, MA, USA, Department of Information and
Computer Science, Aalto University, PO Box 15400, FI-00076 Aalto, Finland and
Computational Biology, Memorial Sloan-Kettering Cancer Center, New York, NY, USA.

MOTIVATION: Recently it has been shown that the quality of protein contact
prediction from evolutionary information can be improved significantly if direct 
and indirect information is separated. Given sufficiently large protein families,
the contact predictions contain sufficient information to predict the structure
of many protein families. However, since the first studies contact prediction
methods have improved. Here, we ask how much the final models are improved if
improved contact predictions are used.
RESULTS: In a small benchmark of 15 proteins, we show that the TM-scores of
top-ranked models are improved by on average 33% using PconsFold compared with
the original version of EVfold. In a larger benchmark, we find that the quality
is improved with 15-30% when using PconsC in comparison with earlier contact
prediction methods. Further, using Rosetta instead of CNS does not significantly 
improve global model accuracy, but the chemistry of models generated with Rosetta
is improved.
AVAILABILITY: PconsFold is a fully automated pipeline for ab initio protein
structure prediction based on evolutionary information. PconsFold is based on
PconsC contact prediction and uses the Rosetta folding protocol. Due to its
modularity, the contact prediction tool can be easily exchanged. The source code 
of PconsFold is available on GitHub at
https://www.github.com/ElofssonLab/pcons-fold under the MIT license. PconsC is
available from http://c.pcons.net/.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu458 
PMCID: PMC4147911
PMID: 25161237  [PubMed - indexed for MEDLINE]


1197. Bioinformatics. 2014 Sep 1;30(17):i379-85. doi: 10.1093/bioinformatics/btu484.

Probabilistic single-individual haplotyping.

Kuleshov V(1).

Author information: 
(1)Department of Computer Science, Stanford University, Stanford, CA 94305, USA.

MOTIVATION: Accurate haplotyping-determining from which parent particular
portions of the genome are inherited-is still mostly an unresolved problem in
genomics. This problem has only recently started to become tractable, thanks to
the development of new long read sequencing technologies. Here, we introduce
ProbHap, a haplotyping algorithm targeted at such technologies. The main
algorithmic idea of ProbHap is a new dynamic programming algorithm that exactly
optimizes a likelihood function specified by a probabilistic graphical model and 
which generalizes a popular objective called the minimum error correction. In
addition to being accurate, ProbHap also provides confidence scores at phased
positions.
RESULTS: On a standard benchmark dataset, ProbHap makes 11% fewer errors than
current state-of-the-art methods. This accuracy can be further increased by
excluding low-confidence positions, at the cost of a small drop in haplotype
completeness.
AVAILABILITY: Our source code is freely available at:
https://github.com/kuleshov/ProbHap.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu484 
PMCID: PMC4147930
PMID: 25161223  [PubMed - indexed for MEDLINE]


1198. Genome Biol. 2014 Aug 26;15(8):443. doi: 10.1186/s13059-014-0443-x.

SubcloneSeeker: a computational framework for reconstructing tumor clone
structure for cancer variant interpretation and prioritization.

Qiao Y, Quinlan AR, Jazaeri AA, Verhaak RG, Wheeler DA, Marth GT.

Many tumors are composed of genetically divergent cell subpopulations. We report 
SubcloneSeeker, a package capable of exhaustive identification of subclone
structures and evolutionary histories with bulk somatic variant allele frequency 
measurements from tumor biopsies. We present a statistical framework to elucidate
whether specific sets of mutations are present within the same subclones, and the
order in which they occur. We demonstrate how subclone reconstruction provides
crucial information about tumorigenesis and relapse mechanisms; guides functional
study by variant prioritization, and has the potential as a rational basis for
informed therapeutic strategies for the patient. SubcloneSeeker is available at: 
https://github.com/yiq/SubcloneSeeker.

DOI: 10.1186/s13059-014-0443-x 
PMCID: PMC4180956
PMID: 25160522  [PubMed - indexed for MEDLINE]


1199. BMC Genomics. 2014 Aug 26;15:717. doi: 10.1186/1471-2164-15-717.

HGTector: an automated method facilitating genome-wide discovery of putative
horizontal gene transfers.

Zhu Q(1), Kosoy M, Dittmar K.

Author information: 
(1)Department of Biological Sciences, University at Buffalo, State University of 
New York, 109 Cooke Hall, Buffalo, NY 14260, USA. qiyunzhu@buffalo.edu.

BACKGROUND: First pass methods based on BLAST match are commonly used as an
initial step to separate the different phylogenetic histories of genes in
microbial genomes, and target putative horizontal gene transfer (HGT) events.
This will continue to be necessary given the rapid growth of genomic data and the
technical difficulties in conducting large-scale explicit phylogenetic analyses. 
However, these methods often produce misleading results due to their inability to
resolve indirect phylogenetic links and their vulnerability to stochastic events.
RESULTS: A new computational method of rapid, exhaustive and genome-wide
detection of HGT was developed, featuring the systematic analysis of BLAST hit
distribution patterns in the context of a priori defined hierarchical
evolutionary categories. Genes that fall beyond a series of statistically
determined thresholds are identified as not adhering to the typical vertical
history of the organisms in question, but instead having a putative horizontal
origin. Tests on simulated genomic data suggest that this approach effectively
targets atypically distributed genes that are highly likely to be HGT-derived,
and exhibits robust performance compared to conventional BLAST-based approaches. 
This method was further tested on real genomic datasets, including Rickettsia
genomes, and was compared to previous studies. Results show consistency with
currently employed categories of HGT prediction methods. In-depth analysis of
both simulated and real genomic data suggests that the method is notably
insensitive to stochastic events such as gene loss, rate variation and database
error, which are common challenges to the current methodology. An automated
pipeline was created to implement this approach and was made publicly available
at: https://github.com/DittmarLab/HGTector. The program is versatile, easily
deployed, has a low requirement for computational resources.
CONCLUSIONS: HGTector is an effective tool for initial or standalone large-scale 
discovery of candidate HGT-derived genes.

DOI: 10.1186/1471-2164-15-717 
PMCID: PMC4155097
PMID: 25159222  [PubMed - indexed for MEDLINE]


1200. Bioinformatics. 2014 Dec 1;30(23):3408-9. doi: 10.1093/bioinformatics/btu567.
Epub 2014 Aug 21.

Visualization of protein sequence features using JavaScript and SVG with pViz.js.

Mukhyala K(1), Masselot A(1).

Author information: 
(1)Department of Bioinformatics and Computational Biology, Genentech Inc., South 
San Francisco, CA 94080, USA.

pViz.js is a visualization library for displaying protein sequence features in a 
Web browser. By simply providing a sequence and the locations of its features,
this lightweight, yet versatile, JavaScript library renders an interactive view
of the protein features. Interactive exploration of protein sequence features
over the Web is a common need in Bioinformatics. Although many Web sites have
developed viewers to display these features, their implementations are usually
focused on data from a specific source or use case. Some of these viewers can be 
adapted to fit other use cases but are not designed to be reusable. pViz makes it
easy to display features as boxes aligned to a protein sequence with zooming
functionality but also includes predefined renderings for secondary structure and
post-translational modifications. The library is designed to further customize
this view. We demonstrate such applications of pViz using two examples: a
proteomic data visualization tool with an embedded viewer for displaying features
on protein structure, and a tool to visualize the results of the
variant_effect_predictor tool from Ensembl.AVAILABILITY AND IMPLEMENTATION:
pViz.js is a JavaScript library, available on github at
https://github.com/Genentech/pviz. This site includes examples and functional
applications, installation instructions and usage documentation. A Readme file,
which explains how to use pViz with examples, is available as Supplementary
Material A.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu567 
PMID: 25147360  [PubMed - indexed for MEDLINE]


1201. Bioinformatics. 2014 Dec 1;30(23):3405-7. doi: 10.1093/bioinformatics/btu565.
Epub 2014 Aug 21.

PyBamView: a browser-based application for viewing short read alignments.

Gymrek M(1).

Author information: 
(1)Whitehead Institute for Biomedical Research, 9 Cambridge Center, Cambridge, MA
02142, Harvard-MIT Division of Health Sciences and Technology, MIT, Cambridge, MA
02139 and Program in Medical and Population Genetics, Broad Institute of MIT and 
Harvard, Cambridge, MA 02142, USA Whitehead Institute for Biomedical Research, 9 
Cambridge Center, Cambridge, MA 02142, Harvard-MIT Division of Health Sciences
and Technology, MIT, Cambridge, MA 02139 and Program in Medical and Population
Genetics, Broad Institute of MIT and Harvard, Cambridge, MA 02142, USA Whitehead 
Institute for Biomedical Research, 9 Cambridge Center, Cambridge, MA 02142,
Harvard-MIT Division of Health Sciences and Technology, MIT, Cambridge, MA 02139 
and Program in Medical and Population Genetics, Broad Institute of MIT and
Harvard, Cambridge, MA 02142, USA.

Current sequence alignment browsers allow visualization of large and complex
next-generation sequencing datasets. However, most of these tools provide
inadequate display of insertions and can be cumbersome to use on large datasets. 
I implemented PyBamView, a lightweight Web application for visualizing short read
alignments. It provides an easy-to-use Web interface for viewing alignments
across multiple samples, with a focus on accurate visualization of
insertions.AVAILABILITY AND IMPLEMENTATION: PyBamView is available as a standard 
python package. The source code is freely available under the MIT license at
https://mgymrek.github.io/pybamview.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu565 
PMID: 25147359  [PubMed - indexed for MEDLINE]


1202. Bioinformatics. 2014 Dec 1;30(23):3334-41. doi: 10.1093/bioinformatics/btu561.
Epub 2014 Aug 21.

SecureMA: protecting participant privacy in genetic association meta-analysis.

Xie W(1), Kantarcioglu M(1), Bush WS(2), Crawford D(2), Denny JC(2), Heatherly
R(1), Malin BA(2).

Author information: 
(1)Department of Electrical Engineering & Computer Science, Vanderbilt
University, Nashville, TN 37232, USA, Department of Computer Science, University 
of Texas at Dallas, Richardson, TX 75080, USA, Department of Biomedical
Informatics, Center for Human Genetics Research, Department of Molecular
Physiology and Biophysics and Department of Medicine, Vanderbilt University,
Nashville, TN 37232, USA. (2)Department of Electrical Engineering & Computer
Science, Vanderbilt University, Nashville, TN 37232, USA, Department of Computer 
Science, University of Texas at Dallas, Richardson, TX 75080, USA, Department of 
Biomedical Informatics, Center for Human Genetics Research, Department of
Molecular Physiology and Biophysics and Department of Medicine, Vanderbilt
University, Nashville, TN 37232, USA Department of Electrical Engineering &
Computer Science, Vanderbilt University, Nashville, TN 37232, USA, Department of 
Computer Science, University of Texas at Dallas, Richardson, TX 75080, USA,
Department of Biomedical Informatics, Center for Human Genetics Research,
Department of Molecular Physiology and Biophysics and Department of Medicine,
Vanderbilt University, Nashville, TN 37232, USA.

MOTIVATION: Sharing genomic data is crucial to support scientific investigation
such as genome-wide association studies. However, recent investigations suggest
the privacy of the individual participants in these studies can be compromised,
leading to serious concerns and consequences, such as overly restricted access to
data.
RESULTS: We introduce a novel cryptographic strategy to securely perform
meta-analysis for genetic association studies in large consortia. Our methodology
is useful for supporting joint studies among disparate data sites, where privacy 
or confidentiality is of concern. We validate our method using three multisite
association studies. Our research shows that genetic associations can be analyzed
efficiently and accurately across substudy sites, without leaking information on 
individual participants and site-level association summaries.
AVAILABILITY AND IMPLEMENTATION: Our software for secure meta-analysis of genetic
association studies, SecureMA, is publicly available at
http://github.com/XieConnect/SecureMA. Our customized secure computation
framework is also publicly available at
http://github.com/XieConnect/CircuitService.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu561 
PMCID: PMC4296153
PMID: 25147357  [PubMed - indexed for MEDLINE]


1203. Bioinformatics. 2014 Dec 1;30(23):3399-401. doi: 10.1093/bioinformatics/btu555.
Epub 2014 Aug 20.

Poretools: a toolkit for analyzing nanopore sequence data.

Loman NJ(1), Quinlan AR(1).

Author information: 
(1)Institute of Microbiology and Infection, University of Birmingham, Birmingham 
B15 2TT, UK and Department of Public Health Sciences, University of Virginia,
Charlottesville 22932, VA, USA.

Comment in
    Nat Methods. 2015 Jan;12(1):12-3.

MOTIVATION: Nanopore sequencing may be the next disruptive technology in
genomics, owing to its ability to detect single DNA molecules without prior
amplification, lack of reliance on expensive optical components, and the ability 
to sequence long fragments. The MinION™ from Oxford Nanopore Technologies (ONT)
is the first nanopore sequencer to be commercialized and is now available to
early-access users. The MinION™ is a USB-connected, portable nanopore sequencer
that permits real-time analysis of streaming event data. Currently, the research 
community lacks a standardized toolkit for the analysis of nanopore datasets.
RESULTS: We introduce poretools, a flexible toolkit for exploring datasets
generated by nanopore sequencing devices from MinION™ for the purposes of quality
control and downstream analysis. Poretools operates directly on the native FAST5 
(an application of the HDF5 standard) file format produced by ONT and provides a 
wealth of format conversion utilities and data exploration and visualization
tools.
AVAILABILITY AND IMPLEMENTATION: Poretools is an open-source software and is
written in Python as both a suite of command line utilities and a Python
application programming interface. Source code is freely available in Github at
https://www.github.com/arq5x/poretools.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu555 
PMCID: PMC4296151
PMID: 25143291  [PubMed - indexed for MEDLINE]


1204. Bioinformatics. 2014 Dec 1;30(23):3396-8. doi: 10.1093/bioinformatics/btu553.
Epub 2014 Aug 20.

Acceleration of short and long DNA read mapping without loss of accuracy using
suffix array.

Tárraga J(1), Arnau V(2), Martínez H(2), Moreno R(2), Cazorla D(2),
Salavert-Torres J(2), Blanquer-Espert I(1), Dopazo J(3), Medina I(2).

Author information: 
(1)Department of Computational Genomics, Centro de Investigación Príncipe Felipe 
(CIPF), Functional Genomics Node, (INB) at CIPF 46012, Departamento de
Informática, Universidad de Valencia, 46100 Valencia, Departamento de Ingeniería 
y Ciencia de Computadores, Universitat Jaume I, 12071 Castellón de la Plana,
Instituto de Investigación en Informática de Albacete, Universidad de Castilla-La
Mancha, Campus Universitario, 02071 Albacete, Universitat Politècnica de
València, Instituto de Instrumentación para Imagen Molecular, 46022 Valencia,
Grupo de Investigación Biomédica de Imagen (GIBI 2^30), La Fe Polytechnic
University Hospital, 46022 Valencia and Bioinformatics of Rare Diseases (BIER),
CIBER de Enfermedades Raras (CIBERER), Valencia, Spain Department of
Computational Genomics, Centro de Investigación Príncipe Felipe (CIPF),
Functional Genomics Node, (INB) at CIPF 46012, Departamento de Informática,
Universidad de Valencia, 46100 Valencia, Departamento de Ingeniería y Ciencia de 
Computadores, Universitat Jaume I, 12071 Castellón de la Plana, Instituto de
Investigación en Informática de Albacete, Universidad de Castilla-La Mancha,
Campus Universitario, 02071 Albacete, Universitat Politècnica de València,
Instituto de Instrumentación para Imagen Molecular, 46022 Valencia, Grupo de
Investigación Biomédica de Imagen (GIBI 2^30), La Fe Polytechnic University
Hospital, 46022 Valencia and Bioinformatics of Rare Diseases (BIER), CIBER de
Enfermedades Raras (CIBERER), Valencia, Spain. (2)Department of Computational
Genomics, Centro de Investigación Príncipe Felipe (CIPF), Functional Genomics
Node, (INB) at CIPF 46012, Departamento de Informática, Universidad de Valencia, 
46100 Valencia, Departamento de Ingeniería y Ciencia de Computadores, Universitat
Jaume I, 12071 Castellón de la Plana, Instituto de Investigación en Informática
de Albacete, Universidad de Castilla-La Mancha, Campus Universitario, 02071
Albacete, Universitat Politècnica de València, Instituto de Instrumentación para 
Imagen Molecular, 46022 Valencia, Grupo de Investigación Biomédica de Imagen
(GIBI 2^30), La Fe Polytechnic University Hospital, 46022 Valencia and
Bioinformatics of Rare Diseases (BIER), CIBER de Enfermedades Raras (CIBERER),
Valencia, Spain. (3)Department of Computational Genomics, Centro de Investigación
Príncipe Felipe (CIPF), Functional Genomics Node, (INB) at CIPF 46012,
Departamento de Informática, Universidad de Valencia, 46100 Valencia,
Departamento de Ingeniería y Ciencia de Computadores, Universitat Jaume I, 12071 
Castellón de la Plana, Instituto de Investigación en Informática de Albacete,
Universidad de Castilla-La Mancha, Campus Universitario, 02071 Albacete,
Universitat Politècnica de València, Instituto de Instrumentación para Imagen
Molecular, 46022 Valencia, Grupo de Investigación Biomédica de Imagen (GIBI
2^30), La Fe Polytechnic University Hospital, 46022 Valencia and Bioinformatics
of Rare Diseases (BIER), CIBER de Enfermedades Raras (CIBERER), Valencia, Spain
Department of Computational Genomics, Centro de Investigación Príncipe Felipe
(CIPF), Functional Genomics Node, (INB) at CIPF 46012, Departamento de
Informática, Universidad de Valencia, 46100 Valencia, Departamento de Ingeniería 
y Ciencia de Computadores, Universitat Jaume I, 12071 Castellón de la Plana,
Instituto de Investigación en Informática de Albacete, Universidad de Castilla-La
Mancha, Campus Universitario, 02071 Albacete, Universitat Politècnica de
València, Instituto de Instrumentación para Imagen Molecular, 46022 Valencia,
Grupo de Investigación Biomédica de Imagen (GIBI 2^30), La Fe Polytechnic
University Hospital, 46022 Valencia and Bioinformatics of Rare Diseases (BIER),
CIBER de Enfermedades Raras (CIBERER), Valencia, Spain Department of
Computational Genomics, Centro de Investigación Príncipe Felipe (CIPF),
Functional Genomics Node, (INB) at CIPF 46012, Departamento de Informática,
Universidad de Valencia, 46100 Valencia, Departamento de Ingeniería y Ciencia de 
Computadores, Universitat Jaume I, 12071 Castellón de la Plana, Instituto de
Investigación en Informática de Albacete, Universidad de Castilla-La Mancha,
Campus Universitario, 02071 Albacete, Universitat Politècnica de Valènci

HPG Aligner applies suffix arrays for DNA read mapping. This implementation
produces a highly sensitive and extremely fast mapping of DNA reads that scales
up almost linearly with read length. The approach presented here is faster (over 
20× for long reads) and more sensitive (over 98% in a wide range of read lengths)
than the current state-of-the-art mappers. HPG Aligner is not only an optimal
alternative for current sequencers but also the only solution available to cope
with longer reads and growing throughputs produced by forthcoming sequencing
technologies.AVAILABILITY AND IMPLEMENTATION:
https://github.com/opencb/hpg-aligner.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu553 
PMCID: PMC4816028
PMID: 25143289  [PubMed - indexed for MEDLINE]


1205. Bioinformatics. 2014 Dec 1;30(23):3293-301. doi: 10.1093/bioinformatics/btu534.
Epub 2014 Aug 18.

Comparative assembly hubs: web-accessible browsers for comparative genomics.

Nguyen N(1), Hickey G(1), Raney BJ(1), Armstrong J(1), Clawson H(1), Zweig A(1), 
Karolchik D(1), Kent WJ(1), Haussler D(2), Paten B(1).

Author information: 
(1)Center for Biomolecular Sciences and Engineering, CBSE/ITI, UC Santa Cruz,
1156 High St, Santa Cruz, CA 95064, USA and Howard Hughes Medical Institute,
Center for Biomolecular Science and Engineering, UCSC, 1156 High Street, Santa
Cruz, CA 95064, USA. (2)Center for Biomolecular Sciences and Engineering,
CBSE/ITI, UC Santa Cruz, 1156 High St, Santa Cruz, CA 95064, USA and Howard
Hughes Medical Institute, Center for Biomolecular Science and Engineering, UCSC, 
1156 High Street, Santa Cruz, CA 95064, USA Center for Biomolecular Sciences and 
Engineering, CBSE/ITI, UC Santa Cruz, 1156 High St, Santa Cruz, CA 95064, USA and
Howard Hughes Medical Institute, Center for Biomolecular Science and Engineering,
UCSC, 1156 High Street, Santa Cruz, CA 95064, USA.

MOTIVATION: Researchers now have access to large volumes of genome sequences for 
comparative analysis, some generated by the plethora of public sequencing
projects and, increasingly, from individual efforts. It is not possible, or
necessarily desirable, that the public genome browsers attempt to curate all
these data. Instead, a wealth of powerful tools is emerging to empower users to
create their own visualizations and browsers.
RESULTS: We introduce a pipeline to easily generate collections of Web-accessible
UCSC Genome Browsers interrelated by an alignment. It is intended to democratize 
our comparative genomic browser resources, serving the broad and growing
community of evolutionary genomicists and facilitating easy public sharing via
the Internet. Using the alignment, all annotations and the alignment itself can
be efficiently viewed with reference to any genome in the collection,
symmetrically. A new, intelligently scaled alignment display makes it simple to
view all changes between the genomes at all levels of resolution, from
substitutions to complex structural rearrangements, including duplications. To
demonstrate this work, we create a comparative assembly hub containing 57
Escherichia coli and 9 Shigella genomes and show examples that highlight their
unique biology.
AVAILABILITY AND IMPLEMENTATION: The source code is available as open source at: 
https://github.com/glennhickey/progressiveCactus The E.coli and Shigella genome
hub is now a public hub listed on the UCSC browser public hubs Web page.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu534 
PMCID: PMC4296145
PMID: 25138168  [PubMed - indexed for MEDLINE]


1206. Mol Biol Evol. 2014 Nov;31(11):3068-80. doi: 10.1093/molbev/msu244. Epub 2014 Aug
18.

Detecting recent positive selection with high accuracy and reliability by
conditional coalescent tree.

Wang M(1), Huang X(1), Li R(1), Xu H(1), Jin L(2), He Y(3).

Author information: 
(1)Department of Computational Regulatory Genomics, CAS-MPG Partner Institute for
Computational Biology, Shanghai Institutes for Biological Sciences, Chinese
Academy of Sciences, Shanghai, China Key Laboratory of Computational Biology,
CAS-MPG Partner Institute for Computational Biology, Chinese Academy of Sciences,
Shanghai, China. (2)Department of Computational Regulatory Genomics, CAS-MPG
Partner Institute for Computational Biology, Shanghai Institutes for Biological
Sciences, Chinese Academy of Sciences, Shanghai, China Key Laboratory of
Computational Biology, CAS-MPG Partner Institute for Computational Biology,
Chinese Academy of Sciences, Shanghai, China State Key Laboratory of Genetic
Engineering and Ministry of Education Key Laboratory of Contemporary
Anthropology, Collaborative Innovation Center for Genetics and Development,
School of Life Sciences, Fudan University, Shanghai, China lijin.fudan@gmail.com 
yunganghe@picb.ac.cn. (3)Department of Computational Regulatory Genomics, CAS-MPG
Partner Institute for Computational Biology, Shanghai Institutes for Biological
Sciences, Chinese Academy of Sciences, Shanghai, China Key Laboratory of
Computational Biology, CAS-MPG Partner Institute for Computational Biology,
Chinese Academy of Sciences, Shanghai, China lijin.fudan@gmail.com
yunganghe@picb.ac.cn.

Studies of natural selection, followed by functional validation, are shedding
light on understanding of genetic mechanisms underlying human evolution and
adaptation. Classic methods for detecting selection, such as the integrated
haplotype score (iHS) and Fay and Wu's H statistic, are useful for candidate gene
searching underlying positive selection. These methods, however, have limited
capability to localize causal variants in selection target regions. In this
study, we developed a novel method based on conditional coalescent tree to detect
recent positive selection by counting unbalanced mutations on coalescent gene
genealogies. Extensive simulation studies revealed that our method is more robust
than many other approaches against biases due to various demographic effects,
including population bottleneck, expansion, or stratification, while not
sacrificing its power. Furthermore, our method demonstrated its superiority in
localizing causal variants from massive linked genetic variants. The rate of
successful localization was about 20-40% higher than that of other
state-of-the-art methods on simulated data sets. On empirical data, validated
functional causal variants of four well-known positive selected genes were all
successfully localized by our method, such as ADH1B, MCM6, APOL1, and HBB.
Finally, the computational efficiency of this new method was much higher than
that of iHS implementations, that is, 24-66 times faster than the REHH package,
and more than 10,000 times faster than the original iHS implementation. These
magnitudes make our method suitable for applying on large sequencing data sets.
Software can be downloaded from https://github.com/wavefancy/scct.

© The Author 2014. Published by Oxford University Press on behalf of the Society 
for Molecular Biology and Evolution. All rights reserved. For permissions, please
e-mail: journals.permissions@oup.com.

DOI: 10.1093/molbev/msu244 
PMID: 25135945  [PubMed - indexed for MEDLINE]


1207. J Clin Epidemiol. 2014 Dec;67(12):1358-63. doi: 10.1016/j.jclinepi.2014.06.012.
Epub 2014 Aug 15.

Open-source electronic data capture system offered increased accuracy and
cost-effectiveness compared with paper methods in Africa.

Dillon DG(1), Pirie F(2), Rice S(3), Pomilla C(1), Sandhu MS(1), Motala AA(2),
Young EH(4); African Partnership for Chronic Disease Research (APCDR).

Author information: 
(1)International Health Research Group, Department of Public Health and Primary
Care, University of Cambridge, Strangeways Research Laboratory, Wort's Causeway, 
Cambridge, CB1 8RN, United Kingdom; Genetic Epidemiology Group, Wellcome Trust
Sanger Institute, Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1HH,
United Kingdom. (2)Department of Diabetes and Endocrinology, Nelson R. Mandela
School of Medicine, University of KwaZulu-Natal, Private Bag 7, Congella, 4013,
Durban, South Africa. (3)System Support Team, Wellcome Trust Sanger Institute,
Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1HH, United Kingdom.
(4)International Health Research Group, Department of Public Health and Primary
Care, University of Cambridge, Strangeways Research Laboratory, Wort's Causeway, 
Cambridge, CB1 8RN, United Kingdom; Genetic Epidemiology Group, Wellcome Trust
Sanger Institute, Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1HH,
United Kingdom. Electronic address: liz.young@sanger.ac.uk.

OBJECTIVES: Existing electronic data capture options are often financially
unfeasible in resource-poor settings or difficult to support technically in the
field. To help facilitate large-scale multicenter studies in sub-Saharan Africa, 
the African Partnership for Chronic Disease Research (APCDR) has developed an
open-source electronic questionnaire (EQ).
STUDY DESIGN AND SETTING: To assess its relative validity, we compared the EQ
against traditional pen-and-paper methods using 200 randomized interviews
conducted in an ongoing type 2 diabetes case-control study in South Africa.
RESULTS: During its 3-month validation, the EQ had a lower frequency of errors
(EQ, 0.17 errors per 100 questions; paper, 0.73 errors per 100 questions; P-value
≤0.001), and a lower monetary cost per correctly entered question, compared with 
the pen-and-paper method. We found no marked difference in the average duration
of the interview between methods (EQ, 5.4 minutes; paper, 5.6 minutes).
CONCLUSION: This validation study suggests that the EQ may offer increased
accuracy, similar interview duration, and increased cost-effectiveness compared
with paper-based data collection methods. The APCDR EQ software is freely
available (https://github.com/apcdr/questionnaire).

Copyright © 2014 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.jclinepi.2014.06.012 
PMCID: PMC4271740
PMID: 25135245  [PubMed - indexed for MEDLINE]


1208. Mol Cell Proteomics. 2014 Aug 16. pii: mcp.O113.030932. [Epub ahead of print]

Bayesian Proteoform Modeling Improves Protein Quantification of Global Proteomic 
Measurements.

Webb-Robertson BJ(1), Matzke MM(2), Datta S(3), Payne SH(2), Kang J(2), Bramer
LM(2), Nicora CD(2), Shukla AK(2), Metz TO(2), Rodland KD(2), Smith RD(2),
Tardiff MF(2), McDermott JE(2), Pounds JG(2), Waters KM(2).

Author information: 
(1)Pacific Northwest National Laboratory, United States; bj@pnnl.gov. (2)Pacific 
Northwest National Laboratory, United States; (3)University of Louisville, United
States.

As the capability of mass spectrometry-based proteomics has matured, tens of
thousands of peptides can be measured simultaneously, which has the benefit of
offering a systems view of protein expression. However, a major challenge is that
with an increase in throughput, protein quantification estimation from the native
measured peptides has become a computational task. A limitation to existing
computationally-driven protein quantification methods is that most ignore protein
variation, such as alternate splicing of the RNA transcript and
post-translational modifications or other possible proteoforms, which will affect
a significant fraction of the proteome. The consequence of this assumption is
that statistical inference at the protein level, and consequently downstream
analyses, such as network and pathway modeling, have only limited power for
biomarker discovery. Here, we describe a Bayesian model (BP-Quant) that uses
statistically derived peptides signatures to identify peptides that are outside
the dominant pattern, or the existence of multiple over-expressed patterns to
improve relative protein abundance estimates. It is a research-driven approach
that utilizes the objectives of the experiment, defined in the context of a
standard statistical hypothesis, to identify a set of peptides exhibiting similar
statistical behavior relating to a protein. This approach infers that changes in 
relative protein abundance can be used as a surrogate for changes in function,
without necessarily taking into account the effect of differential
post-translational modifications, processing, or splicing in altering protein
function. We verify the approach using a dilution study from mouse plasma samples
and demonstrate that BP-Quant achieves similar accuracy as the current
state-of-the-art methods at proteoform identification with significantly better
specificity. BP-Quant is available as a MatLab ® and R packages at
https://github.com/PNNL-Comp-Mass-Spec/BP-Quant.

Copyright © 2014, The American Society for Biochemistry and Molecular Biology.

DOI: 10.1074/mcp.O113.030932 
PMID: 25129695  [PubMed - as supplied by publisher]


1209. Bioinformatics. 2014 Dec 1;30(23):3438-9. doi: 10.1093/bioinformatics/btu539.
Epub 2014 Aug 14.

Cordova: web-based management of genetic variation data.

Ephraim SS(1), Anand N(1), DeLuca AP(1), Taylor KR(1), Kolbe DL(1), Simpson
AC(1), Azaiez H(1), Sloan CM(1), Shearer AE(2), Hallier AR(1), Casavant TL(1),
Scheetz TE(1), Smith RJ(3), Braun TA(1).

Author information: 
(1)Department of Biomedical Engineering, Department of Ophthalmology and Visual
Sciences, Department of Electrical and Computer Engineering, Department of
Otolaryngology-Head & Neck Surgery, Carver College of Medicine, Department of
Molecular Physiology & Biophysics, Carver College of Medicine, Interdisciplinary 
Graduate Program in Genetics and Iowa Institute for Human Genetics, Carver
College of Medicine, The University of Iowa, Iowa City, IA 52242, USA.
(2)Department of Biomedical Engineering, Department of Ophthalmology and Visual
Sciences, Department of Electrical and Computer Engineering, Department of
Otolaryngology-Head & Neck Surgery, Carver College of Medicine, Department of
Molecular Physiology & Biophysics, Carver College of Medicine, Interdisciplinary 
Graduate Program in Genetics and Iowa Institute for Human Genetics, Carver
College of Medicine, The University of Iowa, Iowa City, IA 52242, USA Department 
of Biomedical Engineering, Department of Ophthalmology and Visual Sciences,
Department of Electrical and Computer Engineering, Department of
Otolaryngology-Head & Neck Surgery, Carver College of Medicine, Department of
Molecular Physiology & Biophysics, Carver College of Medicine, Interdisciplinary 
Graduate Program in Genetics and Iowa Institute for Human Genetics, Carver
College of Medicine, The University of Iowa, Iowa City, IA 52242, USA.
(3)Department of Biomedical Engineering, Department of Ophthalmology and Visual
Sciences, Department of Electrical and Computer Engineering, Department of
Otolaryngology-Head & Neck Surgery, Carver College of Medicine, Department of
Molecular Physiology & Biophysics, Carver College of Medicine, Interdisciplinary 
Graduate Program in Genetics and Iowa Institute for Human Genetics, Carver
College of Medicine, The University of Iowa, Iowa City, IA 52242, USA Department 
of Biomedical Engineering, Department of Ophthalmology and Visual Sciences,
Department of Electrical and Computer Engineering, Department of
Otolaryngology-Head & Neck Surgery, Carver College of Medicine, Department of
Molecular Physiology & Biophysics, Carver College of Medicine, Interdisciplinary 
Graduate Program in Genetics and Iowa Institute for Human Genetics, Carver
College of Medicine, The University of Iowa, Iowa City, IA 52242, USA Department 
of Biomedical Engineering, Department of Ophthalmology and Visual Sciences,
Department of Electrical and Computer Engineering, Department of
Otolaryngology-Head & Neck Surgery, Carver College of Medicine, Department of
Molecular Physiology & Biophysics, Carver College of Medicine, Interdisciplinary 
Graduate Program in Genetics and Iowa Institute for Human Genetics, Carver
College of Medicine, The University of Iowa, Iowa City, IA 52242, USA Department 
of Biomedical Engineering, Department of Ophthalmology and Visual Sciences,
Department of Electrical and Computer Engineering, Department of
Otolaryngology-Head & Neck Surgery, Carver College of Medicine, Department of
Molecular Physiology & Biophysics, Carver College of Medicine, Interdisciplinary 
Graduate Program in Genetics and Iowa Institute for Human Genetics, Carver
College of Medicine, The University of Iowa, Iowa City, IA 52242, USA.

Cordova is an out-of-the-box solution for building and maintaining an online
database of genetic variations integrated with pathogenicity prediction results
from popular algorithms. Our primary motivation for developing this system is to 
aid researchers and clinician-scientists in determining the clinical significance
of genetic variations. To achieve this goal, Cordova provides an interface to
review and manually or computationally curate genetic variation data as well as
share it for clinical diagnostics and the advancement of research.AVAILABILITY
AND IMPLEMENTATION: Cordova is open source under the MIT license and is freely
available for download at https://github.com/clcg/cordova.

Published by Oxford University Press. This work is written by US Government
employees and is in the public domain in the US.

DOI: 10.1093/bioinformatics/btu539 
PMCID: PMC4296146
PMID: 25123904  [PubMed - indexed for MEDLINE]


1210. Bioinformatics. 2014 Dec 1;30(23):3302-9. doi: 10.1093/bioinformatics/btu537.
Epub 2014 Aug 14.

HapMuC: somatic mutation calling using heterozygous germ line variants near
candidate mutations.

Usuyama N(1), Shiraishi Y(1), Sato Y(2), Kume H(1), Homma Y(1), Ogawa S(1),
Miyano S(1), Imoto S(1).

Author information: 
(1)Human Genome Center, Institute of Medical Science, The University of Tokyo,
Tokyo 108-8639, Department of Urology, Graduate School of Medicine, The
University of Tokyo, Tokyo 113-8655 and Department of Pathology and Tumor
Biology, Graduate School of Medicine, Kyoto University, Kyoto 606-8501, Japan.
(2)Human Genome Center, Institute of Medical Science, The University of Tokyo,
Tokyo 108-8639, Department of Urology, Graduate School of Medicine, The
University of Tokyo, Tokyo 113-8655 and Department of Pathology and Tumor
Biology, Graduate School of Medicine, Kyoto University, Kyoto 606-8501, Japan
Human Genome Center, Institute of Medical Science, The University of Tokyo, Tokyo
108-8639, Department of Urology, Graduate School of Medicine, The University of
Tokyo, Tokyo 113-8655 and Department of Pathology and Tumor Biology, Graduate
School of Medicine, Kyoto University, Kyoto 606-8501, Japan.

MOTIVATION: Identifying somatic changes from tumor and matched normal sequences
has become a standard approach in cancer research. More specifically, this
requires accurate detection of somatic point mutations with low allele
frequencies in impure and heterogeneous cancer samples. Although haplotype
phasing information derived by using heterozygous germ line variants near
candidate mutations would improve accuracy, no somatic mutation caller that uses 
such information is currently available.
RESULTS: We propose a Bayesian hierarchical method, termed HapMuC, in which power
is increased by using available information on heterozygous germ line variants
located near candidate mutations. We first constructed two generative models (the
mutation model and the error model). In the generative models, we prepared
candidate haplotypes, considering a heterozygous germ line variant if available, 
and the observed reads were realigned to the haplotypes. We then inferred the
haplotype frequencies and computed the marginal likelihoods using a variational
Bayesian algorithm. Finally, we derived a Bayes factor for evaluating the
possibility of the existence of somatic mutations. We also demonstrated that our 
algorithm has superior specificity and sensitivity compared with existing
methods, as determined based on a simulation, the TCGA Mutation Calling Benchmark
4 datasets and data from the COLO-829 cell line.
AVAILABILITY AND IMPLEMENTATION: The HapMuC source code is available from
http://github.com/usuyama/hapmuc.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu537 
PMCID: PMC4816033
PMID: 25123903  [PubMed - indexed for MEDLINE]


1211. Bioinformatics. 2014 Nov 15;30(22):3266-7. doi: 10.1093/bioinformatics/btu544.
Epub 2014 Aug 12.

Figmop: a profile HMM to identify genes and bypass troublesome gene models in
draft genomes.

Curran DM(1), Gilleard JS(2), Wasmuth JD(2).

Author information: 
(1)Department of Ecosystem and Public Health and Department of Comparative
Biology and Experimental Medicine, Faculty of Veterinary Medicine, University of 
Calgary, Calgary, Alberta, T2N 4Z6, Canada Department of Ecosystem and Public
Health and Department of Comparative Biology and Experimental Medicine, Faculty
of Veterinary Medicine, University of Calgary, Calgary, Alberta, T2N 4Z6, Canada.
(2)Department of Ecosystem and Public Health and Department of Comparative
Biology and Experimental Medicine, Faculty of Veterinary Medicine, University of 
Calgary, Calgary, Alberta, T2N 4Z6, Canada.

MOTIVATION: Gene models from draft genome assemblies of metazoan species are
often incorrect, missing exons or entire genes, particularly for large gene
families. Consequently, labour-intensive manual curation is often necessary. We
present Figmop (Finding Genes using Motif Patterns) to help with the manual
curation of gene families in draft genome assemblies. The program uses a pattern 
of short sequence motifs to identify putative genes directly from the genome
sequence. Using a large gene family as a test case, Figmop was found to be more
sensitive and specific than a BLAST-based approach. The visualization used allows
the validation of potential genes to be carried out quickly and easily, saving
hours if not days from an analysis.
AVAILABILITY AND IMPLEMENTATION: Source code of Figmop is freely available for
download at https://github.com/dave-the-scientist, implemented in C and Python
and is supported on Linux, Unix and MacOSX.
CONTACT: curran.dave.m@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu544 
PMID: 25115706  [PubMed - indexed for MEDLINE]


1212. Bioinformatics. 2014 Nov 15;30(22):3274-5. doi: 10.1093/bioinformatics/btu541.
Epub 2014 Aug 8.

Fast construction of FM-index for long sequence reads.

Li H(1).

Author information: 
(1)Medical Population Genetics Program, Broad Institute, 75 Ames Street,
Cambridge, MA 02142, USA.

SUMMARY: We present a new method to incrementally construct the FM-index for both
short and long sequence reads, up to the size of a genome. It is the first
algorithm that can build the index while implicitly sorting the sequences in the 
reverse (complement) lexicographical order without a separate sorting step. The
implementation is among the fastest for indexing short reads and the only one
that practically works for reads of averaged kilobases in length.
AVAILABILITY AND IMPLEMENTATION: https://github.com/lh3/ropebwt2 CONTACT:
hengli@broadinstitute.org.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu541 
PMCID: PMC4221129
PMID: 25107872  [PubMed - indexed for MEDLINE]


1213. Bioinformatics. 2014 Nov 15;30(22):3276-8. doi: 10.1093/bioinformatics/btu531.
Epub 2014 Aug 5.

AliView: a fast and lightweight alignment viewer and editor for large datasets.

Larsson A(1).

Author information: 
(1)Systematic Biology, Department of Organismal Biology, Evolutionary Biology
Centre, Uppsala University, Uppsala 75236, Sweden.

SUMMARY: AliView is an alignment viewer and editor designed to meet the
requirements of next-generation sequencing era phylogenetic datasets. AliView
handles alignments of unlimited size in the formats most commonly used, i.e.
FASTA, Phylip, Nexus, Clustal and MSF. The intuitive graphical interface makes it
easy to inspect, sort, delete, merge and realign sequences as part of the manual 
filtering process of large datasets. AliView also works as an easy-to-use
alignment editor for small as well as large datasets.
AVAILABILITY AND IMPLEMENTATION: AliView is released as open-source software
under the GNU General Public License, version 3.0 (GPLv3), and is available at
GitHub (www.github.com/AliView). The program is cross-platform and extensively
tested on Linux, Mac OS X and Windows systems. Downloads and help are available
at http://ormbunkar.se/aliview
CONTACT: anders.larsson@ebc.uu.se
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu531 
PMCID: PMC4221126
PMID: 25095880  [PubMed - indexed for MEDLINE]


1214. J Biomed Semantics. 2014 Jun 2;5:26. doi: 10.1186/2041-1480-5-26. eCollection
2014.

Generalising semantic category disambiguation with large lexical resources for
fun and profit.

Stenetorp P(1), Pyysalo S(2), Ananiadou S(2), Tsujii J(3).

Author information: 
(1)Department of Computer Science, University of Tokyo, Tokyo, Japan. (2)School
of Computer Science, University of Manchester, Manchester, UK ; National Centre
for Text Mining, University of Manchester, Manchester, UK. (3)School of Computer 
Science, University of Manchester, Manchester, UK ; National Centre for Text
Mining, University of Manchester, Manchester, UK ; Microsoft Research Asia,
Beijing, People's Republic of China.

BACKGROUND: Semantic Category Disambiguation (SCD) is the task of assigning the
appropriate semantic category to given spans of text from a fixed set of
candidate categories, for example Protein to "Fibrin". SCD is relevant to Natural
Language Processing tasks such as Named Entity Recognition, coreference
resolution and coordination resolution. In this work, we study machine
learning-based SCD methods using large lexical resources and approximate string
matching, aiming to generalise these methods with regard to domains, lexical
resources and the composition of data sets. We specifically consider the
applicability of SCD for the purposes of supporting human annotators and acting
as a pipeline component for other Natural Language Processing systems.
RESULTS: While previous research has mostly cast SCD purely as a classification
task, we consider a task setting that allows for multiple semantic categories to 
be suggested, aiming to minimise the number of suggestions while maintaining high
recall. We argue that this setting reflects aspects which are essential for both 
a pipeline component and when supporting human annotators. We introduce an SCD
method based on a recently introduced machine learning-based system and evaluate 
it on 15 corpora covering biomedical, clinical and newswire texts and ranging in 
the number of semantic categories from 2 to 91. With appropriate settings, our
system maintains an average recall of 99% while reducing the number of candidate 
semantic categories on average by 65% over all data sets.
CONCLUSIONS: Machine learning-based SCD using large lexical resources and
approximate string matching is sensitive to the selection and granularity of
lexical resources, but generalises well to a wide range of text domains and data 
sets given appropriate resources and parameter settings. By substantially
reducing the number of candidate categories while only very rarely excluding the 
correct one, our method is shown to be applicable to manual annotation support
tasks and use as a high-recall component in text processing pipelines. The
introduced system and all related resources are freely available for research
purposes at: https://github.com/ninjin/simsem.

DOI: 10.1186/2041-1480-5-26 
PMCID: PMC4107982
PMID: 25093067  [PubMed]


1215. BMC Genomics. 2014;15 Suppl 5:S2. doi: 10.1186/1471-2164-15-S5-S2. Epub 2014 Jul 
14.

RandAL: a randomized approach to aligning DNA sequences to reference genomes.

Vo NS, Tran Q, Niraula N, Phan V.

BACKGROUND: The alignment of short reads generated by next-generation sequencers 
to genomes is an important problem in many biomedical and bioinformatics
applications. Although many proposed methods work very well on narrow ranges of
read lengths, they tend to suffer in performance and alignment quality for reads 
outside of these ranges.
RESULTS: We introduce RandAL, a novel method that aligns DNA sequences to
reference genomes. Our approach utilizes two FM indices to facilitate efficient
bidirectional searching, a pruning heuristic to speed up the computing of edit
distances, and most importantly, a randomized strategy that enables effective
estimation of key parameters. Extensive comparisons showed that RandAL
outperformed popular aligners in most instances and was unique in its consistent 
and accurate performance over a wide range of read lengths and error rates. The
software package is publicly available at https://github.com/namsyvo/RandAL.
CONCLUSIONS: RandAL promises to align effectively and accurately short reads that
come from a variety of technologies with different read lengths and rates of
sequencing error.

DOI: 10.1186/1471-2164-15-S5-S2 
PMCID: PMC4120144
PMID: 25081493  [PubMed - indexed for MEDLINE]


1216. Nucleic Acids Res. 2014;42(17):e135. doi: 10.1093/nar/gku672. Epub 2014 Jul 31.

MixMir: microRNA motif discovery from gene expression data using mixed linear
models.

Diao L(1), Marcais A(2), Norton S(3), Chen KC(4).

Author information: 
(1)BioMaPS Institute for Quantitative Biology and Department of Genetics,
Rutgers, The State University of New Jersey, Piscataway, NJ 08854, USA. (2)CIRI, 
International Center for Infectiology Research, Université de Lyon, Inserm, CNRS,
Ecole Normale Supérieure, Lyon, France. (3)BioMaPS Institute for Quantitative
Biology and Department of Genetics, Rutgers, The State University of New Jersey, 
Piscataway, NJ 08854, USA Department of Mathematics and Department of Molecular
and Cell Biology, University of Connecticut, Storrs, CT 06269, USA. (4)BioMaPS
Institute for Quantitative Biology and Department of Genetics, Rutgers, The State
University of New Jersey, Piscataway, NJ 08854, USA kcchen@dls.rutgers.edu.

microRNAs (miRNAs) are a class of ∼22nt non-coding RNAs that potentially regulate
over 60% of human protein-coding genes. miRNA activity is highly specific,
differing between cell types, developmental stages and environmental conditions, 
so the identification of active miRNAs in a given sample is of great interest.
Here we present a novel computational approach for analyzing both mRNA sequence
and gene expression data, called MixMir. Our method corrects for 3' UTR
background sequence similarity between transcripts, which is known to correlate
with mRNA transcript abundance. We demonstrate that after accounting for kmer
sequence similarities in 3' UTRs, a statistical linear model based on motif
presence/absence can effectively discover active miRNAs in a sample. MixMir
utilizes fast software implementations for solving mixed linear models, which are
widely used in genome-wide association studies (GWASs). Essentially we use 3' UTR
sequence similarity in place of population cryptic relatedness in the GWAS
problem. Compared to similar methods such as miReduce, Sylamer and cWords, we
found that MixMir performed better at discovering true miRNA motifs in three
mouse Dicer-knockout experiments from different tissues, two of which were
collected by our group. We confirmed these results on protein and mRNA expression
data obtained from miRNA transfection experiments in human cell lines. MixMir can
be freely downloaded from https://github.com/ldiao/MixMir.

© The Author(s) 2014. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gku672 
PMCID: PMC4176157
PMID: 25081207  [PubMed - indexed for MEDLINE]


1217. BMC Bioinformatics. 2014;15 Suppl 7:S12. doi: 10.1186/1471-2105-15-S7-S12. Epub
2014 May 28.

Variant Tool Chest: an improved tool to analyze and manipulate variant call
format (VCF) files.

Ebbert MT, Wadsworth ME, Boehme KL, Hoyt KL, Sharp AR, O'Fallon BD, Kauwe JS,
Ridge PG.

BACKGROUND: Since the advent of next-generation sequencing many previously
untestable hypotheses have been realized. Next-generation sequencing has been
used for a wide range of studies in diverse fields such as population and medical
genetics, phylogenetics, microbiology, and others. However, this novel technology
has created unanticipated challenges such as the large numbers of genetic
variants. Each caucasian genome has more than four million single nucleotide
variants, insertions and deletions, copy number variants, and structural
variants. Several formats have been suggested for storing these variants;
however, the variant call format (VCF) has become the community standard.
RESULTS: We developed new software called the Variant Tool Chest (VTC) to provide
much needed tools to work with VCF files. VTC provides a variety of tools for
manipulating, comparing, and analyzing VCF files beyond the functionality of
existing tools. In addition, VTC was written to be easily extended with new
tools.
CONCLUSIONS: Variant Tool Chest brings new and important functionality that
complements and integrates well with existing software. VTC is available at
https://github.com/mebbert/VariantToolChest.

DOI: 10.1186/1471-2105-15-S7-S12 
PMCID: PMC4110736
PMID: 25080132  [PubMed - indexed for MEDLINE]


1218. PLoS Comput Biol. 2014 Jul 31;10(7):e1003750. doi: 10.1371/journal.pcbi.1003750. 
eCollection 2014.

A real-time all-atom structural search engine for proteins.

Gonzalez G(1), Hannigan B(1), DeGrado WF(1).

Author information: 
(1)Cardiovascular Research Institute, University of California, San Francisco,
San Francisco, California, United States of America.

Protein designers use a wide variety of software tools for de novo design, yet
their repertoire still lacks a fast and interactive all-atom search engine. To
solve this, we have built the Suns program: a real-time, atomic search engine
integrated into the PyMOL molecular visualization system. Users build
atomic-level structural search queries within PyMOL and receive a stream of
search results aligned to their query within a few seconds. This instant feedback
cycle enables a new "designability"-inspired approach to protein design where the
designer searches for and interactively incorporates native-like fragments from
proven protein structures. We demonstrate the use of Suns to interactively build 
protein motifs, tertiary interactions, and to identify scaffolds compatible with 
hot-spot residues. The official web site and installer are located at
http://www.degradolab.org/suns/ and the source code is hosted at
https://github.com/godotgildor/Suns (PyMOL plugin, BSD license),
https://github.com/Gabriel439/suns-cmd (command line client, BSD license), and
https://github.com/Gabriel439/suns-search (search engine server, GPLv2 license).

DOI: 10.1371/journal.pcbi.1003750 
PMCID: PMC4117414
PMID: 25079944  [PubMed - indexed for MEDLINE]


1219. F1000Res. 2014 Feb 13;3:55. doi: 10.12688/f1000research.3-55.v1. eCollection
2014.

BioJS: an open source standard for biological visualisation - its status in 2014.

Corpas M(1), Jimenez R(2), Carbon SJ(3), García A(4), Garcia L(2), Goldberg T(5),
Gomez J(2), Kalderimis A(6), Lewis SE(3), Mulvany I(7), Pawlik A(8), Rowland
F(2), Salazar G(9), Schreiber F(10), Sillitoe I(11), Spooner WH(12), Thanki
AS(1), Villaveces JM(13), Yachdav G(14), Hermjakob H(2).

Author information: 
(1)The Genome Analysis Centre, Norwich Research Park, Norwich, NR4 7UH, UK.
(2)European Bioinformatics Institute EMBL-EBI, Hinxton, CB10 1SD, UK. (3)Lawrence
Berkeley National Laboratory, Berkeley, CA, 94720, USA. (4)School of Library and 
Information Science, Florida State University, Tallahassee, FL, USA. (5)TUM,
Department of Informatics, Bioinformatics & Computational Biology, 5748 Garching/
Munich, Germany. (6)Department of Genetics and Cambridge Systems Biology Centre, 
Cambridge University, Cambridge, CB2 3EH, UK. (7)eLife, Cambridge, CB2 1JP, UK.
(8)Faculty of Mathematics, Computing and Technology, Open University, UK, Milton 
Keynes, MK7 6AA, UK. (9)Computational Biology Group, University of Cape Town,
Cape Town, South Africa. (10)European Bioinformatics Institute EMBL-EBI, Hinxton,
CB10 1SD, UK ; The Wellcome Trust Sanger Institute, Hinxton, Cambridge, CB10 1SD,
UK. (11)Biomolecular Structure and Modelling Group Department of Biochemistry,
University College London, London, UK. (12)Eagle Genomics Ltd, Cambridge, CB22
3AT, UK. (13)Max Planck Institute of Biochemistry, Am Klopferspitz 18, 82152,
Germany. (14)TUM, Department of Informatics, Bioinformatics & Computational
Biology, 5748 Garching/ Munich, Germany ; TUM Graduate School of Information
Science in Health (GSISH), 85748 Garching/Munich, Germany ; Biosof LLC, New York,
NY, 10001, USA.

BioJS is a community-based standard and repository of functional components to
represent biological information on the web. The development of BioJS has been
prompted by the growing need for bioinformatics visualisation tools to be easily 
shared, reused and discovered. Its modular architecture makes it easy for users
to find a specific functionality without needing to know how it has been built,
while components can be extended or created for implementing new functionality.
The BioJS community of developers currently provides a range of functionality
that is open access and freely available. A registry has been set up that
categorises and provides installation instructions and testing facilities at
http://www.ebi.ac.uk/tools/biojs/. The source code for all components is
available for ready use at https://github.com/biojs/biojs.

DOI: 10.12688/f1000research.3-55.v1 
PMCID: PMC4103492
PMID: 25075290  [PubMed]


1220. F1000Res. 2014 Feb 13;3:50. doi: 10.12688/f1000research.3-50.v1. eCollection
2014.

PPI layouts: BioJS components for the display of Protein-Protein Interactions.

Salazar GA(1), Meintjes A(1), Mulder N(1).

Author information: 
(1)Computational Biology Group, University of Cape Town, Cape Town, South Africa.

SUMMARY: We present two web-based components for the display of Protein-Protein
Interaction networks using different self-organizing layout methods:
force-directed and circular. These components conform to the BioJS standard and
can be rendered in an HTML5-compliant browser without the need for third-party
plugins. We provide examples of interaction networks and how the components can
be used to visualize them, and refer to a more complex tool that uses these
components.
AVAILABILITY: http://github.com/biojs/biojs;
http://dx.doi.org/10.5281/zenodo.7753.

DOI: 10.12688/f1000research.3-50.v1 
PMCID: PMC4103490
PMID: 25075288  [PubMed]


1221. F1000Res. 2014 Feb 13;3:44. doi: 10.12688/f1000research.3-44.v1. eCollection
2014.

PsicquicGraph, a BioJS component to visualize molecular interactions from
PSICQUIC servers.

Villaveces JM(1), Jimenez RC(2), Habermann BH(1).

Author information: 
(1)Max Planck Institute of Biochemistry, Am Klopferspitz 18, 82152, Germany.
(2)European Bioinformatics Institute, Wellcome Trust Genome Campus, Hinxton, CB10
1SD, UK.

SUMMARY: Protein interaction networks have become an essential tool in
large-scale data analysis, integration, and the visualization of high-throughput 
data in the context of complex cellular networks. Many individual databases are
available that provide information on binary interactions of proteins and small
molecules. Community efforts such as PSICQUIC aim to unify and standardize
information emanating from these public databases. Here we introduce
PsicquicGraph, an open-source, web-based visualization component for molecular
interactions from PSIQUIC services.
AVAILABILITY: PsicquicGraph is freely available at the BioJS Registry for
download and enhancement. Instructions on how to use the tool are available here 
http://goo.gl/kDaIgZ and the source code can be found at
http://github.com/biojs/biojs and DOI: 10.5281/zenodo.7709.

DOI: 10.12688/f1000research.3-44.v1 
PMCID: PMC4097353
PMID: 25075287  [PubMed]


1222. Bioinformatics. 2014 Nov 1;30(21):3139-41. doi: 10.1093/bioinformatics/btu501.
Epub 2014 Jul 28.

NetPathMiner: R/Bioconductor package for network path mining through gene
expression.

Mohamed A(1), Hancock T(2), Nguyen CH(1), Mamitsuka H(1).

Author information: 
(1)Bioinformatics Center, Institute for Chemical Research, Kyoto University,
Gokasho, Uji, Japan and Department of Computing and Information Systems, The
University of Melbourne, Victoria, Australia. (2)Bioinformatics Center, Institute
for Chemical Research, Kyoto University, Gokasho, Uji, Japan and Department of
Computing and Information Systems, The University of Melbourne, Victoria,
Australia Bioinformatics Center, Institute for Chemical Research, Kyoto
University, Gokasho, Uji, Japan and Department of Computing and Information
Systems, The University of Melbourne, Victoria, Australia.

NetPathMiner is a general framework for mining, from genome-scale networks, paths
that are related to specific experimental conditions. NetPathMiner interfaces
with various input formats including KGML, SBML and BioPAX files and allows for
manipulation of networks in three different forms: metabolic, reaction and gene
representations. NetPathMiner ranks the obtained paths and applies Markov
model-based clustering and classification methods to the ranked paths for easy
interpretation. NetPathMiner also provides static and interactive visualizations 
of networks and paths to aid manual investigation.AVAILABILITY: The package is
available through Bioconductor and from Github at
http://github.com/ahmohamed/NetPathMiner.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu501 
PMCID: PMC4609018
PMID: 25075120  [PubMed - indexed for MEDLINE]


1223. Bioinformatics. 2014 Nov 1;30(21):3125-7. doi: 10.1093/bioinformatics/btu505.
Epub 2014 Jul 29.

Circleator: flexible circular visualization of genome-associated data with
BioPerl and SVG.

Crabtree J(1), Agrawal S(1), Mahurkar A(1), Myers GS(2), Rasko DA(3), White O(3).

Author information: 
(1)Institute for Genome Sciences, University of Maryland School of Medicine,
Baltimore, MD 21201, Department of Microbiology and Immunology, University of
Maryland School of Medicine, Baltimore, MD 21201, i3 Institute, University of
Technology, Sydney, PO Box 123 Broadway NSW 2007, Australia, Department of
Microbial Pathogenesis, University of Maryland Dental School, Baltimore, MD
21201, Center for Health-Related Informatics and Bioimaging, University of
Maryland, College Park, MD 20740 and Department of Epidemiology and Public
Health, University of Maryland School of Medicine, Baltimore, MD 21201, USA.
(2)Institute for Genome Sciences, University of Maryland School of Medicine,
Baltimore, MD 21201, Department of Microbiology and Immunology, University of
Maryland School of Medicine, Baltimore, MD 21201, i3 Institute, University of
Technology, Sydney, PO Box 123 Broadway NSW 2007, Australia, Department of
Microbial Pathogenesis, University of Maryland Dental School, Baltimore, MD
21201, Center for Health-Related Informatics and Bioimaging, University of
Maryland, College Park, MD 20740 and Department of Epidemiology and Public
Health, University of Maryland School of Medicine, Baltimore, MD 21201, USA
Institute for Genome Sciences, University of Maryland School of Medicine,
Baltimore, MD 21201, Department of Microbiology and Immunology, University of
Maryland School of Medicine, Baltimore, MD 21201, i3 Institute, University of
Technology, Sydney, PO Box 123 Broadway NSW 2007, Australia, Department of
Microbial Pathogenesis, University of Maryland Dental School, Baltimore, MD
21201, Center for Health-Related Informatics and Bioimaging, University of
Maryland, College Park, MD 20740 and Department of Epidemiology and Public
Health, University of Maryland School of Medicine, Baltimore, MD 21201, USA
Institute for Genome Sciences, University of Maryland School of Medicine,
Baltimore, MD 21201, Department of Microbiology and Immunology, University of
Maryland School of Medicine, Baltimore, MD 21201, i3 Institute, University of
Technology, Sydney, PO Box 123 Broadway NSW 2007, Australia, Department of
Microbial Pathogenesis, University of Maryland Dental School, Baltimore, MD
21201, Center for Health-Related Informatics and Bioimaging, University of
Maryland, College Park, MD 20740 and Department of Epidemiology and Public
Health, University of Maryland School of Medicine, Baltimore, MD 21201, USA
Institute for Genome Sciences, University of Maryland School of Medicine,
Baltimore, MD 21201, Department of Microbiology and Immunology, University of
Maryland School of Medicine (3)Institute for Genome Sciences, University of
Maryland School of Medicine, Baltimore, MD 21201, Department of Microbiology and 
Immunology, University of Maryland School of Medicine, Baltimore, MD 21201, i3
Institute, University of Technology, Sydney, PO Box 123 Broadway NSW 2007,
Australia, Department of Microbial Pathogenesis, University of Maryland Dental
School, Baltimore, MD 21201, Center for Health-Related Informatics and
Bioimaging, University of Maryland, College Park, MD 20740 and Department of
Epidemiology and Public Health, University of Maryland School of Medicine,
Baltimore, MD 21201, USA Institute for Genome Sciences, University of Maryland
School of Medicine, Baltimore, MD 21201, Department of Microbiology and
Immunology, University of Maryland School of Medicine, Baltimore, MD 21201, i3
Institute, University of Technology, Sydney, PO Box 123 Broadway NSW 2007,
Australia, Department of Microbial Pathogenesis, University of Maryland Dental
School, Baltimore, MD 21201, Center for Health-Related Informatics and
Bioimaging, University of Maryland, College Park, MD 20740 and Department of
Epidemiology and Public Health, University of Maryland School of Medicine,
Baltimore, MD 21201, USA Institute for Genome Sciences, University of Maryland
School of Medicine, Baltimore, MD 21201, Department of Microbiology and
Immunology, University of Maryland School of Medicine, Baltimore, MD 21201, i3
Institute, University of Technology, Sydney, PO Box 123 Broadway NSW 2007,
Australia, Department of Microbial Pathogenesis, University of Maryland Dental
School, Baltimore, MD 21201, Center for Health-Related Informatics and
Bioimaging, University of Maryland, College Park, MD 20740 and Department of
Epidemiology and Public Health, University of Maryland School of Medicine,
Baltimore, MD 21201, USA.

SUMMARY: Circleator is a Perl application that generates circular figures of
genome-associated data. It leverages BioPerl to support standard annotation and
sequence file formats and produces publication-quality SVG output. It is designed
to be both flexible and easy to use. It includes a library of circular track
types and predefined configuration files for common use-cases, including. (i)
visualizing gene annotation and DNA sequence data from a GenBank flat file, (ii) 
displaying patterns of gene conservation in related microbial strains, (iii)
showing Single Nucleotide Polymorphisms (SNPs) and indels relative to a reference
genome and gene set and (iv) viewing RNA-Seq plots.
AVAILABILITY AND IMPLEMENTATION: Circleator is freely available under the
Artistic License 2.0 from http://jonathancrabtree.github.io/Circleator/ and is
integrated with the CloVR cloud-based sequence analysis Virtual Machine (VM),
which can be downloaded from http://clovr.org or run on Amazon EC2.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu505 
PMCID: PMC4201160
PMID: 25075113  [PubMed - indexed for MEDLINE]


1224. BMC Bioinformatics. 2014 Jul 28;15:253. doi: 10.1186/1471-2105-15-253.

Hamiltonian Monte Carlo methods for efficient parameter estimation in steady
state dynamical systems.

Kramer A(1), Calderhead B, Radde N.

Author information: 
(1)Institute for Systems Theory and Automatic Control, Pfaffenwaldring 9, 70550
Stuttgart, Germany. andrei.kramer@ist.uni-stuttgart.de.

BACKGROUND: Parameter estimation for differential equation models of
intracellular processes is a highly relevant bu challenging task. The available
experimental data do not usually contain enough information to identify all
parameters uniquely, resulting in ill-posed estimation problems with often highly
correlated parameters. Sampling-based Bayesian statistical approaches are
appropriate for tackling this problem. The samples are typically generated via
Markov chain Monte Carlo, however such methods are computationally expensive and 
their convergence may be slow, especially if there are strong correlations
between parameters. Monte Carlo methods based on Euclidean or Riemannian
Hamiltonian dynamics have been shown to outperform other samplers by making
proposal moves that take the local sensitivities of the system's states into
account and accepting these moves with high probability. However, the high
computational cost involved with calculating the Hamiltonian trajectories
prevents their widespread use for all but the smallest differential equation
models. The further development of efficient sampling algorithms is therefore an 
important step towards improving the statistical analysis of predictive models of
intracellular processes.
RESULTS: We show how state of the art Hamiltonian Monte Carlo methods may be
significantly improved for steady state dynamical models. We present a novel
approach for efficiently calculating the required geometric quantities by
tracking steady states across the Hamiltonian trajectories using a Newton-Raphson
method and employing local sensitivity information. Using our approach, we
compare both Euclidean and Riemannian versions of Hamiltonian Monte Carlo on
three models for intracellular processes with real data and demonstrate at least 
an order of magnitude improvement in the effective sampling speed. We further
demonstrate the wider applicability of our approach to other gradient based MCMC 
methods, such as those based on Langevin diffusions.
CONCLUSION: Our approach is strictly benefitial in all test cases. The Matlab
sources implementing our MCMC methodology is available from
https://github.com/a-kramer/ode_rmhmc.

DOI: 10.1186/1471-2105-15-253 
PMCID: PMC4262080
PMID: 25066046  [PubMed - indexed for MEDLINE]


1225. Bioinformatics. 2014 Nov 1;30(21):3109-14. doi: 10.1093/bioinformatics/btu499.
Epub 2014 Jul 26.

e-Driver: a novel method to identify protein regions driving cancer.

Porta-Pardo E(1), Godzik A(1).

Author information: 
(1)Bioinformatics and Systems Biology Program, Sanford-Burnham Medical Research
Institute, 10901 North Torrey Pines Road, La Jolla, CA 92037, USA.

MOTIVATION: Most approaches used to identify cancer driver genes focus, true to
their name, on entire genes and assume that a gene, treated as one entity, has a 
specific role in cancer. This approach may be correct to describe effects of gene
loss or changes in gene expression; however, mutations may have different
effects, including their relevance to cancer, depending on which region of the
gene they affect. Except for rare and well-known exceptions, there are not enough
data for reliable statistics for individual positions, but an intermediate level 
of analysis, between an individual position and the entire gene, may give us
better statistics than the former and better resolution than the latter approach.
RESULTS: We have developed e-Driver, a method that exploits the internal
distribution of somatic missense mutations between the protein's functional
regions (domains or intrinsically disordered regions) to find those that show a
bias in their mutation rate as compared with other regions of the same protein,
providing evidence of positive selection and suggesting that these proteins may
be actual cancer drivers. We have applied e-Driver to a large cancer genome
dataset from The Cancer Genome Atlas and compared its performance with that of
four other methods, showing that e-Driver identifies novel candidate cancer
drivers and, because of its increased resolution, provides deeper insights into
the potential mechanism of cancer driver genes identified by other methods.
AVAILABILITY AND IMPLEMENTATION: A Perl script with e-Driver and the files to
reproduce the results described here can be downloaded from
https://github.com/eduardporta/e-Driver.git.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu499 
PMCID: PMC4609017
PMID: 25064568  [PubMed - indexed for MEDLINE]


1226. PLoS One. 2014 Jul 25;9(7):e101271. doi: 10.1371/journal.pone.0101271.
eCollection 2014.

These are not the k-mers you are looking for: efficient online k-mer counting
using a probabilistic data structure.

Zhang Q(1), Pell J(1), Canino-Koning R(1), Howe AC(2), Brown CT(3).

Author information: 
(1)Department of Computer Science and Engineering, Michigan State University,
East Lansing, Michigan, United States of America. (2)Department of Microbiology
and Molecular Genetics, Michigan State University, East Lansing, Michigan, United
States of America; Department of Plant, Soil, and Microbial Sciences, Michigan
State University, East Lansing, Michigan, United States of America. (3)Department
of Computer Science and Engineering, Michigan State University, East Lansing,
Michigan, United States of America; Department of Microbiology and Molecular
Genetics, Michigan State University, East Lansing, Michigan, United States of
America.

K-mer abundance analysis is widely used for many purposes in nucleotide sequence 
analysis, including data preprocessing for de novo assembly, repeat detection,
and sequencing coverage estimation. We present the khmer software package for
fast and memory efficient online counting of k-mers in sequencing data sets.
Unlike previous methods based on data structures such as hash tables, suffix
arrays, and trie structures, khmer relies entirely on a simple probabilistic data
structure, a Count-Min Sketch. The Count-Min Sketch permits online updating and
retrieval of k-mer counts in memory which is necessary to support online k-mer
analysis algorithms. On sparse data sets this data structure is considerably more
memory efficient than any exact data structure. In exchange, the use of a
Count-Min Sketch introduces a systematic overcount for k-mers; moreover, only the
counts, and not the k-mers, are stored. Here we analyze the speed, the memory
usage, and the miscount rate of khmer for generating k-mer frequency
distributions and retrieving k-mer counts for individual k-mers. We also compare 
the performance of khmer to several other k-mer counting packages, including
Tallymer, Jellyfish, BFCounter, DSK, KMC, Turtle and KAnalyze. Finally, we
examine the effectiveness of profiling sequencing error, k-mer abundance
trimming, and digital normalization of reads in the context of high khmer false
positive rates. khmer is implemented in C++ wrapped in a Python interface, offers
a tested and robust API, and is freely available under the BSD license at
github.com/ged-lab/khmer.

DOI: 10.1371/journal.pone.0101271 
PMCID: PMC4111482
PMID: 25062443  [PubMed - indexed for MEDLINE]


1227. BMC Res Notes. 2014 Jul 23;7:468. doi: 10.1186/1756-0500-7-468.

SnipViz: a compact and lightweight web site widget for display and dissemination 
of multiple versions of gene and protein sequences.

Jaschob D, Davis TN, Riffle M(1).

Author information: 
(1)Department of Biochemistry, University of Washington, Seattle, UW Box 357350, 
1705 NE Pacific St,, Seattle, WA 98195-7350, USA. mriffle@uw.edu.

BACKGROUND: As high throughput sequencing continues to grow more commonplace, the
need to disseminate the resulting data via web applications continues to grow.
Particularly, there is a need to disseminate multiple versions of related gene
and protein sequences simultaneously--whether they represent alleles present in a
single species, variations of the same gene among different strains, or homologs 
among separate species. Often this is accomplished by displaying all versions of 
the sequence at once in a manner that is not intuitive or space-efficient and
does not facilitate human understanding of the data. Web-based applications
needing to disseminate multiple versions of sequences would benefit from a
drop-in module designed to effectively disseminate these data.
FINDINGS: SnipViz is a client-side software tool designed to disseminate multiple
versions of related gene and protein sequences on web sites. SnipViz has a
space-efficient, interactive, and dynamic interface for navigating, analyzing and
visualizing sequence data. It is written using standard World Wide Web
technologies (HTML, Javascript, and CSS) and is compatible with most web
browsers. SnipViz is designed as a modular client-side web component and may be
incorporated into virtually any web site and be implemented without any
programming.
CONCLUSIONS: SnipViz is a drop-in client-side module for web sites designed to
efficiently visualize and disseminate gene and protein sequences. SnipViz is open
source and is freely available at https://github.com/yeastrc/snipviz.

DOI: 10.1186/1756-0500-7-468 
PMCID: PMC4118779
PMID: 25056180  [PubMed - indexed for MEDLINE]


1228. Bioinformatics. 2014 Nov 1;30(21):3118-9. doi: 10.1093/bioinformatics/btu486.
Epub 2014 Jul 15.

AffyPipe: an open-source pipeline for Affymetrix Axiom genotyping workflow.

Nicolazzi EL(1), Iamartino D(1), Williams JL(1).

Author information: 
(1)Fondazione Parco Tecnologico Padano, Lodi (LO), 26900, Italy.

The Affymetrix Axiom genotyping standard and 'best practice' workflow for Linux
and Mac users consists of three stand-alone executable programs (Affymetrix Power
Tools) and an R package (SNPolisher). Currently, SNP analysis has to be performed
in a step-by-step procedure. Manual intervention and/or programming skills by the
user is required at each intermediate point, as Affymetrix Power Tools programs
do not produce input files for the program next-in-line. An additional problem is
that the output format of genotypes is not compatible with most analysis software
currently available. AffyPipe solves all the above problems, by automating both
standard and 'best practice' workflows for any species genotyped with the Axiom
technology. AffyPipe does not require programming skills and performs all the
steps necessary to obtain a final genotype file. Furthermore, users can directly 
edit SNP probes and export genotypes in PLINK format.AVAILABILITY AND
IMPLEMENTATION: https://github.com/nicolazzie/AffyPipe.git.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu486 
PMCID: PMC4609010
PMID: 25028724  [PubMed - indexed for MEDLINE]


1229. Mol Biol Evol. 2014 Oct;31(10):2824-7. doi: 10.1093/molbev/msu211. Epub 2014 Jul 
10.

selscan: an efficient multithreaded program to perform EHH-based scans for
positive selection.

Szpiech ZA(1), Hernandez RD(2).

Author information: 
(1)Department of Bioengineering and Therapeutic Sciences, University of
California, San Francisco zachary.szpiech@ucsf.edu. (2)Department of
Bioengineering and Therapeutic Sciences, University of California, San Francisco 
Institute for Human Genetics, University of California, San Francisco Institute
for Quantitative Biosciences (QB3), University of California, San Francisco.

Haplotype-based scans to detect natural selection are useful to identify recent
or ongoing positive selection in genomes. As both real and simulated genomic data
sets grow larger, spanning thousands of samples and millions of markers, there is
a need for a fast and efficient implementation of these scans for general use.
Here, we present selscan, an efficient multithreaded application that implements 
Extended Haplotype Homozygosity (EHH), Integrated Haplotype Score (iHS), and
Cross-population EHH (XPEHH). selscan accepts phased genotypes in multiple
formats, including TPED, and performs extremely well on both simulated and real
data and over an order of magnitude faster than existing available
implementations. It calculates iHS on chromosome 22 (22,147 loci) across 204 CEU 
haplotypes in 353 s on one thread (33 s on 16 threads) and calculates XPEHH for
the same data relative to 210 YRI haplotypes in 578 s on one thread (52 s on 16
threads). Source code and binaries (Windows, OSX, and Linux) are available at
https://github.com/szpiech/selscan.

© The Author 2014. Published by Oxford University Press on behalf of the Society 
for Molecular Biology and Evolution.

DOI: 10.1093/molbev/msu211 
PMCID: PMC4166924
PMID: 25015648  [PubMed - indexed for MEDLINE]


1230. Bioinformatics. 2014 Oct 15;30(20):2991-2. doi: 10.1093/bioinformatics/btu429.
Epub 2014 Jul 7.

MCMC_CLIB-an advanced MCMC sampling package for ODE models.

Kramer A(1), Stathopoulos V(1), Girolami M(1), Radde N(1).

Author information: 
(1)Institute for Systems Theory and Automatic Control, University of Stuttgart,
70569 Stuttgart, Germany, Department of Statistical Science, University College, 
London WC1E 6BT, UK and Department of Statistics, University of Warwick, Coventry
CV4 7AL, UK.

SUMMARY: We present a new C implementation of an advanced Markov chain Monte
Carlo (MCMC) method for the sampling of ordinary differential equation (ode)
model parameters. The software mcmc_clib uses the simplified manifold
Metropolis-adjusted Langevin algorithm (SMMALA), which is locally adaptive; it
uses the parameter manifold's geometry (the Fisher information) to make efficient
moves. This adaptation does not diminish with MC length, which is highly
advantageous compared with adaptive Metropolis techniques when the parameters
have large correlations and/or posteriors substantially differ from multivariate 
Gaussians. The software is standalone (not a toolbox), though dependencies
include the GNU scientific library and sundials libraries for ode integration and
sensitivity analysis.
AVAILABILITY AND IMPLEMENTATION: The source code and binary files are freely
available for download at http://a-kramer.github.io/mcmc_clib/. This also
includes example files and data. A detailed documentation, an example model and
user manual are provided with the software.
CONTACT: andrei.kramer@ist.uni-stuttgart.de.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu429 
PMID: 25005749  [PubMed - indexed for MEDLINE]


1231. PLoS One. 2014 Jul 8;9(7):e101704. doi: 10.1371/journal.pone.0101704. eCollection
2014.

Contextual cross-referencing of species names for fiddler crabs (genus Uca): an
experiment in cyber-taxonomy.

Rosenberg MS(1).

Author information: 
(1)School of Life Sciences and Center for Evolutionary Medicine and Informatics, 
The Biodesign Institute, Arizona State University, Tempe, Arizona, United States 
of America.

Cyber-taxonomy of name usage has focused primarily on producing authoritative
lists of names or cross-linking names and data across disparate databases. A
feature missing from much of this work is the recording and analysis of the
context in which a name was used--context which can be critical for understanding
not only what name an author used, but to which currently recognized species they
actually refer. An experiment on recording contextual information associated with
name usage was conducted for the fiddler crabs (genus Uca). Data from
approximately one quarter of all publications that mention fiddler crabs,
including 95% of those published prior to 1924 and 67% of those published prior
to 1976, have currently been recorded in a database. Approaches and difficulties 
in recording and analyzing the context of name use are discussed. These results
are not meant to be a full solution, rather to highlight problems which have not 
been previously investigated and may act as a springboard for broader approaches 
and discussion. Some data on the accessibility of the literature, including in
particular electronic forms of publication, are also presented. The resulting
data has been integrated for general browsing into the website
http://www.fiddlercrab.info; the raw data and code used to construct the website 
is available at https://github.com/msrosenberg/fiddlercrab.info.

DOI: 10.1371/journal.pone.0101704 
PMCID: PMC4086947
PMID: 25004097  [PubMed - indexed for MEDLINE]


1232. PLoS One. 2014 Jul 7;9(7):e101357. doi: 10.1371/journal.pone.0101357. eCollection
2014.

DyCoNet: a Gephi plugin for community detection in dynamic complex networks.

Kauffman J(1), Kittas A(1), Bennett L(2), Tsoka S(1).

Author information: 
(1)Department of Informatics, King's College London, Strand, London, United
Kingdom. (2)Centre for Process Systems Engineering, Department of Chemical
Engineering, University College London, Torrington Place, London, United Kingdom.

Community structure detection has proven to be important in revealing the
underlying organisation of complex networks. While most current analyses focus on
static networks, the detection of communities in dynamic data is both challenging
and timely. An analysis and visualisation procedure for dynamic networks is
presented here, which identifies communities and sub-communities that persist
across multiple network snapshots. An existing method for community detection in 
dynamic networks is adapted, extended, and implemented. We demonstrate the
applicability of this method to detect communities in networks where individuals 
tend not to change their community affiliation very frequently. When stability of
communities cannot be assumed, we show that the sub-community model may be a
better alternative. This is illustrated through test cases of social and
biological networks. A plugin for Gephi, an open-source software program used for
graph visualisation and manipulation, named "DyCoNet", was created to execute the
algorithm and is freely available from https://github.com/juliemkauffman/DyCoNet.

DOI: 10.1371/journal.pone.0101357 
PMCID: PMC4084810
PMID: 25000497  [PubMed - indexed for MEDLINE]


1233. Bioinformatics. 2015 Feb 15;31(4):453-61. doi: 10.1093/bioinformatics/btu407.
Epub 2014 Jul 3.

Inter-species prediction of protein phosphorylation in the sbv IMPROVER species
translation challenge.

Biehl M(1), Sadowski P(1), Bhanot G(1), Bilal E(1), Dayarian A(1), Meyer P(1),
Norel R(1), Rhrissorrakrai K(1), Zeller MD(1), Hormoz S(1).

Author information: 
(1)Johann Bernoulli Institute for Mathematics and Computer Science, University of
Groningen, 9700 AK Groningen, The Netherlands, University of California, Irvine, 
CA 92617, Department of Physics and Department of Molecular Biology and
Biochemistry, Busch Campus, Rutgers University, Piscataway, NJ 08854, IBM T.J.
Watson Research Center, Computational Biology, Yorktown Heights, NY 10598, Kavli 
Institute for Theoretical Physics, University of California, Santa Barbara, CA
93106, USA.

MOTIVATION: Animal models are widely used in biomedical research for reasons
ranging from practical to ethical. An important issue is whether rodent models
are predictive of human biology. This has been addressed recently in the
framework of a series of challenges designed by the systems biology verification 
for Industrial Methodology for Process Verification in Research (sbv IMPROVER)
initiative. In particular, one of the sub-challenges was devoted to the
prediction of protein phosphorylation responses in human bronchial epithelial
cells, exposed to a number of different chemical stimuli, given the responses in 
rat bronchial epithelial cells. Participating teams were asked to make
inter-species predictions on the basis of available training examples, comprising
transcriptomics and phosphoproteomics data.
RESULTS: Here, the two best performing teams present their data-driven approaches
and computational methods. In addition, post hoc analyses of the datasets and
challenge results were performed by the participants and challenge organizers.
The challenge outcome indicates that successful prediction of protein
phosphorylation status in human based on rat phosphorylation levels is feasible. 
However, within the limitations of the computational tools used, the inclusion of
gene expression data does not improve the prediction quality. The post hoc
analysis of time-specific measurements sheds light on the signaling pathways in
both species.
AVAILABILITY AND IMPLEMENTATION: A detailed description of the dataset, challenge
design and outcome is available at www.sbvimprover.com. The code used by team IGB
is provided under http://github.com/uci-igb/improver2013. Implementations of the 
algorithms applied by team AMG are available at
http://bhanot.biomaps.rutgers.edu/wiki/AMG-sc2-code.zip.
CONTACT: meikelbiehl@gmail.com.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu407 
PMCID: PMC4325536
PMID: 24994890  [PubMed - indexed for MEDLINE]


1234. Bioinformatics. 2014 Oct 15;30(20):2978-80. doi: 10.1093/bioinformatics/btu424.
Epub 2014 Jul 1.

PyWATER: a PyMOL plug-in to find conserved water molecules in proteins by
clustering.

Patel H(1), Grüning BA(1), Günther S(1), Merfort I(1).

Author information: 
(1)Pharmaceutical Biology and Biotechnology, Institute of Pharmaceutical
Sciences, Albert-Ludwigs-University, Stefan-Meier-Str. 19, D-79104 Freiburg,
Germany and Pharmaceutical Bioinformatics, Institute of Pharmaceutical Sciences, 
Albert-Ludwigs-University, Hermann-Herder-Str. 9, D-79104 Freiburg, Germany.

SUMMARY: Conserved water molecules play a crucial role in protein structure,
stabilization of secondary structure, protein activity, flexibility and ligand
binding. Clustering of water molecules in superimposed protein structures,
obtained by X-ray crystallography at high resolution, is an established method to
identify consensus water molecules in all known protein structures of the same
family. PyWATER is an easy-to-use PyMOL plug-in and identifies conserved water
molecules in the protein structure of interest. PyWATER can be installed via the 
user interface of PyMOL. No programming or command-line knowledge is required for
its use.
AVAILABILITY AND IMPLEMENTATION: PyWATER and a tutorial are available at
https://github.com/hiteshpatel379/PyWATER. PyMOL is available at
http://www.pymol.org/ or http://sourceforge.net/projects/pymol/.
CONTACT: stefan.guenther@pharmazie.uni-freiburg.de.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu424 
PMID: 24990608  [PubMed - indexed for MEDLINE]


1235. Source Code Biol Med. 2014 Jun 9;9:12. doi: 10.1186/1751-0473-9-12. eCollection
2014.

Modular and configurable optimal sequence alignment software: Cola.

Zamani N(1), Sundström G(1), Höppner MP(1), Grabherr MG(1).

Author information: 
(1)Science for Life Laboratory, Department of Medical Biochemistry and
Microbiology, Uppsala University, Uppsala, Sweden.

BACKGROUND: The fundamental challenge in optimally aligning homologous sequences 
is to define a scoring scheme that best reflects the underlying biological
processes. Maximising the overall number of matches in the alignment does not
always reflect the patterns by which nucleotides mutate. Efficiently implemented 
algorithms that can be parameterised to accommodate more complex non-linear
scoring schemes are thus desirable.
RESULTS: We present Cola, alignment software that implements different optimal
alignment algorithms, also allowing for scoring contiguous matches of nucleotides
in a nonlinear manner. The latter places more emphasis on short, highly conserved
motifs, and less on the surrounding nucleotides, which can be more diverged. To
illustrate the differences, we report results from aligning 14,100 sequences from
3' untranslated regions of human genes to 25 of their mammalian counterparts,
where we found that a nonlinear scoring scheme is more consistent than a linear
scheme in detecting short, conserved motifs.
CONCLUSIONS: Cola is freely available under LPGL from
https://github.com/nedaz/cola.

DOI: 10.1186/1751-0473-9-12 
PMCID: PMC4064277
PMID: 24976859  [PubMed]


1236. BMC Bioinformatics. 2014 Jun 30;15:227. doi: 10.1186/1471-2105-15-227.

A universal genomic coordinate translator for comparative genomics.

Zamani N(1), Sundström G, Meadows JR, Höppner MP, Dainat J, Lantz H, Haas BJ,
Grabherr MG.

Author information: 
(1)Science for Life Laboratory, Department of Medical Biochemistry and
Microbiology, Uppsala University, Uppsala, Sweden. neda.zamani@imbim.uu.se.

BACKGROUND: Genomic duplications constitute major events in the evolution of
species, allowing paralogous copies of genes to take on fine-tuned biological
roles. Unambiguously identifying the orthology relationship between copies across
multiple genomes can be resolved by synteny, i.e. the conserved order of genomic 
sequences. However, a comprehensive analysis of duplication events and their
contributions to evolution would require all-to-all genome alignments, which
increases at N2 with the number of available genomes, N.
RESULTS: Here, we introduce Kraken, software that omits the all-to-all
requirement by recursively traversing a graph of pairwise alignments and
dynamically re-computing orthology. Kraken scales linearly with the number of
targeted genomes, N, which allows for including large numbers of genomes in
analyses. We first evaluated the method on the set of 12 Drosophila genomes,
finding that orthologous correspondence computed indirectly through a graph of
multiple synteny maps comes at minimal cost in terms of sensitivity, but reduces 
overall computational runtime by an order of magnitude. We then used the method
on three well-annotated mammalian genomes, human, mouse, and rat, and show that
up to 93% of protein coding transcripts have unambiguous pairwise orthologous
relationships across the genomes. On a nucleotide level, 70 to 83% of exons match
exactly at both splice junctions, and up to 97% on at least one junction. We last
applied Kraken to an RNA-sequencing dataset from multiple vertebrates and diverse
tissues, where we confirmed that brain-specific gene family members, i.e.
one-to-many or many-to-many homologs, are more highly correlated across species
than single-copy (i.e. one-to-one homologous) genes. Not limited to protein
coding genes, Kraken also identifies thousands of newly identified transcribed
loci, likely non-coding RNAs that are consistently transcribed in human,
chimpanzee and gorilla, and maintain significant correlation of expression levels
across species.
CONCLUSIONS: Kraken is a computational genome coordinate translator that
facilitates cross-species comparisons, distinguishes orthologs from paralogs, and
does not require costly all-to-all whole genome mappings. Kraken is freely
available under LPGL from http://github.com/nedaz/kraken.

DOI: 10.1186/1471-2105-15-227 
PMCID: PMC4086997
PMID: 24976580  [PubMed - indexed for MEDLINE]


1237. Bioinformatics. 2014 Oct 15;30(20):2962-4. doi: 10.1093/bioinformatics/btu410.
Epub 2014 Jun 28.

bammds: a tool for assessing the ancestry of low-depth whole-genome data using
multidimensional scaling (MDS).

Malaspinas AS(1), Tange O(1), Moreno-Mayar JV(1), Rasmussen M(2), DeGiorgio M(1),
Wang Y(2), Valdiosera CE(2), Politis G(2), Willerslev E(1), Nielsen R(2).

Author information: 
(1)Centre for GeoGenetics, Natural History Museum of Denmark, University of
Copenhagen, 1350 Copenhagen K, Denmark, Department of Genetics, Stanford
University School of Medicine, Stanford, CA 94305, Department of Biology,
Pennsylvania State University, Wartik Laboratory, University Park, PA 16802,
Centre for Theoretical Evolutionary Genomics, Departments of Integrative Biology 
and Statistics, University of California, Berkeley, CA 94720-3140, Ancestry.com
DNA LLC, San Francisco, CA 94107, Department of Archaeology, Environment and
Community Planning Faculty of Humanities and Social Sciences, La Trobe
University, Melbourne, VIC 3086, Australia, INCUAPA-CONICET, Universidad del
Centro de la Provincia de Buenos Aires, 7600 Olavarría, Argentina and Facultad de
Ciencias Naturales y Museo de La Plata, 1900 La Plata, Argentina. (2)Centre for
GeoGenetics, Natural History Museum of Denmark, University of Copenhagen, 1350
Copenhagen K, Denmark, Department of Genetics, Stanford University School of
Medicine, Stanford, CA 94305, Department of Biology, Pennsylvania State
University, Wartik Laboratory, University Park, PA 16802, Centre for Theoretical 
Evolutionary Genomics, Departments of Integrative Biology and Statistics,
University of California, Berkeley, CA 94720-3140, Ancestry.com DNA LLC, San
Francisco, CA 94107, Department of Archaeology, Environment and Community
Planning Faculty of Humanities and Social Sciences, La Trobe University,
Melbourne, VIC 3086, Australia, INCUAPA-CONICET, Universidad del Centro de la
Provincia de Buenos Aires, 7600 Olavarría, Argentina and Facultad de Ciencias
Naturales y Museo de La Plata, 1900 La Plata, Argentina Centre for GeoGenetics,
Natural History Museum of Denmark, University of Copenhagen, 1350 Copenhagen K,
Denmark, Department of Genetics, Stanford University School of Medicine,
Stanford, CA 94305, Department of Biology, Pennsylvania State University, Wartik 
Laboratory, University Park, PA 16802, Centre for Theoretical Evolutionary
Genomics, Departments of Integrative Biology and Statistics, University of
California, Berkeley, CA 94720-3140, Ancestry.com DNA LLC, San Francisco, CA
94107, Department of Archaeology, Environment and Community Planning Faculty of
Humanities and Social Sciences, La Trobe University, Melbourne, VIC 3086,
Australia, INCUAPA-CONICET, Universidad del Centro de la Provincia de Buenos
Aires, 7600 Olavarría, Argentina and Facultad de Ciencias Naturales y Museo de La
Plata, 1900 La Plata, Argentina.

SUMMARY: We present bammds, a practical tool that allows visualization of samples
sequenced by second-generation sequencing when compared with a reference panel of
individuals (usually genotypes) using a multidimensional scaling algorithm. Our
tool is aimed at determining the ancestry of unknown samples-typical of ancient
DNA data-particularly when only low amounts of data are available for those
samples.
AVAILABILITY AND IMPLEMENTATION: The software package is available under GNU
General Public License v3 and is freely available together with test datasets
https://savannah.nongnu.org/projects/bammds/. It is using R
(http://www.r-project.org/), parallel (http://www.gnu.org/software/parallel/),
samtools (https://github.com/samtools/samtools).
CONTACT: bammds-users@nongnu.org
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu410 
PMCID: PMC4184259
PMID: 24974206  [PubMed - indexed for MEDLINE]


1238. Bioinformatics. 2014 Oct 15;30(20):2843-51. doi: 10.1093/bioinformatics/btu356.
Epub 2014 Jun 27.

Toward better understanding of artifacts in variant calling from high-coverage
samples.

Li H(1).

Author information: 
(1)Medical Population Genetics Program, Broad Institute of Harvard and MIT,
Cambridge, MA 02142, USA.

MOTIVATION: Whole-genome high-coverage sequencing has been widely used for
personal and cancer genomics as well as in various research areas. However, in
the lack of an unbiased whole-genome truth set, the global error rate of variant 
calls and the leading causal artifacts still remain unclear even given the great 
efforts in the evaluation of variant calling methods.
RESULTS: We made 10 single nucleotide polymorphism and INDEL call sets with two
read mappers and five variant callers, both on a haploid human genome and a
diploid genome at a similar coverage. By investigating false heterozygous calls
in the haploid genome, we identified the erroneous realignment in low-complexity 
regions and the incomplete reference genome with respect to the sample as the two
major sources of errors, which press for continued improvements in these two
areas. We estimated that the error rate of raw genotype calls is as high as 1 in 
10-15 kb, but the error rate of post-filtered calls is reduced to 1 in 100-200 kb
without significant compromise on the sensitivity.
AVAILABILITY AND IMPLEMENTATION: BWA-MEM alignment and raw variant calls are
available at http://bit.ly/1g8XqRt scripts and miscellaneous data at
https://github.com/lh3/varcmp.
CONTACT: hengli@broadinstitute.org
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu356 
PMCID: PMC4271055
PMID: 24974202  [PubMed - indexed for MEDLINE]


1239. Genome Biol. 2014 Jun 26;15(6):R84. doi: 10.1186/gb-2014-15-6-r84.

LUMPY: a probabilistic framework for structural variant discovery.

Layer RM, Chiang C, Quinlan AR, Hall IM.

Comprehensive discovery of structural variation (SV) from whole genome sequencing
data requires multiple detection signals including read-pair, split-read,
read-depth and prior knowledge. Owing to technical challenges, extant SV
discovery algorithms either use one signal in isolation, or at best use two
sequentially. We present LUMPY, a novel SV discovery framework that naturally
integrates multiple SV signals jointly across multiple samples. We show that
LUMPY yields improved sensitivity, especially when SV signal is reduced owing to 
either low coverage data or low intra-sample variant allele frequency. We also
report a set of 4,564 validated breakpoints from the NA12878 human genome.
https://github.com/arq5x/lumpy-sv.

DOI: 10.1186/gb-2014-15-6-r84 
PMCID: PMC4197822
PMID: 24970577  [PubMed - indexed for MEDLINE]


1240. Bioinformatics. 2014 Oct;30(19):2796-801. doi: 10.1093/bioinformatics/btu387.
Epub 2014 Jun 20.

BEETL-fastq: a searchable compressed archive for DNA reads.

Janin L(1), Schulz-Trieglaff O(1), Cox AJ(1).

Author information: 
(1)Computational Biology Group, Illumina Cambridge Ltd., Little Chesterford,
Essex CB10 1XL, UK.

MOTIVATION: FASTQ is a standard file format for DNA sequencing data, which stores
both nucleotides and quality scores. A typical sequencing study can easily
generate hundreds of gigabytes of FASTQ files, while public archives such as ENA 
and NCBI and large international collaborations such as the Cancer Genome Atlas
can accumulate many terabytes of data in this format. Compression tools such as
gzip are often used to reduce the storage burden but have the disadvantage that
the data must be decompressed before they can be used. Here, we present
BEETL-fastq, a tool that not only compresses FASTQ-formatted DNA reads more
compactly than gzip but also permits rapid search for k-mer queries within the
archived sequences. Importantly, the full FASTQ record of each matching read or
read pair is returned, allowing the search results to be piped directly to any of
the many standard tools that accept FASTQ data as input.
RESULTS: We show that 6.6 terabytes of human reads in FASTQ format can be
transformed into 1.7 terabytes of indexed files, from where we can search for 1, 
10, 100, 1000 and a million of 30-mers in 3, 8, 14, 45 and 567 s, respectively,
plus 20 ms per output read. Useful applications of the search capability are
highlighted, including the genotyping of structural variant breakpoints and 'in
silico pull-down' experiments in which only the reads that cover a region of
interest are selectively extracted for the purposes of variant calling or
visualization.
AVAILABILITY AND IMPLEMENTATION: BEETL-fastq is part of the BEETL library,
available as a github repository at github.com/BEETL/BEETL.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu387 
PMID: 24950811  [PubMed - indexed for MEDLINE]


1241. Bioinformatics. 2014 Oct;30(19):2802-7. doi: 10.1093/bioinformatics/btu396. Epub 
2014 Jun 19.

PGS: a tool for association study of high-dimensional microRNA expression data
with repeated measures.

Zheng Y(1), Fei Z(1), Zhang W(1), Starren JB(1), Liu L(1), Baccarelli AA(1), Li
Y(1), Hou L(2).

Author information: 
(1)Institute for Public Health and Medicine, Northwestern University Feinberg
School of Medicine, Chicago, IL 60611, Department of Biostatistics, University of
Michigan, Ann Arbor, MI 48109, Institute of Human Genetics, University of
Illinois at Chicago, Chicago, IL 60612, Division of Health and Biomedical
Informatics, Departments of Preventive Medicine and Medical Social Sciences,
Northwestern University Feinberg School of Medicine, Chicago, IL 60611,
Department of Preventive Medicine, Northwestern University Feinberg School of
Medicine, Chicago, IL 60611, Department of Environmental Health, Harvard School
of Public Health, Boston, MA 02115 and The Robert H. Lurie Comprehensive Cancer
Center, Northwestern University Feinberg School of Medicine, Chicago, IL 60611,
USA. (2)Institute for Public Health and Medicine, Northwestern University
Feinberg School of Medicine, Chicago, IL 60611, Department of Biostatistics,
University of Michigan, Ann Arbor, MI 48109, Institute of Human Genetics,
University of Illinois at Chicago, Chicago, IL 60612, Division of Health and
Biomedical Informatics, Departments of Preventive Medicine and Medical Social
Sciences, Northwestern University Feinberg School of Medicine, Chicago, IL 60611,
Department of Preventive Medicine, Northwestern University Feinberg School of
Medicine, Chicago, IL 60611, Department of Environmental Health, Harvard School
of Public Health, Boston, MA 02115 and The Robert H. Lurie Comprehensive Cancer
Center, Northwestern University Feinberg School of Medicine, Chicago, IL 60611,
USA Institute for Public Health and Medicine, Northwestern University Feinberg
School of Medicine, Chicago, IL 60611, Department of Biostatistics, University of
Michigan, Ann Arbor, MI 48109, Institute of Human Genetics, University of
Illinois at Chicago, Chicago, IL 60612, Division of Health and Biomedical
Informatics, Departments of Preventive Medicine and Medical Social Sciences,
Northwestern University Feinberg School of Medicine, Chicago, IL 60611,
Department of Preventive Medicine, Northwestern University Feinberg School of
Medicine, Chicago, IL 60611, Department of Environmental Health, Harvard School
of Public Health, Boston, MA 02115 and The Robert H. Lurie Comprehensive Cancer
Center, Northwestern University Feinberg School of Medicine, Chicago, IL 60611,
USA.

MOTIVATION: MicroRNAs (miRNAs) are short single-stranded non-coding molecules
that usually function as negative regulators to silence or suppress gene
expression. Owning to the dynamic nature of miRNA and reduced microarray and
sequencing costs, a growing number of researchers are now measuring
high-dimensional miRNA expression data using repeated or multiple measures in
which each individual has more than one sample collected and measured over time. 
However, the commonly used univariate association testing or the site-by-site
(SBS) testing may underutilize the longitudinal feature of the data, leading to
underpowered results and less biologically meaningful results.
RESULTS: We propose a penalized regression model incorporating grid search method
(PGS), for analyzing associations of high-dimensional miRNA expression data with 
repeated measures. The development of this analytical framework was motivated by 
a real-world miRNA dataset. Comparisons between PGS and the SBS testing revealed 
that PGS provided smaller phenotype prediction errors and higher enrichment of
phenotype-related biological pathways than the SBS testing. Our extensive
simulations showed that PGS provided more accurate estimates and higher
sensitivity than the SBS testing with comparable specificities.
AVAILABILITY AND IMPLEMENTATION: R source code for PGS algorithm, implementation 
example and simulation study are available for download at
https://github.com/feizhe/PGS.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu396 
PMCID: PMC4173025
PMID: 24947752  [PubMed - indexed for MEDLINE]


1242. Bioinformatics. 2014 Oct;30(19):2820-1. doi: 10.1093/bioinformatics/btu394. Epub 
2014 Jun 17.

DAFGA: diversity analysis of functional gene amplicons.

Kim Y(1), Liesack W(1).

Author information: 
(1)Department of Biogeochemistry, Max Planck Institute for Terrestrial
Microbiology. 35043 Marburg, Germany.

SUMMARY: Diversity analysis of functional marker genes provides physiological
insights into microbial guilds that perform an ecologically relevant process.
However, it is challenging to group functional gene sequences to valid taxonomic 
units, primarily because of differences in the evolutionary rates of individual
genes and possible horizontal gene transfer events. We developed a python script 
package named DAFGA, which estimates the evolutionary rate of a particular
functional gene in a standardized manner by relating its sequence divergence to
that of the 16S rRNA gene. As a result, DAFGA provides gene-specific parameter
sets for operational taxonomic unit clustering and taxonomic assignment at
desired rank, and it can be implemented into the diversity measurements offered
by QIIME.
AVAILABILITY AND IMPLEMENTATION: DAFGA is freely available with a manual and test
data from https://github.com/outbig/DAFGA.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu394 
PMID: 24939150  [PubMed - indexed for MEDLINE]


1243. Bioinformatics. 2014 Jun 15;30(12):i319-i328. doi: 10.1093/bioinformatics/btu291.

AlignGraph: algorithm for secondary de novo genome assembly guided by closely
related references.

Bao E(1), Jiang T(1), Girke T(1).

Author information: 
(1)Department of Computer Science and Engineering and Department of Botany and
Plant Sciences, University of California, Riverside, CA 92521, USA.

MOTIVATION: De novo assemblies of genomes remain one of the most challenging
applications in next-generation sequencing. Usually, their results are incomplete
and fragmented into hundreds of contigs. Repeats in genomes and sequencing errors
are the main reasons for these complications. With the rapidly growing number of 
sequenced genomes, it is now feasible to improve assemblies by guiding them with 
genomes from related species.
RESULTS: Here we introduce AlignGraph, an algorithm for extending and joining de 
novo-assembled contigs or scaffolds guided by closely related reference genomes. 
It aligns paired-end (PE) reads and preassembled contigs or scaffolds to a close 
reference. From the obtained alignments, it builds a novel data structure, called
the PE multipositional de Bruijn graph. The incorporated positional information
from the alignments and PE reads allows us to extend the initial assemblies,
while avoiding incorrect extensions and early terminations. In our performance
tests, AlignGraph was able to substantially improve the contigs and scaffolds
from several assemblers. For instance, 28.7-62.3% of the contigs of Arabidopsis
thaliana and human could be extended, resulting in improvements of common
assembly metrics, such as an increase of the N50 of the extendable contigs by
89.9-94.5% and 80.3-165.8%, respectively. In another test, AlignGraph was able to
improve the assembly of a published genome (Arabidopsis strain Landsberg) by
increasing the N50 of its extendable scaffolds by 86.6%. These results
demonstrate AlignGraph's efficiency in improving genome assemblies by taking
advantage of closely related references.
AVAILABILITY AND IMPLEMENTATION: The AlignGraph software can be downloaded for
free from this site: https://github.com/baoe/AlignGraph.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu291 
PMCID: PMC4058956
PMID: 24932000  [PubMed - indexed for MEDLINE]


1244. Bioinformatics. 2014 Jun 15;30(12):i302-9. doi: 10.1093/bioinformatics/btu280.

Ragout-a reference-assisted assembly tool for bacterial genomes.

Kolmogorov M(1), Raney B(2), Paten B(2), Pham S(2).

Author information: 
(1)St. Petersburg University of the Russian Academy of Sciences, Bioinformatics
Institute, St. Petersburg, Russia, UCSC, 1156 High Street, Santa Cruz, CA and
Department of Computer Science and Engineering, UCSD, 9500 Gilman Drive, La
Jolla, CA, USASt. Petersburg University of the Russian Academy of Sciences,
Bioinformatics Institute, St. Petersburg, Russia, UCSC, 1156 High Street, Santa
Cruz, CA and Department of Computer Science and Engineering, UCSD, 9500 Gilman
Drive, La Jolla, CA, USA. (2)St. Petersburg University of the Russian Academy of 
Sciences, Bioinformatics Institute, St. Petersburg, Russia, UCSC, 1156 High
Street, Santa Cruz, CA and Department of Computer Science and Engineering, UCSD, 
9500 Gilman Drive, La Jolla, CA, USA.

SUMMARY: Bacterial genomes are simpler than mammalian ones, and yet assembling
the former from the data currently generated by high-throughput short-read
sequencing machines still results in hundreds of contigs. To improve assembly
quality, recent studies have utilized longer Pacific Biosciences (PacBio) reads
or jumping libraries to connect contigs into larger scaffolds or help assemblers 
resolve ambiguities in repetitive regions of the genome. However, their
popularity in contemporary genomic research is still limited by high cost and
error rates. In this work, we explore the possibility of improving assemblies by 
using complete genomes from closely related species/strains. We present Ragout, a
genome rearrangement approach, to address this problem. In contrast with most
reference-guided algorithms, where only one reference genome is used, Ragout uses
multiple references along with the evolutionary relationship among these
references in order to determine the correct order of the contigs. Additionally, 
Ragout uses the assembly graph and multi-scale synteny blocks to reduce assembly 
gaps caused by small contigs from the input assembly. In simulations as well as
real datasets, we believe that for common bacterial species, where many complete 
genome sequences from related strains have been available, the current
high-throughput short-read sequencing paradigm is sufficient to obtain a single
high-quality scaffold for each chromosome.
AVAILABILITY: The Ragout software is freely available at:
https://github.com/fenderglass/Ragout.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu280 
PMCID: PMC4058940
PMID: 24931998  [PubMed - indexed for MEDLINE]


1245. Bioinformatics. 2014 Jun 15;30(12):i246-i254. doi: 10.1093/bioinformatics/btu287.

Gene network inference by probabilistic scoring of relationships from a
factorized model of interactions.

Zitnik M(1), Zupan B(2).

Author information: 
(1)Faculty of Computer and Information Science, University of Ljubljana, SI-1000 
Ljubljana, Slovenia and Department of Molecular and Human Genetics, Baylor
College of Medicine, Houston, TX 77030, USA. (2)Faculty of Computer and
Information Science, University of Ljubljana, SI-1000 Ljubljana, Slovenia and
Department of Molecular and Human Genetics, Baylor College of Medicine, Houston, 
TX 77030, USAFaculty of Computer and Information Science, University of
Ljubljana, SI-1000 Ljubljana, Slovenia and Department of Molecular and Human
Genetics, Baylor College of Medicine, Houston, TX 77030, USA.

MOTIVATION: Epistasis analysis is an essential tool of classical genetics for
inferring the order of function of genes in a common pathway. Typically, it
considers single and double mutant phenotypes and for a pair of genes observes
whether a change in the first gene masks the effects of the mutation in the
second gene. Despite the recent emergence of biotechnology techniques that can
provide gene interaction data on a large, possibly genomic scale, few methods are
available for quantitative epistasis analysis and epistasis-based network
reconstruction.
RESULTS: We here propose a conceptually new probabilistic approach to gene
network inference from quantitative interaction data. The approach is founded on 
epistasis analysis. Its features are joint treatment of the mutant phenotype data
with a factorized model and probabilistic scoring of pairwise gene relationships 
that are inferred from the latent gene representation. The resulting gene network
is assembled from scored pairwise relationships. In an experimental study, we
show that the proposed approach can accurately reconstruct several known pathways
and that it surpasses the accuracy of current approaches.
AVAILABILITY AND IMPLEMENTATION: Source code is available at
http://github.com/biolab/red.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu287 
PMCID: PMC4229904
PMID: 24931990  [PubMed - indexed for MEDLINE]


1246. Bioinformatics. 2014 Jun 15;30(12):i212-8. doi: 10.1093/bioinformatics/btu292.

Probabilistic method for detecting copy number variation in a fetal genome using 
maternal plasma sequencing.

Rampášek L(1), Arbabi A(1), Brudno M(2).

Author information: 
(1)Department of Computer Science, University of Toronto, Toronto M5S 2E4, Centre
for Computational Medicine and Genetics and Genome Biology, Hospital for Sick
Children, Toronto M5G 1L7, Canada. (2)Department of Computer Science, University 
of Toronto, Toronto M5S 2E4, Centre for Computational Medicine and Genetics and
Genome Biology, Hospital for Sick Children, Toronto M5G 1L7, CanadaDepartment of 
Computer Science, University of Toronto, Toronto M5S 2E4, Centre for
Computational Medicine and Genetics and Genome Biology, Hospital for Sick
Children, Toronto M5G 1L7, CanadaDepartment of Computer Science, University of
Toronto, Toronto M5S 2E4, Centre for Computational Medicine and Genetics and
Genome Biology, Hospital for Sick Children, Toronto M5G 1L7, Canada.

MOTIVATION: The past several years have seen the development of methodologies to 
identify genomic variation within a fetus through the non-invasive sequencing of 
maternal blood plasma. These methods are based on the observation that maternal
plasma contains a fraction of DNA (typically 5-15%) originating from the fetus,
and such methodologies have already been used for the detection of
whole-chromosome events (aneuploidies), and to a more limited extent for smaller 
(typically several megabases long) copy number variants (CNVs).
RESULTS: Here we present a probabilistic method for non-invasive analysis of de
novo CNVs in fetal genome based on maternal plasma sequencing. Our novel method
combines three types of information within a unified Hidden Markov Model: the
imbalance of allelic ratios at SNP positions, the use of parental genotypes to
phase nearby SNPs and depth of coverage to better differentiate between various
types of CNVs and improve precision. Our simulation results, based on in silico
introduction of novel CNVs into plasma samples with 13% fetal DNA concentration, 
demonstrate a sensitivity of 90% for CNVs >400 kb (with 13 calls in an unaffected
genome), and 40% for 50-400 kb CNVs (with 108 calls in an unaffected genome).
AVAILABILITY AND IMPLEMENTATION: Implementation of our model and data simulation 
method is available at http://github.com/compbio-UofT/fCNV.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu292 
PMCID: PMC4058944
PMID: 24931986  [PubMed - indexed for MEDLINE]


1247. Bioinformatics. 2014 Jun 15;30(12):i19-25. doi: 10.1093/bioinformatics/btu261.

EPIQ-efficient detection of SNP-SNP epistatic interactions for quantitative
traits.

Arkin Y(1), Rahmani E(1), Kleber ME(1), Laaksonen R(2), März W(3), Halperin E(3).

Author information: 
(1)The Blavatnik School of Computer Science, Tel Aviv University, Tel-Aviv 69978,
Israel, V Department of Medicine (Nephrology, Hypertensiology, Endocrinology,
Diabetology, Rheumatology), Medical Faculty of Mannheim, University of
Heidelberg, Mannheim D-68167, Germany, Zora Biosciences Oy, Espoo 02150, Finland,
Medical School, University of Tampere, Tampere 33104, Finland, Clinical Institute
of Medical and Chemical Laboratory Diagnostics, Medical University of Graz, Graz 
A-8036, Austria, Synlab Academy, Synlab Services GmbH, Mannheim D-68165, Germany,
Department of Molecular Microbiology and Biotechnology, George Wise Faculty of
Life Science, Tel-Aviv University, Tel-Aviv 69978, Israel and International
Computer Science Institute, Berkeley, CA 94704, USA. (2)The Blavatnik School of
Computer Science, Tel Aviv University, Tel-Aviv 69978, Israel, V Department of
Medicine (Nephrology, Hypertensiology, Endocrinology, Diabetology, Rheumatology),
Medical Faculty of Mannheim, University of Heidelberg, Mannheim D-68167, Germany,
Zora Biosciences Oy, Espoo 02150, Finland, Medical School, University of Tampere,
Tampere 33104, Finland, Clinical Institute of Medical and Chemical Laboratory
Diagnostics, Medical University of Graz, Graz A-8036, Austria, Synlab Academy,
Synlab Services GmbH, Mannheim D-68165, Germany, Department of Molecular
Microbiology and Biotechnology, George Wise Faculty of Life Science, Tel-Aviv
University, Tel-Aviv 69978, Israel and International Computer Science Institute, 
Berkeley, CA 94704, USAThe Blavatnik School of Computer Science, Tel Aviv
University, Tel-Aviv 69978, Israel, V Department of Medicine (Nephrology,
Hypertensiology, Endocrinology, Diabetology, Rheumatology), Medical Faculty of
Mannheim, University of Heidelberg, Mannheim D-68167, Germany, Zora Biosciences
Oy, Espoo 02150, Finland, Medical School, University of Tampere, Tampere 33104,
Finland, Clinical Institute of Medical and Chemical Laboratory Diagnostics,
Medical University of Graz, Graz A-8036, Austria, Synlab Academy, Synlab Services
GmbH, Mannheim D-68165, Germany, Department of Molecular Microbiology and
Biotechnology, George Wise Faculty of Life Science, Tel-Aviv University, Tel-Aviv
69978, Israel and International Computer Science Institute, Berkeley, CA 94704,
USA. (3)The Blavatnik School of Computer Science, Tel Aviv University, Tel-Aviv
69978, Israel, V Department of Medicine (Nephrology, Hypertensiology,
Endocrinology, Diabetology, Rheumatology), Medical Faculty of Mannheim,
University of Heidelberg, Mannheim D-68167, Germany, Zora Biosciences Oy, Espoo
02150, Finland, Medical School, University of Tampere, Tampere 33104, Finland,
Clinical Institute of Medical and Chemical Laboratory Diagnostics, Medical
University of Graz, Graz A-8036, Austria, Synlab Academy, Synlab Services GmbH,
Mannheim D-68165, Germany, Department of Molecular Microbiology and
Biotechnology, George Wise Faculty of Life Science, Tel-Aviv University, Tel-Aviv
69978, Israel and International Computer Science Institute, Berkeley, CA 94704,
USAThe Blavatnik School of Computer Science, Tel Aviv University, Tel-Aviv 69978,
Israel, V Department of Medicine (Nephrology, Hypertensiology, Endocrinology,
Diabetology, Rheumatology), Medical Faculty of Mannheim, University of
Heidelberg, Mannheim D-68167, Germany, Zora Biosciences Oy, Espoo 02150, Finland,
Medical School, University of Tampere, Tampere 33104, Finland, Clinical Institute
of Medical and Chemical Laboratory Diagnostics, Medical University of Graz, Graz 
A-8036, Austria, Synlab Academy, Synlab Services GmbH, Mannheim D-68165, Germany,
Department of Molecular Microbiology and Biotechnology, George Wise Faculty of
Life Science, Tel-Aviv University, Tel-Aviv 69978, Israel and International
Computer Science Institute, Berkeley, CA 94704, USAThe Blavatnik School of
Computer Science, Tel Aviv University, Tel-Aviv 69978, Israel, V Department of
Medicine (Nephrology, Hypertensiology, Endocrinology, Diabetology, Rheumatology),
Medical Faculty of Mannheim, University of Heidelberg, Mannheim D-68167, Germany,
Zora Biosciences Oy, Espoo 02150, Finland, Medical School, University of Tampere,
Tampere 33104, Finland, Clinical Institute of Medical and Chemical Laboratory
Diagnostics, Medical University of Graz, Graz A-803

MOTIVATION: Gene-gene interactions are of potential biological and medical
interest, as they can shed light on both the inheritance mechanism of a trait and
on the underlying biological mechanisms. Evidence of epistatic interactions has
been reported in both humans and other organisms. Unlike single-locus genome-wide
association studies (GWAS), which proved efficient in detecting numerous genetic 
loci related with various traits, interaction-based GWAS have so far produced
very few reproducible discoveries. Such studies introduce a great computational
and statistical burden by necessitating a large number of hypotheses to be tested
including all pairs of single nucleotide polymorphisms (SNPs). Thus, many
software tools have been developed for interaction-based case-control studies,
some leading to reliable discoveries. For quantitative data, on the other hand,
only a handful of tools exist, and the computational burden is still substantial.
RESULTS: We present an efficient algorithm for detecting epistasis in
quantitative GWAS, achieving a substantial runtime speedup by avoiding the need
to exhaustively test all SNP pairs using metric embedding and random projections.
Unlike previous metric embedding methods for case-control studies, we introduce a
new embedding, where each SNP is mapped to two Euclidean spaces. We implemented
our method in a tool named EPIQ (EPIstasis detection for Quantitative GWAS), and 
we show by simulations that EPIQ requires hours of processing time where other
methods require days and sometimes weeks. Applying our method to a dataset from
the Ludwigshafen risk and cardiovascular health study, we discovered a pair of
SNPs with a near-significant interaction (P = 2.2 × 10(-13)), in only 1.5 h on 10
processors.
AVAILABILITY: https://github.com/yaarasegre/EPIQ

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu261 
PMCID: PMC4229902
PMID: 24931983  [PubMed - indexed for MEDLINE]


1248. Bioinformatics. 2014 Oct;30(19):2837-9. doi: 10.1093/bioinformatics/btu380. Epub 
2014 Jun 14.

miR-PREFeR: an accurate, fast and easy-to-use plant miRNA prediction tool using
small RNA-Seq data.

Lei J(1), Sun Y(1).

Author information: 
(1)Department of Computer Science and Engineering, Michigan State University,
East Lansing, MI 48824, USA.

SUMMARY: Plant microRNA prediction tools that use small RNA-sequencing data are
emerging quickly. These existing tools have at least one of the following
problems: (i) high false-positive rate; (ii) long running time; (iii) work only
for genomes in their databases; (iv) hard to install or use. We developed
miR-PREFeR (miRNA PREdiction From small RNA-Seq data), which uses expression
patterns of miRNA and follows the criteria for plant microRNA annotation to
accurately predict plant miRNAs from one or more small RNA-Seq data samples of
the same species. We tested miR-PREFeR on several plant species. The results show
that miR-PREFeR is sensitive, accurate, fast and has low-memory footprint.
AVAILABILITY AND IMPLEMENTATION: https://github.com/hangelwen/miR-PREFeR

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu380 
PMID: 24930140  [PubMed - indexed for MEDLINE]


1249. Bioinformatics. 2014 Oct;30(19):2816-7. doi: 10.1093/bioinformatics/btu386. Epub 
2014 Jun 12.

BioBlend.objects: metacomputing with Galaxy.

Leo S(1), Pireddu L(1), Cuccuru G(2), Lianas L(2), Soranzo N(2), Afgan E(2),
Zanetti G(2).

Author information: 
(1)CRS4, Polaris, 09010 Pula (CA), Università degli Studi di Cagliari, via
Università 40, 09124 Cagliari, Italy and Ruđer Bošković Institute, 10000 Zagreb, 
Croatia CRS4, Polaris, 09010 Pula (CA), Università degli Studi di Cagliari, via
Università 40, 09124 Cagliari, Italy and Ruđer Bošković Institute, 10000 Zagreb, 
Croatia. (2)CRS4, Polaris, 09010 Pula (CA), Università degli Studi di Cagliari,
via Università 40, 09124 Cagliari, Italy and Ruđer Bošković Institute, 10000
Zagreb, Croatia.

SUMMARY: BioBlend.objects is a new component of the BioBlend package, adding an
object-oriented interface for the Galaxy REST-based application programming
interface. It improves support for metacomputing on Galaxy entities by providing 
higher-level functionality and allowing users to more easily create programs to
explore, query and create Galaxy datasets and workflows.
AVAILABILITY AND IMPLEMENTATION: BioBlend.objects is available online at
https://github.com/afgane/bioblend. The new object-oriented API is implemented by
the galaxy/objects subpackage.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu386 
PMCID: PMC4173020
PMID: 24928211  [PubMed - indexed for MEDLINE]


1250. Bioinformatics. 2014 Oct;30(19):2813-5. doi: 10.1093/bioinformatics/btu376. Epub 
2014 Jun 6.

ABRA: improved coding indel detection via assembly-based realignment.

Mose LE(1), Wilkerson MD(2), Hayes DN(2), Perou CM(2), Parker JS(2).

Author information: 
(1)Lineberger Comprehensive Cancer Center, Department of Genetics, Division of
Medical Oncology, Department of Internal Medicine, Multidisciplinary Thoracic
Oncology Program, University of North Carolina at Chapel Hill, Chapel Hill, NC
27599, USA. (2)Lineberger Comprehensive Cancer Center, Department of Genetics,
Division of Medical Oncology, Department of Internal Medicine, Multidisciplinary 
Thoracic Oncology Program, University of North Carolina at Chapel Hill, Chapel
Hill, NC 27599, USA Lineberger Comprehensive Cancer Center, Department of
Genetics, Division of Medical Oncology, Department of Internal Medicine,
Multidisciplinary Thoracic Oncology Program, University of North Carolina at
Chapel Hill, Chapel Hill, NC 27599, USA.

MOTIVATION: Variant detection from next-generation sequencing (NGS) data is an
increasingly vital aspect of disease diagnosis, treatment and research. Commonly 
used NGS-variant analysis tools generally rely on accurately mapped short reads
to identify somatic variants and germ-line genotypes. Existing NGS read mappers
have difficulty accurately mapping short reads containing complex variation (i.e.
more than a single base change), thus making identification of such variants
difficult or impossible. Insertions and deletions (indels) in particular have
been an area of great difficulty. Indels are frequent and can have substantial
impact on function, which makes their detection all the more imperative.
RESULTS: We present ABRA, an assembly-based realigner, which uses an efficient
and flexible localized de novo assembly followed by global realignment to more
accurately remap reads. This results in enhanced performance for indel detection 
as well as improved accuracy in variant allele frequency estimation.
AVAILABILITY AND IMPLEMENTATION: ABRA is implemented in a combination of Java and
C/C++ and is freely available for download at https://github.com/mozack/abra.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu376 
PMCID: PMC4173014
PMID: 24907369  [PubMed - indexed for MEDLINE]


1251. Bioinformatics. 2014 Oct;30(19):2808-10. doi: 10.1093/bioinformatics/btu379. Epub
2014 Jun 5.

Sushi.R: flexible, quantitative and integrative genomic visualizations for
publication-quality multi-panel figures.

Phanstiel DH(1), Boyle AP(1), Araya CL(1), Snyder MP(1).

Author information: 
(1)Department of Genetics, Stanford University School of Medicine, Stanford, CA
94305, USA.

MOTIVATION: Interpretation and communication of genomic data require flexible and
quantitative tools to analyze and visualize diverse data types, and yet, a
comprehensive tool to display all common genomic data types in publication
quality figures does not exist to date. To address this shortcoming, we present
Sushi.R, an R/Bioconductor package that allows flexible integration of genomic
visualizations into highly customizable, publication-ready, multi-panel figures
from common genomic data formats including Browser Extensible Data (BED),
bedGraph and Browser Extensible Data Paired-End (BEDPE). Sushi.R is open source
and made publicly available through GitHub (https://github.com/dphansti/Sushi)
and Bioconductor (http://bioconductor.org/packages/release/bioc/html/Sushi.html).

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu379 
PMCID: PMC4173017
PMID: 24903420  [PubMed - indexed for MEDLINE]


1252. Mol Ecol Resour. 2015 Jan;15(1):99-106. doi: 10.1111/1755-0998.12286. Epub 2014
Jun 28.

Pipeliner: software to evaluate the performance of bioinformatics pipelines for
next-generation resequencing.

Nevado B(1), Perez-Enciso M.

Author information: 
(1)Centre for Research in Agricultural Genomics (CRAG), CSIC-IRTA-UAB-UB, 08193, 
Bellaterra, Spain; Universitat Autònoma de Barcelona, 08193, Bellaterra, Spain.

The choice of technology and bioinformatics approach is critical in obtaining
accurate and reliable information from next-generation sequencing (NGS)
experiments. An increasing number of software and methodological guidelines are
being published, but deciding upon which approach and experimental design to use 
can depend on the particularities of the species and on the aims of the study.
This leaves researchers unable to produce informed decisions on these central
questions. To address these issues, we developed pipeliner - a tool to evaluate, 
by simulation, the performance of NGS pipelines in resequencing studies.
Pipeliner provides a graphical interface allowing the users to write and test
their own bioinformatics pipelines with publicly available or custom software. It
computes a number of statistics summarizing the performance in SNP calling,
including the recovery, sensitivity and false discovery rate for heterozygous and
homozygous SNP genotypes. Pipeliner can be used to answer many practical
questions, for example, for a limited amount of NGS effort, how many more
reliable SNPs can be detected by doubling coverage and halving sample size or
what is the false discovery rate provided by different SNP calling algorithms and
options. Pipeliner thus allows researchers to carefully plan their study's
sampling design and compare the suitability of alternative bioinformatics
approaches for their specific study systems. Pipeliner is written in C++ and is
freely available from http://github.com/brunonevado/Pipeliner.

© 2014 John Wiley & Sons Ltd.

DOI: 10.1111/1755-0998.12286 
PMID: 24890372  [PubMed - indexed for MEDLINE]


1253. BMC Bioinformatics. 2014 May 6;15:129. doi: 10.1186/1471-2105-15-129.

A web-based protein interaction network visualizer.

Salazar GA(1), Meintjes A, Mazandu GK, Rapanoël HA, Akinola RO, Mulder NJ.

Author information: 
(1)Computational Biology Group, IDM, Faculty of Health Sciences, University of
Cape Town, Anzio Road, Cape Town, South Africa. gustavo@cbio.uct.ac.za.

BACKGROUND: Interaction between proteins is one of the most important mechanisms 
in the execution of cellular functions. The study of these interactions has
provided insight into the functioning of an organism's processes. As of October
2013, Homo sapiens had over 170000 Protein-Protein interactions (PPI) registered 
in the Interologous Interaction Database, which is only one of the many public
resources where protein interactions can be accessed. These numbers exemplify the
volume of data that research on the topic has generated. Visualization of large
data sets is a well known strategy to make sense of information, and protein
interaction data is no exception. There are several tools that allow the
exploration of this data, providing different methods to visualize protein
network interactions. However, there is still no native web tool that allows this
data to be explored interactively online.
RESULTS: Given the advances that web technologies have made recently it is time
to bring these interactive views to the web to provide an easily accessible forum
to visualize PPI. We have created a Web-based Protein Interaction Network
Visualizer: PINV, an open source, native web application that facilitates the
visualization of protein interactions (http://biosual.cbio.uct.ac.za/pinv.html). 
We developed PINV as a set of components that follow the protocol defined in
BioJS and use the D3 library to create the graphic layouts. We demonstrate the
use of PINV with multi-organism interaction networks for a predicted target from 
Mycobacterium tuberculosis, its interacting partners and its orthologs.
CONCLUSIONS: The resultant tool provides an attractive view of complex, fully
interactive networks with components that allow the querying, filtering and
manipulation of the visible subset. Moreover, as a web resource, PINV simplifies 
sharing and publishing, activities which are vital in today's research
collaborative environments. The source code is freely available for download at
https://github.com/4ndr01d3/biosual.

DOI: 10.1186/1471-2105-15-129 
PMCID: PMC4029974
PMID: 24885165  [PubMed - indexed for MEDLINE]


1254. PLoS One. 2014 May 30;9(5):e97896. doi: 10.1371/journal.pone.0097896. eCollection
2014.

The Index-based Subgraph Matching Algorithm with General Symmetries (ISMAGS):
exploiting symmetry for faster subgraph enumeration.

Houbraken M(1), Demeyer S(2), Michoel T(2), Audenaert P(1), Colle D(1), Pickavet 
M(1).

Author information: 
(1)Department of Information Technology, Ghent University - iMinds, Ghent,
Belgium. (2)Division of Genetics and Genomics, The Roslin Institute - University 
of Edinburgh, Midlothian, Scotland, United Kingdom.

Subgraph matching algorithms are used to find and enumerate specific
interconnection structures in networks. By enumerating these specific
structures/subgraphs, the fundamental properties of the network can be derived.
More specifically in biological networks, subgraph matching algorithms are used
to discover network motifs, specific patterns occurring more often than expected 
by chance. Finding these network motifs yields information on the underlying
biological relations modelled by the network. In this work, we present the
Index-based Subgraph Matching Algorithm with General Symmetries (ISMAGS), an
improved version of the Index-based Subgraph Matching Algorithm (ISMA). ISMA
quickly finds all instances of a predefined motif in a network by intelligently
exploring the search space and taking into account easily identifiable symmetric 
structures. However, more complex symmetries (possibly involving switching
multiple nodes) are not taken into account, resulting in superfluous output.
ISMAGS overcomes this problem by using a customised symmetry analysis phase to
detect all symmetric structures in the network motif subgraphs. These structures 
are then converted to symmetry-breaking constraints used to prune the search
space and speed up calculations. The performance of the algorithm was tested on
several types of networks (biological, social and computer networks) for various 
subgraphs with a varying degree of symmetry. For subgraphs with complex
(multi-node) symmetric structures, high speed-up factors are obtained as the
search space is pruned by the symmetry-breaking constraints. For subgraphs with
no or simple symmetric structures, ISMAGS still reduces computation times by
optimising set operations. Moreover, the calculated list of subgraph instances is
minimal as it contains no instances that differ by only a subgraph symmetry. An
implementation of the algorithm is freely available at
https://github.com/mhoubraken/ISMAGS.

DOI: 10.1371/journal.pone.0097896 
PMCID: PMC4039476
PMID: 24879305  [PubMed - indexed for MEDLINE]


1255. Med Phys. 2014 Jun;41(6):145. doi: 10.1118/1.4888016.

SU-E-I-66: Radiomics and Image Registration Updates for the Computational
Environment for Radiotherapy Research (CERR).

Apte A(1), Wang Y(1), Deasy J(1).

Author information: 
(1)Memorial Sloan Kettering Cancer Center, NY, NY.

PURPOSE: To present new tools in CERR for Radiomics, image registration and other
software updates and additions.
METHODS: Radiomics: CERR supports generating 3-D texture metrics based on gray
scale co-occurance. Two new ways to calculate texture features were added: (1)
Local Texture Averaging: Local texture is calculated around a voxel within the
userdefined bounding box. The final texture metrics are the average of local
textures for all the voxels. This is useful to detect any local texture patterns 
within an image. (2) Image Smoothing: A convolution ball of user-defined radius
is rolled over an image to smooth out artifacts. The texture metrics are then
computed on the smooth image. Image Registration: (1) Support was added to import
deformation vector fields as well as non-deformable transformation matrices
generated by vendor software and stored in standard DICOM format. (2) Support was
added to use image within masks while computing image deformations. CT to MR
registration is supported. This registration uses morphological edge information 
within the images to guide the deformation process. In addition to these
features, other noteworthy additions to CERR include (1) Irregularly shaped ROI: 
This is done by taking intersection between infinitely extended irregular
polygons drawn on any of the two views. Such an ROI is more conformal and useful 
in avoiding any unwanted parts of images that cannot be avoided with the
conventional cubic box. The ROI is useful to generate Radiomics metrics. (2)
Ability to insert RTDOSE in DICOM format to existing CERR plans. (3) Ability to
import multi-frame PET-CT and SPECT-CT while maintaining spatial registration
between the two modalities. (4) Ability to compile CERR on Unix-like systems.
RESULTS: The new features and updates are available via
https://www.github.com/adityaapte/cerr.
CONCLUSION: Features added to CERR increase its utility in Radiomics,
Image-Registration and Outcomes modeling.

© 2014 American Association of Physicists in Medicine.

DOI: 10.1118/1.4888016 
PMID: 28036867  [PubMed - in process]


1256. Bioinformatics. 2014 Sep 15;30(18):2678-80. doi: 10.1093/bioinformatics/btu363.
Epub 2014 May 29.

PatternCNV: a versatile tool for detecting copy number changes from exome
sequencing data.

Wang C(1), Evans JM(1), Bhagwate AV(1), Prodduturi N(1), Sarangi V(1), Middha
M(1), Sicotte H(1), Vedell PT(1), Hart SN(1), Oliver GR(1), Kocher JP(1), Maurer 
MJ(1), Novak AJ(1), Slager SL(1), Cerhan JR(1), Asmann YW(1).

Author information: 
(1)Division of Biomedical Statistics and Informatics, Department of Health
Sciences Research, Division of Epidemiology, Department of Health Sciences
Research, Division of Hematology, Department of Internal Medicine, Mayo Clinic,
200 First Street SW, Rochester, MN 55905 and Department of Health Sciences
Research, Mayo Clinic, 4500 San Pablo Road South, Jacksonville, FL 32224, USA.

MOTIVATION: Exome sequencing (exome-seq) data, which are typically used for
calling exonic mutations, have also been utilized in detecting DNA copy number
variations (CNVs). Despite the existence of several CNV detection tools, there is
still a great need for a sensitive and an accurate CNV-calling algorithm with
built-in QC steps, and does not require a paired reference for each sample.
RESULTS: We developed a novel method named PatternCNV, which (i) accounts for the
read coverage variations between exons while leveraging the consistencies of this
variability across different samples; (ii) reduces alignment BAM files to WIG
format and therefore greatly accelerates computation; (iii) incorporates multiple
QC measures designed to identify outlier samples and batch effects; and (iv)
provides a variety of visualization options including chromosome, gene and
exon-level views of CNVs, along with a tabular summarization of the exon-level
CNVs. Compared with other CNV-calling algorithms using data from a lymphoma
exome-seq study, PatternCNV has higher sensitivity and specificity.
AVAILABILITY AND IMPLEMENTATION: The software for PatternCNV is implemented using
Perl and R, and can be used in Mac or Linux environments. Software and user
manual are available at http://bioinformaticstools.mayo.edu/research/patterncnv/,
and R package at https://github.com/topsoil/patternCNV/.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu363 
PMCID: PMC4155258
PMID: 24876377  [PubMed - indexed for MEDLINE]


1257. Bioinformatics. 2014 Sep 15;30(18):2636-43. doi: 10.1093/bioinformatics/btu359.
Epub 2014 May 28.

Massifquant: open-source Kalman filter-based XC-MS isotope trace feature
detection.

Conley CJ(1), Smith R(1), Torgrip RJ(1), Taylor RM(1), Tautenhahn R(2), Prince
JT(1).

Author information: 
(1)Department of Statistics, University of California Davis, Davis, CA 95616,
Department of Computer Science, Brigham Young University, Provo, UT 84606, USA,
Department of Analytical Chemistry, Stockholm University, SE-106 91, Stockholm,
Sweden, Department of Chemistry and Biochemistry, Brigham Young University,
Provo, UT 84606, Department of Chemistry, Department of Molecular Biology and
Center for Metabolomics, The Scripps Research Institute, La Jolla, CA 92037, USA.
(2)Department of Statistics, University of California Davis, Davis, CA 95616,
Department of Computer Science, Brigham Young University, Provo, UT 84606, USA,
Department of Analytical Chemistry, Stockholm University, SE-106 91, Stockholm,
Sweden, Department of Chemistry and Biochemistry, Brigham Young University,
Provo, UT 84606, Department of Chemistry, Department of Molecular Biology and
Center for Metabolomics, The Scripps Research Institute, La Jolla, CA 92037, USA 
Department of Statistics, University of California Davis, Davis, CA 95616,
Department of Computer Science, Brigham Young University, Provo, UT 84606, USA,
Department of Analytical Chemistry, Stockholm University, SE-106 91, Stockholm,
Sweden, Department of Chemistry and Biochemistry, Brigham Young University,
Provo, UT 84606, Department of Chemistry, Department of Molecular Biology and
Center for Metabolomics, The Scripps Research Institute, La Jolla, CA 92037, USA 
Department of Statistics, University of California Davis, Davis, CA 95616,
Department of Computer Science, Brigham Young University, Provo, UT 84606, USA,
Department of Analytical Chemistry, Stockholm University, SE-106 91, Stockholm,
Sweden, Department of Chemistry and Biochemistry, Brigham Young University,
Provo, UT 84606, Department of Chemistry, Department of Molecular Biology and
Center for Metabolomics, The Scripps Research Institute, La Jolla, CA 92037, USA.

MOTIVATION: Isotope trace (IT) detection is a fundamental step for liquid or gas 
chromatography mass spectrometry (XC-MS) data analysis that faces a multitude of 
technical challenges on complex samples. The Kalman filter (KF) application to IT
detection addresses some of these challenges; it discriminates closely eluting
ITs in the m/z dimension, flexibly handles heteroscedastic m/z variances and does
not bin the m/z axis. Yet, the behavior of this KF application has not been fully
characterized, as no cost-free open-source implementation exists and incomplete
evaluation standards for IT detection persist.
RESULTS: Massifquant is an open-source solution for KF IT detection that has been
subjected to novel and rigorous methods of performance evaluation. The presented 
evaluation with accompanying annotations and optimization guide sets a new
standard for comparative IT detection. Compared with centWave, matchedFilter and 
MZMine2-alternative IT detection engines-Massifquant detected more true ITs in a 
real LC-MS complex sample, especially low-intensity ITs. It also offers
competitive specificity and equally effective quantitation accuracy.
AVAILABILITY AND IMPLEMENTATION: Massifquant is integrated into XCMS with GPL
license ≥ 2.0 and hosted by Bioconductor: http://bioconductor.org. Annotation
data are archived at http://hdl.lib.byu.edu/1877/3232. Parameter optimization
code and documentation is hosted at https://github.com/topherconley/optimize-it.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu359 
PMID: 24872423  [PubMed - indexed for MEDLINE]


1258. Bioinformatics. 2014 Sep 15;30(18):2670-2. doi: 10.1093/bioinformatics/btu353.
Epub 2014 May 26.

MIPgen: optimized modeling and design of molecular inversion probes for targeted 
resequencing.

Boyle EA(1), O'Roak BJ(1), Martin BK(1), Kumar A(1), Shendure J(1).

Author information: 
(1)Department of Genome Sciences, University of Washington, Seattle, WA 98105 and
Department of Molecular & Medical Genetics, Oregon Health & Science University,
Portland, OR 97239, USA.

Molecular inversion probes (MIPs) enable cost-effective multiplex targeted gene
resequencing in large cohorts. However, the design of individual MIPs is a
critical parameter governing the performance of this technology with respect to
capture uniformity and specificity. MIPgen is a user-friendly package that
simplifies the process of designing custom MIP assays to arbitrary targets. New
logistic and SVM-derived models enable in silico predictions of assay success,
and assay redesign exhibits improved coverage uniformity relative to previous
methods, which in turn improves the utility of MIPs for cost-effective targeted
sequencing for candidate gene validation and for diagnostic sequencing in a
clinical setting.AVAILABILITY AND IMPLEMENTATION: MIPgen is implemented in C++.
Source code and accompanying Python scripts are available at
http://shendurelab.github.io/MIPGEN/.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu353 
PMCID: PMC4155255
PMID: 24867941  [PubMed - indexed for MEDLINE]


1259. F1000Res. 2014 Feb 13;3:48. doi: 10.12688/f1000research.3-48.v1. eCollection
2014.

HeatMapViewer: interactive display of 2D data in biology.

Yachdav G(1), Hecht M(2), Pasmanik-Chor M(3), Yeheskel A(3), Rost B(1).

Author information: 
(1)TUM, Department of Informatics, Bioinformatics & Computational Biology, 5748
Garching/ Munich, Germany ; TUM Graduate School of Information Science in Health 
(GSISH), 85748 Garching/Munich, Germany ; Biosof LLC, New York, NY, 10001, USA.
(2)TUM, Department of Informatics, Bioinformatics & Computational Biology, 5748
Garching/ Munich, Germany ; TUM Graduate School of Information Science in Health 
(GSISH), 85748 Garching/Munich, Germany. (3)Bioinformatics Unit, G.S.W. Faculty
of Life Sciences, Tel Aviv University, Tel Aviv, 69978, Israel.

SUMMARY: The HeatMapViewer is a BioJS component that lays-out and renders
two-dimensional (2D) plots or heat maps that are ideally suited to visualize
matrix formatted data in biology such as for the display of microarray
experiments or the outcome of mutational studies and the study of SNP-like
sequence variants. It can be easily integrated into documents and provides a
powerful, interactive way to visualize heat maps in web applications. The
software uses a scalable graphics technology that adapts the visualization
component to any required resolution, a useful feature for a presentation with
many different data-points. The component can be applied to present various
biological data types. Here, we present two such cases - showing gene expression 
data and visualizing mutability landscape analysis.
AVAILABILITY: https://github.com/biojs/biojs;
http://dx.doi.org/10.5281/zenodo.7706.

DOI: 10.12688/f1000research.3-48.v1 
PMCID: PMC4023661
PMID: 24860644  [PubMed]


1260. Bioinformatics. 2014 Sep 15;30(18):2551-8. doi: 10.1093/bioinformatics/btu351.
Epub 2014 May 23.

Identification of chromosomal translocation hotspots via scan statistics.

Silva IT(1), Rosales RA(2), Holanda AJ(2), Nussenzweig MC(2), Jankovic M(2).

Author information: 
(1)Laboratory of Molecular Immunology, The Rockefeller University, 1230 York
Avenue, New York, NY 10065, USA, Departamento de Computação e Matemática,
Universidade de São Paulo. Av. Bandeirantes, 3900, Ribeirão Preto, CEP 14049-901 
and National Institute of Science and Technology in Stem Cell and Cell Therapy
and Center for Cell Based Therapy. Rua Catão Roxo, 2501, Ribeirão Preto, CEP
14051-140, SP, Brazil Laboratory of Molecular Immunology, The Rockefeller
University, 1230 York Avenue, New York, NY 10065, USA, Departamento de Computação
e Matemática, Universidade de São Paulo. Av. Bandeirantes, 3900, Ribeirão Preto, 
CEP 14049-901 and National Institute of Science and Technology in Stem Cell and
Cell Therapy and Center for Cell Based Therapy. Rua Catão Roxo, 2501, Ribeirão
Preto, CEP 14051-140, SP, Brazil. (2)Laboratory of Molecular Immunology, The
Rockefeller University, 1230 York Avenue, New York, NY 10065, USA, Departamento
de Computação e Matemática, Universidade de São Paulo. Av. Bandeirantes, 3900,
Ribeirão Preto, CEP 14049-901 and National Institute of Science and Technology in
Stem Cell and Cell Therapy and Center for Cell Based Therapy. Rua Catão Roxo,
2501, Ribeirão Preto, CEP 14051-140, SP, Brazil.

MOTIVATION: The detection of genomic regions unusually rich in a given pattern is
an important undertaking in the analysis of next-generation sequencing data.
Recent studies of chromosomal translocations in activated B lymphocytes have
identified regions that are frequently translocated to c-myc oncogene. A
quantitative method for the identification of translocation hotspots was crucial 
to this study. Here we improve this analysis by using a simple probabilistic
model and the framework provided by scan statistics to define the number and
location of translocation breakpoint hotspots. A key feature of our method is
that it provides a global chromosome-wide nominal control level to clustering, as
opposed to previous methods based on local criteria. While being motivated by a
specific application, the detection of unusual clusters is a widespread problem
in bioinformatics. We expect our method to be useful in the analysis of data from
other experimental approaches such as of ChIP-seq and 4C-seq.
RESULTS: The analysis of translocations from B lymphocytes with the method
described here reveals the presence of longer hotspots when compared with those
defined previously. Further, we show that the hotspot size changes substantially 
in the absence of DNA repair protein 53BP1. When 53BP1 deficiency is combined
with overexpression of activation-induced cytidine deaminase, the hotspot length 
increases even further. These changes are not detected by previous methods that
use local significance criteria for clustering. Our method is also able to
identify several exclusive translocation hotspots located in genes of known tumor
supressors.
AVAILABILITY AND IMPLEMENTATION: The detection of translocation hotspots is done 
with hot_scan, a program implemented in R and Perl. Source code and documentation
are freely available for download at https://github.com/itojal/hot_scan.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu351 
PMCID: PMC4155254
PMID: 24860160  [PubMed - indexed for MEDLINE]


1261. Biodivers Data J. 2014 Jan 29;(2):e1041. doi: 10.3897/BDJ.2.e1041. eCollection
2014.

Morphological and geographical traits of the british odonata.

Powney GD(1), Brooks SJ(2), Barwell LJ(3), Bowles P(4), Fitt RN(5), Pavitt A(4), 
Spriggs RA(6), Isaac NJ(7).

Author information: 
(1)Centre for Ecology & Hydrology, Wallingford, United Kingdom ; Department of
Life Sciences, Imperial College London, Ascot, United Kingdom. (2)Life Sciences
Department, Natural History Museum, London, United Kingdom. (3)Centre for Ecology
& Hydrology, Wallingford, United Kingdom ; School of Biology, University of
Leeds, Leeds, United Kingdom. (4)Department of Life Sciences, Imperial College
London, Ascot, United Kingdom. (5)Zoology Department, University of Aberdeen,
Aberdeen, United Kingdom. (6)Department of Plant Sciences, University of
Cambridge, Cambridge, United Kingdom. (7)Centre for Ecology & Hydrology,
Wallingford, United Kingdom.

Trait data are fundamental for many aspects of ecological research, particularly 
for modeling species response to environmental change. We synthesised information
from the literature (mainly field guides) and direct measurements from museum
specimens, providing a comprehensive dataset of 26 attributes, covering the 43
resident species of Odonata in Britain. Traits included in this database range
from morphological traits (e.g. body length) to attributes based on the
distribution of the species (e.g. climatic restriction). We measured 11
morphometric traits from five adult males and five adult females per species.
Using digital callipers, these measurements were taken from dry museum specimens,
all of which were wild caught individuals. Repeated measures were also taken to
estimate measurement error. The trait data are stored in an online repository
(https://github.com/BiologicalRecordsCentre/Odonata_traits), alongside R code
designed to give an overview of the morphometric data, and to combine the
morphometric data to the single value per trait per species data.

DOI: 10.3897/BDJ.2.e1041 
PMCID: PMC4030211
PMID: 24855438  [PubMed]


1262. Bioinformatics. 2014 Sep 15;30(18):2603-10. doi: 10.1093/bioinformatics/btu342.
Epub 2014 May 19.

Estimates of allele-specific expression in Drosophila with a single genome
sequence and RNA-seq data.

Quinn A(1), Juneja P(1), Jiggins FM(1).

Author information: 
(1)Department of Genetics, University of Cambridge, Cambridge CB2 3EH, UK.

MOTIVATION: Genetic variation in cis-regulatory elements is an important cause of
variation in gene expression. Cis-regulatory variation can be detected by using
high-throughput RNA sequencing (RNA-seq) to identify differences in the
expression of the two alleles of a gene. This requires that reads from the two
alleles are equally likely to map to a reference genome(s), and that
single-nucleotide polymorphisms (SNPs) are accurately called, so that reads
derived from the different alleles can be identified. Both of these prerequisites
can be achieved by sequencing the genomes of the parents of the individual being 
studied, but this is often prohibitively costly.
RESULTS: In Drosophila, we demonstrate that biases during read mapping can be
avoided by mapping reads to two alternative genomes that incorporate SNPs called 
from the RNA-seq data. The SNPs can be reliably called from the RNA-seq data
itself, provided any variants not found in high-quality SNP databases are
filtered out. Finally, we suggest a way of measuring allele-specific expression
(ASE) by crossing the line of interest to a reference line with a high-quality
genome sequence. Combined with our bioinformatic methods, this approach minimizes
mapping biases, allows poor-quality data to be identified and removed and aides
in the biological interpretation of the data as the parent of origin of each
allele is known. In conclusion, our results suggest that accurate estimates of
ASE do not require the parental genomes of the individual being studied to be
sequenced.
AVAILABILITY AND IMPLEMENTATION: Scripts used to perform our analysis are
available at https://github.com/d-quinn/bio_quinn2013.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu342 
PMID: 24845654  [PubMed - indexed for MEDLINE]


1263. Bioinformatics. 2014 Sep 1;30(17):2471-9. doi: 10.1093/bioinformatics/btu340.
Epub 2014 May 19.

Exploration and retrieval of whole-metagenome sequencing samples.

Seth S(1), Välimäki N(2), Kaski S(2), Honkela A(1).

Author information: 
(1)Helsinki Institute for Information Technology HIIT, Department of Information 
and Computer Science, Aalto University, Espoo, Finland, Genome-Scale Biology
Program and Department of Medical Genetics, University of Helsinki, Helsinki,
Finland, and Helsinki Institute for Information Technology HIIT, Department of
Computer Science, University of Helsinki, Helsinki, Finland. (2)Helsinki
Institute for Information Technology HIIT, Department of Information and Computer
Science, Aalto University, Espoo, Finland, Genome-Scale Biology Program and
Department of Medical Genetics, University of Helsinki, Helsinki, Finland, and
Helsinki Institute for Information Technology HIIT, Department of Computer
Science, University of Helsinki, Helsinki, Finland Helsinki Institute for
Information Technology HIIT, Department of Information and Computer Science,
Aalto University, Espoo, Finland, Genome-Scale Biology Program and Department of 
Medical Genetics, University of Helsinki, Helsinki, Finland, and Helsinki
Institute for Information Technology HIIT, Department of Computer Science,
University of Helsinki, Helsinki, Finland.

MOTIVATION: Over the recent years, the field of whole-metagenome shotgun
sequencing has witnessed significant growth owing to the high-throughput
sequencing technologies that allow sequencing genomic samples cheaper, faster and
with better coverage than before. This technical advancement has initiated the
trend of sequencing multiple samples in different conditions or environments to
explore the similarities and dissimilarities of the microbial communities.
Examples include the human microbiome project and various studies of the human
intestinal tract. With the availability of ever larger databases of such
measurements, finding samples similar to a given query sample is becoming a
central operation.
RESULTS: In this article, we develop a content-based exploration and retrieval
method for whole-metagenome sequencing samples. We apply a distributed string
mining framework to efficiently extract all informative sequence k-mers from a
pool of metagenomic samples and use them to measure the dissimilarity between two
samples. We evaluate the performance of the proposed approach on two human gut
metagenome datasets as well as human microbiome project metagenomic samples. We
observe significant enrichment for diseased gut samples in results of queries
with another diseased sample and high accuracy in discriminating between
different body sites even though the method is unsupervised.
AVAILABILITY AND IMPLEMENTATION: A software implementation of the DSM framework
is available at https://github.com/HIITMetagenomics/dsm-framework.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu340 
PMCID: PMC4230234
PMID: 24845653  [PubMed - indexed for MEDLINE]


1264. J Chem Inf Model. 2014 Jun 23;54(6):1810-9. doi: 10.1021/ci500173w. Epub 2014 Jun
9.

iBIOMES Lite: summarizing biomolecular simulation data in limited settings.

Thibault JC(1), Cheatham TE 3rd, Facelli JC.

Author information: 
(1)Department of Biomedical Informatics and ‡Department of Medicinal Chemistry,
University of Utah , Salt Lake City, Utah 84112, United States.

As the amount of data generated by biomolecular simulations dramatically
increases, new tools need to be developed to help manage this data at the
individual investigator or small research group level. In this paper, we
introduce iBIOMES Lite, a lightweight tool for biomolecular simulation data
indexing and summarization. The main goal of iBIOMES Lite is to provide a simple 
interface to summarize computational experiments in a setting where the user
might have limited privileges and limited access to IT resources. A command-line 
interface allows the user to summarize, publish, and search local simulation data
sets. Published data sets are accessible via static hypertext markup language
(HTML) pages that summarize the simulation protocols and also display data
analysis graphically. The publication process is customized via extensible markup
language (XML) descriptors while the HTML summary template is customized through 
extensible stylesheet language (XSL). iBIOMES Lite was tested on different
platforms and at several national computing centers using various data sets
generated through classical and quantum molecular dynamics, quantum chemistry,
and QM/MM. The associated parsers currently support AMBER, GROMACS, Gaussian, and
NWChem data set publication. The code is available at
https://github.com/jcvthibault/ibiomes .

DOI: 10.1021/ci500173w 
PMCID: PMC4076027
PMID: 24830957  [PubMed - indexed for MEDLINE]


1265. Int J Mol Sci. 2014 May 13;15(5):8491-508. doi: 10.3390/ijms15058491.

DEFLATE compression algorithm corrects for overestimation of phylogenetic
diversity by Grantham approach to single-nucleotide polymorphism classification.

Schlosberg A(1), Lam BY(2), Yeo GS(3), Clifton-Bligh RJ(4).

Author information: 
(1)Kolling Institute of Medical Research, Royal North Shore Hospital, Pacific
Hwy, St Leonards, NSW 2065, Australia. asch5328@uni.sydney.edu.au. (2)University 
of Cambridge Metabolic Research Laboratories, Box 289, Level 4 Wellcome Trust-MRC
Institute of Metabolic Science, Addenbrooke's Hospital, Hills Road, Cambridge CB2
0QQ, UK. yhbl2@cam.ac.uk. (3)University of Cambridge Metabolic Research
Laboratories, Box 289, Level 4 Wellcome Trust-MRC Institute of Metabolic Science,
Addenbrooke's Hospital, Hills Road, Cambridge CB2 0QQ, UK. gshy2@cam.ac.uk.
(4)Kolling Institute of Medical Research, Royal North Shore Hospital, Pacific
Hwy, St Leonards, NSW 2065, Australia. jclifton@med.usyd.edu.au.

Improvements in speed and cost of genome sequencing are resulting in increasing
numbers of novel non-synonymous single nucleotide polymorphisms (nsSNPs) in genes
known to be associated with disease. The large number of nsSNPs makes
laboratory-based classification infeasible and familial co-segregation with
disease is not always possible. In-silico methods for classification or triage
are thus utilised. A popular tool based on multiple-species sequence alignments
(MSAs) and work by Grantham, Align-GVGD, has been shown to underestimate
deleterious effects, particularly as sequence numbers increase. We utilised the
DEFLATE compression algorithm to account for expected variation across a number
of species. With the adjusted Grantham measure we derived a means of
quantitatively clustering known neutral and deleterious nsSNPs from the same
gene; this was then used to assign novel variants to the most appropriate cluster
as a means of binary classification. Scaling of clusters allows for inter-gene
comparison of variants through a single pathogenicity score. The approach
improves upon the classification accuracy of Align-GVGD while correcting for
sensitivity to large MSAs. Open-source code and a web server are made available
at https://github.com/aschlosberg/CompressGV.

DOI: 10.3390/ijms15058491 
PMCID: PMC4057744
PMID: 24828207  [PubMed - indexed for MEDLINE]


1266. Bioinformatics. 2014 Sep 1;30(17):2501-2. doi: 10.1093/bioinformatics/btu310.
Epub 2014 May 13.

PLAAC: a web and command-line application to identify proteins with prion-like
amino acid composition.

Lancaster AK(1), Nutter-Upham A(2), Lindquist S(1), King OD(2).

Author information: 
(1)Whitehead Institute for Biomedical Research, 9 Cambridge Center, Cambridge, MA
02142, Department of Pathology, Beth Israel Deaconess Medical Center, Center for 
Biomedical Informatics, Harvard Medical School, 10 Shattuck Street, Boston, MA
02115, USA, Department of Biology, Howard Hughes Medical Institute, MIT, 77
Massachusetts Avenue, Cambridge, MA 02139 and Department of Cell and
Developmental Biology, University of Massachusetts Medical School, 55 Lake Avenue
North, Worcester, MA 01655, USA Whitehead Institute for Biomedical Research, 9
Cambridge Center, Cambridge, MA 02142, Department of Pathology, Beth Israel
Deaconess Medical Center, Center for Biomedical Informatics, Harvard Medical
School, 10 Shattuck Street, Boston, MA 02115, USA, Department of Biology, Howard 
Hughes Medical Institute, MIT, 77 Massachusetts Avenue, Cambridge, MA 02139 and
Department of Cell and Developmental Biology, University of Massachusetts Medical
School, 55 Lake Avenue North, Worcester, MA 01655, USA Whitehead Institute for
Biomedical Research, 9 Cambridge Center, Cambridge, MA 02142, Department of
Pathology, Beth Israel Deaconess Medical Center, Center for Biomedical
Informatics, Harvard Medical School, 10 Shattuck Street, Boston, MA 02115, USA,
Department of Biology, Howard Hughes Medical Institute, MIT, 77 Massachusetts
Avenue, Cambridge, MA 02139 and Department of Cell and Developmental Biology,
University of Massachusetts Medical School, 55 Lake Avenue North, Worcester, MA
01655, USA. (2)Whitehead Institute for Biomedical Research, 9 Cambridge Center,
Cambridge, MA 02142, Department of Pathology, Beth Israel Deaconess Medical
Center, Center for Biomedical Informatics, Harvard Medical School, 10 Shattuck
Street, Boston, MA 02115, USA, Department of Biology, Howard Hughes Medical
Institute, MIT, 77 Massachusetts Avenue, Cambridge, MA 02139 and Department of
Cell and Developmental Biology, University of Massachusetts Medical School, 55
Lake Avenue North, Worcester, MA 01655, USA.

Prions are self-templating protein aggregates that stably perpetuate distinct
biological states and are of keen interest to researchers in both evolutionary
and biomedical science. The best understood prions are from yeast and have a
prion-forming domain with strongly biased amino acid composition, most notably
enriched for Q or N. PLAAC is a web application that scans protein sequences for 
domains with P: rion- L: ike A: mino A: cid C: omposition. Users can upload
sequence files, or paste sequences directly into a textbox. PLAAC ranks the input
sequences by several summary scores and allows scores along sequences to be
visualized. Text output files can be downloaded for further analyses, and
visualizations saved in PDF and PNG formats.AVAILABILITY AND IMPLEMENTATION:
http://plaac.wi.mit.edu/. The Ruby-based web framework and the command-line
software (implemented in Java, with visualization routines in R) are available at
http://github.com/whitehead/plaac under the MIT license. All software can be run 
under OS X, Windows and Unix.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu310 
PMCID: PMC4147883
PMID: 24825614  [PubMed - indexed for MEDLINE]


1267. Bioinformatics. 2014 Sep 1;30(17):2503-5. doi: 10.1093/bioinformatics/btu314.
Epub 2014 May 7.

SAMBLASTER: fast duplicate marking and structural variant read extraction.

Faust GG(1), Hall IM(2).

Author information: 
(1)Department of Biochemistry and Molecular Genetics and Center for Public Health
Genomics, University of Virginia, Charlottesville, VA 22908, USA. (2)Department
of Biochemistry and Molecular Genetics and Center for Public Health Genomics,
University of Virginia, Charlottesville, VA 22908, USA Department of Biochemistry
and Molecular Genetics and Center for Public Health Genomics, University of
Virginia, Charlottesville, VA 22908, USA.

MOTIVATION: Illumina DNA sequencing is now the predominant source of raw genomic 
data, and data volumes are growing rapidly. Bioinformatic analysis pipelines are 
having trouble keeping pace. A common bottleneck in such pipelines is the
requirement to read, write, sort and compress large BAM files multiple times.
RESULTS: We present SAMBLASTER, a tool that reduces the number of times such
costly operations are performed. SAMBLASTER is designed to mark duplicates in
read-sorted SAM files as a piped post-pass on DNA aligner output before it is
compressed to BAM. In addition, it can simultaneously output into separate files 
the discordant read-pairs and/or split-read mappings used for structural variant 
calling. As an alignment post-pass, its own runtime overhead is negligible, while
dramatically reducing overall pipeline complexity and runtime. As a stand-alone
duplicate marking tool, it performs significantly better than PICARD or SAMBAMBA 
in terms of both speed and memory usage, while achieving nearly identical
results.
AVAILABILITY AND IMPLEMENTATION: SAMBLASTER is open-source C+ + code and freely
available for download from https://github.com/GregoryFaust/samblaster.

© The Author(s) 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu314 
PMCID: PMC4147885
PMID: 24812344  [PubMed - indexed for MEDLINE]


1268. Bioinformatics. 2014 Sep 1;30(17):2537-9. doi: 10.1093/bioinformatics/btu311.
Epub 2014 May 2.

Bioclojure: a functional library for the manipulation of biological sequences.

Plieskatt J(1), Rinaldi G(1), Brindley PJ(1), Jia X(2), Potriquet J(2), Bethony
J(2), Mulvenna J(1).

Author information: 
(1)Department of Microbiology, Immunology and Tropical Medicine, Research Center 
for Neglected Diseases of Poverty, School of Medicine and Health Sciences, George
Washington University, Washington, DC, 20052, USA, QIMR Berghofer Medical
Research Institute, Infectious Disease and Cancer and The University of
Queensland, School of Biomedical Sciences, Brisbane, Queensland, 4072, Australia 
Department of Microbiology, Immunology and Tropical Medicine, Research Center for
Neglected Diseases of Poverty, School of Medicine and Health Sciences, George
Washington University, Washington, DC, 20052, USA, QIMR Berghofer Medical
Research Institute, Infectious Disease and Cancer and The University of
Queensland, School of Biomedical Sciences, Brisbane, Queensland, 4072, Australia.
(2)Department of Microbiology, Immunology and Tropical Medicine, Research Center 
for Neglected Diseases of Poverty, School of Medicine and Health Sciences, George
Washington University, Washington, DC, 20052, USA, QIMR Berghofer Medical
Research Institute, Infectious Disease and Cancer and The University of
Queensland, School of Biomedical Sciences, Brisbane, Queensland, 4072, Australia.

MOTIVATION: BioClojure is an open-source library for the manipulation of
biological sequence data written in the language Clojure. BioClojure aims to
provide a functional framework for the processing of biological sequence data
that provides simple mechanisms for concurrency and lazy evaluation of large
datasets.
RESULTS: BioClojure provides parsers and accessors for a range of biological
sequence formats, including UniProtXML, Genbank XML, FASTA and FASTQ. In
addition, it provides wrappers for key analysis programs, including BLAST,
SignalP, TMHMM and InterProScan, and parsers for analyzing their output. All
interfaces leverage Clojure's functional style and emphasize laziness and
composability, so that BioClojure, and user-defined, functions can be chained
into simple pipelines that are thread-safe and seamlessly integrate lazy
evaluation.
AVAILABILITY AND IMPLEMENTATION: BioClojure is distributed under the Lesser GPL, 
and the source code is freely available from GitHub
(https://github.com/s312569/clj-biosequence).

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu311 
PMCID: PMC4147884
PMID: 24794932  [PubMed - indexed for MEDLINE]


1269. Bioinformatics. 2014 Aug 15;30(16):2381-3. doi: 10.1093/bioinformatics/btu300.
Epub 2014 Apr 29.

Vacceed: a high-throughput in silico vaccine candidate discovery pipeline for
eukaryotic pathogens based on reverse vaccinology.

Goodswen SJ(1), Kennedy PJ(1), Ellis JT(1).

Author information: 
(1)School of Medical and Molecular Biosciences, The ithree Institute and Faculty 
of Engineering and Information Technology, School of Software, The Centre for
Quantum Computation and Intelligent Systems, University of Technology Sydney
(UTS), Ultimo, NSW 2007, Australia.

We present Vacceed, a highly configurable and scalable framework designed to
automate the process of high-throughput in silico vaccine candidate discovery for
eukaryotic pathogens. Given thousands of protein sequences from the target
pathogen as input, the main output is a ranked list of protein candidates
determined by a set of machine learning algorithms. Vacceed has the potential to 
save time and money by reducing the number of false candidates allocated for
laboratory validation. Vacceed, if required, can also predict protein sequences
from the pathogen's genome.AVAILABILITY AND IMPLEMENTATION: Vacceed is tested on 
Linux and can be freely downloaded from
https://github.com/sgoodswe/vacceed/releases (includes a worked example with
sample data). Vacceed User Guide can be obtained from
https://github.com/sgoodswe/vacceed.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu300 
PMCID: PMC4207429
PMID: 24790156  [PubMed - indexed for MEDLINE]


1270. Bioinformatics. 2014 Aug 15;30(16):2272-9. doi: 10.1093/bioinformatics/btu201.
Epub 2014 Apr 20.

Efficient Bayesian inference under the structured coalescent.

Vaughan TG(1), Kühnert D(2), Popinga A(3), Welch D(3), Drummond AJ(3).

Author information: 
(1)Allan Wilson Centre for Molecular Ecology and Evolution, Massey University,
Palmerston North 4442, New Zealand, Institute of Integrative Biology, Swiss
Federal Institute of Technology (ETH), Zurich 8092, Switzerland and Department of
Computer Science, University of Auckland, Auckland 1142, New Zealand. (2)Allan
Wilson Centre for Molecular Ecology and Evolution, Massey University, Palmerston 
North 4442, New Zealand, Institute of Integrative Biology, Swiss Federal
Institute of Technology (ETH), Zurich 8092, Switzerland and Department of
Computer Science, University of Auckland, Auckland 1142, New ZealandAllan Wilson 
Centre for Molecular Ecology and Evolution, Massey University, Palmerston North
4442, New Zealand, Institute of Integrative Biology, Swiss Federal Institute of
Technology (ETH), Zurich 8092, Switzerland and Department of Computer Science,
University of Auckland, Auckland 1142, New ZealandAllan Wilson Centre for
Molecular Ecology and Evolution, Massey University, Palmerston North 4442, New
Zealand, Institute of Integrative Biology, Swiss Federal Institute of Technology 
(ETH), Zurich 8092, Switzerland and Department of Computer Science, University of
Auckland, Auckland 1142, New Zealand. (3)Allan Wilson Centre for Molecular
Ecology and Evolution, Massey University, Palmerston North 4442, New Zealand,
Institute of Integrative Biology, Swiss Federal Institute of Technology (ETH),
Zurich 8092, Switzerland and Department of Computer Science, University of
Auckland, Auckland 1142, New ZealandAllan Wilson Centre for Molecular Ecology and
Evolution, Massey University, Palmerston North 4442, New Zealand, Institute of
Integrative Biology, Swiss Federal Institute of Technology (ETH), Zurich 8092,
Switzerland and Department of Computer Science, University of Auckland, Auckland 
1142, New Zealand.

MOTIVATION: Population structure significantly affects evolutionary dynamics.
Such structure may be due to spatial segregation, but may also reflect any other 
gene-flow-limiting aspect of a model. In combination with the structured
coalescent, this fact can be used to inform phylogenetic tree reconstruction, as 
well as to infer parameters such as migration rates and subpopulation sizes from 
annotated sequence data. However, conducting Bayesian inference under the
structured coalescent is impeded by the difficulty of constructing Markov Chain
Monte Carlo (MCMC) sampling algorithms (samplers) capable of efficiently
exploring the state space.
RESULTS: In this article, we present a new MCMC sampler capable of sampling from 
posterior distributions over structured trees: timed phylogenetic trees in which 
lineages are associated with the distinct subpopulation in which they lie. The
sampler includes a set of MCMC proposal functions that offer significant mixing
improvements over a previously published method. Furthermore, its implementation 
as a BEAST 2 package ensures maximum flexibility with respect to model and prior 
specification. We demonstrate the usefulness of this new sampler by using it to
infer migration rates and effective population sizes of H3N2 influenza between
New Zealand, New York and Hong Kong from publicly available hemagglutinin (HA)
gene sequences under the structured coalescent.
AVAILABILITY AND IMPLEMENTATION: The sampler has been implemented as a publicly
available BEAST 2 package that is distributed under version 3 of the GNU General 
Public License at http://compevol.github.io/MultiTypeTree.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu201 
PMCID: PMC4207426
PMID: 24753484  [PubMed - indexed for MEDLINE]


1271. Nucleic Acids Res. 2014 Jun;42(11):6826-38. doi: 10.1093/nar/gku323. Epub 2014
Apr 21.

TEMP: a computational method for analyzing transposable element polymorphism in
populations.

Zhuang J(1), Wang J(1), Theurkauf W(2), Weng Z(3).

Author information: 
(1)Program in Bioinformatics and Integrative Biology, Department of Biochemistry 
and Molecular Pharmacology. (2)Program in Cell and Developmental Dynamics Program
in Molecular Medicine, and University of Massachusetts Medical School, Worcester,
MA 01605, USA william.theurkauf@umassmed.edu. (3)Program in Bioinformatics and
Integrative Biology, Department of Biochemistry and Molecular Pharmacology
zhiping.weng@umassmed.edu.

Insertions and excisions of transposable elements (TEs) affect both the stability
and variability of the genome. Studying the dynamics of transposition at the
population level can provide crucial insights into the processes and mechanisms
of genome evolution. Pooling genomic materials from multiple individuals followed
by high-throughput sequencing is an efficient way of characterizing genomic
polymorphisms in a population. Here we describe a novel method named TEMP,
specifically designed to detect TE movements present with a wide range of
frequencies in a population. By combining the information provided by pair-end
reads and split reads, TEMP is able to identify both the presence and absence of 
TE insertions in genomic DNA sequences derived from heterogeneous samples;
accurately estimate the frequencies of transposition events in the population and
pinpoint junctions of high frequency transposition events at nucleotide
resolution. Simulation data indicate that TEMP outperforms other algorithms such 
as PoPoolationTE, RetroSeq, VariationHunter and GASVPro. TEMP also performs well 
on whole-genome human data derived from the 1000 Genomes Project. We applied TEMP
to characterize the TE frequencies in a wild Drosophila melanogaster population
and study the inheritance patterns of TEs during hybrid dysgenesis. We also
identified sequence signatures of TE insertion and possible molecular effects of 
TE movements, such as altered gene expression and piRNA production. TEMP is
freely available at github: https://github.com/JialiUMassWengLab/TEMP.git.

© The Author(s) 2014. Published by Oxford University Press on behalf of Nucleic
Acids Research.

DOI: 10.1093/nar/gku323 
PMCID: PMC4066757
PMID: 24753423  [PubMed - indexed for MEDLINE]


1272. Methods Mol Biol. 2014;1150:81-95. doi: 10.1007/978-1-4939-0512-6_4.

Use model-based Analysis of ChIP-Seq (MACS) to analyze short reads generated by
sequencing protein-DNA interactions in embryonic stem cells.

Liu T(1).

Author information: 
(1)Department of Biochemistry, University at Buffalo-COEBLS, 701 Ellicott St,
B2-163, Buffalo, NY, 14203-1221, USA, tliu4@buffalo.edu.

Model-based Analysis of ChIP-Seq (MACS) is a computational algorithm for
identifying genome-wide protein-DNA interaction from ChIP-Seq data. MACS combines
multiple modules to process aligned ChIP-Seq reads for either transcription
factor or histone modification by removing redundant reads, estimating fragment
length, building signal profile, calculating peak enrichment, and refining and
reporting peak calls. In this protocol, we provide a detailed demonstration of
how to apply MACS to analyze ChIP-Seq datasets related to protein-DNA
interactions in embryonic stem cells (ES cells). Instruction on how to interpret 
and visualize the results is also provided. MACS is an open-source and is
available from http://github.com/taoliu/MACS.

DOI: 10.1007/978-1-4939-0512-6_4 
PMID: 24743991  [PubMed - indexed for MEDLINE]


1273. Version 2. F1000Res. 2014 Feb 13 [revised 2014 Apr 9];3:47. doi:
10.12688/f1000research.3-47.v2. eCollection 2014.

FeatureViewer, a BioJS component for visualization of position-based annotations 
in protein sequences.

Garcia L(1), Yachdav G(2), Martin MJ(1).

Author information: 
(1)European Bioinformatics Institute EMBL-EBI, Hinxton, Cambridge, CB10 1SD, UK. 
(2)TUM, Department of Informatics, Bioinformatics and Computational Biology-I12, 
85748 Garching, Germany.

SUMMARY: FeatureViewer is a BioJS component that lays out, maps, orients, and
renders position-based annotations for protein sequences. This component is
highly flexible and customizable, allowing the presentation of annotations by
rows, all centered, or distributed in non-overlapping tracks. It uses either
lines or shapes for sites and rectangles for regions. The result is a powerful
visualization tool that can be easily integrated into web applications as well as
documents as it provides an export-to-image functionality.
AVAILABILITY:
https://github.com/biojs/biojs/blob/master/src/main/javascript/Biojs.FeatureViewe
r.js; http://dx.doi.org/10.5281/zenodo.7719.

DOI: 10.12688/f1000research.3-47.v2 
PMCID: PMC3983936
PMID: 24741440  [PubMed]


1274. Bioinformatics. 2014 Aug 1;30(15):2179-88. doi: 10.1093/bioinformatics/btu196.
Epub 2014 Apr 14.

Association analysis using next-generation sequence data from publicly available 
control groups: the robust variance score statistic.

Derkach A(1), Chiang T(1), Gong J(1), Addis L(1), Dobbins S(1), Tomlinson I(1),
Houlston R(1), Pal DK(1), Strug LJ(2).

Author information: 
(1)Department of Statistical Science, University of Toronto, Toronto, ON, Canada,
Program in Child Health Evaluative Sciences, the Hospital for Sick Children
Research Institute, Toronto, ON, Canada, Department of Clinical Neuroscience,
Institute of Psychiatry, King's College London, London, Division of Genetics and 
Epidemiology, Institute of Cancer Research, Sutton, Surrey, Molecular and
Population Genetics and NIHR Comprehensive Biomedical Research Centre, Wellcome
Trust Centre for Human Genetics, University of Oxford, Oxford, UK, Division of
Biostatistics, Dalla Lana School of Public Health, University of Toronto,
Toronto, ON, Canada. (2)Department of Statistical Science, University of Toronto,
Toronto, ON, Canada, Program in Child Health Evaluative Sciences, the Hospital
for Sick Children Research Institute, Toronto, ON, Canada, Department of Clinical
Neuroscience, Institute of Psychiatry, King's College London, London, Division of
Genetics and Epidemiology, Institute of Cancer Research, Sutton, Surrey,
Molecular and Population Genetics and NIHR Comprehensive Biomedical Research
Centre, Wellcome Trust Centre for Human Genetics, University of Oxford, Oxford,
UK, Division of Biostatistics, Dalla Lana School of Public Health, University of 
Toronto, Toronto, ON, CanadaDepartment of Statistical Science, University of
Toronto, Toronto, ON, Canada, Program in Child Health Evaluative Sciences, the
Hospital for Sick Children Research Institute, Toronto, ON, Canada, Department of
Clinical Neuroscience, Institute of Psychiatry, King's College London, London,
Division of Genetics and Epidemiology, Institute of Cancer Research, Sutton,
Surrey, Molecular and Population Genetics and NIHR Comprehensive Biomedical
Research Centre, Wellcome Trust Centre for Human Genetics, University of Oxford, 
Oxford, UK, Division of Biostatistics, Dalla Lana School of Public Health,
University of Toronto, Toronto, ON, Canada.

MOTIVATION: Sufficiently powered case-control studies with next-generation
sequence (NGS) data remain prohibitively expensive for many investigators. If
feasible, a more efficient strategy would be to include publicly available
sequenced controls. However, these studies can be confounded by differences in
sequencing platform; alignment, single nucleotide polymorphism and variant
calling algorithms; read depth; and selection thresholds. Assuming one can match 
cases and controls on the basis of ethnicity and other potential confounding
factors, and one has access to the aligned reads in both groups, we investigate
the effect of systematic differences in read depth and selection threshold when
comparing allele frequencies between cases and controls. We propose a novel
likelihood-based method, the robust variance score (RVS), that substitutes
genotype calls by their expected values given observed sequence data.
RESULTS: We show theoretically that the RVS eliminates read depth bias in the
estimation of minor allele frequency. We also demonstrate that, using simulated
and real NGS data, the RVS method controls Type I error and has comparable power 
to the 'gold standard' analysis with the true underlying genotypes for both
common and rare variants.
AVAILABILITY AND IMPLEMENTATION: An RVS R script and instructions can be found at
strug.research.sickkids.ca, and at https://github.com/strug-lab/RVS.
CONTACT: lisa.strug@utoronto.ca
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu196 
PMCID: PMC4103600
PMID: 24733292  [PubMed - indexed for MEDLINE]


1275. Bioinformatics. 2014 Aug 1;30(15):2130-6. doi: 10.1093/bioinformatics/btu183.
Epub 2014 Apr 10.

Lossy compression of quality scores in genomic data.

Cánovas R(1), Moffat A(1), Turpin A(1).

Author information: 
(1)NICTA Victoria Research Laboratory, Department of Computing and Information
Systems, The University of Melbourne, Victoria 3010, Australia.

MOTIVATION: Next-generation sequencing technologies are revolutionizing medicine.
Data from sequencing technologies are typically represented as a string of bases,
an associated sequence of per-base quality scores and other metadata, and in
aggregate can require a large amount of space. The quality scores show how
accurate the bases are with respect to the sequencing process, that is, how
confident the sequencer is of having called them correctly, and are the largest
component in datasets in which they are retained. Previous research has examined 
how to store sequences of bases effectively; here we add to that knowledge by
examining methods for compressing quality scores. The quality values originate in
a continuous domain, and so if a fidelity criterion is introduced, it is possible
to introduce flexibility in the way these values are represented, allowing lossy 
compression over the quality score data.
RESULTS: We present existing compression options for quality score data, and then
introduce two new lossy techniques. Experiments measuring the trade-off between
compression ratio and information loss are reported, including quantifying the
effect of lossy representations on a downstream application that carries out
single nucleotide polymorphism and insert/deletion detection. The new methods are
demonstrably superior to other techniques when assessed against the spectrum of
possible trade-offs between storage required and fidelity of representation.
AVAILABILITY AND IMPLEMENTATION: An implementation of the methods described here 
is available at https://github.com/rcanovas/libCSAM.
CONTACT: rcanovas@student.unimelb.edu.au
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu183 
PMID: 24728856  [PubMed - indexed for MEDLINE]


1276. Bioinformatics. 2014 Aug 1;30(15):2216-8. doi: 10.1093/bioinformatics/btu181.
Epub 2014 Apr 10.

geiger v2.0: an expanded suite of methods for fitting macroevolutionary models to
phylogenetic trees.

Pennell MW(1), Eastman JM(1), Slater GJ(1), Brown JW(2), Uyeda JC(1), FitzJohn
RG(1), Alfaro ME(1), Harmon LJ(1).

Author information: 
(1)Department of Biological Sciences and Institute for Bioinformatics and
Evolutionary Studies, University of Idaho, Moscow, ID 83844, Department of
Paleobiology, National Museum of Natural History, Smithsonian Institution,
Washington, DC 20013, Department of Ecology and Evolutionary Biology, University 
of Michigan, Ann Arbor, MI 48109, USA, Department of Biological Sciences,
Macquarie University, Sydney, NSW 2109, Australia and Department of Ecology and
Evolutionary Biology, University of California, Los Angeles, Los Angeles, CA
90095, USA. (2)Department of Biological Sciences and Institute for Bioinformatics
and Evolutionary Studies, University of Idaho, Moscow, ID 83844, Department of
Paleobiology, National Museum of Natural History, Smithsonian Institution,
Washington, DC 20013, Department of Ecology and Evolutionary Biology, University 
of Michigan, Ann Arbor, MI 48109, USA, Department of Biological Sciences,
Macquarie University, Sydney, NSW 2109, Australia and Department of Ecology and
Evolutionary Biology, University of California, Los Angeles, Los Angeles, CA
90095, USADepartment of Biological Sciences and Institute for Bioinformatics and 
Evolutionary Studies, University of Idaho, Moscow, ID 83844, Department of
Paleobiology, National Museum of Natural History, Smithsonian Institution,
Washington, DC 20013, Department of Ecology and Evolutionary Biology, University 
of Michigan, Ann Arbor, MI 48109, USA, Department of Biological Sciences,
Macquarie University, Sydney, NSW 2109, Australia and Department of Ecology and
Evolutionary Biology, University of California, Los Angeles, Los Angeles, CA
90095, USA.

SUMMARY: Phylogenetic comparative methods are essential for addressing
evolutionary hypotheses with interspecific data. The scale and scope of such data
have increased dramatically in the past few years. Many existing approaches are
either computationally infeasible or inappropriate for data of this size. To
address both of these problems, we present geiger v2.0, a complete overhaul of
the popular R package geiger. We have reimplemented existing methods with more
efficient algorithms and have developed several new approaches for accomodating
heterogeneous models and data types.
AVAILABILITY AND IMPLEMENTATION:  This R package is available on the CRAN
repository http://cran.r-project.org/web/packages/geiger/. All source code is
also available on github http://github.com/mwpennell/geiger-v2. geiger v2.0
depends on the ape package.
CONTACT: mwpennell@gmail.com
SUPPLEMENTARY INFORMATION:  Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu181 
PMID: 24728855  [PubMed - indexed for MEDLINE]


1277. Nat Methods. 2014 Jun;11(6):689-94. doi: 10.1038/nmeth.2924. Epub 2014 Apr 13.

Multiscale representation of genomic signals.

Knijnenburg TA(1), Ramsey SA(2), Berman BP(3), Kennedy KA(4), Smit AF(1), Wessels
LF(5), Laird PW(3), Aderem A(4), Shmulevich I(1).

Author information: 
(1)Institute for Systems Biology, Seattle, Washington, USA. (2)1] Seattle
Biomedical Research Institute, Seattle, Washington, USA. [2]. (3)University of
Southern California Epigenome Center, University of Southern California, Keck
School of Medicine, Los Angeles, California, USA. (4)Seattle Biomedical Research 
Institute, Seattle, Washington, USA. (5)1] Division of Molecular Carcinogenesis, 
Netherlands Cancer Institute, Amsterdam, The Netherlands. [2] Faculty of
Electrical Engineering, Mathematics and Computer Science, Delft University of
Technology, Delft, The Netherlands.

Genomic information is encoded on a wide range of distance scales, ranging from
tens of bases to megabases. We developed a multiscale framework to analyze and
visualize the information content of genomic signals. Different types of signals,
such as G+C content or DNA methylation, are characterized by distinct patterns of
signal enrichment or depletion across scales spanning several orders of
magnitude. These patterns are associated with a variety of genomic annotations.
By integrating the information across all scales, we demonstrated improved
prediction of gene expression from polymerase II chromatin immunoprecipitation
sequencing (ChIP-seq) measurements, and we observed that gene expression
differences in colorectal cancer are related to methylation patterns that extend 
beyond the single-gene scale. Our software is available at
https://github.com/tknijnen/msr/.

DOI: 10.1038/nmeth.2924 
PMCID: PMC4040162
PMID: 24727652  [PubMed - indexed for MEDLINE]


1278. F1000Res. 2014 Feb 13;3:43. doi: 10.12688/f1000research.3-43.v1. eCollection
2014.

KEGGViewer, a BioJS component to visualize KEGG Pathways.

Villaveces JM(1), Jimenez RC(2), Habermann BH(1).

Author information: 
(1)Max Planck Institute of Biochemistry, Am Klopferspitz 18, 82152, Germany.
(2)European Bioinformatics Institute, Wellcome Trust Genome Campus, Hinxton,
Cambridge, CB10 1SD, UK.

SUMMARY: Signaling pathways provide essential information on complex regulatory
processes within the cell. They are moreover widely used to interpret and
integrate data from large-scale studies, such as expression or functional
screens. We present KEGGViewer a BioJS component to visualize KEGG pathways and
to allow their visual integration with functional data.
AVAILABILITY: KEGGViewer is an open-source tool freely available at the BioJS
Registry. Instructions on how to use the tool are available at
http://goo.gl/dVeWpg and the source code can be found at
http://github.com/biojs/biojs and DOI: 10.5281/zenodo.7708.

DOI: 10.12688/f1000research.3-43.v1 
PMCID: PMC3954160
PMID: 24715980  [PubMed]


1279. PLoS Curr. 2014 Apr 2;6. pii: ecurrents.tol.c24b6054aebf3602748ac042ccc8f2e9.
doi: 10.1371/currents.tol.c24b6054aebf3602748ac042ccc8f2e9.

Building a phylogenomic pipeline for the eukaryotic tree of life - addressing
deep phylogenies with genome-scale data.

Grant JR(1), Katz LA(1).

Author information: 
(1)Department of Biological Sciences, Smith College, Northampton, Massachusetts, 
USA.

Erratum in
    PLoS Curr. 2015;7. pii: ecurrents.tol.e089df47766ed1e9dabac39c76bae266. doi:
10.1371/currents.tol.e089df47766ed1e9dabac39c76bae266.

Background Understanding the evolutionary relationships of all eukaryotes on
Earth remains a paramount goal of modern biology, yet analyzing homologous
sequences across 1.8 billion years of eukaryotic evolution is challenging. Many
existing tools for identifying gene orthologs are inadequate when working with
heterogeneous rates of evolution and endosymbiotic/lateral gene transfer.
Moreover, genomic-scale sequencing, which was once the domain of large sequencing
centers, has advanced to the point where small laboratories can now generate the 
data needed for phylogenomic studies. This has opened the door for increased
taxonomic sampling as individual research groups have the ability to conduct
genome-scale projects on their favorite non-model organism. Results Here we
present some of the tools developed, and insights gained, as we created a
pipeline that combines data-mining from public databases and our own
transcriptome data to study the eukaryotic tree of life. The first steps of a
phylogenomic pipeline involve choosing taxa and loci, and making decisions about 
how to handle alleles, paralogs and non-overlapping sequences. Next, orthologs
are aligned for analyses including gene tree reconstruction and concatenation for
supermatrix approaches. To build our pipeline, we created scripts written in
Python that integrate third-party tools with custom methods. As a test case, we
present the placement of five amoebae on the eukaryotic tree of life based on
analyses of transcriptome data. Our scripts available on GitHUb and may be used
as-is for automated analyses of large scale phylogenomics, or adapted for use in 
other types of studies. Conclusion Analyses on the scale of all eukaryotes
present challenges not necessarily found in studies of more closely related
organisms. Our approach will be of relevance to others for whom existing
third-party tools fail to fully answer desired phylogenetic questions.

DOI: 10.1371/currents.tol.c24b6054aebf3602748ac042ccc8f2e9 
PMCID: PMC3973741
PMID: 24707447  [PubMed]


1280. Genomics. 2014 May-Jun;103(5-6):323-8. doi: 10.1016/j.ygeno.2014.03.006. Epub
2014 Apr 3.

Multi-perspective quality control of Illumina exome sequencing data using QC3.

Guo Y(1), Zhao S(2), Sheng Q(3), Ye F(4), Li J(5), Lehmann B(6), Pietenpol J(7), 
Samuels DC(8), Shyr Y(9).

Author information: 
(1)Vanderbilt Ingram Cancer Center, Center for Quantitative Sciences, Nashville, 
TN, USA. Electronic address: yan.guo@vanderbilt.edu. (2)Vanderbilt Ingram Cancer 
Center, Center for Quantitative Sciences, Nashville, TN, USA. Electronic address:
shilin.zhao@vanderbilt.edu. (3)Vanderbilt Ingram Cancer Center, Center for
Quantitative Sciences, Nashville, TN, USA. Electronic address:
Quanhu.sheng@vanderbilt.edu. (4)Vanderbilt Ingram Cancer Center, Center for
Quantitative Sciences, Nashville, TN, USA. Electronic address:
Fei.ye@vanderbilt.edu. (5)Vanderbilt Ingram Cancer Center, Center for
Quantitative Sciences, Nashville, TN, USA. Electronic address:
riverlee2008@gmail.com. (6)Department of Biochemistry, Vanderbilt University,
Nashville, TN 37027, USA. Electronic address: brian.d.lehmann@vanderbilt.edu.
(7)Department of Biochemistry, Vanderbilt University, Nashville, TN 37027, USA.
Electronic address: j.pietenpol@vanderbilt.edu. (8)Center for Human Genetics
Research, Vanderbilt University Medical Center, Nashville, TN, USA. Electronic
address: david.samuels@chgr.mc.vanderbilt.edu. (9)Vanderbilt Ingram Cancer
Center, Center for Quantitative Sciences, Nashville, TN, USA. Electronic address:
yu.shyr@Vanderbilt.Edu.

Advances in next-generation sequencing (NGS) technologies have greatly improved
our ability to detect genomic variants for biomedical research. The advance in
NGS technologies has also created significant challenges in bioinformatics. One
of the major challenges is the quality control of sequencing data. There has been
heavy focus on performing raw data quality control. In order to correctly
interpret the quality of the DNA sequencing data, however, proper quality control
should be conducted at all stages of DNA sequencing data analysis: raw data,
alignment, and variant detection. We designed QC3, a quality control tool aimed
at those three major stages of DNA sequencing. QC3 monitors quality control
metrics at each stage of NGS data and provides unique and independent evaluations
of the data quality from different perspectives. QC3 offers unique features such 
as detection of batch effect and cross contamination. QC3 and its source code are
freely downloadable at https://github.com/slzhao/QC3.

Copyright © 2014 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.ygeno.2014.03.006 
PMID: 24703969  [PubMed - indexed for MEDLINE]


1281. Proteomics. 2014 Jun;14(12):1464-6. doi: 10.1002/pmic.201400036. Epub 2014 May
15.

GradientOptimizer: an open-source graphical environment for calculating optimized
gradients in reversed-phase liquid chromatography.

Moruz L(1), Käll L.

Author information: 
(1)Science for Life Laboratory, Department of Biochemistry and Biophysics,
Stockholm University, Solna, Sweden.

We here present GradientOptimizer, an intuitive, lightweight graphical user
interface to design nonlinear gradients for separation of peptides by
reversed-phase liquid chromatography. The software allows to calculate three
types of nonlinear gradients, each of them optimizing a certain retention time
distribution of interest. GradientOptimizer is straightforward to use, requires
minimum processing of the input files, and is supported under Windows, Linux, and
OS X platforms. The software is open-source and can be downloaded under an Apache
2.0 license at https://github.com/statisticalbiotechnology/NonlinearGradientsUI.

© 2014 WILEY-VCH Verlag GmbH & Co. KGaA, Weinheim.

DOI: 10.1002/pmic.201400036 
PMID: 24700534  [PubMed - indexed for MEDLINE]


1282. PLoS One. 2014 Apr 2;9(4):e93379. doi: 10.1371/journal.pone.0093379. eCollection 
2014.

Exploiting SNP correlations within random forest for genome-wide association
studies.

Botta V(1), Louppe G(1), Geurts P(1), Wehenkel L(1).

Author information: 
(1)Department of EE and CS & GIGA-Research, University of Liège, Belgium.

The primary goal of genome-wide association studies (GWAS) is to discover
variants that could lead, in isolation or in combination, to a particular trait
or disease. Standard approaches to GWAS, however, are usually based on univariate
hypothesis tests and therefore can account neither for correlations due to
linkage disequilibrium nor for combinations of several markers. To discover and
leverage such potential multivariate interactions, we propose in this work an
extension of the Random Forest algorithm tailored for structured GWAS data. In
terms of risk prediction, we show empirically on several GWAS datasets that the
proposed T-Trees method significantly outperforms both the original Random Forest
algorithm and standard linear models, thereby suggesting the actual existence of 
multivariate non-linear effects due to the combinations of several SNPs. We also 
demonstrate that variable importances as derived from our method can help
identify relevant loci. Finally, we highlight the strong impact that quality
control procedures may have, both in terms of predictive power and loci
identification. Variable importance results and T-Trees source code are all
available at www.montefiore.ulg.ac.be/~botta/ttrees/ and
github.com/0asa/TTree-source respectively.

DOI: 10.1371/journal.pone.0093379 
PMCID: PMC3973686
PMID: 24695491  [PubMed - indexed for MEDLINE]


1283. Bioinformatics. 2014 Aug 1;30(15):2121-9. doi: 10.1093/bioinformatics/btu174.
Epub 2014 Apr 2.

Deconvolving tumor purity and ploidy by integrating copy number alterations and
loss of heterozygosity.

Li Y(1), Xie X(2).

Author information: 
(1)Department of Computer Science, Institute for Genomics and Bioinformatics and 
Center for Machine Learning and Intelligent Systems, University of California,
Irvine, CA 92697, USA. (2)Department of Computer Science, Institute for Genomics 
and Bioinformatics and Center for Machine Learning and Intelligent Systems,
University of California, Irvine, CA 92697, USADepartment of Computer Science,
Institute for Genomics and Bioinformatics and Center for Machine Learning and
Intelligent Systems, University of California, Irvine, CA 92697, USADepartment of
Computer Science, Institute for Genomics and Bioinformatics and Center for
Machine Learning and Intelligent Systems, University of California, Irvine, CA
92697, USA.

Erratum in
    Bioinformatics. 2015 Feb 15;31(4):618.

MOTIVATION: Next-generation sequencing (NGS) has revolutionized the study of
cancer genomes. However, the reads obtained from NGS of tumor samples often
consist of a mixture of normal and tumor cells, which themselves can be of
multiple clonal types. A prominent problem in the analysis of cancer genome
sequencing data is deconvolving the mixture to identify the reads associated with
tumor cells or a particular subclone of tumor cells. Solving the problem is,
however, challenging because of the so-called 'identifiability problem', where
different combinations of tumor purity and ploidy often explain the sequencing
data equally well.
RESULTS: We propose a new model to resolve the identifiability problem by
integrating two types of sequencing information-somatic copy number alterations
and loss of heterozygosity-within a unified probabilistic framework. We derive
algorithms to solve our model, and implement them in a software package called
PyLOH. We benchmark the performance of PyLOH using both simulated data and 12
breast cancer sequencing datasets and show that PyLOH outperforms existing
methods in disambiguating the identifiability problem and estimating tumor
purity.
AVAILABILITY AND IMPLEMENTATION: The PyLOH package is written in Python and is
publicly available at https://github.com/uci-cbcl/PyLOH.
CONTACT: xhx@ics.uci.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu174 
PMCID: PMC4103592
PMID: 24695406  [PubMed - indexed for MEDLINE]


1284. PeerJ. 2014 Mar 4;2:e277. doi: 10.7717/peerj.277. eCollection 2014.

FragBuilder: an efficient Python library to setup quantum chemistry calculations 
on peptides models.

Christensen AS(1), Hamelryck T(2), Jensen JH(1).

Author information: 
(1)Department of Chemistry, University of Copenhagen , Copenhagen , Denmark.
(2)Department of Biology, University of Copenhagen , Copenhagen , Denmark.

We present a powerful Python library to quickly and efficiently generate
realistic peptide model structures. The library makes it possible to quickly set 
up quantum mechanical calculations on model peptide structures. It is possible to
manually specify a specific conformation of the peptide. Additionally the library
also offers sampling of backbone conformations and side chain rotamer
conformations from continuous distributions. The generated peptides can then be
geometry optimized by the MMFF94 molecular mechanics force field via convenient
functions inside the library. Finally, it is possible to output the resulting
structures directly to files in a variety of useful formats, such as XYZ or PDB
formats, or directly as input files for a quantum chemistry program. FragBuilder 
is freely available at https://github.com/jensengroup/fragbuilder/ under the
terms of the BSD open source license.

DOI: 10.7717/peerj.277 
PMCID: PMC3961104
PMID: 24688855  [PubMed]


1285. J Mol Biol. 2014 May 29;426(11):2255-68. doi: 10.1016/j.jmb.2014.03.010. Epub
2014 Mar 26.

Systematic detection of internal symmetry in proteins using CE-Symm.

Myers-Turnbull D(1), Bliven SE(2), Rose PW(3), Aziz ZK(4), Youkharibache P(5),
Bourne PE(6), Prlić A(7).

Author information: 
(1)Department of Computer Science and Engineering, University of California San
Diego, La Jolla, CA 92093, USA. (2)Bioinformatics and Systems Biology Program,
University of California San Diego, La Jolla, CA 92093, USA. (3)San Diego
Supercomputer Center, University of California San Diego, La Jolla, CA 92093,
USA. (4)Department of Chemistry and Biochemistry, University of California San
Diego, La Jolla, CA 92093, USA. (5)InPharmatics Corporation, 4203 Genesee Avenue 
Suite 103, San Diego, CA 92117, USA. (6)Skaggs School of Pharmacy and
Pharmaceutical Sciences, University of California San Diego, La Jolla, CA 92093, 
USA. Electronic address: pbourne@ucsd.edu. (7)San Diego Supercomputer Center,
University of California San Diego, La Jolla, CA 92093, USA. Electronic address: 
andreas.prlic@gmail.com.

Symmetry is an important feature of protein tertiary and quaternary structures
that has been associated with protein folding, function, evolution, and
stability. Its emergence and ensuing prevalence has been attributed to gene
duplications, fusion events, and subsequent evolutionary drift in sequence. This 
process maintains structural similarity and is further supported by this study.
To further investigate the question of how internal symmetry evolved, how
symmetry and function are related, and the overall frequency of internal
symmetry, we developed an algorithm, CE-Symm, to detect pseudo-symmetry within
the tertiary structure of protein chains. Using a large manually curated
benchmark of 1007 protein domains, we show that CE-Symm performs significantly
better than previous approaches. We use CE-Symm to build a census of symmetry
among domain superfamilies in SCOP and note that 18% of all superfamilies are
pseudo-symmetric. Our results indicate that more domains are pseudo-symmetric
than previously estimated. We establish a number of recurring types of
symmetry-function relationships and describe several characteristic cases in
detail. With the use of the Enzyme Commission classification, symmetry was found 
to be enriched in some enzyme classes but depleted in others. CE-Symm thus
provides a methodology for a more complete and detailed study of the role of
symmetry in tertiary protein structure [availability: CE-Symm can be run from the
Web at http://source.rcsb.org/jfatcatserver/symmetry.jsp. Source code and
software binaries are also available under the GNU Lesser General Public License 
(version 2.1) at https://github.com/rcsb/symmetry. An interactive census of
domains identified as symmetric by CE-Symm is available from
http://source.rcsb.org/jfatcatserver/scopResults.jsp].

Copyright © 2014. Published by Elsevier Ltd.

DOI: 10.1016/j.jmb.2014.03.010 
PMCID: PMC4456030
PMID: 24681267  [PubMed - indexed for MEDLINE]


1286. Hum Mutat. 2014 May;35(5):548-55. doi: 10.1002/humu.22531. Epub 2014 Apr 9.

Jannovar: a java library for exome annotation.

Jäger M(1), Wang K, Bauer S, Smedley D, Krawitz P, Robinson PN.

Author information: 
(1)Institute for Medical and Human Genetics, Charité-Universitätsmedizin Berlin, 
Berlin, Germany; Berlin Brandenburg Center for Regenerative Therapies (BCRT),
Charité-Universitätsmedizin Berlin, Berlin, Germany.

Transcript-based annotation and pedigree analysis are two basic steps in the
computational analysis of whole-exome sequencing experiments in genetic
diagnostics and disease-gene discovery projects. Here, we present Jannovar, a
stand-alone Java application as well as a Java library designed to be used in
larger software frameworks for exome and genome analysis. Jannovar uses an
interval tree to identify all transcripts affected by a given variant, and
provides Human Genome Variation Society-compliant annotations both for variants
affecting coding sequences and splice junctions as well as untranslated regions
and noncoding RNA transcripts. Jannovar can also perform family-based pedigree
analysis with Variant Call Format (VCF) files with data from members of a family 
segregating a Mendelian disorder. Using a desktop computer, Jannovar requires a
few seconds to annotate a typical VCF file with exome data. Jannovar is freely
available under the BSD2 license. Source code as well as the Java application and
library file can be downloaded from http://compbio.charite.de (with tutorial) and
https://github.com/charite/jannovar.

© 2014 WILEY PERIODICALS, INC.

DOI: 10.1002/humu.22531 
PMID: 24677618  [PubMed - indexed for MEDLINE]


1287. PLoS Comput Biol. 2014 Mar 27;10(3):e1003515. doi: 10.1371/journal.pcbi.1003515. 
eCollection 2014.

Viral quasispecies assembly via maximal clique enumeration.

Töpfer A(1), Marschall T(2), Bull RA(3), Luciani F(3), Schönhuth A(2),
Beerenwinkel N(1).

Author information: 
(1)Department of Biosystems Science and Engineering, ETH Zurich, Basel,
Switzerland; SIB Swiss Institute of Bioinformatics, Basel, Switzerland.
(2)Centrum Wiskunde & Informatica, Amsterdam, The Netherlands. (3)Inflammation
and Infection Research Centre, School of Medical Sciences, UNSW, Sydney,
Australia.

Virus populations can display high genetic diversity within individual hosts. The
intra-host collection of viral haplotypes, called viral quasispecies, is an
important determinant of virulence, pathogenesis, and treatment outcome. We
present HaploClique, a computational approach to reconstruct the structure of a
viral quasispecies from next-generation sequencing data as obtained from bulk
sequencing of mixed virus samples. We develop a statistical model for paired-end 
reads accounting for mutations, insertions, and deletions. Using an iterative
maximal clique enumeration approach, read pairs are assembled into haplotypes of 
increasing length, eventually enabling global haplotype assembly. The performance
of our quasispecies assembly method is assessed on simulated data for varying
population characteristics and sequencing technology parameters. Owing to its
paired-end handling, HaploClique compares favorably to state-of-the-art haplotype
inference methods. It can reconstruct error-free full-length haplotypes from low 
coverage samples and detect large insertions and deletions at low frequencies. We
applied HaploClique to sequencing data derived from a clinical hepatitis C virus 
population of an infected patient and discovered a novel deletion of length
357±167 bp that was validated by two independent long-read sequencing
experiments. HaploClique is available at
https://github.com/armintoepfer/haploclique. A summary of this paper appears in
the proceedings of the RECOMB 2014 conference, April 2-5.

DOI: 10.1371/journal.pcbi.1003515 
PMCID: PMC3967922
PMID: 24675810  [PubMed - indexed for MEDLINE]


1288. Front Neuroinform. 2014 Mar 14;8:24. doi: 10.3389/fninf.2014.00024. eCollection
2014.

BROCCOLI: Software for fast fMRI analysis on many-core CPUs and GPUs.

Eklund A(1), Dufort P(2), Villani M(3), Laconte S(4).

Author information: 
(1)Virginia Tech Carilion Research Institute, Virginia Tech Roanoke, VA, USA.
(2)Department of Medical Imaging, University of Toronto Toronto, ON, Canada.
(3)Division of Statistics, Department of Computer and Information Science,
Linköping University Linköping, Sweden. (4)Virginia Tech Carilion Research
Institute, Virginia Tech Roanoke, VA, USA ; School of Biomedical Engineering and 
Sciences, Virginia Tech-Wake Forest University Blacksburg, VA, USA.

Analysis of functional magnetic resonance imaging (fMRI) data is becoming ever
more computationally demanding as temporal and spatial resolutions improve, and
large, publicly available data sets proliferate. Moreover, methodological
improvements in the neuroimaging pipeline, such as non-linear spatial
normalization, non-parametric permutation tests and Bayesian Markov Chain Monte
Carlo approaches, can dramatically increase the computational burden. Despite
these challenges, there do not yet exist any fMRI software packages which
leverage inexpensive and powerful graphics processing units (GPUs) to perform
these analyses. Here, we therefore present BROCCOLI, a free software package
written in OpenCL (Open Computing Language) that can be used for parallel
analysis of fMRI data on a large variety of hardware configurations. BROCCOLI
has, for example, been tested with an Intel CPU, an Nvidia GPU, and an AMD GPU.
These tests show that parallel processing of fMRI data can lead to significantly 
faster analysis pipelines. This speedup can be achieved on relatively standard
hardware, but further, dramatic speed improvements require only a modest
investment in GPU hardware. BROCCOLI (running on a GPU) can perform non-linear
spatial normalization to a 1 mm(3) brain template in 4-6 s, and run a second
level permutation test with 10,000 permutations in about a minute. These
non-parametric tests are generally more robust than their parametric
counterparts, and can also enable more sophisticated analyses by estimating
complicated null distributions. Additionally, BROCCOLI includes support for
Bayesian first-level fMRI analysis using a Gibbs sampler. The new software is
freely available under GNU GPL3 and can be downloaded from github
(https://github.com/wanderine/BROCCOLI/).

DOI: 10.3389/fninf.2014.00024 
PMCID: PMC3953750
PMID: 24672471  [PubMed]


1289. PLoS One. 2014 Mar 25;9(3):e92108. doi: 10.1371/journal.pone.0092108. eCollection
2014.

Open source software to control Bioflo bioreactors.

Burdge DA(1), Libourel IG(2).

Author information: 
(1)Biotechnology Institute, University of Minnesota, Saint Paul, Minnesota,
United States of America. (2)Biotechnology Institute, University of Minnesota,
Saint Paul, Minnesota, United States of America; Department of Plant Biology,
University of Minnesota, Saint Paul, Minnesota, United States of America.

Bioreactors are designed to support highly controlled environments for growth of 
tissues, cell cultures or microbial cultures. A variety of bioreactors are
commercially available, often including sophisticated software to enhance the
functionality of the bioreactor. However, experiments that the bioreactor
hardware can support, but that were not envisioned during the software design
cannot be performed without developing custom software. In addition, support for 
third party or custom designed auxiliary hardware is often sparse or absent. This
work presents flexible open source freeware for the control of bioreactors of the
Bioflo product family. The functionality of the software includes setpoint
control, data logging, and protocol execution. Auxiliary hardware can be easily
integrated and controlled through an integrated plugin interface without altering
existing software. Simple experimental protocols can be entered as a CSV
scripting file, and a Python-based protocol execution model is included for more 
demanding conditional experimental control. The software was designed to be a
more flexible and free open source alternative to the commercially available
solution. The source code and various auxiliary hardware plugins are publicly
available for download from https://github.com/LibourelLab/BiofloSoftware. In
addition to the source code, the software was compiled and packaged as a
self-installing file for 32 and 64 bit windows operating systems. The compiled
software will be able to control a Bioflo system, and will not require the
installation of LabVIEW.

DOI: 10.1371/journal.pone.0092108 
PMCID: PMC3965399
PMID: 24667828  [PubMed - indexed for MEDLINE]


1290. J Neural Eng. 2014 Apr;11(2):026017. doi: 10.1088/1741-2560/11/2/026017. Epub
2014 Mar 24.

A fast, robust algorithm for power line interference cancellation in neural
recording.

Keshtkaran MR(1), Yang Z.

Author information: 
(1)Department of Electrical and Computer Engineering , National University of
Singapore, 117583 Singapore.

OBJECTIVE: Power line interference may severely corrupt neural recordings at
50/60 Hz and harmonic frequencies. The interference is usually non-stationary and
can vary in frequency, amplitude and phase. To retrieve the gamma-band
oscillations at the contaminated frequencies, it is desired to remove the
interference without compromising the actual neural signals at the interference
frequency bands. In this paper, we present a robust and computationally efficient
algorithm for removing power line interference from neural recordings.
APPROACH: The algorithm includes four steps. First, an adaptive notch filter is
used to estimate the fundamental frequency of the interference. Subsequently,
based on the estimated frequency, harmonics are generated by using discrete-time 
oscillators, and then the amplitude and phase of each harmonic are estimated by
using a modified recursive least squares algorithm. Finally, the estimated
interference is subtracted from the recorded data.
MAIN RESULTS: The algorithm does not require any reference signal, and can track 
the frequency, phase and amplitude of each harmonic. When benchmarked with other 
popular approaches, our algorithm performs better in terms of noise immunity,
convergence speed and output signal-to-noise ratio (SNR). While minimally
affecting the signal bands of interest, the algorithm consistently yields fast
convergence (<100 ms) and substantial interference rejection (output SNR >30 dB) 
in different conditions of interference strengths (input SNR from -30 to 30 dB), 
power line frequencies (45-65 Hz) and phase and amplitude drifts. In addition,
the algorithm features a straightforward parameter adjustment since the
parameters are independent of the input SNR, input signal power and the sampling 
rate. A hardware prototype was fabricated in a 65 nm CMOS process and tested.
Software implementation of the algorithm has been made available for open access 
at https://github.com/mrezak/removePLI.
SIGNIFICANCE: The proposed algorithm features a highly robust operation, fast
adaptation to interference variations, significant SNR improvement, low
computational complexity and memory requirement and straightforward parameter
adjustment. These features render the algorithm suitable for wearable and
implantable sensor applications, where reliable and real-time cancellation of the
interference is desired.

DOI: 10.1088/1741-2560/11/2/026017 
PMID: 24658388  [PubMed - indexed for MEDLINE]


1291. Neuroimage. 2014 Jul 15;95:217-31. doi: 10.1016/j.neuroimage.2014.03.037. Epub
2014 Mar 21.

Derivation of high-resolution MRI atlases of the human cerebellum at 3T and
segmentation using multiple automatically generated templates.

Park MT(1), Pipitone J(2), Baer LH(3), Winterburn JL(2), Shah Y(2), Chavez S(4), 
Schira MM(5), Lobaugh NJ(6), Lerch JP(7), Voineskos AN(8), Chakravarty MM(9).

Author information: 
(1)Kimel Family Translational Imaging Genetics Research Laboratory, Research
Imaging Centre, Centre for Addiction and Mental Health, Toronto, Canada.
Electronic address: mtpark89@gmail.com. (2)Kimel Family Translational Imaging
Genetics Research Laboratory, Research Imaging Centre, Centre for Addiction and
Mental Health, Toronto, Canada. (3)Department of Psychology, Concordia
University, Montreal, QC, Canada. (4)MRI Unit, Research Imaging Centre, Centre
for Addiction and Mental Health, Toronto, Canada; Department of Psychiatry,
University of Toronto, Toronto, Canada. (5)School of Psychology, University of
Wollongong, Wollongong, NSW, Australia; Neuroscience Research Australia, Sydney, 
NSW, Australia. (6)MRI Unit, Research Imaging Centre, Centre for Addiction and
Mental Health, Toronto, Canada; Division of Neurology, Department of Medicine,
University of Toronto, Toronto, Canada. (7)Program in Neuroscience and Mental
Health, Hospital for Sick Children, Toronto, Canada; Department of Medical
Biophysics, University of Toronto, Toronto, Canada. (8)Kimel Family Translational
Imaging Genetics Research Laboratory, Research Imaging Centre, Centre for
Addiction and Mental Health, Toronto, Canada; Department of Psychiatry,
University of Toronto, Toronto, Canada. (9)Kimel Family Translational Imaging
Genetics Research Laboratory, Research Imaging Centre, Centre for Addiction and
Mental Health, Toronto, Canada; Department of Psychiatry, University of Toronto, 
Toronto, Canada; Institute of Biomaterials and Biomedical Engineering, University
of Toronto, Toronto, Canada. Electronic address: mallar.chakravarty@camh.ca.

The cerebellum has classically been linked to motor learning and coordination.
However, there is renewed interest in the role of the cerebellum in non-motor
functions such as cognition and in the context of different neuropsychiatric
disorders. The contribution of neuroimaging studies to advancing understanding of
cerebellar structure and function has been limited, partly due to the cerebellum 
being understudied as a result of contrast and resolution limitations of standard
structural magnetic resonance images (MRI). These limitations inhibit proper
visualization of the highly compact and detailed cerebellar foliations. In
addition, there is a lack of robust algorithms that automatically and reliably
identify the cerebellum and its subregions, further complicating the design of
large-scale studies of the cerebellum. As such, automated segmentation of the
cerebellar lobules would allow detailed population studies of the cerebellum and 
its subregions. In this manuscript, we describe a novel set of high-resolution in
vivo atlases of the cerebellum developed by pairing MR imaging with a carefully
validated manual segmentation protocol. Using these cerebellar atlases as inputs,
we validate a novel automated segmentation algorithm that takes advantage of the 
neuroanatomical variability that exists in a given population under study in
order to automatically identify the cerebellum, and its lobules. Our automatic
segmentation results demonstrate good accuracy in the identification of all
lobules (mean Kappa [κ]=0.731; range 0.40-0.89), and the entire cerebellum (mean 
κ=0.925; range 0.90-0.94) when compared to "gold-standard" manual segmentations. 
These results compare favorably in comparison to other publically available
methods for automatic segmentation of the cerebellum. The completed cerebellar
atlases are available freely online (http://imaging-genetics.camh.ca/cerebellum) 
and can be customized to the unique neuroanatomy of different subjects using the 
proposed segmentation pipeline (https://github.com/pipitone/MAGeTbrain).

Copyright © 2014 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.neuroimage.2014.03.037 
PMID: 24657354  [PubMed - indexed for MEDLINE]


1292. Front Neuroinform. 2014 Mar 11;8:22. doi: 10.3389/fninf.2014.00022. eCollection
2014.

SCoT: a Python toolbox for EEG source connectivity.

Billinger M(1), Brunner C(1), Müller-Putz GR(1).

Author information: 
(1)Institute for Knowledge Discovery, Graz University of Technology Graz,
Austria.

Analysis of brain connectivity has become an important research tool in
neuroscience. Connectivity can be estimated between cortical sources
reconstructed from the electroencephalogram (EEG). Such analysis often relies on 
trial averaging to obtain reliable results. However, some applications such as
brain-computer interfaces (BCIs) require single-trial estimation methods. In this
paper, we present SCoT-a source connectivity toolbox for Python. This toolbox
implements routines for blind source decomposition and connectivity estimation
with the MVARICA approach. Additionally, a novel extension called CSPVARICA is
available for labeled data. SCoT estimates connectivity from various spectral
measures relying on vector autoregressive (VAR) models. Optionally, these VAR
models can be regularized to facilitate ill posed applications such as
single-trial fitting. We demonstrate basic usage of SCoT on motor imagery (MI)
data. Furthermore, we show simulation results of utilizing SCoT for feature
extraction in a BCI application. These results indicate that CSPVARICA and
correct regularization can significantly improve MI classification. While SCoT
was mainly designed for application in BCIs, it contains useful tools for other
areas of neuroscience. SCoT is a software package that (1) brings combined source
decomposition and connectivtiy estimation to the open Python platform, and (2)
offers tools for single-trial connectivity estimation. The source code is
released under the MIT license and is available online at
github.com/SCoT-dev/SCoT.

DOI: 10.3389/fninf.2014.00022 
PMCID: PMC3949292
PMID: 24653694  [PubMed]


1293. PLoS One. 2014 Mar 19;9(3):e89204. doi: 10.1371/journal.pone.0089204. eCollection
2014.

openSNP--a crowdsourced web resource for personal genomics.

Greshake B(1), Bayer PE(2), Rausch H(3), Reda J(4).

Author information: 
(1)Molecular Ecology Group, Biodiversity & Climate Research Centre, Frankfurt am 
Main, Germany; Department for Applied Bioinformatics, Institute for Cell Biology 
and Neuroscience, Goethe University, Frankfurt am Main, Germany. (2)School of
Land, Crop, and Food Sciences, University of Queensland, Brisbane, Australia;
Australian Centre for Plant Functional Genomics, School of Agriculture and Food
Sciences, University of Queensland, Brisbane, Australia. (3)Hochschule für
Technik und Wirtschaft, Berlin, Germany. (4)Johannes Gutenberg University, Mainz,
Germany.

Comment in
    PLoS One. 2014;9(3):e92060.

Genome-Wide Association Studies are widely used to correlate phenotypic traits
with genetic variants. These studies usually compare the genetic variation
between two groups to single out certain Single Nucleotide Polymorphisms (SNPs)
that are linked to a phenotypic variation in one of the groups. However, it is
necessary to have a large enough sample size to find statistically significant
correlations. Direct-To-Consumer (DTC) genetic testing can supply additional
data: DTC-companies offer the analysis of a large amount of SNPs for an
individual at low cost without the need to consult a physician or geneticist.
Over 100,000 people have already been genotyped through Direct-To-Consumer
genetic testing companies. However, this data is not public for a variety of
reasons and thus cannot be used in research. It seems reasonable to create a
central open data repository for such data. Here we present the web platform
openSNP, an open database which allows participants of Direct-To-Consumer genetic
testing to publish their genetic data at no cost along with phenotypic
information. Through this crowdsourced effort of collecting genetic and
phenotypic information, openSNP has become a resource for a wide area of studies,
including Genome-Wide Association Studies. openSNP is hosted at
http://www.opensnp.org, and the code is released under MIT-license at
http://github.com/gedankenstuecke/snpr.

DOI: 10.1371/journal.pone.0089204 
PMCID: PMC3960092
PMID: 24647222  [PubMed - indexed for MEDLINE]


1294. F1000Res. 2014 Feb 13;3:51. doi: 10.12688/f1000research.3-51.v1. eCollection
2014.

BioJS DAGViewer: A reusable JavaScript component for displaying directed graphs.

Kalderimis A(1), Stepan R(1), Sullivan J(1), Lyne R(1), Lyne M(1), Micklem G(1).

Author information: 
(1)Department of Genetics and Cambridge Systems Biology Centre, Cambridge
University, Cambridge, CB2 3EH, UK.

SUMMARY: The DAGViewer BioJS component is a reusable JavaScript component made
available as part of the BioJS project and intended to be used to display graphs 
of structured data, with a particular emphasis on Directed Acyclic Graphs (DAGs).
It enables users to embed representations of graphs of data, such as ontologies
or phylogenetic trees, in hyper-text documents (HTML). This component is generic,
since it is capable (given the appropriate configuration) of displaying any kind 
of data that is organised as a graph. The features of this component which are
useful for examining and filtering large and complex graphs are described.
AVAILABILITY: http://github.com/alexkalderimis/dag-viewer-biojs;
http://github.com/biojs/biojs; http://dx.doi.org/10.5281/zenodo.8303.

DOI: 10.12688/f1000research.3-51.v1 
PMCID: PMC3945768
PMID: 24627804  [PubMed]


1295. Bioinformatics. 2014 Jul 1;30(13):1867-75. doi: 10.1093/bioinformatics/btu134.
Epub 2014 Mar 10.

Probabilistic PCA of censored data: accounting for uncertainties in the
visualization of high-throughput single-cell qPCR data.

Buettner F(1), Moignard V(1), Göttgens B(1), Theis FJ(2).

Author information: 
(1)Institute of Computational Biology, Helmholtz-Zentrum München, 85764
Neuherberg, Germany, Department of Haematology, University of Cambridge,
Cambridge Institute for Medical Research and Wellcome Trust & MRC Cambridge Stem 
Cell Institute, Cambridge CB2 0XY, UK and Department of Mathematics, TU München, 
85748 Garching, Germany. (2)Institute of Computational Biology, Helmholtz-Zentrum
München, 85764 Neuherberg, Germany, Department of Haematology, University of
Cambridge, Cambridge Institute for Medical Research and Wellcome Trust & MRC
Cambridge Stem Cell Institute, Cambridge CB2 0XY, UK and Department of
Mathematics, TU München, 85748 Garching, GermanyInstitute of Computational
Biology, Helmholtz-Zentrum München, 85764 Neuherberg, Germany, Department of
Haematology, University of Cambridge, Cambridge Institute for Medical Research
and Wellcome Trust & MRC Cambridge Stem Cell Institute, Cambridge CB2 0XY, UK and
Department of Mathematics, TU München, 85748 Garching, Germany.

MOTIVATION: High-throughput single-cell quantitative real-time polymerase chain
reaction (qPCR) is a promising technique allowing for new insights in complex
cellular processes. However, the PCR reaction can be detected only up to a
certain detection limit, whereas failed reactions could be due to low or absent
expression, and the true expression level is unknown. Because this censoring can 
occur for high proportions of the data, it is one of the main challenges when
dealing with single-cell qPCR data. Principal component analysis (PCA) is an
important tool for visualizing the structure of high-dimensional data as well as 
for identifying subpopulations of cells. However, to date it is not clear how to 
perform a PCA of censored data. We present a probabilistic approach that accounts
for the censoring and evaluate it for two typical datasets containing single-cell
qPCR data.
RESULTS: We use the Gaussian process latent variable model framework to account
for censoring by introducing an appropriate noise model and allowing a different 
kernel for each dimension. We evaluate this new approach for two typical qPCR
datasets (of mouse embryonic stem cells and blood stem/progenitor cells,
respectively) by performing linear and non-linear probabilistic PCA. Taking the
censoring into account results in a 2D representation of the data, which better
reflects its known structure: in both datasets, our new approach results in a
better separation of known cell types and is able to reveal subpopulations in one
dataset that could not be resolved using standard PCA.
AVAILABILITY AND IMPLEMENTATION: The implementation was based on the existing
Gaussian process latent variable model toolbox
(https://github.com/SheffieldML/GPmat); extensions for noise models and kernels
accounting for censoring are available at
http://icb.helmholtz-muenchen.de/censgplvm.

© The Author 2014. Published by Oxford University Press. All rights reserved.

DOI: 10.1093/bioinformatics/btu134 
PMCID: PMC4071202
PMID: 24618470  [PubMed - indexed for MEDLINE]


1296. Algorithms Mol Biol. 2014 Mar 6;9(1):5. doi: 10.1186/1748-7188-9-5.

Faster algorithms for RNA-folding using the Four-Russians method.

Venkatachalam B(1), Gusfield D, Frid Y.

Author information: 
(1)Department of Computer Science, University of California, Davis, 1 Shields
Ave, Davis, CA, USA. balaji@cs.ucdavis.edu.

BACKGROUND: The secondary structure that maximizes the number of non-crossing
matchings between complimentary bases of an RNA sequence of length n can be
computed in O(n3) time using Nussinov's dynamic programming algorithm. The
Four-Russians method is a technique that reduces the running time for certain
dynamic programming algorithms by a multiplicative factor after a preprocessing
step where solutions to all smaller subproblems of a fixed size are exhaustively 
enumerated and solved. Frid and Gusfield designed an O(n3logn) algorithm for RNA 
folding using the Four-Russians technique. In their algorithm the preprocessing
is interleaved with the algorithm computation.
THEORETICAL RESULTS: We simplify the algorithm and the analysis by doing the
preprocessing once prior to the algorithm computation. We call this the
two-vector method. We also show variants where instead of exhaustive
preprocessing, we only solve the subproblems encountered in the main algorithm
once and memoize the results. We give a simple proof of correctness and explore
the practical advantages over the earlier method.The Nussinov algorithm admits an
O(n2) time parallel algorithm. We show a parallel algorithm using the two-vector 
idea that improves the time bound to O(n2logn).
PRACTICAL RESULTS: We have implemented the parallel algorithm on graphics
processing units using the CUDA platform. We discuss the organization of the data
structures to exploit coalesced memory access for fast running times. The ideas
to organize the data structures also help in improving the running time of the
serial algorithms. For sequences of length up to 6000 bases the parallel
algorithm takes only about 2.5 seconds and the two-vector serial method takes
about 57 seconds on a desktop and 15 seconds on a server. Among the serial
algorithms, the two-vector and memoized versions are faster than the
Frid-Gusfield algorithm by a factor of 3, and are faster than Nussinov by up to a
factor of 20. The source-code for the algorithms is available at
http://github.com/ijalabv/FourRussiansRNAFolding.

DOI: 10.1186/1748-7188-9-5 
PMCID: PMC3996002
PMID: 24602450  [PubMed]


1297. Front Neuroinform. 2014 Feb 21;8:8. doi: 10.3389/fninf.2014.00008. eCollection
2014.

Dipy, a library for the analysis of diffusion MRI data.

Garyfallidis E(1), Brett M(2), Amirbekian B(3), Rokem A(4), van der Walt S(5),
Descoteaux M(6), Nimmo-Smith I(6); Dipy Contributors.

Author information: 
(1)Computer Science Department, University of Sherbrooke Sherbrooke, QC, Canada ;
MRC Cognition and Brain Sciences Unit, University of Cambridge Cambridge, UK.
(2)Henry H. Wheeler, Jr. Brain Imaging Center, University of California Berkeley,
CA, USA. (3)Department of Neurology and Graduate Group in Bioengineering,
University of California San Francisco, CA, USA. (4)Department of Psychology,
Stanford University Stanford, CA, USA. (5)Department of Mathematical Sciences,
Division of Applied Mathematics, Stellenbosch University Stellenbosch, South
Africa. (6)MRC Cognition and Brain Sciences Unit, University of Cambridge
Cambridge, UK.

Diffusion Imaging in Python (Dipy) is a free and open source software project for
the analysis of data from diffusion magnetic resonance imaging (dMRI)
experiments. dMRI is an application of MRI that can be used to measure structural
features of brain white matter. Many methods have been developed to use dMRI data
to model the local configuration of white matter nerve fiber bundles and infer
the trajectory of bundles connecting different parts of the brain. Dipy gathers
implementations of many different methods in dMRI, including: diffusion signal
pre-processing; reconstruction of diffusion distributions in individual voxels;
fiber tractography and fiber track post-processing, analysis and visualization.
Dipy aims to provide transparent implementations for all the different steps of
dMRI analysis with a uniform programming interface. We have implemented classical
signal reconstruction techniques, such as the diffusion tensor model and
deterministic fiber tractography. In addition, cutting edge novel reconstruction 
techniques are implemented, such as constrained spherical deconvolution and
diffusion spectrum imaging (DSI) with deconvolution, as well as methods for
probabilistic tracking and original methods for tractography clustering. Many
additional utility functions are provided to calculate various statistics,
informative visualizations, as well as file-handling routines to assist in the
development and use of novel techniques. In contrast to many other scientific
software projects, Dipy is not being developed by a single research group.
Rather, it is an open project that encourages contributions from any
scientist/developer through GitHub and open discussions on the project mailing
list. Consequently, Dipy today has an international team of contributors,
spanning seven different academic institutions in five countries and three
continents, which is still growing.

DOI: 10.3389/fninf.2014.00008 
PMCID: PMC3931231
PMID: 24600385  [PubMed]


1298. J Chem Phys. 2014 Feb 28;140(8):084109. doi: 10.1063/1.4866448.

Recovering position-dependent diffusion from biased molecular dynamics
simulations.

Ljubetič A(1), Urbančič I(1), Štrancar J(1).

Author information: 
(1)Laboratory of Biophysics, Condensed Matter Physics Department, "Jožef Stefan" 
Institute, 1000 Ljubljana, Slovenia.

All atom molecular dynamics (MD) models provide valuable insight into the
dynamics of biophysical systems, but are limited in size or length by the high
computational demands. The latter can be reduced by simulating long term
diffusive dynamics (also known as Langevin dynamics or Brownian motion) of the
most interesting and important user-defined parts of the studied system, termed
collective variables (colvars). A few hundred nanosecond-long biased MD
trajectory can therefore be extended to millisecond lengths in the colvars
subspace at a very small additional computational cost. In this work, we develop 
a method for determining multidimensional anisotropic position- and
timescale-dependent diffusion coefficients (D) by analysing the changes of
colvars in an existing MD trajectory. As a test case, we obtained D for dihedral 
angles of the alanine dipeptide. An open source Mathematica(®) package, capable
of determining and visualizing D in one or two dimensions, is available at
https://github.com/lbf-ijs/DiffusiveDynamics. Given known free energy and D, the 
package can also generate diffusive trajectories.

DOI: 10.1063/1.4866448 
PMID: 24588150  [PubMed - indexed for MEDLINE]


1299. Mol Biol Evol. 2014 Jun;31(6):1593-605. doi: 10.1093/molbev/msu082. Epub 2014 Feb
27.

Efficient inference of recombination hot regions in bacterial genomes.

Yahara K(1), Didelot X(2), Ansari MA(3), Sheppard SK(4), Falush D(5).

Author information: 
(1)Department of Medical Genome Sciences, Graduate School of Frontier Sciences,
University of Tokyo, Tokyo, JapanInstitute of Medical Science, University of
Tokyo, Tokyo, JapanInstitute of Life Science, College of Medicine, Swansea
University, Swansea, United Kingdom. (2)Department of Infectious Disease
Epidemiology, Imperial College London, London, United Kingdom. (3)Department of
Statistics, University of Oxford, Oxford, United Kingdom. (4)Institute of Life
Science, College of Medicine, Swansea University, Swansea, United Kingdom.
(5)Department of Evolutionary Genetics, Max Planck Institute for Evolutionary
Anthropology, Leipzig, Germany daniel_falush@eva.mpg.de.

In eukaryotes, detailed surveys of recombination rates have shown variation at
multiple genomic scales and the presence of "hotspots" of highly elevated
recombination. In bacteria, studies of recombination rate variation are less
developed, in part because there are few analysis methods that take into account 
the clonal context within which bacterial evolution occurs. Here, we focus in
particular on identifying "hot regions" of the genome where DNA is transferred
frequently between isolates. We present a computationally efficient algorithm
based on the recently developed "chromosome painting" algorithm, which
characterizes patterns of haplotype sharing across a genome. We compare the
average genome wide painting, which principally reflects clonal descent, with the
painting for each site which additionally reflects the specific deviations at the
site due to recombination. Using simulated data, we show that hot regions have
consistently higher deviations from the genome wide average than normal regions. 
We applied our approach to previously analyzed Escherichia coli genomes and
revealed that the new method is highly correlated with the number of
recombination events affecting each site inferred by ClonalOrigin, a method that 
is only applicable to small numbers of genomes. Furthermore, we analyzed
recombination hot regions in Campylobacter jejuni by using 200 genomes. We
identified three recombination hot regions, which are enriched for genes related 
to membrane proteins. Our approach and its implementation, which is downloadable 
from https://github.com/bioprojects/orderedPainting, will help to develop a new
phase of population genomic studies of recombination in prokaryotes.

© The Author 2014. Published by Oxford University Press on behalf of the Society 
for Molecular Biology and Evolution.

DOI: 10.1093/molbev/msu082 
PMCID: PMC4032127
PMID: 24586045  [PubMed - indexed for MEDLINE]


1300. Bioinformatics. 2014 Jun 15;30(12):1762-4. doi: 10.1093/bioinformatics/btu113.
Epub 2014 Feb 25.

CanSNPer: a hierarchical genotype classifier of clonal pathogens.

Lärkeryd A(1), Myrtennäs K(1), Karlsson E(1), Dwibedi CK(2), Forsman M(1),
Larsson P(1), Johansson A(1), Sjödin A(2).

Author information: 
(1)Department of Clinical Microbiology, Umeå University, Division of CBRN
Security and Defence, FOI, Swedish Defence Research Agency, Department of
Clinical Microbiology, The Laboratory for Molecular Infection Medicine Sweden
(MIMS) and Department of Chemistry, Computational Life Science Cluster (CLiC),
Umeå University, Umeå, Sweden. (2)Department of Clinical Microbiology, Umeå
University, Division of CBRN Security and Defence, FOI, Swedish Defence Research 
Agency, Department of Clinical Microbiology, The Laboratory for Molecular
Infection Medicine Sweden (MIMS) and Department of Chemistry, Computational Life 
Science Cluster (CLiC), Umeå University, Umeå, SwedenDepartment of Clinical
Microbiology, Umeå University, Division of CBRN Security and Defence, FOI,
Swedish Defence Research Agency, Department of Clinical Microbiology, The
Laboratory for Molecular Infection Medicine Sweden (MIMS) and Department of
Chemistry, Computational Life Science Cluster (CLiC), Umeå University, Umeå,
Sweden.

SUMMARY: Advances in typing methodologies have recently reformed the field of
molecular epidemiology of pathogens. The falling cost of sequencing technologies 
is creating a deluge of whole genome sequencing data that burdens bioinformatics 
resources and tool development. In particular, single nucleotide polymorphisms in
core genomes of pathogens are recognized as the most important markers for
inferring genetic relationships because they are evolutionarily stable and
amenable to high-throughput detection methods. Sequence data will provide an
excellent opportunity to extend our understanding of infectious disease when the 
challenge of extracting knowledge from available sequence resources is met. Here,
we present an efficient and user-friendly genotype classification pipeline,
CanSNPer, based on an easily expandable database of predefined canonical single
nucleotide polymorphisms.
AVAILABILITY AND IMPLEMENTATION: All documentation and Python-based source code
for the CanSNPer are freely available at http://github.com/adrlar/CanSNPer.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu113 
PMID: 24574113  [PubMed - indexed for MEDLINE]


1301. Bioinformatics. 2014 Jun 15;30(12):1757-8. doi: 10.1093/bioinformatics/btu094.
Epub 2014 Feb 23.

jHeatmap: an interactive heatmap viewer for the web.

Deu-Pons J(1), Schroeder MP(1), Lopez-Bigas N(2).

Author information: 
(1)Research Unit on Biomedical Informatics, Department of Experimental and Health
Sciences, Universitat Pompeu Fabra, Dr. Aiguader 88, Barcelona, Spain and
Institució Catalana de Recerca i Estudis Avançats (ICREA), Passeig Lluís
Companys, 23, Barcelona, Spain. (2)Research Unit on Biomedical Informatics,
Department of Experimental and Health Sciences, Universitat Pompeu Fabra, Dr.
Aiguader 88, Barcelona, Spain and Institució Catalana de Recerca i Estudis
Avançats (ICREA), Passeig Lluís Companys, 23, Barcelona, SpainResearch Unit on
Biomedical Informatics, Department of Experimental and Health Sciences,
Universitat Pompeu Fabra, Dr. Aiguader 88, Barcelona, Spain and Institució
Catalana de Recerca i Estudis Avançats (ICREA), Passeig Lluís Companys, 23,
Barcelona, Spain.

SUMMARY: The generation of large volumes of omics data to conduct exploratory
studies has become feasible and is now extensively used to gain new insights in
life sciences. The effective exploration of the generated data by experts is a
crucial step for the successful extraction of knowledge from these datasets. This
requires availability of intuitive and interactive visualization tools that can
display complex data. Matrix heatmaps are graphical representations frequently
used for the description of complex omics data. Here, we present jHeatmap, a
web-based tool that allows interactive matrix heatmap visualization and
exploration. It is an adaptable javascript library designed to be embedded by
means of basic coding skills into web portals to visualize data matrices as
interactive and customizable heatmaps.
AVAILABILITY: jHeatmap is freely available at the GitHub code repository at
https://github.com/jheatmap/jheatmap. Working examples and the documentation may 
be found at http://jheatmap.github.io/jheatmap.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu094 
PMID: 24567544  [PubMed - indexed for MEDLINE]


1302. BMC Syst Biol. 2013;7 Suppl 2:S10. doi: 10.1186/1752-0509-7-S2-S10. Epub 2013 Dec
17.

HSA: a heuristic splice alignment tool.

Bu J, Chi X, Jin Z.

BACKGROUND: RNA-Seq methodology is a revolutionary transcriptomics sequencing
technology, which is the representative of Next generation Sequencing (NGS). With
the high throughput sequencing of RNA-Seq, we can acquire much more information
like differential expression and novel splice variants from deep sequence
analysis and data mining. But the short read length brings a great challenge to
alignment, especially when the reads span two or more exons.
METHODS: A two steps heuristic splice alignment tool is generated in this
investigation. First, map raw reads to reference with unspliced aligner--BWA;
second, split initial unmapped reads into three equal short reads (seeds), align 
each seed to the reference, filter hits, search possible split position of read
and extend hits to a complete match.
RESULTS: Compare with other splice alignment tools like SOAPsplice and Tophat2,
HSA has a better performance in call rate and efficiency, but its results do not 
as accurate as the other software to some extent.
CONCLUSIONS: HSA is an effective spliced aligner of RNA-Seq reads mapping, which 
is available at https://github.com/vlcc/HSA.

DOI: 10.1186/1752-0509-7-S2-S10 
PMCID: PMC3866249
PMID: 24564867  [PubMed - indexed for MEDLINE]


1303. BMC Bioinformatics. 2014;15 Suppl 1:S11. doi: 10.1186/1471-2105-15-S1-S11. Epub
2014 Jan 10.

The Risa R/Bioconductor package: integrative data analysis from experimental
metadata and back again.

González-Beltrán A, Neumann S, Maguire E, Sansone SA, Rocca-Serra P.

BACKGROUND: The ISA-Tab format and software suite have been developed to break
the silo effect induced by technology-specific formats for a variety of data
types and to better support experimental metadata tracking. Experimentalists
seldom use a single technique to monitor biological signals. Providing a
multi-purpose, pragmatic and accessible format that abstracts away common
constructs for describing Investigations, Studies and Assays, ISA is increasingly
popular. To attract further interest towards the format and extend support to
ensure reproducible research and reusable data, we present the Risa package,
which delivers a central component to support the ISA format by enabling
effortless integration with R, the popular, open source data crunching
environment.
RESULTS: The Risa package bridges the gap between the metadata collection and
curation in an ISA-compliant way and the data analysis using the widely used
statistical computing environment R. The package offers functionality for: i)
parsing ISA-Tab datasets into R objects, ii) augmenting annotation with extra
metadata not explicitly stated in the ISA syntax; iii) interfacing with domain
specific R packages iv) suggesting potentially useful R packages available in
Bioconductor for subsequent processing of the experimental data described in the 
ISA format; and finally v) saving back to ISA-Tab files augmented with analysis
specific metadata from R. We demonstrate these features by presenting use cases
for mass spectrometry data and DNA microarray data.
CONCLUSIONS: The Risa package is open source (with LGPL license) and freely
available through Bioconductor. By making Risa available, we aim to facilitate
the task of processing experimental data, encouraging a uniform representation of
experimental information and results while delivering tools for ensuring
traceability and provenance tracking.
SOFTWARE AVAILABILITY: The Risa package is available since Bioconductor 2.11
(version 1.0.0) and version 1.2.1 appeared in Bioconductor 2.12, both along with 
documentation and examples. The latest version of the code is at the development 
branch in Bioconductor and can also be accessed from GitHub
https://github.com/ISA-tools/Risa, where the issue tracker allows users to report
bugs or feature requests.

DOI: 10.1186/1471-2105-15-S1-S11 
PMCID: PMC4015122
PMID: 24564732  [PubMed - indexed for MEDLINE]


1304. BMC Bioinformatics. 2013;14 Suppl 15:S16. doi: 10.1186/1471-2105-14-S15-S16. Epub
2013 Oct 15.

Finishing bacterial genome assemblies with Mix.

Soueidan H, Maurier F, Groppi A, Sirand-Pugnet P, Tardy F, Citti C, Dupuy V,
Nikolski M.

MOTIVATION: Among challenges that hamper reaping the benefits of genome assembly 
are both unfinished assemblies and the ensuing experimental costs. First,
numerous software solutions for genome de novo assembly are available, each
having its advantages and drawbacks, without clear guidelines as to how to choose
among them. Second, these solutions produce draft assemblies that often require a
resource intensive finishing phase.
METHODS: In this paper we address these two aspects by developing Mix , a tool
that mixes two or more draft assemblies, without relying on a reference genome
and having the goal to reduce contig fragmentation and thus speed-up genome
finishing. The proposed algorithm builds an extension graph where vertices
represent extremities of contigs and edges represent existing alignments between 
these extremities. These alignment edges are used for contig extension. The
resulting output assembly corresponds to a set of paths in the extension graph
that maximizes the cumulative contig length.
RESULTS: We evaluate the performance of Mix on bacterial NGS data from the GAGE-B
study and apply it to newly sequenced Mycoplasma genomes. Resulting final
assemblies demonstrate a significant improvement in the overall assembly quality.
In particular, Mix is consistent by providing better overall quality results even
when the choice is guided solely by standard assembly statistics, as is the case 
for de novo projects.
AVAILABILITY: Mix is implemented in Python and is available at
https://github.com/cbib/MIX, novel data for our Mycoplasma study is available at 
http://services.cbib.u-bordeaux2.fr/mix/.

DOI: 10.1186/1471-2105-14-S15-S16 
PMCID: PMC3851838
PMID: 24564706  [PubMed - indexed for MEDLINE]


1305. BMC Genomics. 2013;14 Suppl 8:S7. doi: 10.1186/1471-2164-14-S8-S7. Epub 2013 Dec 
9.

Molecular pathway identification using biological network-regularized logistic
models.

Zhang W, Wan YW, Allen GI, Pang K, Anderson ML, Liu Z.

BACKGROUND: Selecting genes and pathways indicative of disease is a central
problem in computational biology. This problem is especially challenging when
parsing multi-dimensional genomic data. A number of tools, such as L1-norm based 
regularization and its extensions elastic net and fused lasso, have been
introduced to deal with this challenge. However, these approaches tend to ignore 
the vast amount of a priori biological network information curated in the
literature.
RESULTS: We propose the use of graph Laplacian regularized logistic regression to
integrate biological networks into disease classification and pathway association
problems. Simulation studies demonstrate that the performance of the proposed
algorithm is superior to elastic net and lasso analyses. Utility of this
algorithm is also validated by its ability to reliably differentiate breast
cancer subtypes using a large breast cancer dataset recently generated by the
Cancer Genome Atlas (TCGA) consortium. Many of the protein-protein interaction
modules identified by our approach are further supported by evidence published in
the literature. Source code of the proposed algorithm is freely available at
http://www.github.com/zhandong/Logit-Lapnet.
CONCLUSION: Logistic regression with graph Laplacian regularization is an
effective algorithm for identifying key pathways and modules associated with
disease subtypes. With the rapid expansion of our knowledge of biological
regulatory networks, this approach will become more accurate and increasingly
useful for mining transcriptomic, epi-genomic, and other types of genome wide
association studies.

DOI: 10.1186/1471-2164-14-S8-S7 
PMCID: PMC4046566
PMID: 24564637  [PubMed - indexed for MEDLINE]


1306. BMC Genomics. 2013;14 Suppl 5:S15. doi: 10.1186/1471-2164-14-S5-S15. Epub 2013
Oct 16.

PLW: Probabilistic Local Walks for detecting protein complexes from protein
interaction networks.

Wong D, Li XL, Wu M, Zheng J, Ng SK.

BACKGROUND: Many biological processes are carried out by proteins interacting
with each other in the form of protein complexes. However, large-scale detection 
of protein complexes has remained constrained by experimental limitations. As
such, computational detection of protein complexes by applying clustering
algorithms on the abundantly available protein-protein interaction (PPI) networks
is an important alternative. However, many current algorithms have overlooked the
importance of selecting seeds for expansion into clusters without excluding
important proteins and including many noisy ones, while ensuring a high degree of
functional homogeneity amongst the proteins detected for the complexes.
RESULTS: We designed a novel method called Probabilistic Local Walks (PLW) which 
clusters regions in a PPI network with high functional similarity to find protein
complex cores with high precision and efficiency in O (|V| log |V| + |E|) time. A
seed selection strategy, which prioritises seeds with dense neighbourhoods, was
devised. We defined a topological measure, called common neighbour similarity, to
estimate the functional similarity of two proteins given the number of their
common neighbours.
CONCLUSIONS: Our proposed PLW algorithm achieved the highest F-measure (recall
and precision) when compared to 11 state-of-the-art methods on yeast protein
interaction data, with an improvement of 16.7% over the next highest score. Our
experiments also demonstrated that our seed selection strategy is able to
increase algorithm precision when applied to three previous protein complex
mining techniques.
AVAILABILITY: The software, datasets and predicted complexes are available at
http://wonglkd.github.io/PLW.

DOI: 10.1186/1471-2164-14-S5-S15 
PMCID: PMC3852146
PMID: 24564427  [PubMed - indexed for MEDLINE]


1307. BMC Bioinformatics. 2013;14 Suppl 11:S3. doi: 10.1186/1471-2105-14-S11-S3. Epub
2013 Sep 13.

Efficient digest of high-throughput sequencing data in a reproducible report.

Zhang Z, Leipzig J, Sasson A, Yu AM, Perin JC, Xie HM, Sarmady M, Warren PV,
White PS.

BACKGROUND: High-throughput sequencing (HTS) technologies are spearheading the
accelerated development of biomedical research. Processing and summarizing the
large amount of data generated by HTS presents a non-trivial challenge to
bioinformatics. A commonly adopted standard is to store sequencing reads aligned 
to a reference genome in SAM (Sequence Alignment/Map) or BAM (Binary
Alignment/Map) files. Quality control of SAM/BAM files is a critical checkpoint
before downstream analysis. The goal of the current project is to facilitate and 
standardize this process.
RESULTS: We developed bamchop, a robust program to efficiently summarize key
statistical metrics of HTS data stored in BAM files, and to visually present the 
results in a formatted report. The report documents information about various
aspects of HTS data, such as sequencing quality, mapping to a reference genome,
sequencing coverage, and base frequency. Bamchop uses the R language and
Bioconductor packages to calculate statistical matrices and the Sweave utility
and associated LaTeX markup for documentation. Bamchop's efficiency and
robustness were tested on BAM files generated by local sequencing facilities and 
the 1000 Genomes Project. Source code, instruction and example reports of bamchop
are freely available from https://github.com/CBMi-BiG/bamchop.
CONCLUSIONS: Bamchop enables biomedical researchers to quickly and rigorously
evaluate HTS data by providing a convenient synopsis and user-friendly reports.

DOI: 10.1186/1471-2105-14-S11-S3 
PMCID: PMC3846741
PMID: 24564231  [PubMed - indexed for MEDLINE]


1308. Comput Biol Med. 2014 Apr;47:120-9. doi: 10.1016/j.compbiomed.2014.01.012. Epub
2014 Feb 3.

Exploring medical diagnostic performance using interactive, multi-parameter
sourced receiver operating characteristic scatter plots.

Moore HE 4th(1), Andlauer O(2), Simon N(3), Mignot E(4).

Author information: 
(1)Department of Electrical Engineering, Stanford University, Stanford, CA, USA. 
Electronic address: hyatt4@stanford.edu. (2)EA 481, Laboratoires de
Neurosciences, University of Franche-Comte, 1 place du marechal Leclerc, 25030
Besancon Cedex, France. (3)Department of Statistics, University of Washington,
Seattle, WA, USA. (4)Center for Sleep Sciences and Medicine, Stanford University,
Palo Alto, CA, USA.

Determining diagnostic criteria for specific disorders is often a tedious task
that involves determining optimal diagnostic thresholds for symptoms and
biomarkers using receiver-operating characteristic (ROC) statistics. To help this
endeavor, we developed softROC, a user-friendly graphic-based tool that lets
users visually explore possible ROC tradeoffs. The software requires MATLAB
installation and an Excel file containing threshold symptoms/biological measures,
with corresponding gold standard diagnoses for a set of patients. The software
scans the input file for diagnostic and symptom/biomarkers columns, and populates
the graphical-user-interface (GUI). Users select symptoms/biomarkers of interest 
using Boolean algebra as potential inputs to create diagnostic criteria outputs. 
The software evaluates subtests across the user-established range of cut-points
and compares them to a gold standard in order to generate ROC and quality ROC
scatter plots. These plots can be examined interactively to find optimal
cut-points of interest for a given application (e.g. sensitivity versus
specificity needs). Split-set validation can also be used to set up criteria and 
validate these in independent samples. Bootstrapping is used to produce
confidence intervals. Additional statistics and measures are provided, such as
the area under the ROC curve (AUC). As a testing set, softROC is used to
investigate nocturnal polysomnogram measures as diagnostic features for
narcolepsy. All measures can be outputted to a text file for offline analysis.
The softROC toolbox, with clinical training data and tutorial instruction manual,
is provided as supplementary material and can be obtained online at
http://www.stanford.edu/~hyatt4/software/softroc or from the open source
repository at http://www.github.com/informaton/softroc.

Copyright © 2014 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.compbiomed.2014.01.012 
PMID: 24561350  [PubMed - indexed for MEDLINE]


1309. J Biomed Inform. 2014 Dec;52:130-40. doi: 10.1016/j.jbi.2014.01.015. Epub 2014
Feb 18.

Social network analysis of biomedical research collaboration networks in a CTSA
institution.

Bian J(1), Xie M(2), Topaloglu U(3), Hudson T(4), Eswaran H(5), Hogan W(6).

Author information: 
(1)Division of Biomedical Informatics, University of Arkansas for Medical
Sciences, Little Rock, AR 72205, USA. Electronic address: jbian@uams.edu.
(2)Computer Science, University of Arkansas at Little Rock, Little Rock, AR
72204, USA. Electronic address: mxxie@ualr.edu. (3)Division of Biomedical
Informatics, University of Arkansas for Medical Sciences, Little Rock, AR 72205, 
USA. Electronic address: utopaloglu@uams.edu. (4)Department of Psychiatry,
University of Arkansas for Medical Sciences, Little Rock, AR 72205, USA; Central 
Arkansas Veterans Healthcare System, Little Rock, AR 72205, USA. Electronic
address: HudsonTeresaJ@uams.edu. (5)Division of Biomedical Informatics,
University of Arkansas for Medical Sciences, Little Rock, AR 72205, USA;
Obstetrics & Gynecology Research, University of Arkansas for Medical Sciences,
Little Rock, AR 72205, USA. Electronic address: EswaranHari@uams.edu. (6)Division
of Biomedical Informatics, University of Arkansas for Medical Sciences, Little
Rock, AR 72205, USA. Electronic address: wrhogan@uams.edu.

BACKGROUND: The popularity of social networks has triggered a number of research 
efforts on network analyses of research collaborations in the Clinical and
Translational Science Award (CTSA) community. Those studies mainly focus on the
general understanding of collaboration networks by measuring common network
metrics. More fundamental questions about collaborations still remain unanswered 
such as recognizing "influential" nodes and identifying potential new
collaborations that are most rewarding.
METHODS: We analyzed biomedical research collaboration networks (RCNs)
constructed from a dataset of research grants collected at a CTSA institution
(i.e., University of Arkansas for Medical Sciences (UAMS)) in a comprehensive and
systematic manner. First, our analysis covers the full spectrum of a RCN study:
from network modeling to network characteristics measurement, from key nodes
recognition to potential links (collaborations) suggestion. Second, our analysis 
employs non-conventional model and techniques including a weighted network model 
for representing collaboration strength, rank aggregation for detecting important
nodes, and Random Walk with Restart (RWR) for suggesting new research
collaborations.
RESULTS: By applying our models and techniques to RCNs at UAMS prior to and after
the CTSA, we have gained valuable insights that not only reveal the temporal
evolution of the network dynamics but also assess the effectiveness of the CTSA
and its impact on a research institution. We find that collaboration networks at 
UAMS are not scale-free but small-world. Quantitative measures have been obtained
to evident that the RCNs at UAMS are moving towards favoring multidisciplinary
research. Moreover, our link prediction model creates the basis of collaboration 
recommendations with an impressive accuracy (AUC: 0.990, MAP@3: 1.48 and MAP@5:
1.522). Last but not least, an open-source visual analytical tool for RCNs is
being developed and released through Github.
CONCLUSIONS: Through this study, we have developed a set of techniques and tools 
for analyzing research collaboration networks and conducted a comprehensive case 
study focusing on a CTSA institution. Our findings demonstrate the promising
future of these techniques and tools in understanding the generative mechanisms
of research collaborations and helping identify beneficial collaborations to
members in the research community.

Published by Elsevier Inc.

DOI: 10.1016/j.jbi.2014.01.015 
PMCID: PMC4136998
PMID: 24560679  [PubMed - indexed for MEDLINE]


1310. Version 3. F1000Res. 2013 Oct 10 [revised 2013 Dec 17];2:211. doi:
10.12688/f1000research.2-211.v3. eCollection 2013.

Protein structure quality assessment based on the distance profiles of
consecutive backbone Cα atoms.

Chakraborty S(1), Venkatramani R(2), Rao BJ(1), Asgeirsson B(3), Dandekar AM(4).

Author information: 
(1)Department of Biological Sciences, Tata Institute of Fundamental Research,
Mumbai, 400 005, India. (2)Department of Chemical Sciences, Tata Institute of
Fundamental Research, Mumbai, 400 005, India. (3)Science Institute, Department of
Biochemistry, University of Iceland, Reykjavik, IS-107, Iceland. (4)Plant
Sciences Department, University of California, Davis, CA 95616, USA.

Predicting the three dimensional native state structure of a protein from its
primary sequence is an unsolved grand challenge in molecular biology. Two main
computational approaches have evolved to obtain the structure from the protein
sequence - ab initio/de novo methods and template-based modeling - both of which 
typically generate multiple possible native state structures. Model quality
assessment programs (MQAP) validate these predicted structures in order to
identify the correct native state structure. Here, we propose a MQAP for
assessing the quality of protein structures based on the distances of consecutive
Cα atoms. We hypothesize that the root-mean-square deviation of the distance of
consecutive Cα (RDCC) atoms from the ideal value of 3.8 Å, derived from a
statistical analysis of high quality protein structures (top100H database), is
minimized in native structures. Based on tests with the top100H set, we propose a
RDCC cutoff value of 0.012 Å, above which a structure can be filtered out as a
non-native structure. We applied the RDCC discriminator on decoy sets from the
Decoys 'R' Us database to show that the native structures in all decoy sets
tested have RDCC below the 0.012 Å cutoff. While most decoy sets were either
indistinguishable using this discriminator or had very few violations, all the
decoy structures in the fisa decoy set were discriminated by applying the RDCC
criterion. This highlights the physical non-viability of the fisa decoy set, and 
possible issues in benchmarking other methods using this set. The source code and
manual is made available at https://github.com/sanchak/mqap and permanently
available on 10.5281/zenodo.7134.

DOI: 10.12688/f1000research.2-211.v3 
PMCID: PMC3892923
PMID: 24555103  [PubMed]


1311. Bioinformatics. 2014 Jun 15;30(12):1667-73. doi: 10.1093/bioinformatics/btu093.
Epub 2014 Feb 14.

EXTREME: an online EM algorithm for motif discovery.

Quang D(1), Xie X(1).

Author information: 
(1)Department of Computer Science, University of California, Irvine, CA 92697,
USA and Center for Complex Biological Systems, University of California, Irvine, 
CA 92697, USADepartment of Computer Science, University of California, Irvine, CA
92697, USA and Center for Complex Biological Systems, University of California,
Irvine, CA 92697, USA.

MOTIVATION: Identifying regulatory elements is a fundamental problem in the field
of gene transcription. Motif discovery-the task of identifying the sequence
preference of transcription factor proteins, which bind to these elements-is an
important step in this challenge. MEME is a popular motif discovery algorithm.
Unfortunately, MEME's running time scales poorly with the size of the dataset.
Experiments such as ChIP-Seq and DNase-Seq are providing a rich amount of
information on the binding preference of transcription factors. MEME cannot
discover motifs in data from these experiments in a practical amount of time
without a compromising strategy such as discarding a majority of the sequences.
RESULTS: We present EXTREME, a motif discovery algorithm designed to find
DNA-binding motifs in ChIP-Seq and DNase-Seq data. Unlike MEME, which uses the
expectation-maximization algorithm for motif discovery, EXTREME uses the online
expectation-maximization algorithm to discover motifs. EXTREME can discover
motifs in large datasets in a practical amount of time without discarding any
sequences. Using EXTREME on ChIP-Seq and DNase-Seq data, we discover many motifs,
including some novel and infrequent motifs that can only be discovered by using
the entire dataset. Conservation analysis of one of these novel infrequent motifs
confirms that it is evolutionarily conserved and possibly functional.
AVAILABILITY AND IMPLEMENTATION: All source code is available at the Github
repository http://github.com/uci-cbcl/EXTREME.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu093 
PMCID: PMC4058924
PMID: 24532725  [PubMed - indexed for MEDLINE]


1312. Bioinformatics. 2014 Jun 15;30(12):1690-7. doi: 10.1093/bioinformatics/btu065.
Epub 2014 Feb 14.

Discrete mixture modeling to address genetic heterogeneity in time-to-event
regression.

Eng KH(1), Hanlon BM(1).

Author information: 
(1)Department of Biostatistics and Bioinformatics, Roswell Park Cancer Institute,
Elm and Carlton Streets, Buffalo, NY 14263, USA and Department of Statistics,
University of Wisconsin-Madison, 1300 University Avenue, Madison, WI 53705, USA.

MOTIVATION: Time-to-event regression models are a critical tool for associating
survival time outcomes with molecular data. Despite mounting evidence that
genetic subgroups of the same clinical disease exist, little attention has been
given to exploring how this heterogeneity affects time-to-event model building
and how to accommodate it. Methods able to diagnose and model heterogeneity
should be valuable additions to the biomarker discovery toolset.
RESULTS: We propose a mixture of survival functions that classifies subjects with
similar relationships to a time-to-event response. This model incorporates
multivariate regression and model selection and can be fit with an expectation
maximization algorithm, we call Cox-assisted clustering. We illustrate a likely
manifestation of genetic heterogeneity and demonstrate how it may affect survival
models with little warning. An application to gene expression in ovarian cancer
DNA repair pathways illustrates how the model may be used to learn new genetic
subsets for risk stratification. We explore the implications of this model for
censored observations and the effect on genomic predictors and diagnostic
analysis.
AVAILABILITY AND IMPLEMENTATION: R implementation of CAC using standard packages 
is available at https://gist.github.com/programeng/8620b85146b14b6edf8f Data used
in the analysis are publicly available.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu065 
PMCID: PMC4058947
PMID: 24532723  [PubMed - indexed for MEDLINE]


1313. Bioinformatics. 2014 Jun 15;30(12):1765-6. doi: 10.1093/bioinformatics/btu095.
Epub 2014 Feb 14.

SBARS: fast creation of dotplots for DNA sequences on different scales using
GA-,GC-content.

Pyatkov MI(1), Pankratov AN(1).

Author information: 
(1)Institute of Mathematical Problems of Biology, Russian Academy of Sciences,
Pushchino, Moscow region 142290, Russia.

SUMMARY: Structural analysis of long DNA fragments, including chromosomes and
whole genomes, is one of the main challenges in modern bioinformatics. Here, we
propose an original approach based on spectral methods and its implementation
called SBARS (Spectral-Based Approach for Repeats Search. The main idea of our
approach is that repeated DNA structures are recognized not within the nucleotide
sequence directly but within the function derived from this sequence. This allows
us to investigate nucleotide sequences on different scales and decrease time
complexity for dotplot creation down to [Formula: see text].
AVAILABILITY AND IMPLEMENTATION: Pre-compiled versions for Windows and Linux and 
documentation are available at http://mpyatkov.github.com/sbars/.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu095 
PMID: 24532721  [PubMed - indexed for MEDLINE]


1314. Evol Bioinform Online. 2014 Feb 6;10:11-6. doi: 10.4137/EBO.S13121. eCollection
2014.

RapidMic: Rapid Computation of the Maximal Information Coefficient.

Tang D(1), Wang M(2), Zheng W(1), Wang H(3).

Author information: 
(1)Institute of Information Research, Southwest Jiaotong University, Chengdu,
China. (2)School of Mathematics, Southwest Jiaotong University, Chengdu, China.
(3)School of Information Science and Technology, Southwest Jiaotong University,
Chengdu, China.

To discover relationships and associations rapidly in large-scale datasets, we
propose a cross-platform tool for the rapid computation of the maximal
information coefficient based on parallel computing methods. Through parallel
processing, the provided tool can effectively analyze large-scale biological
datasets with a markedly reduced computing time. The experimental results show
that the proposed tool is notably fast, and is able to perform an all-pairs
analysis of a large biological dataset using a normal computer. The source code
and guidelines can be downloaded from https://github.com/HelloWorldCN/RapidMic.

DOI: 10.4137/EBO.S13121 
PMCID: PMC3921152
PMID: 24526831  [PubMed]


1315. PLoS Comput Biol. 2014 Feb 6;10(2):e1003465. doi: 10.1371/journal.pcbi.1003465.
eCollection 2014.

Comparative genome-scale reconstruction of gapless metabolic networks for present
and ancestral species.

Pitkänen E(1), Jouhten P(2), Hou J(3), Syed MF(2), Blomberg P(2), Kludas J(4),
Oja M(2), Holm L(5), Penttilä M(2), Rousu J(4), Arvas M(2).

Author information: 
(1)Department of Computer Science, University of Helsinki, Helsinki, Finland ;
Department of Medical Genetics, Genome-Scale Biology Research Program, University
of Helsinki, Helsinki, Finland. (2)VTT Technical Research Centre of Finland,
Espoo, Finland. (3)Department of Computer Science, University of Helsinki,
Helsinki, Finland ; Department of Information and Computer Science, Aalto
University, Espoo, Finland. (4)Department of Information and Computer Science,
Aalto University, Espoo, Finland. (5)Institute of Biotechnology & Department of
Biosciences, University of Helsinki, Helsinki, Finland.

We introduce a novel computational approach, CoReCo, for comparative metabolic
reconstruction and provide genome-scale metabolic network models for 49 important
fungal species. Leveraging on the exponential growth in sequenced genome
availability, our method reconstructs genome-scale gapless metabolic networks
simultaneously for a large number of species by integrating sequence data in a
probabilistic framework. High reconstruction accuracy is demonstrated by
comparisons to the well-curated Saccharomyces cerevisiae consensus model and
large-scale knock-out experiments. Our comparative approach is particularly
useful in scenarios where the quality of available sequence data is lacking, and 
when reconstructing evolutionary distant species. Moreover, the reconstructed
networks are fully carbon mapped, allowing their use in 13C flux analysis. We
demonstrate the functionality and usability of the reconstructed fungal models
with computational steady-state biomass production experiment, as these fungi
include some of the most important production organisms in industrial
biotechnology. In contrast to many existing reconstruction techniques, only
minimal manual effort is required before the reconstructed models are usable in
flux balance experiments. CoReCo is available at
http://esaskar.github.io/CoReCo/.

DOI: 10.1371/journal.pcbi.1003465 
PMCID: PMC3916221
PMID: 24516375  [PubMed - indexed for MEDLINE]


1316. J Vis. 2014 Feb 7;14(2). pii: 6. doi: 10.1167/14.2.6.

RenderToolbox3: MATLAB tools that facilitate physically based stimulus rendering 
for vision research.

Heasly BS(1), Cottaris NP, Lichtman DP, Xiao B, Brainard DH.

Author information: 
(1)Department of Psychology, University of Pennsylvania, Philadelphia, PA, USA.

RenderToolbox3 provides MATLAB utilities and prescribes a workflow that should be
useful to researchers who want to employ graphics in the study of vision and
perhaps in other endeavors as well. In particular, RenderToolbox3 facilitates
rendering scene families in which various scene attributes and renderer behaviors
are manipulated parametrically, enables spectral specification of object
reflectance and illuminant spectra, enables the use of physically based material 
specifications, helps validate renderer output, and converts renderer output to
physical units of radiance. This paper describes the design and functionality of 
the toolbox and discusses several examples that demonstrate its use. We have
designed RenderToolbox3 to be portable across computer hardware and operating
systems and to be free and open source (except for MATLAB itself). RenderToolbox3
is available at https://github.com/DavidBrainard/RenderToolbox3.

DOI: 10.1167/14.2.6 
PMCID: PMC3919102
PMID: 24511145  [PubMed - indexed for MEDLINE]


1317. BMC Bioinformatics. 2014 Feb 6;15:44. doi: 10.1186/1471-2105-15-44.

The HTS barcode checker pipeline, a tool for automated detection of illegally
traded species from high-throughput sequencing data.

Lammers Y, Peelen T, Vos RA, Gravendeel B(1).

Author information: 
(1)Naturalis Biodiversity Center, Darwinweg 4, 2333 CR Leiden, The Netherlands.
Barbara.Gravendeel@naturalis.nl.

BACKGROUND: Mixtures of internationally traded organic substances can contain
parts of species protected by the Convention on International Trade in Endangered
Species of Wild Fauna and Flora (CITES). These mixtures often raise the suspicion
of border control and customs offices, which can lead to confiscation, for
example in the case of Traditional Chinese medicines (TCMs). High-throughput
sequencing of DNA barcoding markers obtained from such samples provides insight
into species constituents of mixtures, but manual cross-referencing of results
against the CITES appendices is labor intensive. Matching DNA barcodes against
NCBI GenBank using BLAST may yield misleading results both as false positives,
due to incorrectly annotated sequences, and false negatives, due to spurious
taxonomic re-assignment. Incongruence between the taxonomies of CITES and NCBI
GenBank can result in erroneous estimates of illegal trade.
RESULTS: The HTS barcode checker pipeline is an application for automated
processing of sets of 'next generation' barcode sequences to determine whether
these contain DNA barcodes obtained from species listed on the CITES appendices. 
This analytical pipeline builds upon and extends existing open-source
applications for BLAST matching against the NCBI GenBank reference database and
for taxonomic name reconciliation. In a single operation, reads are converted
into taxonomic identifications matched with names on the CITES appendices. By
inclusion of a blacklist and additional names databases, the HTS barcode checker 
pipeline prevents false positives and resolves taxonomic heterogeneity.
CONCLUSIONS: The HTS barcode checker pipeline can detect and correctly identify
DNA barcodes of CITES-protected species from reads obtained from TCM samples in
just a few minutes. The pipeline facilitates and improves molecular monitoring of
trade in endangered species, and can aid in safeguarding these species from
extinction in the wild. The HTS barcode checker pipeline is available at
https://github.com/naturalis/HTS-barcode-checker.

DOI: 10.1186/1471-2105-15-44 
PMCID: PMC3922334
PMID: 24502833  [PubMed - indexed for MEDLINE]


1318. Bioinformatics. 2014 Jun 1;30(11):1514-21. doi: 10.1093/bioinformatics/btu054.
Epub 2014 Feb 4.

Visualization and probability-based scoring of structural variants within
repetitive sequences.

Halper-Stromberg E(1), Steranka J(2), Burns KH(1), Sabunciyan S(3), Irizarry
RA(3).

Author information: 
(1)Department of Biostatistics, Bloomberg School of Public Health, Johns Hopkins 
University, Program in Human Genetics and Molecular Biology, Johns Hopkins
University School of Medicine, Computational Bioscience Program, University of
Colorado, Denver, Department of Molecular Biology and Genetics, Department of
Oncology, The Sidney Kimmel Comprehensive Cancer Center, Johns Hopkins Hospital, 
Department of Pathology, Johns Hopkins University, High Throughput Biology
Center, Johns Hopkins University School of Medicine, Johns Hopkins University,
Center for Epigenetics, Johns Hopkins University School of Medicine, Department
of Pediatrics, Johns Hopkins University School of Medicine, Baltimore, MD and
Department of Biostatistics and Computational Biology, Dana Farber Cancer
Institute, Boston, Massachusetts, MA, USADepartment of Biostatistics, Bloomberg
School of Public Health, Johns Hopkins University, Program in Human Genetics and 
Molecular Biology, Johns Hopkins University School of Medicine, Computational
Bioscience Program, University of Colorado, Denver, Department of Molecular
Biology and Genetics, Department of Oncology, The Sidney Kimmel Comprehensive
Cancer Center, Johns Hopkins Hospital, Department of Pathology, Johns Hopkins
University, High Throughput Biology Center, Johns Hopkins University School of
Medicine, Johns Hopkins University, Center for Epigenetics, Johns Hopkins
University School of Medicine, Department of Pediatrics, Johns Hopkins University
School of Medicine, Baltimore, MD and Department of Biostatistics and
Computational Biology, Dana Farber Cancer Institute, Boston, Massachusetts, MA,
USADepartment of Biostatistics, Bloomberg School of Public Health, Johns Hopkins 
University, Program in Human Genetics and Molecular Biology, Johns Hopkins
University School of Medicine, Computational Bioscience Program, University of
Colorado, Denver, Department of Molecular Biology and Genetics, Department of
Oncology, The Sidney Kimmel Comprehensive Cancer Cente (2)Department of
Biostatistics, Bloomberg School of Public Health, Johns Hopkins University,
Program in Human Genetics and Molecular Biology, Johns Hopkins University School 
of Medicine, Computational Bioscience Program, University of Colorado, Denver,
Department of Molecular Biology and Genetics, Department of Oncology, The Sidney 
Kimmel Comprehensive Cancer Center, Johns Hopkins Hospital, Department of
Pathology, Johns Hopkins University, High Throughput Biology Center, Johns
Hopkins University School of Medicine, Johns Hopkins University, Center for
Epigenetics, Johns Hopkins University School of Medicine, Department of
Pediatrics, Johns Hopkins University School of Medicine, Baltimore, MD and
Department of Biostatistics and Computational Biology, Dana Farber Cancer
Institute, Boston, Massachusetts, MA, USA. (3)Department of Biostatistics,
Bloomberg School of Public Health, Johns Hopkins University, Program in Human
Genetics and Molecular Biology, Johns Hopkins University School of Medicine,
Computational Bioscience Program, University of Colorado, Denver, Department of
Molecular Biology and Genetics, Department of Oncology, The Sidney Kimmel
Comprehensive Cancer Center, Johns Hopkins Hospital, Department of Pathology,
Johns Hopkins University, High Throughput Biology Center, Johns Hopkins
University School of Medicine, Johns Hopkins University, Center for Epigenetics, 
Johns Hopkins University School of Medicine, Department of Pediatrics, Johns
Hopkins University School of Medicine, Baltimore, MD and Department of
Biostatistics and Computational Biology, Dana Farber Cancer Institute, Boston,
Massachusetts, MA, USADepartment of Biostatistics, Bloomberg School of Public
Health, Johns Hopkins University, Program in Human Genetics and Molecular
Biology, Johns Hopkins University School of Medicine, Computational Bioscience
Program, University of Colorado, Denver, Department of Molecular Biology and
Genetics, Department of Oncology, The Sidney Kimmel Comprehensive Cancer Center, 
Johns Hopkins Hospital, Department of Pathology, Johns Hopkins University, High
Throughput Biology Center, Johns Hopkins University School of Medicine, Johns
Hopkins University, Center for Epigenetics, Johns Hopkins University School of
Medicine, Department of Pediatrics, Johns Hopkins University School of Medicine, 
Baltimore, MD and Department of Biostatistics and Computational Biology, Dana
Farber Cancer Institute, Boston, Massachusetts, MA, USA.

MOTIVATION: Repetitive sequences account for approximately half of the human
genome. Accurately ascertaining sequences in these regions with next generation
sequencers is challenging, and requires a different set of analytical techniques 
than for reads originating from unique sequences. Complicating the matter are
repetitive regions subject to programmed rearrangements, as is the case with the 
antigen-binding domains in the Immunoglobulin (Ig) and T-cell receptor (TCR)
loci.
RESULTS: We developed a probability-based score and visualization method to aid
in distinguishing true structural variants from alignment artifacts. We
demonstrate the usefulness of this method in its ability to separate real
structural variants from false positives generated with existing upstream
analysis tools. We validated our approach using both target-capture and
whole-genome experiments. Capture sequencing reads were generated from primary
lymphoid tumors, cancer cell lines and an EBV-transformed lymphoblast cell line
over the Ig and TCR loci. Whole-genome sequencing reads were from a
lymphoblastoid cell-line.
AVAILABILITY: We implement our method as an R package available at
https://github.com/Eitan177/targetSeqView. Code to reproduce the figures and
results are also available.

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/bioinformatics/btu054 
PMCID: PMC4029030
PMID: 24501098  [PubMed - indexed for MEDLINE]


1319. Bioinformatics. 2014 Jun 1;30(11):1637-9. doi: 10.1093/bioinformatics/btu075.
Epub 2014 Feb 3.

ARTS: automated randomization of multiple traits for study design.

Maienschein-Cline M(1), Lei Z(1), Gardeux V(2), Abbasi T(1), Machado RF(1),
Gordeuk V(1), Desai AA(1), Saraf S(1), Bahroos N(1), Lussier Y(3).

Author information: 
(1)Center for Research Informatics, Institute for Interventional Health
Informatics, Department of Medicine, Department of Bioengineering, University of 
Illinois at Chicago, Chicago, IL, Computation Institute of The University of
Chicago, Chicago and Argonne National Laboratory, The University of Chicago,
Lemont, IL, USA. (2)Center for Research Informatics, Institute for Interventional
Health Informatics, Department of Medicine, Department of Bioengineering,
University of Illinois at Chicago, Chicago, IL, Computation Institute of The
University of Chicago, Chicago and Argonne National Laboratory, The University of
Chicago, Lemont, IL, USACenter for Research Informatics, Institute for
Interventional Health Informatics, Department of Medicine, Department of
Bioengineering, University of Illinois at Chicago, Chicago, IL, Computation
Institute of The University of Chicago, Chicago and Argonne National Laboratory, 
The University of Chicago, Lemont, IL, USACenter for Research Informatics,
Institute for Interventional Health Informatics, Department of Medicine,
Department of Bioengineering, University of Illinois at Chicago, Chicago, IL,
Computation Institute of The University of Chicago, Chicago and Argonne National 
Laboratory, The University of Chicago, Lemont, IL, USA. (3)Center for Research
Informatics, Institute for Interventional Health Informatics, Department of
Medicine, Department of Bioengineering, University of Illinois at Chicago,
Chicago, IL, Computation Institute of The University of Chicago, Chicago and
Argonne National Laboratory, The University of Chicago, Lemont, IL, USACenter for
Research Informatics, Institute for Interventional Health Informatics, Department
of Medicine, Department of Bioengineering, University of Illinois at Chicago,
Chicago, IL, Computation Institute of The University of Chicago, Chicago and
Argonne National Laboratory, The University of Chicago, Lemont, IL, USACenter for
Research Informatics, Institute for Interventional Health Informatics, Department
of Medicine, Department of Bioengineering, University of Illinois at Chicago,
Chicago, IL, Computation Institute of The University of Chicago, Chicago and
Argonne National Laboratory, The University of Chicago, Lemont, IL, USACenter for
Research Informatics, Institute for Interventional Health Informatics, Department
of Medicine, Department of Bioengineering, University of Illinois at Chicago,
Chicago, IL, Computation Institute of The University of Chicago, Chicago and
Argonne National Laboratory, The University of Chicago, Lemont, IL, USACenter for
Research Informatics, Institute for Interventional Health Informatics, Department
of Medicine, Department of Bioengineering, University of Illinois at Chicago,
Chicago, IL, Computation Institute of The University of Chicago, Chicago and
Argonne National Laboratory, The University of Chicago, Lemont, IL, USA.

Collecting data from large studies on high-throughput platforms, such as
microarray or next-generation sequencing, typically requires processing samples
in batches. There are often systematic but unpredictable biases from
batch-to-batch, so proper randomization of biologically relevant traits across
batches is crucial for distinguishing true biological differences from
experimental artifacts. When a large number of traits are biologically relevant, 
as is common for clinical studies of patients with varying sex, age, genotype and
medical background, proper randomization can be extremely difficult to prepare by
hand, especially because traits may affect biological inferences, such as
differential expression, in a combinatorial manner. Here we present ARTS
(automated randomization of multiple traits for study design), which aids
researchers in study design by automatically optimizing batch assignment for any 
number of samples, any number of traits and any batch size.AVAILABILITY AND
IMPLEMENTATION: ARTS is implemented in Perl and is available at
github.com/mmaiensc/ARTS. ARTS is also available in the Galaxy Tool Shed, and can
be used at the Galaxy installation hosted by the UIC Center for Research
Informatics (CRI) at galaxy.cri.uic.edu.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please email: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu075 
PMCID: PMC4029038
PMID: 24493035  [PubMed - indexed for MEDLINE]


1320. Bioinformatics. 2014 Jun 1;30(11):1625-6. doi: 10.1093/bioinformatics/btu057.
Epub 2014 Jan 30.

StochHMM: a flexible hidden Markov model tool and C++ library.

Lott PC(1), Korf I(1).

Author information: 
(1)Genome Center, One Shields Ave., University of California, Davis, CA 95616,
USA.

Hidden Markov models (HMMs) are probabilistic models that are well-suited to
solve many different classification problems in computation biology. StochHMM
provides a command-line program and C++ library that can implement a traditional 
HMM from a simple text file. StochHMM provides researchers the flexibility to
create higher-order emissions, integrate additional data sources and/or
user-defined functions into multiple points within the HMM framework. Additional 
features include user-defined alphabets, ability to handle ambiguous characters
in an emission-dependent manner, user-defined weighting of state paths and
ability to tie transition probabilities to sequence.AVAILABILITY AND
IMPLEMENTATION: StochHMM is implemented in C++ and is available under the MIT
License. Software, source code, documentation and examples can be found at
http://github.com/KorfLab/StochHMM.

© The Author 2014. Published by Oxford University Press. All rights reserved. For
Permissions, please e-mail: journals.permissions@oup.com.

DOI: 10.1093/bioinformatics/btu057 
PMCID: PMC4029032
PMID: 24489371  [PubMed - indexed for MEDLINE]


1321. BMC Bioinformatics. 2014 Feb 1;15:35. doi: 10.1186/1471-2105-15-35.

Inferring clonal evolution of tumors from single nucleotide somatic mutations.

Jiao W, Vembu S, Deshwar AG, Stein L, Morris Q(1).

Author information: 
(1)Department of Molecular Genetics, University of Toronto, Toronto, Canada.
quaid.morris@utoronto.ca.

BACKGROUND: High-throughput sequencing allows the detection and quantification of
frequencies of somatic single nucleotide variants (SNV) in heterogeneous tumor
cell populations. In some cases, the evolutionary history and population
frequency of the subclonal lineages of tumor cells present in the sample can be
reconstructed from these SNV frequency measurements. But automated methods to do 
this reconstruction are not available and the conditions under which
reconstruction is possible have not been described.
RESULTS: We describe the conditions under which the evolutionary history can be
uniquely reconstructed from SNV frequencies from single or multiple samples from 
the tumor population and we introduce a new statistical model, PhyloSub, that
infers the phylogeny and genotype of the major subclonal lineages represented in 
the population of cancer cells. It uses a Bayesian nonparametric prior over trees
that groups SNVs into major subclonal lineages and automatically estimates the
number of lineages and their ancestry. We sample from the joint posterior
distribution over trees to identify evolutionary histories and cell population
frequencies that have the highest probability of generating the observed SNV
frequency data. When multiple phylogenies are consistent with a given set of SNV 
frequencies, PhyloSub represents the uncertainty in the tumor phylogeny using a
"partial order plot". Experiments on a simulated dataset and two real datasets
comprising tumor samples from acute myeloid leukemia and chronic lymphocytic
leukemia patients demonstrate that PhyloSub can infer both linear (or chain) and 
branching lineages and its inferences are in good agreement with ground truth,
where it is available.
CONCLUSIONS: PhyloSub can be applied to frequencies of any "binary" somatic
mutation, including SNVs as well as small insertions and deletions. The PhyloSub 
and partial order plot software is available from
https://github.com/morrislab/phylosub/.

DOI: 10.1186/1471-2105-15-35 
PMCID: PMC3922638
PMID: 24484323  [PubMed - indexed for MEDLINE]


1322. Biochem Biophys Res Commun. 2014 Mar 21;445(4):702-7. doi:
10.1016/j.bbrc.2014.01.066. Epub 2014 Jan 27.

KYSS: mass spectrometry data quality assessment for protein analysis and
large-scale proteomics.

Such-Sanmartín G(1), Sidoli S(2), Ventura-Espejo E(2), Jensen ON(2).

Author information: 
(1)Department of Biochemistry and Molecular Biology, University of Southern
Denmark, Campusvej 55, DK-5230 Odense M, Denmark. Electronic address:
gss@bmb.sdu.dk. (2)Department of Biochemistry and Molecular Biology, University
of Southern Denmark, Campusvej 55, DK-5230 Odense M, Denmark.

We introduce the computer tool "Know Your Samples" (KYSS) for assessment and
visualisation of large scale proteomics datasets, obtained by mass spectrometry
(MS) experiments. KYSS facilitates the evaluation of sample preparation
protocols, LC peptide separation, and MS and MS/MS performance by monitoring the 
number of missed cleavages, precursor ion charge states, number of protein
identifications and peptide mass error in experiments. KYSS generates several
different protein profiles based on protein abundances, and allows for
comparative analysis of multiple experiments. KYSS was adapted for blood plasma
proteomics and provides concentrations of identified plasma proteins. We
demonstrate the utility of the KYSS tool for MS based proteome analysis of blood 
plasma and for assessment of hydrogel particles for depletion of abundant
proteins in plasma. The KYSS software is open source and is freely available at
http://kyssproject.github.io/.

Copyright © 2014 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.bbrc.2014.01.066 
PMID: 24480439  [PubMed - indexed for MEDLINE]


1323. Bioinformatics. 2014 May 15;30(10):1476-7. doi: 10.1093/bioinformatics/btu053.
Epub 2014 Jan 28.

PUmPER: phylogenies updated perpetually.

Izquierdo-Carrasco F(1), Cazes J, Smith SA, Stamatakis A.

Author information: 
(1)Scientific Computing Group, Heidelberg Institute for Theoretical Studies (HITS
gGmbH), Schloss-Wolfsbrunnenweg 35, D-69118 Heidelberg, Baden-Württemberg,
Germany, Texas Advanced Computing Center, University of Texas, Austin, TX, 78758,
USA, University of Michigan, Ann Arbor Department of Ecology and Evolutionary
Biology, 48109, MI, USA and Karlsruhe Institute of Technology, Institute for
Theoretical Informatics, Postfach 6980, 76128 Karlsruhe, Baden-Württemberg,
Germany.

SUMMARY: New sequence data useful for phylogenetic and evolutionary analyses
continues to be added to public databases. The construction of multiple sequence 
alignments and inference of huge phylogenies comprising large taxonomic groups
are expensive tasks, both in terms of man hours and computational resources.
Therefore, maintaining comprehensive phylogenies, based on representative and
up-to-date molecular sequences, is challenging. PUmPER is a framework that can
perpetually construct multi-gene alignments (with PHLAWD) and phylogenetic trees 
(with ExaML or RAxML-Light) for a given NCBI taxonomic group. When sufficient
numbers of new gene sequences for the selected taxonomic group have accumulated
in GenBank, PUmPER automatically extends the alignment and infers extended
phylogenetic trees by using previously inferred smaller trees as starting
topologies. Using our framework, large phylogenetic trees can be perpetually
updated without human intervention. Importantly, resulting phylogenies are not
statistically significantly worse than trees inferred from scratch.
AVAILABILITY AND IMPLEMENTATION: PUmPER can run in stand-alone mode on a single
server, or offload the computationally expensive phylogenetic searches to a
parallel computing cluster. Source code, documentation, and tutorials are
available at https://github.com/fizquierdo/perpetually-updated-trees.
CONTACT: Fernando.Izquierdo@h-its.org
SUPPLEMENTARY INFORMATION: Supplementary Material is available at Bioinformatics 
online.

DOI: 10.1093/bioinformatics/btu053 
PMCID: PMC4016711
PMID: 24478338  [PubMed - indexed for MEDLINE]


1324. G3 (Bethesda). 2014 Mar 20;4(3):547-52. doi: 10.1534/g3.113.009431.

gitter: a robust and accurate method for quantification of colony sizes from
plate images.

Wagih O(1), Parts L.

Author information: 
(1)European Bioinformatics Institute, Wellcome Trust Genome Campus, Hinxton CB10 
1SD, UK.

Colony-based screens that quantify the fitness of clonal populations on solid
agar plates are perhaps the most important source of genome-scale functional
information in microorganisms. The images of ordered arrays of mutants produced
by such experiments can be difficult to process because of laboratory-specific
plate features, morphed colonies, plate edges, noise, and other artifacts. Most
of the tools developed to address this problem are optimized to handle a single
setup and do not work out of the box in other settings. We present gitter, an
image analysis tool for robust and accurate processing of images from
colony-based screens. gitter works by first finding the grid of colonies from a
preprocessed image and then locating the bounds of each colony separately. We
show that gitter produces comparable colony sizes to other tools in simple cases 
but outperforms them by being able to handle a wider variety of screens and more 
accurately quantify colony sizes from difficult images. gitter is freely
available as an R package from http://cran.r-project.org/web/packages/gitter
under the LGPL. Tutorials and demos can be found at
http://omarwagih.github.io/gitter.

DOI: 10.1534/g3.113.009431 
PMCID: PMC3962492
PMID: 24474170  [PubMed - indexed for MEDLINE]


1325. BMC Genomics. 2014 Jan 28;15:76. doi: 10.1186/1471-2164-15-76.

Combinatorial epigenetic patterns as quantitative predictors of chromatin
biology.

Cieślik M(1), Bekiranov S.

Author information: 
(1)Department of Biochemistry and Molecular Genetics, University of Virginia
Health System, Charlottesville, Virginia, USA. mpc4p@virginia.edu.

BACKGROUND: Chromatin immunoprecipitation followed by deep sequencing (ChIP-seq) 
is the most widely used method for characterizing the epigenetic states of
chromatin on a genomic scale. With the recent availability of large genome-wide
data sets, often comprising several epigenetic marks, novel approaches are
required to explore functionally relevant interactions between histone
modifications. Computational discovery of "chromatin states" defined by such
combinatorial interactions enabled descriptive annotations of genomes, but more
quantitative approaches are needed to progress towards predictive models.
RESULTS: We propose non-negative matrix factorization (NMF) as a new unsupervised
method to discover combinatorial patterns of epigenetic marks that frequently
co-occur in subsets of genomic regions. We show that this small set of
combinatorial "codes" can be effectively displayed and interpreted. NMF codes
enable dimensionality reduction and have desirable statistical properties for
regression and classification tasks. We demonstrate the utility of codes in the
quantitative prediction of Pol2-binding and the discrimination between Pol2-bound
promoters and enhancers. Finally, we show that specific codes can be linked to
molecular pathways and targets of pluripotency genes during differentiation.
CONCLUSIONS: We have introduced and evaluated a new computational approach to
represent combinatorial patterns of epigenetic marks as quantitative variables
suitable for predictive modeling and supervised machine learning. To foster
widespread adoption of this method we make it available as an open-source
software-package - epicode at https://github.com/mcieslik-mctp/epicode.

DOI: 10.1186/1471-2164-15-76 
PMCID: PMC3922690
PMID: 24472558  [PubMed - indexed for MEDLINE]


1326. Bioinformatics. 2014 May 15;30(10):1471-2. doi: 10.1093/bioinformatics/btu036.
Epub 2014 Jan 26.

NGSANE: a lightweight production informatics framework for high-throughput data
analysis.

Buske FA(1), French HJ, Smith MA, Clark SJ, Bauer DC.

Author information: 
(1)Cancer Epigenetics Program, Cancer Research Division, Kinghorn Cancer Centre, 
Garvan Institute of Medical Research, RNA Biology and Plasticity Laboratory,
Garvan Institute of Medical Research, St Vincent's Clinical School, University of
NSW, Sydney 2010, Australia and Division of Computational Informatics, CSIRO,
Sydney 2113, Australia.

SUMMARY: The initial steps in the analysis of next-generation sequencing data can
be automated by way of software 'pipelines'. However, individual components
depreciate rapidly because of the evolving technology and analysis methods, often
rendering entire versions of production informatics pipelines obsolete.
Constructing pipelines from Linux bash commands enables the use of hot swappable 
modular components as opposed to the more rigid program call wrapping by higher
level languages, as implemented in comparable published pipelining systems. Here 
we present Next Generation Sequencing ANalysis for Enterprises (NGSANE), a
Linux-based, high-performance-computing-enabled framework that minimizes overhead
for set up and processing of new projects, yet maintains full flexibility of
custom scripting when processing raw sequence data.
AVAILABILITY AND IMPLEMENTATION: Ngsane is implemented in bash and publicly
available under BSD (3-Clause) licence via GitHub at
https://github.com/BauerLab/ngsane.
CONTACT: Denis.Bauer@csiro.au
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btu036 
PMCID: PMC4016703
PMID: 24470576  [PubMed - indexed for MEDLINE]


1327. Bioinformatics. 2014 May 15;30(10):1491-2. doi: 10.1093/bioinformatics/btu050.
Epub 2014 Jan 27.

Bio Simulators: a web UI for biological simulation.

Pedersen M(1), Oury N, Gravill C, Phillips A.

Author information: 
(1)Department of Plant Sciences, Cambridge University, Cambridge CB2 3EA, UK,
School of Informatics, Edinburgh University, Edinburgh EH8 9AB, Scotland and
Microsoft Research, Cambridge CB1 2FB, UK.

SUMMARY: A host of formal, textual languages for modeling cellular processes have
recently emerged, but their simulation tools often require an installation
process which can pose a barrier for use. Bio Simulators is a framework for easy 
online deployment of simulators, providing a uniform web-based user interface to 
a diverse pool of tools. The framework is demonstrated through two plugins based 
on the KaSim Kappa simulator, one running directly in the browser and another
running in the cloud.
AVAILABILITY: Web tool: bsims.azurewebsites.net. KaSim client side simulator:
github.com/NicolasOury/KaSimJS. KaSim cloud simulator:
github.com/mdpedersen/KaSimCloud.
CONTACT: michael.d.pedersen@gmail.com or Andrew.Phillips@microsoft.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btu050 
PMID: 24470571  [PubMed - indexed for MEDLINE]


1328. Bioinformatics. 2014 May 15;30(10):1486-7. doi: 10.1093/bioinformatics/btu041.
Epub 2014 Jan 23.

ngsTools: methods for population genetics analyses from next-generation
sequencing data.

Fumagalli M(1), Vieira FG, Linderoth T, Nielsen R.

Author information: 
(1)Department of Integrative Biology, Department of Statistics, University of
California, Berkeley, CA 94720, USA and Department of Biology, University of
Copenhagen, Copenhagen 2200, Denmark.

SUMMARY: Next-generation sequencing technologies produce short reads that are
either de novo assembled or mapped to a reference genome. Genotypes and/or
single-nucleotide polymorphisms are then determined from the read composition at 
each site, which become the basis for many downstream analyses. However, for low 
sequencing depths, e.g. , there is considerable statistical uncertainty in the
assignment of genotypes because of random sampling of homologous base pairs in
heterozygotes and sequencing or alignment errors. Recently, several probabilistic
methods have been proposed to account for this uncertainty and make accurate
inferences from low quality and/or coverage sequencing data. We present ngsTools,
a collection of programs to perform population genetics analyses from
next-generation sequencing data. The methods implemented in these programs do not
rely on single-nucleotide polymorphism or genotype calling and are particularly
suitable for low sequencing depth data.
AVAILABILITY: Programs included in ngsTools are implemented in C/C++ and are
freely available for noncommercial use at https://github.com/mfumagalli/ngsTools.
CONTACT: mfumagalli82@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary materials are available at
Bioinformatics online.

DOI: 10.1093/bioinformatics/btu041 
PMCID: PMC4016704
PMID: 24458950  [PubMed - indexed for MEDLINE]


1329. Front Neuroinform. 2013 Dec 24;7:40. doi: 10.3389/fninf.2013.00040. eCollection
2013.

pySPACE-a signal processing and classification environment in Python.

Krell MM(1), Straube S(1), Seeland A(2), Wöhrle H(2), Teiwes J(1), Metzen JH(1), 
Kirchner EA(3), Kirchner F(3).

Author information: 
(1)Robotics Group, Faculty 3 - Mathematics and Computer Science, University of
Bremen Bremen, Germany. (2)Robotics Innovation Center, DFKI GmbH Bremen, Germany.
(3)Robotics Group, Faculty 3 - Mathematics and Computer Science, University of
Bremen Bremen, Germany ; Robotics Innovation Center, DFKI GmbH Bremen, Germany.

In neuroscience large amounts of data are recorded to provide insights into
cerebral information processing and function. The successful extraction of the
relevant signals becomes more and more challenging due to increasing complexities
in acquisition techniques and questions addressed. Here, automated signal
processing and machine learning tools can help to process the data, e.g., to
separate signal and noise. With the presented software pySPACE
(http://pyspace.github.io/pyspace), signal processing algorithms can be compared 
and applied automatically on time series data, either with the aim of finding a
suitable preprocessing, or of training supervised algorithms to classify the
data. pySPACE originally has been built to process multi-sensor windowed time
series data, like event-related potentials from the electroencephalogram (EEG).
The software provides automated data handling, distributed processing, modular
build-up of signal processing chains and tools for visualization and performance 
evaluation. Included in the software are various algorithms like temporal and
spatial filters, feature generation and selection, classification algorithms, and
evaluation schemes. Further, interfaces to other signal processing tools are
provided and, since pySPACE is a modular framework, it can be extended with new
algorithms according to individual needs. In the presented work, the structural
hierarchies are described. It is illustrated how users and developers can
interface the software and execute offline and online modes. Configuration of
pySPACE is realized with the YAML format, so that programming skills are not
mandatory for usage. The concept of pySPACE is to have one comprehensive tool
that can be used to perform complete signal processing and classification tasks. 
It further allows to define own algorithms, or to integrate and use already
existing libraries.

DOI: 10.3389/fninf.2013.00040 
PMCID: PMC3871959
PMID: 24399965  [PubMed]


1330. Biostatistics. 2014 Jul;15(3):413-26. doi: 10.1093/biostatistics/kxt053. Epub
2014 Jan 6.

Differential expression analysis of RNA-seq data at single-base resolution.

Frazee AC(1), Sabunciyan S(2), Hansen KD(1), Irizarry RA(1), Leek JT(3).

Author information: 
(1)Department of Biostatistics, The Johns Hopkins University Bloomberg School of 
Public Health, 615 North Wolfe Street, Baltimore, MD 21205, USA. (2)Department of
Pediatrics, The Johns Hopkins University School of Medicine, 600 North Wolfe
Street, Baltimore, MD 21287, USA. (3)Department of Biostatistics, The Johns
Hopkins University Bloomberg School of Public Health, 615 North Wolfe Street,
Baltimore, MD 21205, USA jtleek@gmail.com.

Erratum in
    Biostatistics. 2014 Jul;15(3):584-5.

RNA-sequencing (RNA-seq) is a flexible technology for measuring genome-wide
expression that is rapidly replacing microarrays as costs become comparable.
Current differential expression analysis methods for RNA-seq data fall into two
broad classes: (1) methods that quantify expression within the boundaries of
genes previously published in databases and (2) methods that attempt to
reconstruct full length RNA transcripts. The first class cannot discover
differential expression outside of previously known genes. While the second
approach does possess discovery capabilities, statistical analysis of
differential expression is complicated by the ambiguity and variability incurred 
while assembling transcripts and estimating their abundances. Here, we propose a 
novel method that first identifies differentially expressed regions (DERs) of
interest by assessing differential expression at each base of the genome. The
method then segments the genome into regions comprised of bases showing similar
differential expression signal, and then assigns a measure of statistical
significance to each region. Optionally, DERs can be annotated using a reference 
database of genomic features. We compare our approach with leading competitors
from both current classes of differential expression methods and highlight the
strengths and weaknesses of each. A software implementation of our method is
available on github (https://github.com/alyssafrazee/derfinder).

© The Author 2014. Published by Oxford University Press.

DOI: 10.1093/biostatistics/kxt053 
PMCID: PMC4059460
PMID: 24398039  [PubMed - indexed for MEDLINE]


1331. Biotechniques. 2015 Aug 1;59(2):82-6. doi: 10.2144/000114318. eCollection 2015.

Traxtile: Interactive editing of cell tracks in time-lapse images.

Braun BS(1).

Author information: 
(1)Department of Pediatrics, University of California, San Francisco, UCSF
Benioff Children's Hospital and The Helen Diller Family Comprehensive Cancer
Center, San Francisco, CA.

Time-lapse imaging can be used to quantify how cells move, divide, and die over
time and under defined culture conditions. Open source software packages such as 
CellProfiler, Icy, and Fiji provide robust and convenient interfaces for
performing such analyses. However, object tracking algorithms are imperfect, and 
validation of significant events is often required. This is challenging, as
CellProfiler produces only tabular data for object tracking, and the graphical
tools in Icy and Fiji are not optimal for manual review of these events. Here we 
describe Traxtile, a program that allows interactive graphical review and
revision of object tracking assignments. Traxtile imports initial assignments and
automatically identifies events needing review (i.e., apparent creation of new
objects, splits, merges, and losses). For each such event, the object track is
displayed on a montage of images centered on the event and spanning the preceding
and subsequent frames. Links between cells in successive frames can be reviewed
and edited, yielding validated tracks for the image series. Reports summarize
events from the validated tracks. Traxtile is implemented in Python version 2.7
using standard distribution libraries (available at www.python.org) and is freely
available at https://github.com/braunb/traxtile-public.

DOI: 10.2144/000114318 
PMCID: PMC4560953
PMID: 26260086  [PubMed - indexed for MEDLINE]


1332. Bioinformatics. 2014 Apr 1;30(7):1015-6. doi: 10.1093/bioinformatics/btt755. Epub
2013 Dec 25.

MSIsensor: microsatellite instability detection using paired tumor-normal
sequence data.

Niu B(1), Ye K, Zhang Q, Lu C, Xie M, McLellan MD, Wendl MC, Ding L.

Author information: 
(1)Departments of Genetics and Mathematics, The Genome Institute, Department of
Genetics, Division of Statistical Genomics, Department of Medicine and Siteman
Cancer Center, Washington University in St. Louis, MO 63108, USA.

MOTIVATION: Microsatellite instability (MSI) is an important indicator of larger 
genome instability and has been linked to many genetic diseases, including Lynch 
syndrome. MSI status is also an independent prognostic factor for favorable
survival in multiple cancer types, such as colorectal and endometrial. It also
informs the choice of chemotherapeutic agents. However, the current
PCR-electrophoresis-based detection procedure is laborious and time-consuming,
often requiring visual inspection to categorize samples. We developed MSIsensor, 
a C++ program for automatically detecting somatic microsatellite changes. It
computes length distributions of microsatellites per site in paired tumor and
normal sequence data, subsequently using these to statistically compare observed 
distributions in both samples. Comprehensive testing indicates MSIsensor is an
efficient and effective tool for deriving MSI status from standard tumor-normal
paired sequence data.
AVAILABILITY AND IMPLEMENTATION: https://github.com/ding-lab/msisensor

DOI: 10.1093/bioinformatics/btt755 
PMCID: PMC3967115
PMID: 24371154  [PubMed - indexed for MEDLINE]


1333. Bioinformatics. 2014 Apr 1;30(7):1041-2. doi: 10.1093/bioinformatics/btt741. Epub
2013 Dec 20.

SurpriseMe: an integrated tool for network community structure characterization
using Surprise maximization.

Aldecoa R(1), Marín I.

Author information: 
(1)Instituto de Biomedicina de Valencia, Consejo Superior de Investigaciones
Científicas (IBV-CSIC), Valencia 46010, Spain.

SUMMARY: Detecting communities and densely connected groups may contribute to
unravel the underlying relationships among the units present in diverse
biological networks (e.g. interactomes, coexpression networks, ecological
networks). We recently showed that communities can be precisely characterized by 
maximizing Surprise, a global network parameter. Here, we present SurpriseMe, a
tool that integrates the outputs of seven of the best algorithms available to
estimate the maximum Surprise value. SurpriseMe also generates distance matrices 
that allow visualizing the relationships among the solutions generated by the
algorithms. We show that the communities present in small- and medium-sized
networks, with up to 10 000 nodes, can be easily characterized: on standard PC
computers, these analyses take less than an hour. Also, four of the algorithms
may rapidly analyze networks with up to 100 000 nodes, given enough memory
resources. Because of its performance and simplicity, SurpriseMe is a reference
tool for community structure characterization.
AVAILABILITY AND IMPLEMENTATION: SurpriseMe is implemented in Perl and C/C++. It 
compiles and runs on any UNIX-based operating system, including Linux and Mac
OS/X, using standard libraries. The source code is freely and publicly available 
under the GPL 3.0 license at http://github.com/raldecoa/SurpriseMe/releases.

DOI: 10.1093/bioinformatics/btt741 
PMID: 24363381  [PubMed - indexed for MEDLINE]


1334. Bioinformatics. 2014 Apr 1;30(7):1025-6. doi: 10.1093/bioinformatics/btt733. Epub
2013 Dec 19.

SplicePlot: a utility for visualizing splicing quantitative trait loci.

Wu E(1), Nance T, Montgomery SB.

Author information: 
(1)Department of Pathology, Stanford University School of Medicine, Stanford, CA 
94305-5324, USA.

SUMMARY: RNA sequencing has provided unprecedented resolution of alternative
splicing and splicing quantitative trait loci (sQTL). However, there are few
tools available for visualizing the genotype-dependent effects of splicing at a
population level. SplicePlot is a simple command line utility that produces
intuitive visualization of sQTLs and their effects. SplicePlot takes mapped RNA
sequencing reads in BAM format and genotype data in VCF format as input and
outputs publication-quality Sashimi plots, hive plots and structure plots,
enabling better investigation and understanding of the role of genetics on
alternative splicing and transcript structure.
AVAILABILITY AND IMPLEMENTATION: Source code and detailed documentation are
available at http://montgomerylab.stanford.edu/spliceplot/index.html under
Resources and at Github. SplicePlot is implemented in Python and is supported on 
Linux and Mac OS. A VirtualBox virtual machine running Ubuntu with SplicePlot
already installed is also available.

DOI: 10.1093/bioinformatics/btt733 
PMCID: PMC3967110
PMID: 24363378  [PubMed - indexed for MEDLINE]


1335. Bioinformatics. 2014 Apr 1;30(7):1008-9. doi: 10.1093/bioinformatics/btt737. Epub
2013 Dec 19.

WiggleTools: parallel processing of large collections of genome-wide datasets for
visualization and statistical analysis.

Zerbino DR(1), Johnson N, Juettemann T, Wilder SP, Flicek P.

Author information: 
(1)European Molecular Biology Laboratory, European Bioinformatics Institute
(EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SD, UK.

MOTIVATION: Using high-throughput sequencing, researchers are now generating
hundreds of whole-genome assays to measure various features such as transcription
factor binding, histone marks, DNA methylation or RNA transcription. Displaying
so much data generally leads to a confusing accumulation of plots. We describe
here a multithreaded library that computes statistics on large numbers of
datasets (Wiggle, BigWig, Bed, BigBed and BAM), generating statistical summaries 
within minutes with limited memory requirements, whether on the whole genome or
on selected regions.
AVAILABILITY AND IMPLEMENTATION: The code is freely available under Apache 2.0
license at www.github.com/Ensembl/Wiggletools

DOI: 10.1093/bioinformatics/btt737 
PMCID: PMC3967112
PMID: 24363377  [PubMed - indexed for MEDLINE]


1336. Front Genet. 2013 Nov 29;4:237. doi: 10.3389/fgene.2013.00237. eCollection 2013.

Blobology: exploring raw genome data for contaminants, symbionts and parasites
using taxon-annotated GC-coverage plots.

Kumar S(1), Jones M(1), Koutsovoulos G(1), Clarke M(1), Blaxter M(2).

Author information: 
(1)Institute of Evolutionary Biology, Ashworth Laboratories, University of
Edinburgh Edinburgh, UK. (2)Institute of Evolutionary Biology, Ashworth
Laboratories, University of Edinburgh Edinburgh, UK ; Edinburgh Genomics,
University of Edinburgh Edinburgh, UK.

Generating the raw data for a de novo genome assembly project for a target
eukaryotic species is relatively easy. This democratization of access to
large-scale data has allowed many research teams to plan to assemble the genomes 
of non-model organisms. These new genome targets are very different from the
traditional, inbred, laboratory-reared model organisms. They are often small, and
cannot be isolated free of their environment - whether ingested food, the
surrounding host organism of parasites, or commensal and symbiotic organisms
attached to or within the individuals sampled. Preparation of pure DNA
originating from a single species can be technically impossible, but assembly of 
mixed-organism DNA can be difficult, as most genome assemblers perform poorly
when faced with multiple genomes in different stoichiometries. This class of
problem is common in metagenomic datasets that deliberately try to capture all
the genomes present in an environment, but replicon assembly is not often the
goal of such programs. Here we present an approach to extracting, from mixed DNA 
sequence data, subsets that correspond to single species' genomes and thus
improving genome assembly. We use both numerical (proportion of GC bases and read
coverage) and biological (best-matching sequence in annotated databases)
indicators to aid partitioning of draft assembly contigs, and the reads that
contribute to those contigs, into distinct bins that can then be subjected to
rigorous, optimized assembly, through the use of taxon-annotated GC-coverage
plots (TAGC plots). We also present Blobsplorer, a tool that aids exploration and
selection of subsets from TAGC-annotated data. Partitioning the data in this way 
can rescue poorly assembled genomes, and reveal unexpected symbionts and
commensals in eukaryotic genome projects. The TAGC plot pipeline script is
available from https://github.com/blaxterlab/blobology, and the Blobsplorer tool 
from https://github.com/mojones/Blobsplorer.

DOI: 10.3389/fgene.2013.00237 
PMCID: PMC3843372
PMID: 24348509  [PubMed]


1337. Bioinformatics. 2014 Feb 15;30(4):464-71. doi: 10.1093/bioinformatics/btt706.
Epub 2013 Dec 11.

slaMEM: efficient retrieval of maximal exact matches using a sampled LCP array.

Fernandes F(1), Freitas AT.

Author information: 
(1)Knowledge Discovery and Bioinformatics Group (KDBIO), Instituto de Engenharia 
de Sistemas e Computadores Investigação e Desenvolvimento (INESC-ID), Rua Alves
Redol, 9, 1000-029 Lisbon and Department of Computer Science and Engineering,
Instituto Superior Técnico (IST) - Universidade de Lisboa, Avenida Rovisco Pais, 
1, 1049-001 Lisbon, Portugal.

MOTIVATION: Maximal exact matches, or just MEMs, are a powerful tool in the
context of multiple sequence alignment and approximate string matching. The most 
efficient algorithms to collect them are based on compressed indexes that rely on
longest common prefix array-centered data structures. However, their
space-efficient representations make use of encoding techniques that are
expensive from a computational point of view. With the deluge of data generated
by high-throughput sequencing, new approaches need to be developed to deal with
larger genomic sequences.
RESULTS: In this work, we have developed a new longest common prefix
array-sampled representation, optimized to work with the backward search method
inherently used by the FM-Index. Unlike previous implementations that sacrifice
running time to have smaller space, ours lead to both a fast and a
space-efficient approach. This implementation was used by the new software
slaMEM, developed to efficiently retrieve MEMs. The results show that the new
algorithm is competitive against existing state-of-the-art approaches.
AVAILABILITY AND IMPLEMENTATION: The software is implemented in C and is
operating system independent. The source code is freely available for download at
http://github.com/fjdf/slaMEM/ under the GPLv3 license.

DOI: 10.1093/bioinformatics/btt706 
PMID: 24336412  [PubMed - indexed for MEDLINE]


1338. PLoS One. 2013 Dec 4;8(12):e82138. doi: 10.1371/journal.pone.0082138. eCollection
2013.

SSW library: an SIMD Smith-Waterman C/C++ library for use in genomic
applications.

Zhao M(1), Lee WP, Garrison EP, Marth GT.

Author information: 
(1)Department of Biology, Boston College, Chestnut Hill, Massachusetts, United
States of America.

BACKGROUND: The Smith-Waterman algorithm, which produces the optimal pairwise
alignment between two sequences, is frequently used as a key component of fast
heuristic read mapping and variation detection tools for next-generation
sequencing data. Though various fast Smith-Waterman implementations are
developed, they are either designed as monolithic protein database searching
tools, which do not return detailed alignment, or are embedded into other tools. 
These issues make reusing these efficient Smith-Waterman implementations
impractical.
RESULTS: To facilitate easy integration of the fast
Single-Instruction-Multiple-Data Smith-Waterman algorithm into third-party
software, we wrote a C/C++ library, which extends Farrar's Striped Smith-Waterman
(SSW) to return alignment information in addition to the optimal Smith-Waterman
score. In this library we developed a new method to generate the full optimal
alignment results and a suboptimal score in linear space at little cost of
efficiency. This improvement makes the fast Single-Instruction-Multiple-Data
Smith-Waterman become really useful in genomic applications. SSW is available
both as a C/C++ software library, as well as a stand-alone alignment tool at:
https://github.com/mengyao/Complete-Striped-Smith-Waterman-Library.
CONCLUSIONS: The SSW library has been used in the primary read mapping tool
MOSAIK, the split-read mapping program SCISSORS, the MEI detector TANGRAM, and
the read-overlap graph generation program RZMBLR. The speeds of the mentioned
software are improved significantly by replacing their ordinary Smith-Waterman or
banded Smith-Waterman module with the SSW Library.

DOI: 10.1371/journal.pone.0082138 
PMCID: PMC3852983
PMID: 24324759  [PubMed - indexed for MEDLINE]


1339. Bioinformatics. 2014 Feb 15;30(4):514-22. doi: 10.1093/bioinformatics/btt708.
Epub 2013 Dec 5.

Chemical structure informing statistical hypothesis testing in metabolomics.

Zhu H(1), Luo M.

Author information: 
(1)Department of Biostatistics and Programming, Sanofi, Bridgewater, NJ 08807,
USA, Department of Psychiatry and Behavioral Sciences, Duke University, Durham,
NC 27710, USA, Exploratory Clinical & Translational Research, Bristol-Myers
Squibb, Princeton, NJ 08543, USA and Center for Human Health Assessment, The
Hamner Institutes for Health Sciences, Durham, NC 27709, USA.

MOTIVATION: Metabolomics has been shown as an effective tool to study various
biological and biomedical phenotypes, whereas interrogating the inherently noisy 
metabolite concentration data with limited sample size remains a major challenge.
Accumulating evidence suggests that metabolites' structures are relevant to their
bioactivities.
RESULTS: We present a new strategy to boost the statistical power of hypothesis
testing in metabolomics by incorporating quantitative molecular descriptors for
each metabolite. The strategy selects potentially informative summary molecular
descriptors and outputs chemical structure-informed false discovery rates. The
effectiveness of the proposed strategy is demonstrated by both simulation studies
and a real application. In a metabolomic study on Alzheimer's disease, the
posterior inclusion probability for summary molecular descriptors reaches 0.97.
By incorporating the structure data, our approach uniquely identifies multiple
Alzheimer's disease signatures, which are consistent with existing evidence.
These results evidently suggest the value of the proposed approach for
metabolomic hypothesis-testing problems.
AVAILABILITY AND IMPLEMENTATION: A code package implementing the strategy is
freely available at https://github.com/HongjieZhu/CIMA.git.

DOI: 10.1093/bioinformatics/btt708 
PMID: 24319000  [PubMed - indexed for MEDLINE]


1340. Genomics. 2014 Jan;103(1):1-10. doi: 10.1016/j.ygeno.2013.11.005. Epub 2013 Dec
4.

DuctApe: a suite for the analysis and correlation of genomic and OmniLog™
Phenotype Microarray data.

Galardini M(1), Mengoni A(2), Biondi EG(3), Semeraro R(2), Florio A(4),
Bazzicalupo M(2), Benedetti A(4), Mocali S(5).

Author information: 
(1)Department of Biology, University of Florence, Florence, Italy. Electronic
address: marco.galardini@unifi.it. (2)Department of Biology, University of
Florence, Florence, Italy. (3)Interdisciplinary Research Institute USR3078,
CNRS-Université Lille Nord de France, Villeneuve d'Ascq, France. (4)Consiglio per
la Ricerca e la sperimentazione in Agricoltura, Centro di Ricerca per lo studio
delle Relazioni tra Pianta e Suolo (CRA-RPS), Rome, Italy. (5)Consiglio per la
Ricerca e la sperimentazione in Agricoltura, Centro di Ricerca per l'Agrobiologia
e la Pedologia (CRA-ABP), Florence, Italy.

Addressing the functionality of genomes is one of the most important and
challenging tasks of today's biology. In particular the ability to link genotypes
to corresponding phenotypes is of interest in the reconstruction and
biotechnological manipulation of metabolic pathways. Over the last years, the
OmniLog™ Phenotype Microarray (PM) technology has been used to address many
specific issues related to the metabolic functionality of microorganisms.
However, computational tools that could directly link PM data with the gene(s) of
interest followed by the extraction of information on gene-phenotype correlation 
are still missing. Here we present DuctApe, a suite that allows the analysis of
both genomic sequences and PM data, to find metabolic differences among PM
experiments and to correlate them with KEGG pathways and gene presence/absence
patterns. As example, an application of the program to four bacterial datasets is
presented. The source code and tutorials are available at
http://combogenomics.github.io/DuctApe/.

Copyright © 2013 Elsevier Inc. All rights reserved.

DOI: 10.1016/j.ygeno.2013.11.005 
PMID: 24316132  [PubMed - indexed for MEDLINE]


1341. BMC Bioinformatics. 2013 Dec 7;14:358. doi: 10.1186/1471-2105-14-358.

Fragment assignment in the cloud with eXpress-D.

Roberts A, Feng H, Pachter L(1).

Author information: 
(1)Department of Computer Science, 387 Soda Hall, UC Berkeley, Berkeley, CA
94720, USA. lpachter@math.berkeley.edu.

BACKGROUND: Probabilistic assignment of ambiguously mapped fragments produced by 
high-throughput sequencing experiments has been demonstrated to greatly improve
accuracy in the analysis of RNA-Seq and ChIP-Seq, and is an essential step in
many other sequence census experiments. A maximum likelihood method using the
expectation-maximization (EM) algorithm for optimization is commonly used to
solve this problem. However, batch EM-based approaches do not scale well with the
size of sequencing datasets, which have been increasing dramatically over the
past few years. Thus, current approaches to fragment assignment rely on
heuristics or approximations for tractability.
RESULTS: We present an implementation of a distributed EM solution to the
fragment assignment problem using Spark, a data analytics framework that can
scale by leveraging compute clusters within datacenters-"the cloud". We
demonstrate that our implementation easily scales to billions of sequenced
fragments, while providing the exact maximum likelihood assignment of ambiguous
fragments. The accuracy of the method is shown to be an improvement over the most
widely used tools available and can be run in a constant amount of time when
cluster resources are scaled linearly with the amount of input data.
CONCLUSIONS: The cloud offers one solution for the difficulties faced in the
analysis of massive high-thoughput sequencing data, which continue to grow
rapidly. Researchers in bioinformatics must follow developments in distributed
systems-such as new frameworks like Spark-for ways to port existing methods to
the cloud and help them scale to the datasets of the future. Our software,
eXpress-D, is freely available at: http://github.com/adarob/express-d.

DOI: 10.1186/1471-2105-14-358 
PMCID: PMC3881492
PMID: 24314033  [PubMed - indexed for MEDLINE]


1342. Bioinformatics. 2014 Feb 15;30(4):566-8. doi: 10.1093/bioinformatics/btt702. Epub
2013 Dec 2.

NextClip: an analysis and read preparation tool for Nextera Long Mate Pair
libraries.

Leggett RM(1), Clavijo BJ, Clissold L, Clark MD, Caccamo M.

Author information: 
(1)The Genome Analysis Centre (TGAC), Norwich Research Park, Norwich NR4 7UH, UK.

SUMMARY: Illumina's recently released Nextera Long Mate Pair (LMP) kit enables
production of jumping libraries of up to 12 kb. The LMP libraries are an
invaluable resource for carrying out complex assemblies and other downstream
bioinformatics analyses such as the characterization of structural variants.
However, LMP libraries are intrinsically noisy and to maximize their value,
post-sequencing data analysis is required. Standardizing laboratory protocols and
the selection of sequenced reads for downstream analysis are non-trivial tasks.
NextClip is a tool for analyzing reads from LMP libraries, generating a
comprehensive quality report and extracting good quality trimmed and deduplicated
reads.
AVAILABILITY AND IMPLEMENTATION: Source code, user guide and example data are
available from https://github.com/richardmleggett/nextclip/.

DOI: 10.1093/bioinformatics/btt702 
PMCID: PMC3928519
PMID: 24297520  [PubMed - indexed for MEDLINE]


1343. Bioinformatics. 2014 Jan 15;30(2):180-8. doi: 10.1093/bioinformatics/btt624. Epub
2013 Nov 26.

Flexible analysis of RNA-seq data using mixed effects models.

Turro E(1), Astle WJ, Tavaré S.

Author information: 
(1)Cancer Research UK Cambridge Institute, University of Cambridge, Robinson Way,
Cambridge CB2 0RE, UK, Department of Haematology, University of Cambridge, NHS
Blood and Transplant, Long Road, Cambridge CB2 0PT, UK and Department of
Epidemiology, Biostatistics and Occupational Health, McGill University, 1020 Pine
Avenue West, Montreal QC H3A 1A2, Canada.

MOTIVATION: Most methods for estimating differential expression from RNA-seq are 
based on statistics that compare normalized read counts between treatment
classes. Unfortunately, reads are in general too short to be mapped unambiguously
to features of interest, such as genes, isoforms or haplotype-specific isoforms. 
There are methods for estimating expression levels that account for this source
of ambiguity. However, the uncertainty is not generally accounted for in
downstream analysis of gene expression experiments. Moreover, at the individual
transcript level, it can sometimes be too large to allow useful comparisons
between treatment groups.
RESULTS: In this article we make two proposals that improve the power,
specificity and versatility of expression analysis using RNA-seq data. First, we 
present a Bayesian method for model selection that accounts for read mapping
ambiguities using random effects. This polytomous model selection approach can be
used to identify many interesting patterns of gene expression and is not confined
to detecting differential expression between two groups. For illustration, we use
our method to detect imprinting, different types of regulatory divergence in cis 
and in trans and differential isoform usage, but many other applications are
possible. Second, we present a novel collapsing algorithm for grouping
transcripts into inferential units that exploits the posterior correlation
between transcript expression levels. The aggregate expression levels of these
units can be estimated with useful levels of uncertainty. Our algorithm can
improve the precision of expression estimates when uncertainty is large with only
a small reduction in biological resolution.
AVAILABILITY AND IMPLEMENTATION: We have implemented our software in the mmdiff
and mmcollapse multithreaded C++ programs as part of the open-source MMSEQ
package, available on https://github.com/eturro/mmseq.

DOI: 10.1093/bioinformatics/btt624 
PMID: 24281695  [PubMed - indexed for MEDLINE]


1344. Bioinformatics. 2014 Jan 15;30(2):298-300. doi: 10.1093/bioinformatics/btt666.
Epub 2013 Nov 20.

myChEMBL: a virtual machine implementation of open data and cheminformatics
tools.

Ochoa R(1), Davies M, Papadatos G, Atkinson F, Overington JP.

Author information: 
(1)European Molecular Biology Laboratory, European Bioinformatics Institute
(EMBL-EBI), Wellcome Trust Genome Campus, Hinxton CB10 1SD, UK.

myChEMBL is a completely open platform, which combines public domain bioactivity 
data with open source database and cheminformatics technologies. myChEMBL
consists of a Linux (Ubuntu) Virtual Machine featuring a PostgreSQL schema with
the latest version of the ChEMBL database, as well as the latest RDKit
cheminformatics libraries. In addition, a self-contained web interface is
available, which can be modified and improved according to user
specifications.AVAILABILITY AND IMPLEMENTATION: The VM is available at:
ftp://ftp.ebi.ac.uk/pub/databases/chembl/VM/myChEMBL/current. The web interface
and web services code is available at: https://github.com/rochoa85/myChEMBL.

DOI: 10.1093/bioinformatics/btt666 
PMCID: PMC3892694
PMID: 24262214  [PubMed - indexed for MEDLINE]


1345. Methods. 2014 Feb;65(3):263-73. doi: 10.1016/j.ymeth.2013.10.015. Epub 2013 Nov
6.

Hyb: a bioinformatics pipeline for the analysis of CLASH (crosslinking, ligation 
and sequencing of hybrids) data.

Travis AJ(1), Moody J(2), Helwak A(3), Tollervey D(3), Kudla G(4).

Author information: 
(1)Wellcome Trust Centre for Cell Biology, University of Edinburgh, Edinburgh,
Scotland, United Kingdom; Institute of Biological and Environmental Sciences,
University of Aberdeen, Aberdeen, Scotland, United Kingdom. (2)MRC Human Genetics
Unit, Institute of Genetics and Molecular Medicine, University of Edinburgh,
Edinburgh, Scotland, United Kingdom. (3)Wellcome Trust Centre for Cell Biology,
University of Edinburgh, Edinburgh, Scotland, United Kingdom. (4)MRC Human
Genetics Unit, Institute of Genetics and Molecular Medicine, University of
Edinburgh, Edinburgh, Scotland, United Kingdom. Electronic address:
gkudla@gmail.com.

Associations between proteins and RNA-RNA duplexes are important in
post-transcriptional regulation of gene expression. The CLASH (Cross-linking,
Ligation and Sequencing of Hybrids) technique captures RNA-RNA interactions by
physically joining two RNA molecules associated with a protein complex into a
single chimeric RNA molecule. These events are relatively rare and considerable
effort is needed to detect a small number of chimeric sequences amongst millions 
of non-chimeric cDNA reads resulting from a CLASH experiment. We present the
"hyb" bioinformatics pipeline, which we developed to analyse high-throughput cDNA
sequencing data from CLASH experiments. Although primarily designed for use with 
AGO CLASH data, hyb can also be used for the detection and annotation of chimeric
reads in other high-throughput sequencing datasets. We examined the sensitivity
and specificity of chimera detection in a test dataset using the BLAST, BLAST+,
BLAT, pBLAT and Bowtie2 read alignment programs. We obtained the most reliable
results in the shortest time using a combination of preprocessing with Flexbar
and subsequent read-mapping using Bowtie2. The "hyb" software is distributed
under the GNU GPL (General Public License) and can be downloaded from
https://github.com/gkudla/hyb.

Copyright © 2013 The Authors. Published by Elsevier Inc. All rights reserved.

DOI: 10.1016/j.ymeth.2013.10.015 
PMCID: PMC3969109
PMID: 24211736  [PubMed - indexed for MEDLINE]


1346. Bioinformatics. 2014 Mar 15;30(6):768-74. doi: 10.1093/bioinformatics/btt611.
Epub 2013 Nov 4.

WaveCNV: allele-specific copy number alterations in primary tumors and xenograft 
models from next-generation sequencing.

Holt C(1), Losic B, Pai D, Zhao Z, Trinh Q, Syam S, Arshadi N, Jang GH, Ali J,
Beck T, McPherson J, Muthuswamy LB.

Author information: 
(1)Ontario Institute for Cancer Research, Toronto, ON, M5G 0A3, Canada and
Department of Medical Biophysics, University of Toronto, Toronto, ON, M5G 2M9,
Canada.

MOTIVATION: Copy number variations (CNVs) are a major source of genomic
variability and are especially significant in cancer. Until recently microarray
technologies have been used to characterize CNVs in genomes. However, advances in
next-generation sequencing technology offer significant opportunities to deduce
copy number directly from genome sequencing data. Unfortunately cancer genomes
differ from normal genomes in several aspects that make them far less amenable to
copy number detection. For example, cancer genomes are often aneuploid and an
admixture of diploid/non-tumor cell fractions. Also patient-derived xenograft
models can be laden with mouse contamination that strongly affects accurate
assignment of copy number. Hence, there is a need to develop analytical tools
that can take into account cancer-specific parameters for detecting CNVs directly
from genome sequencing data.
RESULTS: We have developed WaveCNV, a software package to identify copy number
alterations by detecting breakpoints of CNVs using translation-invariant discrete
wavelet transforms and assign digitized copy numbers to each event using
next-generation sequencing data. We also assign alleles specifying the
chromosomal ratio following duplication/loss. We verified copy number calls using
both microarray (correlation coefficient 0.97) and quantitative polymerase chain 
reaction (correlation coefficient 0.94) and found them to be highly concordant.
We demonstrate its utility in pancreatic primary and xenograft sequencing data.
AVAILABILITY AND IMPLEMENTATION: Source code and executables are available at
https://github.com/WaveCNV. The segmentation algorithm is implemented in MATLAB, 
and copy number assignment is implemented Perl.
CONTACT: lakshmi.muthuswamy@gmail.com
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btt611 
PMCID: PMC3957071
PMID: 24192544  [PubMed - indexed for MEDLINE]


1347. Bioinformatics. 2014 Jan 1;30(1):123-4. doi: 10.1093/bioinformatics/btt635. Epub 
2013 Nov 4.

Phylowood: interactive web-based animations of biogeographic and phylogeographic 
histories.

Landis MJ(1), Bedford T.

Author information: 
(1)Department of Integrative Biology, UC Berkeley, Berkeley, CA 94720, USA,
Institute of Evolution, School of Biological Sciences, University of Edinburgh,
Edinburgh EH9 3JT, UK and Vaccine and Infectious Disease Division, Fred
Hutchinson Cancer Research Center, Seattle, WA 98109, USA.

SUMMARY: Phylowood is a web service that uses JavaScript to generate in-browser
animations of biogeographic and phylogeographic histories from annotated
phylogenetic input. The animations are interactive, allowing the user to adjust
spatial and temporal resolution, and highlight phylogenetic lineages of interest.
AVAILABILITY AND IMPLEMENTATION: All documentation and source code for Phylowood 
is freely available at https://github.com/mlandis/phylowood, and a live web
application is available at https://mlandis.github.io/phylowood.

DOI: 10.1093/bioinformatics/btt635 
PMCID: PMC3866560
PMID: 24191071  [PubMed - indexed for MEDLINE]


1348. Bioinformatics. 2014 Mar 15;30(6):876-83. doi: 10.1093/bioinformatics/btt628.
Epub 2013 Oct 30.

The functional therapeutic chemical classification system.

Croset S(1), Overington JP, Rebholz-Schuhmann D.

Author information: 
(1)European Molecular Biology Laboratory, European Bioinformatics Institute
(EMBL-EBI), Wellcome Trust Genome Campus, Hinxton, Cambridge CB10 1SD, United
Kingdom.

MOTIVATION: Drug repositioning is the discovery of new indications for compounds 
that have already been approved and used in a clinical setting. Recently, some
computational approaches have been suggested to unveil new opportunities in a
systematic fashion, by taking into consideration gene expression signatures or
chemical features for instance. We present here a novel method based on knowledge
integration using semantic technologies, to capture the functional role of
approved chemical compounds.
RESULTS: In order to computationally generate repositioning hypotheses, we used
the Web Ontology Language to formally define the semantics of over 20 000 terms
with axioms to correctly denote various modes of action (MoA). Based on an
integration of public data, we have automatically assigned over a thousand of
approved drugs into these MoA categories. The resulting new resource is called
the Functional Therapeutic Chemical Classification System and was further
evaluated against the content of the traditional Anatomical Therapeutic Chemical 
Classification System. We illustrate how the new classification can be used to
generate drug repurposing hypotheses, using Alzheimers disease as a use-case.
AVAILABILITY: https://www.ebi.ac.uk/chembl/ftc; https://github.com/loopasam/ftc.
CONTACT: croset@ebi.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btt628 
PMCID: PMC3957075
PMID: 24177719  [PubMed - indexed for MEDLINE]


1349. Bioinformatics. 2014 Mar 15;30(6):896-8. doi: 10.1093/bioinformatics/btt626. Epub
2013 Oct 31.

pyGCluster, a novel hierarchical clustering approach.

Jaeger D(1), Barth J, Niehues A, Fufezan C.

Author information: 
(1)Institute of Plant Biology and Biotechnology, Department of Biology,
University of Muenster, Münster 48143, Germany.

SUMMARY: pyGCluster is a clustering algorithm focusing on noise injection for
subsequent cluster validation. The reproducibility of a large amount of clusters 
obtained with agglomerative hierarchical clustering is assessed. Furthermore, a
multitude of different distance-linkage combinations are evaluated. Finally,
highly reproducible clusters are meta-clustered into communities. Graphical
illustration of the results as node and expression maps is implemented.
AVAILABILITY AND IMPLEMENTATION: pyGCluster requires Python 2.7, it is freely
available at http://pyGCluster.github.io and published under MIT license.
Dependencies are NumPy, SciPy and optionally fastcluster and rpy2.
CONTACT: christan@fufezan.net
SUPPLEMENTARY INFORMATION: Supplementary data is available at Bioinformatics
online and at http://pyGCluster.github.io.

DOI: 10.1093/bioinformatics/btt626 
PMID: 24177716  [PubMed - indexed for MEDLINE]


1350. Bioinformatics. 2014 Mar 15;30(6):838-45. doi: 10.1093/bioinformatics/btt610.
Epub 2013 Oct 24.

A pathway-based data integration framework for prediction of disease progression.

Seoane JA(1), Day IN, Gaunt TR, Campbell C.

Author information: 
(1)MRC Centre for Causal Analyses in Translational Epidemiology, MRC Integrative 
Epidemiology Unit, School of Social and Community Medicine, University of
Bristol, Clifton BS8 2BN, UK and Intelligent Systems Laboratory, University of
Bristol, Bristol BS8 1UB, UK.

MOTIVATION: Within medical research there is an increasing trend toward deriving 
multiple types of data from the same individual. The most effective prognostic
prediction methods should use all available data, as this maximizes the amount of
information used. In this article, we consider a variety of learning strategies
to boost prediction performance based on the use of all available data.
IMPLEMENTATION: We consider data integration via the use of multiple kernel
learning supervised learning methods. We propose a scheme in which feature
selection by statistical score is performed separately per data type and by
pathway membership. We further consider the introduction of a confidence measure 
for the class assignment, both to remove some ambiguously labeled datapoints from
the training data and to implement a cautious classifier that only makes
predictions when the associated confidence is high.
RESULTS: We use the METABRIC dataset for breast cancer, with prediction of
survival at 2000 days from diagnosis. Predictive accuracy is improved by using
kernels that exclusively use those genes, as features, which are known members of
particular pathways. We show that yet further improvements can be made by using a
range of additional kernels based on clinical covariates such as Estrogen
Receptor (ER) status. Using this range of measures to improve prediction
performance, we show that the test accuracy on new instances is nearly 80%,
though predictions are only made on 69.2% of the patient cohort.
AVAILABILITY: https://github.com/jseoane/FSMKL CONTACT: J.Seoane@bristol.ac.uk
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btt610 
PMCID: PMC3957070
PMID: 24162466  [PubMed - indexed for MEDLINE]


1351. Bioinformatics. 2014 Mar 15;30(6):884-6. doi: 10.1093/bioinformatics/btt607. Epub
2013 Oct 24.

Protter: interactive protein feature visualization and integration with
experimental proteomic data.

Omasits U(1), Ahrens CH, Müller S, Wollscheid B.

Author information: 
(1)Department of Biology, Institute of Molecular Systems Biology, ETH Zürich,
8093 Zürich and Institute of Molecular Life Sciences, University of Zürich, 8057 
Zürich, Switzerland.

SUMMARY: The ability to integrate and visualize experimental proteomic evidence
in the context of rich protein feature annotations represents an unmet need of
the proteomics community. Here we present Protter, a web-based tool that supports
interactive protein data analysis and hypothesis generation by visualizing both
annotated sequence features and experimental proteomic data in the context of
protein topology. Protter supports numerous proteomic file formats and
automatically integrates a variety of reference protein annotation sources, which
can be readily extended via modular plug-ins. A built-in export function produces
publication-quality customized protein illustrations, also for large datasets.
Visualizations of surfaceome datasets show the specific utility of Protter for
the integrated visual analysis of membrane proteins and peptide selection for
targeted proteomics.
AVAILABILITY AND IMPLEMENTATION: The Protter web application is available at
http://wlab.ethz.ch/protter. Source code and installation instructions are
available at http://ulo.github.io/Protter/.
CONTACT: wbernd@ethz.ch
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btt607 
PMID: 24162465  [PubMed - indexed for MEDLINE]


1352. J Proteome Res. 2014 Jan 3;13(1):84-98. doi: 10.1021/pr400820p. Epub 2013 Nov 12.

Tools to covisualize and coanalyze proteomic data with genomes and
transcriptomes: validation of genes and alternative mRNA splicing.

Pang CN(1), Tay AP, Aya C, Twine NA, Harkness L, Hart-Smith G, Chia SZ, Chen Z,
Deshpande NP, Kaakoush NO, Mitchell HM, Kassem M, Wilkins MR.

Author information: 
(1)Systems Biology Initiative, The University of New South Wales , Sydney, New
South Wales 2052, Australia.

Direct links between proteomic and genomic/transcriptomic data are not frequently
made, partly because of lack of appropriate bioinformatics tools. To help address
this, we have developed the PG Nexus pipeline. The PG Nexus allows users to
covisualize peptides in the context of genomes or genomic contigs, along with
RNA-seq reads. This is done in the Integrated Genome Viewer (IGV). A Results
Analyzer reports the precise base position where LC-MS/MS-derived peptides cover 
genes or gene isoforms, on the chromosomes or contigs where this occurs. In
prokaryotes, the PG Nexus pipeline facilitates the validation of genes, where
annotation or gene prediction is available, or the discovery of genes using a
"virtual protein"-based unbiased approach. We illustrate this with a
comprehensive proteogenomics analysis of two strains of Campylobacter concisus . 
For higher eukaryotes, the PG Nexus facilitates gene validation and supports the 
identification of mRNA splice junction boundaries and splice variants that are
protein-coding. This is illustrated with an analysis of splice junctions covered 
by human phosphopeptides, and other examples of relevance to the
Chromosome-Centric Human Proteome Project. The PG Nexus is open-source and
available from https://github.com/IntersectAustralia/ap11_Samifier. It has been
integrated into Galaxy and made available in the Galaxy tool shed.

DOI: 10.1021/pr400820p 
PMID: 24152167  [PubMed - indexed for MEDLINE]


1353. BMC Syst Biol. 2013 Oct 22;7:106. doi: 10.1186/1752-0509-7-106.

ENNET: inferring large gene regulatory networks from expression data using
gradient boosting.

Sławek J, Arodź T(1).

Author information: 
(1)Department of Computer Science, Virginia Commonwealth University, Richmond,
Virginia. tarodz@vcu.edu.

BACKGROUND: The regulation of gene expression by transcription factors is a key
determinant of cellular phenotypes. Deciphering genome-wide networks that capture
which transcription factors regulate which genes is one of the major efforts
towards understanding and accurate modeling of living systems. However,
reverse-engineering the network from gene expression profiles remains a
challenge, because the data are noisy, high dimensional and sparse, and the
regulation is often obscured by indirect connections.
RESULTS: We introduce a gene regulatory network inference algorithm ENNET, which 
reverse-engineers networks of transcriptional regulation from a variety of
expression profiles with a superior accuracy compared to the state-of-the-art
methods. The proposed method relies on the boosting of regression stumps combined
with a relative variable importance measure for the initial scoring of
transcription factors with respect to each gene. Then, we propose a technique for
using a distribution of the initial scores and information about knockouts to
refine the predictions. We evaluated the proposed method on the DREAM3, DREAM4
and DREAM5 data sets and achieved higher accuracy than the winners of those
competitions and other established methods.
CONCLUSIONS: Superior accuracy achieved on the three different benchmark data
sets shows that ENNET is a top contender in the task of network inference. It is 
a versatile method that uses information about which gene was knocked-out in
which experiment if it is available, but remains the top performer even without
such information. ENNET is available for download from
https://github.com/slawekj/ennet under the GNU GPLv3 license.

DOI: 10.1186/1752-0509-7-106 
PMCID: PMC4015806
PMID: 24148309  [PubMed - indexed for MEDLINE]


1354. Bioinformatics. 2014 Mar 1;30(5):743-5. doi: 10.1093/bioinformatics/btt588. Epub 
2013 Oct 15.

Comment on 'Bayesian parentage analysis with systematic accountability of
genotyping error, missing data and false matching'.

Anderson EC(1), Ng TC.

Author information: 
(1)Fisheries Ecology Division, Southwest Fisheries Science Center, National
Marine Fisheries Service, NOAA, 110 Shaffer Road, Santa Cruz, CA 95060,
Department of Applied Math and Statistics and Department of Biomolecular
Engineering, University of California, Santa Cruz, CA, USA.

Comment on
    Bioinformatics. 2013 Mar 15;29(6):725-32.

We show the software SOLOMON is improved by using the likelihood ratio instead of
an ad hoc statistic. CODE:
 github.com/eriqande/solidmon/releases/tag/v0.1-bioinformatics

DOI: 10.1093/bioinformatics/btt588 
PMID: 24130307  [PubMed - indexed for MEDLINE]


1355. Mol Ecol Resour. 2014 Mar;14(2):426-34. doi: 10.1111/1755-0998.12187. Epub 2013
Nov 16.

StreamingTrim 1.0: a Java software for dynamic trimming of 16S rRNA sequence data
from metagenetic studies.

Bacci G(1), Bazzicalupo M, Benedetti A, Mengoni A.

Author information: 
(1)Department of Biology, University of Florence, via Madonna del Piano 6,
Firenze, I-50019, Italy; Consiglio per la Ricerca e la Sperimentazione in
Agricoltura, Centro di Ricerca per lo Studio delle Relazioni tra Pianta e Suolo
(CRA-RPS), Via della Navicella 2/4, Roma, I-00184, Italy.

Next-generation sequencing technologies are extensively used in the field of
molecular microbial ecology to describe taxonomic composition and to infer
functionality of microbial communities. In particular, the so-called barcode or
metagenetic applications that are based on PCR amplicon library sequencing are
very popular at present. One of the problems, related to the utilization of the
data of these libraries, is the analysis of reads quality and removal (trimming) 
of low-quality segments, while retaining sufficient information for subsequent
analyses (e.g. taxonomic assignment). Here, we present StreamingTrim, a DNA reads
trimming software, written in Java, with which researchers are able to analyse
the quality of DNA sequences in fastq files and to search for low-quality zones
in a very conservative way. This software has been developed with the aim to
provide a tool capable of trimming amplicon library data, retaining as much as
taxonomic information as possible. This software is equipped with a graphical
user interface for a user-friendly usage. Moreover, from a computational point of
view, StreamingTrim reads and analyses sequences one by one from an input fastq
file, without keeping anything in memory, permitting to run the computation on a 
normal desktop PC or even a laptop. Trimmed sequences are saved in an output
file, and a statistics summary is displayed that contains the mean and standard
deviation of the length and quality of the whole sequence file. Compiled
software, a manual and example data sets are available under the BSD-2-Clause
License at the GitHub repository at https://github.com/GiBacci/StreamingTrim/.

© 2013 John Wiley & Sons Ltd.

DOI: 10.1111/1755-0998.12187 
PMID: 24128146  [PubMed - indexed for MEDLINE]


1356. Front Neuroinform. 2013 Oct 10;7:20. doi: 10.3389/fninf.2013.00020. eCollection
2013.

MOBBED: a computational data infrastructure for handling large collections of
event-rich time series datasets in MATLAB.

Cockfield J(1), Su K, Robbins KA.

Author information: 
(1)Department of Computer Science, University of Texas at San Antonio San
Antonio, TX, USA.

Experiments to monitor human brain activity during active behavior record a
variety of modalities (e.g., EEG, eye tracking, motion capture, respiration
monitoring) and capture a complex environmental context leading to large,
event-rich time series datasets. The considerable variability of responses within
and among subjects in more realistic behavioral scenarios requires experiments to
assess many more subjects over longer periods of time. This explosion of data
requires better computational infrastructure to more systematically explore and
process these collections. MOBBED is a lightweight, easy-to-use, extensible
toolkit that allows users to incorporate a computational database into their
normal MATLAB workflow. Although capable of storing quite general types of
annotated data, MOBBED is particularly oriented to multichannel time series such 
as EEG that have event streams overlaid with sensor data. MOBBED directly
supports access to individual events, data frames, and time-stamped feature
vectors, allowing users to ask questions such as what types of events or features
co-occur under various experimental conditions. A database provides several
advantages not available to users who process one dataset at a time from the
local file system. In addition to archiving primary data in a central place to
save space and avoid inconsistencies, such a database allows users to manage,
search, and retrieve events across multiple datasets without reading the entire
dataset. The database also provides infrastructure for handling more complex
event patterns that include environmental and contextual conditions. The database
can also be used as a cache for expensive intermediate results that are reused in
such activities as cross-validation of machine learning algorithms. MOBBED is
implemented over PostgreSQL, a widely used open source database, and is freely
available under the GNU general public license at
http://visual.cs.utsa.edu/mobbed. Source and issue reports for MOBBED are
maintained at http://vislab.github.com/MobbedMatlab/

DOI: 10.3389/fninf.2013.00020 
PMCID: PMC3794442
PMID: 24124417  [PubMed]


1357. Bioinformatics. 2014 Mar 1;30(5):629-35. doi: 10.1093/bioinformatics/btt584. Epub
2013 Oct 11.

Nonpareil: a redundancy-based approach to assess the level of coverage in
metagenomic datasets.

Rodriguez-R LM(1), Konstantinidis KT.

Author information: 
(1)Center for Bioinformatics and Computational Genomics, School of Biology and
School of Civil and Environmental Engineering, Georgia Institute of Technology,
311 Ferst Drive, Ford ES&T Building, Suite 3224, Atlanta, GA 30332, USA.

MOTIVATION: Determining the fraction of the diversity within a microbial
community sampled and the amount of sequencing required to cover the total
diversity represent challenging issues for metagenomics studies. Owing to these
limitations, central ecological questions with respect to the global distribution
of microbes and the functional diversity of their communities cannot be robustly 
assessed.
RESULTS: We introduce Nonpareil, a method to estimate and project coverage in
metagenomes. Nonpareil does not rely on high-quality assemblies, operational
taxonomic unit calling or comprehensive reference databases; thus, it is broadly 
applicable to metagenomic studies. Application of Nonpareil on available
metagenomic datasets provided estimates on the relative complexity of soil,
freshwater and human microbiome communities, and suggested that ∼200 Gb of
sequencing data are required for 95% abundance-weighted average coverage of the
soil communities analyzed.
AVAILABILITY AND IMPLEMENTATION: Nonpareil is available at
https://github.com/lmrodriguezr/nonpareil/ under the Artistic License 2.0.

DOI: 10.1093/bioinformatics/btt584 
PMID: 24123672  [PubMed - indexed for MEDLINE]


1358. Bioinformatics. 2014 Jan 1;30(1):131-2. doi: 10.1093/bioinformatics/btt568. Epub 
2013 Sep 29.

BooleSim: an interactive Boolean network simulator.

Bock M(1), Scharp T, Talnikar C, Klipp E.

Author information: 
(1)Department of Biology, Theoretical Biophysics, Humboldt-Universität zu Berlin,
10115 Berlin, Germany and Chemical Engineering Department, Indian Institute of
Technology Bombay, Mumbai 400 076, India.

SUMMARY: BooleSim (Boolean network simulator) is an open-source in-browser tool
for simulation and manipulation of Boolean networks. It was developed mainly
during Google's Summer of Code 2012 and uses the biographer project for network
visualization. It can be used specifically for the modeling of gene regulatory or
signal transduction networks.
AVAILABILITY AND IMPLEMENTATION: BooleSim is free software and can be downloaded 
from GitHub (https://github.com/matthiasbock/BooleSim). Online version available 
at http://rumo.biologie.hu-berlin.de/boolesim/.

DOI: 10.1093/bioinformatics/btt568 
PMID: 24078712  [PubMed - indexed for MEDLINE]


1359. Bioinformatics. 2013 Dec 15;29(24):3204-10. doi: 10.1093/bioinformatics/btt558.
Epub 2013 Sep 27.

STAR: an integrated solution to management and visualization of sequencing data.

Wang T(1), Liu J, Shen L, Tonti-Filippini J, Zhu Y, Jia H, Lister R, Whitaker JW,
Ecker JR, Millar AH, Ren B, Wang W.

Author information: 
(1)Department of Chemistry and Biochemistry, University of California, San Diego,
CA 92093, USA, Department of Neuroscience, Icahn School of Medicine at Mount
Sinai, New York, NY 10029, USA, The ARC Centre of Excellence in Plant Energy
Biology, The University of Western Australia, Crawley, Western Australia 6009,
Australia, Key Laboratory for Symbolic Computation and Knowledge Engineering of
Ministry of Education, College of Computer Science and Technology, Jilin
University, Changchun 130012, China, Genomic Analysis Laboratory, The Salk
Institute for Biological Studies, La Jolla, CA 92037, USA, Department of Cellular
and Molecular Medicine, University of California, San Diego, CA 92093, USA and
Ludwig Institute for Cancer Research, La Jolla, CA 92093, USA.

MOTIVATION: Easily visualization of complex data features is a necessary step to 
conduct studies on next-generation sequencing (NGS) data. We developed STAR, an
integrated web application that enables online management, visualization and
track-based analysis of NGS data.
RESULTS: STAR is a multilayer web service system. On the client side, STAR
leverages JavaScript, HTML5 Canvas and asynchronous communications to deliver a
smoothly scrolling desktop-like graphical user interface with a suite of
in-browser analysis tools that range from providing simple track configuration
controls to sophisticated feature detection within datasets. On the server side, 
STAR supports private session state retention via an account management system
and provides data management modules that enable collection, visualization and
analysis of third-party sequencing data from the public domain with over
thousands of tracks hosted to date. Overall, STAR represents a next-generation
data exploration solution to match the requirements of NGS data, enabling both
intuitive visualization and dynamic analysis of data.
AVAILABILITY AND IMPLEMENTATION: STAR browser system is freely available on the
web at http://wanglab.ucsd.edu/star/browser and
https://github.com/angell1117/STAR-genome-browser.

DOI: 10.1093/bioinformatics/btt558 
PMCID: PMC3842760
PMID: 24078702  [PubMed - indexed for MEDLINE]


1360. Bioinformatics. 2013 Dec 15;29(24):3222-4. doi: 10.1093/bioinformatics/btt553.
Epub 2013 Sep 24.

BlastGraph: a comparative genomics tool based on BLAST and graph algorithms.

Ye Y(1), Wei B, Wen L, Rayner S.

Author information: 
(1)Key Laboratory of Agricultural and Environmental Microbiology, Wuhan Institute
of Virology, Wuhan, Hubei, China, 430071, Graduate School of Chinese Academy of
Sciences, Beijing, China and Exiqon A/S, Vedbaek, Denmark.

BlastGraph is an interactive Java program for comparative genome analysis based
on Basic Local Alignment Search Tool (BLAST), graph clustering and data
visualization. The software generates clusters of sequences of multiple genomes
from all-to-all BLAST results and visualizes the results in graph plots together 
with related information such as sequence features, gene conservation and
similarity relationships. Pruning algorithms are used to reduce results to more
meaningful subclusters. Subsequent analyses can then be conducted based on the
predicted clusters, including gene content, genome phylogenetics and gene gain
and loss.AVAILABILITY AND IMPLEMENTATION: https://github.com/bigwiv/BlastGraph.

DOI: 10.1093/bioinformatics/btt553 
PMID: 24068035  [PubMed - indexed for MEDLINE]


1361. Front Genet. 2013 Sep 5;4:168. doi: 10.3389/fgene.2013.00168. eCollection 2013.

Meta4: a web application for sharing and annotating metagenomic gene predictions 
using web services.

Richardson EJ(1), Escalettes F, Fotheringham I, Wallace RJ, Watson M.

Author information: 
(1)ARK-Genomics, The Roslin Institute and R(D)SVS, University of Edinburgh Easter
Bush, Midlothian, UK.

Whole-genome shotgun metagenomics experiments produce DNA sequence data from
entire ecosystems, and provide a huge amount of novel information. Gene discovery
projects require up-to-date information about sequence homology and domain
structure for millions of predicted proteins to be presented in a simple,
easy-to-use system. There is a lack of simple, open, flexible tools that allow
the rapid sharing of metagenomics datasets with collaborators in a format they
can easily interrogate. We present Meta4, a flexible and extensible web
application that can be used to share and annotate metagenomic gene predictions. 
Proteins and predicted domains are stored in a simple relational database, with a
dynamic front-end which displays the results in an internet browser. Web services
are used to provide up-to-date information about the proteins from homology
searches against public databases. Information about Meta4 can be found on the
project website, code is available on Github, a cloud image is available, and an 
example implementation can be seen at.

DOI: 10.3389/fgene.2013.00168 
PMCID: PMC3763215
PMID: 24046776  [PubMed]


1362. Mol Ecol Resour. 2014 Jan;14(1):215-7. doi: 10.1111/1755-0998.12160. Epub 2013
Sep 6.

HeFPipe: a complete analytical pipeline for heterozygosity-fitness correlation
studies.

Fisher MA(1).

Author information: 
(1)Rm, 117 Riverbend Research North, University of Georgia, 110 Riverbend Road,
Athens, GA, 30602, USA.

As the body of heterozygosity-fitness correlation (HFC) research grows, more and 
increasingly complicated tests have become an integral part of a typical HFC
analysis (Chapman et al. 2009). Currently, no software is available to undertake 
conversion between the file formats required to conduct all of these tests and to
conduct the main regression analyses at the core of all HFCs.
Heterozygosity-Fitness Pipeline (HeFPipe) is a script written in Python that
accomplishes both of these tasks for studies based on microsatellite data.
HeFPipe is designed to be used from the command line terminal and will run on any
Mac OSX computer. The script takes input in the form of allele reports from
either the genotype-calling software, GeneMapper or GeneMarker, and reconfigures 
the data into GENEPOP (Raymond & Rousset 1995), Rhh (Alho et al. 2010), RMES
(David et al. 2007) and GEPHAST (Amos & Acevedo-Whitehouse 2009) formats. The
script is also equipped to reformat the output from GENEPOP on the Web (option 5)
and Rhh into csv spreadsheets that can be incorporated into downstream analyses. 
HeFPipe accommodates user-provided lists of samples and markers to be included in
or excluded from analyses. HeFPipe is equipped to create generalized linear
models (GLMs) from both the main data set and subsets of the data. Finally,
HeFPipe allows users to explore single-marker effects and conduct correlation
analyses. The script, a comprehensive manual, a link to a series of video
tutorials, and an example data set are available from GitHub
(http://github.com/Atticus29/HeFPipe_rpos).

© 2013 John Wiley & Sons Ltd.

DOI: 10.1111/1755-0998.12160 
PMID: 24034598  [PubMed - indexed for MEDLINE]


1363. Evol Bioinform Online. 2013 Sep 1;9:355-62. doi: 10.4137/EBO.S12012. eCollection 
2013.

SBEToolbox: A Matlab Toolbox for Biological Network Analysis.

Konganti K(1), Wang G, Yang E, Cai JJ.

Author information: 
(1)Whole Systems Genomics Initiative, Texas A&M University, College Station,
Texas 77843-4458, USA.

We present SBEToolbox (Systems Biology and Evolution Toolbox), an open-source
Matlab toolbox for biological network analysis. It takes a network file as input,
calculates a variety of centralities and topological metrics, clusters nodes into
modules, and displays the network using different graph layout algorithms.
Straightforward implementation and the inclusion of high-level functions allow
the functionality to be easily extended or tailored through developing custom
plugins. SBEGUI, a menu-driven graphical user interface (GUI) of SBEToolbox,
enables easy access to various network and graph algorithms for programmers and
non-programmers alike. All source code and sample data are freely available at
https://github.com/biocoder/SBEToolbox/releases.

DOI: 10.4137/EBO.S12012 
PMCID: PMC3767578
PMID: 24027418  [PubMed]


1364. Evol Bioinform Online. 2013 Sep 1;9:343-53. doi: 10.4137/EBO.S12751. eCollection 
2013.

POPBAM: Tools for Evolutionary Analysis of Short Read Sequence Alignments.

Garrigan D(1).

Author information: 
(1)Department of Biology, University of Rochester, Rochester, New York 14627 USA.

BACKGROUND: While many bioinformatics tools currently exist for assembling and
discovering variants from next-generation sequence data, there are very few tools
available for performing evolutionary analyses from these data. Evolutionary and 
population genomics studies hold great promise for providing valuable insights
into natural selection, the effect of mutations on phenotypes, and the origin of 
species. Thus, there is a need for an extensible and flexible computational tool 
that can function into a growing number of evolutionary bioinformatics pipelines.
RESULTS: This paper describes the POPBAM software, which is a comprehensive set
of computational tools for evolutionary analysis of whole-genome alignments
consisting of multiple individuals, from multiple populations or species. POPBAM 
works directly from BAM-formatted assembly files, calls variant sites, and
calculates a variety of commonly used evolutionary sequence statistics. POPBAM is
designed primarily to perform analyses in sliding windows across chromosomes or
scaffolds. POPBAM accurately measures nucleotide diversity, population
divergence, linkage disequilibrium, and the frequency spectrum of mutations from 
two or more populations. POPBAM can also produce phylogenetic trees of all
samples in a BAM file. Finally, I demonstrate that the implementation of POPBAM
is both fast and memory-efficient, and also can feasibly scale to the analysis of
large BAM files with many individuals and populations. Software: The POPBAM
program is written in C/C++ and is available from
http://dgarriga.github.io/POPBAM. The program has few dependencies and can be
built on a variety of Linux platforms. The program is open-source and users are
encouraged to participate in the development of this resource.

DOI: 10.4137/EBO.S12751 
PMCID: PMC3767577
PMID: 24027417  [PubMed]


1365. BMC Bioinformatics. 2013 Sep 8;14:268. doi: 10.1186/1471-2105-14-268.

Centroid based clustering of high throughput sequencing reads based on n-mer
counts.

Solovyov A(1), Lipkin WI.

Author information: 
(1)Center for Infection and Immunity, Columbia University, New York, NY, 10032,
USA. avs2132@columbia.edu.

BACKGROUND: Many problems in computational biology require alignment-free
sequence comparisons. One of the common tasks involving sequence comparison is
sequence clustering. Here we apply methods of alignment-free comparison (in
particular, comparison using sequence composition) to the challenge of sequence
clustering.
RESULTS: We study several centroid based algorithms for clustering sequences
based on word counts. Study of their performance shows that using k-means
algorithm with or without the data whitening is efficient from the computational 
point of view. A higher clustering accuracy can be achieved using the soft
expectation maximization method, whereby each sequence is attributed to each
cluster with a specific probability. We implement an open source tool for
alignment-free clustering. It is publicly available from github:
https://github.com/luscinius/afcluster.
CONCLUSIONS: We show the utility of alignment-free sequence clustering for high
throughput sequencing analysis despite its limitations. In particular, it allows 
one to perform assembly with reduced resources and a minimal loss of quality. The
major factor affecting performance of alignment-free read clustering is the
length of the read.

DOI: 10.1186/1471-2105-14-268 
PMCID: PMC3848435
PMID: 24011402  [PubMed - indexed for MEDLINE]


1366. Bioinformatics. 2013 Nov 15;29(22):2955-7. doi: 10.1093/bioinformatics/btt514.
Epub 2013 Sep 5.

OntoQuery: easy-to-use web-based OWL querying.

Tudose I(1), Hastings J, Muthukrishnan V, Owen G, Turner S, Dekker A, Kale N,
Ennis M, Steinbeck C.

Author information: 
(1)Cheminformatics and Metabolism, European Bioinformatics Institute, Cambridge, 
UK, Swiss Center for Affective Sciences, University of Geneva, Geneva,
Switzerland and Evolutionary Bioinformatics, Swiss Institute of Bioinformatics,
Lausanne, Romandy, Switzerland.

SUMMARY: The Web Ontology Language (OWL) provides a sophisticated language for
building complex domain ontologies and is widely used in bio-ontologies such as
the Gene Ontology. The Protégé-OWL ontology editing tool provides a query
facility that allows composition and execution of queries with the human-readable
Manchester OWL syntax, with syntax checking and entity label lookup. No
equivalent query facility such as the Protégé Description Logics (DL) query yet
exists in web form. However, many users interact with bio-ontologies such as
chemical entities of biological interest and the Gene Ontology using their online
Web sites, within which DL-based querying functionality is not available. To
address this gap, we introduce the OntoQuery web-based query utility.
AVAILABILITY AND IMPLEMENTATION:  The source code for this implementation
together with instructions for installation is available at
http://github.com/IlincaTudose/OntoQuery. OntoQuery software is fully compatible 
with all OWL-based ontologies and is available for download (CC-0 license). The
ChEBI installation, ChEBI OntoQuery, is available at
http://www.ebi.ac.uk/chebi/tools/ontoquery.
CONTACT: hastings@ebi.ac.uk.

DOI: 10.1093/bioinformatics/btt514 
PMCID: PMC3810857
PMID: 24008420  [PubMed - indexed for MEDLINE]


1367. Bioinformatics. 2013 Nov 15;29(22):2948-9. doi: 10.1093/bioinformatics/btt510.
Epub 2013 Sep 2.

Metriculator: quality assessment for mass spectrometry-based proteomics.

Taylor RM(1), Dance J, Taylor RJ, Prince JT.

Author information: 
(1)Department of Chemistry and Biochemistry, Department of Computer Science and
Department of Information Systems, Brigham Young University, Provo, UT 84602,
USA.

SUMMARY: Quality control in mass spectrometry-based proteomics remains
subjective, labor-intensive and inconsistent between laboratories. We introduce
Metriculator, a software designed to facilitate long-term storage of extensive
performance metrics as introduced by NIST in 2010. Metriculator features a web
interface that generates interactive comparison plots for contextual
understanding of metric values and an automated metric generation toolkit. The
comparison plots are designed for at-a-glance determination of outliers and
trends in the datasets, together with relevant statistical comparisons.
Easy-to-use quantitative comparisons and a framework for integration plugins will
encourage a culture of quality assurance within the proteomics community.
AVAILABILITY AND IMPLEMENTATION: Available under the MIT license at
http://github.com/princelab/metriculator.

DOI: 10.1093/bioinformatics/btt510 
PMID: 24002108  [PubMed - indexed for MEDLINE]


1368. Bioinformatics. 2013 Nov 15;29(22):2943-5. doi: 10.1093/bioinformatics/btt511.
Epub 2013 Aug 31.

SAMstrt: statistical test for differential expression in single-cell
transcriptome with spike-in normalization.

Katayama S(1), Töhönen V, Linnarsson S, Kere J.

Author information: 
(1)Department of Biosciences and Nutrition, Karolinska Institutet, 141 83
Huddinge, Sweden, Science for Life Laboratory, Karolinska Institutet Science
Park, 171 21 Solna, Sweden and Department of Medical Biochemistry and Biophysics,
Karolinska Institutet, 171 77 Stockholm, Sweden.

MOTIVATION: Recent transcriptome studies have revealed that total transcript
numbers vary by cell type and condition; therefore, the statistical assumptions
for single-cell transcriptome studies must be revisited. SAMstrt is an extension 
code for SAMseq, which is a statistical method for differential expression, to
enable spike-in normalization and statistical testing based on the estimated
absolute number of transcripts per cell for single-cell RNA-seq methods.
AVAILABILITY AND IMPLEMENTATION: SAMstrt is implemented on R and available in
github (https://github.com/shka/R-SAMstrt).
CONTACT: shintaro.katayama@ki.se

DOI: 10.1093/bioinformatics/btt511 
PMCID: PMC3810855
PMID: 23995393  [PubMed - indexed for MEDLINE]


1369. Source Code Biol Med. 2013 Aug 29;8(1):17. doi: 10.1186/1751-0473-8-17.

GEMBASSY: an EMBOSS associated software package for comprehensive genome
analyses.

Itaya H(1), Oshita K, Arakawa K, Tomita M.

Author information: 
(1)Institute for Advanced Biosciences, Keio University, 14-1, Baba town, Tsuruoka
city, Yamagata Pref, 997-0035, Japan. gaou@sfc.keio.ac.jp.

The popular European Molecular Biology Open Software Suite (EMBOSS) currently
contains over 400 tools used in various bioinformatics researches, equipped with 
sophisticated development frameworks for interoperability and tool
discoverability as well as rich documentations and various user interfaces. In
order to further strengthen EMBOSS in the fields of genomics, we here present a
novel EMBOSS associated software (EMBASSY) package named GEMBASSY, which adds
more than 50 analysis tools from the G-language Genome Analysis Environment and
its Representational State Transfer (REST) and SOAP web services. GEMBASSY
basically contains wrapper programs of G-language REST/SOAP web services to
provide intuitive and easy access to various annotations within complete genome
flatfiles, as well as tools for analyzing nucleic composition, calculating codon 
usage, and visualizing genomic information. For example, analysis methods such as
for calculating distance between sequences by genomic signatures and for
predicting gene expression levels from codon usage bias are effective in the
interpretation of meta-genomic and meta-transcriptomic data. GEMBASSY tools can
be used seamlessly with other EMBOSS tools and UNIX command line tools. The
source code written in C is available from GitHub
(https://github.com/celery-kotone/GEMBASSY/) and the distribution package is
freely available from the GEMBASSY web site
(http://www.g-language.org/gembassy/).

DOI: 10.1186/1751-0473-8-17 
PMCID: PMC3847652
PMID: 23987304  [PubMed]


1370. Bioinformatics. 2013 Nov 1;29(21):2705-13. doi: 10.1093/bioinformatics/btt470.
Epub 2013 Aug 24.

Identification of transcription factor binding sites from ChIP-seq data at high
resolution.

Bardet AF(1), Steinmann J, Bafna S, Knoblich JA, Zeitlinger J, Stark A.

Author information: 
(1)Research Institute of Molecular Pathology (IMP), Institute of Molecular
Biotechnology (IMBA), Vienna, Austria and Stowers Institute for Medical Research,
Kansas City, MO, USA.

MOTIVATION: Chromatin immunoprecipitation coupled to next-generation sequencing
(ChIP-seq) is widely used to study the in vivo binding sites of transcription
factors (TFs) and their regulatory targets. Recent improvements to ChIP-seq, such
as increased resolution, promise deeper insights into transcriptional regulation,
yet require novel computational tools to fully leverage their advantages.
RESULTS: To this aim, we have developed peakzilla, which can identify closely
spaced TF binding sites at high resolution (i.e. resolves individual binding
sites even if spaced closely), as we demonstrate using semisynthetic datasets,
performing ChIP-seq for the TF Twist in Drosophila embryos with different
experimental fragment sizes, and analyzing ChIP-exo datasets. We show that the
increased resolution reached by peakzilla is highly relevant, as closely spaced
Twist binding sites are strongly enriched in transcriptional enhancers,
suggesting a signature to discriminate functional from abundant non-functional or
neutral TF binding. Peakzilla is easy to use, as it estimates all the necessary
parameters from the data and is freely available.
AVAILABILITY AND IMPLEMENTATION: The peakzilla program is available from
https://github.com/steinmann/peakzilla or
http://www.starklab.org/data/peakzilla/.
CONTACT: stark@starklab.org.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btt470 
PMCID: PMC3799470
PMID: 23980024  [PubMed - indexed for MEDLINE]


1371. Bioinformatics. 2013 Nov 1;29(21):2790-1. doi: 10.1093/bioinformatics/btt468.
Epub 2013 Aug 23.

NextGenMap: fast and accurate read mapping in highly polymorphic genomes.

Sedlazeck FJ(1), Rescheneder P, von Haeseler A.

Author information: 
(1)Center for Integrative Bioinformatics Vienna, Max F. Perutz Laboratories,
University of Vienna, Medical University of Vienna, Dr. Bohrgasse 9, A-1030
Vienna, Austria and Bioinformatics and Computational Biology, Faculty of Computer
Science, University of Vienna, Waehringerstrasse 17, A-1090 Vienna, Austria.

SUMMARY: When choosing a read mapper, one faces the trade off between speed and
the ability to map reads in highly polymorphic regions. Here, we report
NextGenMap, a fast and accurate read mapper, which reduces this dilemma.
NextGenMap aligns reads reliably to a reference genome even when the sequence
difference between target and reference genome is large, i.e. highly polymorphic 
genome. At the same time, NextGenMap outperforms current mapping methods with
respect to runtime and to the number of correctly mapped reads. NextGenMap
efficiently uses the available hardware by exploiting multi-core CPUs as well as 
graphic cards (GPUs), if available. In addition, NextGenMap handles automatically
any read data independent of read length and sequencing technology.
AVAILABILITY: NextGenMap source code and documentation are available at:
http://cibiv.github.io/NextGenMap/.
CONTACT: fritz.sedlazeck@univie.ac.at.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btt468 
PMID: 23975764  [PubMed - indexed for MEDLINE]


1372. J Chem Inf Model. 2013 Sep 23;53(9):2240-51. doi: 10.1021/ci400308z. Epub 2013
Aug 21.

hERG me out.

Czodrowski P(1).

Author information: 
(1)Merck KGaA , Small Molecule Platform, Global Computational Chemistry,
Frankfurter Strasse 250, 64293 Darmstadt, Germany.

A detailed analysis of the hERG content inside the ChEMBL database is performed. 
The correlation between the outcome from binding assays and functional assays is 
probed. On the basis of descriptor distributions, design paradigms with respect
to structural and physicochemical properties of hERG active and hERG inactive
compounds are challenged. Finally, classification models with different data sets
are trained. All source code is provided, which is based on the Python open
source packages RDKit and scikit-learn to enable the community to rerun the
experiments. The code is stored on github (
https://github.com/pzc/herg_chembl_jcim).

DOI: 10.1021/ci400308z 
PMID: 23944269  [PubMed - indexed for MEDLINE]


1373. PLoS One. 2013 Jul 23;8(7):e69666. doi: 10.1371/journal.pone.0069666. Print 2013.

GobyWeb: simplified management and analysis of gene expression and DNA
methylation sequencing data.

Dorff KC(1), Chambwe N, Zeno Z, Simi M, Shaknovich R, Campagne F.

Author information: 
(1)The HRH Prince Alwaleed Bin Talal Bin Abdulaziz Alsaud Institute for
Computational Biomedicine, The Weill Cornell Medical College, New York, New York,
United States of America.

We present GobyWeb, a web-based system that facilitates the management and
analysis of high-throughput sequencing (HTS) projects. The software provides
integrated support for a broad set of HTS analyses and offers a simple plugin
extension mechanism. Analyses currently supported include quantification of gene 
expression for messenger and small RNA sequencing, estimation of DNA methylation 
(i.e., reduced bisulfite sequencing and whole genome methyl-seq), or the
detection of pathogens in sequenced data. In contrast to previous analysis
pipelines developed for analysis of HTS data, GobyWeb requires significantly less
storage space, runs analyses efficiently on a parallel grid, scales gracefully to
process tens or hundreds of multi-gigabyte samples, yet can be used effectively
by researchers who are comfortable using a web browser. We conducted performance 
evaluations of the software and found it to either outperform or have similar
performance to analysis programs developed for specialized analyses of HTS data. 
We found that most biologists who took a one-hour GobyWeb training session were
readily able to analyze RNA-Seq data with state of the art analysis tools.
GobyWeb can be obtained at http://gobyweb.campagnelab.org and is freely available
for non-commercial use. GobyWeb plugins are distributed in source code and
licensed under the open source LGPL3 license to facilitate code inspection, reuse
and independent extensions http://github.com/CampagneLaboratory/gobyweb2-plugins.

DOI: 10.1371/journal.pone.0069666 
PMCID: PMC3720652
PMID: 23936070  [PubMed - indexed for MEDLINE]


1374. Syst Biol. 2013 Nov;62(6):901-12. doi: 10.1093/sysbio/syt054. Epub 2013 Aug 6.

Efficient exploration of the space of reconciled gene trees.

Szöllõsi GJ(1), Rosikiewicz W, Boussau B, Tannier E, Daubin V.

Author information: 
(1)Laboratoire de Biométrie et Biologie Evolutive, Centre National de la
Recherche Scientifique, Unité Mixte de Recherche 5558, Université Lyon 1, F-69622
Villeurbanne;

Gene trees record the combination of gene-level events, such as duplication,
transfer and loss (DTL), and species-level events, such as speciation and
extinction. Gene tree-species tree reconciliation methods model these processes
by drawing gene trees into the species tree using a series of gene and
species-level events. The reconstruction of gene trees based on sequence alone
almost always involves choosing between statistically equivalent or weakly
distinguishable relationships that could be much better resolved based on a
putative species tree. To exploit this potential for accurate reconstruction of
gene trees, the space of reconciled gene trees must be explored according to a
joint model of sequence evolution and gene tree-species tree reconciliation. Here
we present amalgamated likelihood estimation (ALE), a probabilistic approach to
exhaustively explore all reconciled gene trees that can be amalgamated as a
combination of clades observed in a sample of gene trees. We implement the ALE
approach in the context of a reconciliation model (Szöllősi et al. 2013), which
allows for the DTL of genes. We use ALE to efficiently approximate the sum of the
joint likelihood over amalgamations and to find the reconciled gene tree that
maximizes the joint likelihood among all such trees. We demonstrate using
simulations that gene trees reconstructed using the joint likelihood are
substantially more accurate than those reconstructed using sequence alone. Using 
realistic gene tree topologies, branch lengths, and alignment sizes, we
demonstrate that ALE produces more accurate gene trees even if the model of
sequence evolution is greatly simplified. Finally, examining 1099 gene families
from 36 cyanobacterial genomes we find that joint likelihood-based inference
results in a striking reduction in apparent phylogenetic discord, with
respectively. 24%, 59%, and 46% reductions in the mean numbers of duplications,
transfers, and losses per gene family. The open source implementation of ALE is
available from https://github.com/ssolo/ALE.git.

DOI: 10.1093/sysbio/syt054 
PMCID: PMC3797637
PMID: 23925510  [PubMed - indexed for MEDLINE]


1375. PLoS One. 2013 Jul 29;8(7):e69885. doi: 10.1371/journal.pone.0069885. Print 2013.

GenGIS 2: geospatial analysis of traditional and genetic biodiversity, with new
gradient algorithms and an extensible plugin framework.

Parks DH(1), Mankowski T, Zangooei S, Porter MS, Armanini DG, Baird DJ, Langille 
MG, Beiko RG.

Author information: 
(1)Faculty of Computer Science, Dalhousie University, Halifax, Nova Scotia,
Canada.

GenGIS is free and open source software designed to integrate biodiversity data
with a digital map and information about geography and habitat. While originally 
developed with microbial community analyses and phylogeography in mind, GenGIS
has been applied to a wide range of datasets. A key feature of GenGIS is the
ability to test geographic axes that can correspond to routes of migration or
gradients that influence community similarity. Here we introduce GenGIS version
2, which extends the linear gradient tests introduced in the first version to
allow comprehensive testing of all possible linear geographic axes. GenGIS v2
also includes a new plugin framework that supports the development and use of
graphically driven analysis packages: initial plugins include implementations of 
linear regression and the Mantel test, calculations of alpha-diversity (e.g.,
Shannon Index) for all samples, and geographic visualizations of dissimilarity
matrices. We have also implemented a recently published method for biomonitoring 
reference condition analysis (RCA), which compares observed species richness and 
diversity to predicted values to determine whether a given site has been
impacted. The newest version of GenGIS supports vector data in addition to raster
files. We demonstrate the new features of GenGIS by performing a full gradient
analysis of an Australian kangaroo apple data set, by using plugins and embedded 
statistical commands to analyze human microbiome sample data, and by applying RCA
to a set of samples from Atlantic Canada. GenGIS release versions, tutorials and 
documentation are freely available at http://kiwi.cs.dal.ca/GenGIS, and source
code is available at https://github.com/beiko-lab/gengis.

DOI: 10.1371/journal.pone.0069885 
PMCID: PMC3726740
PMID: 23922841  [PubMed - indexed for MEDLINE]


1376. PeerJ. 2013 Jul 23;1:e113. doi: 10.7717/peerj.113. Print 2013.

Improving transcriptome assembly through error correction of high-throughput
sequence reads.

Macmanes MD(1), Eisen MB.

Author information: 
(1)California Institute for Quantitative Biosciences, University of California , 
Berkeley, CA , USA.

The study of functional genomics, particularly in non-model organisms, has been
dramatically improved over the last few years by the use of transcriptomes and
RNAseq. While these studies are potentially extremely powerful, a computationally
intensive procedure, the de novo construction of a reference transcriptome must
be completed as a prerequisite to further analyses. The accurate reference is
critically important as all downstream steps, including estimating transcript
abundance are critically dependent on the construction of an accurate reference. 
Though a substantial amount of research has been done on assembly, only recently 
have the pre-assembly procedures been studied in detail. Specifically, several
stand-alone error correction modules have been reported on and, while they have
shown to be effective in reducing errors at the level of sequencing reads, how
error correction impacts assembly accuracy is largely unknown. Here, we show via 
use of a simulated and empiric dataset, that applying error correction to
sequencing reads has significant positive effects on assembly accuracy, and
should be applied to all datasets. A complete collection of commands which will
allow for the production of Reptile corrected reads is available at
https://github.com/macmanes/error_correction/tree/master/scripts and as File S1.

DOI: 10.7717/peerj.113 
PMCID: PMC3728768
PMID: 23904992  [PubMed]


1377. Hum Mutat. 2013 Nov;34(11):1458-66. doi: 10.1002/humu.22389. Epub 2013 Sep 13.

The Finnish disease heritage database (FinDis) update-a database for the genes
mutated in the Finnish disease heritage brought to the next-generation sequencing
era.

Polvi A(1), Linturi H, Varilo T, Anttonen AK, Byrne M, Fokkema IF, Almusa H,
Metzidis A, Avela K, Aula P, Kestilä M, Muilu J.

Author information: 
(1)The Institute for Molecular Medicine Finland FIMM Technology Centre,
University of Helsinki, Helsinki, Finland.

The Finnish Disease Heritage Database (FinDis) (http://findis.org) was originally
published in 2004 as a centralized information resource for rare monogenic
diseases enriched in the Finnish population. The FinDis database originally
contained 405 causative variants for 30 diseases. At the time, the FinDis
database was a comprehensive collection of data, but since 1994, a large amount
of new information has emerged, making the necessity to update the database
evident. We collected information and updated the database to contain genes and
causative variants for 35 diseases, including six more genes and more than 1,400 
additional disease-causing variants. Information for causative variants for each 
gene is collected under the LOVD 3.0 platform, enabling easy updating. The FinDis
portal provides a centralized resource and user interface to link information on 
each disease and gene with variant data in the LOVD 3.0 platform. The software
written to achieve this has been open-sourced and made available on GitHub
(http://github.com/findis-db), allowing biomedical institutions in other
countries to present their national data in a similar way, and to both contribute
to, and benefit from, standardized variation data. The updated FinDis portal
provides a unique resource to assist patient diagnosis, research, and the
development of new cures.

© 2013 WILEY PERIODICALS, INC.

DOI: 10.1002/humu.22389 
PMID: 23904198  [PubMed - indexed for MEDLINE]


1378. Database (Oxford). 2013 Jul 26;2013:bat056. doi: 10.1093/database/bat056. Print
2013.

Rapid storage and retrieval of genomic intervals from a relational database
system using nested containment lists.

Wiley LK(1), Sivley RM, Bush WS.

Author information: 
(1)Department of Biomedical Informatics, Center for Human Genetics Research,
Vanderbilt University, 2215 Garland Ave, Nashville, TN 37232, USA.

Efficient storage and retrieval of genomic annotations based on range intervals
is necessary, given the amount of data produced by next-generation sequencing
studies. The indexing strategies of relational database systems (such as MySQL)
greatly inhibit their use in genomic annotation tasks. This has led to the
development of stand-alone applications that are dependent on flat-file
libraries. In this work, we introduce MyNCList, an implementation of the NCList
data structure within a MySQL database. MyNCList enables the storage, update and 
rapid retrieval of genomic annotations from the convenience of a relational
database system. Range-based annotations of 1 million variants are retrieved in
under a minute, making this approach feasible for whole-genome annotation tasks. 
Database URL: https://github.com/bushlab/mynclist.

DOI: 10.1093/database/bat056 
PMCID: PMC3724366
PMID: 23894185  [PubMed - indexed for MEDLINE]


1379. BMC Genomics. 2013 Jul 22;14:494. doi: 10.1186/1471-2164-14-494.

Cloud-based uniform ChIP-Seq processing tools for modENCODE and ENCODE.

Trinh QM(1), Jen FY, Zhou Z, Chu KM, Perry MD, Kephart ET, Contrino S, Ruzanov P,
Stein LD.

Author information: 
(1)Ontario Institute for Cancer Research, MaRS Centre, South Tower, 101 College
Street, Suite 800, Toronto, ON, M5G 0A3, Canada.

BACKGROUND: Funded by the National Institutes of Health (NIH), the aim of the
Model Organism ENCyclopedia of DNA Elements (modENCODE) project is to provide the
biological research community with a comprehensive encyclopedia of functional
genomic elements for both model organisms C. elegans (worm) and D. melanogaster
(fly). With a total size of just under 10 terabytes of data collected and
released to the public, one of the challenges faced by researchers is to extract 
biologically meaningful knowledge from this large data set. While the basic
quality control, pre-processing, and analysis of the data has already been
performed by members of the modENCODE consortium, many researchers will wish to
reinterpret the data set using modifications and enhancements of the original
protocols, or combine modENCODE data with other data sets. Unfortunately this can
be a time consuming and logistically challenging proposition.
RESULTS: In recognition of this challenge, the modENCODE DCC has released uniform
computing resources for analyzing modENCODE data on Galaxy
(https://github.com/modENCODE-DCC/Galaxy), on the public Amazon Cloud
(http://aws.amazon.com), and on the private Bionimbus Cloud for genomic research 
(http://www.bionimbus.org). In particular, we have released Galaxy workflows for 
interpreting ChIP-seq data which use the same quality control (QC) and peak
calling standards adopted by the modENCODE and ENCODE communities. For
convenience of use, we have created Amazon and Bionimbus Cloud machine images
containing Galaxy along with all the modENCODE data, software and other
dependencies.
CONCLUSIONS: Using these resources provides a framework for running consistent
and reproducible analyses on modENCODE data, ultimately allowing researchers to
use more of their time using modENCODE data, and less time moving it around.

DOI: 10.1186/1471-2164-14-494 
PMCID: PMC3734164
PMID: 23875683  [PubMed - indexed for MEDLINE]


1380. Algorithms Mol Biol. 2013 Jul 12;8(1):20. doi: 10.1186/1748-7188-8-20.

Fast half-sibling population reconstruction: theory and algorithms.

Dexter D(1), Brown DG.

Author information: 
(1)David R Cheriton School of Computer Science, University of Waterloo, Waterloo,
ON N2L 3G1, Canada. browndg@uwaterloo.ca.

BACKGROUND: Kinship inference is the task of identifying genealogically related
individuals. Kinship information is important for determining mating structures, 
notably in endangered populations. Although many solutions exist for
reconstructing full sibling relationships, few exist for half-siblings.
RESULTS: We consider the problem of determining whether a proposed half-sibling
population reconstruction is valid under Mendelian inheritance assumptions. We
show that this problem is NP-complete and provide a 0/1 integer program that
identifies the minimum number of individuals that must be removed from a
population in order for the reconstruction to become valid. We also present
SibJoin, a heuristic-based clustering approach based on Mendelian genetics, which
is strikingly fast. The software is available at
http://github.com/ddexter/SibJoin.git+.
CONCLUSIONS: Our SibJoin algorithm is reasonably accurate and thousands of times 
faster than existing algorithms. The heuristic is used to infer a half-sibling
structure for a population which was, until recently, too large to evaluate.

DOI: 10.1186/1748-7188-8-20 
PMCID: PMC3738158
PMID: 23849037  [PubMed]


1381. Bioinformatics. 2013 Oct 1;29(19):2445-51. doi: 10.1093/bioinformatics/btt376.
Epub 2013 Jul 3.

Statistical agglomeration: peak summarization for direct infusion lipidomics.

Smith R(1), Anthonymuthu TS, Ventura D, Prince JT.

Author information: 
(1)Department of Computer Science and Department of Chemistry, Brigham Young
University, Provo, UT 84602, USA.

MOTIVATION: Quantification of lipids is a primary goal in lipidomics. In direct
infusion/injection (or shotgun) lipidomics, accurate downstream identification
and quantitation requires accurate summarization of repetitive peak measurements.
Imprecise peak summarization multiplies downstream error by propagating into
species identification and intensity estimation. To our knowledge, this is the
first analysis of direct infusion peak summarization in the literature.
RESULTS: We present two novel peak summarization algorithms for direct infusion
samples and compare them with an off-machine ad hoc summarization algorithm as
well as with the propriety Xcalibur algorithm. Our statistical agglomeration
algorithm reduces peakwise error by 38% mass/charge (m/z) and 44% (intensity)
compared with the ad hoc method over three datasets. Pointwise error is reduced
by 23% (m/z). Compared with Xcalibur, our statistical agglomeration algorithm
produces 68% less m/z error and 51% less intensity error on average on two
comparable datasets.
AVAILABILITY: The source code for Statistical Agglomeration and the datasets used
are freely available for non-commercial purposes at
https://github.com/optimusmoose/statistical_agglomeration. Modified Bin
Aggolmeration is freely available in MSpire, an open source mass spectrometry
package at https://github.com/princelab/mspire/.

DOI: 10.1093/bioinformatics/btt376 
PMID: 23825371  [PubMed - indexed for MEDLINE]


1382. Bioinformatics. 2013 Sep 15;29(18):2292-9. doi: 10.1093/bioinformatics/btt381.
Epub 2013 Jul 2.

TIGAR: transcript isoform abundance estimation method with gapped alignment of
RNA-Seq data by variational Bayesian inference.

Nariai N(1), Hirose O, Kojima K, Nagasaki M.

Author information: 
(1)Department of Integrative Genomics, Tohoku Medical Megabank Organization,
Tohoku University, Seiryo-machi, Aoba-ku, Sendai, Miyagi, 980-8575, Japan.
nariai@megabank.tohoku.ac.jp

MOTIVATION: Many human genes express multiple transcript isoforms through
alternative splicing, which greatly increases diversity of protein function.
Although RNA sequencing (RNA-Seq) technologies have been widely used in measuring
amounts of transcribed mRNA, accurate estimation of transcript isoform abundances
from RNA-Seq data is challenging because reads often map to more than one
transcript isoforms or paralogs whose sequences are similar to each other.
RESULTS: We propose a statistical method to estimate transcript isoform
abundances from RNA-Seq data. Our method can handle gapped alignments of reads
against reference sequences so that it allows insertion or deletion errors within
reads. The proposed method optimizes the number of transcript isoforms by
variational Bayesian inference through an iterative procedure, and its
convergence is guaranteed under a stopping criterion. On simulated datasets, our 
method outperformed the comparable quantification methods in inferring transcript
isoform abundances, and at the same time its rate of convergence was faster than 
that of the expectation maximization algorithm. We also applied our method to
RNA-Seq data of human cell line samples, and showed that our prediction result
was more consistent among technical replicates than those of other methods.
AVAILABILITY: An implementation of our method is available at
http://github.com/nariai/tigar
CONTACT: nariai@megabank.tohoku.ac.jp
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btt381 
PMID: 23821651  [PubMed - indexed for MEDLINE]


1383. Comput Biol Med. 2013 Sep;43(8):1023-4. doi: 10.1016/j.compbiomed.2013.05.014.
Epub 2013 May 28.

ExonSuite: algorithmically optimizing alternative gene splicing for the PUF
proteins.

Ustek D(1), Kohrman A, Krstic B, Fernandez K.

Author information: 
(1)Grinnell College, Computer Science Department, USA. ustekdil@grinnell.edu

The stability of mRNA and its translation is a vital process necessary for proper
protein production. The specificity of the regulation is controlled by specific
RNA motifs and regulatory proteins. Pumilio/fem-3 mRNA-binding factor (PUF)
proteins are usually used in regulating mRNA stability as well as translation.
Here, we optimized a PUF protein target finder program to understand the natural 
diversity of RNA recognition by this family of proteins. ExonSuite is available
to compile and run at https://github.com/dilanustek/ExonSuite.

Copyright © 2013 Elsevier Ltd. All rights reserved.

DOI: 10.1016/j.compbiomed.2013.05.014 
PMID: 23816174  [PubMed - indexed for MEDLINE]


1384. Bioinformatics. 2013 Jul 1;29(13):i361-70. doi: 10.1093/bioinformatics/btt215.

Short read alignment with populations of genomes.

Huang L(1), Popic V, Batzoglou S.

Author information: 
(1)Department of Computer Science, Stanford University, Stanford, CA 94305, USA.

SUMMARY: The increasing availability of high-throughput sequencing technologies
has led to thousands of human genomes having been sequenced in the past years.
Efforts such as the 1000 Genomes Project further add to the availability of human
genome variation data. However, to date, there is no method that can map reads of
a newly sequenced human genome to a large collection of genomes. Instead, methods
rely on aligning reads to a single reference genome. This leads to inherent
biases and lower accuracy. To tackle this problem, a new alignment tool BWBBLE is
introduced in this article. We (i) introduce a new compressed representation of a
collection of genomes, which explicitly tackles the genomic variation observed at
every position, and (ii) design a new alignment algorithm based on the
Burrows-Wheeler transform that maps short reads from a newly sequenced genome to 
an arbitrary collection of two or more (up to millions of) genomes with high
accuracy and no inherent bias to one specific genome.
AVAILABILITY: http://viq854.github.com/bwbble.

DOI: 10.1093/bioinformatics/btt215 
PMCID: PMC3694645
PMID: 23813006  [PubMed - indexed for MEDLINE]


1385. PLoS One. 2013 Jun 17;8(6):e66643. doi: 10.1371/journal.pone.0066643. Print 2013.

A filtering method to generate high quality short reads using illumina paired-end
technology.

Eren AM(1), Vineis JH, Morrison HG, Sogin ML.

Author information: 
(1)Josephine Bay Paul Center for Comparative Molecular Biology and Evolution,
Marine Biological Laboratory, Woods Hole, Massachusetts, USA.

Erratum in
    PLoS One. 2013;8(6). doi:10.1371/annotation/afa5c40d-c604-46ae-84c4-82cb92193a5e.

Consensus between independent reads improves the accuracy of genome and
transcriptome analyses, however lack of consensus between very similar sequences 
in metagenomic studies can and often does represent natural variation of
biological significance. The common use of machine-assigned quality scores on
next generation platforms does not necessarily correlate with accuracy. Here, we 
describe using the overlap of paired-end, short sequence reads to identify
error-prone reads in marker gene analyses and their contribution to spurious OTUs
following clustering analysis using QIIME. Our approach can also reduce error in 
shotgun sequencing data generated from libraries with small, tightly constrained 
insert sizes. The open-source implementation of this algorithm in Python
programming language with user instructions can be obtained from
https://github.com/meren/illumina-utils.

DOI: 10.1371/journal.pone.0066643 
PMCID: PMC3684618
PMID: 23799126  [PubMed - indexed for MEDLINE]


1386. Comput Methods Programs Biomed. 2013 Sep;111(3):711-4. doi:
10.1016/j.cmpb.2013.05.021. Epub 2013 Jun 22.

Pinda: a web service for detection and analysis of intraspecies gene duplication 
events.

Kontopoulos DG(1), Glykos NM.

Author information: 
(1)Department of Molecular Biology and Genetics, Democritus University of Thrace,
University Campus, 68100 Alexandroupolis, Greece.

We present Pinda, a Web service for the detection and analysis of possible
duplications of a given protein or DNA sequence within a source species. Pinda
fully automates the whole gene duplication detection procedure, from performing
the initial similarity searches, to generating the multiple sequence alignments
and the corresponding phylogenetic trees, to bootstrapping the trees and
producing a Z-score-based list of duplication candidates for the input sequence. 
Pinda has been cross-validated using an extensive set of known and
bibliographically characterized duplication events. The service facilitates the
automatic and dependable identification of gene duplication events, using some of
the most successful bioinformatics software to perform an extensive analysis
protocol. Pinda will prove of use for the analysis of newly discovered genes and 
proteins, thus also assisting the study of recently sequenced genomes. The
service's location is http://orion.mbg.duth.gr/Pinda. The source code is freely
available via https://github.com/dgkontopoulos/Pinda/.

Copyright © 2013 Elsevier Ireland Ltd. All rights reserved.

DOI: 10.1016/j.cmpb.2013.05.021 
PMID: 23796449  [PubMed - indexed for MEDLINE]


1387. Bioinformatics. 2013 Sep 1;29(17):2213-5. doi: 10.1093/bioinformatics/btt342.
Epub 2013 Jun 13.

Metingear: a development environment for annotating genome-scale metabolic
models.

May JW(1), James AG, Steinbeck C.

Author information: 
(1)Cheminformatics and Metabolism, European Molecular Biology Laboratory-European
Bioinformatics Institute (EMBL-EBI), Wellcome Trust Genome Campus, Hinxton,
Cambridge, UK. johnmay@ebi.ac.uk

Genome-scale metabolic models often lack annotations that would allow them to be 
used for further analysis. Previous efforts have focused on associating
metabolites in the model with a cross reference, but this can be problematic if
the reference is not freely available, multiple resources are used or the
metabolite is added from a literature review. Associating each metabolite with
chemical structure provides unambiguous identification of the components and a
more detailed view of the metabolism. We have developed an open-source desktop
application that simplifies the process of adding database cross references and
chemical structures to genome-scale metabolic models. Annotated models can be
exported to the Systems Biology Markup Language open interchange
format.AVAILABILITY: Source code, binaries, documentation and tutorials are
freely available at http://johnmay.github.com/metingear. The application is
implemented in Java with bundles available for MS Windows and Macintosh OS X.

DOI: 10.1093/bioinformatics/btt342 
PMCID: PMC3740624
PMID: 23766418  [PubMed - indexed for MEDLINE]


1388. BMC Bioinformatics. 2013;14 Suppl 5:S11. doi: 10.1186/1471-2105-14-S5-S11. Epub
2013 Apr 10.

A mixture model for expression deconvolution from RNA-seq in heterogeneous
tissues.

Li Y(1), Xie X.

Author information: 
(1)Department of Computer Science, University of California-Irvine, CA, USA.

BACKGROUND: RNA-seq, a next-generation sequencing based method for transcriptome 
analysis, is rapidly emerging as the method of choice for comprehensive
transcript abundance estimation. The accuracy of RNA-seq can be highly impacted
by the purity of samples. A prominent, outstanding problem in RNA-seq is how to
estimate transcript abundances in heterogeneous tissues, where a sample is
composed of more than one cell type and the inhomogeneity can substantially
confound the transcript abundance estimation of each individual cell type.
Although experimental methods have been proposed to dissect multiple distinct
cell types, computationally "deconvoluting" heterogeneous tissues provides an
attractive alternative, since it keeps the tissue sample as well as the
subsequent molecular content yield intact.
RESULTS: Here we propose a probabilistic model-based approach, Transcript
Estimation from Mixed Tissue samples (TEMT), to estimate the transcript
abundances of each cell type of interest from RNA-seq data of heterogeneous
tissue samples. TEMT incorporates positional and sequence-specific biases, and
its online EM algorithm only requires a runtime proportional to the data size and
a small constant memory. We test the proposed method on both simulation data and 
recently released ENCODE data, and show that TEMT significantly outperforms
current state-of-the-art methods that do not take tissue heterogeneity into
account. Currently, TEMT only resolves the tissue heterogeneity resulting from
two cell types, but it can be extended to handle tissue heterogeneity resulting
from multi cell types. TEMT is written in python, and is freely available at
https://github.com/uci-cbcl/TEMT.
CONCLUSIONS: The probabilistic model-based approach proposed here provides a new 
method for analyzing RNA-seq data from heterogeneous tissue samples. By applying 
the method to both simulation data and ENCODE data, we show that explicitly
accounting for tissue heterogeneity can significantly improve the accuracy of
transcript abundance estimation.

DOI: 10.1186/1471-2105-14-S5-S11 
PMCID: PMC3622628
PMID: 23735186  [PubMed - indexed for MEDLINE]


1389. BMC Bioinformatics. 2013;14 Suppl 5:S4. doi: 10.1186/1471-2105-14-S5-S4. Epub
2013 Apr 10.

Discovering and mapping chromatin states using a tree hidden Markov model.

Biesinger J(1), Wang Y, Xie X.

Author information: 
(1)Department of Computer Science, University of California-Irvine, CA, USA.

New biological techniques and technological advances in high-throughput
sequencing are paving the way for systematic, comprehensive annotation of many
genomes, allowing differences between cell types or between disease/normal
tissues to be determined with unprecedented breadth. Epigenetic modifications
have been shown to exhibit rich diversity between cell types, correlate tightly
with cell-type specific gene expression, and changes in epigenetic modifications 
have been implicated in several diseases. Previous attempts to understand
chromatin state have focused on identifying combinations of epigenetic
modification, but in cases of multiple cell types, have not considered the
lineage of the cells in question.We present a Bayesian network that uses
epigenetic modifications to simultaneously model 1) chromatin mark combinations
that give rise to different chromatin states and 2) propensities for transitions 
between chromatin states through differentiation or disease progression. We apply
our model to a recent dataset of histone modifications, covering nine human cell 
types with nine epigenetic modifications measured for each. Since exact inference
in this model is intractable for all the scale of the datasets, we develop
several variational approximations and explore their accuracy. Our method
exhibits several desirable features including improved accuracy of inferring
chromatin states, improved handling of missing data, and linear scaling with
dataset size. The source code for our model is available at http://
http://github.com/uci-cbcl/tree-hmm.

DOI: 10.1186/1471-2105-14-S5-S4 
PMCID: PMC3622631
PMID: 23734743  [PubMed - indexed for MEDLINE]


1390. BMC Bioinformatics. 2013;14 Suppl 5:S2. doi: 10.1186/1471-2105-14-S5-S2. Epub
2013 Apr 10.

metaBEETL: high-throughput analysis of heterogeneous microbial populations from
shotgun DNA sequences.

Ander C(1), Schulz-Trieglaff OB, Stoye J, Cox AJ.

Author information: 
(1)Computational Biology Group, Illumina Cambridge Ltd,, Chesterford Research
Park, Little Chesterford, Essex, United Kingdom.

Environmental shotgun sequencing (ESS) has potential to give greater insight into
microbial communities than targeted sequencing of 16S regions, but requires much 
higher sequence coverage. The advent of next-generation sequencing has made it
feasible for the Human Microbiome Project and other initiatives to generate ESS
data on a large scale, but computationally efficient methods for analysing such
data sets are needed.Here we present metaBEETL, a fast taxonomic classifier for
environmental shotgun sequences. It uses a Burrows-Wheeler Transform (BWT) index 
of the sequencing reads and an indexed database of microbial reference sequences.
Unlike other BWT-based tools, our method has no upper limit on the number or the 
total size of the reference sequences in its database. By capturing sequence
relationships between strains, our reference index also allows us to classify
reads which are not unique to an individual strain but are nevertheless specific 
to some higher phylogenetic order.Tested on datasets with known taxonomic
composition, metaBEETL gave results that are competitive with existing
similarity-based tools: due to normalization steps which other classifiers lack, 
the taxonomic profile computed by metaBEETL closely matched the true
environmental profile. At the same time, its moderate running time and low memory
footprint allow metaBEETL to scale well to large data sets.Code to construct the 
BWT indexed database and for the taxonomic classification is part of the BEETL
library, available as a github repository at git@github.com:BEETL/BEETL.git.

DOI: 10.1186/1471-2105-14-S5-S2 
PMCID: PMC3622627
PMID: 23734710  [PubMed - indexed for MEDLINE]


1391. Bioinformatics. 2013 Aug 1;29(15):1890-2. doi: 10.1093/bioinformatics/btt294.
Epub 2013 Jun 6.

SVGenes: a library for rendering genomic features in scalable vector graphic
format.

Etherington GJ(1), MacLean D.

Author information: 
(1)The Sainsbury Laboratory, Norwich Research Park, Norwich, NR4 7UH, UK.

MOTIVATION: Drawing genomic features in attractive and informative ways is a key 
task in visualization of genomics data. Scalable Vector Graphics (SVG) format is 
a modern and flexible open standard that provides advanced features including
modular graphic design, advanced web interactivity and animation within a
suitable client. SVGs do not suffer from loss of image quality on re-scaling and 
provide the ability to edit individual elements of a graphic on the whole object 
level independent of the whole image. These features make SVG a potentially
useful format for the preparation of publication quality figures including
genomic objects such as genes or sequencing coverage and for web applications
that require rich user-interaction with the graphical elements.
RESULTS: SVGenes is a Ruby-language library that uses SVG primitives to render
typical genomic glyphs through a simple and flexible Ruby interface. The library 
implements a simple Page object that spaces and contains horizontal Track objects
that in turn style, colour and positions features within them. Tracks are the
level at which visual information is supplied providing the full styling
capability of the SVG standard. Genomic entities like genes, transcripts and
histograms are modelled in Glyph objects that are attached to a track and take
advantage of SVG primitives to render the genomic features in a track as any of a
selection of defined glyphs. The feature model within SVGenes is simple but
flexible and not dependent on particular existing gene feature formats meaning
graphics for any existing datasets can easily be created without need for
conversion.
AVAILABILITY: The library is provided as a Ruby Gem from
https://rubygems.org/gems/bio-svgenes under the MIT license, and open source code
is available at https://github.com/danmaclean/bioruby-svgenes also under the MIT 
License.
CONTACT: dan.maclean@tsl.ac.uk.

DOI: 10.1093/bioinformatics/btt294 
PMCID: PMC3712214
PMID: 23749959  [PubMed - indexed for MEDLINE]


1392. Nucleic Acids Res. 2013 Jul;41(Web Server issue):W41-6. doi: 10.1093/nar/gkt530. 
Epub 2013 Jun 8.

Genome Maps, a new generation genome browser.

Medina I(1), Salavert F, Sanchez R, de Maria A, Alonso R, Escobar P, Bleda M,
Dopazo J.

Author information: 
(1)Department of Computational Genomics, Centro de Investigación Príncipe Felipe,
Valencia 46012, Spain.

Genome browsers have gained importance as more genomes and related genomic
information become available. However, the increase of information brought about 
by new generation sequencing technologies is, at the same time, causing a subtle 
but continuous decrease in the efficiency of conventional genome browsers. Here, 
we present Genome Maps, a genome browser that implements an innovative model of
data transfer and management. The program uses highly efficient technologies from
the new HTML5 standard, such as scalable vector graphics, that optimize workloads
at both server and client sides and ensure future scalability. Thus, data
management and representation are entirely carried out by the browser, without
the need of any Java Applet, Flash or other plug-in technology installation.
Relevant biological data on genes, transcripts, exons, regulatory features,
single-nucleotide polymorphisms, karyotype and so forth, are imported from web
services and are available as tracks. In addition, several DAS servers are
already included in Genome Maps. As a novelty, this web-based genome browser
allows the local upload of huge genomic data files (e.g. VCF or BAM) that can be 
dynamically visualized in real time at the client side, thus facilitating the
management of medical data affected by privacy restrictions. Finally, Genome Maps
can easily be integrated in any web application by including only a few lines of 
code. Genome Maps is an open source collaborative initiative available in the
GitHub repository (https://github.com/compbio-bigdata-viz/genome-maps). Genome
Maps is available at: http://www.genomemaps.org.

DOI: 10.1093/nar/gkt530 
PMCID: PMC3692043
PMID: 23748955  [PubMed - indexed for MEDLINE]


1393. Bioinformatics. 2013 Aug 1;29(15):1893-4. doi: 10.1093/bioinformatics/btt312.
Epub 2013 Jun 4.

NGS++: a library for rapid prototyping of epigenomics software tools.

Nordell Markovits A(1), Joly Beauparlant C, Toupin D, Wang S, Droit A, Gevry N.

Author information: 
(1)Department of Biology, Université de Sherbrooke, Sherbrooke, Quebec J1K 2R1,
Canada.

MOTIVATION: The development of computational tools to enable testing and analysis
of high-throughput-sequencing data is essential to modern genomics research.
However, although multiple frameworks have been developed to facilitate access to
these tools, comparatively little effort has been made at implementing low-level 
programming libraries to increase the speed and ease of their development.
RESULTS: We propose NGS++, a programming library in C++11 specialized in
manipulating both next-generation sequencing (NGS) datasets and genomic
information files. This library allows easy integration of new formats and rapid 
prototyping of new functionalities with a focus on the analysis of genomic
regions and features. It offers a powerful, yet versatile and easily extensible
interface to read, write and manipulate multiple genomic file formats. By
standardizing the internal data structures and presenting a common interface to
the data parser, NGS++ offers an effective framework for epigenomics tool
development.
AVAILABILITY: NGS++ was written in C++ using the C++11 standard. It requires
minimal efforts to build and is well-documented via a complete docXygen guide,
online documentation and tutorials. Source code, tests, code examples and
documentation are available via the website at http://www.ngsplusplus.ca and the 
github repository at https://github.com/NGS-lib/NGSplusplus.
CONTACT: nicolas.gevry@usherbrooke.ca or arnaud.droit@crchuq.ulaval.ca.

DOI: 10.1093/bioinformatics/btt312 
PMID: 23736531  [PubMed - indexed for MEDLINE]


1394. Bioinformatics. 2013 Aug 15;29(16):2041-3. doi: 10.1093/bioinformatics/btt314.
Epub 2013 Jun 4.

Isaac: ultra-fast whole-genome secondary analysis on Illumina sequencing
platforms.

Raczy C(1), Petrovski R, Saunders CT, Chorny I, Kruglyak S, Margulies EH, Chuang 
HY, Källberg M, Kumar SA, Liao A, Little KM, Strömberg MP, Tanner SW.

Author information: 
(1)Illumina United Kingdom, Chesterford Research Park, Little Chesterford, Nr
Saffron Walden, Essex, UK. craczy@illumina.com

SUMMARY: An ultrafast DNA sequence aligner (Isaac Genome Alignment Software) that
takes advantage of high-memory hardware (>48 GB) and variant caller (Isaac
Variant Caller) have been developed. We demonstrate that our combined pipeline
(Isaac) is four to five times faster than BWA + GATK on equivalent hardware, with
comparable accuracy as measured by trio conflict rates and sensitivity. We
further show that Isaac is effective in the detection of disease-causing variants
and can easily/economically be run on commodity hardware.
AVAILABILITY: Isaac has an open source license and can be obtained at
https://github.com/sequencing.

DOI: 10.1093/bioinformatics/btt314 
PMID: 23736529  [PubMed - indexed for MEDLINE]


1395. J Biomed Semantics. 2013 Apr 15;4 Suppl 1:S1. doi: 10.1186/2041-1480-4-S1-S1.
Epub 2013 Apr 15.

Ontology-Based Querying with Bio2RDF's Linked Open Data.

Callahan A(1), Cruz-Toledo J, Dumontier M.

Author information: 
(1)Department of Biology, Carleton University, 1125 Colonel By Drive, Ottawa, ON,
Canada. michel_dumontier@carleton.ca.

BACKGROUND: A key activity for life scientists in this post "-omics" age involves
searching for and integrating biological data from a multitude of independent
databases. However, our ability to find relevant data is hampered by non-standard
web and database interfaces backed by an enormous variety of data formats. This
heterogeneity presents an overwhelming barrier to the discovery and reuse of
resources which have been developed at great public expense.To address this
issue, the open-source Bio2RDF project promotes a simple convention to integrate 
diverse biological data using Semantic Web technologies. However, querying
Bio2RDF remains difficult due to the lack of uniformity in the representation of 
Bio2RDF datasets.
RESULTS: We describe an update to Bio2RDF that includes tighter integration
across 19 new and updated RDF datasets. All available open-source scripts were
first consolidated to a single GitHub repository and then redeveloped using a
common API that generates normalized IRIs using a centralized dataset registry.
We then mapped dataset specific types and relations to the Semanticscience
Integrated Ontology (SIO) and demonstrate simplified federated queries across
multiple Bio2RDF endpoints.
CONCLUSIONS: This coordinated release marks an important milestone for the
Bio2RDF open source linked data framework. Principally, it improves the quality
of linked data in the Bio2RDF network and makes it easier to access or recreate
the linked data locally. We hope to continue improving the Bio2RDF network of
linked data by identifying priority databases and increasing the vocabulary
coverage to additional dataset vocabularies beyond SIO.

DOI: 10.1186/2041-1480-4-S1-S1 
PMCID: PMC3632999
PMID: 23735196  [PubMed]


1396. J Biomed Semantics. 2013 Apr 15;4 Suppl 1:S7. doi: 10.1186/2041-1480-4-S1-S7.
Epub 2013 Apr 15.

Representation of probabilistic scientific knowledge.

Soldatova LN(1), Rzhetsky A, De Grave K, King RD.

Author information: 
(1)Department of Information Systems and Computing, Brunel University, London,
UK. larisa.soldatova@brunel.ac.uk.

The theory of probability is widely used in biomedical research for data analysis
and modelling. In previous work the probabilities of the research hypotheses have
been recorded as experimental metadata. The ontology HELO is designed to support 
probabilistic reasoning, and provides semantic descriptors for reporting on
research that involves operations with probabilities. HELO explicitly links
research statements such as hypotheses, models, laws, conclusions, etc. to the
associated probabilities of these statements being true. HELO enables the
explicit semantic representation and accurate recording of probabilities in
hypotheses, as well as the inference methods used to generate and update those
hypotheses. We demonstrate the utility of HELO on three worked examples: changes 
in the probability of the hypothesis that sirtuins regulate human life span;
changes in the probability of hypotheses about gene functions in the S.
cerevisiae aromatic amino acid pathway; and the use of active learning in drug
design (quantitative structure activity relation learning), where a strategy for 
the selection of compounds with the highest probability of improving on the best 
known compound was used. HELO is open source and available at
https://github.com/larisa-soldatova/HELO.

DOI: 10.1186/2041-1480-4-S1-S7 
PMCID: PMC3632998
PMID: 23734675  [PubMed]


1397. BMC Syst Biol. 2013 May 24;7:41. doi: 10.1186/1752-0509-7-41.

Computational modelling of the regulation of Insulin signalling by oxidative
stress.

Smith GR(1), Shanley DP.

Author information: 
(1)Centre for Integrated Systems Biology of Ageing & Nutrition (CISBAN),
Institute for Ageing and Health, Newcastle University, Campus for Ageing and
Vitality, Newcastle upon Tyne NE4 5PL, UK.

BACKGROUND: Existing models of insulin signalling focus on short term dynamics,
rather than the longer term dynamics necessary to understand many physiologically
relevant behaviours. We have developed a model of insulin signalling in rodent
adipocytes that includes both transcriptional feedback through the Forkhead box
type O (FOXO) transcription factor, and interaction with oxidative stress, in
addition to the core pathway. In the model Reactive Oxygen Species are both
generated endogenously and can be applied externally. They regulate signalling
though inhibition of phosphatases and induction of the activity of Stress
Activated Protein Kinases, which themselves modulate feedbacks to insulin
signalling and FOXO.
RESULTS: Insulin and oxidative stress combined produce a lower degree of
activation of insulin signalling than insulin alone. Fasting (nutrient
withdrawal) and weak oxidative stress upregulate antioxidant defences while
stronger oxidative stress leads to a short term activation of insulin signalling 
but if prolonged can have other effects including degradation of the insulin
receptor substrate (IRS1) and FOXO. At high insulin the protective effect of
moderate oxidative stress may disappear.
CONCLUSION: Our model is consistent with a wide range of experimental data, some 
of which is difficult to explain. Oxidative stress can have effects that are both
up- and down-regulatory on insulin signalling. Our model therefore shows the
complexity of the interaction between the two pathways and highlights the need
for such integrated computational models to give insight into the dysregulation
of insulin signalling along with more data at the individual level.A complete
SBML model file can be downloaded from BIOMODELS
(https://www.ebi.ac.uk/biomodels-main) with unique identifier
MODEL1212210000.Other files and scripts are available as additional files with
this journal article and can be downloaded from
https://github.com/graham1034/Smith2012_insulin_signalling.

DOI: 10.1186/1752-0509-7-41 
PMCID: PMC3668293
PMID: 23705851  [PubMed - indexed for MEDLINE]


1398. Silence. 2013 May 20;4(1):2. doi: 10.1186/1758-907X-4-2.

cWords - systematic microRNA regulatory motif discovery from mRNA expression
data.

Rasmussen SH(1), Jacobsen A, Krogh A.

Author information: 
(1)Bioinformatics Centre, Department of Biology, University of Copenhagen, Ole
Maaløes Vej 5, Copenhagen N, 2200, Denmark. krogh@binf.ku.dk.

BACKGROUND: Post-transcriptional regulation of gene expression by small RNAs and 
RNA binding proteins is of fundamental importance in development of complex
organisms, and dysregulation of regulatory RNAs can influence onset, progression 
and potentially be target for treatment of many diseases. Post-transcriptional
regulation by small RNAs is mediated through partial complementary binding to
messenger RNAs leaving nucleotide signatures or motifs throughout the entire
transcriptome. Computational methods for discovery and analysis of sequence
motifs in high-throughput mRNA expression profiling experiments are becoming
increasingly important tools for the identification of post-transcriptional
regulatory motifs and the inference of the regulators and their targets.
RESULTS: cWords is a method designed for regulatory motif discovery in
differential case-control mRNA expression datasets. We have improved the
algorithms and statistical methods of cWords, resulting in at least a factor 100 
speed gain over the previous implementation. On a benchmark dataset of 19
microRNA (miRNA) perturbation experiments cWords showed equal or better
performance than two comparable methods, miReduce and Sylamer. We have developed 
rigorous motif clustering and visualization that accompany the cWords analysis
for more intuitive and effective data interpretation. To demonstrate the
versatility of cWords we show that it can also be used for identification of
potential siRNA off-target binding. Moreover, cWords analysis of an experiment
profiling mRNAs bound by Argonaute ribonucleoprotein particles discovered
endogenous miRNA binding motifs.
CONCLUSIONS: cWords is an unbiased, flexible and easy-to-use tool designed for
regulatory motif discovery in differential case-control mRNA expression datasets.
cWords is based on rigorous statistical methods that demonstrate comparable or
better performance than other existing methods. Rich visualization of results
promotes intuitive and efficient interpretation of data. cWords is available as a
stand-alone Open Source program at Github https://github.com/simras/cWords and as
a web-service at: http://servers.binf.ku.dk/cwords/.

DOI: 10.1186/1758-907X-4-2 
PMCID: PMC3682869
PMID: 23688306  [PubMed]


1399. BMC Bioinformatics. 2013 May 13;14:158. doi: 10.1186/1471-2105-14-158.

Phylotastic! Making tree-of-life knowledge accessible, reusable and convenient.

Stoltzfus A(1), Lapp H, Matasci N, Deus H, Sidlauskas B, Zmasek CM, Vaidya G,
Pontelli E, Cranston K, Vos R, Webb CO, Harmon LJ, Pirrung M, O'Meara B, Pennell 
MW, Mirarab S, Rosenberg MS, Balhoff JP, Bik HM, Heath TA, Midford PE, Brown JW, 
McTavish EJ, Sukumaran J, Westneat M, Alfaro ME, Steele A, Jordan G.

Author information: 
(1)Institute for Bioscience and Biotechnology Research, Biosystems and
Biomaterials Division, National Institute of Standards and Technology,
Gaithersburg, MD 20899, USA. arlin@umd.edu

BACKGROUND: Scientists rarely reuse expert knowledge of phylogeny, in spite of
years of effort to assemble a great "Tree of Life" (ToL). A notable exception
involves the use of Phylomatic, which provides tools to generate custom
phylogenies from a large, pre-computed, expert phylogeny of plant taxa. This
suggests great potential for a more generalized system that, starting with a
query consisting of a list of any known species, would rectify non-standard
names, identify expert phylogenies containing the implicated taxa, prune away
unneeded parts, and supply branch lengths and annotations, resulting in a custom 
phylogeny suited to the user's needs. Such a system could become a sustainable
community resource if implemented as a distributed system of loosely coupled
parts that interact through clearly defined interfaces.
RESULTS: With the aim of building such a "phylotastic" system, the NESCent
Hackathons, Interoperability, Phylogenies (HIP) working group recruited 2 dozen
scientist-programmers to a weeklong programming hackathon in June 2012. During
the hackathon (and a three-month follow-up period), 5 teams produced designs,
implementations, documentation, presentations, and tests including: (1) a
generalized scheme for integrating components; (2) proof-of-concept pruners and
controllers; (3) a meta-API for taxonomic name resolution services; (4) a system 
for storing, finding, and retrieving phylogenies using semantic web technologies 
for data exchange, storage, and querying; (5) an innovative new service,
DateLife.org, which synthesizes pre-computed, time-calibrated phylogenies to
assign ages to nodes; and (6) demonstration projects. These outcomes are
accessible via a public code repository (GitHub.com), a website
(http://www.phylotastic.org), and a server image.
CONCLUSIONS: Approximately 9 person-months of effort (centered on a software
development hackathon) resulted in the design and implementation of
proof-of-concept software for 4 core phylotastic components, 3 controllers, and 3
end-user demonstration tools. While these products have substantial limitations, 
they suggest considerable potential for a distributed system that makes
phylogenetic knowledge readily accessible in computable form. Widespread use of
phylotastic systems will create an electronic marketplace for sharing
phylogenetic knowledge that will spur innovation in other areas of the ToL
enterprise, such as annotation of sources and methods and third-party methods of 
quality assessment.

DOI: 10.1186/1471-2105-14-158 
PMCID: PMC3669619
PMID: 23668630  [PubMed - indexed for MEDLINE]


1400. Bioinformatics. 2014 Jan 1;30(1):24-30. doi: 10.1093/bioinformatics/btt257. Epub 
2013 May 9.

Adaptive reference-free compression of sequence quality scores.

Janin L(1), Rosone G, Cox AJ.

Author information: 
(1)Computational Biology Group, Illumina Cambridge Ltd., Chesterford Research
Park, Little Chesterford, Essex CB10 1XL, UK and Dipartimento di Matematica e
Informatica, University of Palermo, Via Archirafi 34, 90123 Palermo, Italy.

MOTIVATION: Rapid technological progress in DNA sequencing has stimulated
interest in compressing the vast datasets that are now routinely produced.
Relatively little attention has been paid to compressing the quality scores that 
are assigned to each sequence, even though these scores may be harder to compress
than the sequences themselves. By aggregating a set of reads into a compressed
index, we find that the majority of bases can be predicted from the sequence of
bases that are adjacent to them and, hence, are likely to be less informative for
variant calling or other applications. The quality scores for such bases are
aggressively compressed, leaving a relatively small number at full resolution. As
our approach relies directly on redundancy present in the reads, it does not need
a reference sequence and is, therefore, applicable to data from metagenomics and 
de novo experiments as well as to re-sequencing data.
RESULTS: We show that a conservative smoothing strategy affecting 75% of the
quality scores above Q2 leads to an overall quality score compression of 1 bit
per value with a negligible effect on variant calling. A compression of 0.68 bit 
per quality value is achieved using a more aggressive smoothing strategy, again
with a very small effect on variant calling.
AVAILABILITY: Code to construct the BWT and LCP-array on large genomic data sets 
is part of the BEETL library, available as a github repository at
git@github.com:BEETL/BEETL.git.

DOI: 10.1093/bioinformatics/btt257 
PMID: 23661694  [PubMed - indexed for MEDLINE]


1401. Nucleic Acids Res. 2013 Jul;41(13):e129. doi: 10.1093/nar/gkt371. Epub 2013 May
9.

Reconstructing mitochondrial genomes directly from genomic next-generation
sequencing reads--a baiting and iterative mapping approach.

Hahn C(1), Bachmann L, Chevreux B.

Author information: 
(1)Natural History Museum, University of Oslo, Oslo N-0318, Norway.
christoph.hahn@nhm.uio.no

We present an in silico approach for the reconstruction of complete mitochondrial
genomes of non-model organisms directly from next-generation sequencing (NGS)
data-mitochondrial baiting and iterative mapping (MITObim). The method is
straightforward even if only (i) distantly related mitochondrial genomes or (ii) 
mitochondrial barcode sequences are available as starting-reference sequences or 
seeds, respectively. We demonstrate the efficiency of the approach in case
studies using real NGS data sets of the two monogenean ectoparasites species
Gyrodactylus thymalli and Gyrodactylus derjavinoides including their respective
teleost hosts European grayling (Thymallus thymallus) and Rainbow trout
(Oncorhynchus mykiss). MITObim appeared superior to existing tools in terms of
accuracy, runtime and memory requirements and fully automatically recovered
mitochondrial genomes exceeding 99.5% accuracy from total genomic DNA derived NGS
data sets in <24 h using a standard desktop computer. The approach overcomes the 
limitations of traditional strategies for obtaining mitochondrial genomes for
species with little or no mitochondrial sequence information at hand and
represents a fast and highly efficient in silico alternative to laborious
conventional strategies relying on initial long-range PCR. We furthermore
demonstrate the applicability of MITObim for metagenomic/pooled data sets using
simulated data. MITObim is an easy to use tool even for biologists with modest
bioinformatics experience. The software is made available as open source pipeline
under the MIT license at https://github.com/chrishah/MITObim.

DOI: 10.1093/nar/gkt371 
PMCID: PMC3711436
PMID: 23661685  [PubMed - indexed for MEDLINE]


1402. PLoS One. 2013 Apr 22;8(4):e61217. doi: 10.1371/journal.pone.0061217. Print 2013.

phyloseq: an R package for reproducible interactive analysis and graphics of
microbiome census data.

McMurdie PJ(1), Holmes S.

Author information: 
(1)Department of Statistics, Stanford University, Stanford, California, United
States of America.

BACKGROUND: the analysis of microbial communities through dna sequencing brings
many challenges: the integration of different types of data with methods from
ecology, genetics, phylogenetics, multivariate statistics, visualization and
testing. With the increased breadth of experimental designs now being pursued,
project-specific statistical analyses are often needed, and these analyses are
often difficult (or impossible) for peer researchers to independently reproduce. 
The vast majority of the requisite tools for performing these analyses
reproducibly are already implemented in R and its extensions (packages), but with
limited support for high throughput microbiome census data.
RESULTS: Here we describe a software project, phyloseq, dedicated to the
object-oriented representation and analysis of microbiome census data in R. It
supports importing data from a variety of common formats, as well as many
analysis techniques. These include calibration, filtering, subsetting,
agglomeration, multi-table comparisons, diversity analysis, parallelized Fast
UniFrac, ordination methods, and production of publication-quality graphics; all 
in a manner that is easy to document, share, and modify. We show how to apply
functions from other R packages to phyloseq-represented data, illustrating the
availability of a large number of open source analysis techniques. We discuss the
use of phyloseq with tools for reproducible research, a practice common in other 
fields but still rare in the analysis of highly parallel microbiome census data. 
We have made available all of the materials necessary to completely reproduce the
analysis and figures included in this article, an example of best practices for
reproducible research.
CONCLUSIONS: The phyloseq project for R is a new open-source software package,
freely available on the web from both GitHub and Bioconductor.

DOI: 10.1371/journal.pone.0061217 
PMCID: PMC3632530
PMID: 23630581  [PubMed - indexed for MEDLINE]


1403. Bioinformatics. 2013 Jul 1;29(13):1685-6. doi: 10.1093/bioinformatics/btt199.
Epub 2013 Apr 28.

BioBlend: automating pipeline analyses within Galaxy and CloudMan.

Sloggett C(1), Goonasekera N, Afgan E.

Author information: 
(1)Victorian Life Sciences Computation Initiative, University of Melbourne,
Melbourne, Australia.

We present BioBlend, a unified API in a high-level language (python) that wraps
the functionality of Galaxy and CloudMan APIs. BioBlend makes it easy for
bioinformaticians to automate end-to-end large data analysis, from scratch, in a 
way that is highly accessible to collaborators, by allowing them to both provide 
the required infrastructure and automate complex analyses over large datasets
within the familiar Galaxy environment.AVAILABILITY AND IMPLEMENTATION:
http://bioblend.readthedocs.org/. Automated installation of BioBlend is available
via PyPI (e.g. pip install bioblend). Alternatively, the source code is available
from the GitHub repository (https://github.com/afgane/bioblend) under the MIT
open source license. The library has been tested and is working on Linux,
Macintosh and Windows-based systems.

DOI: 10.1093/bioinformatics/btt199 
PMCID: PMC4288140
PMID: 23630176  [PubMed - indexed for MEDLINE]


1404. Bioinformatics. 2013 Jun 15;29(12):1498-503. doi: 10.1093/bioinformatics/btt183. 
Epub 2013 Apr 24.

Shimmer: detection of genetic alterations in tumors using next-generation
sequence data.

Hansen NF(1), Gartner JJ, Mei L, Samuels Y, Mullikin JC.

Author information: 
(1)Genome Technology Branch, NHGRI/NIH, Bethesda, MD 20892-9400, USA.
nhansen@mail.nih.gov

MOTIVATION: Extensive DNA sequencing of tumor and matched normal samples using
exome and whole-genome sequencing technologies has enabled the discovery of
recurrent genetic alterations in cancer cells, but variability in stromal
contamination and subclonal heterogeneity still present a severe challenge to
available detection algorithms.
RESULTS: Here, we describe publicly available software, Shimmer, which accurately
detects somatic single-nucleotide variants using statistical hypothesis testing
with multiple testing correction. This program produces somatic single-nucleotide
variant predictions with significantly higher sensitivity and accuracy than other
available software when run on highly contaminated or heterogeneous samples, and 
it gives comparable sensitivity and accuracy when run on samples of high purity.
AVAILABILITY: http://www.github.com/nhansen/Shimmer

DOI: 10.1093/bioinformatics/btt183 
PMCID: PMC3673219
PMID: 23620360  [PubMed - indexed for MEDLINE]


1405. Bioinformatics. 2013 Jul 1;29(13):1600-6. doi: 10.1093/bioinformatics/btt185.
Epub 2013 Apr 24.

Janus--a comprehensive tool investigating the two faces of transcription.

Barann M(1), Esser D, Klostermeier UC, Lappalainen T, Luzius A, Kuiper JW,
Ammerpohl O, Vater I, Siebert R, Amstislavskiy V, Sudbrak R, Lehrach H, Schreiber
S, Rosenstiel P.

Author information: 
(1)Institute for Clinical Molecular Biology, Christian-Albrechts-University,
24105 Kiel, Germany. m.barann@mucosa.de

MOTIVATION: Protocols to generate strand-specific transcriptomes with
next-generation sequencing platforms have been used by the scientific community
roughly since 2008. Strand-specific reads allow for detection of antisense events
and a higher resolution of expression profiles enabling extension of current
transcript annotations. However, applications making use of this strandedness
information are still scarce.
RESULTS: Here we present a tool (Janus), which focuses on the identification of
transcriptional active regions in antisense orientation to known and novel
transcribed elements of the genome. Janus can compare the antisense events of
multiple samples and assigns scores to identify mutual expression of either
transcript in a sense/antisense pair, which could hint to regulatory mechanisms. 
Janus is able to make use of single-nucleotide variant (SNV) and methylation
data, if available, and reports the sense to antisense ratio of regions in the
vicinity of the identified genetic and epigenetic variation. Janus interrogates
positions of heterozygous SNVs to identify strand-specific allelic imbalance.
AVAILABILITY: Janus is written in C/C++ and freely available at
http://www.ikmb.uni-kiel.de/janus/janus.html under terms of GNU General Public
License, for both, Linux and Windows 64×. Although the binaries will work without
additional downloads, the software depends on bamtools
(https://github.com/pezmaster31/bamtools) for compilation. A detailed tutorial
section is included in the first section of the supplemental material and
included as brief readme.txt in the tutorial archive.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btt185 
PMID: 23620359  [PubMed - indexed for MEDLINE]


1406. Bioinformatics. 2013 Jun 1;29(11):1361-6. doi: 10.1093/bioinformatics/btt172.
Epub 2013 Apr 24.

A support vector machine for identification of single-nucleotide polymorphisms
from next-generation sequencing data.

O'Fallon BD(1), Wooderchak-Donahue W, Crockett DK.

Author information: 
(1)ARUP Institute of Clinical and Experimental Pathology, 500 Chipeta Way, Salt
Lake City, UT 84102, USA. brendan.d.ofallon@aruplab.com

MOTIVATION: Accurate determination of single-nucleotide polymorphisms (SNPs) from
next-generation sequencing data is a significant challenge facing bioinformatics 
researchers. Most current methods use mechanistic models that assume nucleotides 
aligning to a given reference position are sampled from a binomial distribution. 
While such methods are sensitive, they are often unable to discriminate errors
resulting from misaligned reads, sequencing errors or platform artifacts from
true variants.
RESULTS: To enable more accurate SNP calling, we developed an algorithm that uses
a trained support vector machine (SVM) to determine variants from .BAM or .SAM
formatted alignments of sequence reads. Our SVM-based implementation determines
SNPs with significantly greater sensitivity and specificity than alternative
platforms, including the UnifiedGenotyper included with the Genome Analysis
Toolkit, samtools and FreeBayes. In addition, the quality scores produced by our 
implementation more accurately reflect the likelihood that a variant is real when
compared with those produced by the Genome Analysis Toolkit. While results depend
on the model used, the implementation includes tools to easily build new models
and refine existing models with additional training data.
AVAILABILITY: Source code and executables are available from
github.com/brendanofallon/SNPSVM/

DOI: 10.1093/bioinformatics/btt172 
PMID: 23620357  [PubMed - indexed for MEDLINE]


1407. Bioinformatics. 2013 Jul 1;29(13):1682-4. doi: 10.1093/bioinformatics/btt193.
Epub 2013 Apr 23.

mapDamage2.0: fast approximate Bayesian estimates of ancient DNA damage
parameters.

Jónsson H(1), Ginolhac A, Schubert M, Johnson PL, Orlando L.

Author information: 
(1)Centre for GeoGenetics, Natural History Museum of Denmark, University of
Copenhagen, 1350 København K, Denmark. jonsson.hakon@gmail.com

MOTIVATION: Ancient DNA (aDNA) molecules in fossilized bones and teeth,
coprolites, sediments, mummified specimens and museum collections represent
fantastic sources of information for evolutionary biologists, revealing the
agents of past epidemics and the dynamics of past populations. However, the
analysis of aDNA generally faces two major issues. Firstly, sequences consist of 
a mixture of endogenous and various exogenous backgrounds, mostly microbial.
Secondly, high nucleotide misincorporation rates can be observed as a result of
severe post-mortem DNA damage. Such misincorporation patterns are instrumental to
authenticate ancient sequences versus modern contaminants. We recently developed 
the user-friendly mapDamage package that identifies such patterns from
next-generation sequencing (NGS) sequence datasets. The absence of formal
statistical modeling of the DNA damage process, however, precluded rigorous
quantitative comparisons across samples.
RESULTS: Here, we describe mapDamage 2.0 that extends the original features of
mapDamage by incorporating a statistical model of DNA damage. Assuming that
damage events depend only on sequencing position and post-mortem deamination, our
Bayesian statistical framework provides estimates of four key features of aDNA
molecules: the average length of overhangs (λ), nick frequency (ν) and cytosine
deamination rates in both double-stranded regions ( ) and overhangs ( ). Our
model enables rescaling base quality scores according to their probability of
being damaged. mapDamage 2.0 handles NGS datasets with ease and is compatible
with a wide range of DNA library protocols.
AVAILABILITY: mapDamage 2.0 is available at ginolhac.github.io/mapDamage/ as a
Python package and documentation is maintained at the Centre for GeoGenetics Web 
site (geogenetics.ku.dk/publications/mapdamage2.0/).
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btt193 
PMCID: PMC3694634
PMID: 23613487  [PubMed - indexed for MEDLINE]


1408. Bioinformatics. 2013 Jun 15;29(12):1580-2. doi: 10.1093/bioinformatics/btt175.
Epub 2013 Apr 16.

CellH5: a format for data exchange in high-content screening.

Sommer C(1), Held M, Fischer B, Huber W, Gerlich DW.

Author information: 
(1)Institute of Molecular Biotechnology of the Austrian Academy of Sciences, 1030
Vienna, Austria.

High-throughput microscopy data require a diversity of analytical approaches.
However, the construction of workflows that use algorithms from different
software packages is difficult owing to a lack of interoperability. To overcome
this limitation, we present CellH5, an HDF5 data format for cell-based assays in 
high-throughput microscopy, which stores high-dimensional image data along with
inter-object relations in graphs. CellH5Browser, an interactive gallery image
browser, demonstrates the versatility and performance of the file format on live 
imaging data of dividing human cells. CellH5 provides new opportunities for
integrated data analysis by multiple software platforms.AVAILABILITY: Source code
is freely available at www.github.com/cellh5 under the GPL license and at
www.bioconductor.org/packages/release/bioc/html/rhdf5.html under the Artistic-2.0
license. Demo datasets and the CellH5Browser are available at www.cellh5.org. A
Fiji importer for cellh5 will be released soon.

DOI: 10.1093/bioinformatics/btt175 
PMCID: PMC3673213
PMID: 23595665  [PubMed - indexed for MEDLINE]


1409. Gigascience. 2013 Mar 13;2(1):3. doi: 10.1186/2047-217X-2-3.

AXIOME: automated exploration of microbial diversity.

Lynch MDj(1), Masella AP, Hall MW, Bartram AK, Neufeld JD.

Author information: 
(1)Department of Biology, University of Waterloo, 200 University Avenue West,
Waterloo, Ontario, N2L 3G1, Canada. jneufeld@uwaterloo.ca.

BACKGROUND: Although high-throughput sequencing of small subunit rRNA genes has
revolutionized our understanding of microbial ecosystems, these technologies
generate data at depths that benefit from automated analysis. Here we present
AXIOME (Automation, eXtension, and Integration Of Microbial Ecology), a highly
flexible and extensible management tool for popular microbial ecology analysis
packages that promotes reproducibility and customization in microbial research.
FINDINGS: AXIOME streamlines and manages analysis of small subunit (SSU) rRNA
marker data in QIIME and mothur. AXIOME also implements features including the
PAired-eND Assembler for Illumina sequences (PANDAseq), non-negative matrix
factorization (NMF), multi-response permutation procedures (MRPP), exploring and 
recovering phylogenetic novelty (SSUnique) and indicator species analysis. AXIOME
has a companion graphical user interface (GUI) and is designed to be easily
extended to facilitate customized research workflows.
CONCLUSIONS: AXIOME is an actively developed, open source project written in Vala
and available from GitHub (http://neufeld.github.com/axiome) and as a Debian
package. Axiometic, a GUI companion tool is also freely available
(http://neufeld.github.com/axiometic). Given that data analysis has become an
important bottleneck for microbial ecology studies, the development of
user-friendly computational tools remains a high priority. AXIOME represents an
important step in this direction by automating multi-step bioinformatic analyses 
and enabling the customization of procedures to suit the diverse research needs
of the microbial ecology community.

DOI: 10.1186/2047-217X-2-3 
PMCID: PMC3626533
PMID: 23587322  [PubMed]


1410. Gigascience. 2013 Feb 12;2(1):2. doi: 10.1186/2047-217X-2-2.

Crowdsourcing genomic analyses of ash and ash dieback - power to the people.

Maclean D(1), Yoshida K, Edwards A, Crossman L, Clavijo B, Clark M, Swarbreck D, 
Bashton M, Chapman P, Gijzen M, Caccamo M, Downie A, Kamoun S, Saunders DG.

Author information: 
(1)The Sainsbury Laboratory, Norwich Research Park, Norwich NR4 7UH, UK.
dan.maclean@sainsbury-laboratory.ac.uk.

Ash dieback is a devastating fungal disease of ash trees that has swept across
Europe and recently reached the UK. This emergent pathogen has received little
study in the past and its effect threatens to overwhelm the ash population. In
response to this we have produced some initial genomics datasets and taken the
unusual step of releasing them to the scientific community for analysis without
first performing our own. In this manner we hope to 'crowdsource' analyses and
bring the expertise of the community to bear on this problem as quickly as
possible. Our data has been released through our website at oadb.tsl.ac.uk and a 
public GitHub repository.

DOI: 10.1186/2047-217X-2-2 
PMCID: PMC3626535
PMID: 23587306  [PubMed]


1411. Bioinformatics. 2013 Jun 1;29(11):1382-9. doi: 10.1093/bioinformatics/btt148.
Epub 2013 Apr 4.

Detecting regulatory gene-environment interactions with unmeasured environmental 
factors.

Fusi N(1), Lippert C, Borgwardt K, Lawrence ND, Stegle O.

Author information: 
(1)Department of Computer Science, University of Sheffield, Sheffield, UK.
nicolo.fusi@sheffield.ac.uk

MOTIVATION: Genomic studies have revealed a substantial heritable component of
the transcriptional state of the cell. To fully understand the genetic regulation
of gene expression variability, it is important to study the effect of genotype
in the context of external factors such as alternative environmental conditions. 
In model systems, explicit environmental perturbations have been considered for
this purpose, allowing to directly test for environment-specific genetic effects.
However, such experiments are limited to species that can be profiled in
controlled environments, hampering their use in important systems such as human. 
Moreover, even in seemingly tightly regulated experimental conditions, subtle
environmental perturbations cannot be ruled out, and hence unknown environmental 
influences are frequent. Here, we propose a model-based approach to
simultaneously infer unmeasured environmental factors from gene expression
profiles and use them in genetic analyses, identifying environment-specific
associations between polymorphic loci and individual gene expression traits.
RESULTS: In extensive simulation studies, we show that our method is able to
accurately reconstruct environmental factors and their interactions with genotype
in a variety of settings. We further illustrate the use of our model in a
real-world dataset in which one environmental factor has been explicitly
experimentally controlled. Our method is able to accurately reconstruct the true 
underlying environmental factor even if it is not given as an input, allowing to 
detect genuine genotype-environment interactions. In addition to the known
environmental factor, we find unmeasured factors involved in novel
genotype-environment interactions. Our results suggest that interactions with
both known and unknown environmental factors significantly contribute to gene
expression variability.
AVAILABILITY: and implementation: Software available at
http://pmbio.github.io/envGPLVM/.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btt148 
PMID: 23559640  [PubMed - indexed for MEDLINE]


1412. PLoS Comput Biol. 2013;9(3):e1002935. doi: 10.1371/journal.pcbi.1002935. Epub
2013 Mar 14.

Detecting DNA modifications from SMRT sequencing data by modeling sequence
context dependence of polymerase kinetic.

Feng Z(1), Fang G, Korlach J, Clark T, Luong K, Zhang X, Wong W, Schadt E.

Author information: 
(1)Tsinghua National Laboratory for Information Science and Technology, and
Department of Automation, Tsinghua University, Beijing, China.

DNA modifications such as methylation and DNA damage can play critical regulatory
roles in biological systems. Single molecule, real time (SMRT) sequencing
technology generates DNA sequences as well as DNA polymerase kinetic information 
that can be used for the direct detection of DNA modifications. We demonstrate
that local sequence context has a strong impact on DNA polymerase kinetics in the
neighborhood of the incorporation site during the DNA synthesis reaction,
allowing for the possibility of estimating the expected kinetic rate of the
enzyme at the incorporation site using kinetic rate information collected from
existing SMRT sequencing data (historical data) covering the same local sequence 
contexts of interest. We develop an Empirical Bayesian hierarchical model for
incorporating historical data. Our results show that the model could greatly
increase DNA modification detection accuracy, and reduce requirement of control
data coverage. For some DNA modifications that have a strong signal, a control
sample is not even needed by using historical data as alternative to control.
Thus, sequencing costs can be greatly reduced by using the model. We implemented 
the model in a R package named seqPatch, which is available at
https://github.com/zhixingfeng/seqPatch.

DOI: 10.1371/journal.pcbi.1002935 
PMCID: PMC3597545
PMID: 23516341  [PubMed - indexed for MEDLINE]


1413. Hum Mutat. 2013 Jun;34(6):853-9. doi: 10.1002/humu.22317. Epub 2013 Apr 12.

Prioritization of retinal disease genes: an integrative approach.

Wagner AH(1), Taylor KR, DeLuca AP, Casavant TL, Mullins RF, Stone EM, Scheetz
TE, Braun TA.

Author information: 
(1)Department of Biomedical Engineering, University of Iowa, Iowa City, Iowa
52242, USA. alex-wagner@uiowa.edu

The discovery of novel disease-associated variations in genes is often a daunting
task in highly heterogeneous disease classes. We seek a generalizable algorithm
that integrates multiple publicly available genomic data sources in a
machine-learning model for the prioritization of candidates identified in
patients with retinal disease. To approach this problem, we generate a set of
feature vectors from publicly available microarray, RNA-seq, and ChIP-seq
datasets of biological relevance to retinal disease, to observe patterns in gene 
expression specificity among tissues of the body and the eye, in addition to
photoreceptor-specific signals by the CRX transcription factor. Using these
features, we describe a novel algorithm, positive and unlabeled learning for
prioritization (PULP). This article compares several popular supervised learning 
techniques as the regression function for PULP. The results demonstrate a highly 
significant enrichment for previously characterized disease genes using a
logistic regression method. Finally, a comparison of PULP with the popular gene
prioritization tool ENDEAVOUR shows superior prioritization of retinal disease
genes from previous studies. The java source code, compiled binary, assembled
feature vectors, and instructions are available online at
https://github.com/ahwagner/PULP.

© 2013 Wiley Periodicals, Inc.

DOI: 10.1002/humu.22317 
PMCID: PMC4509594
PMID: 23508994  [PubMed - indexed for MEDLINE]


1414. Source Code Biol Med. 2013 Mar 19;8(1):9. doi: 10.1186/1751-0473-8-9.

Inmembrane, a bioinformatic workflow for annotation of bacterial cell-surface
proteomes.

Perry AJ(1), Ho BK.

Author information: 
(1)Department of Biochemistry, Monash University, Melbourne, Australia.
boscoh@gmail.com.

BACKGROUND: The annotation of surface exposed bacterial membrane proteins is an
important step in interpretation and validation of proteomic experiments. In
particular, proteins detected by cell surface protease shaving experiments can
indicate exposed regions of membrane proteins that may contain antigenic
determinants or constitute vaccine targets in pathogenic bacteria.
RESULTS: Inmembrane is a tool to predict the membrane proteins with
surface-exposed regions of polypeptide in sets of bacterial protein sequences. We
have re-implemented a protocol for Gram-positive bacterial proteomes, and
developed a new protocol for Gram-negative bacteria, which interface with
multiple predictors of subcellular localization and membrane protein topology.
Through the use of a modern scripting language, inmembrane provides an accessible
code-base and extensible architecture that is amenable to modification for
related sequence annotation tasks.
CONCLUSIONS: Inmembrane easily integrates predictions from both local binaries
and web-based queries to help gain an overview of likely surface exposed protein 
in a bacterial proteome. The program is hosted on the Github repository
http://github.com/boscoh/inmembrane.

DOI: 10.1186/1751-0473-8-9 
PMCID: PMC3668253
PMID: 23506117  [PubMed]


1415. Bioinformatics. 2013 May 15;29(10):1341-2. doi: 10.1093/bioinformatics/btt128.
Epub 2013 Mar 16.

HAL: a hierarchical format for storing and analyzing multiple genome alignments.

Hickey G(1), Paten B, Earl D, Zerbino D, Haussler D.

Author information: 
(1)Center for Biomolecular Science and Engineering, University of California
Santa Cruz, Santa Cruz CA 95064, USA. hickey@soe.ucsc.edu

MOTIVATION: Large multiple genome alignments and inferred ancestral genomes are
ideal resources for comparative studies of molecular evolution, and advances in
sequencing and computing technology are making them increasingly obtainable.
These structures can provide a rich understanding of the genetic relationships
between all subsets of species they contain. Current formats for storing genomic 
alignments, such as XMFA and MAF, are all indexed or ordered using a single
reference genome, however, which limits the information that can be queried with 
respect to other species and clades. This loss of information grows with the
number of species under comparison, as well as their phylogenetic distance.
RESULTS: We present HAL, a compressed, graph-based hierarchical alignment format 
for storing multiple genome alignments and ancestral reconstructions. HAL graphs 
are indexed on all genomes they contain. Furthermore, they are organized
phylogenetically, which allows for modular and parallel access to arbitrary
subclades without fragmentation because of rearrangements that have occurred in
other lineages. HAL graphs can be created or read with a comprehensive C++ API. A
set of tools is also provided to perform basic operations, such as importing and 
exporting data, identifying mutations and coordinate mapping (liftover).
AVAILABILITY: All documentation and source code for the HAL API and tools are
freely available at http://github.com/glennhickey/hal.
CONTACT: hickey@soe.ucsc.edu or haussler@soe.ucsc.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btt128 
PMCID: PMC3654707
PMID: 23505295  [PubMed - indexed for MEDLINE]


1416. Bioinformatics. 2013 May 1;29(9):1238-9. doi: 10.1093/bioinformatics/btt109. Epub
2013 Mar 16.

Brain: biomedical knowledge manipulation.

Croset S(1), Overington JP, Rebholz-Schuhmann D.

Author information: 
(1)EMBL European Bioinformatics Institute, Wellcome Trust Genome Campus, Hinxton,
Cambridge, CB10 1SD, UK. croset@ebi.ac.uk

SUMMARY: Brain is a Java software library facilitating the manipulation and
creation of ontologies and knowledge bases represented with the Web Ontology
Language (OWL).
AVAILABILITY AND IMPLEMENTATION: The Java source code and the library are freely 
available at https://github.com/loopasam/Brain and on the Maven Central
repository (GroupId: uk.ac.ebi.brain). The documentation is available at
https://github.com/loopasam/Brain/wiki.

DOI: 10.1093/bioinformatics/btt109 
PMCID: PMC3634181
PMID: 23505292  [PubMed - indexed for MEDLINE]


1417. J Chromatogr A. 2013 Apr 19;1286:175-82. doi: 10.1016/j.chroma.2013.02.063. Epub 
2013 Feb 28.

Application of fast Fourier transform cross-correlation and mass spectrometry
data for accurate alignment of chromatograms.

Zheng YB(1), Zhang ZM, Liang YZ, Zhan DJ, Huang JH, Yun YH, Xie HL.

Author information: 
(1)College of Chemistry and Chemical Engineering, Research Center of
Modernization of Chinese Medicines, Central South University, Changsha 410083,
China.

Chromatography has been established as one of the most important analytical
methods in the modern analytical laboratory. However, preprocessing of the
chromatograms, especially peak alignment, is usually a time-consuming task prior 
to extracting useful information from the datasets because of the small
unavoidable differences in the experimental conditions caused by minor changes
and drift. Most of the alignment algorithms are performed on reduced datasets
using only the detected peaks in the chromatograms, which means a loss of data
and introduces the problem of extraction of peak data from the chromatographic
profiles. These disadvantages can be overcome by using the full chromatographic
information that is generated from hyphenated chromatographic instruments. A new 
alignment algorithm called CAMS (Chromatogram Alignment via Mass Spectra) is
present here to correct the retention time shifts among chromatograms accurately 
and rapidly. In this report, peaks of each chromatogram were detected based on
Continuous Wavelet Transform (CWT) with Haar wavelet and were aligned against the
reference chromatogram via the correlation of mass spectra. The aligning
procedure was accelerated by Fast Fourier Transform cross correlation (FFT cross 
correlation). This approach has been compared with several well-known alignment
methods on real chromatographic datasets, which demonstrates that CAMS can
preserve the shape of peaks and achieve a high quality alignment result.
Furthermore, the CAMS method was implemented in the Matlab language and available
as an open source package at http://www.github.com/matchcoder/CAMS.

Copyright © 2013. Published by Elsevier B.V.

DOI: 10.1016/j.chroma.2013.02.063 
PMID: 23489488  [PubMed - indexed for MEDLINE]


1418. Bioinformatics. 2013 May 1;29(9):1210-1. doi: 10.1093/bioinformatics/btt118. Epub
2013 Mar 6.

MitoSeek: extracting mitochondria information and performing high-throughput
mitochondria sequencing analysis.

Guo Y(1), Li J, Li CI, Shyr Y, Samuels DC.

Author information: 
(1)Center for Quantitative Sciences, Vanderbilt University, Nashville, TN 37232, 
USA. yan.guo@vanderbilt.edu

MOTIVATION: Exome capture kits have capture efficiencies that range from 40 to
60%. A significant amount of off-target reads are from the mitochondrial genome. 
These unintentionally sequenced mitochondrial reads provide unique opportunities 
to study the mitochondria genome.
RESULTS: MitoSeek is an open-source software tool that can reliably and easily
extract mitochondrial genome information from exome and whole genome sequencing
data. MitoSeek evaluates mitochondrial genome alignment quality, estimates
relative mitochondrial copy numbers and detects heteroplasmy, somatic mutation
and structural variants of the mitochondrial genome. MitoSeek can be set up to
run in parallel or serial on large exome sequencing datasets.
AVAILABILITY: https://github.com/riverlee/MitoSeek

DOI: 10.1093/bioinformatics/btt118 
PMCID: PMC4492415
PMID: 23471301  [PubMed - indexed for MEDLINE]


1419. Nucleic Acids Res. 2013 Apr;41(7):e89. doi: 10.1093/nar/gkt126. Epub 2013 Mar 6.

An empirical Bayesian framework for somatic mutation detection from cancer genome
sequencing data.

Shiraishi Y(1), Sato Y, Chiba K, Okuno Y, Nagata Y, Yoshida K, Shiba N, Hayashi
Y, Kume H, Homma Y, Sanada M, Ogawa S, Miyano S.

Author information: 
(1)Laboratory of DNA Information Analysis, Human Genome Center, Institute of
Medical Science, The University of Tokyo, 4-6-1, Shirokanedai, Minato-ku, Tokyo
108-8639, Japan. yshira@hgc.jp

Recent advances in high-throughput sequencing technologies have enabled a
comprehensive dissection of the cancer genome clarifying a large number of
somatic mutations in a wide variety of cancer types. A number of methods have
been proposed for mutation calling based on a large amount of sequencing data,
which is accomplished in most cases by statistically evaluating the difference in
the observed allele frequencies of possible single nucleotide variants between
tumours and paired normal samples. However, an accurate detection of mutations
remains a challenge under low sequencing depths or tumour contents. To overcome
this problem, we propose a novel method, Empirical Bayesian mutation Calling
(https://github.com/friend1ws/EBCall), for detecting somatic mutations. Unlike
previous methods, the proposed method discriminates somatic mutations from
sequencing errors based on an empirical Bayesian framework, where the model
parameters are estimated using sequencing data from multiple non-paired normal
samples. Using 13 whole-exome sequencing data with 87.5-206.3 mean sequencing
depths, we demonstrate that our method not only outperforms several existing
methods in the calling of mutations with moderate allele frequencies but also
enables accurate calling of mutations with low allele frequencies (≤ 10%)
harboured within a minor tumour subpopulation, thus allowing for the deciphering 
of fine substructures within a tumour specimen.

DOI: 10.1093/nar/gkt126 
PMCID: PMC3627598
PMID: 23471004  [PubMed - indexed for MEDLINE]


1420. PLoS One. 2013;8(3):e57521. doi: 10.1371/journal.pone.0057521. Epub 2013 Mar 4.

TagGD: fast and accurate software for DNA Tag generation and demultiplexing.

Costea PI(1), Lundeberg J, Akan P.

Author information: 
(1)KTH - Royal Institute of Technology, Science for Life Laboratory, School of
Biotechnology, Solna, Sweden.

Multiplexing is of vital importance for utilizing the full potential of next
generation sequencing technologies. We here report TagGD (DNA-based Tag Generator
and Demultiplexor), a fully-customisable, fast and accurate software package that
can generate thousands of barcodes satisfying user-defined constraints and can
guarantee full demultiplexing accuracy. The barcodes are designed to minimise
their interference with the experiment. Insertion, deletion and substitution
events are considered when designing and demultiplexing barcodes. 20,000 barcodes
of length 18 were designed in 5 minutes and 2 million barcoded Illumina
HiSeq-like reads generated with an error rate of 2% were demultiplexed with full 
accuracy in 5 minutes. We believe that our software meets a central demand in the
current high-throughput biology and can be utilised in any field with ample
sample abundance. The software is available on GitHub
(https://github.com/pelinakan/UBD.git).

DOI: 10.1371/journal.pone.0057521 
PMCID: PMC3587622
PMID: 23469199  [PubMed - indexed for MEDLINE]


1421. PLoS One. 2013;8(2):e54998. doi: 10.1371/journal.pone.0054998. Epub 2013 Feb 20.

Automated authorship attribution using advanced signal classification techniques.

Ebrahimpour M(1), Putniņš TJ, Berryman MJ, Allison A, Ng BW, Abbott D.

Author information: 
(1)School of Electrical and Electronic Engineering, The University of Adelaide,
Adelaide, South Australia, Australia.

In this paper, we develop two automated authorship attribution schemes, one based
on Multiple Discriminant Analysis (MDA) and the other based on a Support Vector
Machine (SVM). The classification features we exploit are based on word
frequencies in the text. We adopt an approach of preprocessing each text by
stripping it of all characters except a-z and space. This is in order to increase
the portability of the software to different types of texts. We test the
methodology on a corpus of undisputed English texts, and use leave-one-out cross 
validation to demonstrate classification accuracies in excess of 90%. We further 
test our methods on the Federalist Papers, which have a partly disputed
authorship and a fair degree of scholarly consensus. And finally, we apply our
methodology to the question of the authorship of the Letter to the Hebrews by
comparing it against a number of original Greek texts of known authorship. These 
tests identify where some of the limitations lie, motivating a number of open
questions for future work. An open source implementation of our methodology is
freely available for use at https://github.com/matthewberryman/author-detection.

DOI: 10.1371/journal.pone.0054998 
PMCID: PMC3577839
PMID: 23437047  [PubMed - indexed for MEDLINE]


1422. Bioinformatics. 2013 Apr 15;29(8):1089-91. doi: 10.1093/bioinformatics/btt085.
Epub 2013 Feb 17.

Nozzle: a report generation toolkit for data analysis pipelines.

Gehlenborg N(1), Noble MS, Getz G, Chin L, Park PJ.

Author information: 
(1)Center for Biomedical Informatics, Harvard Medical School, Boston, MA 02115,
USA.

SUMMARY: We have developed Nozzle, an R package that provides an Application
Programming Interface to generate HTML reports with dynamic user interface
elements. Nozzle was designed to facilitate summarization and rapid browsing of
complex results in data analysis pipelines where multiple analyses are performed 
frequently on big datasets. The package can be applied to any project where
user-friendly reports need to be created.
AVAILABILITY: The R package is available on CRAN at
http://cran.r-project.org/package=Nozzle.R1. Examples and additional materials
are available at http://gdac.broadinstitute.org/nozzle. The source code is also
available at http://www.github.com/parklab/Nozzle.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btt085 
PMCID: PMC3624805
PMID: 23419376  [PubMed - indexed for MEDLINE]


1423. Bioinformatics. 2013 Apr 15;29(8):1076-7. doi: 10.1093/bioinformatics/btt074.
Epub 2013 Feb 14.

Wessim: a whole-exome sequencing simulator based on in silico exome capture.

Kim S(1), Jeong K, Bafna V.

Author information: 
(1)Department of Computer Science and Engineering and Department of Electrical
and Computer Engineering, University of California at San Diego, La Jolla, CA
92093, USA. sak042@cs.ucsd.edu

SUMMARY: We propose a targeted re-sequencing simulator Wessim that generates
synthetic exome sequencing reads from a given sample genome. Wessim emulates
conventional exome capture technologies, including Agilent's SureSelect and
NimbleGen's SeqCap, to generate DNA fragments from genomic target regions. The
target regions can be either specified by genomic coordinates or inferred from in
silico probe hybridization. Coupled with existing next-generation sequencing
simulators, Wessim generates a realistic artificial exome sequencing data, which 
is essential for developing and evaluating exome-targeted variant callers.
AVAILABILITY: Source code and the packaged version of Wessim with manuals are
available at http://sak042.github.com/Wessim/.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btt074 
PMCID: PMC3624799
PMID: 23413434  [PubMed - indexed for MEDLINE]


1424. PLoS One. 2013;8(2):e55484. doi: 10.1371/journal.pone.0055484. Epub 2013 Feb 5.

Maximising the size of non-redundant protein datasets using graph theory.

Bull SC(1), Muldoon MR, Doig AJ.

Author information: 
(1)Manchester Institute of Biotechnology, Faculty of Life Sciences, The
University of Manchester, Manchester, United Kingdom.

Analysis of protein data sets often requires prior removal of redundancy, so that
data is not biased by containing similar proteins. This is usually achieved by
pairwise comparison of sequences, followed by purging so that no two pairs have
similarities above a chosen threshold. From a starting set, such as the PDB or a 
genome, one should remove as few sequences as possible, to give the largest
possible non-redundant set for subsequent analysis. Protein redundancy can be
represented as a graph, with proteins as nodes connected by undirected edges, if 
they have a pairwise similarity above the chosen threshold. The problem is then
equivalent to finding the maximum independent set (MIS), where as few nodes are
removed as possible to remove all edges. We tested seven MIS algorithms, three of
which are new. We applied the methods to the PDB, subsets of the PDB, various
genomes and the BHOLSIB benchmark datasets. For PDB subsets of up to 1000
proteins, we could compare to the exact MIS, found by the Cliquer algorithm. The 
best algorithm was the new method, Leaf. This works by adding clique members that
have no edges to nodes outside the clique to the MIS, starting with the smallest 
cliques. For PDB subsets of up to 1000 members, it usually finds the MIS and is
fast enough to apply to data sets of tens of thousands of proteins. Leaf gives
sets that are around 10% larger than the commonly used PISCES algorithm, that are
of identical quality. We therefore suggest that Leaf should be the method of
choice for generating non-redundant protein data sets, though it is ineffective
on dense graphs, such as the BHOLSIB benchmarks. The Leaf algorithm is available 
at: https://github.com/SimonCB765/Leaf, and sets from genomes and the PDB are
available at: http://www.bioinf.manchester.ac.uk/leaf/.

DOI: 10.1371/journal.pone.0055484 
PMCID: PMC3564766
PMID: 23393584  [PubMed - indexed for MEDLINE]


1425. Bioinformatics. 2013 Apr 1;29(7):950-2. doi: 10.1093/bioinformatics/btt051. Epub 
2013 Jan 30.

MSMExplorer: visualizing Markov state models for biomolecule folding simulations.

Cronkite-Ratcliff B(1), Pande V.

Author information: 
(1)Department of Computer Science, Stanford University, Stanford, CA 94305, USA.

SUMMARY: Markov state models (MSMs) for the study of biomolecule folding
simulations have emerged as a powerful tool for computational study of folding
dynamics. MSMExplorer is a visualization application purpose-built to visualize
these MSMs with an aim to increase the efficacy and reach of MSM science.
AVAILABILITY: MSMExplorer is available for download from
https://simtk.org/home/msmexplorer. The source code is made available under the
GNU Lesser General Public License at https://github.com/SimTk/msmexplorer.

DOI: 10.1093/bioinformatics/btt051 
PMID: 23365411  [PubMed - indexed for MEDLINE]


1426. Front Genet. 2013 Jan 11;3:320. doi: 10.3389/fgene.2012.00320. eCollection 2012.

NSeq: a multithreaded Java application for finding positioned nucleosomes from
sequencing data.

Nellore A(1), Bobkov K, Howe E, Pankov A, Diaz A, Song JS.

Author information: 
(1)Institute for Human Genetics, University of California San Francisco CA, USA ;
The Eli and Edythe Broad Center of Regeneration Medicine and Stem Cell Research, 
University of California San Francisco CA, USA.

We introduce NSeq, a fast and efficient Java application for finding positioned
nucleosomes from the high-throughput sequencing of MNase-digested mononucleosomal
DNA. NSeq includes a user-friendly graphical interface, computes false discovery 
rates (FDRs) for candidate nucleosomes from Monte Carlo simulations, plots
nucleosome coverage and centers, and exploits the availability of multiple
processor cores by parallelizing its computations. Java binaries and source code 
are freely available at https://github.com/songlab/NSeq. The software is
supported on all major platforms equipped with Java Runtime Environment 6 or
later.

DOI: 10.3389/fgene.2012.00320 
PMCID: PMC3542818
PMID: 23335939  [PubMed]


1427. Bioinformatics. 2013 Mar 1;29(5):654-5. doi: 10.1093/bioinformatics/btt025. Epub 
2013 Jan 17.

StatAlign 2.0: combining statistical alignment with RNA secondary structure
prediction.

Arunapuram P(1), Edvardsson I, Golden M, Anderson JW, Novák A, Sükösd Z, Hein J.

Author information: 
(1)Department of Computer Science, University of North Carolina at Chapel Hill,
NC 27599, USA.

MOTIVATION: Comparative modeling of RNA is known to be important for making
accurate secondary structure predictions. RNA structure prediction tools such as 
PPfold or RNAalifold use an aligned set of sequences in predictions. Obtaining a 
multiple alignment from a set of sequences is quite a challenging problem itself,
and the quality of the alignment can affect the quality of a prediction. By
implementing RNA secondary structure prediction in a statistical alignment
framework, and predicting structures from multiple alignment samples instead of a
single fixed alignment, it may be possible to improve predictions.
RESULTS: We have extended the program StatAlign to make use of RNA-specific
features, which include RNA secondary structure prediction from multiple
alignments using either a thermodynamic approach (RNAalifold) or a Stochastic
Context-Free Grammars (SCFGs) approach (PPfold). We also provide the user with
scores relating to the quality of a secondary structure prediction, such as
information entropy values for the combined space of secondary structures and
sampled alignments, and a reliability score that predicts the expected number of 
correctly predicted base pairs. Finally, we have created RNA secondary structure 
visualization plugins and automated the process of setting up Markov Chain Monte 
Carlo runs for RNA alignments in StatAlign.
AVAILABILITY AND IMPLEMENTATION: The software is available from
http://statalign.github.com/statalign/.

DOI: 10.1093/bioinformatics/btt025 
PMID: 23335014  [PubMed - indexed for MEDLINE]


1428. BMC Bioinformatics. 2013 Jan 16;14:16. doi: 10.1186/1471-2105-14-16.

The taxonomic name resolution service: an online tool for automated
standardization of plant names.

Boyle B(1), Hopkins N, Lu Z, Raygoza Garay JA, Mozzherin D, Rees T, Matasci N,
Narro ML, Piel WH, McKay SJ, Lowry S, Freeland C, Peet RK, Enquist BJ.

Author information: 
(1)Department of Ecology and Evolutionary Biology, University of Arizona Tucson, 
P,O, Box 210088, Tucson, AZ 85721, USA. bboyle@email.arizona.edu

BACKGROUND: The digitization of biodiversity data is leading to the widespread
application of taxon names that are superfluous, ambiguous or incorrect,
resulting in mismatched records and inflated species numbers. The ultimate
consequences of misspelled names and bad taxonomy are erroneous scientific
conclusions and faulty policy decisions. The lack of tools for correcting this
'names problem' has become a fundamental obstacle to integrating disparate data
sources and advancing the progress of biodiversity science.
RESULTS: The TNRS, or Taxonomic Name Resolution Service, is an online application
for automated and user-supervised standardization of plant scientific names. The 
TNRS builds upon and extends existing open-source applications for name parsing
and fuzzy matching. Names are standardized against multiple reference taxonomies,
including the Missouri Botanical Garden's Tropicos database. Capable of
processing thousands of names in a single operation, the TNRS parses and corrects
misspelled names and authorities, standardizes variant spellings, and converts
nomenclatural synonyms to accepted names. Family names can be included to
increase match accuracy and resolve many types of homonyms. Partial matching of
higher taxa combined with extraction of annotations, accession numbers and
morphospecies allows the TNRS to standardize taxonomy across a broad range of
active and legacy datasets.
CONCLUSIONS: We show how the TNRS can resolve many forms of taxonomic semantic
heterogeneity, correct spelling errors and eliminate spurious names. As a result,
the TNRS can aid the integration of disparate biological datasets. Although the
TNRS was developed to aid in standardizing plant names, its underlying algorithms
and design can be extended to all organisms and nomenclatural codes. The TNRS is 
accessible via a web interface at http://tnrs.iplantcollaborative.org/ and as a
RESTful web service and application programming interface. Source code is
available at https://github.com/iPlantCollaborativeOpenSource/TNRS/.

DOI: 10.1186/1471-2105-14-16 
PMCID: PMC3554605
PMID: 23324024  [PubMed - indexed for MEDLINE]


1429. Genome Biol. 2013 Jan 15;14(1):R2. doi: 10.1186/gb-2013-14-1-r2.

MetAMOS: a modular and open source metagenomic assembly and analysis pipeline.

Treangen TJ, Koren S, Sommer DD, Liu B, Astrovskaya I, Ondov B, Darling AE,
Phillippy AM, Pop M.

We describe MetAMOS, an open source and modular metagenomic assembly and analysis
pipeline. MetAMOS represents an important step towards fully automated
metagenomic analysis, starting with next-generation sequencing reads and
producing genomic scaffolds, open-reading frames and taxonomic or functional
annotations. MetAMOS can aid in reducing assembly errors, commonly encountered
when assembling metagenomic samples, and improves taxonomic assignment accuracy
while also reducing computational cost. MetAMOS can be downloaded from:
https://github.com/treangen/MetAMOS.

DOI: 10.1186/gb-2013-14-1-r2 
PMCID: PMC4053804
PMID: 23320958  [PubMed - indexed for MEDLINE]


1430. Bioinformatics. 2013 Mar 1;29(5):542-50. doi: 10.1093/bioinformatics/btt004. Epub
2013 Jan 9.

Decombinator: a tool for fast, efficient gene assignment in T-cell receptor
sequences using a finite state machine.

Thomas N(1), Heather J, Ndifon W, Shawe-Taylor J, Chain B.

Author information: 
(1)CoMPLEX Department, UCL, Gower Street, London, WC1E 6BT, UK.

SUMMARY: High-throughput sequencing provides an opportunity to analyse the
repertoire of antigen-specific receptors with an unprecedented breadth and depth.
However, the quantity of raw data produced by this technology requires efficient 
ways to categorize and store the output for subsequent analysis. To this end, we 
have defined a simple five-item identifier that uniquely and unambiguously
defines each TcR sequence. We then describe a novel application of finite-state
automaton to map Illumina short-read sequence data for individual TcRs to their
respective identifier. An extension of the standard algorithm is also described, 
which allows for the presence of single-base pair mismatches arising from
sequencing error. The software package, named Decombinator, is tested first on a 
set of artificial in silico sequences and then on a set of published human TcR-β 
sequences. Decombinator assigned sequences at a rate more than two orders of
magnitude faster than that achieved by classical pairwise alignment algorithms,
and with a high degree of accuracy (>88%), even after introducing up to 1% error 
rates in the in silico sequences. Analysis of the published sequence dataset
highlighted the strong V and J usage bias observed in the human peripheral blood 
repertoire, which seems to be unconnected to antigen exposure. The analysis also 
highlighted the enormous size of the available repertoire and the challenge of
obtaining a comprehensive description for it. The Decombinator package will be a 
valuable tool for further in-depth analysis of the T-cell repertoire.
AVAILABILITY AND IMPLEMENTATION: The Decombinator package is implemented in
Python (v2.6) and is freely available at
https://github.com/uclinfectionimmunity/Decombinator along with full
documentation and examples of typical usage.

DOI: 10.1093/bioinformatics/btt004 
PMID: 23303508  [PubMed - indexed for MEDLINE]


1431. BMC Genomics. 2012;13 Suppl 7:S28. doi: 10.1186/1471-2164-13-S7-S28. Epub 2012
Dec 13.

A de novo next generation genomic sequence assembler based on string graph and
MapReduce cloud computing framework.

Chang YJ(1), Chen CC, Chen CL, Ho JM.

Author information: 
(1)Institute of Information Science, Academia Sinica, Taipei, Taiwan, ROC.

BACKGROUND: State-of-the-art high-throughput sequencers, e.g., the Illumina HiSeq
series, generate sequencing reads that are longer than 150 bp up to a total of
600 Gbp of data per run. The high-throughput sequencers generate lengthier reads 
with greater sequencing depth than those generated by previous technologies. Two 
major challenges exist in using the high-throughput technology for de novo
assembly of genomes. First, the amount of physical memory may be insufficient to 
store the data structure of the assembly algorithm, even for high-end multicore
processors. Moreover, the graph-theoretical model used to capture intersection
relationships of the reads may contain structural defects that are not well
managed by existing assembly algorithms.
RESULTS: We developed a distributed genome assembler based on string graphs and
MapReduce framework, known as the CloudBrush. The assembler includes a novel
edge-adjustment algorithm to detect structural defects by examining the
neighboring reads of a specific read for sequencing errors and adjusting the
edges of the string graph, if necessary. CloudBrush is evaluated against GAGE
benchmarks to compare its assembly quality with the other assemblers. The results
show that our assemblies have a moderate N50, a low misassembly rate of misjoins,
and indels of > 5 bp. In addition, we have introduced two measures, known as
precision and recall, to address the issues of faithfully aligned contigs to
target genomes. Compared with the assembly tools used in the GAGE benchmarks,
CloudBrush is shown to produce contigs with high precision and recall. We also
verified the effectiveness of the edge-adjustment algorithm using simulated
datasets and ran CloudBrush on a nematode dataset using a commercial cloud.
CloudBrush assembler is available at https://github.com/ice91/CloudBrush.

DOI: 10.1186/1471-2164-13-S7-S28 
PMCID: PMC3521391
PMID: 23282094  [PubMed - indexed for MEDLINE]


1432. Version 3. F1000Res. 2013 Nov 13 [revised 2014 Sep 16];2:243. doi:
10.12688/f1000research.2-243.v3. eCollection 2013.

The electrostatic profile of consecutive Cβ atoms applied to protein structure
quality assessment.

Chakraborty S(1), Venkatramani R(2), Rao BJ(1), Asgeirsson B(3), Dandekar AM(4).

Author information: 
(1)Department of Biological Sciences, Tata Institute of Fundamental Research,
Mumbai, 400 005, India. (2)Department of Chemical Sciences, Tata Institute of
Fundamental Research, Mumbai, 400 005, India. (3)Science Institute, Department of
Biochemistry, University of Iceland, IS-107 Reykjavik, Iceland. (4)Plant Sciences
Department, University of California,, Davis, CA, 95616, USA.

The structure of a protein provides insight into its physiological interactions
with other components of the cellular soup. Methods that predict putative
structures from sequences typically yield multiple, closely-ranked possibilities.
A critical component in the process is the model quality assessing program
(MQAP), which selects the best candidate from this pool of structures. Here, we
present a novel MQAP based on the physical properties of sidechain atoms. We
propose a method for assessing the quality of protein structures based on the
electrostatic potential difference (EPD) of Cβ atoms in consecutive residues. We 
demonstrate that the EPDs of Cβ atoms on consecutive residues provide unique
signatures of the amino acid types. The EPD of Cβ atoms are learnt from a set of 
1000 non-homologous protein structures with a resolution cuto of 1.6 Å obtained
from the PISCES database. Based on the Boltzmann hypothesis that lower energy
conformations are proportionately sampled more, and on Annsen's thermodynamic
hypothesis that the native structure of a protein is the minimum free energy
state, we hypothesize that the deviation of observed EPD values from the mean
values obtained in the learning phase is minimized in the native structure. We
achieved an average specificity of 0.91, 0.94 and 0.93 on hg_structal,
4state_reduced and ig_structal decoy sets, respectively, taken from the Decoys
`R' Us database. The source code and manual is made available at
https://github.com/sanchak/mqap and permanently available on 10.5281/zenodo.7134.

DOI: 10.12688/f1000research.2-243.v3 
PMCID: PMC4257144
PMID: 25506420  [PubMed]


1433. Version 2. F1000Res. 2013 Jun 25 [revised 2013 Oct 7];2:143. doi:
10.12688/f1000research.2-143.v2. eCollection 2013.

A fragmented alignment method detects a putative phosphorylation site and a
putative BRC repeat in the Drosophila melanogaster BRCA2 protein.

Chakraborty S(1).

Author information: 
(1)Department of Biological Sciences, Tata Institute of Fundamental Research,
Mumbai, 400 005, India.

Mutations in the BRCA2 tumor suppressor protein leave individuals susceptible to 
breast, ovarian and other cancers. The BRCA2 protein is a critical component of
the DNA repair pathways in eukaryotes, and also plays an integral role in
fostering genomic variability through meiotic recombination. Although present in 
many eukaryotes, as a whole the BRCA2 gene is weakly conserved. Conserved
fragments of 30 amino acids (BRC repeats), which mediate interactions with the
recombinase RAD51, helped detect orthologs of this protein in other organisms.
The carboxy-terminal of the human BRCA2 has been shown to be phosphorylated by
checkpoint kinases (Chk1/Chk2) at T3387, which regulate the sequestration of
RAD51 on DNA damage. However, apart from three BRC repeats, the Drosophila
melanogaster gene has not been annotated and associated with other functionally
relevant sequence fragments in human BRCA2. In the current work, the
carboxy-terminal phosphorylation threonine site (E=9.1e-4) and a new BRC repeat
(E=17e-4) in D. melanogaster has been identified, using a fragmented alignment
methodology (FRAGAL). In a similar study, FRAGAL has also identified a novel
half-a- tetratricopeptide (HAT) motif (E=11e-4), a helical repeat motif
implicated in various aspects of RNA metabolism, in Utp6 from yeast. The
characteristic three aromatic residues with conserved spacing are observed in
this new HAT repeat, further strengthening my claim. The reference and target
sequences are sliced into overlapping fragments of equal parameterized lengths.
All pairs of fragments in the reference and target proteins are aligned, and the 
gap penalties are adjusted to discourage gaps in the middle of the alignment. The
results of the best matches are sorted based on differing criteria to aid the
detection of known and putative sequences. The source code for FRAGAL results on 
these sequences is available at https://github.com/sanchak/FragalCode, while the 
database can be accessed at www.sanchak.com/fragal.html.

DOI: 10.12688/f1000research.2-143.v2 
PMCID: PMC3924952
PMID: 24627786  [PubMed]


1434. PLoS One. 2012;7(12):e51511. doi: 10.1371/journal.pone.0051511. Epub 2012 Dec 14.

MultiMetEval: comparative and multi-objective analysis of genome-scale metabolic 
models.

Zakrzewski P(1), Medema MH, Gevorgyan A, Kierzek AM, Breitling R, Takano E.

Author information: 
(1)Department of Microbial Physiology, University of Groningen, Groningen, The
Netherlands.

Comparative metabolic modelling is emerging as a novel field, supported by the
development of reliable and standardized approaches for constructing genome-scale
metabolic models in high throughput. New software solutions are needed to allow
efficient comparative analysis of multiple models in the context of multiple
cellular objectives. Here, we present the user-friendly software framework
Multi-Metabolic Evaluator (MultiMetEval), built upon SurreyFBA, which allows the 
user to compose collections of metabolic models that together can be subjected to
flux balance analysis. Additionally, MultiMetEval implements functionalities for 
multi-objective analysis by calculating the Pareto front between two cellular
objectives. Using a previously generated dataset of 38 actinobacterial
genome-scale metabolic models, we show how these approaches can lead to exciting 
novel insights. Firstly, after incorporating several pathways for the
biosynthesis of natural products into each of these models, comparative flux
balance analysis predicted that species like Streptomyces that harbour the
highest diversity of secondary metabolite biosynthetic gene clusters in their
genomes do not necessarily have the metabolic network topology most suitable for 
compound overproduction. Secondly, multi-objective analysis of biomass production
and natural product biosynthesis in these actinobacteria shows that the
well-studied occurrence of discrete metabolic switches during the change of
cellular objectives is inherent to their metabolic network architecture.
Comparative and multi-objective modelling can lead to insights that could not be 
obtained by normal flux balance analyses. MultiMetEval provides a powerful
platform that makes these analyses straightforward for biologists. Sources and
binaries of MultiMetEval are freely available from
https://github.com/PiotrZakrzewski/MetEval/downloads.

DOI: 10.1371/journal.pone.0051511 
PMCID: PMC3522732
PMID: 23272111  [PubMed - indexed for MEDLINE]


1435. Bioinformatics. 2013 Feb 15;29(4):525-7. doi: 10.1093/bioinformatics/bts718. Epub
2012 Dec 24.

OntoMaton: a bioportal powered ontology widget for Google Spreadsheets.

Maguire E(1), González-Beltrán A, Whetzel PL, Sansone SA, Rocca-Serra P.

Author information: 
(1)Oxford e-Research Centre, University of Oxford, 7 Keble Road, OX1 3QG, Oxford,
UK. isatools@googlegroups.com

MOTIVATION: Data collection in spreadsheets is ubiquitous, but current solutions 
lack support for collaborative semantic annotation that would promote shared and 
interdisciplinary annotation practices, supporting geographically distributed
players.
RESULTS: OntoMaton is an open source solution that brings ontology lookup and
tagging capabilities into a cloud-based collaborative editing environment,
harnessing Google Spreadsheets and the NCBO Web services. It is a general
purpose, format-agnostic tool that may serve as a component of the ISA software
suite. OntoMaton can also be used to assist the ontology development process.
AVAILABILITY: OntoMaton is freely available from Google widgets under the CPAL
open source license; documentation and examples at:
https://github.com/ISA-tools/OntoMaton.

DOI: 10.1093/bioinformatics/bts718 
PMCID: PMC3570217
PMID: 23267176  [PubMed - indexed for MEDLINE]


1436. Bioinformatics. 2013 Feb 15;29(4):461-7. doi: 10.1093/bioinformatics/bts714. Epub
2012 Dec 24.

Data exploration, quality control and testing in single-cell qPCR-based gene
expression experiments.

McDavid A(1), Finak G, Chattopadyay PK, Dominguez M, Lamoreaux L, Ma SS, Roederer
M, Gottardo R.

Author information: 
(1)Department of Statistics, University of Washington, Seattle, WA 98195, USA.

MOTIVATION: Cell populations are never truly homogeneous; individual cells exist 
in biochemical states that define functional differences between them. New
technology based on microfluidic arrays combined with multiplexed quantitative
polymerase chain reactions now enables high-throughput single-cell gene
expression measurement, allowing assessment of cellular heterogeneity. However,
few analytic tools have been developed specifically for the statistical and
analytical challenges of single-cell quantitative polymerase chain reactions
data.
RESULTS: We present a statistical framework for the exploration, quality control 
and analysis of single-cell gene expression data from microfluidic arrays. We
assess accuracy and within-sample heterogeneity of single-cell expression and
develop quality control criteria to filter unreliable cell measurements. We
propose a statistical model accounting for the fact that genes at the single-cell
level can be on (and a continuous expression measure is recorded) or
dichotomously off (and the recorded expression is zero). Based on this model, we 
derive a combined likelihood ratio test for differential expression that
incorporates both the discrete and continuous components. Using an experiment
that examines treatment-specific changes in expression, we show that this
combined test is more powerful than either the continuous or dichotomous
component in isolation, or a t-test on the zero-inflated data. Although developed
for measurements from a specific platform (Fluidigm), these tools are
generalizable to other multi-parametric measures over large numbers of events.
AVAILABILITY: All results presented here were obtained using the SingleCellAssay 
R package available on GitHub (http://github.com/RGLab/SingleCellAssay).

DOI: 10.1093/bioinformatics/bts714 
PMCID: PMC3570210
PMID: 23267174  [PubMed - indexed for MEDLINE]


1437. Bioinformatics. 2013 Feb 15;29(4):413-9. doi: 10.1093/bioinformatics/bts704. Epub
2012 Dec 13.

SwiftLink: parallel MCMC linkage analysis using multicore CPU and GPU.

Medlar A(1), Głowacka D, Stanescu H, Bryson K, Kleta R.

Author information: 
(1)Division of Medicine, University College London, London WC1E 6BT, UK,
Institute of Biotechnology, University of Helsinki, Helsinki 00014, Finland.
alan.j.medlar@helsinki.fi

MOTIVATION: Linkage analysis remains an important tool in elucidating the genetic
component of disease and has become even more important with the advent of whole 
exome sequencing, enabling the user to focus on only those genomic regions
co-segregating with Mendelian traits. Unfortunately, methods to perform
multipoint linkage analysis scale poorly with either the number of markers or
with the size of the pedigree. Large pedigrees with many markers can only be
evaluated with Markov chain Monte Carlo (MCMC) methods that are slow to converge 
and, as no attempts have been made to exploit parallelism, massively underuse
available processing power. Here, we describe SWIFTLINK, a novel application that
performs MCMC linkage analysis by spreading the computational burden between
multiple processor cores and a graphics processing unit (GPU) simultaneously.
SWIFTLINK was designed around the concept of explicitly matching the
characteristics of an algorithm with the underlying computer architecture to
maximize performance.
RESULTS: We implement our approach using existing Gibbs samplers redesigned for
parallel hardware. We applied SWIFTLINK to a real-world dataset, performing
parametric multipoint linkage analysis on a highly consanguineous pedigree with
EAST syndrome, containing 28 members, where a subset of individuals were
genotyped with single nucleotide polymorphisms (SNPs). In our experiments with a 
four core CPU and GPU, SWIFTLINK achieves a 8.5× speed-up over the
single-threaded version and a 109× speed-up over the popular linkage analysis
program SIMWALK.
AVAILABILITY: SWIFTLINK is available at https://github.com/ajm/swiftlink. All
source code is licensed under GPLv3.

DOI: 10.1093/bioinformatics/bts704 
PMID: 23239673  [PubMed - indexed for MEDLINE]


1438. PLoS Comput Biol. 2012;8(12):e1002780. doi: 10.1371/journal.pcbi.1002780. Epub
2012 Dec 6.

ACME: automated cell morphology extractor for comprehensive reconstruction of
cell membranes.

Mosaliganti KR(1), Noche RR, Xiong F, Swinburne IA, Megason SG.

Author information: 
(1)Department of Systems Biology, Harvard Medical School, Boston, Massachusetts, 
United States of America.

The quantification of cell shape, cell migration, and cell rearrangements is
important for addressing classical questions in developmental biology such as
patterning and tissue morphogenesis. Time-lapse microscopic imaging of transgenic
embryos expressing fluorescent reporters is the method of choice for tracking
morphogenetic changes and establishing cell lineages and fate maps in vivo.
However, the manual steps involved in curating thousands of putative cell
segmentations have been a major bottleneck in the application of these
technologies especially for cell membranes. Segmentation of cell membranes while 
more difficult than nuclear segmentation is necessary for quantifying the
relations between changes in cell morphology and morphogenesis. We present a
novel and fully automated method to first reconstruct membrane signals and then
segment out cells from 3D membrane images even in dense tissues. The approach has
three stages: 1) detection of local membrane planes, 2) voting to fill structural
gaps, and 3) region segmentation. We demonstrate the superior performance of the 
algorithms quantitatively on time-lapse confocal and two-photon images of
zebrafish neuroectoderm and paraxial mesoderm by comparing its results with those
derived from human inspection. We also compared with synthetic microscopic images
generated by simulating the process of imaging with fluorescent reporters under
varying conditions of noise. Both the over-segmentation and under-segmentation
percentages of our method are around 5%. The volume overlap of individual cells, 
compared to expert manual segmentation, is consistently over 84%. By using our
software (ACME) to study somite formation, we were able to segment touching cells
with high accuracy and reliably quantify changes in morphogenetic parameters such
as cell shape and size, and the arrangement of epithelial and mesenchymal cells. 
Our software has been developed and tested on Windows, Mac, and Linux platforms
and is available publicly under an open source BSD license
(https://github.com/krm15/ACME).

DOI: 10.1371/journal.pcbi.1002780 
PMCID: PMC3516542
PMID: 23236265  [PubMed - indexed for MEDLINE]


1439. Bioinformatics. 2013 Feb 1;29(3):389-90. doi: 10.1093/bioinformatics/bts697. Epub
2012 Dec 10.

RetroSeq: transposable element discovery from next-generation sequencing data.

Keane TM(1), Wong K, Adams DJ.

Author information: 
(1)Wellcome Trust Sanger Institute, Wellcome Trust Genome Campus, Hinxton, UK.
tk2@sanger.ac.uk

A significant proportion of eukaryote genomes consist of transposable element
(TE)-derived sequence. These elements are known to have the capacity to modulate 
gene function and genome evolution. We have developed RetroSeq for detecting
non-reference TE insertions from Illumina paired-end whole-genome sequencing
data. We evaluate RetroSeq on a human trio from the 1000 Genomes Project, showing
that it produces highly accurate TE calls.AVAILABILTY: RetroSeq is open-source
and available from https://github.com/tk2/RetroSeq.

DOI: 10.1093/bioinformatics/bts697 
PMCID: PMC3562067
PMID: 23233656  [PubMed - indexed for MEDLINE]


1440. Bioinformatics. 2013 Feb 1;29(3):384-6. doi: 10.1093/bioinformatics/bts695. Epub 
2012 Dec 6.

ChromoZoom: a flexible, fluid, web-based genome browser.

Pak TR(1), Roth FP.

Author information: 
(1)Donnelly Centre, University of Toronto, Toronto, ON M5S3E1, Canada.

Current web-based genome browsers require repetitious user input to scroll over
long distances, alter the drawing density of elements or zoom through multiple
orders of magnitude. Generally, either the server or the client is responsible
for the majority of data processing, resulting in either servers having to
receive and handle data relevant only to one user, or clients redundantly
processing widely viewed data. ChromoZoom pre-renders and caches general-use
tracks into tiled images on the server and serves them in an interactive web
interface with inertial scrolling and precise, fluent zooming via the mouse wheel
or trackpad. Custom tracks in several formats can be rendered by client-side code
alongside the pre-rendered tracks, minimizing server load because of
user-specific rendering and eliminating the need to transmit private data.
ChromoZoom thereby enables rapid and simultaneous exploration of curated,
experimental and personal genomic datasets.AVAILABILITY: Human and yeast genome
researchers may browse recent assemblies within ChromoZoom at
http://chromozoom.org/. Source code is available at
http://github.com/rothlab/chromozoom/.

DOI: 10.1093/bioinformatics/bts695 
PMCID: PMC3562068
PMID: 23220575  [PubMed - indexed for MEDLINE]


1441. Bioinformatics. 2013 Feb 1;29(3):387-8. doi: 10.1093/bioinformatics/bts696. Epub 
2012 Dec 6.

Nestly--a framework for running software with nested parameter choices and
aggregating results.

McCoy CO(1), Gallagher A, Hoffman NG, Matsen FA.

Author information: 
(1)Program in Computational Biology, Fred Hutchinson Cancer Research Center,
Seattle, WA 98109, USA. cmccoy@fhcrc.org

The execution of a software application or pipeline using various combinations of
parameters and inputs is a common task in bioinformatics. In the absence of a
specialized tool to organize, streamline and formalize this process, scientists
must write frequently complex scripts to perform these tasks. We present nestly, 
a Python package to facilitate running tools with nested combinations of
parameters and inputs. nestly provides three components. First, a module to build
nested directory structures corresponding to choices of parameters. Second, the
nestrun script to run a given command using each set of parameter choices. Third,
the nestagg script to aggregate results of the individual runs into a CSV file,
as well as support for more complex aggregation. We also include a module for
easily specifying nested dependencies for the SCons build tool, enabling
incremental builds.AVAILABILITY: Source, documentation and tutorial examples are 
available at http://github.com/fhcrc/nestly. nestly can be installed from the
Python Package Index via pip; it is open source (MIT license).

DOI: 10.1093/bioinformatics/bts696 
PMCID: PMC3562064
PMID: 23220574  [PubMed - indexed for MEDLINE]


1442. Bioinformatics. 2013 Jan 1;29(1):135-6. doi: 10.1093/bioinformatics/bts647. Epub 
2012 Nov 29.

BlueSNP: R package for highly scalable genome-wide association studies using
Hadoop clusters.

Huang H(1), Tata S, Prill RJ.

Author information: 
(1)Healthcare Informatics, IBM Almaden Research Center, San Jose, CA 95120, USA.

SUMMARY: Computational workloads for genome-wide association studies (GWAS) are
growing in scale and complexity outpacing the capabilities of single-threaded
software designed for personal computers. The BlueSNP R package implements GWAS
statistical tests in the R programming language and executes the calculations
across computer clusters configured with Apache Hadoop, a de facto standard
framework for distributed data processing using the MapReduce formalism. BlueSNP 
makes computationally intensive analyses, such as estimating empirical p-values
via data permutation, and searching for expression quantitative trait loci over
thousands of genes, feasible for large genotype-phenotype datasets.
AVAILABILITY AND IMPLEMENTATION: http://github.com/ibm-bioinformatics/bluesnp

DOI: 10.1093/bioinformatics/bts647 
PMID: 23202745  [PubMed - indexed for MEDLINE]


1443. Nucleic Acids Res. 2013 Jan;41(Database issue):D1009-13. doi:
10.1093/nar/gks1161. Epub 2012 Nov 24.

CircaDB: a database of mammalian circadian gene expression profiles.

Pizarro A(1), Hayer K, Lahens NF, Hogenesch JB.

Author information: 
(1)The Institute for Translational Medicine and Therapeutics, University of
Pennsylvania, 3400 Civic Center Boulevard, Building 421, Philadelphia, PA 19104, 
USA. angel@upenn.edu

CircaDB (http://circadb.org) is a new database of circadian transcriptional
profiles from time course expression experiments from mice and humans. Each
transcript's expression was evaluated by three separate algorithms, JTK_Cycle,
Lomb Scargle and DeLichtenberg. Users can query the gene annotations using simple
and powerful full text search terms, restrict results to specific data sets and
provide probability thresholds for each algorithm. Visualizations of the data are
intuitive charts that convey profile information more effectively than a table of
probabilities. The CircaDB web application is open source and available at
http://github.com/itmat/circadb.

DOI: 10.1093/nar/gks1161 
PMCID: PMC3531170
PMID: 23180795  [PubMed - indexed for MEDLINE]


1444. Bioinformatics. 2013 Jan 15;29(2):286-9. doi: 10.1093/bioinformatics/bts681. Epub
2012 Nov 23.

Bioclipse-R: integrating management and visualization of life science data with
statistical analysis.

Spjuth O(1), Georgiev V, Carlsson L, Alvarsson J, Berg A, Willighagen E, Wikberg 
JE, Eklund M.

Author information: 
(1)Department of Pharmaceutical Biosciences, Uppsala University, SE-751 24
Uppsala, Sweden.

SUMMARY: Bioclipse, a graphical workbench for the life sciences, provides
functionality for managing and visualizing life science data. We introduce
Bioclipse-R, which integrates Bioclipse and the statistical programming language 
R. The synergy between Bioclipse and R is demonstrated by the construction of a
decision support system for anticancer drug screening and mutagenicity
prediction, which shows how Bioclipse-R can be used to perform complex tasks from
within a single software system.
AVAILABILITY AND IMPLEMENTATION: Bioclipse-R is implemented as a set of Java
plug-ins for Bioclipse based on the R-package rj. Source code and binary packages
are available from https://github.com/bioclipse and
http://www.bioclipse.net/bioclipse-r, respectively.
CONTACT: martin.eklund@farmbio.uu.se
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/bts681 
PMCID: PMC3546796
PMID: 23178637  [PubMed - indexed for MEDLINE]


1445. Bioinformatics. 2013 Feb 1;29(3):381-3. doi: 10.1093/bioinformatics/bts677. Epub 
2012 Nov 19.

Scribl: an HTML5 Canvas-based graphics library for visualizing genomic data over 
the web.

Miller CA(1), Anthony J, Meyer MM, Marth G.

Author information: 
(1)Department of Biology, Boston College, Chestnut Hill, MA 02467, USA.

MOTIVATION: High-throughput biological research requires simultaneous
visualization as well as analysis of genomic data, e.g. read alignments, variant 
calls and genomic annotations. Traditionally, such integrative analysis required 
desktop applications operating on locally stored data. Many current terabyte-size
datasets generated by large public consortia projects, however, are already only 
feasibly stored at specialist genome analysis centers. As even small laboratories
can afford very large datasets, local storage and analysis are becoming
increasingly limiting, and it is likely that most such datasets will soon be
stored remotely, e.g. in the cloud. These developments will require web-based
tools that enable users to access, analyze and view vast remotely stored data
with a level of sophistication and interactivity that approximates desktop
applications. As rapidly dropping cost enables researchers to collect data
intended to answer questions in very specialized contexts, developers must also
provide software libraries that empower users to implement customized data
analyses and data views for their particular application. Such specialized, yet
lightweight, applications would empower scientists to better answer specific
biological questions than possible with general-purpose genome browsers currently
available.
RESULTS: Using recent advances in core web technologies (HTML5), we developed
Scribl, a flexible genomic visualization library specifically targeting
coordinate-based data such as genomic features, DNA sequence and genetic
variants. Scribl simplifies the development of sophisticated web-based graphical 
tools that approach the dynamism and interactivity of desktop applications.
AVAILABILITY AND IMPLEMENTATION: Software is freely available online at
http://chmille4.github.com/Scribl/ and is implemented in JavaScript with all
modern browsers supported.

DOI: 10.1093/bioinformatics/bts677 
PMCID: PMC3562066
PMID: 23172864  [PubMed - indexed for MEDLINE]


1446. Bioinformatics. 2013 Jan 15;29(2):273-4. doi: 10.1093/bioinformatics/bts678. Epub
2012 Nov 21.

Intron-centric estimation of alternative splicing from RNA-seq data.

Pervouchine DD(1), Knowles DG, Guigó R.

Author information: 
(1)Centre de Regulació Genòmica, 08003 Barcelona, Spain. dp@crg.eu

MOTIVATION: Novel technologies brought in unprecedented amounts of
high-throughput sequencing data along with great challenges in their analysis and
interpretation. The percent-spliced-in (PSI, ) metric estimates the incidence of 
single-exon-skipping events and can be computed directly by counting reads that
align to known or predicted splice junctions. However, the majority of human
splicing events are more complex than single-exon skipping.
RESULTS: In this short report, we present a framework that generalizes the metric
to arbitrary classes of splicing events. We change the view from exon centric to 
intron centric and split the value of into two indices, and , measuring the rate 
of splicing at the 5' and 3' end of the intron, respectively. The advantage of
having two separate indices is that they deconvolute two distinct elementary acts
of the splicing reaction. The completeness of splicing index is decomposed in a
similar way. This framework is implemented as bam2ssj, a BAM-file-processing
pipeline for strand-specific counting of reads that align to splice junctions or 
overlap with splice sites. It can be used as a consistent protocol for
quantifying splice junctions from RNA-seq data because no such standard procedure
currently exists.
AVAILABILITY: The C code of bam2ssj is open source and is available at
https://github.com/pervouchine/bam2ssj
CONTACT: dp@crg.eu

DOI: 10.1093/bioinformatics/bts678 
PMCID: PMC3546801
PMID: 23172860  [PubMed - indexed for MEDLINE]


1447. Bioinformatics. 2013 Jan 15;29(2):277-8. doi: 10.1093/bioinformatics/bts663. Epub
2012 Nov 17.

Largenet2: an object-oriented programming library for simulating large adaptive
networks.

Zschaler G(1), Gross T.

Author information: 
(1)Max-Planck-Institut für Physik komplexer Systeme, 01187 Dresden, Germany.
gerd@biond.org

SUMMARY: The largenet2 C++ library provides an infrastructure for the simulation 
of large dynamic and adaptive networks with discrete node and link states.
AVAILABILITY: The library is released as free software. It is available at
http://biond.github.com/largenet2. Largenet2 is licensed under the Creative
Commons Attribution-NonCommercial 3.0 Unported License.
CONTACT: gerd@biond.org

DOI: 10.1093/bioinformatics/bts663 
PMID: 23162057  [PubMed - indexed for MEDLINE]


1448. Bioinformatics. 2013 Jan 1;29(1):1-7. doi: 10.1093/bioinformatics/bts652. Epub
2012 Nov 4.

Binary Interval Search: a scalable algorithm for counting interval intersections.

Layer RM(1), Skadron K, Robins G, Hall IM, Quinlan AR.

Author information: 
(1)Department of Computer Science, University of Virginia, Charlottesville, VA
22904, USA.

MOTIVATION: The comparison of diverse genomic datasets is fundamental to
understand genome biology. Researchers must explore many large datasets of genome
intervals (e.g. genes, sequence alignments) to place their experimental results
in a broader context and to make new discoveries. Relationships between genomic
datasets are typically measured by identifying intervals that intersect, that is,
they overlap and thus share a common genome interval. Given the continued
advances in DNA sequencing technologies, efficient methods for measuring
statistically significant relationships between many sets of genomic features are
crucial for future discovery.
RESULTS: We introduce the Binary Interval Search (BITS) algorithm, a novel and
scalable approach to interval set intersection. We demonstrate that BITS
outperforms existing methods at counting interval intersections. Moreover, we
show that BITS is intrinsically suited to parallel computing architectures, such 
as graphics processing units by illustrating its utility for efficient Monte
Carlo simulations measuring the significance of relationships between sets of
genomic intervals.
AVAILABILITY: https://github.com/arq5x/bits.

DOI: 10.1093/bioinformatics/bts652 
PMCID: PMC3530906
PMID: 23129298  [PubMed - indexed for MEDLINE]


1449. Nucleic Acids Res. 2013 Jan 7;41(1):e32. doi: 10.1093/nar/gks981. Epub 2012 Oct
22.

Accurate human microsatellite genotypes from high-throughput resequencing data
using informed error profiles.

Highnam G(1), Franck C, Martin A, Stephens C, Puthige A, Mittelman D.

Author information: 
(1)Virginia Bioinformatics Institute, Virginia Tech, Blacksburg, VA 24061, USA.

Repetitive sequences are biologically and clinically important because they can
influence traits and disease, but repeats are challenging to analyse using
short-read sequencing technology. We present a tool for genotyping microsatellite
repeats called RepeatSeq, which uses Bayesian model selection guided by an
empirically derived error model that incorporates sequence and read properties.
Next, we apply RepeatSeq to high-coverage genomes from the 1000 Genomes Project
to evaluate performance and accuracy. The software uses common formats, such as
VCF, for compatibility with existing genome analysis pipelines. Source code and
binaries are available at http://github.com/adaptivegenome/repeatseq.

DOI: 10.1093/nar/gks981 
PMCID: PMC3592458
PMID: 23090981  [PubMed - indexed for MEDLINE]


1450. PLoS One. 2012;7(10):e46847. doi: 10.1371/journal.pone.0046847. Epub 2012 Oct 10.

lociNGS: a lightweight alternative for assessing suitability of next-generation
loci for evolutionary analysis.

Hird SM(1).

Author information: 
(1)Department of Biological Sciences, Louisiana State University, Baton Rouge,
LA, USA. shird1@tigers.lsu.edu

Genomic enrichment methods and next-generation sequencing produce uneven coverage
for the portions of the genome (the loci) they target; this information is
essential for ascertaining the suitability of each locus for further analysis.
lociNGS is a user-friendly accessory program that takes multi-FASTA formatted
loci, next-generation sequence alignments and demographic data as input and
collates, displays and outputs information about the data. Summary information
includes the parameters coverage per locus, coverage per individual and number of
polymorphic sites, among others. The program can output the raw sequences used to
call loci from next-generation sequencing data. lociNGS also reformats subsets of
loci in three commonly used formats for multi-locus phylogeographic and
population genetics analyses - NEXUS, IMa2 and Migrate. lociNGS is available at
https://github.com/SHird/lociNGS and is dependent on installation of MongoDB
(freely available at http://www.mongodb.org/downloads). lociNGS is written in
Python and is supported on MacOSX and Unix; it is distributed under a GNU General
Public License.

DOI: 10.1371/journal.pone.0046847 
PMCID: PMC3468592
PMID: 23071651  [PubMed - indexed for MEDLINE]


1451. Genome Biol. 2012 Oct 15;13(10):R98. doi: 10.1186/gb-2012-13-10-r98.

CHANCE: comprehensive software for quality control and validation of ChIP-seq
data.

Diaz A, Nellore A, Song JS.

ChIP-seq is a powerful method for obtaining genome-wide maps of protein-DNA
interactions and epigenetic modifications. CHANCE (CHip-seq ANalytics and
Confidence Estimation) is a standalone package for ChIP-seq quality control and
protocol optimization. Our user-friendly graphical software quickly estimates the
strength and quality of immunoprecipitations, identifies biases, compares the
user's data with ENCODE's large collection of published datasets, performs
multi-sample normalization, checks against quantitative PCR-validated control
regions, and produces informative graphical reports. CHANCE is available at
https://github.com/songlab/chance.

DOI: 10.1186/gb-2012-13-10-r98 
PMCID: PMC4053734
PMID: 23068444  [PubMed - indexed for MEDLINE]


1452. Bioinformatics. 2012 Dec 1;28(23):3137-8. doi: 10.1093/bioinformatics/bts572.
Epub 2012 Sep 27.

FeatureStack: Perl module for comparative visualization of gene features.

Frech C(1), Choo C, Chen N.

Author information: 
(1)Department of Molecular Biology and Biochemistry, Simon Fraser University,
Burnaby, British Columbia, Canada V5A 1S6.

SUMMARY: FeatureStack is a Perl module for the automatic generation of multi-gene
images. FeatureStack takes BioPerl-compliant gene or transcript features as input
and renders them side by side using a user-defined BioPerl glyph. Output images
can be generated in SVG or PNG format. FeatureStack comes with a new BioPerl
glyph, decorated_gene, which can highlight protein features on top of gene
models. Used in combination, FeatureStack and decorated_gene enable rapid and
automated generation of annotation-rich images of stacked gene models that
greatly facilitate evolutionary studies of related gene structures and gene
families.
AVAILABILITY AND IMPLEMENTATION: Bio-Draw-FeatureStack and
Bio-Graphics-glyph-decorated_gene are freely available at the Comprehensive Perl 
Archive Network (CPAN) and GitHub.
CONTACT: chenn@sfu.ca
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/bts572 
PMID: 23023981  [PubMed - indexed for MEDLINE]


1453. BMC Bioinformatics. 2012 Sep 21;13:240. doi: 10.1186/1471-2105-13-240.

The Ruby UCSC API: accessing the UCSC genome database using Ruby.

Mishima H(1), Aerts J, Katayama T, Bonnal RJ, Yoshiura K.

Author information: 
(1)Department of Human Genetics, Nagasaki University Graduate School of
Biomedical Sciences, 1-12-4 Sakamoto, Nagasaki, Nagasaki, 852-8523, Japan.
hmishima@nagasaki-u.ac.jp

BACKGROUND: The University of California, Santa Cruz (UCSC) genome database is
among the most used sources of genomic annotation in human and other organisms.
The database offers an excellent web-based graphical user interface (the UCSC
genome browser) and several means for programmatic queries. A simple application 
programming interface (API) in a scripting language aimed at the biologist was
however not yet available. Here, we present the Ruby UCSC API, a library to
access the UCSC genome database using Ruby.
RESULTS: The API is designed as a BioRuby plug-in and built on the ActiveRecord 3
framework for the object-relational mapping, making writing SQL statements
unnecessary. The current version of the API supports databases of all organisms
in the UCSC genome database including human, mammals, vertebrates, deuterostomes,
insects, nematodes, and yeast.The API uses the bin index-if available-when
querying for genomic intervals. The API also supports genomic sequence queries
using locally downloaded *.2bit files that are not stored in the official MySQL
database. The API is implemented in pure Ruby and is therefore available in
different environments and with different Ruby interpreters (including JRuby).
CONCLUSIONS: Assisted by the straightforward object-oriented design of Ruby and
ActiveRecord, the Ruby UCSC API will facilitate biologists to query the UCSC
genome database programmatically. The API is available through the RubyGem
system. Source code and documentation are available at
https://github.com/misshie/bioruby-ucsc-api/ under the Ruby license. Feedback and
help is provided via the website at http://rubyucscapi.userecho.com/.

DOI: 10.1186/1471-2105-13-240 
PMCID: PMC3542311
PMID: 22994508  [PubMed - indexed for MEDLINE]


1454. Bioinformatics. 2012 Sep 15;28(18):i640-i646. doi: 10.1093/bioinformatics/bts402.

PARADIGM-SHIFT predicts the function of mutations in multiple cancers using
pathway impact analysis.

Ng S(1), Collisson EA, Sokolov A, Goldstein T, Gonzalez-Perez A, Lopez-Bigas N,
Benz C, Haussler D, Stuart JM.

Author information: 
(1)Department of Biomolecular Engineering and CBSE, University of California
Santa Cruz, Santa Cruz, CA 95064, USA.

MOTIVATION: A current challenge in understanding cancer processes is to pinpoint 
which mutations influence the onset and progression of disease. Toward this goal,
we describe a method called PARADIGM-SHIFT that can predict whether a mutational 
event is neutral, gain-or loss-of-function in a tumor sample. The method uses a
belief-propagation algorithm to infer gene activity from gene expression and copy
number data in the context of a set of pathway interactions.
RESULTS: The method was found to be both sensitive and specific on a set of
positive and negative controls for multiple cancers for which pathway information
was available. Application to the Cancer Genome Atlas glioblastoma, ovarian and
lung squamous cancer datasets revealed several novel mutations with predicted
high impact including several genes mutated at low frequency suggesting the
approach will be complementary to current approaches that rely on the prevalence 
of events to reach statistical significance.
AVAILABILITY: All source code is available at the github repository
http:github.org/paradigmshift.
CONTACT: jstuart@soe.ucsc.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/bts402 
PMCID: PMC3436829
PMID: 22962493  [PubMed - indexed for MEDLINE]


1455. Bioinformatics. 2012 Nov 15;28(22):3009-11. doi: 10.1093/bioinformatics/bts543.
Epub 2012 Sep 8.

ImgLib2--generic image processing in Java.

Pietzsch T(1), Preibisch S, Tomancák P, Saalfeld S.

Author information: 
(1)Max Planck Institute of Molecular Cell Biology and Genetics, 01307 Dresden,
Germany.

Erratum in
    Bioinformatics. 2013 Jan 15;29(2):298.

SUMMARY: ImgLib2 is an open-source Java library for n-dimensional data
representation and manipulation with focus on image processing. It aims at
minimizing code duplication by cleanly separating pixel-algebra, data access and 
data representation in memory. Algorithms can be implemented for classes of pixel
types and generic access patterns by which they become independent of the
specific dimensionality, pixel type and data representation. ImgLib2 illustrates 
that an elegant high-level programming interface can be achieved without
sacrificing performance. It provides efficient implementations of common data
types, storage layouts and algorithms. It is the data model underlying ImageJ2,
the KNIME Image Processing toolbox and an increasing number of Fiji-Plugins.
AVAILABILITY: ImgLib2 is licensed under BSD. Documentation and source code are
available at http://imglib2.net and in a public repository at
https://github.com/imagej/imglib.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
Online.
CONTACT: saalfeld@mpi-cbg.de

DOI: 10.1093/bioinformatics/bts543 
PMCID: PMC3496339
PMID: 22962343  [PubMed - indexed for MEDLINE]


1456. J Chem Phys. 2012 Sep 7;137(9):094108. doi: 10.1063/1.4748100.

A general theory of DNA-mediated and other valence-limited colloidal
interactions.

Varilly P(1), Angioletti-Uberti S, Mognetti BM, Frenkel D.

Author information: 
(1)Department of Chemistry, University of Cambridge, Lensfield Road, CB2 1EW
Cambridge, United Kingdom.

We present a general theory for predicting the interaction potentials between
DNA-coated colloids, and more broadly, any particles that interact via
valence-limited ligand-receptor binding. Our theory correctly incorporates the
configurational and combinatorial entropic factors that play a key role in
valence-limited interactions. By rigorously enforcing self-consistency, it
achieves near-quantitative accuracy with respect to detailed Monte Carlo
calculations. With suitable approximations and in particular geometries, our
theory reduces to previous successful treatments, which are now united in a
common and extensible framework. We expect our tools to be useful to other
researchers investigating ligand-mediated interactions. A complete and
well-documented Python implementation is freely available at
http://github.com/patvarilly/DNACC.

DOI: 10.1063/1.4748100 
PMID: 22957556  [PubMed - indexed for MEDLINE]


1457. Bioinformatics. 2012 Nov 15;28(22):2986-8. doi: 10.1093/bioinformatics/bts545.
Epub 2012 Sep 5.

Comb-p: software for combining, analyzing, grouping and correcting spatially
correlated P-values.

Pedersen BS(1), Schwartz DA, Yang IV, Kechris KJ.

Author information: 
(1)Department of Medicine, University of Colorado, Denver, Anschutz Medical
Campus, Aurora, CO 80045, USA. bpederse@gmail.com

SUMMARY: comb-p is a command-line tool and a python library that manipulates BED 
files of possibly irregularly spaced P-values and (1) calculates
auto-correlation, (2) combines adjacent P-values, (3) performs false discovery
adjustment, (4) finds regions of enrichment (i.e. series of adjacent low
P-values) and (5) assigns significance to those regions. In addition, tools are
provided for visualization and assessment. We provide validation and example uses
on bisulfite-seq with P-values from Fisher's exact test, tiled methylation probes
using a linear model and Dam-ID for chromatin binding using moderated
t-statistics. Because the library accepts input in a simple, standardized format 
and is unaffected by the origin of the P-values, it can be used for a wide
variety of applications.
AVAILABILITY: comb-p is maintained under the BSD license. The documentation and
implementation are available at https://github.com/brentp/combined-pvalues.
CONTACT: bpederse@gmail.com

DOI: 10.1093/bioinformatics/bts545 
PMCID: PMC3496335
PMID: 22954632  [PubMed - indexed for MEDLINE]


1458. Bioinformatics. 2012 Nov 1;28(21):2851-2. doi: 10.1093/bioinformatics/bts528.
Epub 2012 Aug 31.

FSelector: a Ruby gem for feature selection.

Cheng T(1), Wang Y, Bryant SH.

Author information: 
(1)Computational Biology Branch, National Center for Biotechnology Information,
National Library of Medicine, National Institutes of Health, 8600 Rockville Pike,
Bethesda, MD 20894, USA.

SUMMARY: The FSelector package contains a comprehensive list of feature selection
algorithms for supporting bioinformatics and machine learning research. FSelector
primarily collects and implements the filter type of feature selection
techniques, which are computationally efficient for mining large datasets. In
particular, FSelector allows ensemble feature selection that takes advantage of
multiple feature selection algorithms to yield more robust results. FSelector
also provides many useful auxiliary tools, including normalization,
discretization and missing data imputation.
AVAILABILITY: FSelector, written in the Ruby programming language, is free and
open-source software that runs on all Ruby supporting platforms, including
Windows, Linux and Mac OS X. FSelector is available from
https://rubygems.org/gems/fselector and can be installed like a breeze via the
command gem install fselector. The source code is available
(https://github.com/need47/fselector) and is fully documented
(http://rubydoc.info/gems/fselector/frames).

DOI: 10.1093/bioinformatics/bts528 
PMCID: PMC3476337
PMID: 22942017  [PubMed - indexed for MEDLINE]


1459. Bioinformatics. 2012 Sep 1;28(17):2215-22.

Improved gap size estimation for scaffolding algorithms.

Sahlin K(1), Street N, Lundeberg J, Arvestad L.

Author information: 
(1)Department of Computational Biology, mKTH Royal Institute of Technology,
Science for Life Laboratory, School of Computer Science and Communication, Solna,
Sweden. ksahlin@csc.kth.se

MOTIVATION: One of the important steps of genome assembly is scaffolding, in
which contigs are linked using information from read-pairs. Scaffolding provides 
estimates about the order, relative orientation and distance between contigs. We 
have found that contig distance estimates are generally strongly biased and based
on false assumptions. Since erroneous distance estimates can mislead in
subsequent analysis, it is important to provide unbiased estimation of contig
distance.
RESULTS: In this article, we show that state-of-the-art programs for scaffolding 
are using an incorrect model of gap size estimation. We discuss why current
maximum likelihood estimators are biased and describe what different cases of
bias we are facing. Furthermore, we provide a model for the distribution of reads
that span a gap and derive the maximum likelihood equation for the gap length. We
motivate why this estimate is sound and show empirically that it outperforms gap 
estimators in popular scaffolding programs. Our results have consequences both
for scaffolding software, structural variation detection and for library
insert-size estimation as is commonly performed by read aligners.
AVAILABILITY: A reference implementation is provided at
https://github.com/SciLifeLab/gapest.
SUPPLEMENTARY INFORMATION: Supplementary data are availible at Bioinformatics
online.

DOI: 10.1093/bioinformatics/bts441 
PMID: 22923455  [PubMed - indexed for MEDLINE]


1460. Bioinformatics. 2012 Oct 15;28(20):2689-90. doi: 10.1093/bioinformatics/bts492.
Epub 2012 Aug 20.

treePL: divergence time estimation using penalized likelihood for large
phylogenies.

Smith SA(1), O'Meara BC.

Author information: 
(1)Department of Ecology and Evolutionary Biology, University of Michigan, Ann
Arbor, MI 48109, USA. eebsmith@umich.edu

Ever larger phylogenies are being constructed due to the explosion of genetic
data and development of high-performance phylogenetic reconstruction algorithms. 
However, most methods for calculating divergence times are limited to datasets
that are orders of magnitude smaller than recently published large phylogenies.
Here, we present an algorithm and implementation of a divergence time method
using penalized likelihood that can handle datasets of thousands of taxa. We
implement a method that combines the standard derivative-based optimization with 
a stochastic simulated annealing approach to overcome optimization challenges. We
compare this approach with existing software including r8s, PATHd8 and
BEAST.AVAILABILITY: Source code, example files, binaries and documentation for
treePL are available at https://github.com/blackrim/treePL.

DOI: 10.1093/bioinformatics/bts492 
PMID: 22908216  [PubMed - indexed for MEDLINE]


1461. PLoS One. 2012;7(8):e42887. doi: 10.1371/journal.pone.0042887. Epub 2012 Aug 7.

SAP--a sequence mapping and analyzing program for long sequence reads alignment
and accurate variants discovery.

Sun Z(1), Tian W.

Author information: 
(1)State Key Laboratory of Genetic Engineering, Institute of Biostatistics,
School of Life Sciences, Fudan University, Shanghai, China.

The third-generation of sequencing technologies produces sequence reads of 1000
bp or more that may contain high polymorphism information. However, most
currently available sequence analysis tools are developed specifically for
analyzing short sequence reads. While the traditional Smith-Waterman (SW)
algorithm can be used to map long sequence reads, its naive implementation is
computationally infeasible. We have developed a new Sequence mapping and
Analyzing Program (SAP) that implements a modified version of SW to speed up the 
alignment process. In benchmarks with simulated and real exon sequencing data and
a real E. coli genome sequence data generated by the third-generation sequencing 
technologies, SAP outperforms currently available tools for mapping short and
long sequence reads in both speed and proportion of captured reads. In addition, 
it achieves high accuracy in detecting SNPs and InDels in the simulated data. SAP
is available at https://github.com/davidsun/SAP.

DOI: 10.1371/journal.pone.0042887 
PMCID: PMC3413671
PMID: 22880129  [PubMed - indexed for MEDLINE]


1462. Bioinformatics. 2012 Oct 15;28(20):2707-9. doi: 10.1093/bioinformatics/bts486.
Epub 2012 Jul 31.

MetiTree: a web application to organize and process high-resolution multi-stage
mass spectrometry metabolomics data.

Rojas-Chertó M(1), van Vliet M, Peironcely JE, van Doorn R, Kooyman M, te Beek T,
van Driel MA, Hankemeier T, Reijmers T.

Author information: 
(1)Netherlands Metabolomics Centre, Leiden, The Netherlands.
m.rojas@lacdr.leidenuniv.nl

Identification of metabolites using high-resolution multi-stage mass spectrometry
(MS(n)) data is a significant challenge demanding access to all sorts of
computational infrastructures. MetiTree is a user-friendly, web application
dedicated to organize, process, share, visualize and compare MS(n) data. It
integrates several features to export and visualize complex MS(n) data,
facilitating the exploration and interpretation of metabolomics experiments. A
dedicated spectral tree viewer allows the simultaneous presentation of three
related types of MS(n) data, namely, the spectral data, the fragmentation tree
and the fragmentation reactions. MetiTree stores the data in an internal database
to enable searching for similar fragmentation trees and matching against other
MS(n) data. As such MetiTree contains much functionality that will make the
difficult task of identifying unknown metabolites much easier.AVAILABILITY:
MetiTree is accessible at http://www.MetiTree.nl. The source code is available at
https://github.com/NetherlandsMetabolomicsCentre/metitree/wiki.

DOI: 10.1093/bioinformatics/bts486 
PMCID: PMC3467742
PMID: 22851531  [PubMed - indexed for MEDLINE]


1463. Bioinformatics. 2012 Sep 1;28(17):2281-2. doi: 10.1093/bioinformatics/bts428.
Epub 2012 Jul 4.

Voronto: mapper for expression data to ontologies.

Santamaría R(1), Pierre P.

Author information: 
(1)Departmento de Informática y Automática, Universidad de Salamanca, 37008
Salamanca, Spain. rodri@usal.es

MOTIVATION: Several techniques analyze gene expression data from the point of
view of biological ontologies. These methods focus on statistical and numerical
analyses, but there is an additional need for fast, global and interactive
visualizations of gene expression data in the context of biological ontologies.
RESULTS: Voronto addresses these needs with an easy to use integration of custom 
gene expression data with custom or public ontologies. In order to do that, it
implements Voronoi diagrams where ontologies are mapped with gene expression,
providing a quick hierarchy browsing and integration with ontology's resources.
AVAILABILITY: The tool is available at http://vis.usal.es/voronto. Source code
available at https:/github.com/rodrigoSantamaria/Voronto.

DOI: 10.1093/bioinformatics/bts428 
PMID: 22764160  [PubMed - indexed for MEDLINE]


1464. Mol Biol Evol. 2012 Nov;29(11):3413-25. doi: 10.1093/molbev/mss163. Epub 2012 Jun
29.

Testing the infinitely many genes model for the evolution of the bacterial core
genome and pangenome.

Collins RE(1), Higgs PG.

Author information: 
(1)Origins Institute and Department of Physics and Astronomy, McMaster
University, Hamilton, Ontario, Canada. rec3141@mcmaster.ca

When groups of related bacterial genomes are compared, the number of core genes
found in all genomes is usually much less than the mean genome size, whereas the 
size of the pangenome (the set of genes found on at least one of the genomes) is 
much larger than the mean size of one genome. We analyze 172 complete genomes of 
Bacilli and compare the properties of the pangenomes and core genomes of
monophyletic subsets taken from this group. We then assess the capabilities of
several evolutionary models to predict these properties. The infinitely many
genes (IMG) model is based on the assumption that each new gene can arise only
once. The predictions of the model depend on the shape of the evolutionary tree
that underlies the divergence of the genomes. We calculate results for coalescent
trees, star trees, and arbitrary phylogenetic trees of predefined fixed branch
length. On a star tree, the pangenome size increases linearly with the number of 
genomes, as has been suggested in some previous studies, whereas on a coalescent 
tree, it increases logarithmically. The coalescent tree gives a better fit to the
data, for all the examples we consider. In some cases, a fixed phylogenetic tree 
proved better than the coalescent tree at reproducing structure in the gene
frequency spectrum, but little improvement was gained in predictions of the core 
and pangenome sizes. Most of the data are well explained by a model with three
classes of gene: an essential class that is found in all genomes, a slow class
whose rate of origination and deletion is slow compared with the time of
divergence of the genomes, and a fast class showing rapid origination and
deletion. Although the majority of genes originating in a genome are in the fast 
class, these genes are not retained for long periods, and the majority of genes
present in a genome are in the slow or essential classes. In general, we show
that the IMG model is useful for comparison with experimental genome data both
for species level and widely divergent taxonomic groups. Software implementing
the described formulae is provided at http://github.com/rec3141/pangenome.

DOI: 10.1093/molbev/mss163 
PMID: 22752048  [PubMed - indexed for MEDLINE]


1465. Bioinformatics. 2012 Aug 15;28(16):2207-8. doi: 10.1093/bioinformatics/bts359.
Epub 2012 Jun 23.

BIDDSAT: visualizing the content of biodiversity data publishers in the Global
Biodiversity Information Facility network.

Otegui J(1), Ariño AH.

Author information: 
(1)Department of Zoology and Ecology, University of Navarra, 31080 Pamplona,
Spain. jotellechea@alumni.unav.es

In any data quality workflow, data publishers must become aware of issues in
their data so these can be corrected. User feedback mechanisms provide one
avenue, while global assessments of datasets provide another. To date, there is
no publicly available tool to allow both biodiversity data institutions sharing
their data through the Global Biodiversity Information Facility network and its
potential users to assess datasets as a whole. Contributing to bridge this gap
both for publishers and users, we introduce BIoDiversity DataSets Assessment
Tool, an online tool that enables selected diagnostic visualizations on the
content of data publishers and/or their individual collections.AVAILABILITY AND
IMPLEMENTATION: The online application is accessible at
http://www.unav.es/unzyec/mzna/biddsat/ and is supported by all major browsers.
The source code is licensed under the GNU GPLv3 license
(http://www.gnu.org/licenses/gpl-3.0.txt) and is available at
https://github.com/jotegui/BIDDSAT.

DOI: 10.1093/bioinformatics/bts359 
PMID: 22730433  [PubMed - indexed for MEDLINE]


1466. BMC Bioinformatics. 2012 Jun 19;13:137. doi: 10.1186/1471-2105-13-137.

A Bayesian model for classifying all differentially expressed proteins
simultaneously in 2D PAGE gels.

Wu SH(1), Black MA, North RA, Rodrigo AG.

Author information: 
(1)Bioinformatics Institute, University of Auckland, Private Bag, 92019,
Auckland, New Zealand. steven.wu@duke.edu

BACKGROUND: Two-dimensional polyacrylamide gel electrophoresis (2D PAGE) is
commonly used to identify differentially expressed proteins under two or more
experimental or observational conditions. Wu et al (2009) developed a univariate 
probabilistic model which was used to identify differential expression between
Case and Control groups, by applying a Likelihood Ratio Test (LRT) to each
protein on a 2D PAGE. In contrast to commonly used statistical approaches, this
model takes into account the two possible causes of missing values in 2D PAGE:
either (1) the non-expression of a protein; or (2) a level of expression that
falls below the limit of detection.
RESULTS: We develop a global Bayesian model which extends the previously
described model. Unlike the univariate approach, the model reported here is able 
treat all differentially expressed proteins simultaneously. Whereas each protein 
is modelled by the univariate likelihood function previously described, several
global distributions are used to model the underlying relationship between the
parameters associated with individual proteins. These global distributions are
able to combine information from each protein to give more accurate estimates of 
the true parameters. In our implementation of the procedure, all parameters are
recovered by Markov chain Monte Carlo (MCMC) integration. The 95% highest
posterior density (HPD) intervals for the marginal posterior distributions are
used to determine whether differences in protein expression are due to
differences in mean expression intensities, and/or differences in the
probabilities of expression.
CONCLUSIONS: Simulation analyses showed that the global model is able to
accurately recover the underlying global distributions, and identify more
differentially expressed proteins than the simple application of a LRT.
Additionally, simulations also indicate that the probability of incorrectly
identifying a protein as differentially expressed (i.e., the False Discovery
Rate) is very low. The source code is available at
https://github.com/stevenhwu/BIDE-2D.

DOI: 10.1186/1471-2105-13-137 
PMCID: PMC3505467
PMID: 22712439  [PubMed - indexed for MEDLINE]


1467. IEEE Trans Nanobioscience. 2012 Dec;11(4):324-35. doi: 10.1109/TNB.2012.2197863. 
Epub 2012 Jun 12.

Identifying protein complexes from interactome based on essential proteins and
local fitness method.

Wang J(1), Chen G, Liu B, Li M, Pan Y.

Author information: 
(1)School of Information Science and Engineering, Central South University,
Changsha, 410005, China. jxwang@mail.csu.edu.cn

High-throughput experimental technologies, along with computational predictions, 
have promoted the emergence of large-scale interactome for numerous organisms.
Identification of protein complexes from these interactome networks is crucial to
understand principles of cellular organization and predict protein functions.
Protein complexes are generally considered as dense subgraphs. However, the real 
protein complexes do not always have highly connected topologies. In this paper, 
a novel protein complex identifying method, named EPOF, is proposed, using
essential proteins and the local metric of vertex fitness. In EPOF, cliques in
the subnetwork which is consisted by the essential proteins are firstly
considered as seeds, which are ordered according to their size and the number of 
their neighbors. A protein complex is extended from a seed based on the
evaluation of its neighbors' fitness value. Then, the similar procedure is
applied to the cliques identified in the subnetwork which is consisted by the
proteins which is not clustered in the first step. When EPOF identifies complexes
by expanding essential protein cliques, the essential proteins have higher
priority and lower threshold. When it identifies complexes by expanding
nonessential protein cliques, the nonessential proteins have higher priority and 
lower threshold. Finally, the last step, we output the identified complexes set. 
The proposed algorithm EPOF is applied to the unweighted and weighted interaction
networks of S. cerevisiae and detects many well known protein complexes. We
compare the performances of EPOF to other ten previous algorithms, including
EAGLE, NFC, MCODE, DPClus, IPCA, CPM, MCL, CMC, SPICi, and Core-Attachment.
Experimental results show that EPOF outperforms other previous competing
algorithms in terms of matching with known complexes, sensitivity, specificity,
f-measure, function enrichment and accuracy. The program and related files
available on https://github.com/gangchen/epof.

DOI: 10.1109/TNB.2012.2197863 
PMID: 22711784  [PubMed - indexed for MEDLINE]


1468. Nucleic Acids Res. 2012 Jul;40(Web Server issue):W205-8. doi: 10.1093/nar/gks552.
Epub 2012 Jun 11.

MFEprimer-2.0: a fast thermodynamics-based program for checking PCR primer
specificity.

Qu W(1), Zhou Y, Zhang Y, Lu Y, Wang X, Zhao D, Yang Y, Zhang C.

Author information: 
(1)Beijing Institute of Radiation Medicine, State Key Laboratory of Proteomics,
Cognitive and Mental Health Research Center, Beijing 100850, China.

Evaluating the specificity of polymerase chain reaction (PCR) primers is an
essential step in PCR primer design. The MFEprimer-2.0 server allows users to
check primer specificity against genomic DNA and messenger RNA/complementary DNA 
sequence databases quickly and easily. MFEprimer-2.0 uses a k-mer index algorithm
to accelerate the search process for primer binding sites and uses thermodynamics
to evaluate binding stability between each primer and its DNA template. Several
important characteristics, such as the sequence, melting temperature and size of 
each amplicon, either specific or non-specific, are reported on the results page.
Based on these characteristics and the user-friendly output, users can readily
draw conclusions about the specificity of PCR primers. Analyses for degenerate
primers and multiple PCR primers are also supported in MFEprimer-2.0. In
addition, the databases supported by MFEprimer-2.0 are comprehensive, and custom 
databases can also be supported on request. The MFEprimer-2.0 server does not
require a login and is freely available at
http://biocompute.bmi.ac.cn/CZlab/MFEprimer-2.0. More over, the MFEprimer-2.0
command-line version and local server version are open source and can be
downloaded at https://github.com/quwubin/MFEprimer/wiki/Manual/.

DOI: 10.1093/nar/gks552 
PMCID: PMC3394324
PMID: 22689644  [PubMed - indexed for MEDLINE]


1469. Bioinformatics. 2012 Jul 15;28(14):1921-2. doi: 10.1093/bioinformatics/bts298.
Epub 2012 May 23.

Marker2sequence, mine your QTL regions for candidate genes.

Chibon PY(1), Schoof H, Visser RG, Finkers R.

Author information: 
(1)Wageningen UR Plant Breeding, Wageningen University and Research Centre, PO
Box 386, 6700 AJ, Wageningen, The Netherlands.

Marker2sequence (M2S) aims at mining quantitative trait loci (QTLs) for candidate
genes. For each gene, within the QTL region, M2S uses data integration technology
to integrate putative gene function with associated gene ontology terms,
proteins, pathways and literature. As a typical QTL region easily contains
several hundreds of genes, this gene list can then be further filtered using a
keyword-based query on the aggregated annotations. M2S will help breeders to
identify potential candidate genes for their traits of interest.AVAILABILITY:
Marker2sequence is freely accessible at
http://www.plantbreeding.wur.nl/BreeDB/marker2seq/. The source code can be
obtained at https://github.com/PBR/Marker2Sequence.
CONTACT: richard.finkers@wur.nl

DOI: 10.1093/bioinformatics/bts298 
PMID: 22628524  [PubMed - indexed for MEDLINE]


1470. Bioinformatics. 2012 Aug 1;28(15):2064-6. doi: 10.1093/bioinformatics/bts309.
Epub 2012 May 24.

RAxML-Light: a tool for computing terabyte phylogenies.

Stamatakis A(1), Aberer AJ, Goll C, Smith SA, Berger SA, Izquierdo-Carrasco F.

Author information: 
(1)The Exelixis Lab, Scientific Computing Group, Heidelberg Institute for
Theoretical Studies, Schloss-Wolfsbrunnenweg 35, D-68159 Heidelberg, Germany.
alexandros.stamatakis@h-its.org

MOTIVATION: Due to advances in molecular sequencing and the increasingly rapid
collection of molecular data, the field of phyloinformatics is transforming into 
a computational science. Therefore, new tools are required that can be deployed
in supercomputing environments and that scale to hundreds or thousands of cores.
RESULTS: We describe RAxML-Light, a tool for large-scale phylogenetic inference
on supercomputers under maximum likelihood. It implements a light-weight
checkpointing mechanism, deploys 128-bit (SSE3) and 256-bit (AVX) vector
intrinsics, offers two orthogonal memory saving techniques and provides a
fine-grain production-level message passing interface parallelization of the
likelihood function. To demonstrate scalability and robustness of the code, we
inferred a phylogeny on a simulated DNA alignment (1481 taxa, 20 000 000 bp)
using 672 cores. This dataset requires one terabyte of RAM to compute the
likelihood score on a single tree. CODE AVAILABILITY:
https://github.com/stamatak/RAxML-Light-1.0.5 DATA AVAILABILITY:
http://www.exelixis-lab.org/onLineMaterial.tar.bz2
CONTACT: alexandros.stamatakis@h-its.org
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/bts309 
PMCID: PMC3400957
PMID: 22628519  [PubMed - indexed for MEDLINE]


1471. Bioinformatics. 2012 Aug 1;28(15):2052-8. doi: 10.1093/bioinformatics/bts300.
Epub 2012 May 17.

flowPeaks: a fast unsupervised clustering for flow cytometry data via K-means and
density peak finding.

Ge Y(1), Sealfon SC.

Author information: 
(1)Department of Neurology and Center of Translational System Biology, Mount
Sinai School of Medicine, New York, NY 10029, USA. yongchao.ge@mssm.edu

MOTIVATION: For flow cytometry data, there are two common approaches to the
unsupervised clustering problem: one is based on the finite mixture model and the
other on spatial exploration of the histograms. The former is computationally
slow and has difficulty to identify clusters of irregular shapes. The latter
approach cannot be applied directly to high-dimensional data as the computational
time and memory become unmanageable and the estimated histogram is unreliable. An
algorithm without these two problems would be very useful.
RESULTS: In this article, we combine ideas from the finite mixture model and
histogram spatial exploration. This new algorithm, which we call flowPeaks, can
be applied directly to high-dimensional data and identify irregular shape
clusters. The algorithm first uses K-means algorithm with a large K to partition 
the cell population into many small clusters. These partitioned data allow the
generation of a smoothed density function using the finite mixture model. All
local peaks are exhaustively searched by exploring the density function and the
cells are clustered by the associated local peak. The algorithm flowPeaks is
automatic, fast and reliable and robust to cluster shape and outliers. This
algorithm has been applied to flow cytometry data and it has been compared with
state of the art algorithms, including Misty Mountain, FLOCK, flowMeans,
flowMerge and FLAME.
AVAILABILITY: The R package flowPeaks is available at
https://github.com/yongchao/flowPeaks.
CONTACT: yongchao.ge@mssm.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/bts300 
PMCID: PMC3400953
PMID: 22595209  [PubMed - indexed for MEDLINE]


1472. Bioinformatics. 2012 Jul 15;28(14):1947-8. doi: 10.1093/bioinformatics/bts273.
Epub 2012 May 9.

MicrobeDB: a locally maintainable database of microbial genomic sequences.

Langille MG(1), Laird MR, Hsiao WW, Chiu TA, Eisen JA, Brinkman FS.

Author information: 
(1)Department of Biochemistry & Molecular Biology, Dalhousie University, Halifax,
Nova Scotia, Canada. morgan.g.i.langille@gmail.com

Analysis of microbial genomes often requires the general organization and
comparison of tens to thousands of genomes both from public repositories and
unpublished sources. MicrobeDB provides a foundation for such projects by the
automation of downloading published, completed bacterial and archaeal genomes
from key sources, parsing annotations of all genomes (both public and private)
into a local database, and allowing interaction with the database through an easy
to use programming interface. MicrobeDB creates a simple to use, easy to
maintain, centralized local resource for various large-scale comparative genomic 
analyses and a back-end for future microbial application design.AVAILABILITY:
MicrobeDB is freely available under the GNU-GPL at:
http://github.com/mlangill/microbedb/

DOI: 10.1093/bioinformatics/bts273 
PMCID: PMC3389766
PMID: 22576174  [PubMed - indexed for MEDLINE]


1473. Bioinformatics. 2012 Jul 15;28(14):1838-44. doi: 10.1093/bioinformatics/bts280.
Epub 2012 May 7.

Exploring single-sample SNP and INDEL calling with whole-genome de novo assembly.

Li H(1).

Author information: 
(1)Medical Population Genetics Program, Broad Institute, 7 Cambridge Center, MA
02142, USA. hengli@broadinstitute.org

MOTIVATION: Eugene Myers in his string graph paper suggested that in a string
graph or equivalently a unitig graph, any path spells a valid assembly. As a
string/unitig graph also encodes every valid assembly of reads, such a graph,
provided that it can be constructed correctly, is in fact a lossless
representation of reads. In principle, every analysis based on whole-genome
shotgun sequencing (WGS) data, such as SNP and insertion/deletion (INDEL)
calling, can also be achieved with unitigs.
RESULTS: To explore the feasibility of using de novo assembly in the context of
resequencing, we developed a de novo assembler, fermi, that assembles Illumina
short reads into unitigs while preserving most of information of the input reads.
SNPs and INDELs can be called by mapping the unitigs against a reference genome. 
By applying the method on 35-fold human resequencing data, we showed that in
comparison to the standard pipeline, our approach yields similar accuracy for SNP
calling and better results for INDEL calling. It has higher sensitivity than
other de novo assembly based methods for variant calling. Our work suggests that 
variant calling with de novo assembly can be a beneficial complement to the
standard variant calling pipeline for whole-genome resequencing. In the
methodological aspects, we propose FMD-index for forward-backward extension of
DNA sequences, a fast algorithm for finding all super-maximal exact matches and
one-pass construction of unitigs from an FMD-index.
AVAILABILITY: http://github.com/lh3/fermi

DOI: 10.1093/bioinformatics/bts280 
PMCID: PMC3389770
PMID: 22569178  [PubMed - indexed for MEDLINE]


1474. Bioinformatics. 2012 Jun 15;28(12):1665-7. doi: 10.1093/bioinformatics/bts258.
Epub 2012 May 3.

graph2tab, a library to convert experimental workflow graphs into tabular
formats.

Brandizi M(1), Kurbatova N, Sarkans U, Rocca-Serra P.

Author information: 
(1)European Bioinformatics Institute, Wellcome Trust Genome Campus, Cambridge,
UK. brandizi@ebi.ac.uk

MOTIVATIONS: Spreadsheet-like tabular formats are ever more popular in the
biomedical field as a mean for experimental reporting. The problem of converting 
the graph of an experimental workflow into a table-based representation occurs in
many such formats and is not easy to solve.
RESULTS: We describe graph2tab, a library that implements methods to realise such
a conversion in a size-optimised way. Our solution is generic and can be adapted 
to specific cases of data exporters or data converters that need to be
implemented.
AVAILABILITY AND IMPLEMENTATION: The library source code and documentation are
available at http://github.com/ISA-tools/graph2tab.

DOI: 10.1093/bioinformatics/bts258 
PMCID: PMC3371871
PMID: 22556367  [PubMed - indexed for MEDLINE]


1475. Bioinformatics. 2012 Jun 1;28(11):1415-9. doi: 10.1093/bioinformatics/bts173.
Epub 2012 May 3.

Large-scale compression of genomic sequence databases with the Burrows-Wheeler
transform.

Cox AJ(1), Bauer MJ, Jakobi T, Rosone G.

Author information: 
(1)Computational Biology Group, Illumina Cambridge Ltd., Chesterford Research
Park, Little Chesterford, Essex, UK. acox@illumina.com

MOTIVATION: The Burrows-Wheeler transform (BWT) is the foundation of many
algorithms for compression and indexing of text data, but the cost of computing
the BWT of very large string collections has prevented these techniques from
being widely applied to the large sets of sequences often encountered as the
outcome of DNA sequencing experiments. In previous work, we presented a novel
algorithm that allows the BWT of human genome scale data to be computed on very
moderate hardware, thus enabling us to investigate the BWT as a tool for the
compression of such datasets.
RESULTS: We first used simulated reads to explore the relationship between the
level of compression and the error rate, the length of the reads and the level of
sampling of the underlying genome and compare choices of second-stage compression
algorithm. We demonstrate that compression may be greatly improved by a
particular reordering of the sequences in the collection and give a novel
'implicit sorting' strategy that enables these benefits to be realized without
the overhead of sorting the reads. With these techniques, a 45× coverage of real 
human genome sequence data compresses losslessly to under 0.5 bits per base,
allowing the 135.3 Gb of sequence to fit into only 8.2 GB of space (trimming a
small proportion of low-quality bases from the reads improves the compression
still further). This is >4 times smaller than the size achieved by a standard
BWT-based compressor (bzip2) on the untrimmed reads, but an important further
advantage of our approach is that it facilitates the building of compressed full 
text indexes such as the FM-index on large-scale DNA sequence collections.
AVAILABILITY: Code to construct the BWT and SAP-array on large genomic datasets
is part of the BEETL library, available as a github repository at
https://github.com/BEETL/BEETL.

DOI: 10.1093/bioinformatics/bts173 
PMID: 22556365  [PubMed - indexed for MEDLINE]


1476. Algorithms Mol Biol. 2012 May 2;7(1):12. doi: 10.1186/1748-7188-7-12.

Fractal MapReduce decomposition of sequence alignment.

Almeida JS(1), Grüneberg A, Maass W, Vinga S.

Author information: 
(1)Div Informatics, Dept Pathology, University of Alabama at Birmingham, USA.
jalmeida@uab.edu.

BACKGROUND: The dramatic fall in the cost of genomic sequencing, and the
increasing convenience of distributed cloud computing resources, positions the
MapReduce coding pattern as a cornerstone of scalable bioinformatics algorithm
development. In some cases an algorithm will find a natural distribution via use 
of map functions to process vectorized components, followed by a reduce of
aggregate intermediate results. However, for some data analysis procedures such
as sequence analysis, a more fundamental reformulation may be required.
RESULTS: In this report we describe a solution to sequence comparison that can be
thoroughly decomposed into multiple rounds of map and reduce operations. The
route taken makes use of iterated maps, a fractal analysis technique, that has
been found to provide a "alignment-free" solution to sequence analysis and
comparison. That is, a solution that does not require dynamic programming,
relying on a numeric Chaos Game Representation (CGR) data structure. This claim
is demonstrated in this report by calculating the length of the longest similar
segment by inspecting only the USM coordinates of two analogous units: with no
resort to dynamic programming.
CONCLUSIONS: The procedure described is an attempt at extreme decomposition and
parallelization of sequence alignment in anticipation of a volume of genomic
sequence data that cannot be met by current algorithmic frameworks. The solution 
found is delivered with a browser-based application (webApp), highlighting the
browser's emergence as an environment for high performance distributed computing.
AVAILABILITY: Public distribution of accompanying software library with open
source and version control at http://usm.github.com. Also available as a webApp
through Google Chrome's WebStore http://chrome.google.com/webstore: search with
"usm".

DOI: 10.1186/1748-7188-7-12 
PMCID: PMC3394223
PMID: 22551205  [PubMed]


1477. Bioinformatics. 2012 Jun 15;28(12):1661-2. doi: 10.1093/bioinformatics/bts249.
Epub 2012 Apr 26.

DecoyFinder: an easy-to-use python GUI application for building target-specific
decoy sets.

Cereto-Massagué A(1), Guasch L, Valls C, Mulero M, Pujadas G, Garcia-Vallvé S.

Author information: 
(1)Grup de Recerca en Nutrigenòmica, Departament de Bioquímica i Biotecnologia,
Universitat Rovira i Virgili, Campus de Sescelades, C/Marcel.lí Domingo s/n,
43007 Tarragona, Spain.

Decoys are molecules that are presumed to be inactive against a target (i.e. will
not likely bind to the target) and are used to validate the performance of
molecular docking or a virtual screening workflow. The Directory of Useful Decoys
database (http://dud.docking.org/) provides a free directory of decoys for use in
virtual screening, though it only contains a limited set of decoys for 40
targets.To overcome this limitation, we have developed an application called
DecoyFinder that selects, for a given collection of active ligands of a target, a
set of decoys from a database of compounds. Decoys are selected if they are
similar to active ligands according to five physical descriptors (molecular
weight, number of rotational bonds, total hydrogen bond donors, total hydrogen
bond acceptors and the octanol-water partition coefficient) without being
chemically similar to any of the active ligands used as an input (according to
the Tanimoto coefficient between MACCS fingerprints). To the best of our
knowledge, DecoyFinder is the first application designed to build target-specific
decoy sets.AVAILABILITY: A complete description of the software is included on
the application home page. A validation of DecoyFinder on 10 DUD targets is
provided as Supplementary Table S1. DecoyFinder is freely available at
http://URVnutrigenomica-CTNS.github.com/DecoyFinder.

DOI: 10.1093/bioinformatics/bts249 
PMID: 22539671  [PubMed - indexed for MEDLINE]


1478. J Comput Chem. 2012 May 5;33(12):1207-14. doi: 10.1002/jcc.22947. Epub 2012 Feb
28.

Enabling grand-canonical Monte Carlo: extending the flexibility of GROMACS
through the GromPy python interface module.

Pool R(1), Heringa J, Hoefling M, Schulz R, Smith JC, Feenstra KA.

Author information: 
(1)Centre for Integrative Bioinformatics Vrije Universiteit (IBIVU), VU
University Amsterdam, De Boelelaan 1081a, 1081HV Amsterdam, The Netherlands;
Netherlands Bioinformatics Centre, Geert Grooteplein 28, 6525GA Nijmegen, The
Netherlands. r.pool@vu.nl.

We report on a python interface to the GROMACS molecular simulation package,
GromPy (available at https://github.com/GromPy). This application programming
interface (API) uses the ctypes python module that allows function calls to
shared libraries, for example, written in C. To the best of our knowledge, this
is the first reported interface to the GROMACS library that uses direct library
calls. GromPy can be used for extending the current GROMACS simulation and
analysis modes. In this work, we demonstrate that the interface enables hybrid
Monte-Carlo/molecular dynamics (MD) simulations in the grand-canonical ensemble, 
a simulation mode that is currently not implemented in GROMACS. For this
application, the interplay between GromPy and GROMACS requires only minor
modifications of the GROMACS source code, not affecting the operation,
efficiency, and performance of the GROMACS applications. We validate the
grand-canonical application against MD in the canonical ensemble by comparison of
equations of state. The results of the grand-canonical simulations are in
complete agreement with MD in the canonical ensemble. The python overhead of the 
grand-canonical scheme is only minimal.

Copyright © 2012 Wiley Periodicals, Inc.

DOI: 10.1002/jcc.22947 
PMID: 22370965  [PubMed - indexed for MEDLINE]


1479. Bioinformatics. 2012 Apr 1;28(7):1024-5. doi: 10.1093/bioinformatics/bts064. Epub
2012 Feb 1.

Breakpointer: using local mapping artifacts to support sequence breakpoint
discovery from single-end reads.

Sun R(1), Love MI, Zemojtel T, Emde AK, Chung HR, Vingron M, Haas SA.

Author information: 
(1)Department of Computational Molecular Biology, Max-Planck-Institute for
Molecular Genetics, Ihnestr. 63-73, 14195 Berlin, Germany. ruping@molgen.mpg.de

SUMMARY: We developed Breakpointer, a fast algorithm to locate breakpoints of
structural variants (SVs) from single-end reads produced by next-generation
sequencing. By taking advantage of local non-uniform read distribution and
misalignments created by SVs, Breakpointer scans the alignment of single-end
reads to identify regions containing potential breakpoints. The detection of such
breakpoints can indicate insertions longer than the read length and SVs located
in repetitve regions which might be missd by other methods. Thus, Breakpointer
complements existing methods to locate SVs from single-end reads.
AVAILABILITY: https://github.com/ruping/Breakpointer
CONTACT: ruping@molgen.mpg.de
SUPPLEMENTARY INFORMATION: Supplementary material is available at Bioinformatics 
online.

DOI: 10.1093/bioinformatics/bts064 
PMID: 22302574  [PubMed - indexed for MEDLINE]


1480. Bioinformatics. 2012 Apr 1;28(7):1052-3. doi: 10.1093/bioinformatics/bts066. Epub
2012 Feb 2.

pymzML--Python module for high-throughput bioinformatics on mass spectrometry
data.

Bald T(1), Barth J, Niehues A, Specht M, Hippler M, Fufezan C.

Author information: 
(1)Institute of Plant Biology and Biotechnology, University of Muenster, 48143
Muenster, Germany.

SUMMARY: pymzML is an extension to Python that offers (i) an easy access to mass 
spectrometry (MS) data that allows the rapid development of tools, (ii) a very
fast parser for mzML data, the standard data format in MS and (iii) a set of
functions to compare or handle spectra.
AVAILABILITY AND IMPLEMENTATION: pymzML requires Python2.6.5+ and is fully
compatible with Python3. The module is freely available on
http://pymzml.github.com or pypi, is published under LGPL license and requires no
additional modules to be installed.
CONTACT: christian@fufezan.net.

DOI: 10.1093/bioinformatics/bts066 
PMID: 22302572  [PubMed - indexed for MEDLINE]


1481. RNA. 2012 Mar;18(3):385-93. doi: 10.1261/rna.027201.111. Epub 2012 Jan 25.

Improved prediction of RNA tertiary structure with insights into native state
dynamics.

Bida JP(1), Maher LJ 3rd.

Author information: 
(1)Department of Biochemistry and Molecular Biology, Mayo Clinic College of
Medicine, Rochester, Minnesota 55905, USA.

The importance of RNA tertiary structure is evident from the growing number of
published high resolution NMR and X-ray crystallographic structures of RNA
molecules. These structures provide insights into function and create a knowledge
base that is leveraged by programs such as Assemble, ModeRNA, RNABuilder, NAST,
FARNA, Mc-Sym, RNA2D3D, and iFoldRNA for tertiary structure prediction and
design. While these methods sample native-like RNA structures during simulations,
all struggle to capture the native RNA conformation after scoring. We propose
RSIM, an improved RNA fragment assembly method that preserves RNA global
secondary structure while sampling conformations. This approach enhances the
quality of predicted RNA tertiary structure, provides insights into the native
state dynamics, and generates a powerful visualization of the RNA conformational 
space. RSIM is available for download from http://www.github.com/jpbida/rsim.

DOI: 10.1261/rna.027201.111 
PMCID: PMC3285927
PMID: 22279150  [PubMed - indexed for MEDLINE]


1482. Bioinformatics. 2012 Mar 1;28(5):717-8. doi: 10.1093/bioinformatics/bts007. Epub 
2012 Jan 11.

CHROMATRA: a Galaxy tool for visualizing genome-wide chromatin signatures.

Hentrich T(1), Schulze JM, Emberly E, Kobor MS.

Author information: 
(1)Department of Computing Science, University of British Columbia, Vancouver, BC
V6T 1Z4, Canada.

CHROMATRA (CHROmatin Mapping Across TRAnscripts) is a visualization tool
available as plug-in for the Galaxy platform. It allows detailed yet concise
presentations of data derived from ChIP-chip or ChIP-seq experiments by
visualizing enrichment scores across genes or other genomic features while
accounting for their length and additional characteristics such as gene
expression. It integrates into typical analysis workflows and enables rapid
graphical assessment and comparison of genome-wide data at a glance.AVAILABILITY:
https://github.com/cmmt/chromatra.

DOI: 10.1093/bioinformatics/bts007 
PMID: 22238257  [PubMed - indexed for MEDLINE]


1483. PLoS One. 2012;7(1):e29115. doi: 10.1371/journal.pone.0029115. Epub 2012 Jan 3.

Bayesian variable selection in searching for additive and dominant effects in
genome-wide data.

Peltola T(1), Marttinen P, Jula A, Salomaa V, Perola M, Vehtari A.

Author information: 
(1)Department of Biomedical Engineering and Computational Science, Aalto
University School of Science, Espoo, Finland. tomi.peltola@aalto.fi

Although complex diseases and traits are thought to have multifactorial genetic
basis, the common methods in genome-wide association analyses test each variant
for association independent of the others. This computational simplification may 
lead to reduced power to identify variants with small effect sizes and requires
correcting for multiple hypothesis tests with complex relationships. However,
advances in computational methods and increase in computational resources are
enabling the computation of models that adhere more closely to the theory of
multifactorial inheritance. Here, a Bayesian variable selection and model
averaging approach is formulated for searching for additive and dominant genetic 
effects. The approach considers simultaneously all available variants for
inclusion as predictors in a linear genotype-phenotype mapping and averages over 
the uncertainty in the variable selection. This leads to naturally interpretable 
summary quantities on the significances of the variants and their contribution to
the genetic basis of the studied trait. We first characterize the behavior of the
approach in simulations. The results indicate a gain in the causal variant
identification performance when additive and dominant variation are simulated,
with a negligible loss of power in purely additive case. An application to the
analysis of high- and low-density lipoprotein cholesterol levels in a dataset of 
3895 Finns is then presented, demonstrating the feasibility of the approach at
the current scale of single-nucleotide polymorphism data. We describe a Markov
chain Monte Carlo algorithm for the computation and give suggestions on the
specification of prior parameters using commonly available prior information. An 
open-source software implementing the method is available at
http://www.lce.hut.fi/research/mm/bmagwa/ and https://github.com/to-mi/.

DOI: 10.1371/journal.pone.0029115 
PMCID: PMC3250410
PMID: 22235263  [PubMed - indexed for MEDLINE]


1484. Bioinformatics. 2012 Mar 1;28(5):636-42. doi: 10.1093/bioinformatics/btr698. Epub
2012 Jan 3.

Evaluating bacterial gene-finding HMM structures as probabilistic logic programs.

Mørk S(1), Holmes I.

Author information: 
(1)Department of Science, Systems and Models, Roskilde University, 4000 Roskilde,
Denmark. soer@ruc.dk

MOTIVATION: Probabilistic logic programming offers a powerful way to describe and
evaluate structured statistical models. To investigate the practicality of
probabilistic logic programming for structure learning in bioinformatics, we
undertook a simplified bacterial gene-finding benchmark in PRISM, a probabilistic
dialect of Prolog.
RESULTS: We evaluate Hidden Markov Model structures for bacterial protein-coding 
gene potential, including a simple null model structure, three structures based
on existing bacterial gene finders and two novel model structures. We test
standard versions as well as ADPH length modeling and three-state versions of the
five model structures. The models are all represented as probabilistic logic
programs and evaluated using the PRISM machine learning system in terms of
statistical information criteria and gene-finding prediction accuracy, in two
bacterial genomes. Neither of our implementations of the two currently most used 
model structures are best performing in terms of statistical information criteria
or prediction performances, suggesting that better-fitting models might be
achievable.
AVAILABILITY: The source code of all PRISM models, data and additional scripts
are freely available for download at: http://github.com/somork/codonhmm.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btr698 
PMCID: PMC3289911
PMID: 22215819  [PubMed - indexed for MEDLINE]


1485. Proc Int Conf Inf Technol New Gener. 2012;2012:89-94.

An Open-Source Sandbox for Increasing the Accessibility of Functional Programming
to the Bioinformatics and Scientific Communities.

Fenwick M(1), Sesanker C(2), Schiller MR(3), Ellis HJ, Hinman ML, Vyas J, Gryk
MR.

Author information: 
(1)Department of Microbial, Molecular and Structural Biology, University of
Connecticut Health Center, 263 Farmington Avenue Farmington, Connecticut 06030.
(2)School of Life Sciences, University of Nevada Las Vegas, 4505 Maryland Pkwy., 
Las Vegas 89154-4004. (3)Department of Computer Science/Information Technology,
Western New England University, Springfield, Massachusetts.

Scientists are continually faced with the need to express complex mathematical
notions in code. The renaissance of functional languages such as LISP and Haskell
is often credited to their ability to implement complex data operations and
mathematical constructs in an expressive and natural idiom. The slow adoption of 
functional computing in the scientific community does not, however, reflect the
congeniality of these fields. Unfortunately, the learning curve for adoption of
functional programming techniques is steeper than that for more traditional
languages in the scientific community, such as Python and Java, and this is
partially due to the relative sparseness of available learning resources. To fill
this gap, we demonstrate and provide applied, scientifically substantial examples
of functional programming, We present a multi-language source-code repository for
software integration and algorithm development, which generally focuses on the
fields of machine learning, data processing, bioinformatics. We encourage
scientists who are interested in learning the basics of functional programming to
adopt, reuse, and learn from these examples. The source code is available at:
https://github.com/CONNJUR/CONNJUR-Sandbox (see also http://www.connjur.org).

DOI: 10.1109/ITNG.2012.21 
PMCID: PMC4197993
PMID: 25328913  [PubMed]


1486. BMC Bioinformatics. 2011 Oct 5;12 Suppl 9:S11. doi: 10.1186/1471-2105-12-S9-S11.

Constraints on genes shape long-term conservation of macro-synteny in metazoan
genomes.

Lv J(1), Havlak P, Putnam NH.

Author information: 
(1)Department of Ecology and Evolutionary Biology, Rice University, Houston, TX
77098, USA.

BACKGROUND: Many metazoan genomes conserve chromosome-scale gene linkage
relationships ("macro-synteny") from the common ancestor of multicellular animal 
life 1234, but the biological explanation for this conservation is still unknown.
Double cut and join (DCJ) is a simple, well-studied model of neutral genome
evolution amenable to both simulation and mathematical analysis 5, but as we show
here, it is not sufficent to explain long-term macro-synteny conservation.
RESULTS: We examine a family of simple (one-parameter) extensions of DCJ to
identify models and choices of parameters consistent with the levels of macro-
and micro-synteny conservation observed among animal genomes. Our software
implements a flexible strategy for incorporating genomic context into the DCJ
model to incorporate various types of genomic context ("DCJ-[C]"), and is
available as open source software from http://github.com/putnamlab/dcj-c.
CONCLUSIONS: A simple model of genome evolution, in which DCJ moves are allowed
only if they maintain chromosomal linkage among a set of constrained genes, can
simultaneously account for the level of macro-synteny conservation and for
correlated conservation among multiple pairs of species. Simulations under this
model indicate that a constraint on approximately 7% of metazoan genes is
sufficient to constrain genome rearrangement to an average rate of 25 inversions 
and 1.7 translocations per million years.

DOI: 10.1186/1471-2105-12-S9-S11 
PMCID: PMC3283319
PMID: 22151646  [PubMed - indexed for MEDLINE]


1487. J Digit Imaging. 2012 Apr;25(2):206-12. doi: 10.1007/s10278-011-9434-6.

A flexible database architecture for mining DICOM objects: the DICOM data
warehouse.

Langer SG(1).

Author information: 
(1)Radiology Informatics Lab, Mayo Clinic, Rochester, MN 55905, USA.
Langer.steve@mayo.edu

Digital Imaging and Communications in Medicine (DICOM) has brought a very high
level of standardization to medical images, allowing interoperability in many
cases. However, there are still challenges facing the informaticist attempting to
data mine DICOM objects. Images (and other objects) from different vintage
equipment will encompass different levels of the standard, and there are also
proprietary "shadow" tags to be aware of. The database architecture described
herein "flattens" such differences by compiling a knowledge base of specific
DICOM implementations and mapping variable data elements to a common lexicon for 
subsequent queries. The project is open sourced, built on open infrastructure,
and is available at GitHub.

DOI: 10.1007/s10278-011-9434-6 
PMCID: PMC3295972
PMID: 22080292  [PubMed - indexed for MEDLINE]


1488. BMC Bioinformatics. 2011 Oct 21;12:408. doi: 10.1186/1471-2105-12-408.

A motif-independent metric for DNA sequence specificity.

Pinello L(1), Lo Bosco G, Hanlon B, Yuan GC.

Author information: 
(1)Department of Biostatistics, Harvard School of Public Health, 677 Huntington
Avenue, Boston, MA 02115, USA.

BACKGROUND: Genome-wide mapping of protein-DNA interactions has been widely used 
to investigate biological functions of the genome. An important question is to
what extent such interactions are regulated at the DNA sequence level. However,
current investigation is hampered by the lack of computational methods for
systematic evaluating sequence specificity.
RESULTS: We present a simple, unbiased quantitative measure for DNA sequence
specificity called the Motif Independent Measure (MIM). By analyzing both
simulated and real experimental data, we found that the MIM measure can be used
to detect sequence specificity independent of presence of transcription factor
(TF) binding motifs. We also found that the level of specificity associated with 
H3K4me1 target sequences is highly cell-type specific and highest in embryonic
stem (ES) cells. We predicted H3K4me1 target sequences by using the N- score
model and found that the prediction accuracy is indeed high in ES cells.The
software to compute the MIM is freely available at:
https://github.com/lucapinello/mim.
CONCLUSIONS: Our method provides a unified framework for quantifying DNA sequence
specificity and serves as a guide for development of sequence-based prediction
models.

DOI: 10.1186/1471-2105-12-408 
PMCID: PMC3267244
PMID: 22017798  [PubMed - indexed for MEDLINE]


1489. Bioinformatics. 2011 Dec 15;27(24):3425-6. doi: 10.1093/bioinformatics/btr569.
Epub 2011 Oct 12.

Visualization and quality assessment of de novo genome assemblies.

Riba-Grognuz O(1), Keller L, Falquet L, Xenarios I, Wurm Y.

Author information: 
(1)Department of Ecology and Evolution, University of Lausanne, 1015 Lausanne,
Switzerland. oksana.ribagrognuz@unil.ch

SUMMARY: Recent technological progress has greatly facilitated de novo genome
sequencing. However, de novo assemblies consist in many pieces of contiguous
sequence (contigs) arranged in thousands of scaffolds instead of small numbers of
chromosomes. Confirming and improving the quality of such assemblies is critical 
for subsequent analysis. We present a method to evaluate genome scaffolding by
aligning independently obtained transcriptome sequences to the genome and
visually summarizing the alignments using the Cytoscape software. Applying this
method to the genome of the red fire ant Solenopsis invicta allowed us to
identify inconsistencies in 7%, confirm contig order in 20% and extend 16% of
scaffolds.
CONTACT: oksana.ribagrognuz@unil.ch; yannick.wurm@unil.ch
AVAILABILITY: Scripts that generate tables for visualization in Cytoscape from
FASTA sequence and scaffolding information files are publicly available at
https://github.com/ksanao/TGNet.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btr569 
PMID: 21994228  [PubMed - indexed for MEDLINE]


1490. Bioinformatics. 2011 Oct 15;27(20):2910-2. doi: 10.1093/bioinformatics/btr481.
Epub 2011 Sep 11.

SPREAD: spatial phylogenetic reconstruction of evolutionary dynamics.

Bielejec F(1), Rambaut A, Suchard MA, Lemey P.

Author information: 
(1)Rega Institute for Medical Research, Clinical and Epidemiological Virology
Section, Katholieke Universiteit Leuven, Leuven, Belgium.
filip.bielejec@rega.kuleuven.be

SUMMARY: SPREAD is a user-friendly, cross-platform application to analyze and
visualize Bayesian phylogeographic reconstructions incorporating spatial-temporal
diffusion. The software maps phylogenies annotated with both discrete and
continuous spatial information and can export high-dimensional posterior
summaries to keyhole markup language (KML) for animation of the spatial diffusion
through time in virtual globe software. In addition, SPREAD implements Bayes
factor calculation to evaluate the support for hypotheses of historical diffusion
among pairs of discrete locations based on Bayesian stochastic search variable
selection estimates. SPREAD takes advantage of multicore architectures to process
large joint posterior distributions of phylogenies and their spatial diffusion
and produces visualizations as compelling and interpretable statistical summaries
for the different spatial projections.
AVAILABILITY: SPREAD is licensed under the GNU Lesser GPL and its source code is 
freely available as a GitHub repository: https://github.com/phylogeography/SPREAD
CONTACT: filip.bielejec@rega.kuleuven.be.

DOI: 10.1093/bioinformatics/btr481 
PMCID: PMC3187652
PMID: 21911333  [PubMed - indexed for MEDLINE]


1491. BMC Res Notes. 2011 Sep 8;4:331. doi: 10.1186/1756-0500-4-331.

Agile parallel bioinformatics workflow management using Pwrake.

Mishima H(1), Sasaki K, Tanaka M, Tatebe O, Yoshiura K.

Author information: 
(1)Department of Human Genetics, Nagasaki University Graduate School of
Biomedical Sciences, 1-12-4 Sakamoto, Nagasaki, Nagasaki, Japan.
hmishima@nagasaki-u.ac.jp.

BACKGROUND: In bioinformatics projects, scientific workflow systems are widely
used to manage computational procedures. Full-featured workflow systems have been
proposed to fulfil the demand for workflow management. However, such systems tend
to be over-weighted for actual bioinformatics practices. We realize that quick
deployment of cutting-edge software implementing advanced algorithms and data
formats, and continuous adaptation to changes in computational resources and the 
environment are often prioritized in scientific workflow management. These
features have a greater affinity with the agile software development method
through iterative development phases after trial and error.Here, we show the
application of a scientific workflow system Pwrake to bioinformatics workflows.
Pwrake is a parallel workflow extension of Ruby's standard build tool Rake, the
flexibility of which has been demonstrated in the astronomy domain. Therefore, we
hypothesize that Pwrake also has advantages in actual bioinformatics workflows.
FINDINGS: We implemented the Pwrake workflows to process next generation
sequencing data using the Genomic Analysis Toolkit (GATK) and Dindel. GATK and
Dindel workflows are typical examples of sequential and parallel workflows,
respectively. We found that in practice, actual scientific workflow development
iterates over two phases, the workflow definition phase and the parameter
adjustment phase. We introduced separate workflow definitions to help focus on
each of the two developmental phases, as well as helper methods to simplify the
descriptions. This approach increased iterative development efficiency. Moreover,
we implemented combined workflows to demonstrate modularity of the GATK and
Dindel workflows.
CONCLUSIONS: Pwrake enables agile management of scientific workflows in the
bioinformatics domain. The internal domain specific language design built on Ruby
gives the flexibility of rakefiles for writing scientific workflows. Furthermore,
readability and maintainability of rakefiles may facilitate sharing workflows
among the scientific community. Workflows for GATK and Dindel are available at
http://github.com/misshie/Workflows.

DOI: 10.1186/1756-0500-4-331 
PMCID: PMC3180464
PMID: 21899774  [PubMed]


1492. BMC Bioinformatics. 2011 Aug 8;12:327. doi: 10.1186/1471-2105-12-327.

NETGEM: Network Embedded Temporal GEnerative Model for gene expression data.

Jethava V(1), Bhattacharyya C, Dubhashi D, Vemuri GN.

Author information: 
(1)Department of Computer Science and Engineering, Chalmers University
ofTechnology, Göteborg, Sweden.

BACKGROUND: Temporal analysis of gene expression data has been limited to
identifying genes whose expression varies with time and/or correlation between
genes that have similar temporal profiles. Often, the methods do not consider the
underlying network constraints that connect the genes. It is becoming
increasingly evident that interactions change substantially with time. Thus far, 
there is no systematic method to relate the temporal changes in gene expression
to the dynamics of interactions between them. Information on interaction dynamics
would open up possibilities for discovering new mechanisms of regulation by
providing valuable insight into identifying time-sensitive interactions as well
as permit studies on the effect of a genetic perturbation.
RESULTS: We present NETGEM, a tractable model rooted in Markov dynamics, for
analyzing the dynamics of the interactions between proteins based on the dynamics
of the expression changes of the genes that encode them. The model treats the
interaction strengths as random variables which are modulated by suitable priors.
This approach is necessitated by the extremely small sample size of the datasets,
relative to the number of interactions. The model is amenable to a linear time
algorithm for efficient inference. Using temporal gene expression data, NETGEM
was successful in identifying (i) temporal interactions and determining their
strength, (ii) functional categories of the actively interacting partners and
(iii) dynamics of interactions in perturbed networks.
CONCLUSIONS: NETGEM represents an optimal trade-off between model complexity and 
data requirement. It was able to deduce actively interacting genes and functional
categories from temporal gene expression data. It permits inference by
incorporating the information available in perturbed networks. Given that the
inputs to NETGEM are only the network and the temporal variation of the nodes,
this algorithm promises to have widespread applications, beyond biological
systems.The source code for NETGEM is available from
https://github.com/vjethava/NETGEM.

DOI: 10.1186/1471-2105-12-327 
PMCID: PMC3228555
PMID: 21824426  [PubMed - indexed for MEDLINE]


1493. Bioinformatics. 2011 Sep 1;27(17):2435-6. doi: 10.1093/bioinformatics/btr394.
Epub 2011 Jun 30.

MethylCoder: software pipeline for bisulfite-treated sequences.

Pedersen B(1), Hsieh TF, Ibarra C, Fischer RL.

Author information: 
(1)Department of Plant and Microbial Biology, University of California, Berkeley,
CA 94720, USA. bpederse@gmail.com

MOTIVATION: MethylCoder is a software program that generates per-base methylation
data given a set of bisulfite-treated reads. It provides the option to use either
of two existing short-read aligners, each with different strengths. It accounts
for soft-masked alignments and overlapping paired-end reads. MethylCoder outputs 
data in text and binary formats in addition to the final alignment in SAM format,
so that common high-throughput sequencing tools can be used on the resulting
output. It is more flexible than existing software and competitive in terms of
speed and memory use.
AVAILABILITY: MethylCoder requires only a python interpreter and a C compiler to 
run. Extensive documentation and the full source code are available under the MIT
license at: https://github.com/brentp/methylcode.
CONTACT: bpederse@gmail.com.

DOI: 10.1093/bioinformatics/btr394 
PMCID: PMC3157921
PMID: 21724594  [PubMed - indexed for MEDLINE]


1494. Bioinformatics. 2011 Aug 15;27(16):2309-10. doi: 10.1093/bioinformatics/btr364.
Epub 2011 Jun 17.

Menu-driven cloud computing and resource sharing for R and Bioconductor.

Bolouri H(1), Dulepet R, Angerman M.

Author information: 
(1)Division of Biology, California Institute of Technology, Pasadena, CA 91125,
USA. hbolouri@fhcrc.org

SUMMARY: We report CRdata.org, a cloud-based, free, open-source web server for
running analyses and sharing data and R scripts with others. In addition to using
the free, public service, CRdata users can launch their own private Amazon
Elastic Computing Cloud (EC2) nodes and store private data and scripts on
Amazon's Simple Storage Service (S3) with user-controlled access rights. All
CRdata services are provided via point-and-click menus.
AVAILABILITY AND IMPLEMENTATION: CRdata is open-source and free under the
permissive MIT License (opensource.org/licenses/mit-license.php). The source code
is in Ruby (ruby-lang.org/en/) and available at: github.com/seerdata/crdata.
CONTACT: hbolouri@fhcrc.org.

DOI: 10.1093/bioinformatics/btr364 
PMCID: PMC3150038
PMID: 21685055  [PubMed - indexed for MEDLINE]


1495. Bioinformatics. 2011 Aug 15;27(16):2296-7. doi: 10.1093/bioinformatics/btr356.
Epub 2011 Jun 17.

Methyl-Analyzer--whole genome DNA methylation profiling.

Xin Y(1), Ge Y, Haghighi FG.

Author information: 
(1)Department of Psychiatry, Columbia University and New York State Psychiatric
Institute, New York, NY 10032, USA.

SUMMARY: Methyl-Analyzer is a python package that analyzes genome-wide DNA
methylation data produced by the Methyl-MAPS (methylation mapping analysis by
paired-end sequencing) method. Methyl-MAPS is an enzymatic-based method that uses
both methylation-sensitive and -dependent enzymes covering >80% of CpG
dinucleotides within mammalian genomes. It combines enzymatic-based approaches
with high-throughput next-generation sequencing technology to provide whole
genome DNA methylation profiles. Methyl-Analyzer processes and integrates
sequencing reads from methylated and unmethylated compartments and estimates CpG 
methylation probabilities at single base resolution.
AVAILABILITY AND IMPLEMENTATION: Methyl-Analyzer is available at
http://github.com/epigenomics/methylmaps. Sample dataset is available for
download at http://epigenomicspub.columbia.edu/methylanalyzer_data.html.
CONTACT: fgh3@columbia.edu
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btr356 
PMCID: PMC3150045
PMID: 21685051  [PubMed - indexed for MEDLINE]


1496. BMC Genomics. 2011 Jun 2;12:285. doi: 10.1186/1471-2164-12-285.

ngs_backbone: a pipeline for read cleaning, mapping and SNP calling using next
generation sequence.

Blanca JM(1), Pascual L, Ziarsolo P, Nuez F, Cañizares J.

Author information: 
(1)Instituto de Conservación y Mejora de la Agrodiversidad Valenciana (COMAV),
Universidad Politécnica de Valencia, Camino de Vera s/n, Valencia, Spain.

BACKGROUND: The possibilities offered by next generation sequencing (NGS)
platforms are revolutionizing biotechnological laboratories. Moreover, the
combination of NGS sequencing and affordable high-throughput genotyping
technologies is facilitating the rapid discovery and use of SNPs in non-model
species. However, this abundance of sequences and polymorphisms creates new
software needs. To fulfill these needs, we have developed a powerful, yet
easy-to-use application.
RESULTS: The ngs_backbone software is a parallel pipeline capable of analyzing
Sanger, 454, Illumina and SOLiD (Sequencing by Oligonucleotide Ligation and
Detection) sequence reads. Its main supported analyses are: read cleaning,
transcriptome assembly and annotation, read mapping and single nucleotide
polymorphism (SNP) calling and selection. In order to build a truly useful tool, 
the software development was paired with a laboratory experiment. All public
tomato Sanger EST reads plus 14.2 million Illumina reads were employed to test
the tool and predict polymorphism in tomato. The cleaned reads were mapped to the
SGN tomato transcriptome obtaining a coverage of 4.2 for Sanger and 8.5 for
Illumina. 23,360 single nucleotide variations (SNVs) were predicted. A total of
76 SNVs were experimentally validated, and 85% were found to be real.
CONCLUSIONS: ngs_backbone is a new software package capable of analyzing
sequences produced by NGS technologies and predicting SNVs with great accuracy.
In our tomato example, we created a highly polymorphic collection of SNVs that
will be a useful resource for tomato researchers and breeders. The software
developed along with its documentation is freely available under the AGPL license
and can be downloaded from http://bioinf.comav.upv.es/ngs_backbone/ or
http://github.com/JoseBlanca/franklin.

DOI: 10.1186/1471-2164-12-285 
PMCID: PMC3124440
PMID: 21635747  [PubMed - indexed for MEDLINE]


1497. Genome Biol. 2011;12(5):R44. doi: 10.1186/gb-2011-12-5-r44. Epub 2011 May 19.

EMIRGE: reconstruction of full-length ribosomal genes from microbial community
short read sequencing data.

Miller CS(1), Baker BJ, Thomas BC, Singer SW, Banfield JF.

Author information: 
(1)Department of Earth and Planetary Science, University of California, Berkeley,
307 McCone Hall #4767, Berkeley, CA 94720, USA. csmiller@berkeley.edu

Recovery of ribosomal small subunit genes by assembly of short read community DNA
sequence data generally fails, making taxonomic characterization difficult. Here,
we solve this problem with a novel iterative method, based on the expectation
maximization algorithm, that reconstructs full-length small subunit gene
sequences and provides estimates of relative taxon abundances. We apply the
method to natural and simulated microbial communities, and correctly recover
community structure from known and previously unreported rRNA gene sequences. An 
implementation of the method is freely available at
https://github.com/csmiller/EMIRGE.

DOI: 10.1186/gb-2011-12-5-r44 
PMCID: PMC3219967
PMID: 21595876  [PubMed - indexed for MEDLINE]


1498. Source Code Biol Med. 2011 Apr 29;6:8. doi: 10.1186/1751-0473-6-8.

KBWS: an EMBOSS associated package for accessing bioinformatics web services.

Oshita K(1), Arakawa K, Tomita M.

Author information: 
(1)1Institute for Advanced Biosciences, Keio University, Fujisawa, 252-8520,
Japan. gaou@sfc.keio.ac.jp.

The availability of bioinformatics web-based services is rapidly proliferating,
for their interoperability and ease of use. The next challenge is in the
integration of these services in the form of workflows, and several projects are 
already underway, standardizing the syntax, semantics, and user interfaces. In
order to deploy the advantages of web services with locally installed tools, here
we describe a collection of proxy client tools for 42 major bioinformatics web
services in the form of European Molecular Biology Open Software Suite (EMBOSS)
UNIX command-line tools. EMBOSS provides sophisticated means for discoverability 
and interoperability for hundreds of tools, and our package, named the Keio
Bioinformatics Web Service (KBWS), adds functionalities of local and multiple
alignment of sequences, phylogenetic analyses, and prediction of cellular
localization of proteins and RNA secondary structures. This software implemented 
in C is available under GPL from http://www.g-language.org/kbws/ and GitHub
repository http://github.com/cory-ko/KBWS. Users can utilize the SOAP services
implemented in Perl directly via WSDL file at
http://soap.g-language.org/kbws.wsdl (RPC Encoded) and
http://soap.g-language.org/kbws_dl.wsdl (Document/literal).

DOI: 10.1186/1751-0473-6-8 
PMCID: PMC3101651
PMID: 21529350  [PubMed]


1499. BMC Bioinformatics. 2011 Apr 18;12:102. doi: 10.1186/1471-2105-12-102.

Screening synteny blocks in pairwise genome comparisons through integer
programming.

Tang H(1), Lyons E, Pedersen B, Schnable JC, Paterson AH, Freeling M.

Author information: 
(1)Department of Plant and Microbial Biology, University of California, Berkeley,
CA 94720, USA. tanghaibao@gmail.com

BACKGROUND: It is difficult to accurately interpret chromosomal correspondences
such as true orthology and paralogy due to significant divergence of genomes from
a common ancestor. Analyses are particularly problematic among lineages that have
repeatedly experienced whole genome duplication (WGD) events. To compare multiple
"subgenomes" derived from genome duplications, we need to relax the traditional
requirements of "one-to-one" syntenic matchings of genomic regions in order to
reflect "one-to-many" or more generally "many-to-many" matchings. However this
relaxation may result in the identification of synteny blocks that are derived
from ancient shared WGDs that are not of interest. For many downstream analyses, 
we need to eliminate weak, low scoring alignments from pairwise genome
comparisons. Our goal is to objectively select subset of synteny blocks whose
total scores are maximized while respecting the duplication history of the
genomes in comparison. We call this "quota-based" screening of synteny blocks in 
order to appropriately fill a quota of syntenic relationships within one genome
or between two genomes having WGD events.
RESULTS: We have formulated the synteny block screening as an optimization
problem known as "Binary Integer Programming" (BIP), which is solved using
existing linear programming solvers. The computer program QUOTA-ALIGN performs
this task by creating a clear objective function that maximizes the compatible
set of synteny blocks under given constraints on overlaps and depths
(corresponding to the duplication history in respective genomes). Such a
procedure is useful for any pairwise synteny alignments, but is most useful in
lineages affected by multiple WGDs, like plants or fish lineages. For example,
there should be a 1:2 ploidy relationship between genome A and B if genome B had 
an independent WGD subsequent to the divergence of the two genomes. We show
through simulations and real examples using plant genomes in the rosid superorder
that the quota-based screening can eliminate ambiguous synteny blocks and focus
on specific genomic evolutionary events, like the divergence of lineages (in
cross-species comparisons) and the most recent WGD (in self comparisons).
CONCLUSIONS: The QUOTA-ALIGN algorithm screens a set of synteny blocks to retain 
only those compatible with a user specified ploidy relationship between two
genomes. These blocks, in turn, may be used for additional downstream analyses
such as identifying true orthologous regions in interspecific comparisons. There 
are two major contributions of QUOTA-ALIGN: 1) reducing the block screening task 
to a BIP problem, which is novel; 2) providing an efficient software pipeline
starting from all-against-all BLAST to the screened synteny blocks with dot plot 
visualizations. Python codes and full documentations are publicly available
http://github.com/tanghaibao/quota-alignment. QUOTA-ALIGN program is also
integrated as a major component in SynMap
http://genomevolution.com/CoGe/SynMap.pl, offering easier access to thousands of 
genomes for non-programmers.

© 2011 Tang et al; licensee BioMed Central Ltd.

DOI: 10.1186/1471-2105-12-102 
PMCID: PMC3088904
PMID: 21501495  [PubMed - indexed for MEDLINE]


1500. Bioinformatics. 2011 Jun 15;27(12):1691-2. doi: 10.1093/bioinformatics/btr174.
Epub 2011 Apr 14.

BamTools: a C++ API and toolkit for analyzing and managing BAM files.

Barnett DW(1), Garrison EK, Quinlan AR, Strömberg MP, Marth GT.

Author information: 
(1)Department of Biology, Boston College, Chestnut Hill, MA 02467, USA.
barnetde@bc.edu

MOTIVATION: Analysis of genomic sequencing data requires efficient, easy-to-use
access to alignment results and flexible data management tools (e.g. filtering,
merging, sorting, etc.). However, the enormous amount of data produced by current
sequencing technologies is typically stored in compressed, binary formats that
are not easily handled by the text-based parsers commonly used in bioinformatics 
research.
RESULTS: We introduce a software suite for programmers and end users that
facilitates research analysis and data management using BAM files. BamTools
provides both the first C++ API publicly available for BAM file support as well
as a command-line toolkit.
AVAILABILITY: BamTools was written in C++, and is supported on Linux, Mac OSX and
MS Windows. Source code and documentation are freely available at
http://github.org/pezmaster31/bamtools.

DOI: 10.1093/bioinformatics/btr174 
PMCID: PMC3106182
PMID: 21493652  [PubMed - indexed for MEDLINE]


1501. Nucleic Acids Res. 2011 Aug;39(14):5845-52. doi: 10.1093/nar/gkr168. Epub 2011
Apr 7.

RNIE: genome-wide prediction of bacterial intrinsic terminators.

Gardner PP(1), Barquist L, Bateman A, Nawrocki EP, Weinberg Z.

Author information: 
(1)Wellcome Trust Sanger Institute, Wellcome Trust Genome Campus, Hinxton CB10
1SA0, UK. pg5@sanger.ac.uk

Bacterial Rho-independent terminators (RITs) are important genomic landmarks
involved in gene regulation and terminating gene expression. In this
investigation we present RNIE, a probabilistic approach for predicting RITs. The 
method is based upon covariance models which have been known for many years to be
the most accurate computational tools for predicting homology in structural
non-coding RNAs. We show that RNIE has superior performance in model species from
a spectrum of bacterial phyla. Further analysis of species where a low number of 
RITs were predicted revealed a highly conserved structural sequence motif
enriched near the genic termini of the pathogenic Actinobacteria, Mycobacterium
tuberculosis. This motif, together with classical RITs, account for up to 90% of 
all the significantly structured regions from the termini of M. tuberculosis
genic elements. The software, predictions and alignments described below are
available from http://github.com/ppgardne/RNIE.

DOI: 10.1093/nar/gkr168 
PMCID: PMC3152330
PMID: 21478170  [PubMed - indexed for MEDLINE]


1502. RNA. 2011 Apr;17(4):578-94. doi: 10.1261/rna.2536111. Epub 2011 Feb 28.

RNAcode: robust discrimination of coding and noncoding regions in comparative
sequence data.

Washietl S(1), Findeiss S, Müller SA, Kalkhof S, von Bergen M, Hofacker IL,
Stadler PF, Goldman N.

Author information: 
(1)EMBL-European Bioinformatics Institute, Wellcome Trust Genome Campus, Hinxton,
Cambridgeshire CB101SD, United Kingdom. wash@mit.edu

With the availability of genome-wide transcription data and massive comparative
sequencing, the discrimination of coding from noncoding RNAs and the assessment
of coding potential in evolutionarily conserved regions arose as a core analysis 
task. Here we present RNAcode, a program to detect coding regions in multiple
sequence alignments that is optimized for emerging applications not covered by
current protein gene-finding software. Our algorithm combines information from
nucleotide substitution and gap patterns in a unified framework and also deals
with real-life issues such as alignment and sequencing errors. It uses an
explicit statistical model with no machine learning component and can therefore
be applied "out of the box," without any training, to data from all domains of
life. We describe the RNAcode method and apply it in combination with mass
spectrometry experiments to predict and confirm seven novel short peptides in
Escherichia coli and to analyze the coding potential of RNAs previously annotated
as "noncoding." RNAcode is open source software and available for all major
platforms at http://wash.github.com/rnacode.

DOI: 10.1261/rna.2536111 
PMCID: PMC3062170
PMID: 21357752  [PubMed - indexed for MEDLINE]


1503. Bioinformatics. 2011 Apr 1;27(7):1015-6. doi: 10.1093/bioinformatics/btr056. Epub
2011 Feb 3.

Gobe: an interactive, web-based tool for comparative genomic visualization.

Pedersen BS(1), Tang H, Freeling M.

Author information: 
(1)Department of Plant and Microbial Biology, University of California, Berkeley,
CA 94720, USA. bpederse@berkeley.edu

Gobe is a web-based tool for viewing comparative genomic data. It supports
viewing multiple genomic regions simultaneously. Its simple text format and
flash-based rendering make it an interactive, exploratory research tool. Gobe can
be used without installation through our web service, or downloaded and
customized with stylesheets and javascript callback functions.AVAILABILITY: Gobe 
is a flash application that runs in all modern web-browsers. The full
source-code, including that for the online web application is available under the
MIT license at: http://github.com/brentp/gobe. Sample applications are hosted at 
http://try-gobe.appspot.com/ and http://synteny.cnr.berkeley.edu/gobe-app/.

DOI: 10.1093/bioinformatics/btr056 
PMID: 21296748  [PubMed - indexed for MEDLINE]


1504. Bioinformatics. 2011 Feb 15;27(4):589-91. doi: 10.1093/bioinformatics/btq693.
Epub 2010 Dec 17.

SAIL--a software system for sample and phenotype availability across biobanks and
cohorts.

Gostev M(1), Fernandez-Banet J, Rung J, Dietrich J, Prokopenko I, Ripatti S,
McCarthy MI, Brazma A, Krestyaninova M.

Author information: 
(1)Wellcome Trust Genome Campus, Hinxton, Cambridge, CB10 1SD, UK.
gostev@ebi.ac.uk

SUMMARY: The Sample avAILability system-SAIL-is a web based application for
searching, browsing and annotating biological sample collections or biobank
entries. By providing individual-level information on the availability of
specific data types (phenotypes, genetic or genomic data) and samples within a
collection, rather than the actual measurement data, resource integration can be 
facilitated. A flexible data structure enables the collection owners to provide
descriptive information on their samples using existing or custom vocabularies.
Users can query for the available samples by various parameters combining them
via logical expressions. The system can be scaled to hold data from millions of
samples with thousands of variables.
AVAILABILITY: SAIL is available under Aferro-GPL open source license:
https://github.com/sail.

DOI: 10.1093/bioinformatics/btq693 
PMCID: PMC3035801
PMID: 21169373  [PubMed - indexed for MEDLINE]


1505. PLoS One. 2010 Nov 18;5(11):e13897. doi: 10.1371/journal.pone.0013897.

A Bayesian search for transcriptional motifs.

Miller AK(1), Print CG, Nielsen PM, Crampin EJ.

Author information: 
(1)Auckland Bioengineering Institute, The University of Auckland, Auckland, New
Zealand. ak.miller@auckland.ac.nz

Identifying transcription factor (TF) binding sites (TFBSs) is an important step 
towards understanding transcriptional regulation. A common approach is to use
gaplessly aligned, experimentally supported TFBSs for a particular TF, and
algorithmically search for more occurrences of the same TFBSs. The largest
publicly available databases of TF binding specificities contain models which are
represented as position weight matrices (PWM). There are other methods using more
sophisticated representations, but these have more limited databases, or aren't
publicly available. Therefore, this paper focuses on methods that search using
one PWM per TF. An algorithm, MATCHTM, for identifying TFBSs corresponding to a
particular PWM is available, but is not based on a rigorous statistical model of 
TF binding, making it difficult to interpret or adjust the parameters and output 
of the algorithm. Furthermore, there is no public description of the algorithm
sufficient to exactly reproduce it. Another algorithm, MAST, computes a p-value
for the presence of a TFBS using true probabilities of finding each base at each 
offset from that position. We developed a statistical model, BaSeTraM, for the
binding of TFs to TFBSs, taking into account random variation in the base present
at each position within a TFBS. Treating the counts in the matrices and the
sequences of sites as random variables, we combine this TFBS composition model
with a background model to obtain a Bayesian classifier. We implemented our
classifier in a package (SBaSeTraM). We tested SBaSeTraM against a MATCHTM
implementation by searching all probes used in an experimental Saccharomyces
cerevisiae TF binding dataset, and comparing our predictions to the data. We
found no statistically significant differences in sensitivity between the
algorithms (at fixed selectivity), indicating that SBaSeTraM's performance is at 
least comparable to the leading currently available algorithm. Our software is
freely available at: http://wiki.github.com/A1kmm/sbasetram/building-the-tools.

DOI: 10.1371/journal.pone.0013897 
PMCID: PMC2987817
PMID: 21124986  [PubMed - indexed for MEDLINE]


1506. Nucleic Acids Res. 2011 Jan;39(Database issue):D1149-55. doi: 10.1093/nar/gkq866.
Epub 2010 Oct 8.

The Sol Genomics Network (solgenomics.net): growing tomatoes using Perl.

Bombarely A(1), Menda N, Tecle IY, Buels RM, Strickler S, Fischer-York T, Pujar
A, Leto J, Gosselin J, Mueller LA.

Author information: 
(1)Boyce Thompson Institute for Plant Research, Tower Road, Ithaca, NY 14853,
USA.

The Sol Genomics Network (SGN; http://solgenomics.net/) is a clade-oriented
database (COD) containing biological data for species in the Solanaceae and their
close relatives, with data types ranging from chromosomes and genes to phenotypes
and accessions. SGN hosts several genome maps and sequences, including a
pre-release of the tomato (Solanum lycopersicum cv Heinz 1706) reference genome. 
A new transcriptome component has been added to store RNA-seq and microarray
data. SGN is also an open source software project, continuously developing and
improving a complex system for storing, integrating and analyzing data. All code 
and development work is publicly visible on GitHub (http://github.com). The
database architecture combines SGN-specific schemas and the community-developed
Chado schema (http://gmod.org/wiki/Chado) for compatibility with other genome
databases. The SGN curation model is community-driven, allowing researchers to
add and edit information using simple web tools. Currently, over a hundred
community annotators help curate the database. SGN can be accessed at
http://solgenomics.net/.

DOI: 10.1093/nar/gkq866 
PMCID: PMC3013765
PMID: 20935049  [PubMed - indexed for MEDLINE]


1507. Bioinformatics. 2010 Oct 15;26(20):2631-2. doi: 10.1093/bioinformatics/btq455.
Epub 2010 Aug 26.

METAREP: JCVI metagenomics reports--an open source tool for high-performance
comparative metagenomics.

Goll J(1), Rusch DB, Tanenbaum DM, Thiagarajan M, Li K, Methé BA, Yooseph S.

Author information: 
(1)The J. Craig Venter Institute, Rockville, MD 20850, USA.

SUMMARY: JCVI Metagenomics Reports (METAREP) is a Web 2.0 application designed to
help scientists analyze and compare annotated metagenomics datasets. It utilizes 
Solr/Lucene, a high-performance scalable search engine, to quickly query large
data collections. Furthermore, users can use its SQL-like query syntax to filter 
and refine datasets. METAREP provides graphical summaries for top taxonomic and
functional classifications as well as a GO, NCBI Taxonomy and KEGG Pathway
Browser. Users can compare absolute and relative counts of multiple datasets at
various functional and taxonomic levels. Advanced comparative features comprise
statistical tests as well as multidimensional scaling, heatmap and hierarchical
clustering plots. Summaries can be exported as tab-delimited files, publication
quality plots in PDF format. A data management layer allows collaborative data
analysis and result sharing.
AVAILABILITY: Web site http://www.jcvi.org/metarep; source code
http://github.com/jcvi/METAREP CONTACT: syooseph@jcvi.org
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btq455 
PMCID: PMC2951084
PMID: 20798169  [PubMed - indexed for MEDLINE]


1508. Bioinformatics. 2010 Aug 15;26(16):2055-6. doi: 10.1093/bioinformatics/btq320.
Epub 2010 Jun 20.

Bridges: a tool for identifying local similarities in long sequences.

Kondrashov AS(1), Assis R.

Author information: 
(1)Center for Computational Medicine and Bioinformatics, University of Michigan, 
Ann Arbor, MI 48109, USA. kondrash@umich.edu

SUMMARY: Bridges is a heuristic search tool that uses short word matches to
rapidly identify local similarities between sequences. It consists of three
stages: filtering input sequences, identifying local similarities and
post-processing local similarities. As input sequence data are released from
memory after the filtering stage, genome-scale datasets can be efficiently
compared in a single run. Bridges also includes 20 parameters, which enable the
user to dictate the sensitivity and specificity of a search.
AVAILABILITY: Bridges is implemented in the C programming language and can be run
on all platforms. Source code and documentation are available at
http://github.com/rassis/bridges.

DOI: 10.1093/bioinformatics/btq320 
PMID: 20562450  [PubMed - indexed for MEDLINE]


1509. Bioinformatics. 2010 Jun 15;26(12):i237-45. doi: 10.1093/bioinformatics/btq182.

Inference of patient-specific pathway activities from multi-dimensional cancer
genomics data using PARADIGM.

Vaske CJ(1), Benz SC, Sanborn JZ, Earl D, Szeto C, Zhu J, Haussler D, Stuart JM.

Author information: 
(1)Howard Hughes Medical Institute, UC Santa Cruz, CA, USA.

MOTIVATION: High-throughput data is providing a comprehensive view of the
molecular changes in cancer tissues. New technologies allow for the simultaneous 
genome-wide assay of the state of genome copy number variation, gene expression, 
DNA methylation and epigenetics of tumor samples and cancer cell lines. Analyses 
of current data sets find that genetic alterations between patients can differ
but often involve common pathways. It is therefore critical to identify relevant 
pathways involved in cancer progression and detect how they are altered in
different patients.
RESULTS: We present a novel method for inferring patient-specific genetic
activities incorporating curated pathway interactions among genes. A gene is
modeled by a factor graph as a set of interconnected variables encoding the
expression and known activity of a gene and its products, allowing the
incorporation of many types of omic data as evidence. The method predicts the
degree to which a pathway's activities (e.g. internal gene states, interactions
or high-level 'outputs') are altered in the patient using probabilistic
inference. Compared with a competing pathway activity inference approach called
SPIA, our method identifies altered activities in cancer-related pathways with
fewer false-positives in both a glioblastoma multiform (GBM) and a breast cancer 
dataset. PARADIGM identified consistent pathway-level activities for subsets of
the GBM patients that are overlooked when genes are considered in isolation.
Further, grouping GBM patients based on their significant pathway perturbations
divides them into clinically-relevant subgroups having significantly different
survival outcomes. These findings suggest that therapeutics might be chosen that 
target genes at critical points in the commonly perturbed pathway(s) of a group
of patients.
AVAILABILITY: Source code available at http://sbenz.github.com/Paradigm,.
SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics
online.

DOI: 10.1093/bioinformatics/btq182 
PMCID: PMC2881367
PMID: 20529912  [PubMed - indexed for MEDLINE]


1510. Bioinformatics. 2010 Jun 15;26(12):1569-71. doi: 10.1093/bioinformatics/btq228.
Epub 2010 Apr 25.

DendroPy: a Python library for phylogenetic computing.

Sukumaran J(1), Holder MT.

Author information: 
(1)Department of Ecology and Evolutionary Biology, University of Kansas,
Lawrence, USA. jeet@ku.edu

DendroPy is a cross-platform library for the Python programming language that
provides for object-oriented reading, writing, simulation and manipulation of
phylogenetic data, with an emphasis on phylogenetic tree operations. DendroPy
uses a splits-hash mapping to perform rapid calculations of tree distances,
similarities and shape under various metrics. It contains rich simulation
routines to generate trees under a number of different phylogenetic and
coalescent models. DendroPy's data simulation and manipulation facilities, in
conjunction with its support of a broad range of phylogenetic data formats
(NEXUS, Newick, PHYLIP, FASTA, NeXML, etc.), allow it to serve a useful role in
various phyloinformatics and phylogeographic pipelines.AVAILABILITY: The stable
release of the library is available for download and automated installation
through the Python Package Index site (http://pypi.python.org/pypi/DendroPy),
while the active development source code repository is available to the public
from GitHub (http://github.com/jeetsukumaran/DendroPy).

DOI: 10.1093/bioinformatics/btq228 
PMID: 20421198  [PubMed - indexed for MEDLINE]


1511. Bioinformatics. 2010 Mar 15;26(6):843-4. doi: 10.1093/bioinformatics/btq026. Epub
2010 Jan 26.

iMotifs: an integrated sequence motif visualization and analysis environment.

Piipari M(1), Down TA, Saini H, Enright A, Hubbard TJ.

Author information: 
(1)Wellcome Trust Sanger Institute, Hinxton, Cambridgeshire, UK.
matias.piipari@gmail.com

MOTIVATION: Short sequence motifs are an important class of models in molecular
biology, used most commonly for describing transcription factor binding site
specificity patterns. High-throughput methods have been recently developed for
detecting regulatory factor binding sites in vivo and in vitro and consequently
high-quality binding site motif data are becoming available for increasing number
of organisms and regulatory factors. Development of intuitive tools for the study
of sequence motifs is therefore important. iMotifs is a graphical motif analysis 
environment that allows visualization of annotated sequence motifs and scored
motif hits in sequences. It also offers motif inference with the sensitive
NestedMICA algorithm, as well as overrepresentation and pairwise motif matching
capabilities. All of the analysis functionality is provided without the need to
convert between file formats or learn different command line interfaces. The
application includes a bundled and graphically integrated version of the
NestedMICA motif inference suite that has no outside dependencies. Problems
associated with local deployment of software are therefore avoided.
AVAILABILITY: iMotifs is licensed with the GNU Lesser General Public License v2.0
(LGPL 2.0). The software and its source is available at
http://wiki.github.com/mz2/imotifs and can be run on Mac OS X Leopard
(Intel/PowerPC). We also provide a cross-platform (Linux, OS X, Windows) LGPL 2.0
licensed library libxms for the Perl, Ruby, R and Objective-C programming
languages for input and output of XMS formatted annotated sequence motif set
files.
CONTACT: matias.piipari@gmail.com; imotifs@googlegroups.com.

DOI: 10.1093/bioinformatics/btq026 
PMCID: PMC2832821
PMID: 20106815  [PubMed - indexed for MEDLINE]

